{"text": "\n\nThe `multi2vec-palm` module uses a Google multimodal embedding model to create vectors from text or images\n\n## Considerations\n\n- This module enables the `nearText` and `nearImage` [search operators](#additional-search-operators).\n- `multi2vec-palm` uses an external API.\n  - Check vendor pricing before you vectorize data.\n  - Obtain an API key from the vendor.\n\n- This module is only compatible with [Google Vertex AI](https://cloud.google.com/vertex-ai). It is not compatible with Google AI Studio.\n- The module s not compatible with Auto-schema. [Define](#collection-configuration) your collections manually.\n\n## Weaviate instance configuration\n\nIf you use Weaviate Cloud Services (WCS), this module is already enabled and pre-configured. You cannot edit the configuration in WCS.\n\n### Docker Compose file\n\nTo use the `multi2vec-palm` module, enable it in your [Docker Compose](/developers/weaviate/installation/docker-compose) file. Edit your `docker-compose.yml` manually or use the Weaviate [configuration tool](/developers/weaviate/installation/docker-compose.md#configurator) to generate the file.\n\n#### Parameters\n\n| Parameter | Required | Default | Description |\n|:--|:--|:--|:--|\n| `location` | Yes | None | Where the model runs (e.g. `\"us-central1\"`). |\n| `projectId` | Yes | `\"\"` | The name of your GCP project. |\n| `modelId` |  No | `\"multimodalembedding@001\"` | Current the only model available. |\n| `dimensions` | No | `1408` | Must be one of: `128`, `256`, `512`, `1408`. |\n\nSpecify the API key as a request header or an environment variable.\n\n- Request header: `X-Palm-Api-Key`\n- Environment variable: `PALM_APIKEY`\n\n## Configure `multi2vec-palm` for VertexAI\n\nThis module is only supported in [Google Vertex AI](https://cloud.google.com/vertex-ai). It is not supported in Google AI Studio.\n\nTo enable the Vertex AI API on your Google Cloud project, follow [Google's instructions](https://cloud.google.com/vertex-ai/docs/featurestore/setup).\n\n### Vertex AI API key\n\nThe Vertex AI API key is called an `access token` in Google Cloud.\n\nTo retrieve your token, install the [Google Cloud CLI tool](https://cloud.google.com/cli) and run this command:\n\n```shell\ngcloud auth print-access-token\n```\n\n### Token expiration\n\n\n\n### Example\n\nThis configuration does the following:\n\n- enables  `multi2vec-palm`\n- sets `multi2vec-palm` as the default vectorizer\n- uses an environment variable to set the PaLM API key\n\n```yaml\n...\nversion: '3.4'\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:||site.weaviate_version||\n    restart: on-failure:0\n    ports:\n     - 8080:8080\n     - 50051:50051\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      ENABLE_MODULES: multi2vec-palm\n      DEFAULT_VECTORIZER_MODULE: multi2vec-palm\n      PALM_APIKEY: sk-replace-with-your-api-key  # Or provide the key at query time.\n      CLUSTER_HOSTNAME: 'node1'\n...\n```\n\n## Collection configuration\n\nTo specify module behavior in a collection, edit the Weaviate [schema](/developers/weaviate/manage-data/collections.mdx).\n\n### Vectorization settings\n\nSet vectorizer behavior in the `moduleConfig` section for each collection and property.\n\n#### Collection-level settings\n\n| Parameter | Description |\n| :-- | :-- |\n| `vectorizer` | The module to use to vectorize the data. |\n| `vectorizeClassName` | When `true`, vectorize the collection name. Defaults to `true`. |\n| `Fields` | Map property names to modalities (under `moduleConfig.multi2vec-palm`).One of: `textFields`, `imageFields` |\n| `weights` | Change the contribution of the different modalities when calculating the vector. |\n\n\n#### Property-level settings\n\n| Parameter | Description |\n| :-- | :-- |\n| `skip` | When true, do not vectorize the property. Defaults to `false` |\n| `vectorizePropertyName` | When `true`, vectorize the property name. Defaults to `true`. |\n| `dataType` | The property's data type. Use in `Fields`. One of: `text`,`blob` |\n\n#### Example\n\nThis collection definition sets the following:\n\n- The `multi2vec-palm` module is the `vectorizer` for the collection `MultimodalExample`.\n- The `name` property is `text` datatype and is a text field.\n- The `image` property is a `blob` datatype and is an image field.\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"MultimodalExample\",\n      \"description\": \"An example collection for multi2vec-palm\",\n      // highlight-start\n      \"vectorizer\": \"multi2vec-palm\",\n      \"moduleConfig\": {\n        \"multi2vec-palm\": {\n          \"textFields\": [\"name\"],\n          \"imageFields\": [\"image\"],\n        }\n      },\n      \"properties\": [\n        {\n          \"dataType\": [\"text\"],\n          \"name\": \"name\"\n        },\n        {\n          \"dataType\": [\"blob\"],\n          \"name\": \"image\"\n        }\n      ],\n      // highlight-end\n    }\n  ]\n}\n```\n\n#### Example with weights\n\nThe following example adds weights:\n\n- `textFields` is 0.7\n- `imageFields` is 0.3\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"MultimodalExample\",\n      \"moduleConfig\": {\n        \"multi2vec-palm\": {\n          ...\n          // highlight-start\n          \"weights\": {\n            \"textFields\": [0.7],\n            \"imageFields\": [0.3],\n          }\n          // highlight-end\n        }\n      }\n    }\n  ]\n}\n```\n\n### `blob` data objects\n\nData that has the `blob` property type must be base64 encoded. To get the base64-encoded value of an image, use the helper methods in the Weaviate clients or run the following command:\n\n```bash\ncat my_image.png | base64\n```\n\n## Additional information\n\n### Available models\n\nCurrently, the only available model is `multimodalembedding@001`.\n\n## Additional search operators\n\nThe `multi2vec-palm` vectorizer module enables the `nearText` and `nearImage` search operators.\n\nThese operators can do cross-modal search and retrieval.\n\nAll objects are encoded into a single vector space. This means, a query that use one modality, such as text, returns results from all available modalities.\n\n## Usage example\n\n### NearText\n\n\n\n### NearImage\n\n\n\n\n\n", "type": "Documentation", "name": "Retriever-vectorizer-modules Multi2vec-palm", "path": "developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-palm.md", "link": "https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/multi2vec-palm", "timestamp": "2024-05-08 10:50:28", "reader": "JSON", "meta": {}, "chunks": []}