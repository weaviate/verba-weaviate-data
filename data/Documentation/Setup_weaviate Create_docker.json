{"text": "\nGenerating multimodal vectors is currently only possible with local models, and as a result this course uses a local, Docker instance of Weaviate. If you are generating vectors outside of Weaviate, you can use a cloud instance. See the [Work with: your own vectors](../../starter_custom_vectors/index.md) course for more information.\n\nHere, you will create a Weaviate instance and a multi-modal vectorizer container using Docker.\n\n###  Download and run the docker-compose file\n\nInstall Docker on your machine. We recommend following the [official Docker installation guide](https://docs.docker.com/get-docker/).\n\nCreate a new directory and navigate to it in your terminal. Then, create a new file called `docker-compose.yml` and add the following content:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'\n      OPENAI_APIKEY: $OPENAI_APIKEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'multi2vec-clip'\n      ENABLE_MODULES: 'multi2vec-clip,generative-openai,generative-cohere'\n      CLUSTER_HOSTNAME: 'node1'\n  multi2vec-clip:\n    image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n    environment:\n      ENABLE_CUDA: '0'\nvolumes:\n  weaviate_data:\n...\n\n```\n\n###  Create a Weaviate instance\n\nRun the following command to start Weaviate:\n\n```bash\ndocker compose up\n```\n\n###  Your Weaviate instance details\n\nOnce the instance is created, you can access it at `http://localhost:8080`.\n\n###  Connect to your Weaviate instance\n\nTo connect to the Weaviate instance, use the `connect_to_local` function.\n\n\n\n#### Provide inference API keys\n\nSome Weaviate modules can use inference APIs for vectorizing data or large language model integration. You can provide the API keys for these services to Weaviate at instantiation.\n\nThis course uses OpenAI (for retrieval augmented generation), so you can provide the OpenAI API key to Weaviate through `headers={\"X-OpenAI-Api-Key\": }` as shown below:\n\n\n\n\n", "type": "Documentation", "name": "Setup_weaviate Create_docker", "path": "developers/academy/py/starter_multimodal_data/101_setup_weaviate/20_create_docker.mdx", "link": "https://weaviate.io/developers/academy/py/starter_multimodal_data/setup_weaviate/create_docker", "timestamp": "2024-05-08 10:48:03", "reader": "JSON", "meta": {}, "chunks": []}