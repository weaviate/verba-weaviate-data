{"text": "\nSince we are using custom vectors, we need to generate them ourselves.\n\nThis step is optional, as the next section shows you how to download and use the pre-generated vectors. But if you are interested in how to generate vectors, read on.\n\n###  Code\n\nThis example creates embeddings for the movie dataset:\n\n\n\nThis will generate a vector for each movie in the dataset, which we can use when adding the movies to Weaviate.\n\n##  Explain the code\n\n###  Model\n\nWe use the `sentence-transformers/all-MiniLM-L6-v2` model to generate the vectors. We access it here through the Hugging Face API for convenience. You could also use the `transformers` library, if you would like to perform the generation locally.\n\n###  Source text\n\nWe combine the movie title and overview to create a source string for the model. This is the text that the model will \"translate\" into a vector.\n\n\n\n###  Get embeddings in batches\n\nWe use a buffer to store the concatenated strings, and then get the embeddings in batches. This is a good practice to limit the number of requests to the model, and to avoid timeouts.\n\n\n\n###  Export the embeddings\n\nThe embeddings are then saved to a file so that we can use when adding the movies to Weaviate.\n\n\n\n\n", "type": "Documentation", "name": "Object_collections Generate_vectors", "path": "developers/academy/py/starter_custom_vectors/102_object_collections/25_generate_vectors.mdx", "link": "https://weaviate.io/developers/academy/py/starter_custom_vectors/object_collections/generate_vectors", "timestamp": "2024-05-08 10:47:56", "reader": "JSON", "meta": {}, "chunks": []}