{"text": "\n\n## Overview\n\nWeaviate supports deployment with Docker Compose, which allows you to run Weaviate on any OS supported by Docker.\n\nTo start Weaviate with Docker, you can use a Docker Compose file, typically called `docker-compose.yml`. You can:\n* use the Starter Docker Compose file,\n* generate one with the configuration tool,\n* pick one of the examples below.\n\nIf you are new to Docker (Compose) and containerization, check out our Docker Introduction for Weaviate Users.\n\n## Starter Docker Compose file\n\nIf you are new to Weaviate, this is a good place to start.\n\nWe prepared a starter Docker Compose file, which will let you:\n* Run vector searches with `Cohere`, `HuggingFace`, `OpenAI`, and `Google PaLM`.\n* Search already vectorized data \u2013 no vectorizer required.\n* Retrieval augmentated generation (RAG) with `OpenAI` (i.e. `gpt-4`), `Cohere`, and `Google PaLM`.\n\n### Download and run\n\nFirst, save the text below as `docker-compose.yml`:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    - 50051:50051\n    volumes:\n    - weaviate_data:/var/lib/weaviate\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-palm,text2vec-openai,generative-openai,generative-cohere,generative-palm,ref2vec-centroid,reranker-cohere,qna-openai'\n      CLUSTER_HOSTNAME: 'node1'\nvolumes:\n  weaviate_data:\n...\n```\n\nThen, navigate to the directory containing the `docker-compose.yml` file and run this command from your shell:\n\n```bash\ndocker compose up -d\n```\n\n## Configurator\n\nThe Configurator can help you generate the Weaviate setup you need.\n\nUse it to select specific Weaviate modules, including vectorizers that run locally (i.e. `text2vec-transformers`, or `multi2vec-clip`)\n\n\n\n\n\n\n## Environment variables\n\nYou can use environment variables to control your Weaviate setup, authentication and authorization, module settings, and data storage settings.\n\nA comprehensive of list environment variables can be found on this page.\n\n## Example configurations\n\nHere are some examples of how to configure `docker-compose.yml`.\n\n### Persistent volume\n\nIt's recommended to set a persistent volume to avoid data loss and improve reading and writing speeds.\n\nMake sure to run `docker compose down` when shutting down. This writes all the files from memory to disk.\n\n**With named volume**\n```yaml\nservices:\n  weaviate:\n    volumes:\n        - weaviate_data:/var/lib/weaviate\n    # etc\n\nvolumes:\n    weaviate_data:\n```\n\nAfter running a `docker compose up -d`, Docker will create a named volume `weaviate_data` and mount it to the `PERSISTENCE_DATA_PATH` inside the container.\n\n**With host binding**\n```yaml\nservices:\n  weaviate:\n    volumes:\n      - /var/weaviate:/var/lib/weaviate\n    # etc\n```\n\nAfter running a `docker compose up -d`, Docker will mount `/var/weaviate` on the host to the `PERSISTENCE_DATA_PATH` inside the container.\n\n### Weaviate without any modules\n\nAn example Docker Compose setup for Weaviate without any modules can be found below. In this case, no model inference is performed at either import or search time. You will need to provide your own vectors (e.g. from an outside ML model) at import and search time:\n\n```yaml\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\n```\n\n### Weaviate with the `text2vec-transformers` module\n\nAn example Docker Compose file with the transformers model `sentence-transformers/multi-qa-MiniLM-L6-cos-v1` is:\n\n```yaml\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    restart: on-failure:0\n    ports:\n     - \"8080:8080\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      DEFAULT_VECTORIZER_MODULE: text2vec-transformers\n      ENABLE_MODULES: text2vec-transformers\n      TRANSFORMERS_INFERENCE_API: http://t2v-transformers:8080\n      CLUSTER_HOSTNAME: 'node1'\n  t2v-transformers:\n    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1\n    environment:\n      ENABLE_CUDA: 0 # set to 1 to enable\n      # NVIDIA_VISIBLE_DEVICES: all # enable if running with CUDA\n```\n\nNote that transformer models are Neural Networks built to run on\nGPUs. Running Weaviate with the `text2vec-transformers` module and without GPU is\npossible, but it will be slower. Enable CUDA if you have a GPU available\n(`ENABLE_CUDA=1`).\n\nFor more information on how to set up the environment with the\n`text2vec-transformers` module, see [this\npage](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers.md).\n\nThe `text2vec-transformers` module requires at least Weaviate version `v1.2.0`.\n\n\n## Multi-node setup\n\nYou can create a multi-node setup with Weaviate using docker compose. To do so, you need to:\n- Set up one node as a \"founding\" member, and configure the other nodes in the cluster to join it using the `CLUSTER_JOIN` variable.\n- Configure `CLUSTER_GOSSIP_BIND_PORT` and `CLUSTER_DATA_BIND_PORT` for each node.\n- Optionally, you can set the hostname for each node using `CLUSTER_HOSTNAME`.\n\n(Read more about horizontal replication in Weaviate.)\n\nSo, the Docker Compose file includes environment variables for the \"founding\" member that look like this:\n\n```yaml\n  weaviate-node-1:  # Founding member service name\n    ...  # truncated for brevity\n    environment:\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n```\n\nAnd the other members' configurations may look like this:\n\n```yaml\n  weaviate-node-2:\n    ...  # truncated for brevity\n    environment:\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-1:7100'  # This must be the service name of the \"founding\" member node.\n```\n\nBelow is an example configuration for a 3-node setup. You may be able to test replication examples locally using this configuration.\n\n\n\n  Docker Compose file for a replication setup with 3 nodes\n\n```yaml\nservices:\n  weaviate-node-1:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    - 6060:6060\n    restart: on-failure:0\n    volumes:\n      - ./data-node-1:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node1'\n      CLUSTER_GOSSIP_BIND_PORT: '7100'\n      CLUSTER_DATA_BIND_PORT: '7101'\n\n  weaviate-node-2:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8081:8080\n    - 6061:6060\n    restart: on-failure:0\n    volumes:\n      - ./data-node-2:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node2'\n      CLUSTER_GOSSIP_BIND_PORT: '7102'\n      CLUSTER_DATA_BIND_PORT: '7103'\n      CLUSTER_JOIN: 'weaviate-node-1:7100'\n\n  weaviate-node-3:\n    init: true\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8082:8080\n    - 6062:6060\n    restart: on-failure:0\n    volumes:\n      - ./data-node-3:/var/lib/weaviate\n    environment:\n      LOG_LEVEL: 'debug'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      ENABLE_MODULES: 'text2vec-openai,text2vec-cohere,text2vec-huggingface'\n      DEFAULT_VECTORIZER_MODULE: 'none'\n      CLUSTER_HOSTNAME: 'node3'\n      CLUSTER_GOSSIP_BIND_PORT: '7104'\n      CLUSTER_DATA_BIND_PORT: '7105'\n      CLUSTER_JOIN: 'weaviate-node-1:7100'\n```\n\n\n\nIt is a Weaviate convention to set the `CLUSTER_DATA_BIND_PORT` to 1 higher than `CLUSTER_GOSSIP_BIND_PORT`.\n\n\n## Shell attachment options\n\nThe output of `docker compose up` is quite verbose as it attaches to the logs of all containers.\n\nYou can attach the logs only to Weaviate itself, for example, by running the following command instead of `docker compose up`:\n\n```bash\n# Run Docker Compose\ndocker compose up -d && docker compose logs -f weaviate\n```\n\nAlternatively you can run docker compose entirely detached with `docker compose up -d` _and_ then poll `{bindaddress}:{port}/v1/meta` until you receive a status `200 OK`.\n\n\n\n\n\n\n", "type": "Documentation", "name": "installation-docker-compose", "path": "developers/weaviate/installation/docker-compose.md", "link": "https://weaviate.io/developers/weaviate/installation/docker-compose", "timestamp": "2023-11-13 10:40:45", "reader": "JSON", "meta": {}, "chunks": []}