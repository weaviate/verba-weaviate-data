{"text": "\n\n## Overview\n\n* The `generative-palm` module performs retrieval augmented generation, or RAG, using the data stored in your Weaviate instance.\n* The module can generate a response for each returned object, or a single response for a group of objects.\n* The module enables generative search operations on the Weaviate instance.\n* You need an API key for a Google generative model API to use this module.\n* **You may incur costs when you use this module**.\n    * Please check the vendor pricing.\n* You can use this module with Google Cloud Vertex AI, or with Google Google AI Studio.\n\n\n\n\n\nAI Studio (previously called MakerSuite) support was added in version `1.22.4`.\n\n\n\n\n\n\n\n## Configuring `generative-palm` for VertexAI or AI Studio\n\nThe module can be used with either Google Cloud Vertex AI or AI Studio. The configurations vary slightly for each.\n\n### Google Cloud Vertex AI\n\nYou must enable the Vertex AI API on your Google Cloud project. To enable the API, following these instructions.\n\n#### API key for Vertex AI users\n\nThe API key for Vertex AI users is called an `access token` in Google Cloud.\n\nIf you have the Google Cloud CLI tool installed and set up, you can view your token by running the following command:\n\n```shell\ngcloud auth print-access-token\n```\n\n#### Token expiration for Vertex AI users\n\n\n\n\n### AI Studio\n\nAI Studio may not be available in all regions. See this page for the latest information.\n\n#### API key for AI Studio users\n\nYou can obtain an API key by logging in to your AI Studio account and creating an API key. This is the key to pass on to Weaviate. This key does not have an expiration date.\n\n#### `apiEndpoint` for AI Studio users\n\nIn the Weaviate schema configuration, set the `apiEndpoint` to `generativelanguage.googleapis.com`.\n\n## Introduction\n\n`generative-palm` performs retrieval augmented generation, or RAG, based on the data stored in your Weaviate instance.\n\nThe module works in two steps:\n1. Run a search query in Weaviate to find relevant objects.\n2. Use a PaLM or Gemini model to generate a response. The response is based on the results of the previous step and a prompt or task that you provide.\n\nYou can use the `generative-palm` module with any upstream modules. For example, you could use `text2vec-openai`, `text2vec-cohere`, or `text2vec-huggingface` to vectorize and query your data. Then, you can pass the query results to the `generative-palm` module to generate a response.\n\nThe generative module provides results for individual objects or groups of objects:\n\n* `singlePrompt` returns a response for each object.\n* `groupedTask` groups the results to return a single response.\n\nYou need to input both a query and a prompt (for individual responses) or a task (for all responses).\n\n## Inference API key\n\n`generative-palm` uses a google API endpoint, you must provide a valid google API key to Weaviate.\n\n### Provide the key to Weaviate\n\nTo provide your Google API key, use the `\"X-PaLM-Api-Key\"` request header. If you use a Weaviate client, follow these examples:\n\n\n\n\nOptionally (not recommended), you can provide the Google API key as an environment variable.\n\n\n  How to provide the Google API key as an environment variable\n\nDuring the **configuration** of your Docker instance, by adding `PALM_APIKEY` under `environment` to your `Docker Compose` file, like this:\n\n  ```yaml\n  environment:\n    PALM_APIKEY: 'your-key-goes-here'  # Setting this parameter is optional; you can also provide the key at runtime.\n    ...\n  ```\n\n\n\n## Module configuration\n\nThis module is enabled and pre-configured on Weaviate Cloud Services.\n\n### Docker Compose file (Weaviate open source only)\n\nYou can enable the Generative Palm module in your Docker Compose file (e.g. `docker-compose.yml`). Add the `generative-palm` module (alongside any other module you may need) to the `ENABLE_MODULES` property, like this:\n\n```\nENABLE_MODULES: 'text2vec-palm,generative-palm'\n```\n\n\n  See a full example of a Docker configuration with generative-palm\n\nHere is a full example of a Docker configuration that uses the `generative-palm` module in combination with `text2vec-palm`. The configuration also provides the API key:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image:\n      semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n      - 8080:8080\n      - 50051:50051\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-palm'\n      // highlight-next-line\n      ENABLE_MODULES: 'text2vec-palm,generative-palm'\n      PALM_APIKEY: sk-yourKeyGoesHere  # This parameter is optional; you can also provide the key at runtime.\n      CLUSTER_HOSTNAME: 'node1'\n```\n\n\n\n## Schema configuration\n\nTo configure how the module behaves in a collection, see Weaviate schema.\n\nNote that the `projectId` parameter is required for Vertex AI.\n\nSee this page for code examples on how to specify a generative module.\n\n### Example schema\n\nThis schema configuration sets the Google API information, as well as some optional parameters.\n\n| Parameter | Purpose | Example |\n|:--|:--|:--|\n| `\"projectId\"` | Only required with Vertex AI | `\"cloud-large-language-models\"` |\n| `\"apiEndpoint\"` | Optional | `\"us-central1-aiplatform.googleapis.com\"` |\n| `\"modelId\"` | Optional | `\"chat-bison\"` (Vertex AI)  `\"chat-bison-001\"` (AI Studio) |\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      ...,\n      \"moduleConfig\": {\n        // highlight-start\n        \"generative-palm\": {\n          \"projectId\": \"YOUR-GOOGLE-CLOUD-PROJECT-ID\",    // Only required if using Vertex AI. Replace with your value: (e.g. \"cloud-large-language-models\")\n          \"apiEndpoint\": \"YOUR-API-ENDPOINT\",             // Optional. Defaults to \"us-central1-aiplatform.googleapis.\n          \"modelId\": \"YOUR-GOOGLE-CLOUD-ENDPOINT-ID\",     // Optional. Defaults to `\"chat-bison\"` for Vertex AI and `\"chat-bison-001\"` for AI Studio.\n          \"temperature\": 0.2,      // Optional\n          \"maxOutputTokens\": 512,  // Optional\n          \"topK\": 3,               // Optional\n          \"topP\": 0.95,            // Optional\n        }\n        // highlight-end\n      }\n    }\n  ]\n}\n```\n\nSee the relevant Google API documentation for further details on these parameters.\n\n\n  New to Weaviate Schemas?\n\nIf you are new to Weaviate, check out the Weaviate schema tutorial.\n\n\n\n## How to use the module\n\nThis module extends the `_additional {...}` property with a `generate` operator.\n\n`generate` takes the following arguments:\n\n| Field | Data Type | Required | Example | Description |\n|- |- |- |- |- |\n| `singleResult {prompt}`  | string | no | `Summarize the following in a tweet: {summary}`  | Generates a response for each individual search result. You need to include at least one result field in the prompt, between braces. |\n| `groupedResult {task}`  | string | no | `Explain why these results are similar to each other`  | Generates a single response for all search results |\n\n### Example of properties in the prompt\n\nWhen you pipe query results to the prompt, the query pass at least one field. If your results don't pass any fields, Weaviate throws an error.\n\nFor example, assume your schema looks like this:\n\n```graphql\n{\n  Article {\n    title\n    summary\n  }\n}\n```\n\nYou can add both `title` and `summary` to the prompt by enclosing them in curly brackets:\n\n```graphql\n{\n  Get {\n    Article {\n      title\n      summary\n      _additional {\n        generate(\n          singleResult: {\n            prompt: \"\"\"\n            Summarize the following in a tweet:\n\n            {title} - {summary}\n            \"\"\"\n          }\n        ) {\n          singleResult\n          error\n        }\n      }\n    }\n  }\n}\n```\n\n### Example - single result\n\nHere is an example of a single result query:\n* A vector search (with `nearText`) finds articles about \"Italian food.\"\n* The generator module describes each result as a Facebook ad.\n  * The query asks for the `summary` field\n  * The query adds `summary` field to the `prompt` for the `generate` operator.\n\n\n\n\n### Example response - single result\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"generate\": {\n              \"error\": null,\n              \"singleResult\": \"This Facebook Ad will explore the fascinating history of Italian food and how it has evolved over time. Learn from Dr Eva Del Soldato and Diego Zancani, two experts in Italian food history, about how even the emoji for pasta isn't just pasta -- it's a steaming plate of spaghetti heaped with tomato sauce on top. Discover how Italy's complex history has shaped the Italian food we know and love today.\"\n            }\n          },\n          \"summary\": \"Even the emoji for pasta isn't just pasta -- it's a steaming plate of spaghetti heaped with tomato sauce on top. But while today we think of tomatoes as inextricably linked to Italian food, that hasn't always been the case. \\\"People tend to think Italian food was always as it is now -- that Dante was eating pizza,\\\" says Dr Eva Del Soldato , associate professor of romance languages at the University of Pennsylvania, who leads courses on Italian food history. In fact, she says, Italy's complex history -- it wasn't unified until 1861 -- means that what we think of Italian food is, for the most part, a relatively modern concept. Diego Zancani, emeritus professor of medieval and modern languages at Oxford University and author of \\\"How We Fell in Love with Italian Food,\\\" agrees.\",\n          \"title\": \"How this fruit became the star of Italian cooking\"\n        }\n      ]\n    }\n  }\n}\n```\n\n### Example - grouped result\n\nHere is an example of a grouped result query:\n* A vector search (with `nearText`) finds publications about finance.\n* The generator module explains why these articles are about finance.\n\n\n\n\n### Example response - grouped result\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Publication\": [\n        {\n          \"_additional\": {\n            \"generate\": {\n              \"error\": null,\n              \"groupedResult\": \"The Financial Times, Wall Street Journal, and The New York Times Company are all about finance because they provide news and analysis on the latest financial markets, economic trends, and business developments. They also provide advice and commentary on personal finance, investments, and other financial topics.\"\n            }\n          },\n          \"name\": \"Financial Times\"\n        },\n        {\n          \"_additional\": {\n            \"generate\": null\n          },\n          \"name\": \"Wall Street Journal\"\n        },\n        {\n          \"_additional\": {\n            \"generate\": null\n          },\n          \"name\": \"The New York Times Company\"\n        }\n      ]\n    }\n  }\n}\n```\n\n## Additional information\n\n### Supported models\n\nYou can specify the model as a part of the schema as shown earlier. Available models and names differ between Vertex AI and AI Studio.\n\nVertex AI:\n- `chat-bison` (default)\n\nAI Studio:\n- `chat-bison-001` (default)\n- `gemini-pro`\n\n\n- `gemini-pro-vision` for Vertex AI and AI Studio\n- `gemini-pro` on Vertex AI\n\n\n\n\n", "type": "Documentation", "name": "reader-generator-modules-generative-palm", "path": "developers/weaviate/modules/reader-generator-modules/generative-palm.md", "link": "https://weaviate.io/developers/weaviate/modules/reader-generator-modules/generative-palm", "timestamp": "2024-02-08 21:21:34", "reader": "JSON", "meta": {}, "chunks": []}