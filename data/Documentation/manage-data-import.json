{"text": "\n\n## Overview\n\nThis page shows how to efficiently add data objects and cross-references to Weaviate. We will collectively refer to these as \"items\".\n\nWe suggest you use batch imports unless you have a specific reason not to. A batch import drastically improves import speed by processing multiple items per request, and clients can parallelize requests.\n\n- How-to: Create objects\n- References: REST - /v1/batch\n\n\n## Requirements\n\nTo import items in batches using a Weaviate client,\n\n1. Initialize a batcher,\n1. Add items to the batcher, and\n1. Ensure that the last batch is sent (i.e. flushed).\n\n### Optimizing for import speed\n\nTo maximise import speed, enable asynchronous indexing in Weaviate and use gRPC batch imports. Asynchronous indexing decouples vector indexing from object creation (read more), and gRPC batch imports are faster than REST batch imports.\n\nBoth features are available in Weaviate `1.22` and higher. (Note that asynchronous indexing is still experimental as of `1.22`, and we do not yet recommend using it in production.)\n\n#### How to use asynchronous indexing\n\nTo enable asynchronous indexing, set the `ASYNC_INDEXING` environment variable to `true` in the Weaviate configuration (e.g. in the `docker-compose.yml` file).\n\nFor example, the `docker-compose.yml` file might look like this (note the `environment` section):\n\n```yaml\nweaviate:\n  image: semitechnologies/weaviate:||site.weaviate_version||\n  ...\n  environment:\n    ASYNC_INDEXING: 'true'\n  ...\n```\n\nAs the asynchronous indexing is being carried out, you can choose to wait for the indexing to complete. For example, the Python client includes a `client.batch.wait_for_vector_indexing()` function to wait for the indexing to complete.\n\n- Configuration: Indexes\n\n#### How to use gRPC batch imports\n\nThe easiest way to use gRPC batch imports is to use the `v4` Python client. Alternatively, you can use the gRPC API (read more) if you so wish.\n\n### Notes\n\n- On supported clients, you can also configure the batch parameters.\n- For multi-tenancy classes, you can specify the tenant name.\n- Some clients can be configured for auto-flushing.\n\n## Basic batch import example\n\nThe following example will add objects to `YourClassName` class using a batch import.\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n    \n  \n\n  \n    \n  \n\n\nIn this example, if the class `YourClassName` does not already exist, it will be created by Weaviate with its auto-schema feature.\n\n\n## Optional object parameters\n\nThe following does not apply to cross-references.\n\n### `id`\n\nYou can optionally specify a UUID as the ID, leave it blank to have Weaviate generate one. You can also use a deterministic UUID (UUIDv5) as shown here to prevent duplicates.\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n### `vector`\n\nYou can optionally specify a vector to represent each object. Otherwise, Weaviate will follow the relevant vectorizer setting.\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n## Batch parameters - Python client\n\nWe recommend using `client.batch` in a context manager as it will automatically flush the last batch when exiting.\n\n### Set batch parameters\n\nYou can set batch parameters using the `client.batch.configure` function.\n\nThe following example specifies a batch size of 200 and parallelizes the import process with up to 2 threads:\n\n\n\n\n### Performance parameters\n\nThe following parameters will have the greatest impact on the batch import speed:\n- `batch_size` (int) - the (initial) size of the batch\n- `num_workers` (int) - the maximum number of parallel workers\n- `dynamic` (bool) - whether to dynamically adjust the `batch_size` based on the number of items in the batch\n\nWe recommend starting with:\n- `batch_size`: 50-200\n- `num_workers`: 1-2,\n- `dynamic`: `True` (if you are not sure what batch size to use)\n\nUsing these parameters, you can set dynamic or automatic batching:\n\n\n\n\n```python\nwith client.batch(\n    batch_size=100,  # Specify the batch size\n    num_workers=2,   # Parallelize the process\n    # dynamic=False  # By default\n) as batch:\n# Add objects to batch\n```\n\n\n\n\n```python\nwith client.batch(\n    batch_size=100,  # Specify the batch size\n    num_workers=2,   # Parallelize the process\n    dynamic=True,    # Weaviate will dynamically adjust the batch size\n) as batch:\n# Add objects to batch\n```\n\n\n\n\n\n### Error handling parameters\n\nThe following parameters will most impact error handling:\n- `timeout_retries` (int) & `connection_error_retries` (int) - Batch-level numbers of retries\n- `weaviate_error_retries` (int) - Object-level number of retries for an error originating from Weaviate (for example inference / transformer timeouts)\n- `callback` - Call a function at the end of batching - for example to inspect the response\n    - The default is `weaviate.util.check_batch_result`\n\nFor a complete list of batch parameters and details about the types of batching, see the Python client batching section.\n\n\n## Batch parameters - other clients\n\nAt this point in time, the other clients do not support batch parameters, and manual flushing is required.\n\n\n## Managing potential duplication\n\nIn Weaviate, the only unique field is the `id`. If you try to import an object with an existing id Weaviate will overwrite the object if one exists. (In single-object creation, Weaviate will throw an error if the `id` exists.)\n\nTo prevent duplicates, we suggest:\n- Using a deterministic ID generation method.\n\nWith a deterministic ID, Weaviate will either be creating a new object or overwriting an existing one, depending on whether the object already exists.\n\n### Generate deterministic ID\n\nYou can do so with the `generate_uuid5` function in the Python client, or the `generateUuid5` function in the TypeScript client. See the `id` section above for a concrete example.\n\n### Check if an object exists\n\nYou can check if an object exists given its id.\n\nClasses and tenants each work like namespaces. So, it is possible to have the same id in different classes and/or tenants.\n\n## Tip: Stream data from large files\n\nA good practice for importing large datasets is to stream the input file rather than risking running out of memory by loading it all at once. For Python, this can be achieved with libraries like ijson for JSON files and pandas for CSV files. For Node, a streams-based solution is presented below.\n\n\n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n\n  \n\n  \n\n\n\n\n\n\n", "type": "Documentation", "name": "manage-data-import", "path": "developers/weaviate/manage-data/import.mdx", "link": "https://weaviate.io/developers/weaviate/manage-data/import", "timestamp": "2023-11-02 10:53:09", "reader": "JSON", "meta": {}, "chunks": []}