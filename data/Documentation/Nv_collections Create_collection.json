{"text": "\nTo use named vectors, your collection be configured with named vector definitions.\n\n##  Code\n\nThis example creates a collection for the movie data, including multiple named vector definitions:\n\n\n\n##  Explain the code\n\nThe key difference here is the use of `NamedVectors` class to define vectorizer configurations. Let's review the code in further detail:\n\nThis code builds on the [multimodal](../../starter_multimodal_data/102_mm_collections/20_create_collection.mdx) example. Review that example for further explanations.\n\n###  Named vector configuration\n\nThis definition allows each object to be represented by three vectors, named `title`, `overview` and `poster_title`.\n\n\n\n#### `title`\n\nThis vector representation is generated from the `title` property (`source_properties`). The `text2vec-openai` module is used for vectorization.\n\nYou could use this to search for movies by similarities to their titles.\n\n#### `overview`\n\nThis vector representation is based on the `overview` property. As such, you could use this to search for movies by similarities to their plot or key ideas.\n\n#### `poster_title`\n\nThis vector representation is generated from a combination of the `title` and `poster` properties. The `multi2vec-clip` module is used for vectorization.\n\nNote that the majority of the vector weight is given to the `poster` property (90%), and the rest to the `title` property (10%). This means that the vector representation will be more influenced by the poster than the title.\n\nAs this uses a multimodal vectorizer, you could use this to search for movies using any image, or text, by their similarity to the title or poster.\n\n\n", "type": "Documentation", "name": "Nv_collections Create_collection", "path": "developers/academy/py/named_vectors/102_nv_collections/20_create_collection.mdx", "link": "https://weaviate.io/developers/academy/py/named_vectors/nv_collections/create_collection", "timestamp": "2024-05-08 10:47:38", "reader": "JSON", "meta": {}, "chunks": []}