{"text": "\nStarting in v1.23, AutoPQ simplifies configuring PQ on new collections.\n\nimport PQOverview from '/_includes/pq-compression/overview-text.mdx' ;\n\n\n\nimport PQTradeoffs from '/_includes/pq-compression/tradeoffs.mdx' ;\n\n\n\nTo configure HNSW, see [Configuration: Vector index](../config-refs/schema/vector-index.md) .\n\n## Enable PQ compression\n\nPQ is configured at a collection level. There are two ways to enable PQ compression:\n\n- [Use AutoPQ to enable PQ compression](./pq-compression.md#configure-autopq).\n- [Manually enable PQ compression](./pq-compression.md#manually-configure-pq).\n\n## Configure AutoPQ\n\n\nFor new collections, use AutoPQ. AutoPQ automates triggering of the PQ training step based on the size of the collection.\n\n### 1. Set the environment variable\n\nAutoPQ requires asynchronous indexing.\n\n- **Open-source Weaviate users**: To enable AutoPQ, set the environment variable `ASYNC_INDEXING=true` and restart your Weaviate instance.\n- [**Weaviate Cloud Services (WCS)**](https://console.weaviate.cloud/) users: Enable async indexing through the WCS console and restart your Weaviate instance.\n\n\n### 2. Configure PQ\n\nSpecify PQ settings for each collection for which it is to be enabled.\n\nFor additional configuration options, see the [PQ parameters](./pq-compression.md#pq-parameters).\n\n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n\n\n### 3. Load your data\n\nLoad your data. You do not have to load an initial set of training data.\n\nAutoPQ creates the PQ codebook when the object count reaches the training limit. By default, the training limit is 100,000 objects per shard.\n\n## Manually configure PQ\n\nAs an alternative to AutoPQ, you can also manually enable PQ on an existing collection. Upon enabling PQ, Weaviate will train the PQ codebook, using the pre-loaded set of objects.\n\nTo manually enable PQ, follow these steps:\n\n- Phase One: Create a codebook\n\n    - [Configure an initial schema without PQ](./pq-compression.md#1-configure-an-initial-schema-without-pq)\n    - [Load some training data](./pq-compression.md#2-load-training-data)\n    - [Enable and train PQ](./pq-compression.md#3-enable-pq-and-create-the-codebook)\n\n- Phase Two: Load the rest of your data\n\n    - [Load the rest of your data](./pq-compression.md#4-load-the-rest-of-your-data)\n\nWhen PQ is enabled, Weaviate uses the smaller of training limit or the collection object count to train PQ.\n\nWe recommend importing a set of 10,000 to 100,000 training objects per shard before you enable PQ.\n\nWeaviate [logs messages](#check-the-system-logs) when PQ is enabled and when vector compression is complete. Do not import the rest of your data until the training step is complete.\n\nThe next few sections work through these steps.\n\n### 1. Configure an initial schema without PQ\n\n[Create a collection](../manage-data/collections.mdx#create-a-collection) without specifying a quantizer.\n\n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n### 2. Load training data\n\n[Add objects](../manage-data/import.mdx) that will be used to train PQ. Weaviate will use the greater of the training limit, or the collection size, to train PQ.\n\nWe recommend loading a representative sample such that the trained centroids are representative of the entire dataset.\n\n\n\n\n  \n    Download sample data\n  \n\n  \n    Use these scripts to get the data for these examples. If you are configuring your own system, you do not need to import this sample data.\n  \n\n\n  \n      \n  \n\n  \n      \n  \n\n  \n      \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n\n\n\n\n  \n    Add data\n  \n\n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n -->\n\n### 3. Enable PQ and create the codebook\n\nUpdate your collection definition to enable PQ. Once PQ is enabled, Weaviate trains the codebook using the training data.\n\n- If the collection has more objects than the training limit, Weaviate randomly selects objects from the collection to train the codebook.\n- If the collection has fewer objects than the training limit, Weaviate uses all objects in the collection to train the codebook.\n\nimport PQMakesCodebook from '/_includes/pq-compression/makes-a-codebook.mdx' ;\n\n\n\nTo enable PQ, update your schema as shown below. For additional configuration options, see the [PQ parameter table](./pq-compression.md#pq-parameters).\n\n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n     \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n### 4. Load the rest of your data\n\nOnce the [codebook has been trained](#enable-pq-and-create-the-codebook), you may continue to add data as per normal. Weaviate compresses the new data when it adds it to the database.\n\nIf you already have data in your Weaviate instance when you create the codebook, Weaviate automatically compresses the remaining objects (the ones after the initial training set).\n\n## PQ Parameters\n\nYou can configure PQ compression by setting the following parameters at the collection level.\n\nimport PQParameters from '/_includes/pq-compression/parameters.mdx' ;\n\n\n\n\n## Additional tools and considerations\n\n### Change the codebook training limit\n\nFor most use cases, 100,000 objects is an optimal training size. There is little benefit to increasing `trainingLimit`. If you do increase `trainingLimit`, the training period will take longer. You could also have memory problems if you set a high `trainingLimit`.\n\nIf you have a small dataset and wish to enable compression, consider using [binary quantization (BQ)](./bq-compression.md). BQ is a simpler compression method that does not require training.\n\n### Check the system logs\n\nWhen compression is enabled, Weaviate logs diagnostic messages like these.\n\n```bash\npq-conf-demo-1  | {\"action\":\"compress\",\"level\":\"info\",\"msg\":\"switching to compressed vectors\",\"time\":\"2023-11-13T21:10:52Z\"}\n\npq-conf-demo-1  | {\"action\":\"compress\",\"level\":\"info\",\"msg\":\"vector compression complete\",\"time\":\"2023-11-13T21:10:53Z\"}\n```\n\nIf you use `docker-compose` to run Weaviate, you can get the logs on the system console.\n\n```bash\ndocker compose logs -f --tail 10 weaviate\n```\n\nYou can also view the log file directly. Check `docker` to get the file location.\n\n```bash\ndocker inspect --format='{{.LogPath}}' \n```\n\n### Review the current `pq` configuration\n\nTo review the current `pq` configuration, you can retrieve it as shown below.\n\n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n## Multiple vectors\n\n\n\nSimilarly, compression must be enabled independently for each vector. The procedure varies slightly by client language, but in each case the idea is the same. Each vector is independent and can use [PQ](/weaviate/configuration/pq-compression.md), [BQ](/weaviate/configuration/bq-compression.md), or no compression.\n\n## Related pages\n- [Configuration: Vector index](../config-refs/schema/vector-index.md)\n- [Concepts: Vector index](../concepts/vector-index.md)\n- [Concepts: Vector quantization](../concepts/vector-quantization.md)\n- [Tutorial: Schema](/developers/weaviate/starter-guides/schema)\n\n\n", "type": "Documentation", "name": "Configuration Pq-compression", "path": "developers/weaviate/configuration/pq-compression.md", "link": "https://weaviate.io/developers/weaviate/configuration/pq-compression", "timestamp": "2024-05-08 10:50:03", "reader": "JSON", "meta": {}, "chunks": []}