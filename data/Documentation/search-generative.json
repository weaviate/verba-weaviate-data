{"text": "\n\n\n\n## Overview\n\nThis page shows you how to perform `generative` searches.\n\nA generative search uses a large language model (LLM) to generate text based on the search results and a user-provided prompt. This technique is also called *retrieval augmented generation*, or RAG.\n\n- API References: GraphQL: Get\n- References: Modules: generative-openai\n- References: Modules: generative-cohere\n- References: Modules: generative-palm\n\n## Requirements\n\nTo use the generative search feature, you must:\n1. Configure Weaviate to use a generator module (`generative-openai`, `generative-cohere`, `generative-palm`),\n2. Configure the parameters for the `generative-*` module in the target class,\n3. Specify a query to retrieve one or more objects, and\n4. Provide a `single prompt` or a `grouped task` to generate text from.\n\n\n\n  How do I configure Weaviate with a generator module?\n\n  You must enable the desired generative search module and (optionally) specify the corresponding inference service (OpenAI, Cohere, PaLM) API key in the relevant Docker Compose file (e.g. `docker-compose.yml`), or (recommended) request that client code provide it with every request. You can generate this file using the Weaviate configuration tool.\n\n  Here are the relevant settings from the Docker Compose file. Ensure the corresponding environment variable is set (i.e. `$OPENAI_APIKEY`, `$COHERE_APIKEY`, or `$PALM_APIKEY`), unless you want the client to supply the API key (recommended).\n\n  \n\n\n```yaml\nservices:\n  weaviate:\n    environment:\n      OPENAI_APIKEY: $OPENAI_APIKEY\n      ENABLE_MODULES: '...,generative-openai,...'\n```\n\n\n\n\n```yaml\nservices:\n  weaviate:\n    environment:\n      COHERE_APIKEY: $COHERE_APIKEY\n      ENABLE_MODULES: '...,generative-cohere,...'\n```\n\n\n\n\n```yaml\nservices:\n  weaviate:\n    environment:\n      PALM_APIKEY: $PALM_APIKEY\n      ENABLE_MODULES: '...,generative-palm,...'\n```\n\n\n\n\n\n\n  How do I set the generative module in the target class?\n\nWhere multiple `generative` modules are enabled, you must specify the generative module to be used in the `moduleConfig` section of the schema. For example, this configures the `Article` class to use the `generative-openai` module:\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Article\",\n      ...,\n      \"moduleConfig\": {\n        \"generative-openai\": {},  // This will configure the 'Article' class to use the 'generative-openai' module\n      }\n    }\n  ]\n}\n```\n\nYou can configure additional module parameters here also. Please refer to the \"Schema configuration\" section in the relevant module page.\n\n\n\n\n## Single prompt\n\nA **single prompt** generative search returns a generated response for each object in the query results. For **single prompt** generative searches, you must specify which object *properties* to use in the prompt.\n\nIn this example, the query:\n1. Retrieves two `JeopardyQuestion` objects related to `World history`,\n1. Prepares a prompt for each object, based on the prompt `\"Convert the following into a question for twitter. Include emojis for fun, but do not include the answer: {question}.\"`, where `{question}` is an object property, and\n1. Retrieves a generated text for each object (2 total), and\n1. Returns the generated text as a part of each object, along with the `question` property.\n\n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n\n  Example response\n\nIt should produce a response like the one below:\n\n\n\n\n\n### Single prompt property selection\n\nWhen using generative search with single prompts, you must specify which object _properties_ to use in the prompt.\n\nThe properties to use as a part of the prompt do *not* need to be among the properties retrieved in the query.\n\nIn this example, the query:\n1. Retrieves two `JeopardyQuestion` objects related to `World history`,\n1. Prepares a prompt for each object, based on the prompt `\"Convert this quiz question: {question} and answer: {answer} into a trivia tweet.` where `{question}` and `{answer}` are object properties, and\n1. Retrieves a generated text for each object (2 total), and\n1. Returns the generated text as a part of each object.\n\nNote that the `question` and `answer` properties are not retrieved in the query, but are used in the prompt.\n\n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n\n  Example response\n\nIt should produce a response like the one below:\n\n\n\n\n\n## Grouped task\n\nA **grouped task** works by generating a response for the entire query results set.\n\nWhen using generative search with a **grouped task**, the required parameter is the user prompt. By default, the entire set of properties are included in the combined prompt unless specified otherwise.\n\n### Example\n\nIn this example, the query:\n1. Retrieves three `JeopardyQuestion` objects related to `cute animals`,\n1. Combines the user prompt with the set of retrieved objects to build the grouped task,\n1. Retrieves one generated text using the grouped task, and\n1. Returns the generated text as a part of the first object returned, as well as the requested `points` property.\n\nNote that the prompt includes information about the type of the animal (from the `answer` property), even though the `answer` property is not explicitly retrieved.\n\n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n\n  Example response\n\nIt should produce a response like the one below:\n\n\n\n\n\n### Grouped task property selection\n\n\nYou can specify which properties will be included in the `grouped task` prompt. Use this to limit the information provided in the prompt, and to reduce the prompt length.\n\nIn this example, the prompt only includes the `question` and `answer` properties. Note that the `answer` property is not explicitly retrieved in the query, but it is used by the prompt.\n\n\n\n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n  \n    \n  \n\n\n\n  Example response\n\nIt should produce a response like the one below:\n\n\n\n\n\n\n\n\n", "type": "Documentation", "name": "search-generative", "path": "developers/weaviate/search/generative.md", "link": "https://weaviate.io/developers/weaviate/search/generative", "timestamp": "2023-11-13 10:41:31", "reader": "JSON", "meta": {}, "chunks": []}