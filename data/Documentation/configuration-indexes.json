{"text": "\n\n\n\n- Concepts: Indexing\n- Concepts: Vector Indexing\n\n## Vector index\n\nWeaviate uses a vector index to facilitate efficient, vector-first data storage and retrieval. This makes it possible to store *very* large amounts of data without decreasing performance (assuming scaled well horizontally or having sufficient shards for the indices).\n\n## Weaviate's vector index\nThe first vector index type that Weaviate supports is Hierarchical Navigable Small Worlds (HNSW). Consequently, HNSW is the default vector index type. HNSW indexes are scalable and super fast at query time, but HNSW algorithms are costly during the building process (adding data with vectors).\n\nIf you want to contribute to developing a new index type at Weaviate, you can always contact us or make a pull request in our GitHub project. Stay tuned for updates!\n\n### HNSW configuration parameters\n\nCurrently the only index type is HNSW, so all data objects will be indexed using the HNSW algorithm unless you specify otherwise in your data schema.\n\n- `vectorIndexType` is the ANN algorithm you want to use. By default, Weaviate selects `hnsw` -- the Hierarchical Navigable Small World (HNSW) algorithm.\n- `\"vectorIndexConfig\"`: an object where you can set specific parameters to the chosen vector index type, in this case to hnsw, which has the following parameters:\n  - `\"distance\"`: The distance metric to be used to calculate the distance between any two arbitrary vectors. Defaults to `cosine`. See supported metrics here.\n  - `\"ef\"`: The higher `ef` is chosen, the more accurate, but also slower a search becomes. This helps in the recall/performance trade-off that is possible with HNSW. If you omit setting this field it will default to `-1` which means \"Let Weaviate pick the right `ef` value\". `ef` can be updated over time, and is not immutable like `efConstruction` and `maxConnections`.\n  - `\"efConstruction\"`: controls index search speed/build speed tradeoff. The tradeoff here is on importing. So a high `efConstruction` means that you can lower your `ef` settings but that importing will be slower. Default is set to 128, the integer should be greater than 0. This setting is immutable after class initialization.\n  - `\"maxConnections\"`: the maximum number of connections per element in all layers. Default is set to 64, the integer should be greater than 0. This setting is immutable after class initialization.\n  - `\"dynamicEfMin\"`: If using dynamic `ef` (set to `-1`), this value acts as a lower boundary. Even if the limit is small enough to suggest a lower value, `ef` will never drop below this value. This helps in keeping search accuracy high even when setting very low limits, such as 1, 2, or 3. *Not available prior to `v1.10.0`. Defaults to `100`. This setting has no effect if `ef` has a value other than `-1`.*\n  - `\"dynamicEfMax\"`: If using dynamic `ef` (set to `-1`), this value acts as an upper boundary. Even if the limit is large enough to suggest a lower value, `ef` will be capped at this value. This helps to keep search speed reasonable when retrieving massive search result sets, e.g. 500+. Note that the maximum will not have any effect if the limit itself is higher than this maximum. In this case the limit will be chosen as `ef` to avoid a situation where `limit` would higher than `ef` which is impossible with HNSW. *Not available prior to `v1.10.0`. Defaults to `500`. This setting has no effect if `ef` has a value other than `-1`.*\n  - `\"dynamicEfFactor\"`: If using dynamic `ef` (set to `-1`), this value controls how `ef` is determined based on the given limit. E.g. with a factor of `8`, `ef` will be set to `8*limit` as long as this value is between the lower and upper boundary. It will be capped on either end, otherwise. *Not available prior to `v1.10.0`. Defaults to `8`. This setting has no effect if `ef` has a value other than `-1`.*\n  - `\"vectorCacheMaxObjects\"`: For optimal search and import performance all previously imported vectors need to be held in memory. However, Weaviate also allows for limiting the number of vectors in memory. By default, when creating a new class, this limit is set to one trillion (i.e. `1e12`) objects. A disk lookup for a vector is orders of magnitudes slower than memory lookup, so the cache should be used sparingly. This field is mutable after initially creating the class.\n  Generally we recommend that:\n    - During imports set the limit so that all vectors can be held in memory. Each import requires multiple searches so import performance will drop drastically as not all vectors can be held in the cache.\n    - When only or mostly querying (as opposed to bulk importing) you can experiment with vector cache limits which are lower than your total dataset size. Vectors which aren't currently in cache will be added to the cache if there is still room. If the cache runs full it is dropped entirely and all future vectors need to be read from disk for the first time. Subsequent queries will be taken from the cache, until it runs full again and the procedure repeats. Note that the cache can be a very valuable tool if you have a large dataset, but a large percentage of users only query a specific subset of vectors. In this case you might be able to serve the largest user group from cache while requiring disk lookups for \"irregular\" queries.\n  - `\"flatSearchCutoff\"`: Absolute number of objects configured as the threshold for a flat-search cutoff. If a filter on a filtered vector search matches fewer than the specified elements, the HNSW index is bypassed entirely and a flat (brute-force) search is performed instead. This can speed up queries with very restrictive filters considerably. Optional, defaults to `40000`. Set to `0` to turn off flat-search cutoff entirely.\n  - `\"cleanupIntervalSeconds\"`: How often the async process runs that \"repairs\" the HNSW graph after deletes and updates. (Prior to the repair/cleanup process, deleted objects are simply marked as deleted, but still a fully connected member of the HNSW graph. After the repair has run, the edges are reassigned and the datapoints deleted for good). Typically this value does not need to be adjusted, but if deletes or updates are very frequent it might make sense to adjust the value up or down. (Higher value means it runs less frequently, but cleans up more in a single batch. Lower value means it runs more frequently, but might not be as efficient with each run).\n  - `\"pq\"`: Used to enable product quantization which is a technique that allows for Weaviate\u2019s HNSW vector index to store vectors using fewer bytes. As HNSW stores vectors in memory, this allows for running larger datasets on a given amount of memory. *Weaviate\u2019s HNSW implementation assumes that product quantization will occur after some data has already been loaded. The reason for this is that the codebook needs to be trained on existing data. A good recommendation is to have 10,000 to 100,000 vectors per shard loaded before enabling product quantization.* Please refer to the parameters that can be configured for `\"pq\"` below:\n\n        \n    - `enabled`: Whether product quantization is enabled or not (defaults to `false`). To enable set to `true`.\n    - `trainingLimit`: The maximum number of objects, per shard, used to fit the centroids. Defaults to 100,000 objects. Setting this to a large value will increase the time it takes to fit centroids when PQ is enabled.\n    - `segments`: The number of segments to use. By default this is equal to the number of dimensions. Reducing the number of segments will further reduce the size of the quantized vectors. The number of segments must be divisible by the number of dimensions of each vector.\n    - `centroids`: The number of centroids to use. Reducing the number of centroids will further reduce the size of quantized vectors at the price of recall. When using the `kmeans` encoder, centroids is set to 256 or one byte by default in Weaviate.\n    - `encoder`: An object with encoder specific information. Here you can specify the `type` of encoder as either `kmeans`(default) or `tile`. If using the `tile` encoder you can also specify the `distribution` as `log-normal` (default) or `normal`.\n  - `\"skip\"`: There are situations where it doesn't make sense to vectorize a class. For example if the class is just meant as glue between two other class (consisting only of references) or if the class contains mostly duplicate elements (Note that importing duplicate vectors into HNSW is very expensive as the algorithm uses a check whether a candidate's distance is higher than the worst candidate's distance for an early exit condition. With (mostly) identical vectors, this early exit condition is never met leading to an exhaustive search on each  if not set to `true`, classes will be indexed normally. This setting is immutable after class initialization. _Note that the creation of a vector through a module is decoupled from storing the vector in Weaviate. So, simply skipping the indexing does not skip the generation of a vector if a vectorizer other than `none` is configured on the class (for example through a global default). It is therefore recommended to always set: `\"vectorizer\": \"none\"` explicitly when skipping the vector indexing. If vector indexing is skipped, but a vectorizer is configured (or a vector is provided manually) a warning is logged on each import._\n\nExample of a class could be configured in your data schema:\n\n```json\n{\n  \"class\": \"Article\",\n  \"description\": \"string\",\n  \"properties\": [\n    {\n      \"name\": \"title\",\n      \"description\": \"string\",\n      \"dataType\": [\"text\"]\n    }\n  ],\n  \"vectorIndexType\": \"hnsw\",\n  \"vectorIndexConfig\": {\n    \"skip\": false,\n    \"ef\": 100,\n    \"efConstruction\": 128,\n    \"maxConnections\": 64,\n  }\n}\n```\n\n### Configuration tips\n\nNow you might be wondering: \"What settings do I need for my use case?\"\n\nTo determine this, you need to ask yourself the following questions and compare your answers in the table below:\n\n1. How many queries am I expecting per second?\n1. Am I expecting a lot of imports or updates?\n1. How high should the recall be?\n\n| Answer to Q1 | Answer to Q2 | Answer to Q3 | configuration |\n| --- | --- | --- | --- |\n| not many | no | low | This is the ideal scenario, just keep increasing both the `ef` and `efConstruction` settings low. You don't need a big machine and you will still be happy with the results. |\n| not many | no | high | Here the tricky thing is that your recall needs to be high, the fact you're not expecting a lot of requests or imports means that you can increase both the `ef` and `efConstruction` settings. Just keep increasing them until you are happy with the recall. In this case, you can get pretty close to 100%. |\n| not many | yes | low | Here the tricky thing is the high volume of imports and updates. Whatever you do, make sure to keep `efConstruction` low. Luckily you don't need a high recall, and you're not expecting a lot of queries, so you can play around with the `ef` setting until you've reached the desired recall. |\n| not many | yes | high | Now we need to start and pay attention, you need high recall _and_ you're dealing with a lot of imports or updates. This means that we need to keep the `efConstruction` setting low but we can significantly increase the `ef` settings because your queries per second will be low. |\n| many | no | low | Many queries per second means a low `ef` setting. Luckily you don't need high accuracy and or recall so you can significantly increase the `efConstruction` value. |\n| many | no | high | Many queries per second means a low `ef` setting. Because you need a high recall but are not expecting a lot of imports or updates, you can increase your `efConstruction` until you've reached the desired recall. |\n| many | yes | low | Many queries per second means a low `ef` setting and a high amount of imports and updates means a low `efConstruction` as well. Luckily your recall does not have to be as close to 100% as possible, so you can set the `efConstruction` relatively low to support your input or update throughput while throttling the query per second speed with the `ef` setting. |\n| many | yes | high | Aha, this means you're a perfectionist _or_ that you have a use case which needs the best of all three worlds. What we advise you to do is this: keep increasing your `efConstruction` until you've hit the time limit of imports and updates. Next, keep increasing the `ef` setting until you've reached the desired query per second vs recall trade-off. For what it's worth, many people _think_ they need this, but often they don't. We leave it up to you to decide, or ask for help in our forum.\n\nIf you're looking for a starting point for values, we would advise an `efConstruction` of `128`, `maxConnections` of `32`, and `ef` of `64`.\n\n\nNote that the vector index type only specifies how the vectors of data objects are *indexed* and this is used for data retrieval and similarity search. How the data vectors are determined (which numbers the vectors contain) is specified by the `\"vectorizer\"` parameter which points to a module such as `\"text2vec-contextionary\"` (or to `\"none\"` if you want to import your own vectors). Learn more about all parameters in the data schema here.\n\n### Asynchronous indexing\n\n\nAs of `v1.22`, this is an experimental, opt-in feature. Please use with caution.\n\nStarting in Weaviate `1.22`, you can use asynchronous indexing by opting in.\n\nAsynchronous indexing decouples object creation from vector index updates. Objects are created faster, and the vector index updates in the background. Asynchronous indexing is especially useful for importing large amounts of data.\n\nAsynchronous indexing is off by default. It can be enabled by setting the `ASYNC_INDEXING` environment variable to `true` in the Weaviate configuration (e.g. in the `docker-compose.yml` file). This will enable asynchronous indexing for all classes.\n\n\n  Example Docker Compose configuration\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    restart: on-failure:0\n    ports:\n     - \"8080:8080\"\n     - \"50051:50051\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      QUERY_MAXIMUM_RESULTS: 10000\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n      ENABLE_MODULES: 'text2vec-cohere,text2vec-huggingface,text2vec-openai,text2vec-palm,generative-cohere,generative-openai,generative-palm'\n      CLUSTER_HOSTNAME: 'node1'\n      AUTOSCHEMA_ENABLED: 'false'\n      ASYNC_INDEXING: 'true'\n...\n```\n\n\n\nIf asynchronous indexing is enabled, and search is performed before vectir indexing is complete, a maximum of 100,000 un-indexed objects will be searched by brute force along with the indexed objects. This means that the search performance will be slower until the vector index has been fully updated, and any objects outside of the first 100,000 objects in the queue will not be searched.\n\nThe index status can be found through the node status endpoint. The `nodes/shards/vectorQueueLength` field will show the number of remaining objects to be indexed.\n\n\n\n\nThen, you can check the status of the vector index queue by inspecting the output. The `vectorQueueLength` field will show the number of remaining objects to be indexed. In the example below, the vector index queue has 425 objects remaining to be indexed on the `TestArticle` shard, out of a total of 1000 objects.\n\n```json\n{\n  \"nodes\": [\n    {\n      \"batchStats\": {\n        \"ratePerSecond\": 0\n      },\n      \"gitHash\": \"e6b37ce\",\n      \"name\": \"weaviate-0\",\n      \"shards\": [\n        {\n          \"class\": \"TestArticle\",\n          \"name\": \"nq1Bg9Q5lxxP\",\n          \"objectCount\": 1000,\n          // highlight-start\n          \"vectorIndexingStatus\": \"INDEXING\",\n          \"vectorQueueLength\": 425\n          // highlight-end\n        },\n      ],\n      \"stats\": {\n        \"objectCount\": 1000,\n        \"shardCount\": 1\n      },\n      \"status\": \"HEALTHY\",\n      \"version\": \"1.22.1\"\n    },\n  ]\n}\n```\n\n## Inverted index\n\n### Configure the inverted index\n\nThere are two indexes for filtering or searching the data, where the first (filterable) is for building a fast, Roaring Bitmaps index, and the second (searchable) index is for a BM25 or hybrid search.\n\nSo there are `indexFilterable` and `indexSearchable` keys that can be set to `true` (on) or `false` (off) on a property level. Both are _on_ by default.\n\nThe filterable index is only capable of filtering, while the searchable index can be used for both searching and filtering (though not as fast as the filterable index).\n\nSo, setting `\"indexFilterable\": false` and `\"indexSearchable\": true` (or not setting it at all) will have the trade-off of worse filtering performance but faster imports (due to only needing to update one index) and lower disk usage.\n\nYou can set these keys in the schema like shown below, at a property level:\n\n```json\n{\n    \"class\": \"Author\",\n    \"properties\": [ // \n", "type": "Documentation", "name": "configuration-indexes", "path": "developers/weaviate/configuration/indexes.md", "link": "https://weaviate.io/developers/weaviate/configuration/indexes", "timestamp": "2023-11-02 10:52:58", "reader": "JSON", "meta": {}, "chunks": []}