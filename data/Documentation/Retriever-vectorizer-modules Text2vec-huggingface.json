{"text": "\n\n## Overview\n\nThe `text2vec-huggingface` module enables Weaviate to obtain vectors using the [Hugging Face](https://huggingface.co/models) Inference API.\n\nKey notes:\n\n- As it uses a third-party API, you will need an API key.\n- **Its usage may incur costs**.\n    - Please check the inference [pricing page](https://huggingface.co/inference-api#pricing), especially before vectorizing large amounts of data.\n- This module is available on Weaviate Cloud Services (WCS).\n- Enabling this module will enable the [`nearText` search operator](/developers/weaviate/api/graphql/search-operators.md#neartext).\n- This module only supports [sentence similarity](https://huggingface.co/models?pipeline_tag=sentence-similarity) models.\n\n\n## Weaviate instance configuration\n\nIf you use Weaviate Cloud Services (WCS), this module is already enabled and pre-configured. You cannot edit the configuration in WCS.\n\n### Docker Compose file\n\nTo use `text2vec-huggingface`, you must enable it in your Docker Compose file (`docker-compose.yml`). You can do so manually, or create one using the [Weaviate configuration tool](/developers/weaviate/installation/docker-compose.md#configurator).\n\n#### Parameters\n\n- `ENABLE_MODULES` (Required): The modules to enable. Include `text2vec-huggingface` to enable the module.\n- `DEFAULT_VECTORIZER_MODULE` (Optional): The default vectorizer module. You can set this to `text2vec-huggingface` to make it the default for all classes.\n- `HUGGINGFACE_APIKEY` (Optional): Your Hugging Face API key. You can also provide the key at query time.\n\n#### Example\n\nThis configuration enables `text2vec-huggingface`, sets it as the default vectorizer, and sets the API keys.\n\n```yaml\nversion: '3.4'\nservices:\n  weaviate:\n    image: cr.weaviate.io/semitechnologies/weaviate:||site.weaviate_version||\n    restart: on-failure:0\n    ports:\n     - 8080:8080\n     - 50051:50051\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      # highlight-start\n      ENABLE_MODULES: text2vec-huggingface\n      DEFAULT_VECTORIZER_MODULE: text2vec-huggingface\n      HUGGINGFACE_APIKEY: sk-foobar # Setting this parameter is optional, you can also provide the API key at query time.\n      # highlight-end\n      CLUSTER_HOSTNAME: 'node1'\n```\n\n## Class configuration\n\nYou can configure how the module will behave in each class through the [Weaviate schema](/developers/weaviate/manage-data/collections.mdx).\n\n### API settings\n\n#### Parameters\n\nThe following parameters are available for the API.\n\nNote that you should only set one of:\n\n- `model`,\n- `passageModel` and `queryModel`, or\n- `endpointURL`\n\n| setting | type | description | example | notes |\n| --- | --- | --- | --- | --- |\n| `model` | `string` | The model to use. Do not use with `queryModel` nor `passageModel`. | `\"bert-base-uncased\"` | Can be any public or private Hugging Face model, [sentence similarity models](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads) work best for vectorization.\n| `passageModel` | `string` | DPR passage model.Should be set together with `queryModel`, but without `model`. |`\"sentence-transformers/facebook-dpr-ctx_encoder-single-nq-base\"` | |\n| `queryModel` | `string` | DPR query model.Should be set together with `passageModel`, but without `model`. | `\"sentence-transformers/facebook-dpr-question_encoder-single-nq-base\"` | |\n| `endpointURL` | `string` | (Private or public) Endpoint URL to useNote: when this variable is set, the module will ignore model settings like `model` `queryModel` and `passageModel`. | | [Read more on](https://huggingface.co/inference-endpoints) how to deploy your own Hugging Face Inference Endpoint. |\n| `options.waitForModel` | `boolean` | If the model is not ready, wait for it instead of receiving 503. | | |\n| `options.useGPU` | `boolean` | Use GPU instead of CPU for inference.(If your [account plan](https://huggingface.co/inference-api#pricing) supports it) | | |\n| `options.useCache` | `boolean` | Use the HF cache to speed up results. | | If you use a non-deterministic model, you can set this parameter to prevent the caching mechanism from being used. |\n\n#### Example\n\nThe following example configures the `Document` class by setting the vectorizer to `text2vec-huggingface`, model to `sentence-transformers/all-MiniLM-L6-v2` as well as to wait for the model to load, use GPU and use the cache.\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      \"vectorizer\": \"text2vec-huggingface\",\n      \"moduleConfig\": {\n        \"text2vec-huggingface\": {\n          \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n          \"options\": {\n            \"waitForModel\": true,\n            \"useGPU\": true,\n            \"useCache\": true\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n### Vectorization settings\n\nYou can set vectorizer behavior using the `moduleConfig` section under each class and property:\n\n#### Class-level\n\n- `vectorizer` - what module to use to vectorize the data.\n- `vectorizeClassName` \u2013 whether to vectorize the class name. Default: `true`.\n\n#### Property-level\n\n- `skip` \u2013 whether to skip vectorizing the property altogether. Default: `false`\n- `vectorizePropertyName` \u2013 whether to vectorize the property name. Default: `false`\n\n#### Example\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      \"vectorizer\": \"text2vec-huggingface\",\n      \"moduleConfig\": {\n        \"text2vec-huggingface\": {\n          \"model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n          \"options\": {\n            \"waitForModel\": true,\n            \"useGPU\": true,\n            \"useCache\": true\n          },\n          \"vectorizeClassName\": false\n        }\n      },\n      \"properties\": [\n        {\n          \"name\": \"content\",\n          \"dataType\": [\"text\"],\n          \"description\": \"Content that will be vectorized\",\n          // highlight-start\n          \"moduleConfig\": {\n            \"text2vec-huggingface\": {\n              \"skip\": false,\n              \"vectorizePropertyName\": false\n            }\n          }\n          // highlight-end\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Query-time parameters\n\n### API key\n\nYou can supply the API key at query time by adding it to the HTTP header:\n- `\"X-Huggingface-Api-Key\": \"YOUR-HUGGINGFACE-API-KEY\"`\n\n## Additional information\n\n### API rate limits\n\nSince this module uses your API key, your account's corresponding rate limits will also apply to the module. Weaviate will output any rate-limit related error messages generated by the API.\n\n### Import throttling\n\nOne potential solution to rate limiting would be to throttle the import within your application. We include an example below.\n\n\n  See code example\n\n\n\n\n\n### Support for Hugging Face Inference Endpoints\n\nThe `text2vec-huggingface` module also supports [Hugging Face Inference Endpoints](https://huggingface.co/inference-endpoints), where you can deploy your own model as an endpoint.\n\nTo use your own Hugging Face Inference Endpoint for vectorization with the `text2vec-huggingface` module, pass the endpoint url in the class configuration as the `endpointURL` setting.\n\nPlease note that only `feature extraction` inference endpoint types are supported.\n\n## Usage example\n\n\n\n## Model license(s)\n\nThe `text2vec-huggingface` module is compatible with various models, each with their own license. For detailed information, please review the license of the model you are using in the [Hugging Face Model Hub](https://huggingface.co/models).\n\nIt is your responsibility to evaluate whether the terms of its license(s), if any, are appropriate for your intended use.\n\n\n\n", "type": "Documentation", "name": "Retriever-vectorizer-modules Text2vec-huggingface", "path": "developers/weaviate/modules/retriever-vectorizer-modules/text2vec-huggingface.md", "link": "https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-huggingface", "timestamp": "2024-05-08 10:50:34", "reader": "JSON", "meta": {}, "chunks": []}