{"text": "\n -->\n\nimport PreviewUnit from '../../_snippets/preview.mdx'\n\n\n\n## &nbsp;&nbsp;Overview\n\nWe have covered a lot of ground on chunking in this unit already.\n\nYou saw what chunking is and learned about different chunking methods, and dived into example implementations so that you can see their impact.\n\nIn this section, we will take a step back out from the detailed, micro view to the high level, macro view, while using all that we've learned in context. More specifically, we will take a look at some considerations of what to think about when chunking data, and what it means for your Weaviate implementation.\n\n## &nbsp;&nbsp;Considerations\n\nAs you have seen, there are many different ways to chunk data. But which one is right for you?\n\nThe answer is, as always, \"it depends\". But here are some things to consider when choosing a chunking method:\n\n#### Text per search result\n\nHow much text should each \"hit\" in your search results contain? Is it a sentence, or a paragraph, or something else?\n\nA natural fit would be to chunk the data into the same size as the desired search result.\n\n#### Input query length\n\nConsider what a typical input query might look like. Will it be short search strings, or longer texts, such as those extracted from a document?\n\nKeep in mind that the vector of the query will be compared to the vector of the chunks. So, it may be helpful to have shorter chunks for shorter queries, and longer chunks for longer queries.\n\nIn cases where shorter chunks are used but further context would be beneficial, you could structure your app so that you return the chunk that contains the search term, and the surrounding chunks.\n\n#### Database size\n\nThe larger the chunks, the fewer chunks there will be, and the smaller the database will be. This may be important if you are working with a large dataset.\n\n#### Model requirements\n\nYou will need to ensure that the chunk size is within the model's maximum allowed size (context window). This goes for generating embeddings, as well as for RAG.\n\n#### RAG workflows\n\nAs discussed earlier, shorter chunks will make it easier to include many chunks from a variety of sources, but may not provide enough context. Longer chunks will provide more context, but may not be able to include as many chunks.\n\n### &nbsp;&nbsp;Rule of thumb\n\nHaving said all that, it may be helpful to have a rule of thumb to start with. We suggest starting with a chunk size of 100-150 words and going from there.\n\nThen, you can modify the chunk size based on the considerations above, and your observations on your app's performance.\n\n## &nbsp;&nbsp;Data modelling\n\nBy definition, chunking your source data will mean creating multiple objects out of one source.\n\nAccordingly, you should consider how to model your data to capture the relationships between the chunks and the source data, as well as between chunks. This may help you to efficiently retrieve what you need, such as the metadata relating to the source, or surrounding chunks.\n\n### &nbsp;&nbsp;Collection definition examples\n\nConsider a Weaviate database designed to store data from a library of reference books.\n\nStoring each book as a vector may still be too large, so you may want to chunk the books into paragraphs. Having done so, you may want to create a `Book` collection, and a `Paragraph` collection, with the `Paragraph` collection having the cross-reference property `fromBook`. This will allow you to retrieve the book metadata from the `Book` collection, and the surrounding paragraphs from the `Paragraph` collection.\n\nSo, for example, you may build a `Book` collection like this:\n\n```json\n{\n    \"class\": \"Book\",\n    \"properties\": [\n        ...  // other class properties\n        // highlight-start\n        {\n            \"name\": \"title\",\n            \"dataType\": [\"text\"],\n        },\n        {\n            \"name\": \"text\",\n            \"dataType\": [\"text\"],\n        },\n        // highlight-end\n    ],\n    \"vectorIndexConfig\": {\n        \"skip\": true\n    }\n    ...  // other class attributes\n}\n```\n\nAnd add a `Paragraph` collection like this, that references the `Book` collection:\n\n```json\n{\n    \"class\": \"Paragraph\",\n    \"properties\": [\n        ...  // other class properties\n        // highlight-start\n        {\n            \"name\": \"body\",\n            \"dataType\": [\"Text\"]\n        },\n        {\n            \"name\": \"chunk_number\",\n            \"dataType\": [\"int\"]\n        },\n        {\n            \"name\": \"fromBook\",\n            \"dataType\": [\"Book\"]\n        },\n        // highlight-end\n    ],\n    ...  // other class attributes (e.g. vectorizer)\n}\n```\n\nNote that in this configuration, the `Book` collection is not vectorized, but the `Paragraph` collection is. This will allow the `Book` collection to be used for storage and retrieval of metadata, while the `Paragraph` collection is used for search.\n\nThis is just one example of how you could model your data. You may want to experiment with different configurations to see what works best for your use case.\n\n&nbsp;&nbsp;Review\n\n\n\nAny quiz questions\n\n### &nbsp;&nbsp;Review exercise\n\nTry out ...\n\n### &nbsp;&nbsp;Key takeaways\n\nAdd summary\n\n\n\n\n", "type": "Documentation", "name": "chunking-considerations", "path": "developers/academy/standalone/chunking/50_considerations.mdx", "link": "https://weaviate.io/developers/academy/standalone/chunking/considerations", "timestamp": "2024-02-08 20:21:05", "reader": "JSON", "meta": {}, "chunks": []}