{"text": "\n\n## In short\n\n* The Summarization (`sum-transformers`) module is a Weaviate module that summarizes whole paragraphs into a short text.\n* The module containerizes a summarization-focussed transformers model for Weaviate to connect to. We make pre-built models available here, but you can also attach another transformer model from Hugging Face or even a custom model.\n* The module adds a `summary {}` filter to the GraphQL `_additional {}` field.\n* The module returns the results in the GraphQL `_additional { summary {} }` field.\n\n## Introduction\n\nAs the name indicates, the summarization module can produce a summary of Weaviate text objects at query time.\n\n**For example**, it allows us to run a query on our data in Weaviate, which can take a text like this:\n\n> \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n\nand transform it to a short sentence like this:\n\n> \"The Eiffel Tower is a landmark in Paris, France.\"\n\nFor maximum performance of your queries, transformer-based models should run with GPUs.\nCPUs can be used, however, this will significantly slow down your queries.\n\n### Available modules\n\nHere is the current list of available `SUM` modules - sourced from Hugging Face Model Hub:\n* `bart-large-cnn`\n* `pegasus-xsum`\n\n## How to enable (module configuration)\n\n### Docker Compose\n\nThe `sum-transformers` module can be added as a service to the Docker Compose file. You must have a text vectorizer like `text2vec-contextionary` or `text2vec-transformers` running.\n\nAn example Docker Compose file for using the `sum-transformers` module (with the `facebook-bart-large-cnn` model) in combination with the `text2vec-contextionary` vectorizer module is below:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    - 50051:50051\n    restart: on-failure:0\n    environment:\n      CONTEXTIONARY_URL: contextionary:9999\n      SUM_INFERENCE_API: \"http://sum-transformers:8080\"\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-contextionary'\n      ENABLE_MODULES: 'text2vec-contextionary,sum-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  contextionary:\n    environment:\n      OCCURRENCE_WEIGHT_LINEAR_FACTOR: 0.75\n      EXTENSIONS_STORAGE_MODE: weaviate\n      EXTENSIONS_STORAGE_ORIGIN: http://weaviate:8080\n      NEIGHBOR_OCCURRENCE_IGNORE_PERCENTILE: 5\n      ENABLE_COMPOUND_SPLITTING: 'false'\n    image: semitechnologies/contextionary:en0.16.0-v1.0.2\n    ports:\n    - 9999:9999\n  sum-transformers:\n    image: semitechnologies/sum-transformers:facebook-bart-large-cnn-1.2.0\n    # image: semitechnologies/sum-transformers:google-pegasus-xsum-1.2.0  # Could be used instead\n...\n```\n\nVariable explanations:\n* `SUM_INFERENCE_API`: where the summarization module is running\n\n## How to use (GraphQL)\n\nTo make use of the modules capabilities, extend your query with the following new `_additional` property:\n\n### GraphQL Token\n\nThis module adds a search filter to the GraphQL `_additional` field in queries: `summary{}`. This new filter takes the following arguments:\n\n| Field \t| Data Type \t| Required \t| Example value \t| Description \t|\n|-\t|-\t|-\t|-\t|-\t|\n| `properties` \t| list of strings \t| yes \t| `[\"description\"]` \t| The properties of the queries Class which contains text (`text` or `string` Datatype). You must provide at least one property\t|\n\n### Example query\n\n\n\n\n### GraphQL response\n\nThe answer is contained in a new GraphQL `_additional` property called `summary`, which returns a list of tokens. It contains the following fields:\n* `property` (`string`): The property that was summarized \u2013 this is useful when you summarize more than one property\n* `result` (`string`): The output summary\n\n### Example response\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"summary\": [\n              {\n                \"property\": \"summary\",\n                \"result\": \"Finding the perfect pair of jeans can be a challenge.\"\n              }\n            ]\n          },\n          \"title\": \"The Most Comfortable Gap Jeans to Shop Now\"\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\n```\n\n## Use another Summarization module from Hugging Face\n\nYou can build a Docker image which supports any summarization model from the Hugging Face Model Hub with a two-line Dockerfile. In the following example, we are going to build a custom image for the `google/pegasus-pubmed` model.\n\n#### Step 1: Create a `Dockerfile`\n\nCreate a new `Dockerfile`. We will name it `my-model.Dockerfile`. Add the following lines to it:\n```\nFROM semitechnologies/sum-transformers:custom\nRUN chmod +x ./download.py\nRUN MODEL_NAME=google/pegasus-pubmed ./download.py\n```\n\n#### Step 2: Build and tag your Dockerfile.\n\nWe will tag our Dockerfile as `google-pegasus-pubmed`:\n```\ndocker build -f my-model.Dockerfile -t google-pegasus-pubmed .\n```\n\n#### Step 3: Use the image with Weaviate\n\nYou can now push your image to your favorite registry or reference it locally in your Weaviate `docker-compose.yml` using the Docker tag `google-pegasus-pubmed`.\n\n\n## How it works (under the hood)\n\nThe `sum-transformers` module uses transformer-based summarizer models. They are abstractive, in that they generate new text from the input text, rather than to extract particular sentences. For example, a model may take text like this:\n\n\n  See original text\n\n> *The Loch Ness Monster (Scottish Gaelic: Uilebheist Loch Nis), affectionately known as Nessie, is a creature in Scottish folklore that is said to inhabit Loch Ness in the Scottish Highlands. It is often described as large, long-necked, and with one or more humps protruding from the water. Popular interest and belief in the creature has varied since it was brought to worldwide attention in 1933. Evidence of its existence is anecdotal, with a number of disputed photographs and sonar readings.*\n> *The scientific community explains alleged sightings of the Loch Ness Monster as hoaxes, wishful thinking, and the misidentification of mundane objects. The pseudoscience and subculture of cryptozoology has placed particular emphasis on the creature.*\n\n\n\nAnd summarize it to produce a text like:\n\n> *The Loch Ness Monster is said to be a large, long-necked creature. Popular belief in the creature has varied since it was brought to worldwide attention in 1933. Evidence of its existence is disputed, with a number of disputed photographs and sonar readings. The pseudoscience and subculture of cryptozoology has placed particular emphasis on the creature.*\n\nNote that much of output does not copy the input verbatim, but is *based on* it. The `sum-transformers` module then delivers this output in the response.\n\nNote that like many other language models, summarizer models can only process a limited amount of text. The `sum-transformers` module will be limited to the maximum length of the model it is using. For example, the `facebook/bart-large-cnn` model can only process 1024 tokens.\n\nOn the other hand, be aware that providing an input of insufficient length and detail may cause the transformer model to hallucinate).\n\n## Model license(s)\n\nThe `sum-transformers` module is compatible with various models, each with their own license. For detailed information, please review the license of the model you are using in the Hugging Face Model Hub.\n\nIt is your responsibility to evaluate whether the terms of its license(s), if any, are appropriate for your intended use.\n\n\n\n\n", "type": "Documentation", "name": "reader-generator-modules-sum-transformers", "path": "developers/weaviate/modules/reader-generator-modules/sum-transformers.md", "link": "https://weaviate.io/developers/weaviate/modules/reader-generator-modules/sum-transformers", "timestamp": "2024-02-08 20:23:13", "reader": "JSON", "meta": {}, "chunks": []}