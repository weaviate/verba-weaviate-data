{"text": "## Overview\n\nIn this section, we will explore data import, including details of the batch import process. We will discuss points such as how vectors are imported, what a batch import is, how to manage errors, and some advice on optimization.\n\n## Prerequisites\n\nBefore you start this tutorial, you should follow the steps in the tutorials to have:\n\n- An instance of Weaviate running (e.g. on the [Weaviate Cloud Services](https://console.weaviate.cloud)),\n- An API key for your preferred inference API, such as OpenAI, Cohere, or Hugging Face,\n- Installed your preferred Weaviate client library, and\n- Set up a `Question` class in your schema.\n    - You can follow the Quickstart guide, or the [schema tutorial](../starter-guides/schema.md) to construct the Question class if you have not already.\n\nWe will use the dataset below. We suggest that you download it to your working directory.\n\n\n  Download jeopardy_tiny.json\n\n\n## Import setup\n\nAs mentioned in the [schema tutorial](../starter-guides/schema.md), the `schema` specifies the data structure for Weaviate.\n\nSo the data import must map properties of each record to those of the relevant class in the schema. In this case, the relevant class is **Question** as defined in the previous section.\n\n### Data object structure\n\nEach Weaviate data object is structured as follows:\n\n```json\n{\n  \"class\": \"\",  // as defined during schema creation\n  \"id\": \"\",     // optional, must be in UUID format.\n  \"properties\": {\n    \"\": \"\", // specified in dataType defined during schema creation\n  }\n}\n```\n\nMost commonly, Weaviate users import data through a Weaviate client library.\n\nIt is worth noting, however, that data is ultimately added through the RESTful API, either through the [`objects` endpoint](/developers/weaviate/api/rest#tag/objects) or the [`batch` endpoint](/developers/weaviate/api/rest#tag/batch).\n\nAs the names suggest, the use of these endpoints depend on whether objects are being imported as batches or individually.\n\n### To batch or not to batch\n\nFor importing data, we **strongly suggest that you use batch imports** unless you have a specific reason not to. Batch imports can greatly improve performance by sending multiple objects in a single request.\n\nWe note that batch imports are carried out through the [`batch` REST endpoint](../manage-data/import.mdx).\n\n### Batch import process\n\nA batch import process generally looks like this:\n\n1. Connect to your Weaviate instance\n1. Load objects from the data file\n1. Prepare a batch process\n1. Loop through the records\n    1. Parse each record and build an object\n    1. Push the object through a batch process\n1. Flush the batch process \u2013 in case there are any remaining objects in the buffer\n\nHere is the full code you need to import the **Question** objects:\n\n\n\nThere are a couple of things to note here.\n\n#### Batch size\n\nSome clients include this as a parameter (e.g. `batch_size` in the Python client), or it can be manually set by periodically flushing the batch.\n\nTypically, a size between 20 and 100 is a reasonable starting point, although this depends on the size of each data object. A smaller size may be preferable for larger data objects, such as if vectors are included in each object upload.\n\n#### Where are the vectors?\n\nYou may have noticed that we do not provide a vector. As a `vectorizer` is specified in our schema, Weaviate will send a request to the appropriate module (`text2vec-openai` in this case) to vectorize the data, and the vector in the response will be indexed and saved as a part of the data object.\n\n### Bring your own vectors\n\nIf you wish to upload your own vectors, you can do so with Weaviate. Refer to the [this page](../manage-data/import.mdx#specify-a-vector).\n\nYou can also manually upload existing vectors and use a vectorizer module for vectorizing queries.\n\n## Confirm data import\n\nYou can quickly check the imported object by opening `/v1/objects` in a browser, like this (replace with your Weaviate endpoint):\n\n```\nhttps://some-endpoint.semi.network/v1/objects\n```\n\nOr you can read the objects in your project, like this:\n\n\n\nThe result should look something like this:\n\n```json\n{\n    \"deprecations\": null,\n    \"objects\": [\n        ...  // Details of each object\n    ],\n    \"totalResults\": 10  // You should see 10 results here\n}\n```\n\n## Data import - best practices\n\nWhen importing large datasets, it may be worth planning out an optimized import strategy. Here are a few things to keep in mind.\n\n1. The most likely bottleneck is the import script. Accordingly, aim to max out all the CPUs available.\n1. To use multiple CPUs efficiently, enable sharding when you import data. For the fastest imports, enable sharding even on a single node.\n1. Use [parallelization](https://www.computerhope.com/jargon/p/parallelization.htm#:~:text=Parallelization%20is%20the%20act%20of,the%20next%2C%20then%20the%20next.); if the CPUs are not maxed out, just add another import process.\n1. Use `htop` when importing to see if all CPUs are maxed out.\n1. To avoid out-of-memory issues during imports, set `LIMIT_RESOURCES` to `True` or configure the `GOMEMLIMIT` environment variable. For details, see [Environment variables](../config-refs/env-vars.md).\n1. For Kubernetes, a few large machines are faster than many small machines (due to network latency).\n\nOur rules of thumb are:\n* You should always use batch import.\n* Use multiple shards.\n* As mentioned above, max out your CPUs (on the Weaviate cluster). Often your import script is the bottleneck.\n* Process error messages.\n* Some clients (e.g. Python) have some built-in logic to efficiently control batch importing.\n\n### Error handling\n\nWe recommend that you implement error handling at an object level, such as in [this example](../client-libraries/python/index.md#error-handling).\n\nIt is important to note that an HTTP `200` status code only indicates that the **request** has been successfully sent to Weaviate. In other words, there were no issues with the connection or processing of the batch and no malformed request.\n\nA request with a `200` response may still include object-level errors, which is why error handling is critical.\n\n## Recap\n\n* Data to be imported should match the database schema\n* Use batch import unless you have a good reason not to\n* For importing large datasets, make sure to consider and optimize your import strategy.\n\n## Suggested reading\n\n- [Tutorial: Schemas in detail](../starter-guides/schema.md)\n- [Tutorial: Queries in detail](./query.md)\n- [Tutorial: Introduction to modules](./modules.md)\n- [Tutorial: Introduction to Weaviate Console](/developers/wcs/console.mdx)\n\n### Other object operations\n\nAll other CRUD object operations are available in the [manage-data](../manage-data/index.md) section.\n\n\n\n", "type": "Documentation", "name": "Tutorials Import", "path": "developers/weaviate/tutorials/import.md", "link": "https://weaviate.io/developers/weaviate/tutorials/import", "timestamp": "2024-05-08 10:51:04", "reader": "JSON", "meta": {}, "chunks": []}