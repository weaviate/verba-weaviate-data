{"text": "\n## Introduction\n\n- The `reranker-transformers` module enables reranking search results using sentence transformers models.\n- The `reranker-transformers` module is run on your own inference container with a pre-trained language transformer model.\n\n- How-to search: Rerank\n\n\n## How to enable\n\n### Weaviate Cloud Services\n\nThe `reranker-transformers` module is not available on the WCS.\n\n### Weaviate open source\n\nAdd `reranker-transformers` to the `ENABLE_MODULES` environment variable.\n\nBelow is an example Docker Compose file, which will spin up Weaviate with the `reranker-transformers` module (as well as `text2vec-openai`).\n\nIt also configures `reranker-transformers` to use the `cross-encoder/ms-marco-MiniLM-L-6-v2` model, with CUDA acceleration disabled.\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    restart: on-failure:0\n    environment:\n      RERANKER_INFERENCE_API: 'http://reranker-transformers:8080'\n      OPENAI_APIKEY: $OPENAI_APIKEY\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n      ENABLE_MODULES: 'text2vec-openai,reranker-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  reranker-transformers:\n    image: semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2\n    environment:\n      ENABLE_CUDA: '0'\n...\n```\n\n## Configuration\n\nThe `reranker-transformers` module can be configured for any class in the schema.\n\n\n### Reranker selection\n\nIf there is only one `reranker` module enabled, you don't need to do anything. The `reranker` module will be used by default.\n\nWhere multiple `reranker` modules are enabled, you must specify the reranker module to be used for each class. You can do this by adding the desired reranker in the `moduleConfig` section of the schema, even without any further settings.\n\n\n  Set reranker for a class\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      ...,\n      \"moduleConfig\": {\n        \"reranker-transformers\": {},  // This will configure the 'Document' class to use the 'reranker-transformers' module\n      }\n    }\n  ]\n}\n```\n\n\n\n### Model selection\n\nThe reranker-transformers module enables using sentence transformers models as a second stage re-ranking for vector, bm25 and hybrid search results.\n\nWith `reranker-transformers` module, you must set the model using environment variables as shown above.\n\nThe `reranker-transformers` module supports the following models:\n\n- `cross-encoder/ms-marco-MiniLM-L-6-v2`\n- `cross-encoder/ms-marco-MiniLM-L-2-v2`\n- `cross-encoder/ms-marco-TinyBERT-L-2-v2`\n\nThese pre-trained models are open-sourced on Hugging Face. The `cross-encoder/ms-marco-MiniLM-L-6-v2` model, for example, provides approximately the same benchmark performance as the largest model (L-12) when evaluated on MS-MARCO (39.01 vs. 39.02).\n\n## Usage\n\n### Queries\n\n* Using this module will enable the `rerank` GraphQL _additional property.\n* For usage examples, see the Howto: Search - Reranking page.\n\n\n\n\n\n", "type": "Documentation", "name": "retriever-vectorizer-modules-reranker-transformers", "path": "developers/weaviate/modules/retriever-vectorizer-modules/reranker-transformers.md", "link": "https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/reranker-transformers", "timestamp": "2023-11-02 10:53:28", "reader": "JSON", "meta": {}, "chunks": []}