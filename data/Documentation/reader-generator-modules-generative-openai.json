{"text": "\n\n## In short\n\n* The Generative OpenAI (`generative-openai`) module generates responses based on the data stored in your Weaviate instance.\n* The module can generate a response for each returned object, or a single response for a group of objects.\n* The module adds a `generate {}` operator to the GraphQL `_additional {}` property of the `Get {}` queries.\n* Added in Weaviate `v1.17.3`.\n* The default OpenAI model is `gpt-3.5-turbo`, but other models (e.g. `gpt-4`) are supported.\n* For Azure OpenAI, a model must be specified.\n\n\n\n\n## Introduction\n\n`generative-openai` generates responses based on the data stored in your Weaviate instance.\n\nThe module works in two steps:\n1. (Weaviate) Run a search query in Weaviate to find relevant objects.\n2. (OpenAI) Use an OpenAI model to generate a response based on the results (from the previous step) and the provided prompt or task.\n\nYou can use the Generative OpenAI module with non-OpenAI upstream modules. For example, you could use `text2vec-cohere` or `text2vec-huggingface` to vectorize and query your data, but then rely on the `generative-openai` module to generate a response.\n\nThe generative module can provide results for:\n* each returned object - `singleResult{ prompt }`\n* the group of all results together \u2013 `groupedResult{ task }`\n\nYou need to input both a query and a prompt (for individual responses) or a task (for all responses).\n\n## Inference API key\n\n`generative-openai` requires an API key from OpenAI or Azure OpenAI.\n\nYou only need to provide one of the two keys, depending on which service (OpenAI or Azure OpenAI) you are using.\n\n### Providing the key to Weaviate\n\nYou can provide your API key in two ways:\n\n1. During the **configuration** of your Docker instance, by adding `OPENAI_APIKEY` or `AZURE_APIKEY` as appropriate under `environment` to your `Docker Compose` file, like this:\n\n  ```yaml\n  environment:\n    OPENAI_APIKEY: 'your-key-goes-here'  # For use with OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n    AZURE_APIKEY: 'your-key-goes-here'  # For use with Azure OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n    ...\n  ```\n\n2. At **run-time** (recommended), by providing `\"X-OpenAI-Api-Key\"` or `\"X-Azure-Api-Key\"` through the request header. You can provide it using the Weaviate client, like this:\n\n\n\n\n## Organization name\n\n\nFor requests that require the OpenAI organization name, you can provide it at query time by adding it to the HTTP header:\n- `\"X-OpenAI-Organization\": \"YOUR-OPENAI-ORGANIZATION\"` for OpenAI\n\n## Module configuration\n\nThis module is enabled and pre-configured on Weaviate Cloud Services.\n\n### Docker Compose file (Weaviate open source only)\n\nYou can enable the Generative OpenAI module in your Docker Compose file (e.g. `docker-compose.yml`). Add the `generative-openai` module (alongside any other module you may need) to the `ENABLE_MODULES` property, like this:\n\n```\nENABLE_MODULES: 'text2vec-openai,generative-openai'\n```\n\nHere is a full example of a Docker configuration, which uses the `generative-openai` module in combination with `text2vec-openai`:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n      - --host\n      - 0.0.0.0\n      - --port\n      - '8080'\n      - --scheme\n      - http\n    image:\n      semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n      - 8080:8080\n    restart: on-failure:0\n    environment:\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n      // highlight-next-line\n      ENABLE_MODULES: 'text2vec-openai,generative-openai'\n      OPENAI_APIKEY: sk-foobar  # For use with OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n      OPENAI_ORGANIZATION: your-orgname  # For use with OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n      AZURE_APIKEY: sk-foobar  # For use with Azure OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n      CLUSTER_HOSTNAME: 'node1'\n```\n\n## Schema configuration\n\nYou can define settings for this module in the schema.\n\n### OpenAI vs Azure OpenAI\n\n- **OpenAI** users can optionally set the `model` parameter.\n- **Azure OpenAI** users must set the parameters `resourceName` and `deploymentId`.\n\n### Model parameters\n\nYou can also configure additional parameters for the generative model through the `xxxProperty` parameters shown below.\n\n### Example schema\n\nFor example, the following schema configuration will set Weaviate to use the `generative-openai` model with the `Document` class.\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      ...,\n      \"moduleConfig\": {\n        // highlight-start\n        \"generative-openai\": {\n          \"model\": \"gpt-3.5-turbo\",  // Optional - Defaults to `gpt-3.5-turbo`\n          \"resourceName\": \"\",  // For Azure OpenAI - Required\n          \"deploymentId\": \"\",  // For Azure OpenAI - Required\n          \"temperatureProperty\": ,  // Optional, applicable to both OpenAI and Azure OpenAI\n          \"maxTokensProperty\": ,  // Optional, applicable to both OpenAI and Azure OpenAI\n          \"frequencyPenaltyProperty\": ,  // Optional, applicable to both OpenAI and Azure OpenAI\n          \"presencePenaltyProperty\": ,  // Optional, applicable to both OpenAI and Azure OpenAI\n          \"topPProperty\": ,  // Optional, applicable to both OpenAI and Azure OpenAI\n        },\n        // highlight-end\n      }\n    }\n  ]\n}\n```\n\n\n  New to Weaviate Schemas?\n\nIf you are new to Weaviate, check out the Weaviate schema tutorial.\n\n\n\n## How to use\n\nThis module extends the  `_additional {...}` property with a `generate` operator.\n\n`generate` takes the following arguments:\n\n| Field | Data Type | Required | Example | Description |\n|- |- |- |- |- |\n| `singleResult {prompt}`  | string | no | `Summarize the following in a tweet: {summary}`  | Generates a response for each individual search result. You need to include at least one result field in the prompt, between braces. |\n| `groupedResult {task}`  | string | no | `Explain why these results are similar to each other`  | Generates a single response for all search results |\n\n### Example of properties in the prompt\n\nWhen piping the results to the prompt, at least one field returned by the query must be added to the prompt. If you don't add any fields, Weaviate will throw an error.\n\nFor example, assume your schema looks like this:\n\n```graphql\n{\n  Article {\n    title\n    summary\n  }\n}\n```\n\nYou can add both `title` and `summary` to the prompt by enclosing them in curly brackets:\n\n```graphql\n{\n  Get {\n    Article {\n      title\n      summary\n      _additional {\n        generate(\n          singleResult: {\n            prompt: \"\"\"\n            Summarize the following in a tweet:\n\n            {title} - {summary}\n            \"\"\"\n          }\n        ) {\n          singleResult\n          error\n        }\n      }\n    }\n  }\n}\n```\n\n### Example - single result\n\nHere is an example of a query where:\n* we run a vector search (with `nearText`) to find articles about \"Italian food\"\n* then we ask the generator module to describe each result as a Facebook ad.\n  * the query asks for the `summary` field, which it then includes in the `prompt` argument of the `generate` operator.\n\n\n\n\n### Example response - single result\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"generate\": {\n              \"error\": null,\n              \"singleResult\": \"This Facebook Ad will explore the fascinating history of Italian food and how it has evolved over time. Learn from Dr Eva Del Soldato and Diego Zancani, two experts in Italian food history, about how even the emoji for pasta isn't just pasta -- it's a steaming plate of spaghetti heaped with tomato sauce on top. Discover how Italy's complex history has shaped the Italian food we know and love today.\"\n            }\n          },\n          \"summary\": \"Even the emoji for pasta isn't just pasta -- it's a steaming plate of spaghetti heaped with tomato sauce on top. But while today we think of tomatoes as inextricably linked to Italian food, that hasn't always been the case. \\\"People tend to think Italian food was always as it is now -- that Dante was eating pizza,\\\" says Dr Eva Del Soldato , associate professor of romance languages at the University of Pennsylvania, who leads courses on Italian food history. In fact, she says, Italy's complex history -- it wasn't unified until 1861 -- means that what we think of Italian food is, for the most part, a relatively modern concept. Diego Zancani, emeritus professor of medieval and modern languages at Oxford University and author of \\\"How We Fell in Love with Italian Food,\\\" agrees.\",\n          \"title\": \"How this fruit became the star of Italian cooking\"\n        }\n      ]\n    }\n  }\n}\n```\n\n### Example - grouped result\n\nHere is an example of a query where:\n* we run a vector search (with `nearText`) to find publications about finance,\n* then we ask the generator module to explain why these articles are about finance.\n\n\n\n\n### Example response - grouped result\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Publication\": [\n        {\n          \"_additional\": {\n            \"generate\": {\n              \"error\": null,\n              \"groupedResult\": \"The Financial Times, Wall Street Journal, and The New York Times Company are all about finance because they provide news and analysis on the latest financial markets, economic trends, and business developments. They also provide advice and commentary on personal finance, investments, and other financial topics.\"\n            }\n          },\n          \"name\": \"Financial Times\"\n        },\n        {\n          \"_additional\": {\n            \"generate\": null\n          },\n          \"name\": \"Wall Street Journal\"\n        },\n        {\n          \"_additional\": {\n            \"generate\": null\n          },\n          \"name\": \"The New York Times Company\"\n        }\n      ]\n    }\n  }\n}\n```\n\n## Additional information\n\n### Supported models (OpenAI)\n\nYou can use any of\n\n* gpt-3.5-turbo (default)\n* gpt-3.5-turbo-16k\n* gpt-4\n* gpt-4-32k\n\nThe module also supports these legacy models (not recommended)\n\n* davinci 002\n* davinci 003\n\n\n\n\n", "type": "Documentation", "name": "reader-generator-modules-generative-openai", "path": "developers/weaviate/modules/reader-generator-modules/generative-openai.md", "link": "https://weaviate.io/developers/weaviate/modules/reader-generator-modules/generative-openai", "timestamp": "2023-11-02 10:53:17", "reader": "JSON", "meta": {}, "chunks": []}