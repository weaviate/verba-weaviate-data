{"text": "\n\n## In short\n\n* The Named Entity Recognition (NER) module is a Weaviate module for token classification.\n* The module depends on a NER Transformers model that should be running with Weaviate. There are pre-built models available, but you can also attach another HuggingFace Transformer or custom NER model.\n* The module adds a `tokens {}` filter to the GraphQL `_additional {}` field.\n* The module returns data objects as usual, with recognized tokens in the GraphQL `_additional { tokens {} }` field.\n\n## Introduction\n\nNamed Entity Recognition (NER) module is a Weaviate module to extract entities from your existing Weaviate (text) objects on the fly. Entity Extraction happens at query time. Note that for maximum performance, transformer-based models should run with GPUs. CPUs can be used, but the throughput will be lower.\n\nThere are currently three different NER modules available (taken from Hugging Face): `dbmdz-bert-large-cased-finetuned-conll03-english`, `dslim-bert-base-NER`, `davlan-bert-base-multilingual-cased-ner-hrl`.\n\n## How to enable (module configuration)\n\n### Docker Compose\n\nThe NER module can be added as a service to the Docker Compose file. You must have a text vectorizer like `text2vec-contextionary` or `text2vec-transformers` running. An example Docker Compose file for using the `ner-transformers` module (`dbmdz-bert-large-cased-finetuned-conll03-english`) in combination with the `text2vec-contextionary`:\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    ports:\n    - 8080:8080\n    - 50051:50051\n    restart: on-failure:0\n    environment:\n      CONTEXTIONARY_URL: contextionary:9999\n      NER_INFERENCE_API: \"http://ner-transformers:8080\"\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-contextionary'\n      ENABLE_MODULES: 'text2vec-contextionary,ner-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  contextionary:\n    environment:\n      OCCURRENCE_WEIGHT_LINEAR_FACTOR: 0.75\n      EXTENSIONS_STORAGE_MODE: weaviate\n      EXTENSIONS_STORAGE_ORIGIN: http://weaviate:8080\n      NEIGHBOR_OCCURRENCE_IGNORE_PERCENTILE: 5\n      ENABLE_COMPOUND_SPLITTING: 'false'\n    image: semitechnologies/contextionary:en0.16.0-v1.0.2\n    ports:\n    - 9999:9999\n  ner-transformers:\n    image: semitechnologies/ner-transformers:dbmdz-bert-large-cased-finetuned-conll03-english\n...\n```\n\nVariable explanations:\n* `NER_INFERENCE_API`: where the qna module is running\n\n## How to use (GraphQL)\n\nTo make use of the modules capabilities, simply extend your query with the following new `_additional` property:\n\n### GraphQL Token\n\nThis module adds a search filter to the GraphQL `_additional` field in queries: `token{}`. This new filter takes the following arguments:\n\n| Field \t| Data Type \t| Required \t| Example value \t| Description \t|\n|-\t|-\t|-\t|-\t|-\t|\n| `properties` \t| list of strings \t| yes \t| `[\"summary\"]` \t| The properties of the queries Class which contains text (`text` or `string` Datatype). You must provide at least one property\t|\n| `certainty` \t| float \t| no \t| `0.75` | Desired minimal certainty or confidence that the recognized token must have. The higher the value, the stricter the token classification. If no certainty is set, all tokens that are found by the model will be returned. |\n| `limit` \t| int \t| no \t| `1` | The maximum amount of tokens returned per data object in total. |\n\n### Example query\n\n\n\n\n### GraphQL response\n\nThe answer is contained in a new GraphQL `_additional` property called `tokens`, which returns a list of tokens. It contains the following fields:\n* `entity` (`string`): The Entity group (classified token)\n* `word` (`string`): The word that is recognized as entity\n* `property` (`string`): The property in which the token is found\n* `certainty` (`float`): 0.0-1.0 of how certain the model is that the token is correctly classified\n* `startPosition` (`int`): The position of the first character of the word in the property value\n* `endPosition` (`int`): The position of the last character of the word in the property value\n\n### Example response\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"tokens\": [\n              {\n                \"property\": \"title\",\n                \"entity\": \"PER\",\n                \"certainty\": 0.9894614815711975,\n                \"word\": \"Sarah\",\n                \"startPosition\": 11,\n                \"endPosition\": 16\n              },\n              {\n                \"property\": \"title\",\n                \"entity\": \"LOC\",\n                \"certainty\": 0.7529033422470093,\n                \"word\": \"London\",\n                \"startPosition\": 31,\n                \"endPosition\": 37\n              }\n            ]\n          },\n          \"title\": \"My name is Sarah and I live in London\"\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\n```\n\n## Use another NER Transformer module from HuggingFace\n\nYou can build a Docker image which supports any model from the Hugging Face model hub with a two-line Dockerfile. In the following example, we are going to build a custom image for the `Davlan/bert-base-multilingual-cased-ner-hrl` model.\n\n#### Step 1: Create a `Dockerfile`\nCreate a new `Dockerfile`. We will name it `my-model.Dockerfile`. Add the following lines to it:\n```\nFROM semitechnologies/ner-transformers:custom\nRUN chmod +x ./download.py\nRUN MODEL_NAME=Davlan/bert-base-multilingual-cased-ner-hrl ./download.py\n```\n\n#### Step 2: Build and tag your Dockerfile.\nWe will tag our Dockerfile as `davlan-bert-base-multilingual-cased-ner-hrl`:\n```\ndocker build -f my-model.Dockerfile -t davlan-bert-base-multilingual-cased-ner-hrl .\n```\n\n#### Step 3: That's it!\nYou can now push your image to your favorite registry or reference it locally in your Weaviate `docker-compose.yml` using the Docker tag `davlan-bert-base-multilingual-cased-ner-hrl`.\n\n\n## How it works (under the hood)\n\nThe code for the application in this repo works well with models that take in a text input like `My name is Sarah and I live in London` and return information in JSON format like this:\n\n```json\n[\n  {\n    \"entity_group\": \"PER\",\n    \"score\": 0.9985478520393372,\n    \"word\": \"Sarah\",\n    \"start\": 11,\n    \"end\": 16\n  },\n  {\n    \"entity_group\": \"LOC\",\n    \"score\": 0.999621570110321,\n    \"word\": \"London\",\n    \"start\": 31,\n    \"end\": 37\n  }\n]\n```\n\nThe Weaviate NER Module then takes this output and processes this to GraphQL output.\n\n## Model license(s)\n\nThe `ner-transformers` module is compatible with various models, each with their own license. For detailed information, please review the license of the model you are using in the Hugging Face Model Hub.\n\nIt is your responsibility to evaluate whether the terms of its license(s), if any, are appropriate for your intended use.\n\n\n\n\n", "type": "Documentation", "name": "reader-generator-modules-ner-transformers", "path": "developers/weaviate/modules/reader-generator-modules/ner-transformers.md", "link": "https://weaviate.io/developers/weaviate/modules/reader-generator-modules/ner-transformers", "timestamp": "2024-02-08 20:23:11", "reader": "JSON", "meta": {}, "chunks": []}