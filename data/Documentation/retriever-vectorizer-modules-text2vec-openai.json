{"text": "\n\n## Overview\n\nWeaviate uses the `text2vec-openai` module to obtain vectors.\n- OpenAI\n- Azure OpenAI\n\nKey notes:\n\n- As it uses a third-party API, you will need an API key.\n- **Its usage may incur costs**.\n    - Please check the vendor pricing (e.g. OpenAI pricing page), especially before vectorizing large amounts of data.\n- This module is available on Weaviate Cloud Services (WCS).\n- Enabling this module will enable the `nearText` search operator.\n- The default model is `text-embedding-ada-002`.\n\n\n\n\n## Weaviate instance configuration\n\nThis module is enabled and pre-configured on Weaviate Cloud Services.\n\n### Docker Compose file\n\nTo use `text2vec-openai`, you must enable it in your Docker Compose file (`docker-compose.yml`). You can do so manually, or create one using the Weaviate configuration tool.\n\n#### Parameters\n\n|Parameter|Required|Purpose|\n|:-|:-|:-|\n|`ENABLE_MODULES`|Required|The modules to enable. Include `text2vec-openai` to enable the module.|\n|`DEFAULT_VECTORIZER_MODULE|Optional|The default vectorizer module. You can set this to `text2vec-openai` to make it the default for all classes.|\n|`OPENAI_APIKEY`|Optional|Your OpenAI API key (if using OpenAI). You can also provide the key at query time.|\n|`AZURE_APIKEY`|Optional|Your Azure OpenAI API key (if using Azure OpenAI). You can also provide the key at query time.|\n\n#### Example\n\nThis configuration enables `text2vec-openai`, sets it as the default vectorizer, and sets the API keys.\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    image: semitechnologies/weaviate:||site.weaviate_version||\n    restart: on-failure:0\n    ports:\n     - \"8080:8080\"\n    environment:\n      QUERY_DEFAULTS_LIMIT: 20\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: \"./data\"\n      # highlight-start\n      ENABLE_MODULES: text2vec-openai\n      DEFAULT_VECTORIZER_MODULE: text2vec-openai\n      OPENAI_APIKEY: sk-foobar  # For use with OpenAI. Setting this parameter is optional; you can also provide the key at query time.\n      OPENAI_ORGANIZATION: your-orgname  # For use with OpenAI. Setting this parameter is optional; you can also provide the key at runtime.\n      AZURE_APIKEY: sk-foobar  # For use with Azure OpenAI. Setting this parameter is optional; you can also provide the key at query time.\n      # highlight-end\n      CLUSTER_HOSTNAME: 'node1'\n...\n```\n\n## Class configuration\n\nYou can configure how the module will behave in each class through the Weaviate schema.\n\n### API settings (OpenAI)\n\n#### Parameters\n\n|Parameter|Required|Default|Purpose|\n|:-|:-|:-|:-|\n|`model`|Optional|`text-embedding-ada-002`|A model family, e.g. `davinci`.|\n|`modelVersion`|Optional||Version string, e.g. `003`.|\n|`type`|Optional||Model type. Can be `text` or `code`.|\n|`baseURL`|Optional|`https://api.openai.com`|Sets a proxy or other URL instead of the default OpenAI URL.&nbsp; To specify the URL, use protocol domain format: `https://your.domain.com`.|\n#### Example\n\nThe following example configures the `Document` class by setting the vectorizer to `text2vec-openai`, model to `ada`, the model version to `002` and the type to `text`:\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      // highlight-start\n      \"vectorizer\": \"text2vec-openai\",\n      \"moduleConfig\": {\n        \"text2vec-openai\": {\n          \"model\": \"ada\",\n          \"modelVersion\": \"002\",\n          \"type\": \"text\"\n          \"baseURL\": \"https://proxy.yourCompanyDomain.com\"\n        }\n      },\n      // highlight-end\n    }\n  ]\n}\n```\n\n### API settings (Azure OpenAI)\n\n#### Parameters\n\n|Parameter||Purpose|\n|:-|:-|\n|`resourceName`|Azure resource name|\n|`deploymentId`|Azure deployment ID (your model name)|\n\n#### Example\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      // highlight-start\n      \"vectorizer\": \"text2vec-openai\",\n      \"moduleConfig\": {\n        \"text2vec-openai\": {\n          \"resourceName\": \"\",\n          \"deploymentId\": \"\",\n        }\n      }\n      // highlight-end\n    }\n  ]\n}\n```\n\n### Vectorization settings\n\nYou can set vectorizer behavior using the `moduleConfig` section under each class and property:\n\n#### Class-level\n\n|Parameter|Default|Purpose|\n|:-|:-|:-|\n|`vectorizer`|| Use this module to vectorize the data.|\n|`vectorizeClassName`| `true`| When `true`, vectorizes the class name.\n\n#### Property-level\n\n|Parameter|Default|Purpose|\n|:-|:-|:-|\n|`skip`|`false`|When `true`, does not vectorize the property.|\n|`vectorizePropertyName`|`true`|When `true`, vectorizes the property name.\n\n#### Example\n\n```json\n{\n  \"classes\": [\n    {\n      \"class\": \"Document\",\n      \"description\": \"A class called document\",\n      \"vectorizer\": \"text2vec-openai\",\n      \"moduleConfig\": {\n        \"text2vec-openai\": {\n          \"model\": \"ada\",\n          \"modelVersion\": \"002\",\n          \"type\": \"text\",\n          // highlight-start\n          \"vectorizeClassName\": false\n          // highlight-end\n        }\n      },\n      \"properties\": [\n        {\n          \"name\": \"content\",\n          \"dataType\": [\"text\"],\n          \"description\": \"Content that will be vectorized\",\n          // highlight-start\n          \"moduleConfig\": {\n            \"text2vec-openai\": {\n              \"skip\": false,\n              \"vectorizePropertyName\": false\n            }\n          }\n          // highlight-end\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Query-time parameters\n\n### API key\n\nYou can supply the API key at query time by adding it to the HTTP header.\n\n|HTTP Header|Value|Purpose|\n|:-|:-|:-|\n|`\"X-OpenAI-Api-Key\"|\"YOUR-OPENAI-API-KEY\"`|OpenAI key|\n|`\"X-Azure-Api-Key\"|\"YOUR-AZURE-API-KEY\"`|Azure OpenAI key|\n\n### Organization name\n\n\nFor requests that require the OpenAI organization name, you can provide it at query time by adding it to the HTTP header:\n- `\"X-OpenAI-Organization\": \"YOUR-OPENAI-ORGANIZATION\"` for OpenAI\n\n## Additional information\n\n### Available models (OpenAI)\n\nYou can use any OpenAI embedding model with `text2vec-openai`.\n\nFor document embeddings, choose from the following models:\n* ada\n* babbage\n* curie\n* davinci\n\nFor code embeddings, see the Codex models.\n\nThe more dimensions a model produces, the larger your data footprint will be. You can estimate the total size of your dataset here.\n\n### API rate limits\n\nSince this module uses your API key, your account's corresponding rate limits will also apply to the module. Weaviate will output any rate-limit related error messages generated by the API.\n\nYou can request to increase your rate limit by emailing OpenAI at `support@openai.com` describing your use case with Weaviate.\n\nThe current rate limit will appear in the error message, as shown below:\n\n```json\n{\n  \"message\": \"Rate limit reached for requests. Limit: 600.000000 / min. Current: 1024.000000 / min. Contact support@openai.com if you continue to have issues.\"\n}\n```\n\n### Import throttling\n\nOne potential solution to rate limiting would be to throttle the import within your application. We include an example below.\n\n\n\n  See code example\n\n\n\n\n\n## Usage example\n\nThis is an example of a `nearText` query with `text2vec-openai`.\n\n\n\n\n\n\n\n", "type": "Documentation", "name": "retriever-vectorizer-modules-text2vec-openai", "path": "developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai.md", "link": "https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai", "timestamp": "2023-11-02 10:53:32", "reader": "JSON", "meta": {}, "chunks": []}