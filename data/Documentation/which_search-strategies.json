{"text": "\n\n\n## &nbsp;&nbsp;Overview\n\nIn addition to selecting the right search types, there are also strategies you can employ to improve the quality of your search results.\n\nLet's explore some of these strategies.\n\n## &nbsp;&nbsp;Improve vector search\n\nThe key to improving vector search is to make sure that the vector representation of the object is fit for purpose, so as to suit the search needs.\n\n### &nbsp;&nbsp;Vectorizer selection\n\nUnless you are inserting data with your own vectors, you will be using a Weaviate vectorizer module, and a model within that module, to generate vectors for your data.\n\nThe choice of vectorizer module and model is important, as it will determine what aspects of the data are captured in the vector representation, and how well the model is able to \"understand\" the data.\n\nFirst and foremost, you should select a vectorizer module that is best suited for your data type. For example, if you are working with text data, you should use the `text2vec` module, and if you are using image or multi-modal data, you should likely use the `multi2vec` module.\n\nWe will cover vectorizer selection in another unit. But, if you are not sure where to start, try:\n- `text2vec-cohere`, or `text2vec-openai` for text data (API-based)\n    - Cohere offers a multi-lingual model that can be used with over 100 languages.\n- `multi2vec-clip` for image or image and text data.\n\nIf you are working with text and prefer to run a local inference container, try `text2vec-transformers`, with a popular model such as `sentence-transformers/all-MiniLM-L12-v2`.\n\n### &nbsp;&nbsp;Try a re-ranker\n\nRe-ranker modules are a great way to improve the quality of your search results.\n\nA re-ranker module is a module that takes in the results of a vector search, and re-ranks the results based on additional criteria, or a different model. This allows a higher-quality (but slower) model to be used for re-ranking, while still benefiting from the fast first stage search.\n\nFor example, you can use the `text2vec-cohere` module to perform a vector search, and then use the `reranker-cohere` module to re-rank the results using a different model.\n\n### &nbsp;&nbsp;Property selection\n\nVectorization captures the \"meaning\" of the object. Accordingly, if a property is not relevant to the criteria to be applied for search, it should be excluded from the vectorization process.\n\nAs an example, if a product object includes metadata such as its manufacturing process or location, and the vector search is intended to be based on the product's features, then the properties for manufacturing process and location should be excluded from the vectorization process.\n\nYou can do this by specifying whether to skip a property during vectorization, as shown below. Note that you can do the same with the collection name, and the property name.\n\n\n\n \n    \n  \n\n\n\n### &nbsp;&nbsp;Chunking\n\nChunking refers to the process of splitting a text into smaller chunks, and vectorizing each chunk separately. This is very important, as it defines how much information each vector contains.\n\nAs a rule of thumb, the more granular the search needs, the smaller the chunk size should be. For example, if you are searching for specific concepts and ideas, you should chunk data into smaller units such as sentences or small windows of text. Alternatively, if you are searching for broader concepts, such as finding relevant chapters or books, you might chunk text accordingly.\n\nRead more about it in the chunking unit of Weaviate Academy.\n\n## &nbsp;&nbsp;Improve keyword search\n\n### &nbsp;&nbsp;Tokenization\n\nAlthough we refer to BM25 search as a \"keyword\" search, in reality the exact matches are for \"tokens\", rather than words. This is a different tokenization process to that used for generating vector embeddings, but instead, it is used to build the inverted index for BM25 searches and filtering.\n\nAccordingly, the tokenization process is very important, as it determines what tokens are used for matching.\n\nThe available options are: `word`, `lowercase`, `whitespace`, and `field`. The default (`word`) might be sufficient for prose, but for text where exact matches including case and symbols are important, something like `whitespace` might be more appropriate.\n\nAvailable tokenization options:\n\n\n\n\nYou can set tokenization in the collection configuration.\n\n\n\n \n    \n  \n\n\n\n### &nbsp;&nbsp;Select and boost properties\n\nIf you observe that matches in some properties are having too much of an impact, you can exclude them from the search, and/or boost the importance certain properties.\n\nFor example, matches in the `description` property might be more important than matches in the `notes` property. You can specify this at query time.\n\n\n\n \n    \n  \n\n\n\n## &nbsp;&nbsp;Improve hybrid search\n\n### &nbsp;&nbsp;Alpha\n\nThe alpha parameter determines the balance between the vector and keyword search results.\n\nIf you want to configure your search to be more vector-based, you can increase the alpha value. Conversely, if you want to configure your search to be more keyword-based, you can decrease the alpha value.\n\n\n\n \n    \n  \n\n\n\n### &nbsp;&nbsp;Fusion algorithm\n\nThe fusion algorithm determines how the results from the vector and keyword searches are combined.\n\nBy default, an inverse of the ranks from each results set are summed, in what is called the \"ranked fusion\" algorithm. However, you can also use the \"relative score fusion\" algorithm, which sums normalized scores from each results set.\n\nGenerally, we have found that the \"relative score fusion\" algorithm works better, but you should try both to see which works best for your use case.\n\n\n\n \n    \n  \n\n\n\n&nbsp;&nbsp;Review\n\n\n\nAny quiz questions\n\n### &nbsp;&nbsp;Review exercise\n\nTry out ...\n\n### &nbsp;&nbsp;Key takeaways\n\nAdd summary\n\n\n\n\nimport Quiz from '/src/components/Academy/quiz.js'\nconst varName = [{\n  questionText: 'questionText',\n  answerOptions: [\n    {\n      answerText: 'answerOne',\n      isCorrect: false,\n      feedback: 'feedbackOne',\n    },\n    {\n      answerText: 'answerTwo',\n      isCorrect: false,\n      feedback: 'feedbackTwo',\n    },\n    {\n      answerText: 'answerThree',\n      isCorrect: false,\n      feedback: 'feedbackThree',\n    },\n  ]\n}]; -->\n", "type": "Documentation", "name": "which_search-strategies", "path": "developers/academy/building_with_weaviate/201_which_search/30_strategies.mdx", "link": "https://weaviate.io/developers/academy/building_with_weaviate/which_search/strategies", "timestamp": "2024-02-08 20:20:57", "reader": "JSON", "meta": {}, "chunks": []}