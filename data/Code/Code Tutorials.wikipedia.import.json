{"text": "import Tabs from '@theme/Tabs';\nimport TabItem from '@theme/TabItem';\n\n<Tabs groupId=\"languages\">\n<TabItem value=\"py\" label=\"Python\">\n\n```python\n# ===== Import data =====\n# Settings for displaying the import progress\ncounter = 0\ninterval = 100  # print progress every this many records\n\n# Create a pandas dataframe iterator with lazy-loading,\n# so we don't load all records in RAM at once.\nimport pandas as pd\ncsv_iterator = pd.read_csv(\n    'vector_database_wikipedia_articles_embedded.csv',\n    usecols=['id', 'url', 'title', 'text', 'content_vector'],\n    chunksize=100,  # number of rows per chunk\n    # nrows=350  # optionally limit the number of rows to import\n)\n\n# Iterate through the dataframe chunks and add each CSV record to the batch\nimport ast\nclient.batch.configure(batch_size=100)  # Configure batch\nwith client.batch as batch:\n  for chunk in csv_iterator:\n      for index, row in chunk.iterrows():\n\n          properties = {\n              \"title\": row.title,\n              \"content\": row.text,\n              \"url\": row.url\n          }\n\n          # Convert the vector from CSV string back to array of floats\n          vector = ast.literal_eval(row.content_vector)\n\n          # Add the object to the batch, and set its vector embedding\n          batch.add_data_object(properties, \"Article\", vector=vector)\n\n          # Calculate and display progress\n          counter += 1\n          if counter % interval == 0:\n              print(f\"Imported {counter} articles...\")\nprint(f\"Finished importing {counter} articles.\")\n```\n\n</TabItem>\n<TabItem value=\"js\" label=\"JavaScript/TypeScript\">\n\n```js\n// ===== Import data =====\nimport fs from 'fs';\nimport csv from 'csv-parser';\n\nasync function importCSV(filePath) {\n  let batcher = client.batch.objectsBatcher();\n  let counter = 0;\n  const batchSize = 100;\n\n  return new Promise((resolve, reject) => {\n    fs.createReadStream(filePath)\n      .pipe(csv())\n      .on('data', async (row) => {\n        // Import each record\n        const obj = {\n          class: 'Article',\n          properties: {\n            title: row.title,\n            content: row.text,\n            url: row.url,\n          },\n          vector: JSON.parse(row['content_vector']),\n        }\n        // Add the object to the batch queue\n        batcher = batcher.withObject(obj);\n        counter++;\n\n        // When the batch counter reaches batchSize, push the objects to Weaviate\n        if (counter % batchSize === 0) {\n          console.log(`Imported ${counter} articles...`);\n          // Flush the batch queue and restart it\n          await batcher.do();\n          batcher = client.batch.objectsBatcher();\n        }\n      })\n      .on('end', async () => {\n        // Flush the remaining objects\n        await batcher.do();\n        console.log(`Finished importing ${counter} articles.`);\n        resolve();\n      });\n  });\n}\n\nawait importCSV('vector_database_wikipedia_articles_embedded.csv');\n```\n\n</TabItem>\n</Tabs>\n", "type": "Code", "name": "Code Tutorials.wikipedia.import", "path": "_includes/code/tutorials.wikipedia.import.mdx", "link": "https://weaviate.io/_includes/code/tutorials.wikipedia.import", "timestamp": "2024-05-08 15:31:58", "reader": "JSON", "meta": {}, "chunks": []}