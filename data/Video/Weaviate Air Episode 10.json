{"text": "New hybrid search ranking algorithm: https://weaviate.io/blog/weaviate-1-20-release#new-hybrid-search-ranking-algorithm ... \nforeign[Music]this is super exciting we finally hitdouble digits we I have a great crewhere with me so I've got Derek Zen JPand Philip so Zen and JP you alreadyknow Dirk and Philip they're new toVivid air so it's super great to haveyou guys with us and this is superexcitingum so yes as always thank you forwatching and listening it's always greatto see you all keep coming back for moreand if you like this kind of content yesplease subscribe and then then youalways get a notification and not justfor vivid air but we do loads of reallycool stuff with podcasts and various funvideos and we also have some more newideas around tutorials Etc so it'sdefinitely worth subscribing to ourChannel and of course one of the bestthings about this kind of content andvideos that we are creating it is livetherefore you can ask questions you knowso don't feel don't be shy feel free toask questions always as we go and we'lltry to help them out but also if youdon't have questions but you just wantto say hi and tell us where you arewatching us from uh then this is also agood opportunity to introduce yourselfto the rest of the community communityright so today we have a few really cooltopics to cover so first off we will betalking about multi-modal models andapplications so JP sorry Zen we'll talkabout that uh the next one we haveAutoCAD feature so that's something thatis brand new that was added to viviateit with like the 120 release so JP andDerek will talk about thisum then we have new hybrid searchranking algorithm and that's also likesomething that GP and Doug will continuetalking about then we we talk about PQand risk scoring this is actually apretty cool topic that Zen will cover soif you're interested in like varioustypes of maybe indexing and the kind ofclever stuff that we do behind thescenes to make within more performantand you know more memory Savvy even oryou know to get the best out of yourvector database this is a really cooltopic and then last but not least we'llhave like a really cool demo by JParound like the knowledge base app sothis should be really really cool andone more reminder you know pleasesubscribe you know like if you arrivelate you know make sure to subscribe souh and basically let's have fun duringthis sessionsoum let's kick it off with Zen and Zenokay what can you tell us about themultimodal multi-modal models andassociations so let me let me kind ofjustify why I wanted to talk about thisuh in this episode firstum I've been on this hype train ofmultimodal models recently I've beenreading all the papers in this fieldum I've been looking at implementationsfor uh Summer State some of the state ofthe art multimodal models from from metafrom Carnegie Mellon and I wrote aboutthis in the previous blogand I wanted to talk about this as faras how how this is going to impact uhwhat we're releasing would leviate goingforwardum so let me step back and let's talkabout what multimodal models are rightum the only multimodal model that wehave right now in weaviate is the clipmodeland it's multimodal because itunderstands multiple modalities of dataright you can pass in text and it willembed it into vectors you can pass itimages and it's going to embed it intothe same Vector space and the wholepoint of multimodality is that you canactually understand and search dataacross modality so you can give it animage and and then obtain images or textyou can give it a text query and you canobtain text or images back so you can dothis cross modal searchum and so this really excited me and Istarted exploring new papers around thisand now what people are trying to do isuh go go beyond just text and images andthe motivation here is of course ashumans we use all of our modalities tounderstand a data point where if you goto the park and you look at uh and yousee a dog passing by you can see themnot just in images but the the timeseries of them moving you can smell themif they're close by enough you can seeuh you can hear them there's all thesemodalities that go in and into our brainand that's how we understand a dogand the power of this is that everymodality is adding a specific amount ofinformationanother example of this is I wasrecently on the plane um flying toSeattlelast month and I didn't have uh these umthough the wired headphones I had theBluetooth headphones so I watched theentire movie without listening to it andI got pretty much all of it so humansare very good multimodal reasoningengines where I can show you a moviewithout giving you the audio behind itand you'd still understand pretty muchall of it because we can fill in theblanks of the missing modalityum and so the main thinking behind thisis if we want powerful reasoning engineswhich these large language models are weneed for them to understand othermodalities of data right now they onlyunderstand language and some of themunderstand uh image so like the new Bardmodelunderstands imagesum but in the future what we'd like forthem to do is understand audiounderstand moving time frame so videounderstand maybe even motion so if youlook at your phone there's a bunch ofaccelerometers and gyroscopes in here uhwhat if you could give the data fromThose sensors to a multimodal model andthen get it to understand what type ofmotion the human is performing runningwalking all sorts of interesting stuffsoum I went down this rabbit hole and thenwe started reading this paper calledimage bind from meta and we're in theprocess of uh implementing this intointo Eva and there's going to be moreinformation soonum but the main idea behind this now isthat you can take any type of data embedit into Eva and the vector space isgoing to represent all sorts ofmodalities nowumand then you can do cross-modal searchso you could pass in you could literallytalk to your database before you couldwrite in text and you would get relevantanswers back but now you could recordyourself and your query could be anaudio recording your query could be avideo your query could beum could be motion sensors actually aswell so you can take a motion sensorvectorize that data point and thenretrieve back any of the relevant uhdata points back hey Zen um so on the onthe topic because I think there's likeso many things that you could probablyrecognize and in terms of modalities souh back in the days when I was doinglike way more more public speaking I gotthis gadget so it's something that youput on have you seen it yes yes I haveto say so this this oh you have the sameso this thing actually you can uh likefeels like as your different joints andyour bones move inside so if I make thisgesture this gesture show you somefingers you know I'm not gonna show youyou do this all that that's kind of likeone of the modalities so you could if Ido this you could kind of translatemodality of like oh yeah this person ishappy or something right if I show thislike oh this person's angry so thiscould be yet another example likestrange modality and uh yeah so yeahthat that device by the way is from acompany in Canada and it and itrecognizes uh muscular activity uh inyour arm and this is similar to what uhthe the people at meta are doing withtheir image buying model one of themodalities that they process isaccelerometer dataso because there was a time where metawas super interested in these specialinput devices and they they were therewere a lot of Buzz around these so thatthey take over I'm not sure if it wasthis startup but at least theyum yeah to get a replacement for for myfor a computer mouseyeah I'm not sure if they bought thisone but I I know this particular devicethat Sebastian is wearingum yeah but they are they are looking atthe new interface right the whole playeron the VR they want to be the nextscreenum no but this could potentially be oneof the modalities right if I'm moving myarm like this or like this what is theclosest thing in Vector space to thismovement actionum yeah and I really like your yourexample in your blog course around thisinfant which is them growing up and uhgetting a higher level of abstractionand then being so like like fine tuningor having a model which is thengeneralizing better so if it's uh if youhave more datayeah the other thing that's reallyinteresting about this is that you cando better classification if you havemultiple modalities yes right exactly itwas the point yeah like if if I show youa really weird image you can onlyinspect the weirdness or the anomaly uhcomponent of that image through theimage modality but if I show you areally weirddata point through six differentmodalities you can you can view it fromdifferent modalities and say okay it'sabnormal in these modalities but it'snormally in the other modalities so youcan do anomaly detection much betteracross modalities which is why humansum like if something seems really weirdlike you get a weird feeling you can'texplain it it might be that all theother modalities are normal one modalityis going off the charts right so thenumber of applications you can do withthis is really amazing I'm reallyexcited to see what people do with thisand one of the main modules the clipmodule people love so I'm hoping theycan take this new image bind module andbuild on top of it one more technicaldetail by the way so in image bind theyactually start off with the clip moduleand they use the clip module to localizeand and bring together all of the othermodalities so if you have an image of alion and the word lionin the clip module in the the clip datamodelthose two vectors are already going tobe closer together and now if youproject in the sound of a lion roaringthey use examples that are similarversus dissimilar to bind the the um theembedding space together across thesemodalities that's why it's called imagebind because they're using concepts ofimages to bind the other modalitiescloser togetherum so hopefully the the idea is that youcould still use the bind model if you'reonly doing image and word search andthat would work just as well but if youwanted to do audio search down the roadgoing with the bind rather than the clipmodel would just be a better idea nowcool so you can go on I was gonna say sothen from uh like from a weeviate userperspective you can now is it correct tosay that you can now kind ofum embed information or like vectorizeinformation in any of the N modalitiesthis model would support like it kind ofup to end uh different modalities inyour data point rightyeah if you if you have the modality ifyou have the data point for thatmodality which is one of the mainchallenges of the space Philip go aheadyou were sayingum but it's limited to 10 modalities areuh no this one has six modalities so ithas image audio it has accelerometer ithas depth and it has uh video and it'sgot heatradar so um okay because the the highmodality multi-transformer that hitsyeah the high mmt from Carnegie Mellonthat has 10 different modalities thatone is super interesting as well thedifference between these two is thatthis model uhBill the the bind model built a modelper modality so you have a model thatunderstands Vision a model thatunderstands audio and then they bindthem together the high mmt one is onemodel that they can keep on addingmodalities to and the more modalitiesyou add it looks at what informationwhat incremental information you'regiving to the model and it says okaythis is a useful modality because now Iknow something that I didn't from theother mod the mod modalities that I hadand so that builds one model up and it'sit's a lot more scalable cool so it'slike a Voltron of older models niceexactly the more the more modalities yougive it the better it becomes and youcan give it all sorts of modalities theythey went into like structured documentunderstanding that that model canunderstand like a word uh documents aswellso what are the use cases that you thinkwe could do with like maybe databasebecause like the thing I I can think ofis like hey if I left if I were tovectorize maybe a video and then I coulddo either search based on what I can seein the images just like you were sayingyou could watch a movie without evenlike putting headphones on or I couldjust search based on audio right solet's say I search for a fight scene andthen you know maybe you could see it ormaybe there's just a fight that you canoverhear right so yeah so it's kind ofinteresting but what will be otherexamples you would you want to use itfor I think probably the most relevantapplication would be performing searcheslet's say you have a data point thatthat you have three different modalitiesfor right you have text for a modalityyou have video for a modality as well asthe audio for that modality which if youtake any YouTube video you have allthese three modalities you have thetranscription you have the video itselfas well as the frames and you have thethe sound recording for this you coulddo you could vectorize all three of thethese data points as separate queriesand then you could do more refinedsearch before you could say okay show meanything that looks like this image nowyou could say I have this image or videorepresented as three differentmodalities show me a more accuraterepresentation of what this uh what thisis in multimodal spaceum I I think that would be one reallycool applicationum the other application could also beif you only have one modality you canlook for other modalities uh as outputfrom your vector database if you have alarge enough data setum this was one of the challenges thatthey talked about in the paper whereit's very difficult to find Richmultimodal data sets How likely is itthat you have the picture of a lion thesound of a lion and then the motion of aline in accelerometer data it's quiterare So training this thing was a bit ofa nightmare I think they used seven oreight different data sets that theystitched together to even train thisthing to begin withbecause I think that the the use case inthis case wouldn't necessarily even haveto be where I have a video and Iabstract three modalities from it whatyou could do is like have a collectionwhere you just throw all my videos allmy mp3s and and all my pictures on allmy PDFs and then I can you know searchthrough all of them because that's likethe ml model can understand all of themso I don't have to have five differentcollections I could actually just lumpit in it's like just search to myunstructured data right like it's allthere yeah exactlycooldid I hijack you did I hijack your trainof thoughtsoh no I'm good uh any other questions uhwe can take those when can we have itah that took it we're aiming for thewe're aiming for for the next releasebut no promises yet right uh we're justgoing through finalizing it testing itum well there will be another blog postaround all the cool things that you cando with itum all sorts of multimodal searches I'mreally excited about that but um yeahthe next release is the we're aiming forthat but uh so it sounds like if someonemashed the Subscribe button on theYouTube channel they'll probably getsome notifications about videos orcontent about it in the futurethat will for sure happen and if you dosubscribe you might uh it might come outearlier no promises but that might justhappen it's a good excuse to uh giveanother call outum and then while before we switchtopics we have somebody saying hi fromColombia which is uh code egoso that's good to see people alwayssaying hi you know like we hope youenjoy it if you have any questions uhdrop us a question or just you know keepsaying hi or send us encouragement sothat we keep goingthank youvery cool audience from all over theplaceI know I know it's it's nice to seepeople from everywhereperfect in this case might be good morea good moment to go to AutoCAD featureuh so I will leave you Dirk and JP tohandle it cool I mean um the lastrelease was so jam-packed with featuresright so we talked about it uh lastpodcast with Etienne and he's one ofbeing on Connor's podcast talk about itas well but yeah we didn't have time tocover some of the other features thatwould be a good time and one of them wasum autocut and we've got Derek here fromthe core team is that the right yeahgroup term and uh yeah so Derek and Iwork together to to write about it um soI thought I'd lean on Dirk to uh sort ofthe hard questions like hey what isAutoCADum can you just tell us a little bitlike at a very high level Dirk aboutwhat it isuh yeah so you do a search you getresults back and thenum they often get bad after a while sowe have one two three good results andthen the bunch that don't have goodscores that are not really relevant toyour search and you don't really want toshow them to your users andum obviously you could you could playaround with the limits to try to onlyinclude the ones that you really want toshow and not include the irrelevant onesbut it's not really possible to set thelimit to a value that works everywhereso what AutoCAD is doing is it dependsjumps in the scoreso you have I say let's say one 0.90.85 and then the scores go down to 0.50.4 so on and then you do a cut at thejump in this course and throw away therest of the results and only for thegood ones and you can set how many ofthe jumps you want to doandumimportant who those that you want somaybe for your use case you want to gofor the second jump or the third to geteverything that might be relevant or youwant to really do a hard cut off andonly show the best ones and then you useoneyeah I think it's really cool becauselike obviously uh you know Vector searchworking on similarity you have tospecify some some sort of threshold toget results back whether it's you knowjust hey get me 10 results or resultswithin this distance from my query andthat's a little bit painful sometimesbecause you have to uh figure out whatyour threshold is and what I really findinteresting about AutoCAD is that youknow you create this natural groupingstoo as well as like thresholds you cango hey give me two like you said groupsof results that are like could end upbeing not necessarily close together butyou knowum they're gonna become naturalgroupings of this first group is withinthis threshold and then kind of get thisouter ring of results and then so on asyou go it kind of like this nice mappingof vector distances so yeah I think Ithink it's really cool and hopefully uhour users kind of find it useful as wellbecause for me when I you know do demosand people are like oh I see you'regetting eight results back or threeresults back why did you do that and Igo because that's how many feet on myscreen is usually the answer for demosbutit's really hard question to answer whenpeople say things like oh what thresholdshould I use if they're using a distancenumber and it's like how long is a pieceof string whereas I think AutoCAD reallylends to kind of natural groupings ofthese these results so that's reallycoolum and andyou kind of need uh result sets thatlead to these groupings right like youkind of need some meaningful distancesfrom results which is why it works wellwith Vector searchyes basically you take the distance weget from the vector search or bm25search and that's the input to AutoAutoCAD we don't use anything elseum and it's really simple inside so itbasically it's a very simple way ofcalculating derivative and it uses thatto to detect the jumps and then cuts offwhen other people are talking aboutusing some complex models to do that andit probably works better for some casesbut it's a very very cheap way to getuseful results and obviously can alwaysbe improved lateryeah is the idea then that if I run asearch and I get like a couple of greatones and then I have like a bunch oflike good ones then the good one getscut out because you know they're not asgood as the great ones but if I only getgood ones then the good ones will beshown because there's nothing betterrightexactly so it doesn't look at anyabsolute values it only looks at it's arelative thing rightsorry again it's a relative thing so youcan Define I want to the first or thebest ones and then there's maybe somesome space between them and then I wentalso the second ranking and the thirdranking and I cando a config thing that I want to Firstpairs or the first two pairs exactlythat's how it works yeah I mentionedthat it doesn't know how good yourscores are so you get some scores backand you don't know if a 0.8 is great ornot great so it can't do any absoluteranking you can only look at therelativedistances between the different objectsand then group them by by using thesejumps in this course and then cuts itoff depending on how you how youconfigure it it's sort of like when yougo for a holiday and you're looking fora hotel and then sometimes you if youbook in early there's like loads ofgreat options so you don't want like thecrappy hotels to pop up but when you'relike booking like on the day when you'reflying you go like okay at least show methe average ones don't cut them out butdon't show like the ones where you getmurdered I'm also taking this tent andthe highway yeah yeahso like Vegas can be chooses rightyeah I guess yeah because when we weretalking about what image to put in theblog I said um let's fill out thisreally obviously the horrible sketch uhthat it was like wave yet as a robotgrabbing you and like some sets ofresults so it's like oh it's basicallytelling we've yet hey get me one set ofresults or two sets of results uh howgood are they don't know whether it justgoes and grabs them for you as it'sconvenient so yeah the hotel in thatwhich is quite funny uh quite goodsomeone sounds like someone who's beenon holiday recently yeah but also veryspecific to to your role Sebastian orlike looking for a hotel for the samedayno no I'm actually a pretty good plannerSo like um it only happened once in mylife when uh when I had to book a hotelon uh on the same day but that's a not astory live on the screenandum uh I think that kind of leads in wellwith our next discussion which was goingto be I have one more question this issuper important so every time I learnedabout a new feature the first thing thatI think of is how how could I break itortry to understand it it's atroublemaker's end soum you talked about using the derivativeum is there a minimum threshold to thederivative let's say I ask for 10answers back and they're all great sothe derivative is not going to be veryhigh right it's going to be a relativelyflat derivative and I ask for one cut itwill it just make an arbitrary cutsomewhere or how do we handle that no umbasically if your scores are very linearand there is no no jump in them then itwill not cut off anything it could alsobe if your results are all bad[Music]okay so there is some some minimumthreshold for the derivative needs to bethat high before the cut to happen notan absolute threshold it kind of itdetects that the that the derivativechanges okayumI think it's called the knee in EnglishI'm actually not 100 sure but it's avery very fast but kind of crude way ofcalculating itum but it basically if if you don't havejumps that are large in your data set itdoesn't really do anything because ifyou can't really group them if they'reon a line or something okay it doesn'tmake sense to to to to say this is thefirst group this is the second groupokay makes senseawesome JP now you can do fine oh thanksa questionum yes no that's a really good questionum yeah and then to that point rightabout aboutum how those groupings are derivedthat's led to a change in theum I always get this term wrong sohybrid Fusion ranking algorithm did Iget that right deckso closePhilip you want to say somethingumnope I just want to ask because offusion the word Fusionbut I'm pretty sure you elaborate on itso relatively confusion yeahum do you just want to share my screenSebastianthere you go so this is a picture fromthe blog post and this is how hybridsearch works so hybrid search be doing avector search and a bm25 search and eachof them have their own scoresand now we want to combine the resultsfrom both different searches problem isthe scores are completely differentthings and you can't just add them up itjust doesn't make any sense because theymeasure different things a vector searchyou get distances and for bm25 searchyou get something out of a formula whichmethod like the frequency of your termand how many documents you have and theaverage lengths and a bunch of otherthings that go in there so you can'tjust add them upandumthe methods we used before to addresults up just look on the rank of eachresult in the in the individual searchand then use the rank to fuse theresults that's why it's called Fusionand the old algorithm was called rankedfusion and just to kind of show how ithow it works this is a very simplenotebook very hacked together so don'tlook at my code too much butum what what rank Fusion does it looksat the rank in your search results andthen assigns the score to it so thefirst results in your this is the actualformula for itso the first results in your search getsthe score one divided by 0.60 plus onewhich happens to be0.1s0.01 blah blah blah blah doesn't reallymatter the second one gets a bit lessthe third one gets a bit less it doesn'tmatter what the scores actually are onlythe rank countsand you do this for your for yourtwo searches and then you just add thenumbers up and that's your final scoreyou get in the output and just to showyou the what that means so here are twodifferent input scoresyou know here in the first one you havea really good one another really goodone and then a better one when thesecond one you have a really good oneand then two bad ones right pizzacrap and these ones are really good butboth lead to the same results withranked Fusion because this is the firstrank this is the second rank it's thethird Rank and nothing else mattersyeah I I printed out below what the whatthe ranked Fusion scores would be forthese two scores and it's exactly thesameand umnow to compare the old one the old wayof using things with the new one Ium made a small example here but beforeI go into the I just want to explain howhow I do it now or maybe first theproblem so the problem is with this youget a very regular scores out of yourFusion algorithm and if you have veryregular scores you don't have any jumpsin your scores and so AutoCAD doesn'tworkthat is what we just discussed this isit's not exactly linear but it's veryclose to being linear andum so the AutoCAD algorithm cannot findthe jump in these scores and so it willmostly give everything back and maybecut something off at the end that'sthat's a really low low rank in bothsearchesandum now what new algorithm is doing isit'snormalizes the scores between zero andoneso you get your scores from vm25 yourscores from from the vector search andyou just say the higher score is one thelowest one is zero and everything willbe normalized in between according tothe relative distances between themso if we scroll down to these theseexamples so here the the higher score is500 the lowest one is zero to zero nineso this one will become one this onewill become zero and the other one'srelative to that so this will be areally low number and so on for thevector search this will become a onethis will become a zero and because thisis so close the maximum score this willbecome like a 0.9 whatever it doesn'treally matter in detailand what you have with that is the therelative distances in yourscores from the individual search otherinsurance course yeah Frank Fusion youonly have to rank in the final scoreeverything else get lost so you don'tknow if a result wasalmost as good as the first one oralmost as bad as the worst one you onlylook at the rank and with the new oneyou have like the relativeumyeah the relative distribution of thescores also in your final resultwhat's important is what you don't haveyou still don't know if 500 here is agood oneyou know this could be your best scoreyou get but it could still be really badyou don't know if 500 is a good scoreand a bad scoreumand now we can kind of with this made upexample so the first document of 500second one for the six and so on andVector score is also second document asa six false documentation 5.98 I justwant to show the outcome for bothalgorithm so here we do it for rankedFusion so we just look at the rank ofeach document we sum upthe score for the given Rank and this iswhat you get in the endyou see the second one is the best oneand then you have the other ones veryclose together and only the one that wasworse in all in both searches at the endbut if you if you look at the input thefirst one was so much better in thekeyword search than the other onesand here it's it's on the first rankyeah the fourth rank but the the scoresare almost the same so it's still areally good result here but you only getit on second placenow if you go to the relative scopeFusion the one is the first result rightbecause it gets a really high score fromthe vector search and from the keywordsearch and so if you sum it up you get areally high score together so it's thefirst result you get back from thevector search then you have this groupherethat has almost the same scoreand here is the one that was bad in allin both searches and if you would runAutoCAD here you would get a cut hereand one here and you get this groups ofvery good results good results prettybad resultsso I guess it retains a lot more of thatinformation in the scores right likebefore all that was kind of like gettinglost because all we kept were therankings and what we ended up getting inthe hybrid score was either you know Ikind of found that if it scored well inone of the other searches you tend tocome up to the top whereas here the howfar you are I mean because it's stillrelative so the top results still tendto do really well but it was if you'rethe same if your second result andyou're very far away from that topresult you don't benefit from that asmuchyeah exactly yeah I think the the thisjump in the scores is probably the bestway to see it so I could change that tofive and you wouldn't see any changehere sorry I need to rerun everythingumit looks exactly the same as beforeright Ithis this discourse now much lower butthe the right Fusion is still exactlythe same whereas whatever do the sameone here you suddenly get a completelydifferent result because now thethis score is almost the same as thosetwobut again now you get all of those firstgroupings or results probably in your inyour uh one group autocut yeah exactlyyeah that's really neatum so what are the two ranked Fusionmath no hybrid fuchsia method it'scalled againone is called rank Fusion in what iscalled relative score of fusion and youcan set it with the python client as awhen the hybrid search there's anargument Fusion type and there's just anenum you can import and then set it torelative score or to ranked and that'show it works and just for graphql it'sthe same Fusion type and then you put inone of the two options inum rank Fusion is the default so the oldone we might change in the future andyou'll be very happy to hear if yourresults get better like what we testedgot better with the new Fusion algorithmbut it would be great to hear from allpeopleyeah I saw that when we ran somebenchmarks internally there was some youknow like much improved recall resultswith the hybrid search it was reallycool and um yeah it's obviously itdoesn't like it's still compatible withnot setting the result because of thedefaults if you don't change anything itshould still behave as it did before sothat's obviously neat as well for peoplein the I have a question in the examplehere in the Jupiter notebook the um thealpha is 0.5 so both the um the dentsand the sparse search are equallyweighted in this example correctum if I if I change that waiting doesthat does the re-weighting uh workbetter with this relative search asopposed to the old research we hadI think it's more exactly the same so itbasically would have a 0.5 or somethingor 0.7 here and here and for therelativeyear and here but the the base of it isexactly the same you still only look atthe ranked for rank fusion and you stilllook at the relative scores for the forthe new one okayand then is there any reason why I wouldnot want to use this versus the olderalgorithmwell I guess we just wanted to get somefeedback for now everything that we havetested is better but you never knowright so it would be creative if peoplesay yes it's better for us and then weswitch it over and on for everyone Zaynis just creeping its way to how to breakit yeah I'm just thinking about thisjust seems like a an overall betterthing it retains more information likeit just seems like all good I'mwondering if there's anything bad aboutthis but apparently so like you said thetesting we've done it doesn't it doesn'tseem that way but this is why thecommunity can use it and and tell us andwe'll go from there I guessexactly sometimes there's stuff youhaven't thought of so it's always hereall the time all the timecool thanks dickum yeah I think that was that was reallycool and it was cool to for me to sortof be like you know writing up about itand and yeah everything kind of you saidas you're showing me this stuff was likeoh this is like x amount better and thisis my better so uh everyone everythingseemed really positive when you guyswere developing it and and implementingit so obviously if anyone hasexperiences would love to hear about itum because I guess one of the questionsI had for you Dirk was set the same asZen's like when would you use onealgorithm versus the other and at themoment it kind of seems like generallywe're kind of keeping the old one forlegacy reasons as default but maybewe'll think about moving towards this inthe future is that right yeah if we getgood feedback and nobody complains thatthat scores the results are much worsethanwe will switch it oversounds good cool thanks very much so howcan I start using it what do I need todoyou just if you use the python clientthat's what you addah and like just go to the to thedocumentation check forFusion ranking methods and then thereare examples for Python typescripts andcraft UL oh it's missing here but it'salready implemented so it's alsowhat the example yeahum and is there a way to make it adefaultuh even outside of the query where it'slike hey I like it I just I want iteverywhere or do we just have to use theflag every time you just have to set itright now for each searchokay sounds goodso let's see if Zen can break it beforethe next movie thereoh it's good that I if I break it thenwe fix it and then so this type ofthinking on the limits not just helpswith understanding but also good productsoabsolutely in the past I work with thisguy Frank and uh he he was the like thetorment of all the engineers becausewhenever we release like a new productlike our new version of the product healways found like this obscure exampleon how to break it so we always had tokind of like do uh pre-frank release andthen Post front release that was prettyfunand no matter how much the QA teamtested the tools like Frank always foundsomethingso uh maybe Zen you're the new Frankyeah sounds good to mecool coolum all right should we move on to PQ andrisk scoring because that sounds likeit's along the similar subject so uhthen what is this all about and um howdid we get to hear and give us a storyyeah so let me start off withum I'll give a quick intro to what PQ isbefore I talk about the rescoring partthat we added with this uh 1.20 releaseum so I think it was 1.8um 1.18 when we initially releasedPQ which stands for product quantizationum and the main motivation behind thiswasnow when you take your unstructured dataand you vectorize it all of that so thethe huge vectors are stored in memoryand that increases a lot of the memoryload the requirements of uh what whatyour what your computer needs to be ableto run vv8um so product quantization basicallysays for all the vectors that you'restoring I'm going to in memory store acompressed version of them and I'm goingto have the originalrepresentation of them in disk and theway that it works is it'll take yourvector and it will chunk it up intosmaller pieces and for every piece let'ssay you have a vector that's a hundrednumbers long 100 units 100 dimensionalit'll chunk it up into units that arefive numbers five numbers five numbersand so you've got a bunch of these kindof vector chunks now and then it trainsan algorithm to say what are the whatare the average representations of theseof the first chunk of all of yourvectors it'll take the second chunk andit'll say what is what is the averagerepresentation of these vectorsum and you can increase that by sayingokay I want 10 average representationsfor the second chunk the third chunk thefourth chunk so another way to thinkabout it isif you if you take a huge Vector it'salmost like specifying a person'slocation down to the XYZ coordinateeverywhere so if I wanted to knowexactly where Sebastian is right now Iwould give the XYZ coordinate and andwherever he is in Europe and then thatwould be my Vector representation forSebastian but what PQ does is it givesyou a more coarser representation so wecan say okay so I don't really careabout whether what XYZ coordinates ofaction is in I only want to know whathis home address is or which countryhe's in or what continent he's in so youcan keep on zooming out further but yousee the problem now is the farther youzoom out the less precise ofrepresentation that you have for everyVector so with product quantization youcan take an exact vector and you can sayI don't really care about exactly thecoordinates of this Vector I'll look atsome average representations of thisVector the different chunks of thisVectorum and so forth for that compression youlose accuracy you lose recall becausenow the vectors are not exactly precisebut the advantage of this is you cansave a lot on RAM you require lessmemory to store all of these vectors sothis is one of the features that weimplemented in 1.18 and we've beenplaying around with it users have beenusing this usually how this works inpractice is you need a specific numberof vectors already in leviate and thenyou can say use the vectors that arethere to approximate what thedistribution of vectors looks like andthen any new Vector coming in can thenbe compressed in real time so there wasa portion where I would put in a hundredthousand vectors into eviate and then Iwould enable product quantization andthen it would go into read-only mode andit would calculate averages of thesevectors and then when it came out ofread-only mode the next time I put avector in it would compress that vectorand it would have the realrepresentation of that Vector on diskbut only a compressed representation inin working memoryand depending on how much you compressand squeeze the vectors you can you canone tenth of the memory requirements or1 100th the memory requirement the moreyou compress it obviously the morerecall and accuracy you're going to losebut now that's a knob that you havecontrol overuh if you value recall then you don'tcompress as much or you don't compressat all if you if you want speed then youcan um then you can actually well if youwant if you want less memoryrequirements if you have less Ram thenyou can crank up how much uh how much uhyou're compressing and you'll be able tostore more vectors so that's the storyof everything that happened till nowand one of the problems with theprevious implementation was thatwe realized that there was thistrade-off the more you compressed uh thethe more uh loss of recall you wouldhave because the the vectors are notmore accurate anymore if I tell you thatSebastian is in this continent it'sharder for you to locate exactly wherehe is right and if JP is also in thesame continent uh if then you can'tdifferentiate between them that was themain problemso that was the story up until 1.20 ifyou share your screen if you share myscreen now Sebastian I can talk aboutthe modifications that we've made toimprove uh improve PQokay so there's a couple of improvementsthat we've made here the firstImprovement uh that we've made oh waitbefore I talk about the improvements anyquestions about PQ any any thoughtsthere guysnope okay this sounds good to me so faryeah okay so one of the main changesthat we made here was well we did someuh memory management to make sure thatyou can query uh compressed vectorsfaster uh these are details that I'm notgonna not gonna cover you can read moreabout theseum the first thing that I want to get tois fit time on large data setsso in my explanation I mentioned thatyou need to have a specific number ofvectors already in review before you canenable PQ because the the averagerepresentations of vectors are learnedfrom vectors that you already have inleviate so before we recommended thatyou have ten thousand a hundred thousandtwo hundred thousand vectors pre-loadedand then you enable PQ to learn the umthe the average representations of thevectors that you can then compress atthose vectors with and new vectors withum and what we realized was people wouldput in a lot of vectors and then theywould enable PQ and their and their V8instance would go into read-only modefor a really long timeso now what we've done is we've addedthis hyper parameter the training limitwhich says you can set this limit but itdefaults to a hundred thousand meaningthat if you have a million or 10 millionvectors already in vva and you enable PQnot all 10 million will be used to fitthe PQ algorithm only a hundred thousandwill be used so the the time that youhave to have the vva instance inread-only mode is only going to becapped by however long it takes to fitit on a hundred thousand data points 100000 vectors so this is a a pretty goodkind of quality of life Improvementumthe the only I guess 100 000 vectors isenough to understand the underlyingdistribution of the vector segments sothis is good enough if you want morethen you can modify this parameter to amillion and then or a half a million andthen it'll use a half a million vectorsto learn the PQ compression algorithmthen others hundred thousand vectorslike randomly sample that they like thefirst hundred thousand how does thatwork I believe they're randomly sampledbut I would have to talk to some of thepeople that implemented it to know butit would make sense that they'rerandomly sampled and because we're onlytrying to understand the underlyingdistribution of the vectors it makessense to just randomly sample them yeah100000 versus a random hundred thousandbecause yeah so this is so does thisgoes back to the question of samplingbias let's say you let's say the orderin which you pass the data in was reallyweird right let's say you're passing inimages and you're vectorizing the imagesand for some reason let's say you have agrocery store and the first 100 000objects are all images of products fromthe uh vegetable aisle right or thefresh produce aisle and the next 100 000are uh our images from the serial aisleor the milk aisle now your hundredthousand objects are going to be all uhfresh produce and so the Learned PQrepresentations are going to be biasedtowards vegetablesso it if you take the first hundredthousand your your PQ algorithm is goingto be all off as opposed to if youshuffle them and you pass the data inand then you randomly sample from thatdataum then in that case you'll get maybe Idon't know 10 000 vegetable uh vectorsten thousand milk vectors ten thousandserial vectors and in that case you havea better approximation of what is foundin in your vector space Oh yeah thatmakes sense yeah cool cool yeahand what what is involving that learningis it to figure out which maybe parts oflike which dimensions are like thebiggest differentiators betweendifferent vectors so if there's like afew fields that are always like between1 and 0 and 98 but there's some othersthat jump a lot like what's thereyeah so the main idea behind learningthe uh PQ compression it's called a codebook because anytime you give me a newVector I can I look through the codebookto learn what is the vector uh what isthe compressed representation of thisand so the training essentially takesthe vector cuts it up into apredetermined size and then it says Itake all of the first segments of all ofmy 100 000 vectors here and then I learnwhat are some good averagerepresentations of these so for exampleif if we're on this call and we say Iwant to learn about I want to representpeople not through their XYZ coordinatesbut the continents that they live inright or the countries that they live inratherum if you only have two countries thatyou can use it'll take the most numerouscountry and it will say okay this is alocation for for an average location forthis person rightum so that's what you're learningapproximately okay uh 100 000 works wellbecause it's uh it's enough to learn theaverage distributionum if you and you can also uhparameterize over how manyapproximations per segment you want tolearn so for example if I say I want tolearn the average country of this calland you say I only want one country thenthat average country is going to besomewhere in between all of ourcountries but now if I say okay you canlearn three countries three averagecountries then we'll get I don't knowGermany will get Canada and we'll get uhsomewhere in Europewhich will be the average of where JP isand where Sebastian is so those averagesare what you what the algorithm isretaining now I don't need to knowexactly where JP is and exactly whereSebastian is I can just remember theaverage of where you guys are and everytime a new person comes in who's closeenough to JP or Sebastian I'm going toturn their Vector into the averageVector of where you guys areand then so now you only need toremember a bunch of averages as opposedto exactly the precise coordinate to thevectors and that's where all the memorysaving happenscool yeah I have a question yes how tobreak ityou can so you can break it if you don'tuh allow for enough uhcentroids so when you fit the algorithmit's called the k-means algorithm if youset the K means if you set K2 low thenit will squish all of the vectors downto one centroid and it will lose allinformationum so if another answer to that is ifyou compress too much then all alluseful information in the vectors islost it's almost like saying all thevectors now project to one data pointand you can't learn anything from thatdata point so and that's when wheneverwhen I made this the decision that Iwant to to then yeah reduce my storagehowever it's possible to go back so isit useless oruh so yeah that's a good question canyou uncompress II'm not sure if you can if you can goback Derek maybe is it I know there's away to enable PQumisn't it why we store the full Vector onthe dish yeah this is what I this iswhat I was about you don't have touncompress that you have full Vector isjust not in memoryyeah this is this goes back to thesecond part of the of the rescoringcomponent here because the main reasonin 1.18 why you lost a lot of recall wasbecause you're now uh ranking andcomparing distances that are compressedum but now because we're storing the uhthe exact representations of the vectorson disk and not in memory we can do thisrescoringum whether you can switch back and forthI'll have to get backum maybe there's someone in the chatthat can answer thisum I'll have to look into that but I Ithink you canum but I want to talk a little bit aboutthis rescoring component which is themain kind of punch line of the releaseHerethe main idea behind rescoring is onesecond let me I'll talk about it andthen I'll show you experiments of beforeand after so now what we do is uh ratherthan show you the uh rather than showyou the uh retrieved vectors uh based ondistance calculation so if you pass in aquery vector and rather than using thecompressed versions of the vectors toreturn the closest vectors what we do isyou pass in a query Vector we use thecompressed representations to learn whatare the let's say 100 most closestpotential vectors and then once we knowthe hundred closest vectors out of themillions of vectors that you have inyour vector space what we do is rescorethe hundred vectors we go back into diskand we say these are the hundred vectorsthat are the most importantgive me the uncompressed perfectrepresentation of these vectors and yourecalculate all the distances betweenthose uncompressed vectors and the queryvector so now what this enables is ifyou had distortions in the ranking ofthose hundred vectors due to PQcompression those are completelyeliminated because now I'm re-scoringthem using the original representationof the vectors and this we're doingexperiments around this wherebeforeuh this is what we had in 1.18 where themore you compressed the the more theless recall you had the more Distortionyou uh introduced into the system andthe less likely you were to get the uhthe correct Vector back so before youwere paying a price uh in terms ofrecall for your memory uh savings butnow because we have this rescoringcomponent we're running experiments onreal world data sets whereif you look at this graph for examplethere's pretty much no differencebetween the compressed recall andperformance versus the uncompressedperformance and this is because when wenarrow down on the few vectors that areimportant we actually rescore using thetheir uncompressed representation whichmakes sense here the only way that thiswould the only way that you would loserecall is if due to the Distortion youuh you weren't able to obtain the 100best vectors and so going back to thequestion of how could this potentiallybe broken or what could go wrong if theDistortion is so high that the 100vectors you get are not the right onesthen retrieving the uh the uncompressedversion of them wouldn't help that muchbut from the experiments that we've doneso far the uncompressed versus thecompressed representationum is is quite basically you're notpaying a price anymore for thecompression so there's no reason not todo itum there's examples of this as well I'llalso show you anotherum a couple of graphs here where we tookuh five a half a million vectors of thedbpedia data set and we vectorize themusing the ada002 model so the vectorsare 1 500 dimensional I believe here andagain you can see the compressed anduncompressed uh performances there's nodifference because of this rescoringcomponent which is all important andgiving us these resultswhen we go up to a million vectors youcan see that we the the the throughputthe query per second here suffers a bitin the compressed representationum we're also running more experimentsusing the sphere data set so we'rerunningum we're compressing and comparing tothe uncompressed representation of amillion sphere data points 10 millionsphere data points so we're we're goingto put all that together into a Blog andthen we're going to release it so thatif you're planning on using PQ you canactually look at how much data pointsyou have what the dimensionality ofthose data points are and then and thenwhat the um what the curve beforecompression and after compression lookslike so that you can judge for yourselffor your application what you want touse okaybut overall this is this is all greatnews because if if you looked at theperformance before there was a materialprice you were paying for uh the uh thelower uh memory but now for the mostpart you don't you don't pay a price soit I think the defaultum you can you can enable PQ and then ifyou see that your throughput is is loweror you're suffering on recall then foryour application you might want to do asimilar analysis to this where you lookat uncompressed and compressed versionsto see for your application if it makessense or notso so then basically if you've got alarge enough data set where memory mightmight start to become an issue you knowthat's when you should be looking at PQrightyeah exactly so let me give you let megive you a couple more specifics here soon this graph on the left hand side theif you look at memory requirements forthis guyum the uncompressed uh vectors thattakes about 5 000 megabytes of memorythe compressed Vector takes about 500megabytes of memory so the uh the orangeline here is uh 10 the memoryrequirements the ram requirements of theblue line over here and the performanceis almost identicalum for one tenth the memory price whichis which is pretty amazingum on on here the the uncompressedversion is so this is a million of thedbpedia data set the uncompressedversion hereis uh 18of the sorry the the compressed versionis 18 memory of the uncompressed versionso that's pretty impressive because thebiggest one of the biggest challengeswe've seen like with Vector databaseswas like uh yeah spending ton of moneyon having more and more RAM but now evenlike large data sets are affordablefor pretty much any business right so ifbefore like you were saying like oh yeahlike I have a billion that's going to beexpensive now you may have a billion yougo like actually that's okay I can do itor if you have like even 10 million he'slike yeah or maybe you could even runthis uh 100 million in your MacBook orsomething now and still be able to get apretty good results MacBook or whatevermachine you're using so I am I'mactually absolutely excited about itI've actually now I want to run it on mycomputer and see how far can I push iton my just local machine until like thewhole thing falls apartand the great thing about this is thatit's all configurable whereum if you don't care about recall asmuch you can keep on compressing sureyou'll lose recall at a point but youcan uh like whatever memory requirementsyou have you can compress uh to it to acertain degree to fit within thoserequirementsum if you're not compressing too muchyou're not paying any price if you'recompressing way too much then you haveto calibrate for what is the price andrecall that that you're paying thereright and and then um where can peoplefind all this good info about PQ and uhimprovements in 120. yeah so the theblog post is your main go-to outside ofthat you can go into documentation hereuh here we think there's links below ohis there are there links one second okayso if we go here yeah these are the twomain pages so if you want to learn moreabout PQ so on a conceptual level someof what we covered here you can readthrough this if you want to learn how toconfigure PQum this is available right here right soif you go into the vector index configscroll all the way down to PQover herethis is I've zoomed in quite a bit herebut so you can enable PQ over here andthis is the new hyper parameter that Iwas talking about you can set this uhover here it defaults to a hundredthousand so you can read all aboutconfiguring as well as the conceptsbehind this as well and then a smallplug here we're gonna we're gonna talkall about this in a in a new blog postthat's coming out soon as wellnice nice and all those links we alsohave in the description of the video orif this one is not there yet we shoulddefinitely add it after the sessionyeah yeah it's all in that release blogso many there's links to all thedocumentation Pages within each sectionof the blog so you can follow throughafter you read about the feature as tohow you configure it and and theconceptual page to describe what it isat high level and so on so yeahis there is there like anyperformance difference in terms of howfast the queries are becauseif we don't have to do like the precisescanning yeah like you actually youactually pay a price in terms ofthroughput so as you can see hereum if you have a a compressedrepresentation you can you can run uhless queries per second because of theDistortion that the compression uhcompression introduces and also becauseof the um the code book lookup everytime you have a vector you have to lookat the the code book so that takes uhsome time as well so it adds a littlebit of latency the compressionit's almost free but not quite yeah youcan also tweak the um the latency so youcan play around based on the theparameters of PQ you can you can tradeoff memory with uh with your latency aswell as recall but if you look at thehnsw parameters you can tweak those foruh latency versuslatency versus uh recall as well rightso there's a bit of juggling between theparameters between QP and then H and SWgoing on or maybe you know the savingsyou make on on RAM like where you knowspend less money on RAM and then putmore powerful CPUs or with more coresand maybe you could actually recoversome of that performance just purelybecause you have more raw power uh to doother parts and calculations so it couldbe that if you look at it just purelyfrom like Financial point of view youmight end up spending similar amount ofmoney or less and yet get like somethingfaster because you know you move yourInvestments all around like you know wedraw investments from ramp and more intothe you know like a CPU land and you'redoing wellportfolio managementyeah yeah an economist on on the planeyou know yeahniceall right awesome that's all I had to todo with PQ and rescoring folksperfect any more questions oh one oneway to break it will probably be toincrease that limit right to 10 millionback toand then that would ohyeah that would that would move it intoread-only for a long long time becausenow it's going to learn the distributionover 10 million vectorsum before before we had this limit ifyou had put in 10 million vectors inthere that's what it was actually dueum yeah so that's I propose we call itthe read-only commayeahthat would be perfect hey um so the lastbut not least we have them the demo fromJPso uh JP do you wanna show us yourknowledge base app yeah sounds good umI'll be pretty quick so let's imagine ifyou can share my screen or at least myapp of course a high chat map so themotivation for this is that I thinktwofold right one is that I run thesewebe workshops every so often and quickplug we've got one coming up tomorrow4pm Bridge Standard time so if you canjoin us uh find the link uh maybe on thedescriptions but also on our socialchannelsum and and people like really enjoyseeing you know practical examples ofwhat you can do with weaviate as well aslike you know sort of like the simplequeries that we show in introductorywebinars right so that was onemotivation the other is that sometimes Iget a bit lazy like I recently got aPlayStation and one of the things Iwanted to do was like hey what games doI get right and there's like all thesegreat YouTube videos on like video youknow game reviews and whatever else butI don't really want to watch 15 minutesof videos each time I want to like youknow learn about a game or like afeature or something and I thought Iwould put the two things together andbuild this fairly simple app soum it also so what I wanted to show hereis just kind of like how it's abstractedso here I'm just instantiating the appand or what it does at a very high levelit creates a wavier instance and dumpsall this text information that I give itinto one collection right so I can giveit YouTube videos I can give it like atext file so this is like some text ofwhat kubernetes is just from the websiteI can add Wikipedia articles just bygiving it the title so these are allkind of wrapper functions for doingthings like that I can even add YouTubevideos just by giving it the URL like soso this is the release podcastum that Connor and Etienne did and thenI can do things with that content whichis like really really cool and look I'llshow this more in more detail in theworkshop but uh writing these wrapperfunctions are really really simple sothat's why I'll be showing that in theworkshop so here I've got a function tosummarize a particular entry so what I'mdoing is summarizing the YouTube videothat I imported aboveum I won't go through a lot of detailsof what's Happening under the hood butbasically what it does is it gets theYouTube video downloads it gets thetranscript through open Ai and theningest it into uh into this waviatedatabase by chunking and the chunking isfairly simple too and I can go heywhat's this video about and it says it'sEtienne talking about wavy at 1.2 andyou can learn about all these thingslike memory usage shots multi-tenancyand so on uh so you know again I can geta high level review or view of thiscontent without like you know listeningto it so I can say decide from thissummary what I want to do with the videogoing forward rightor I can go or actually maybe notlimited to this specific content I cango well based on everything that's inthe database what can I learn about if Igive it a particular topic so if I goum and this is a little bit of promptengineering on my part under the hood Ican say well maybe I want to learn aboutwaviate but I don't know what kind ofthings I want to learn about So based onthe content that's in the knowledge baseI might learn about hybrid searchum you know module system blah blah blahand in a similar way I can just give ita particular promptand and do something with the contentum and for example here I imported avideo game reviewand this is just uh it's quite verbosethe way it does things the theparticular library and I can say oh whatkind of kind of Gamers might thisparticular game appeal to and I can askthat to this video content right soit'll say this game blah blah blah mightappeal to people who enjoys actionadventure games and emphasis onstorytelling so it's all you know stuffwe've seen before in terms of retrievaluh augmented generation right so that'sfairly standard butum and and just I wanted to show peoplejust how simple it is and how easy it isto put these types of apps togetherusing wavy8um I have I want to write anotherwrapper function which I haven't done isto summarize multiple videos which Ihaven't done that or multiple bits ofcontentum but yeah that's the really high levelsummary of what I was trying to buildwith this app and I've got even just afairly simple text search wrapper so Ican just search for a particular phraseand it gets me you know what I a numberof chunks right so if I search for thephrase multi-tenancy it does a vectorsearch and I get different chunks backright so I get like Source path titleand so onso yeah that's the app um I'll stopraving on about itum it's really inspired by partly by mylaziness and and not wanting to watchthese kind of like you know YouTubevideos or reviews and something that'spotentially a little bit you know alittle bit longum but but you know for for demopurposes as well because people reallyseem to enjoyum playing with the generative searchmodule which is really powerful in termsof making your data Dynamic andinteracting with it and um I think thetopic of chunking seems to come a lottoo right I've got this long piece oftext or I've got this video which can'tbe fit into one object and and to behonest you probably don't want to anywayfrom retrieving information from itum so I wanted to show that as well soyeah that's me um and that's that's thethat's the app andum it's not open sourced just yet it'son GitHub but I haven't I haven'treleased itum but I'll do that as well for peopleto check out in in the near future andif you want to see it as a bit of apreview come to the workshop tomorrowand then you can ask me questions aboutit and then check it out in more detailand one question or two questions yeahum is when you get a transcript fromopen areas there are also a timestampincluded so it's possible to jump to toa specific time stamp in the video we'lltranscript thisso I believe you can get time stamps Ihaven't set that up I've seen otherpeople write apps with timestamps Ihaven't done it so all I do is to getthe whole transcript through whisper andchunk that up becauseum no sorry I get the YouTube video Ichunk that up because the whisper APIhas a limit as to how big the file canbe so I kind of make it certain it'slike 15 minute segments or somethingum get transcripts from there and thenthey just get chunked based on whateverword limit that it has so it's like afairly basic chunking mechanism I've gotat the moment with a little bit ofoverlaps it's like a sliding window typedealum and all the bits can be swapped outso I'll be building in like otherchunkers and all that stuff and weshould be able to build in timestamps aswell because yeah it'll be really goodto be like oh I want to find out thepiece a bit of this video where theytalk about like the I don't knowgameplay demos or like uh what wherethey talk about performance or whateverit is or if I want to look at atn'spodcast and look through the bits wherehe talks about the hybrid algorithmright so something like thatum that'll be really useful for surethat would be super nice to have onesingle point of Tools arounddocumentation so we are filling in ourdocs to written docs the YouTube videosand whatever it is multimodaldocumentation or how to use vb8 and thenyeah having this one single point ofentry for for people want to learndeviate or try yeah I think that'll becool and that was one of my othermotivations was too because I want tolearn about you know if I want to learnabout containerization and kubernetesright I can just dump in all thisinformation into it and start asking itquestions and if I kind of get theprompt good enough and kind of carefulabout looking at the results hopefullyit doesn't hallucinate too much right interms of generating results from thefrom the retrieved text and I thinkthat'll be really cool for sure and Ihaven't checked out like typing uh sorrygetting the language model to producecode but I'm sure you could do similarthings if you give it enough like it'spossible but then yeah but um I was partof several projects doing this becauseone of the hackathon projects did thisand also um one of the problems is thatthen the dependencies so the model ishallucinating the dependency or theversions of the program so one of thetricks is then to build the chain you'rehanding in the error error you'regetting and then yeah doing the nextiteration yeahso yeah the the detail around that getsgets quite tricky for sureI think the tricky part is with likemaybe like false positive like what ifwe give somebody call a piece of codethat is just not a good advice or not agood you know piece of code and thenthey kind of maybe learn the wrong wayor they just go like oh this is allbroken right and I think we've all seenit way too oftenum but yeah I I think this would be coolbecause we could combine many of thethings we talked about today because ifwe use uh the multi-model models we thenwe can search across all of thosedifferent results then include Auto cutto kind of exclude maybe some of thepoorer results right and then throw insome uh you know PQ and then like reducethe amount of memory and maybe you couldrun the vector search on all of the Wiidocumentation videos directly on yourmachine right you don't even have tohave it in the cloud or somewhere rightand uh I wonder if you if we could evenshrink it so much that we could put iton a mobile phone right and then I couldtake it you know offline you know takeit on the plane and stuff like thatthat'll be pretty awesome for sure yeahlet's go guys love itum so we have like some uh good uh nicewarm words from our audience so Brent uhsays he liked your presentation JPum so thank you Brent uh we're reallyhappy to have you here uh Felix alsoenjoyed today's sessions and uh so he heliked our presentations and uh of courseuh we didn't forget about codigoum I'm not sure if that's actually yourname or maybe this is just like a in adifferent language like a coder in gomaybe I don't know I'm gonna claimignorance right now but uh but but butalso the avatars is let's go so it couldbe yeah but it could be like you knowSebastian go like I don't know if codigois a is a formal name or maybe now it isright uh and anything elseI was gonna say if your name is codigoyou probably have to pick up Gora likeyou can't be like Oh I'm a Dev my nameisI don't write go it just wouldn't workright I know right like so um you canset your set up your your kids forsuccess or failure depending on whatframeworkforeignyeah like uh yeah I have a cousin hisname is as400 he's not doing wellanymorethis is great this is greatum I think that's it I think this thiswas an amazing sessionum thank you all for uh for joiningthank you for for the audience just likeuh one final uh reminder so thank youfor watching thank you for listening andthen remember to subscribe uh becausethis way you uh you get a notificationfrom YouTube whenever we do cool stuffum and if you have any questions evenafter this you know what to find us justcome to um the wibit community uhdefinitely find us there we are therewe're pretty active and then we areworking on all sort of things but alsoif you build something really cool andmaybe you would want to join one ofthose sessionsum we're always open to having coolguestsum or if you have idea on a topic rightlike hey I'd like to see more of this orthatum I'm pretty sure we'll do somethingabout the long chain the next time youcome around because we've heard thatthis is a popular topic but maybethere's some other topics you are allinterested so but yeah thank you forwatching us and until the next timeum and yeah have a great dayhi everybodybye bye", "type": "Video", "name": "Weaviate Air Episode 10", "path": "", "link": "https://www.youtube.com/watch?v=u5cQ9VjBoAU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}