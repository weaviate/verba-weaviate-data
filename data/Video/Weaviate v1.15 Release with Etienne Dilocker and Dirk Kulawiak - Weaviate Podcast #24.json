{"text": "Weaviate v1.15 Release! Thank you so much for checking out the Weaviate podcast -- here is a summary of what is new in ... \nthank youhey everyone thank you so much forchecking out a new weviate releasepodcast releasing webiate version 1.15this release is shot with all sorts ofexciting new things from cloud nativebackups improved stability for highmemory setups faster Imports for orderedobjects more efficient filteraggregations two new distance metricstwo new Eva modules and then smallerimprovements and Bug fixes so it's along list of exciting new things to me Ithink it's so interesting seeing theseConcepts in computer science like redblack trees and how do they impactdatabase systems how has it been addedto alleviate and all these otherexciting things Eddie's written thisawesome article on the go mem limit andhow that's improving the stability forhigh memory setups and then this Cloudnative backups so Eddie and thank you somuch for coming on the web podcast todiscuss uh version 1.15 hey Connorthanks for having me yeah it's a superexciting releaseum so many cool new features when weinitially set out to to build this 1.15release uh the the main plan basicallywas around backups but now we have thislong list the features and I think everysingle one of them is a great reason toto upgrade but yeah let's maybe startwith backups uh there the the kind ofPoint yeah everyone needs backups rightI mean it's kind of a requirement to runyour your database in production or anystate full loads such as database and uhyou could do backups before you couldkind of do them before because you coulddo them at an infrastructure levelbasically manually deviate writes itsfiles on disk so you could take asnapshot of that particular disk andstore it somewhere dude with your yourcloud provider but that that's not areally smooth process this wouldbasically would give you a vendorlock-in for that specific vendor so youcouldn't really migrate you would bekind of left or you would leave vv8 inthis kind of weird state where it wasn'treally ever prepared to to take copiesof files or unrestore you would getthese like weird error messages did vv8crash instead trying to recoverum yeah so it was It was kind ofpossible but it just wasn't a very gooduser experience and deviate is all aboutuser experience so now we've kind ofdone the exact same opposite and now wehave a backup feature with the userexperience that we're absolutely proudof with the the 1.15 release you canbackup and restore it to any a cloudprovider or to your local file system sowe have support for AWS S3 or any S3implementation actually doesn't have tobe the AWS one it could also be an opensource one for exampleum for for Google Cloud GCS for a localfile system and basically these can allbe be plugged in using v8's modulesystem and then you can just do a singlecommand we have support for this and allof our our clients and all of ourlanguage clients or you could just sendthe raw HTTP request to start a backupand and that's it basically in bb8 willdo all the cool things in the backgroundand it's been engineered to be minimallyintrusive basically so you can keepusing Vivian in fact we encourage you toto do this in production and basicallykeep running vv8 in production sendrequests have your users use the machinethey can even send right requests in theway that it's architect architectedwithout any kind of impact and yeah thebackups will just run in the in thebackground and then you can restore themeither onto the same machine or evenonto a different machine if you likeyeah and I think that the ux the designand the documentation that shows you howto do it is so well communicated andreally you know massive credit to howyou've written the how how we V8 staysrunning all the time how you can selectcertain classes and I want to get rightback to the ux but this little storyabout not backing up your data I reallylike this uh this HBO show SiliconValley I imagine like a lot of ourlisteners maybe have seen this show andenjoyed the show and there's a scenewhere where Richard is he hasn't backedup the data they have like thisinsurance client Dan Melcher and andthey're all panicking that we you knowwe have no backup of our data in themand it like they're they try to likemigrate their server to Stanford and itfalls apart but then the systems backitself up on the refrigerators and it'sthis really funny scene in that show butkind of communicating that urgency oflike you need to have your data backexactlyyou do and nvv it gives you a proper wayto do that now no refrigerators involvedat allyeah and so one thing about the ux is Iwas curious about this notion of backingup specific classes so I imagine I havelike 60 classes and I only want to backup some of them and the ux makes it soclear of how you include certain classesand can you tell me about the designdecisions behind that part of it yeahyeah absolutely so this is actually uhmainly based on user feedback so theentire feature was uh developed aroundusers input like of course you you askyour users before you write the firstline of codeum and then you try and try and getfeedback and this is something that thatwas very very heavily influenced fromCommunity feedback so basically the ideabehind the the backup system is I Ithink there are so many use cases thatyou can do like you can even use it toto migrate between environments andthese kind of things but generally I seetwo main use cases for a backup like oneis the disaster recovery case wherebasically the disk is lost or or someonedeletes it or this kind of basically toto take all the data be very agnostic ofwhat data is on there and just take thewhole thing basically back it up andrestore it that's one option the otheroption is basically more at a yeahlogical level where you know what yourspecific classes mean and you maybe youwant to create a backup not so much toprotect against Hardware failure or orcloud provider failure but against usererrors so for exampleum a user could accidentally delete datajust through the API so if you want toprotect against that then you would do asort of uh yeah I would also do a backupbut it would be more to to protectagainst user actions and more this kindof application Level backup and thereyou might not want to back up the entiredatabasefor example of course vv8 can be usedfor for all kinds of different use casesand then I know of some that use classesbasically as their their isolation unitfor multi-tenancy so they would havetheir own service that that runs fortheir customers and each customer wouldproduce one or or not Direct butbasically their application would wouldcreate one or more classes inside VBAthat belonged to exactly one customer somaybe they have a requirement maybe forforum sock 2 or gdpr or something thatcustomer data needs to store be storedin a specific way so that would be oneoption for example to just create abackup for a specific class and the APIis designed in a way that gives youthree options basically you can provideno information at all this way it wouldjust take a backup of the entireinstance with everything that's that'son there or you could set an explicitlist of classes so then basically onlywhat's included in the class would bebacked up or you could do the other wayaround where everything except basicallywe have this exclude field and you cansay like okayum don't exclude this or don't includethis class basically exclude this classbecause it's sensitive for something andthen it would create a backup of all theother classesum so see I said like different classesmight be you need more secure more likelet's back this up every hour or so andthen other things it's like well we needto back this up put it behind somesecurity because this is particularlysensitive yeah I think that's reallyinteresting great Point yeah think aboutall different the timing timing plays abit role like you could have a classthat rarely changes but is maybe verylarge why would you back it up all thetime or you could have another classthat yeah that frequently changes andyou need much more frequent updates soyeah that's also a nice way to decouplethis a bit basically and just give youall the flexibility to to Reallyum yeah from a technical perspectiveit's just a single call but you can do alot with it you can customize it inwhatever way you wantuh one thing I'm kind of struggling towrap my head around is um so when youback it up what is the kind of statelook like and does it differ from likeS3 because S3 is just like a filestorage thing right or uh so when it'sbacked up is it like uh Json or file ofdata what what is the backup thing thethe backup is almost an exact copy of umwhat you would have on your disk in VBAnormally so it's basically the thebinary file formats for for the LSMtrees for the the hnsw index for otherindex types that we have so so for bm25for example there's a a simple indexthat tracks a property length becauseyou need these like average propertylengths for the vm25 uh combination andand other basicallymetadata that we need for formaintenance so it's almost an exact copyof those files and then there is asnapshot I think it's actually calledsnapshot Json but that's that'sbasically just an implementation detailthat gives you a bit of info about thethe backup itself so it's like what whatkind of machine was it running onum when was the backup created what'sthe the ID of the backup and these kindof things and that's basically the themetadata that that makes this backup asort of self-contained backup I wouldsay and and what that what I mean withthat is basically you could create solet's say you have two instances one isyour production instanceum and the other one is let's say yourlocal instance which is completely emptyand now you want to migrate basicallyusing using backups your data from thereduction instance to the cloud providerand then basically pull back the theum the backup from the cloud providerthen all you have to do is send therequest from the production instance putit into let's say S3 in this S3 bucketand then on your local machine as longas it's configured to to point to thesame S3 bucket you can restore thatexact sameum backup just by specifying its ID andthe the local instance doesn't need toknow anything thing about yourproduction instance so you don't have todo any like pre-configuring basicallythe the backup is completelyself-contained with everything that itneeds to to be runnablethisso one thing I'm very curious about iswith say the collection of demos and onuh GitHub we've yet examples we havethings like you know uh clip demo withthe with the UI and searching throughmovies searching through wines all theseexamples and I love this idea of gettingwevia demos of here's a graphql API thatstarts through Wikipedia search througharchive maybe complete with the UI alsowith with this backup because I'mthinking about how I think right now youclone it locally and then spin it up andhave it running would instead just kindof restoring from a backup be an easierway to run the demo yourself yeahabsolutely so so basically because thethe backup and restore is yeah it isjust copying of files that also meansany kind of index building that you haveto do that's already that's alreadycontainedum so let's say you have this thismassive instance where you have hundredsof millions of objects and took youmaybe over a day to index it if youcreate the backup the backup is justcopying the files expensive we have allthe the index structures that havealready been built and then if you wantto restore it so let's say you want toyeah run a demo case and and we'vebasically just put the demo data setinto a backup and you restore from thatthat would yeah that would make it asuper fast process because you youbasically just wait for the time ittakes to copy the files and once they'rethere you can start it up and you canuse it yeah wow that's incredible thenyou avoid the import time and just backup wow so I think that was a greatcoverage of backups and for peoplelistening we have you know these sevendifferent things that I outlined in thebeginning that are going to be chunkedup in chapters and Dirk is going to becoming on in the second half to discussuh the red black trees in this thing butthe next Topic at Ian could we talkabout the go mem limit you've writtenthis great article how does this helpleave you yeah thank you for forbringing up the the articleum the the go mem limit is one of thosefeatures where we really benefit fromthe goal language Community being activeand improving go itself so a lot of theimprovements that we do in viviatethey're typically code that we ridewhere we've done something that maybewasn't ideal before and now we've wefound a better way or we've justimproved it in in general so so forexample the theum memory uh improvements or allocationimprovements for filtered aggregationsthat you're talking about with Dirklaterum they are are something wherebasically we've just written better codebut go mem limit is one of the those fewthings basically where we didn't have todo much other thanum compile the binaries forum for the new 1.15 version with thelatest version of go because this is anew feature that go actually introducedand go memed is basically a soft memorylimit and soft means that that go cannotprevent your memory from growing beyondthat limit so it's not a hard limitbasically the kernel has a heart limiteddoes an out of memory kill if the memoryis exceeded and that's basically that'sthe hard limit but it's it's a Targetand a Target is super important for a umfor a garbage collected language becauseby default in go the target would alwaysbe twice of what you have so to put thatin simple terms let's say your yourapplication currently uses two gigabytesof memory and and you want it to use togive us like that's not accidental or ortemporary allocations but that is let'ssay you want to keep your vectors inmemory and this is two gigabytes ofvectors then with that Target being todouble so it's called 100 in in Goldlanguage basically it's a go GC equals100 and that would mean that yourinstance can grow all the way up to fourgigabytes and that's relatively smallnumbers so that's that might still beokay you might have a four gigabyteinstance but now let's say you have thismassive setup and your stable memory is200 gigabytes most likely you don't havea 400 gigabyte instance just to have abuffer for for temporary allocations youwould have let's say maybe 20 overheadand you would have a 240 gigabytemachine now if you set your yourum uh go GC instead of to double to 20that would work for this particular casebut a you have to know exactly where youend up which is the 200 gigabyte youhave to know exactly how much you haveand that means that to get there youalready had a basically very aggressivegarbage collector because it was set toto 20 which means you've spent a lot oftime on garbage collection which mightnot be something that you you would wantto to do and go mem limit basically isthe the missing turning knob here it'sactually not turning up to maybe sort ofsort of a knob that turns itself becauseit basically turns the the other knobthe gochi Cena which basically in a umin a single sentence the closer yourmemory usage gets to the Limit the moreaggressive it makes the garbagecollector so in the beginning on your240 gigabyte machine you have all thememory in the world there's no reason tosave memory so go can for example doublethe Heap every time that's fine but at220 gigabytes or 200 gigabytes with 240gigabyte limit you can't double anymoreand this is exactly what go limit doesin the background it would then make thethe go garbage collector quiteaggressive and then you would never sortof run out of memory again when youthink you shouldn't have because you'vecalculated your stable memoryrequirements and it was all fine andum yeah long story short all you have todo is set a single configurationenvironment variable which is this gomem limit and you just put it to howevermemory you have and if there is a waythat the go runtime can can prevent itby basically making the garbagecollector more aggressive it's got yourback and it will will take care of notgoing over there what it can do ofcourse is if you if you keep onimporting and you have vectors thatrequire 260 gigabytes of memory on a 200gigabyte a 40 gigabyte machine that willstill run out of memory but for thosecases where you kind of accidentally ranout of memory it will prevent those andI think that's that's super cool forhaving to do nothing but but yeahupgrading to the latest version andsetting a new environment variableyeah super interesting I I'm not goingto claim to be a knowledgeable about goreally but I've seen like these Cuda omerrors where you try to put a biggradient through the thing and add amemory programs crashing and so I can Ican Reason by analogy there where you'retrying to import too much data and thenit crashes compared to this thing thatcan manage it and I I feel like that'ssuch a huge thing that things would sayum like gradient accumulation in deeplearning is just kind of an analogy thatI'm going to be using to reason aboutthis like the way that it prevents youfrom the oom error has been such a gamechanger with training big models withyou know big batch sizes and it soundslike a very similar thing with this andso from my understanding it sounds likeum you know with the aggressive garbagecollector it might slow it down when youget to that limit maybe because it's uhso I think it's what you do is maybe youover you have like a 32-bit about likeplaceholder right the temporaryallocation is trying to kill those tomake them for more datayeah yeah so the slowing down is is kindof an effect what it does is basicallyit speeds up the garbage collectoritself so so basically the garbagecollector the or the point of thegarbage collector is to to for for anykind of memory that was used temporarilyum in a garbage collected language isnot freed immediately basically thegarbage collector just runs in intervalsand collects all that memory so that itcan be reused again and the longer it itdoesn't run basically so the longer thepass between two cycles the more memorypiles up and if you're getting close toyour memory limit then it basically hasto run more aggressively and that kindof automatically does that trade-offwhere you only have this many CPUs andif your CPUs do more garbage collectionthat means they do less other things soyes you you kind of trade off a bit ofof compute uh Power for more garbagecollection power and and thereforeprevent running out of memory if it'spreventableso does this help with say uh likelarge-scale load tests get a billionvectors into Eva does this kind of thingfacilitate that yeah yeah exactly so sothe the higher your your regular Heapuse or I think I use the the term uhlong lift versus versus temporary sobasically the the higher your long liftHeap or memory usage isn't that isexactly what happens in in such abillion scale case because those billionvectors they will use I don't knowincluding the index something like oneor two terabytes probably depending onthe dimensionality so I think that theSif 1B data set is something that we'veplayed around with and I think it's it'sa billion uh vectors at 128 Dimensionsum yeah and that's that's four bytes forper Dimension so that is not going tocalculate them in my head on the podcastbut that is a lot and I think if youtake into account the theum the space for the index itself weended up with something like oneterabyte or 1.2 terabytes and yeah ifyou have these kind of kind of massivelimits then it really helps if you canset your go mem limit so that thegarbage collector doesn't need thismassive overhead because even just 10 is120 gigabytes at 1.2 terabytes andthat's a lotwow yes super interesting you've gotthree main topics to discuss onimproving the performance of Eva so Dirkthank you so much for uh coming on thepodcast to explain these new ideasyeah thank you for inviting me happy tobe hereso could we start with uh what is a redblack tree how's it different from aregular binary tree and how does thishelp with vva's performance uh I wouldjust stop by suspending what the binarytree is so let's say you have a bunch ofnumbers and you want to find out if anumber is on your list andum like classical approach would be youjust have a long list and you go throughit and check everyone at every numberand that's slow because you might haveto check each entry before you know itand what you can do is youum sort this into a treeso let's say you have numbers from 0 to100 you pick a middle note let's say 50as the root note and then if you want tocheck if 7 is in your in your tree yougo in and say okay yeah fifty Seven issmaller than that so I take the leftentry and the left entry might be 33 andwe go okay seven is smaller than 33 I goagain in the leftthree until you are at the bottom andthey're found to seven or not and thatlets you check if the number is insidewith a lot less steps then compared tojust going throughum to a listnowum if you create these trees you canhave problemsumif you enter objects in orderlet's say the tree is empty and youstart entering entering numbers in itand let's say you start with with onethen one is your first object the rootof the tree then you enter two then okaytwo is larger than one so you go to theright and the right child of one is nowthe two and now if the three comes yougo in three is larger than zero and solarger than one go to the right notewhich is two three is larger than twoyou go to the right and enter it thereand you can continue on that untilyou're at whatever numbers you are andthen your binary tree is basically alistattitude to find any object you start atthe first and you're the right to writethe right to write the right right untilyou're there and so it doesn't improvethe uh performance when when looking upthings and also when writing objectsinto the streetand now the uh well black tree is aself-balanced tree so there are a bunchof rules associated with the tree andthen you rebalancethe tree when certain things happen asof course the example for example theexample I just gave it's you have thenyou enter the tree so you have donethree nodes on the right and zero on theleft so you're just like this rotate itaround that the two is the new roots andthen you have on the right the three andon the left the one and then you have agaps of one instead of a depth of twoand that makes it then faster thanentering and reading notes from it supercool and yeah so around the 1.15 releaseI will have a blog post it'll probablybe an in description of this video andit's released that'll visually describethis concept of how you rotate the treesthe red red black coloring and maybeyou're aware of things like visual algothese these ideas of um you know the redblack coloring how that lets you balancea binary tree before we go a littledeeper into how binary search trees helpwith databases to look into IDs can youtell me about your experienceimplementing this in weediate um likehow what what do you change what kind oflike in the code base the kind of OpenSource database engine this kind oftopicum so we already have a binary tree inthere where you when you insert theobjects at first andum basically the change was was limitedto the existing binary treeimplementation that we already have sobasically I implemented checks are therulesum I just can't think afterwards is anyof the rules are not developed anymoreand if yes do the appropriate rotationchanging values aroundum to to have it balanced so the red redreflectory itself is an idea I thinkfrom the 70s or the 80s so it's aroundsince quite a whileum but it works great soyeah so all this is implemented in gohave you been how long have you beenprogramming and go what was your journeylike learning it two months so I startedI started working on really AIDS um yeahearly July and I I startedI don't know maybe two three weeksbefore it was my first girl collegeum but but it's just surprisingly fastlike I wasum answer it first I'll just put thegovernment like it's really quick thatyou get you took out that's a greatexperiencesuper cool I think that's reallyinteresting that it takes took you twomonths to learn go and this kind of OpenSource database you know upgradinglittle Parts like binary tree to redblack tree these kind of updates can wecan we maybe step a bit into themotivation of the red of the binary treeuh so so we say we have these uuids theyuniquely identify every item in ourdatabase could be images you knowpassages paragraphs whatever you put inyour vector in the web Vector databaseso how does so the uuids they get sortedin in the tree is that the key idea forwhen you like how you use this kind ofstructureum would be an example let's say youhave a uid that isum just a counter that goes upand then if you insert it you would getexacted behaviors I described earlierthat you insert the first object that isyour root insert the object that's yourright side that object it's your textright child and so on and that justreally degrades the performance when youadd objectsand makes it makes it very slow becauseevery time you use an object you have togo through all the objects you addedbefore before you can write itand for the next object it's even longerso it gets really slow and yeahso I kind of have two things I want totake this in but first so so say um youknow if you're looping through your datain on the client side say you've gotpython code and you're looping throughthe data items and you're using thatLoop counter to construct the uuid isthat the kind of idea where your one twothree four and such that you get thisright except for anything going on theright now does this also play with saywe have an inverted index and we have uhI don't know age uh or let's say somenumeric value with a broader range thanthat let's say maybe uhum maybe we haveuh income and some database I don't knowwe have a big set of numbers in theinverted index does the binary tree alsohelp with that kind of lookupuh I'm sorry I don't know that like as Isaid I just started so I I don't fullyunderstand the journey sorry let me setthe stage better that was a bad exampleso so with the inverted index it's likeum those the foundational idea is sayyou have a textbook and you're lookingfor biology you go to the back of thetextbook it says biology is on page 99page 305 inverted index so um so I thinkwith numeric values we can also kind ofhave thisuh inverted index where say let's sayit's age and it's one to a hundred youknow you'd say 80 and then your databaseis indexed where you have 80 and thenthe customers or whatever it is thathave that value 80. could we imaginenumeric values like that his age sayit's like zero to 100 I think you needsomething like a key that identifies anobjectso you can like you can store as a valuewhatever you want so you could have 50values with a given keyumbut I'mI'm not sure if you could use it for forwhat you have in mind so in general isyou have a bunch of objects that haven'thave a unique key and you want to insertor get them out of a structure quicklythat's I think that that's where you usethese these binary trees and red blacktrees are then if you haveum ordered rights helps you to keep theperformance upright yeah I can certainly imagine howto say um with wevia when you're doing anear object search and you pass in theID of the object to reference the vectorof that object having this kind ofstructure to quickly get it grab thevector search with it obviously soundssuper useful yeah I think like I'm nottotally sure about this but there isthis I've got what is it called uh h n sw and did I get that rightum it works kind of into the same directobviously it's a lot more complicatedbut in I get I would say the idea behindit is similar but obviously it's morecomplex andumhelps you to to find find it but this islike the implementation where I work onthe 3D to toyou get objects into vv8 you first storethemand then you do other things later it'sI don't think it takes part in the inthe searchor in the indexing datayeah that's such a fascinatingconnection between say tree structuresfor fast search or the proximity graphshierarchical proximity graph structureof hsw the way that we have these likesymbolic structures to organize data forfast lookup super interesting and Iguess my understanding of it is you knowif you do a near object search where youpass in an ID you can use the balancedred black balance binary binary searchtree to quickly get that ID quickly getthe vector then you take that Vector onthe road to the hnsw index to now dothat approximate nearest neighbor but sokind of stepping out of this topic canwe now talk about the second topic onour agenda um fewer memory allocationson filtered aggregations could maybebegin with the filtered aggregations andand kind of understanding the currentmemory overhead and then kind of what'sbeen done to help with that yeahum yeah so maybe we do it for theaggregation so we're looking for for avalue that's for example Nia anotherlike sorry an object entry in thedatabase it's near another entry andum there was a lot of overhead involvedin temporary allocations while doingthisum I think something like so we we did abenchmark where we added one millionobjects to bb8 and thenaggregation rate for example would justcount how often is this property thereand with this we hadI think 200 gigabytes of just temporaryallocations that would happen whilelooking forby checking how many otherandum yeah there were a lot of differentinefficiencies I would say in the codethat that you could optimizeum in general like this the the stackand the Heapum where you can store memory and gowell in general andumif you start on this you can storethings on the stack where you a know howbig it isandB it doesn't escape so let's say youhave a function you allocate some memorythere and then you return it up thestack to whatever column you don't knowwhat's happening afterwards so you needto have it at the place where it candynamically grow or Shrink or the thelifetime is not limited and so it goesonto the Heapuh if you have a variable that youcreate in a function you only use it inthat function and afterwards it's goneyou can put it on the stack where it'smuch cheaper to create and to uh readandum so I would say there were three orfour different patterns that I noticedthe first one isum we the the objects we store them inLong byte areas so it's just a long areaof bytesand then if you for example want tocheck or I want to read all theproperties from itumthen there was a library that was usedit was called second binary.read I thinkand this just created lots ofallocations for this process yeah so ifyou say oh I want to haveumthis is the the buffer from which I'mreading where the object is stored in Iwant to read the first 20 bytes becausethey mean the the ID of the object thenyou could tell that to the to thatlibrary and it would give you thosefirst 20 bytesum and would create a bunch of temporaryallocations by doing thatum it's nice to use but that makes makesit slow and so I basically created alittle low level library that justumreads from underlying buffer how manybytes you want without any temporaryallocations and that's yeah then usethat library at different places and andmake it yeah somewhat user friendlyum[Music]yeah yeah so I'm sorry to be you knowI'll be re-watching this and hopefullywrap my head around the full the ideabut um maybe so a filtered aggregationis say we're we have a hundred millionpassages in Wikipedia say we're tryingto uh average out the word counts ofthem or something like that right isthat it so that's a filtered aggregationuh yeah so so each Wikipedia Passageuh with its respective properties likeword count is stored as like a bytestring yes so you can better hash outthe thing that you're trying to filteronumso basically you know do you have tohold object like the complete object isone long bite string and there you haveto to get to the to the rightplay so you you basically get that longthing and then you know okay the firsteight bytes are the ID of the objectthen there's a bunch of other things andthen there is umlet's say the length of the of the keyof the object so you first you firstneed to go to the place where the key isthat you read the key then you know okaythe next 53 bytes are the keyif you need it you read those if not youjust jump over it and then you do thatuntil you're at the place where theinformation is that you're looking forand basically with the old library youhad to read everything and every readcreated many allocations and now thisnew library basically allows you okayum I want to read like I know the nextvalue like the next thing I'm reading islet's say an unsigned in 64. so you doreads unsigned in 64. you get that valueback and the internal pointer the pointswhere in the buffer eyes jumps forwardand you do that until you are at theright place in the buffer where theinformation is that you needsuper cool so it sounds like it would beespecially useful if you have say a lotof properties like data objects thathave several properties but especiallybenefit from this kind of technique andmaybe one more thing I'm missing in myunderstanding is so so the temporaryallocationsso is that um so you copy the wholething could you take me through it alittle a little more sorry to be okayokay let's start from a bit let's say wehave aan object that and the the buffer whereeverything is stored is 10 000 entrieslong and then what was done before isthose 10 000 entries were given to thatbinary dot read library and they wouldsay Okay read me the first four bytesread between the next 20 by threemillion next five bytes and so on andeach of these calls the library createdin the library so not in our code but inthe library code a bunch of temporaryallocations where they just createdbuffersfor whatever reason like I haven'tlooked at their code so I don't know itand umbasically what's happening now is youhave two choices a is move the positioninside the buffer forward withoutreading anything so if you know all thefirst 80 bytes don't matter because itis information I don't need you just saymove position forward and the internalnumber that says omx by 15 is just moved80 by 80 entries forward if you then sayOh I know now I'm reading uh answerinteger 64. you call the read answerinteger 64 calland it then reads the next uh eightbytes interprets them in a way thatdoesn't use any temporary allocation andreturns you the valueso having that Precision on umknowing that you're going to read a32-bit value that that reducesI think that makes sense I so thatreduces the uh because otherwise youneed to allocate the 64-bit no do youalways noumyou always need to know what comes nextso you have a you have a format and youknow in in my long long white area thatdescribes the um the the objectlike the first eight bytes are some IDthen some other thing comes then thiscomes and thenum the length of the t comes which isn'tunsigned 32-bit value and so on andumso you always know what to readit's just are you doing it in efficientway or unefficient way basically andthis this library was doing in anunefficient way I don't know why andlike I haven't looked in that code butitumyeah it probably does a bunch of otherthings and for example it works forfiles and for any buffer which makes itreally nice to use you can use the samefunctions on uh like reading a file andreading some byte area probably all'sNetwork also I don't know that and now Ibasically I created some specializedfunction which does a subset of the thespinal.read library does but for us itdoes what we need at this place and itdoes it more efficientlywow so so I guessthe high level takeaway is that you canyou know do these aggregations with lessmemory requirements but yes I'm sofascinated at how you're able to kind ofgo into the database code and make thesemodifications even with you know twomonths ago and replace this library withthis thing it's really opening mythinking of about this kind of like opensource database and the differentcomponents of the databases that you canimprove on you know from The Balancingtrees for the sequential rights to thememory allocations on these aggregationsis super interesting uh so we're notgoing to do our third topic um so withless memory construct consumption withimporting many parallel bashes I thinkum you know just importing data I lovethis topic trying to better understandit myself so I'm so excited to learnabout what's new with this yeah soum what we were doing up to now is uhlike you have your clients and then youfor adsdata in batches to to vv8 and you forexample do it over Network so you justhave five clients that you run inparallel that each send their batches todeviateand that can processed there and uh whatwas done up to now is that for eachbatch that gets imported a number ofgo routines are started they do theactual importing so if the first batcharrivesum we will startbasically a number of CPU cores goroutines and those girl routines thenwork through the to the objects that arein the batch and and add them to theactual database and the same happens forthe second and the third the fourth andso on so if you have 10 batches inparallel you start 10 times your numberof course goal routines that work inparallel importing those objectsandum each worker has a memory costassociated with itso every worker that startedum has certain certain things it doesand does it memory so if you have then10 batches you have that 100 timesandum so I've got that number from etn Ihaven't measured it myself but like hetried to import many objects I think helikeI think he said the billion but I'm nottotally sure if it was a billion and atsome point on a really big machineum like 40 of all memory that's used wasfrom these workers and at a certainamount of time a certain point like theimport doesn't get faster if you addmore gold routine so you just add morememory that gets allocated and usedbut the total throughput doesn't gethigher anymore yeah wow this isincredible the I mean the thinkingaround if I want to import a billionvectors into vva that I can distributeit across say 10 like uploaderscould we talk about that idea a bit moreso umbecause it would speed it up it kind ofreminds me almost of like distributedtraining with deep neural networks andthe same kind of you know distributeddata uploading what else goes into adistributed data uploading with I meanimagine the red black tree balancing itisn't it probably needs to be some kindof synchronization step right likeI mean the the that's a different pointso first you you kind of Center theobjects to vv8 and then youum put each object into vb8 and um andyou have clients let's say the pythonclient and that just has overhead andyou you can't send the data from oneclient fast enough to to saturate like abig server but you have BBI running andso if you instead of just having oneclient sending data you have two orthree clients thenum you come to a point where you reallyuse up all the resources that the theum the the server has so in my localtest on my machinethere is no real point in having two orthree in parallel that doesn't make itlike maybe a little bit faster up to apoint but then it gets lower butif you have this this remote setup soyou're sending over over Network youhave latency you have throughput issuesthen it can help to have multiplebatches in parallelso so maybe we could um Step through sothe the memory overhead of each of theclients what what is it that the clientsneed to store that creates the overheadoh it's not the clients butum it's the these workers that take theobject and actually add it toum toto vv8 and they have some temporarystructures where they where they uh likethat's one of the parts I have looked atso I I don't know it yet butum they have some temporary errors wherethey check ohumI already looked at a bunch of otherobjects and now the new object isdifferent but yeah I can't reallyexpanded the story about that one andum so basically what we've done is nowinstead ofstarting a number of go routines witheach batch that comes there's a shared apool of girl routines that that works onthe object of all batchesso let's say you have 10 clients sendingdata you're sending batches in then allthe objects from these batches get addedto one queueand then the shared workers justtake the first increase at the databaseas soon as one is done it takes the nextone so you always have the same numberof of workersaddingobjects and it doesn't like the numberof broadcast doesn't get up uh doesn'tscale up if you have more batches and soyou you are limited in the growth of ofmemory usage so if you have many batchesbecause you don't have this manyparallel operations that are going oncould you tell me Limited in the um inthe memory of the of the patch can youexplain that one a little more yesumso each worker that adds the objects tothe database create some temporarystructures as I said before I'm nottotally sure what they contain butthey they need some memory to do theirwork so if you have 10 you have 10 timesthose temporary structures if you have100 you have 100 times those temporarystructures soumif you know say okay I'm limited it to10 or 20 workers that go in parallel youlimit the amount of memory they use forwhile importing it andumprobably that as kind of a trade-off soif you have more goal routines up to apoint it gets faster let's say you wouldchange just one worker one gold routinework in parallel then it would be muchlower then you have five if you have afive core machine but if you are goingto 50 then on your five call machine the50 is going routine won't help youadding things faster but it will stillconsume memory but you can't use anyother thingsso the the client is Freer to go get thenext day so the network part is fasterand so when you have 50that um no like the the clients stay thesame the networks stay the same what'sdifferent is how deviate like in deviatehow vv8 accepts the objects and thenadds it to the databaseso vva test instead of having a hundredgoal routines working paralleling theobject that only has 10 or 15 orwhatever you put in uh okay because itneeds less temporary structure yes youhave less gold routines working paralleland deviate so you have less of thesetemporary objects adding uh useso you have less over memory consumptionso then as a result can you add evenmore data to it likeumit scales a bit better if you have um ifyou have many batches then it's a bitfaster not too much but a little bit Ithink the most important thing is ifyou're adding lots of objects inparallel then just your memory is isgrowing so much that you're running outof memory at a certain pointand like this is this is what goes awayorit's lower so you basically you canimport more objects with the same amountof memorysuper cool so so I think that was agreat coverage of the three topics ofyou know self-balancing red black treesto improve the sequential rights fewermemory allocations and filteredaggregations and as we just finished upon less memory consumption whenimporting many parallel batches um soquickly touching on a couple other uhtopics in the 1.15 release we have twonew distance metrics uh hemming distancein Manhattan distance uh Eddie could youquickly explain what they are and howcommunity members have contributed thisyeah yeah so so first of all the factthat Community members have contributedI'm super proud of that fact because foran open source product it's so nice toget these kind of outside contributionsandum yeah users having those use cases andknowing that they they need them andthen um they don't just have to put in afeature request but they can also justdo it themselves that's really nice andit's really cool to to see that thatkind of community usage uh yeah so soManhattan distance that that's one thatI haven't actually used myself beforeum but I like that I like the naming Ithink an alternative names like taxi capdistance and the idea is that you youhave a grid or like you City grit as youwould have in Manhattan and you can'tjust walk straight through a block sobasically the only way to navigate frompoint A to point B is to actually walkthe the uh the grid basically in thegrid then would be your your axes in thecoordinate system and that's basicallywhat the distance is so instead oftaking the diagonals you would in ineuclidean distance you just take thesort of walk along the axes and um yeahI have no idea what use cases are arethere for what models use them butapparently there are some becausecommunity members like themum then Hamming distance is one that I'ma bit more familiar with because that'salso also used for binary passageretrievalum we're basically Hamming distance justgives you the different uh bits or bytesor depending on on what it runs on if itruns on numbers then gives you thedifference between the numbers of eachvector and um yeah on binary passageretrieval the the general ideas that youcompress this entire Vector into thiskind of binary thing and then instead oflet's say with cosine calculating theentire angle basically you just compareyou just walk through all the bits andsee are they the same are they not thesame and if all the bits are the samethen the distance would be zero thevectors or the vectors the binaryvectors would be identical and basicallythe the worst possible score that youcould get is that every bit is differentum so I guess it's in computer scienceterms it's basically an xor kind ofcalculation between the the two umvectors and uh yeah if all are differentthan your maximum distance basically thenumber of bits or if it's on a numberthe the vector Dimension and then thatwould be like the themost farthest apart vectorsum yeah um binary passenger retrievableAscent would be one of the the use casesyeah the new distance metrics are sointeresting I think so I think we'vecovered five things now with uh you knowcosine similarity being the foundationalone and then kind of dot product whereyou remove the normalization from cosinesimilarity and euclidean and Manhattanwhich are similar kind of analogs ofeach other and now this Hamming distancething which I think is pretty unique Iremember doing bioinformatics classeswhere you look at like the RNA ofmutated coronaviruses and so you'd havethis edit distance with the acgtvocabulary and so the edit distance andyeah the maybe the binary passageretrieval may be looking for theseconnections and you know Eric has beenreally studying these distance metricsand trying to prescribe things for webiausers like you know when to use whichone when and so looking at things likeaccuracy and speed I think you have thelittle reasoning around the speed wherethe Manhattan should be faster becauseyou just have the differences you don'tneed to square them some of the dotproduct you don't need to normalize themso it should be like a little bit fasterbut generally I think the prescriptionis uh you know just try it see and seewhat your feeling is our currentthinking so we also have these uh twonew hugging face modules or two newmodules that I think integrate withhiking face correct me if I'm wrong andsaying that they're kind of hugging facemodules but can you explain what I knewabout the new Wii date modules uh yeahyeah so one of those is actually uhcompletely hugging face specific sohugging face has an API where you canbasically dissipate service from fromhugging face and uh basically they hostthe model for you and they do the Ithink it's called the the hugging faceinference API and that's exactly exactlywhat it doesum so with vv8 modules or before allthat you could do with with eBay modulesbasically spin the module up yourselfbut if you maybe already have a huggingface a subscription you just want tointegrate with that because you're yeahyou're already using that and you'rehappy with itum the new module basic features givesyou an integration point to their API sothis is we call this from the mediatesperspective it's basically a third-partyintegrationum because it's it'sfrom a technical perspective it's just anetwork called to um this third partyAPIum but yeah it gives you completely newflexibility because every model that issupported on unhiking faceum you can run it through vb8 and um youcan basically make use of all of theoptimizations that the hug and face teamhas been been doing already so if youare for example self-hosting vv8 butdon't want to self-host the inferencepart that would be one option and ofcourse also with the VBA cloud serviceum you can integrate it as well so youcan if you want a fully managed uhoption then you can integrate as welland have basically the database partbeing managed by semi and the uminference part being managed by huggingphase and then the other module that wehave which is yet another Communitycontribution which I'm I'm super proudofum it's a summarization module whichbasically it runs at at runtime or atquery time so similar to our q a modulefor exampleum which I think we call the categoryreaders and generatorsum and yeah basically it takes yourresults and if you want to it cansummarize results for you into somethinginto a shorter segment or so so if youum run your search results for exampleon very large documents but you want topreview them let's say in in yeah yoursearch results page maybe that that's avery simple and very much search relatedexample you could just generate such asummary on the Fly and display itawesome well thank you so much Eddie andeveryone we have again this recap ofcloud native backups improved stabilityfor high memory setups faster Importsfor ordered objects with thisself-balancing red black tree moreefficient filter aggregations and thenthe two new distance metrics and two newEva modules uh so I'm like a kind oflike a MC of a show now so followingthis this is the conclusion of ourversion 1.4 15 release uh now followingis going to be some more informationabout Dirk uh how did he become workingwith edian on these performanceimprovements what is his background likewhat led him to be thinking about thesethings so I I hope you'll be stickingaround to watch that part as wellthanks for having me Dirk I'm reallycurious like how how is your kind ofcareer development been that you youknow you can identify these performancebottlenecks and develop things like thisum I'm I was a physicist uh so the thephysics Mazda PhD individual postdoc andthat basically wroteum simulations about various barrierstopicsand it's just natural to tolook for these performance optimizationwhen you write the simulations and thenmy my last job was at Deutsche Barnwhich is like a train company in Germanyand uh it's part of a team that wrotethe simulation for microscopic trainsimulations soum yeah I did a lot more morearchitecture and general design thingsthere was always this performance thingin the back or a part of of the workcan you tell me a little more about uhlike simulations simulation code and andkind of what what the experiments looklike for thatuh it really depends so let's let's Iwould I would go to university againbecause I think I'm not allowed to telltoo much about my last jobum so I did there was like cellsimulation so how to sell moves how dothey interact and so on andumin one of these projects for example wehad a lot of of noise how the cellswould move so that like we we werelooking at the collisions between cellsand um you know you have them on a 1Dstripe and they collide with each otherand we had a little bit of noise so theydon't always go head-on but like thissometimes like this sometimes so theyrotate a little bit and so you need alot ofum with the same parameter sets you needmany runs so you can do some statisticsif you just the wallet could be randomthe outcome but if you do a thousand forthis parameter setting you know then ohthis place happens 20 times this casehappens 50 times thenum you can put a statistic and you cancompare different parameter sets so yourcode needs to be fast enough to likeexplore the relevant parameter space andhave enough runs so you can build upstatisticsand so yeahit needs to be fast enough for thatwell yeah can I ask about um whatinspired your interest in we getuh it's a cool project so I I talked tothis with Etienne about it and itsounded really interesting and um Ithought like I did simulations for 10years 12 years something like that andit's time to move on and do somethingdifferent andum like I was very like close to machinelearning in my last project like didn'tdo it myself but with the simulation itwas then used with machine learning andso I feel like I'm keeping thiscloseness to machine learning but notdoing it myselfand yeahalso very interesting going from thefrom the big corporate company to asmall startupoh yeah I'd love to talk about that aswell if I could stay on one more thingwith the what is the role of machinelearning in those simulations that youdescribeum so University there was no machinelearning so I did experiment a littlebit with like detecting the outcomes butit was just like very very very simpleum and then my last job basically thethe goal of the project was to automateschedulinglike long-term planning and short-termplanningum so long-term planning sense ofthe next schedule how all of our trainsdrive to the network for the next half ayear and we have these requirements oftraining companies that try from here tothere from data here and so on and get aschedule where everything fits inand the second part short term let's saythree Falls over you can't drive allthose tracks anymore we need to rerouteeverythinghow can we do itum by staying as close as possible tothe original schedule and making ourpassengers arrive as as close tooriginal time as possible and so I wasbuilding with my teamum this micro microscopic trainsimulations and then there was anotherteam that used reinforcement learningto try to learn with the simulation howto create conflict-free schedules and toreact to risk disruptionsokay is there any scenario in which thatwould be like the the vva data uploadingwould be so chaotic that it would be ananalogous kind of system or is it Ithought a bit about it but I I I don'tthink like I I don't think there's alike a direct connectionum I think possible learning like nottoo much into it but it's it's I thinkvery Niche and special like I thinktheir profit rate fits great andmany way it doesn'tumyeahso sorry so it's like these reallycomplex schedulingalgorithms isI guess I'm curious if like leviatedthey say there's like a million clientsuploading data and then you got tosynchronize it all get in the databasesthat maybe analogous or is it I don'tthink so no because umbut basically the the the the uh theproblems you have in the with the trainsystem is thattrains cannot easily overtake each otherso the theum the order trains are in at a certainpoint in time is really important andyou can have a train like I'm not usingGerman cities but let's say one trainstarting in Munich another trainstarting in Berlin which is 500kilometers away and theywould need to use the same piece of dragin five hours so the the the order whichwill derived at that point like if thehigh speed train comes first so if theslow cargo train comes first really canmess up your schedule because if thehigh speed train is behind the the cargotrain which drives really slow and can'tbe overtaken then you have to ISP trainbehind it going really slow forward andumthat that's a real problem that can't besolved with analytical methods so that'swhy we went the the AI route I thinkthis vv8 is uploading is you have abunch of data you need to get it intothe database and the order doesn'treally matter and you just need tomake it efficient and umyeah what do you think about this ideasay we're we have like video data rightthis video data could be like you know a30 second video is bullet train likeit's you know it gets ready compared tolike a three hour video whereright would that kind of thing maybe besimilarum I don't I don't I don't see aconnection there sorryumyeah I um I think this this like thisscheduling is so difficult because youhave everything affecting everyeverything else so each decision you doat one point can have a day later aneffect somewhere else that you don'tknow immediately and with with likeadding things to bb8 the objects don'tdepend on each other you need to getthem in withouthaving bugs in your code like withoutoverwriting anything else but besidesthat they're independent from each otherand it doesn't really matter if you adda 30 minutes video or a 30 seconds videolike the the process of writing it willprobably take longer because you havemore data butumI think besides that that it's notto pick off a connectionmaybe with the cross-referencing therecould be some kind ofbecause I think with the crossreferencing the current way that youneed to do it is you kind of have like aparent-child import where first youimport uh you know say it's articles andthen they have their paragraphs you needto first get the articles in there andthen you reference the paragraph Somaybe with these graph structuresthere's some kind of scheduling to howyou orchestrate the referencing withuploading that could be like if it'sreally complex and you have likecircular things that you need to breakup and there it could beumwell maybe let's say you're you'recreating objects on the Fly and then youneed to uh make sure that everything isin that you need and then a new objectappears and then you need to reordereverything if you have that then itmight be but um I'm not sure howrealistic like how often that happensmaybe butsuper cool so can you tell me about yourexperience at semi-technologies and youknow just kind of earlier topic wepreviewed of working in a bigCorporation compared to the startup yeahum so I was like in the in the startupin the big company but then the orshould I say the big company came intothe startup and and so yeah meetingscorporate overhead and that wassometimes a bit too much and now I wouldsay it's it's very lean you really workmost of your time obviously can't youtalk to your colleagues sometimes whenyou're there but you really have havetime to work so that's that's aum a very nice nice change and like youstill have a feeling that you can thatyou know everyone solike in the old like the crew like Ithink when I started with 60 people evenover there left it was 250 so I kind ofyou lose you don't know everyone in thecompany anymore and now I have to play Iknow all the names and all the facesumthat's the differenceif I ask one more question aboutum sort of your your motivation and kindof do you do you maybe have like anapplication of we V8 like personally Ilove the idea of searching throughscientific papers and I I find everylittle grounding every little thing I'mworking on in that application to bevery motivating uh do you have that kindof thing or is it just about thetechnical of you know where can I find aperformance like I like personally Ireally like to to coach and tocomplicated problems I I guess umnow when you set statistic papers if ifyou have a lot of results from sciencelike you do experiments or you dosimulations and you have just a bunch ofof results that you can't really look atanymore you'll have a possibility tojust like send it to bb8 and do somesomebasic analytics in there like as I saidwith my my simulations where you haveum where you have the cells crushing aton and I really I look at a lot ofvideos and I wrote like by hand thescript that oh if the cells are aftercolliding at this far away in this caseandyeah that was a bit annoying so if youcould automate that andhappy read in there that would be reallycool and II'm sure in larger projects I I did it Imostly worked alone with one or twocolleagues so we didn't add that muchdata but if you're in a bigcollaboration let's sayum at 7 or somethingwhere they have billions of terabytes ifyou could help thereI think that would be something thatwould really fascinate meyeah wellit does not as thing I thought about butthat kind of yeah like how cellsimulations I've heard of like maybelike docking simulations I I don'treally know too much about this but thiskind of you're simulating a bunch oflike um is it like electromagneticinteractions like that kind of thingso we read it like effective interactionso we didn't go into the the like thephysical details of the electrons thatthat umdon't want to be the same place butbasically if the one cell is here andthe other side can't be here and theyhave some chemical attraction to eachother and umyeah repulsed each other at certainplaces so it was veryum how do you say like high level so wedidn't go into into the details becauseit's already like the the uh the modelsalready complex enough so you reallyneed to think about what can you put inwhat's like the the minimum level ofdetail that you need to have in there toto kind of simulate what's happening inthe experimentum wow so you have like uh like a bigmolecule and some kind of chemical scoreto it rather than like an atom level nowwe did um like real like biologicalcells soandumwe we simulate them as a as a blob andwe used it's called phase field approachso it's basically a field that's betweenone and zerowhere it's one there is the cell whereit's zero that's not and it goes likeit's one one one one one and then itgoes down to zero in like very smallsmallum area and in this in this fuzzy inbetween phase that like it's theboundary of the celland um then the these places fromdifferent cells can get close to eachother and when kind of their boundariestouch you have like physicalinteractions so they they repulse eachother and attract each other in acertain way and then um based off somechemicals instead of the cell you haveadditional chemical interactionsand then if you let them Collide youhave based on these interactions youhave then the cells behave differentlyandand there were like interestingexperiments about it and that's what wetry to to reproduce those experimentsyeah well that sounds super interestinglike that like hierarchy of biology andthe um that's the whole thing is superinteresting well Dirk thank you so muchfor uh describing the new performancechanges in we V8 version 1.15 and Ireally enjoyed getting to learn moreabout um you know your background andthe things that interest you I reallyenjoyed this podcastthank you very much which I did too", "type": "Video", "name": "Weaviate v1.15 Release with Etienne Dilocker and Dirk Kulawiak - Weaviate Podcast #24", "path": "", "link": "https://www.youtube.com/watch?v=8lyA3mf7FjY", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}