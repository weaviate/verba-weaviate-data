{"text": "SeMI Technologies Co-Founder and CTO Etienne Dilocker returns to the Weaviate podcast to describe what's new with Weaviate ... \nhey everyone thank you so much for checking out the we va podcast we have a super exciting episode eddie and dilocker is back on the we vva podcast and we're going to be announcing what's new about wev8 version 1.14 in this podcast format so hopefully this kind of style of having this conversation around the new changes is a nice companion to you know announces of new software and things like that and i'm really excited about kind of uh rolling out we vva version 1.14 in this kind of style so eddie and if you had say one sentence to explain the what's new about wev8 what would it be yeah hey connors thanks for for having me i would say this is the most boring release that we've had so far and i'm super excited about that so what i mean it's it's all about uh reliability about running vb and in production so all that feedback we've recently passed a million downloads and all that feedback that we got from our users running it either in their evaluation setup or in production uh they discovered a lot of issues and and we fixed them all and basically this is all in this release so i'm i'm super excited about it so we have so we have the uh bullet points of the different topics that are going to be covered in the chapters of the podcast as well for people listening if you want to jump ahead to the different parts of the release that you're the most interested in but eddie can we start with um what's new about monitoring and observability what what does that entail yeah yeah so observability i think in in any new software project it's like always one of these things where you know like you need to design software in a way that it's observable because well if it's not observable you don't know what's going on and then it makes it super hard to to run it like in a production setup where uh yeah you can't monitor it as as closely and uh with vv8 i think for the longest time we've kind of said yeah it's coming it's coming it's coming and it's finally here so with this release uh we're adding uh prometheus compatible monitoring so prometheus is a sort of a very standard i would say industry standard for for monitoring tools um essentially it's just a format it's just a format of how the metrics are are presented but it comes with that whole prometheus ecosystem so you can basically just plug in standard software like your standard prometheus a time series database standard grafana for visualizing those metrics and all of a sudden you have like insights into eva that you could never have before so you can get all these these dashboards and and really for everything so it's i think over the past couple of weeks we had like a rough plan of what metrics we would need but we just we kept on adding more and more metrics because it's just so easy to add new metrics now so a very typical example case would be importing into vba so let's say you're importing a relatively large say i don't know 100 million plus and all of a sudden it starts getting slow so that was definitely one of the and also when we talk about the reliability fixes later on that was one of the of the topics that could appear in the in the um in the past so a community user would maybe say maybe say it's suddenly slow and then we would go oh well that's not supposed to be like that but it's kind of hard to tell what's going on because well not only is it not us running that instance like maybe it's self-hostable so so users can run it themselves um but also they how would they know basically and with the monitoring setup this is now super easy because every request that comes in so for example a batch import that is split into its individual components so it's being imported in the vector index and the object storage maybe the inverted index if you if you're building that up as well and and then all of these components are split up further but that gives us a super easy insight to just say oh look we can see that the vector index is fast but the object index is maybe uh slowing down so ever since you crossed i don't know 100 million objects because you can of course also overlay that so you could send okay at that point you had 50 million objects imported and all of a sudden there was a jump maybe in the time to to import one additional object and uh that gives us and then our users and then everyone operating vb8 a lot of confidence and a lot of insight in into just figuring out what the issue is and fixing it so it could easily say like oh looks like you have an issue with your disk maybe or um something else in the setup like yeah before it was a lot of guesswork and now it's it's i guess debugging is still it's still detective work but now the detective has like tools and has hints to to basically uh yeah figure out what's going on yes i'd really love to dive more into the incremental build up of the h s w graph and get back into the technical details of that topic but uh just just so just one more time so prometheus it's um it's like a visual dashboard kind of like uh like a graph where you say have uh you know you have this much ram has been used uh this many vectors are what kind of what does the visual of it look like yeah yeah so basically uh vva itself just comes with those metrics and we can like everything that's going on we can basically measure and prometheus is kind of the format but prometheus is very typically used in combination with grafana which is this dashboard provider where you can you can so users can define their own dashboards they can say okay i want to combine this metric or maybe see like how a metric changed over time and these kind of things um and of course we also have like we have a couple of sample dashboards so if you want you can have like this one click setup where you say um hey so we have in our vba examples repository we have this the setup you just spin it up and it has everything pre-configured and just you start using vva normally but now you can open up that grafana dashboard and you can just see what's going on so so yeah it's a very very visual way you can of course also use those metrics programmatically if you want but like with grafana it's super easy to just visualize it for yeah for the users for the people having to operate it for for everyone that's involved in sort of making their case with vb8 as a success case yeah it sounds super exciting especially for like you know very big scale i imagine that it's very useful to have uh so does this relate to say the horizontal scalability idea we talked about earlier where uh you're using more than one machine with wev8 and does this help you kind of monitor that as well did those kind of play together a little bit yeah yeah yeah exactly so so prometheus is really i would say sort of a cloud native tool um so it does stuff like orchestrating across nodes it does that very well so you can like you can aggregate basically you have two ways like you could say uh is there something going wrong on maybe one specific node and then prometheus just adds a label to it for for each node has a name or has a hostname or these kind of things so it gives you a label to to narrow it down or you could just say well i want to treat this vvate setup that's composed of multiple nodes as one unit basically for for my use case and just tell it to to aggregate those those metrics as one and you can do it as well so that's that's basically this granularity would be you start with the setup like like you could let's say you would have a multi-tenant setup of like multiple vba instances and that would be like the highest one where you would say maybe uh as a as a vba user uh you yourself have like different users and then each user has like its own vba instance for example then that would be the first first level of granularity then per user you would have this one vb8 setup there you video setup itself might have multiple nodes on each node you would have maybe multiple vb8 classes they could be compromised of individual shards so basically you can you can go down as deep as you want until you have like individual objects or even even even deeper on disk or you could go like very highs and this gives you um sort of the the ability and prometheus does that very well to to just aggregate those individual labels um yeah across whatever you want including including distributed notes in a cluster setup yeah super exciting stuff and i definitely want to talk also about uh multiple classes and uh you know to quickly kind of background this for listeners we have this kind of semantic relation data schema design where you could say uh have one class would be say tweets and then you could say like has article link and then maybe you want to store like an article as another class like has image has another image so it's a way to do multimodal data it's a way to say decompose your data if you have a scientific paper and you say want to have a has introduction has related works has methodology you can break it up into multiple classes and then you could have h sw structures for each of the classes if i'm understanding that correctly but uh so could we kind of uh come back into the incremental build up of h sw and i think it ties into the monitoring as well just to maybe get a little more into what's happening so so with h w my current understanding of it again is we have this proximity graph and um so you can take me through how you compute the proximity graph and then and then how you incrementally build up the neighborhood graph to facilitate nearest neighbor search at massive scale yeah yeah yeah i'm gonna gonna try to keep this as short as possible so we don't exploit the entire podcast because you know i love talking about this um but but no in in general uh the idea of the the proximity graph is that a nearest neighbor in the graph basically is the nearest neighbor in the terms of nearest neighbor search so that the distance and that that may also be a good segue to one of the other topics and when you talk about distances later on um the distance between two neighbors in the graph is lower than the distance between a neighbor where you'd need two hops through the graph um and that that is the same like if you import two objects or maybe three objects or five objects or if you go to hundreds of millions like there is a point where if you want to you can chart this up into like multiple instances or into multiple uh yeah indexes basically if you say um for example with this very large machine i can hold 500 million on a single machine but the machine is simply not big enough to hold more than 500 million but i need three billion for example then you could say okay i'm going to split this up into six machines that each hold 500 million and then each of those machine would have their own hmsw graph but from a user's perspective you wouldn't really notice because the the results basically if you do a search it would search all six graphs in parallel and then because we all have this distance metric it's basically in a sense it's re-ranking i guess kind of a fancy term but yeah it basically just means we take those results from those six graphs and and basically uh aggregate them yeah and with the with the monitoring you can you can watch uh the graph grow basically so you can see live like how how many objects are imported and um it also has a couple of so so the the graph itself um basically it grows exponentially so you need to reserve memory and and this kind of growing operation is a bit costly in the sense that while it's growing nothing else can be going on so it's like for for the highly concurrent setup you need synchronization and just i'm just throwing in buzzwords now so basically you need to need to lock this graph and this is something that that um yeah you could you could see before um or or that we couldn't see before because we didn't have the monitoring that the way that we grew this graph um that that wasn't necessarily optimal uh because it cost too much time and and now with the monitoring we could say like okay yeah this is like this or growth interval of the graph is too low in comparison to um to how far we've already made it and this this was to the the point um so this is one of the the the reliability fixes that we have in this release to the point where um we did a load test ourselves and i think beyond 50 million it it just it was very noticeable that it slowed down like there was no problem isn't you couldn't import more than 50 million objects in vva but going from zero to 50 million was super fast and going from 50 million to 100 million was all of a sudden really slow and the culprit was actually the the way that we grew the the h w index which was super super easy to visualize like in our monitoring this is now just like or it was like a graph that was just like steps basically how the the index would grow and then you could easily see that just sort of the amount of data that we imported compared to the the growth cycles just didn't make sense so all we had to do is like change this from a linear to an exponential growth uh setup and and now um yeah the growth operations are relatively rare because i think it grows by like 25 um so if you already have 100 million objects imported the next growth operation would go to 125 and then um yeah you wouldn't wouldn't have to grow it again for the next 25 million imports and that was the entire reason for for why imports slow down so it's something something as significant as well vv8 slows down after 50 million you know just simple change in the growth and this is something that in this case we as the engineers could tell basically from the monitoring but all kinds of these these things i think like whenever you have a problem with v8 in the future just look at the metrics and just see like what's what's going on and typically if you have a bit of a feeling for a bit of experience with vba it will be very easy to just pinpoint okay yeah this is this is the reason yeah i love that and i love that the the numbers behind it when you start thinking like uh you know 50 million 100 million you start putting some numbers behind how many vectors can i load and i think um maybe come back to our a n benchmarks i love how that puts some numbers to you know you have a million vectors you want to search through it the vectors have this dimensionality this is how long it takes i think having these numbers out there really helps just understand what's happening and so i think with the wikipedia example it's like uh 280 million uh paragraphs or something like that just kind of thinking about some some things we can do like putting all of wikipedia into wv8 and yeah yeah i think it's a bit bit smaller than that at the paragraph level i think at the sentence level it would probably be in the in the hundreds of million i think it's in the tens of millions but i'm not entirely sure um but yeah but but just yeah this this kind of scale like it's it's it really is big data in a sense i mean that's just i'm really just throwing in buzzwords today like what is big data but yeah that is like millions tens of millions hundreds of million billions and we're we're talking about like at the billing scale we're talking about okay what are the kind of optimizations that we can make to to uh sort of make that less resource intense in the future but we're never talking about like can i achieve it at all because yeah it's it's there you can do it right now yeah amazing so it's the idea of like say putting all of archive into eva and i love the big data and kind of what that unlocks and uh and yeah i'm sure there's a lot of uh so i think kind of going from this topic now i think that was a good coverage of monitoring observability understanding and maybe quickly to clarify it so the h and sw graph you build up as you scale up horizontally you'll split the proximity graph and you'll have separate proximity graphs for each node and so kind of coming back into the approximate nearest neighbor search it's kind of like that stochastic algorithm where you have that kind of approximation so is that a correct understanding quickly before moving on yeah yeah yeah absolutely and it's it's really the important thing here is you can configure it in whatever way you want it there is a disadvantage of splitting out mainly because you're you're spending basically your resources twice if you have to look to traverse two graphs in parallel um so there is probably a point where it doesn't make sense and you don't have to do it but it's it's full control to the user so it's really you can sort of build up in the same sense that that hmsw itself also has hyper parameters where you could and i think our benchmarks page really visualizes that nicely where you could use different build parameters to to sort of get a different different uh yeah performance metrics out of the the graph and i think uh sharding it into smaller segments is just one more of those sort of build parameters in a sense is so is this approximation is this captured in the a n benchmarks does does the a n benchmarks have the scale where you where you do this kind of thing uh it's currently all a single single chart in there so that's that's not captured yet but that's a that's a good point like we could we could add a sort of a very large scale benchmark and and that's definitely something that we have on our roadmap anyway um and we could we could yeah sort of capture that as well like what how does it change if you build it on let's say a single very large machine as opposed to like three or four large machines or something like that so yeah good idea yeah really exciting and maybe just one more thing on the a n benchmark some i'm maybe just like um a little bit of i'm a little curious how you have the benchmarking script and the server script and then the hdf5 files where you have the uh ground truth and how people can uh you know contribute their own data sets to a n benchmarks uh you tell me take me through the setup of that like if i have my wikipedia vectors right and i want to add it to and benchmarks with wv-8 how do i do that yeah yeah uh the the format that you mentioned hdf5 and this is i think hdf5 in itself is basically just like a container format where you can like um yeah put data very similar to like a folder structure on on disk just like in a single file and uh the reason we chose this is uh because of a n benchmarks on the great work that uh eric benhertzen has been doing there already and just all the data sets that are present there are in this format so this is basically the reason why we chose that format um so all you would have to do to run or to contribute your own benchmark is put that data set in that same format and then for the for the contents basically um yeah you need to have the the vectors obviously so all the all the the vectors you want imported and uh what's great about those existing data sets is that they have so similar as you would have like a train and test split when training a model they also have like this this sort of predefined these predefined queries uh just to make sure that everyone that's running that independently is really asking or is really comparing the same thing so it will always be the exact same queries and i think it's typically in those data sets it's something like a 10 000 queries as part of the set so let's say the set has like 10 million or 1 million or 10 million or something like that object and then you create the same 10 000 uh vectors and because it's the same the same vectors that you query all the time that also means that you expect the same results and this is what the ground truth is so the crown truth is basically just using a non-approximate nearest neighbor well not algorithms not really an algorithm anymore but basically just brute force search across the data set um which is which is slow but it's basically only done once for for each query and then for each query we know the exact nearest neighbors which are the ground truths and then all we have to do is basically compare this and this is this is the what the the benchmark script then does so we have a very simple script that basically it spins up vba with specific configuration you can of course you can tune that it's very simple actually i think the the only sort of non-standard configuration in there is we've slightly tweaked the the garbage collector to to be a bit more aggressive in reserving memory because we've sized the machine relatively largely so so we don't basically don't get interrupted by garbage collection cycles um but that's an optimization that everyone can do so there's no no sort of secret magic but that i think's the the only thing um yeah and then the benchmark script basically just takes that hdf5 files extracts the individual vectors and just imports them and and after importing it queries them and for querying it uses the the query vectors and compares the results that vba will give you to those crown truths and then basically the overlap is the recall so if um out of those 100 results only 98 are part of the crown truth list that basically means you're missing two so you'd have 98 recall yeah i think this is also exciting you know how what's the recall looking like uh how fast is it how many vectors can i load into ev8 having this monitoring observability seeing it get uploaded so you're not just like looking at it loading and you see yeah all of this is really bringing it together not putting some numbers behind it i was so excited so so in our podcast of our release we're now going to kind of pivot into a different topic now so uh so let's talk about vector distance functions cosine distance l2 distance dot product what's new with that yeah uh yeah so in uh if you've seen the the benchmarks there's actually i think some data sets are angular distance which is cosine distance and then one is using uh l2 or euclidean distance and that is something that's actually new so this was kind of a silent release before the version that was released with the benchmarks already supported that but it wasn't officially supported yet so you'd not not find anything in our documentation about it and the reason for this was we we had to sort of we we had to figure out how to do this in the apis correctly because in the past um there was like one sort of single number that always controlled all the distances and that's the certainty so whenever you get a result back uh you could display the certainty and the certainty was always guaranteed to be a number between zero and one zero would essentially mean like it's there's there's absolutely no match so it's like in in uh in an angular space you could say it's the opposite vector so if one vector points in one direction that would be the vector pointing in the exact opposite direction um in not not all spaces basically oh yeah that that that's a good point of sort of why we we need something else so basically you have this bounded score between zero and one which works perfectly for for cosine distance because cosine distance yeah it's an angular distance and an angular angle can only have like 360 degrees basically so it's a limited range in a sense but now if we're looking at a euclidean distance for example um if two points like two points can be infinitely far away from one another so this this uh distance basically there's clearly a minimal distance that they can have which is zero if they're identical uh but there's no maximum distance because you could always basically have coordinates that are higher than other coordinates so the distance would increase so what we're noticing is that that general idea of saying you have a distance score between zero and one that kind of breaks with other distances and and uh euclidean distance is just one example you could also have have a dot product for example where it's then the opposite way like dot product uh um basically the the closer they are the higher the dot product but it's also not entirely correct but a bit of an oversimplification but uh here basically you have a higher number if they're if they're more similar so generally what we're noticing is that this idea of just putting it in a number between zero and one that's nice that's that's easy to understand but it's not very flexible with different distance metrics so what we're doing right now in in the 1.14 release is we're introducing an actual field that's called distance and what you get back in that field is just the raw distance so so if you're using a different distance metric and this is this is the really the new feature that you can use different distance metrics um if you're using cosine nothing changes everything is the same you can still use certainty um but if you use a distance metric that simply isn't bounded in that that's a small range then uh you can just use the raw score and you can interpret in whatever way you want if you you could for example come up in your application with a way to normalize that into a specific range that's all fine but basically we as bb-8 don't want to say like yeah we're doing some elaborate calculation here uh where then users asking like okay i'm using dot product why is this number like why doesn't that match the raw dot product that i could uh calculate outside of vba so general idea is just less magic just sort of pass the actual values through and users can interpret it in in any way possible and that was the major reason of why uh we didn't um release the distances uh uh previously yet because yeah we said okay we need to we need to figure out how to do this properly in the apis for like a a proper user experience for for custom uh distance metrics that's yeah that's the the first part of it uh then there's there's something else that that i personally and this is the the engineer in me speaking and that i find super interesting about distances is the most cpu time that we spend in vba is typically on calculating distances so even with these these uh a n indexes such as h and sw it's basically just a smart way to compute fewer distances but in the end how many distances you can compute and how efficiently you can compute those distances really determines the the performance and throughput of the whole the whole vector search engine and um there we have center specific and this is something that we're also releasing now with the new documentation for 1.14 there's a clear overview of what kind of optimizations are in place for for vv8 so to very quickly dive into how this works from from a coding perspective vva is written in golang and that is unfortunately a bit limited with these like really low level um low level optimization so in c plus plus for example you get this this vector intrinsics api that you can use to to do like parallel computations on a single cpu cycle golang doesn't have that so we had to be a bit creative and had to write that in assembly um which always yeah this is this is the moment like where the audience typically goes yeah so we had to to do this in assembly which i think it's it's cool that we have it um but at the same time um this these kind of assembly optimizations that you do you always do them for like one case so you would say that this is for example for dot product on amd 64 cpu architecture for uh let's say i don't know cpus that support the avx2 instruction set which is typically intel cpus for example so um long story short we have that like completely transparent on the documentation and my hope is that maybe someone out there in the community who really likes dealing with this like really low level stuff is like hey look at that combination like for example there's missing an optimization for making this up a or m64 i know how to use that instruction said i'm going to contribute something so that would be my my dream to get a couple of open source contributors to really help us uh figure out like what the the yeah what distance metrics can still are not distance metrics but distance computation functions where they can still be improved and uh yeah make it a a an even faster experience for everyone out there yeah wow the that part of the arm is instruction that's over my head i'm glad to be on your team where you know i have someone who knows that kind of thing because i don't think i would ever figure that out but that is so interesting how you can go low level to optimize the distance calculations and you know speed these kinds of things up i find that whole thing to be so fascinating and maybe we could return a little bit to the first part about the user experience and kind of usually when i think of user interfaces i think of you know these visuals and you know css and that kind of thing but these little these little design decisions like uh certainty or distance and kind of what that relays to you like you know i like using the when you have the near tech search you get the certainty under the under uh underscore additional certainty that that shows you the distance and it's really useful for say earlier we mentioned re-ranking if you want to see the distances from your query the documents and maybe have some extra processing based on that and yeah having that um distance just the just kind of how it uh helps people understand it because maybe i was curious about the original design of certainty because um do you think about uh vector distances in that kind of probabilistic sense like where you have this kind of uh certainty of saying i'm i'm this certain that this vector is similar to this vector kind of in the same way because i think when you have like a the question answering example the certainty is very like uh clear you have a good sense of what that means but with vector distance um how do you think about that kind of like use of certainty or distance just just a little naming and what that tells people about what it's doing yeah yeah yeah and i think that that was exactly the the original idea of of not going with a raw distance because way back sort of before vv8 version 1.0 uh before we before everything was modular and before um yeah the whole uh sentence transformers were a thing um what you would typically uh or what you would do with vva then was you would only use it with the contextionary so basically we were in control of that whole sort of uh model uh uh uh space um and there was there was just one thing and then our general idea was like okay like if if all of this is abstracted away the user does not need a distance they just need something to indicate them yeah like okay the model is somewhat certain that these things are close matches whereas in other cases the model isn't as certain obviously we've come a very long way since then you can still use the contextionary as a sort of simple uh yeah simple model with vba but also there's there's this whole research out there new models sort of popping up every day and you can use any one of them and that makes it a bit more difficult to to claim that something is more or less certain than something else because every model will do that differently so you have sometimes you have models where like everything is in the 0.99 to 1 uncertainty range and then you have another model where like a perfect almost identical result has like a certainty of 70 percent so that kind of highlights that that yeah as we we've opened up vba and we're making more flexible and where we're enabling all those cool data science teams that have their own models um yeah it's really it's very hard to to make this one claim of like yeah this is how certain uh something is um but of course you can use you can still use certainty in the future on on anything that uses cosine distance um but yeah you'll also just get the raw distance to sort of have an un un uh opinionated way of basically just having an objective number and you can still sort of put something on top of it of saying like yeah distance larger than x means certainty y yeah super cool and yeah the the i love the graphql interface for how you access these things too just kind of maybe come back into the whole design of thing but so so back to our release podcast and pivoting topics so um so this now the next chapter is about uh reliability and bug fixes and i'm so i'm so interested to hear also about how the uh the community plays into this i i'm so impressed by you know your ability mars and stefan and everyone's ability to answer these questions that come up on slack i see these questions come up in the slack chat and i'm like well that would be like a day for me to try to figure out but it seems like you know you all can just answer the question quickly and so i'm really curious to hear how that whole ecosystem plays with developing these things yeah it's it's i think it's it's first of all thank you very much this is super great to hear because i also think like our community is our strongest asset in that sense because um yeah we've now crossed a million downloads which is a lot of users and um we've sort of i think uh vva 1.0 has been out for like one and a half years so there's there's just a lot of usage out there and that gives sort of that gives users the guarantee that what they're using is something that's that's sort of that that's battle tested and at the same time every single user using vva is essentially a qa engineer for us because they're really their stress testing is and like no one is as creative as as our community in in trying to find ways to break vba and that is awesome that is exactly that is exactly what we what we want and what we need um so that that's also how uh sort of how we can be so enthusiastic about barb reports because like i think so someone's asked me at some point like ah aren't you would you like three new bug reports this week aren't you sad or something or aren't you unhappy i was like no this is awesome like the bug was already there now it's visible and and if if a brand new piece of software that that is sort of doing something so revolutionary if that's not getting bug reports then i'm convinced that she's not getting enough usage because like um i i don't think vb8 is any better or worse than our competitors with regard to preventing or not having bucks but if it's being used then bugs are being discovered and then they can be be fixed and um yeah huge shout out to to our team that's doing like spending so much time reproducing that together with our community users and really identifying all these these sort of from smaller issues to to larger issues so for me that the worst i think there was a period in in bb8 history that luckily that's that's gone now but there was a period uh where you could get vba to crash in a specific way that it wouldn't be able to recover and that was that is for me that's the worst because what do you do like yeah that's the one thing that you don't want to happen in your database is that it just stops being stops being visible and you basically have to throw your data away and start to start from scratch it's fine if you're evaluating it but that's not fine if you're running in production and that is luckily that has been fixed for for a couple of versions so i'm i'm not aware of any more reports of people getting into this kind of situation which is super super important but there was one uh um sort of that i would still consider a very critical buck that we've now fixed with the the um what not 14 version um this box so uh martin's always joked that this buck like it has many names because it was like it was very simple bug but it resulted in yeah you could say like in in what was perceived as data loss like you would you would query your data but you wouldn't get a proper result or sometimes there was like a a mismatch in in the way that how you queried it like you could retrieve that object uh if you used a filter that matched its id but you couldn't retrieve the object by its id and this is like this is this is the worst for a database this is really it really shows like yeah you've managed to somehow uh corrupt your index and by saying you that doesn't mean that the plane was on the user not at all like they they couldn't do anything about it that was just a bucking media and as with all of these bugs this bug was it was essentially like a one or two line fix that was just really like one edge case that was somehow uh missed and uh i want to plan like a a twitter threat about what is exactly going on with that bug i think that's a bit too detailed for the for the podcast um but yeah it it just makes me super happy that we can we have users finding these things then we get the help from the community to to reproduce it and then it's sort of this this nice interaction back and forth of our engineers and our users to to really identify these these um these bugs and and then really fix them and and of course also add the testing infrastructure to make sure that we never regress on those of those kind of bugs like if it's if a bug is discovered and fixed once like we we never want this bug to to to reappear and we're adding the tests and we're adding like new and creative ways of internally we call them like stress pipelines or chaos pipelines where really we're just trying to to basically trying to simulate users that uh make heavy use of vva like for example they're importing a lot they're querying while importing and then the server crashes every minute or something and then like the the goal of the pipeline is first of all it needs to come back up uh but also when it comes back up it needs to like that the data can't be corrupt like everything every write that was acknowledged to the user needs to be are actually written to to the database and these kind of things um so these these pipeline help us tremendously to to really guarantee sort of yeah this this battle-testedness of bb-8 by sort of automating what we're getting from the community and every release is is better than the last and uh i really think that that 1.14 as like if if i had to point at one point in our timeline would say like okay for whatever reason i was waiting with going to production with vv8 when should i go then like this this is the point right now this is um where we're getting all that feedback from from uh semis uh uh uh sort of uh customers so paying customers and users from the community uh from our own setups that we're testing internally and and we fixed so i i don't know the exact number right now because we're recording this slightly before the actual release is out so the number may still go up but we're somewhere in the range of like 25 plus issues that are fixed in this particular release and some of those are super critical like the one that i just talked about for for the data loss some of them are just some small edge cases where maybe if you set a different uh specific parameter in some sort of filter you would get an error message and then okay you could fix it by just setting something else so it's like a mix of very large and very small issues um but yeah just all of them coming together and all of them being fixed right now that makes me so proud of our team and so proud to to yeah sort of announce vb8 1.14 yes so it's so interesting the flywheel of of community and open source software and like pull requests issue raising and the way that it's all organized that whole thing i think is such an interesting topic so um yeah so i guess is there so yeah 25 issues mentioned and i think it was a great detailing of particular bugs and i imagine the monitoring and observability that probably helps a lot right with um especially with importing and querying while importing as you mentioned yeah hopefully content like the podcast also and just kind of content generally helps educate people and just make the flywheel spin faster with the whole the whole scope of the thing so um so i think that's a good coverage of um reliability and fixes and i think this next topic in the update is kind of related is it with the um api changes and namespace update is yeah yeah yeah in a sense in a sense you could say that this was also a bug but it was more of a design box so um this is this ties very well into which you mentioned before with the different classes so you gave the example of like a tweet and maybe that has a has a link to i don't know post or something so you would have two separate classes and um the concept of having different classes or different collection or different namespaces and databases i think that's that's as old as databases so if you if you spin up a mysql database uh there i think they're called they're called databases if you um spin up elasticsearch they're called index so so this this kind of concept of isolation um is very yeah it's very useful like if you want to do multi-tenancy or if you just want a separate like even if it's the same tenant but if you just want a separate data somehow it's it makes sense to to isolate stuff um and there was one problem in vva which is technically everything is isolated on disk already so so these never as you said before also we built a different h and sw index for each class and not just the agents w index also the the store around it everything was isolated on disk but then there was one point in the api where actually that isolation was missing and um most notably so this was basically for the the um the v1 objects and then id endpoint if you would create it wasn't really a problem because in your payload when creating an object you would specify a class name so basically you would have that isolation which is the class name but now if you deleted something you would just delete object id without specifying the class name so if your id actually existed in multiple classes which should be fine because we're saying these are separate collections so we're saying like yeah that's that's fine like you can you can no need to to keep ids globally unique because these are separate then what should happen because this is this is and this is what i'm saying like it's a design but because i think there is no good answer and way back we had a bug where i think bb-8 would delete the first object that it would find with that id which is this i mean this is horrible because like what does that mean like you you meant to delete one from one collection but it would just delete the first one that i found and then at some point we we fixed this and then fixed is really in in quotes here because it was more like a workaround or saying like okay the delete function will actually delete every object that has that id so it kind of gives you the guarantee that the object with this id is deleted but it was still a mess because like if that id really existed like in three different classes and you wanted to delete just one all of a sudden you would delete like three objects which means two of them you might not even have wanted to to delete so long story short this is actually a very simple change all we're doing is changing that api and by changing um there's no breaking change so all the old apis are still going to work you'll probably see a couple of deprecation messages in the the coins but everything is still still working but we're simply changing this api to include the class name and and that's that's basically it it took me 10 minutes to explain but now you have that that isolation and now basically all of these problems are are gone because anytime you reference an id you also reference the class name with it and now we have that that completely separate name spacing basically so could you tell me a little bit more so um so when you're saying isolation i'm thinking you mean isolation of the different classes so tweets articles but then there's also the vector index and the object index right is there so what goes into the object index i know we talk a lot about the vector index but is there any particular structure like maybe like i've heard of like inverted file is that the correct thing to say yes yeah yeah so i think we can we can split it up even further and could basically say there's three parts there's the vector index which yeah we've talked about quite a bit um then there's the object store which is basically just a key value store so every object has an id and you can retrieve that object by its id you can delete it you can you can update it replace it these kind of things and then we have the inverted index and the inverted index is sort of it's very similar to the object store in the sense that it's also an lsm store to throw in just yet another buzzword here so that's that's the architecture behind it um it goes too far to to explain what that is uh for now i think um so so they're very similar in the sense that they're both lsm stores but the purpose is quite different so the inverted index basically is there for uh for filtering so for for anything that's structured search basically so uh if you would have a a property color and then it would be blue red green and you would set your filter in your search color blue then probably should have used color pink as an example or color uh whatever the name of our vba green and blue is so well green blue is in there yeah just just red was the one should have been pink um so so if you set that uh filter to to something like color blue uh then the inverted index would be used to to narrow the search down basically so in the inverted index that's why it's called inverted you would have an entry not per object but per value so that's the the inversion basically so there would be an entry for blue and then it would point back to all the objects that are that are blue basically that have color blue set and um yeah and these are these are technically separate instances on disk but vba combines them in a very uh yeah in a very intuitive way so so you can set a filter and you can set a vector search and then basically the inverted index would create what we call this allow list which is just sort of a list of objects that may be contained in that search and it would pass it on to the vector search and then a vector search is optimized to sort of work within uh that allow list in this way you have like combined filtering of uh your combined vector search and filtering yeah really interesting that kind of symbolic filtering on the vector search i think is a huge part of it definitely an interesting part um so i kind of wanted to ask so the lsm thing i don't want to get too into it can i understand it as being like a binary like a b tree kind of right some structure like that where you um is that correct like where you it serves it serves the same purpose as a b tree or as a b plus tree but it's actually a slightly different different structure because b plus trees basically have that and now now we're in a big data area again so b plus trees have that problem that the more you import the slower it is to import something because basically the tree grows and grows and grows lsm trees sort of turn that or i think they probably shouldn't be called trees but i think that's the official name um but lsm stores basically do it in a sense that whenever you import something you always import into a fresh segment it's called a segment and then once a segment basically is is flushed to disk so the segment is first held in memory but no data can be lost because parallel to writing into the in memory segment you also write into a right ahead lock but once this memory segment is basically flush to disk then an async process sort of merges that segment with existing segments so um the the the write speed is pretty much constant like doesn't matter how much how how many objects you already have it's constant and this is super important for these like hundred million plus scales because uh way back uh i think in version before version 1.4 or something we actually used a third-party library that was based on a b-plus tree and back then i think we were talking like very different differences so cool to see where we've come like when we're talking about the hundreds of millions and the billions and back then i think we were i don't know i remember like a million was a barrier and like the b plus tree would really especially if we also use the inverted index like a million plus was really the point where the b plus tree sort of slowed down um and that's when we made the change to the ls m tree and uh yeah now we're talking about the hundreds of millions and billions so so can so so does it have a lot of overhead would it be would some users want to turn that part of it off and have no inverted file just the vector index and that kind of thing that's that's a viable option like if you if you i don't think it has massive overhead um but maybe if you so essentially the overhead is the number of properties that you have because for each property like one bucket and a bucket is the the unit within the the inverted index one bucket is basically created for each property so let's say you would have i don't know 100 properties on your object but you're ever only querying two of them or ever only ever using two of them in filters then there's absolutely no need to index those remaining 98 ones so you could absolutely turn them off yeah that's a that's a good point you can in that sense you could turn off the entire inverted index if you just ignored if you skip basically every every property you would lose the ability to filter but yeah that's a that's a viable case if you know you don't use filters during your search like don't need to spend the the time on indexing it don't need to spend the disk based on indexing it yeah so it's absolutely absolutely viable the object store itself you cannot turn off because like whenever you get a vector search like you don't just get an id background you get the whole object back so that that needs to be there because that's that's in my opinion that that's one of the distinguishing factors between an actual database and like a search library you could like a search library would tell you uh the the results are id 17 id 19 and id22 and then you would have to use like a separate database to retrieve whatever that id represents but because vba being a sort of vector database uh you could just get the whole object back amazing thank you so much eddie and i love our podcast hacksaw it always really increases my understanding of webv8 and and the whole database thing really and i you know i really enjoy this and version 1.14 to quickly recap changes in monitoring and observability reliability and bug fixes support for non-cosine distance l2 dot product and also some api namespace changes so listeners i really hope you enjoy this kind of like podcast style of doing a new release and it's something that we're going to hope to keep doing and that and i think it adds a nice kind of uh you know flair conversational flair to it and i hope that also kind of this like uh you know teacher student with eddie and teaching me these things and hopefully i ask questions that you know you also are at that level if you're not quite on the expert level and it clarifies these ideas so so thanks again eddie thank you very much i definitely enjoyed it hope our listeners too ", "type": "Video", "name": "Etienne Dilocker on Weaviate v1.14 Release! - Weaviate Podcast #19", "path": "", "link": "https://www.youtube.com/watch?v=eiQaZIhUS_o", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}