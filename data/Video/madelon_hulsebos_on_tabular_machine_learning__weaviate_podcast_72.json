{"text": "Hey everyone! Thank you so much for watching the 72nd episode of the Weaviate Podcast with Madelon Hulsebos!! Madelon is ... \nhey everyone thank you so much for watching another episode of the weeva podcast I'm super excited to welcome Dr mateline holos one of the world's leading scientists on table representation learning and understanding structure and AI I think this is just one of the most exciting topics I'm so excited to talk to maton thank you so much for joining the podcast wow fantastic Conor thank you so much for the invitation and great great to be here just one correction I'm not a doctor yet oh sorry no no no I'm about to actually hand in my te is NE today so uh no it's almost accurate almost that's awesome yeah I I actually had the same thing where I did I submitted my dissertation and then did a podcast with Bob like right after so awesome glad to be a part of that but so it's successful timing I guess right yeah yeah yeah so so this topic of table representation learning I think this is just so exciting I've been trying to understand the role of structure in Vector search for so long and I think kind of the the question I'd want to kind of set set the stage with is to understand you know tabular data it's always has this Narrative of you know all the world's most of the world's data is in tables and people have this mix of like numeric categorical features that they organize and to just kind of understand like um the intersection of that in embeddings and how you kind of see that um well I think in terms of the intersection of of tables and embeddings I think I think it's always been very confusing to people um as people well I think now most of the research has been focused on you know language embeddings and just you know a very raw raw text embeddings and and then um everyone is of course very keen to adopt such techniques and models and embeddings directly for tabular data but I think what has been often misunderstood is that tabular data isn't as simple as as just text um so there are many intersections though between the two and of course many tables also contain text but as you said there is just a lot of structure in tables you know columns all relate to each other rows relate to each other um but they have also very specific properties uh that we I'm sure will get to in a later stage um but yeah I think it's it's a hard Challenge and interesting challenge to also see how we can tailor all these you know representation learning techniques towards embedding for example numeric data as well and see how they can perhaps complement each other yeah well I I and I I think I didn't mean to limit it just to embeddings I mean kind of this whole idea of machine learning on tables and I know things like you know table tosql is one of these topics that we'll cover in the podcast and so I guess that kind of idea I want to explore more like so embeddings of numeric properties so maybe like you have a patient electronic health record and you'd have like an embedding for the age attribute so is this is this kind of the thinking like you you take like a a table row that would describe you know electronic health record maybe just to stay in that one and instead of maybe translating it to text and sort of putting the text translation of the tabular row into like open AI embeddings you instead have some way of learning representations for tabular patients ah yeah so I think there are quite some flavors to to this task one of them is indeed for tabular machine learning where indeed you have rowwise embeddings and want to perform some kind of classification task on top of that so that's one big field that is now actually coming up with um pre-trained models such as step pfn very interesting interesting to to check that out it was uh coming out last year um and you can just use such embedding models on top of indeed for example healthc care data to classify for example diseases perhaps although it's of course um well relevant to First evaluate that on specific uh use cases and domains um but then there's also another field that is that has been training these models across like Millions of tables to for example uh retrieve embeddings to service the semantics of columns for example to generate metadata so you know if you want to build a data model and um perform for example data validation on all such columns that you know contain age ages for example of patients um it's very relevant to understand how you know different kind of tables relate to each other so what actually I've seen a lot is that different Healthcare Providers they want to integrate different sources of tables um of their data and then they want to integrate this data together but because everyone has different concepts to refer to ages for example and different ways to specify such attributes it's very hard to map a column of Ages in one table to another um so this is a very interesting use cases that can be uh performed if you have you know accurate semantic embeddings of table columns for example yeah I think as I was studying your work and learning about this kind of semantic type detection for columns that was quite new for me to to have this idea of you're looking through a table and you're like what is this column uh talking about right is I'm almost like I'm I'm very like kind of at the crossroads of where to go next in our conversation because we could talk more about this kind of column uh type detection or that idea of like table embeddings like not just individual patient level but searching through the whole the whole table I find that to be so fascinating so yeah maybe if uh we could stay on the type detection we'll come back to the whole table embedding level but this this semantic type detection can you just kind of yeah like the beginning because I imagine this is kind of new for a lot of people yeah so I think one of the the the key top asks in many data management and many data analysis applications is driven by the semantics of columns so indeed you know what do columns really represent what's in that column um in like real world Concepts so for example with the with the example of Ages you want to label that with like standardized semantic types age address and there are like millions of different types that you can think of but then all in a standardized way and this is actually a key task for table comprehension so basically table understanding as you might also see for example analogous to for example images where you have object detection you want to understand you know if there is a you know a cat in an image or something like that you want to have something similar for tables to understand what these tables actually contain but this can also be used for for example data Discovery um if you have accurate embeddings or representations of columns um and you can generate metadata such as semantic column types from that then you can use it also for data Discovery for example or gener recommending data visualizations for specific tables um given that the tables contain certain semantic types yeah I think the timing on that is amazing with snowflake acquiring Ponder and I listened to Doris Lee things like Stanford seminar this like kind of uh data Discovery like kind of uh recommendations on analyses and visualizations of your data and I guess I'm I'm so just so curious like I I've seen your work on git tables where you've extracted millions of csvs from GitHub very cool I love the data collection is always awesome but so so you have all these tables and now you're now you're trying to say I know like maybe two three out of the five columns try to use that in the values to infer the type of the fourth one maybe help me further understand just kind of like the application of the type detection of the column and sort of the the context it sits in um so ideally we want to train machine learning models over all these tables to perform for example semantic type detection um labeling table columns with semantic types and we want to do that also for new and unseen tables so that's basically the idea and we can do that in of course very different ways you can even just look at the header so for example the column name um but the the values in these columns are very you know they provide very important signal to what these columns are about of course so typically we try to embed full columns um to predict the semantic type of it yeah I'm I'm so maybe looking at the distribution of the values and so yeah with that kind of thinking I'm very curious like how language models and sort of you know chaining maybe you you have like how you can call the pandas functions like DF do describe is kind of like a common function that like gives you all these views of your data and pandas how have kind of the language models help with that interpreting what a column is in the characteristics of call well I think that's a that's a very interesting one and basically where where I myself started off with um was with word embedding so assuming that many tables actually contain textual data and this is a severe limitation actually of this approach um what we did back then is just trying to map every cell value in a column to I think back then we had like glove embed things um so we basically try to to aggregate all kinds of word factors extracted from from column values now I think there is you know with representation learning and um this has been extended to tables as well with table representation learning we see that typically what what what is well most common to do is serialize entire column columns like cell by cell into a sequence and then provide it to language models basically and there are kinds of like adaptations of the me uh attention mechanism to also learn for example relations across different rows across different columns so there are many like tailored approaches to adapt such uh language models to tables as well and this is super cool this has enabled actually very interesting applications for you know Beyond table comprehension so beyond semantic type detection this has enabled for example question answering fact verification over tables and it's really really super cool to see that um but of course there are also limitations to such approaches yeah I think it would be a really nice transition to asking more about your work on that kind of uh table based question answering I think we've seen a lot of uh kind of like in the retrieval augmented generation tooling World we've seen a lot of text tosql kind of things and yeah if you could just continue on how you see that table based question answering uh application yeah I think it's so one of the driving forces of uh git tables was actually that most of these models for example um uh pre-trained table models for question answering they have been trained on tables from the web um and assuming certain structures of tables that were slightly shortsighted so there's you know so many specifics to tables that uh you cannot just you know assume these models to to uh work with out of the box um but for question answering what what I've seen is that um when you try to serialize these um these columns and rows one thing that is typically missed is that there is you know for example properties such as row orders insignificance and column order insignificance about in databases so in relational tables and what what is interesting about these these current pre-trained Table models for question answering is that they can be very sensitive to such characteristics so one of the the driving forces of for for example get tables but also um more analysis uh work that we've been doing with for example Observatory um is to try to figure out how well these table embedding models generalize to different applications and different data bases and I think one of the shortcomings now is that well we have many steps to make still when it comes to scalability so these models have been trained on well relatively smaller scale um data sets of tables now very recently a huge table uh collection has been introduced as well by approximate Labs very cool to to see where that is going um this data set is called tlib and then I hope that these models will also become more robust for example to uh for example small semantic perturbations in tables so what we've seen with Observatory is that which is an analysis tool for um trying to understand what table embeddings how robust they are basically um one of the things we found there is that if you make very small changes to for example the question you ask um or the table that you ask a question on even though the semantic so the meaning of the question remains the same um they don't really capture that well and I assume that when we skill such models up that you know as with large language models these models will also become more robust to such semantic variations for example I think with me I'm trying to understand um like the the the language model kind of uses like uh pandas or SQL apis to kind of answer symbolic questions like it could take in the schema of the table and then it can format like you know select from where like the the CLA and so I'm trying to understand like how you would have uh like instead passing the table directly to a machine learning model that would output some kind of uh answer you you mean if if that is what we should be doing yeah I guess um sorry if this is isn't super bow form but I'm trying to understand that I guess for me it's like um these tabular machine learning models I guess they take as they take as input a table right or maybe a a a row and and then produce the answer based on you know by processing the table with some kind of like maybe columnwise attention and this kind of thing and so I'm just really curious how that differs from say uh just interfacing my large language model with like a pandas or SQL API where it can um if it if it's doing symbolic a I guess like if it's doing symbolic aggregation like what's the average age of country music singers I I say that a lot now I guess but like then you know it just has to like select from the singer's table where genre equals country music right so I guess that that kind of yeah indeed so these Pro this this problem of question answering uh specifically has been approached from two directions indeed one mapping natural language questions to SQL and then executing that on a given table where of course the table schema is integrated into that uh because you need to understand or need to map the like SQL attributes to a to a given column I think that's actually a very very good approach to take and it's I think a very logical one also given the sequence to sequence uh modeling approaches that we that we currently have um and I think we'll we'll see what I I think it's a it's a very interesting approach um to take but it's it's of course also limited I think um with what applications you can serve with that um but I think the the other approach of I think they they kind of relate to each other uh as well a lot um but for example for fact verification where you want to um give a fact or check a a given fact against a certain table then we might need different embedding and different approaches um to this problem um but I think text to SQL um I think it it works well for relatively simple basic cases at the moment and I'm really keen on seeing how well it works if our queries our questions become way more complex and very recently there's a new Benchmark introduced that actually tests text to SQL models for way more complicated schemas but also more complicated questions because so far we've been only working with with very small questions on a single table and I think as soon as you want to you know ask more complicated questions on your data then it will become much harder to generate relevance equel yeah I think that's so inter I I've studied a little bit of like the spider data set for text tosql and I I I have a bit of experience with this because I've been working on the uh text to graphql gorilla with we v8's graphql API and so yeah this this thinking of like these complex schemas like with we8 we kind of have like a collections like abstraction where you have like a uh you know like student teacher book these are like separate classes and so it's like you'd only retrieve kind of one schema at a time to format the query for one schema hopefully that makes sense but like if you're if if you're like joining I can imagine like complex join is where this problem gets really difficult and I actually think that would be a really nice transition into the embeddings of tables as a whole because I imagine there's maybe something to the Joint kind of with what you were saying earlier with um I have this electronic health record where I have patients and I have age is one of my column values maybe want to try to join this to some other table but I'm not sure what which table right so I need to kind of like search through tables to maybe do that kind of joins yeah I think especially for for such cases you really need to embed the underlying data as well you just mapping column names to um natural questions and like generate SQL queries from that I think won't work um if you want to for example integrate data from very different sources um so I'm I think there's actually a later a newer Benchmark called bird and birds really provides more complicated queries that all these models really really uh find challenging so I think it's really interesting to see that such applications will will you know Empower us to ask natural language questions over our data but there are definitely many many challenges ahead also when it comes to for example um the input limit um if you want to embed tables that's a that's a sever Elation um because of the amount of context that you can provide um if you would then need to scale up um across different different tables this becomes already quite challenging yeah I think that there there's so much that I want to keep I I I guess I really like this kind of like when I thought back about like electronic health records and embedding patient rows I really like that kind of rag where you would retrieve similar patients and then maybe have that kind of you know the supplement in the inputting input that comes from that yeah I guess um yeah I kind of want to stay more on these um complex questions this text to SQL thing and I'm very curious about this kind of like um uh like query execution planning like I I don't know too much about how SQL does this but I I know that there's like a lot of underlying mechanics to like how to optimally uh do a query do you think about this kind of thing as well and how um machine learning could help yes yes that's a that's a great question I have been thinking about this a lot um but I haven't been working on this and to be honest I think no one really has so I but there are so many opportunities I think when it comes to query optimization as well but this is just you know gas work at the moment and needs more experimentation but I think there are very interesting opportunities when it comes to for example cashing or uh you know as you said um yeah I think that's an interesting um direction to explore further super cool so uh kind of pivoting topics a little bit I kind of want to talk about um the kind of I'm very curious like what you think about graph neural networks because I've heard you talk about like columnwise attention and these kind of particular architectures for tables and relations and I think you know graph networks it's like always trying to figure out what what it's going to be uh what that's going to become I have seen some interesting approaches um that indeed use graph neural networks to try to model the relationships and tables and I think they are very success they can be successful but I have I I must admit that I'm personally not a big fan of of GRA networks themselves um I don't know why it's just something that you know I don't know it hasn't really taken off so far I think um but definitely there are different ways to also you know perceive tables and you can also see them as you know they can be well represented by crafts as well so I think there's definitely value in that um but I haven't looked into this myself yeah I I guess it's it almost is like I guess with the graph Network you need to have like the whole graph is input and I always thought that was kind of like it makes the inference kind of uh challenging and so I guess kind of another thing I'm curious about is your current sentiment on on like XG boost and like especially in kind of like search and recommendation that like having a symbolic features about your customers to then like rerank your search results with an XG boost model is quite a popular thing and so yeah generally I'd love to just get your take on EX I think it it was super interesting last year um we organized this Workshop table representation learning for the first time at Nubs and by then I've been mostly focusing on data management applications where we were more interested in the semantics of data in generating metadata with for example semantic column types then when we organized this Workshop um people really related this to HG boost directly anything on tables people think like no but actually you know outperforms anything and I was like oh but this is a different task you know that's rwise inference and not necessarily um you know across you know generating General metadata from from different tables and I think now we see that these fields actually approach each other whereas for example actually boost is typically trained on one given table but now as we see also um more representation learning being effective for learning relationships across different tables for tabular like rowwise inference like actually boost and I think we see now more and more approaches that try to try to embed rows and see if that works for such cases as well and I think they have been shown really competitive for um against XG boost and other tree based um classifiers so so that is super interesting to to see and come together because before all these um like more representation learning approaches they also learned representations from one table and now they start to explore trying to learn representations and like transfer semantics from other tables to do this kind of inference as well and I think that's a super interesting area to to see being explored yeah I think well I'm I guess it's like this idea of merging tables and and I guess generally like this generalization of uh symbolic that that would kind of be my uh why I don't actually prescribe people to train an XG boost to rerank their search results is because the generalization probably won't be as good as if you uh translate it to text and use like a cross encoder that has a text is kind of my perspective is that because when you have the symbolic things you're like really like uh the machine learning model is like really fitting to these like high frequency patterns I think compared to kind of text translations where you have these like Rich embeddings that I I think generalized better U that yeah that's kind of how I see that whole like generalization of tabular models but I I definitely am not an expert on it like just from your perspective because you've been uh of course coming from from a different perspective um more on retrieval and um reranking so how do how do for example customers as weate use EXO to to do reranking I guess it with recommendation it's like you have like age gender maybe purchase history these kind of maybe tags and like I did some kind of like customer turn analysis and maybe I have a tag on you based on that other Mo what that other model said about you and so I have all these features that I then use to rerank like uh the shirts I'm going to show you from this your home feed or your search query so that that's kind of how I see it mostly but I can definitely I'm I'm definitely starting to understand this better from listening to you talk about it is this idea of like maybe I have a data set of like I have like my CRM data set and I you know I might have come up with some columns to describe my customers with that someone else from the company has different columns that they've been using right and now we're going to try to merge these tables and it's going to be like is this does this column agree with this is this actually the same column kind of I guess yeah I think what is interesting about the approach of representation learning for tab ml across uh across different tables is that you can actually learn General patterns I I can imagine that you know different companies although their data might be formatted very differently the same patterns might hold and be relevant in in other companies for example in health it it doesn't really matter how how the data is specified if you can embed this and and preserve the generic factors hidden in these for example rows that might represent patients or customers I think it can transfer such you know some patterns from one say context to another and I think that's that's an interesting thing that actually boost I I think will not be able to do it it just doesn't have that you know high capacity yeah that's really the well I think maybe it would be really nice to kind of like um come into so this idea of transferring representations from one table to the other I maybe like to have some examples of visualizing it like I imagine maybe I go to Archive and I get out like all of the experimental tables or I know with your GitHub experiment how you got millions of tables from GitHub could we maybe have like some examples of like I guess just like a transferring of table to table more so yeah I'm I'm thinking of um beyond for example the data integration um problem um thinking of well what we what we might see for example in in certain certain health health data dat bases Healthcare databases you might find specific patterns relating certain ages with certain diseases um and I think such such General patterns might transfer from you know from one city to another city um from one country maybe even to another country uh another I think good example in in that sense is you have all these like open government data portals and there are like millions of T well not Millions but like thousands of tables on there um and I think there are just general patterns to extract from these tables for example um relating GDP with I don't know other economic factors and and try to understand the world better from that and I think if we would we could use such if we could embed that and like retrieve search data for example using we8 then we could use you know we could augment machine learning use cases in companies for example that want to use that econom economic data for I don't know in inference on their very specific company uh goals yeah thank you so much for that that really helping me understand I I've seen this data set called like Wiki tables that was like also like extracting any I'm really I think I'm definitely like uh my understanding of the whole thing is growing as we've been talking about that all these kind of tables and trying to merge them all together into having this view of the world is so interesting and yeah I guess for me I've always kind of been thinking about like it's almost like with Vector databases and knowledge graphs graph databases I think about this a lot is like um what's the best way to kind of represent a fact like can you just have like a natural language sentence that's like a fact or do you need like a you know like a a knowledge graph tupal or like a tabular data entry so how do you kind of think about just like that idea of um you know the the I guess the other approach of instead of kind of merging tables into a big big table I kind of like translate them into facts and I try to see like if the facts disagree with each other kind of in in natural language for like embedding based retrieval yeah that's a that's an interesting question I think so I've always been very driven by observing what data is around and how data is stored so one of my observations was that most data is collected and stored consumed through tables in relational databases for example or or perhaps less structured in CSV files so I always took that perspective and see that that tables typically drive very high value use cases from ter prediction to Health Care Solutions and so on so I've always been very you know fond of tables because of because of that but yeah you could you could also um present facts in in different ways but I think the power of tables is that they are so structured and they provide all these very you know machine readable interfaces to it um and I think that makes it a very suitable a suitable format um to present data and facts in particular in um sometimes you know tabular formats have been taken a bit more flexibly so for example Wikipedia now now we need to extract tables from Wikipedia and try to restructure it in a very structured format um I think if we would all present it in you know very basic tables I think that would help a lot um and could also yeah I think I think tables are just super rich also because you can complement them with metadata um you know they they come with SQL for example um as an interface to this data and you can learn for example patterns across that how other people for example query specific tables you can learn all kinds of signals from that um of course similar yeah similar principles or ideas hold to to less structured data for example just text um but I've been just coming from okay tables are really everywhere in databases so they're you know they they take up the majority of the data landscape the organizational data landscape and they just serve so many high value use cases across data analysis pipelines so that's actually why I've been focusing on on tables specifically and structur data um but yeah there are different ways to to presenting facts and analyzing that yeah yeah yeah I love that I mean yeah like I guess uh like looking at like uh if you're in the NBA and it's like who's the leading rebounder I like like stats you'll see it in like the tables and I love that it's a good way of presenting data I think that really Nails it it makes me qu I'm very curious about like this um you know now the language models can see right with like the gbt 4V what do you think about that kind of like that that they can they can see so you might want like visually give them a table language models might want to pass visualizations of tables to each other or is that like a native language but but generally like I guess this concept of like being able to see data visualization yeah I think that's a super interesting idea um and I've been discussing this with with someone this week actually that you know when people look at at tables they kind of grasp certain patterns to to understand it and I definitely think that the visual representation of a table just as an image of it yeah I'm I'm I'm super curious to see how this you know how this can help also for for the you know for embedding tables and and you know getting insights from them uh I haven't seen much of the results I think just one paper on this where I was like oh that's that's interesting but um it's just in very early stages to see to see how it's used I think so far um researchers have been evaluating the the capabilities and the challenges of using large language models just without the visual um U medium but and they've been trying to understand how you should best input a table into for example chat GPT um how sensitive it is for example when you um ask a certain question and then swap different rows in a table so Tables by by default by by their nature are well from a relational perspective um the order of the rows is insignificant so that doesn't carry meaning but some of these large language models can be very sensitive to that just as they can be sensitive to very small semantic changes in for example column name just the the same semantics but just a different word for example can have actually quite some impact so I think that that opens up new opportunities for for research and seeing how you know how we can integrate properties of relational tables um into such models and I think the the multimodality will at some point also extend um to Stables but I'm I'm very keen to see where this more like image P perspective um and the the representation of a table from an image where that will lead lead to I'm very curious to see to see that yeah I'm also like um I guess another question I have is how the the structured like in in kind of like the vector search world there's this one idea that you have like an image of a dog and then you have metadata about the image like you know maybe the type of dog the age of it or color and then You' maybe like uh embed the features as well and maybe average these embeddings so you have some embedding of like Golden Retriever and then you average that with the image embedding for the dog um do you think that kind of integration of like maybe more unstructured embeddings with the structured components do you think that that you know that that can add to the quality of the embedding oh for sure I think that's such an interesting comment actually um with this latest project called Observatory we do some analysis that relate to that so the notion of you know preserving relations between objects in the embedding space and I think an analogy into the relational data model is functional dependencies so given two columns in a in a table uh we might perceive certain relationships between these columns so for example uh the capital if you have a column with capitals and a column with country then you would well assuming uh you would always see the same values for the same country so for example Amsterdam is the capital of the Netherlands you wouldn't expect other relations than that and we've been analyzing um table embeddings to see and uh particularly comum embeddings to see if these embeddings currently preserve such relationship as well but so far we haven't seen that so and I think there is also from um the knowledge graph embedding space uh so you have for example trans e uh which is a um an approach for preserving such relationships across entities in knowledge graphs and I think this would perfectly extend also to the notional functional dependencies um to embed values in in tables and then we can use such embeddings if once they preserve these functional dependencies so these relationships between between columns then we can also better use that for example for data imputation um um which then serves perhaps Downstream a machine learning model so I think there is definitely interesting interactions between these two yeah between these fields and I think it's an interesting suggestion actually perhaps more generally um to see how certain concepts of of tables how that can be preserved or how we can find such relations between certain semantic Concepts in the embedding space even Beyond functional dependencies I think that's an yeah that's an interesting um approach and we should definitely see if we can preserve such relationships semantically yeah I think that's so powerful I I guess like um that this this kind of yeah like you mentioned trans Z that kind of like uh embedding of a particular kind of relationship like I guess right now it's like semantic similarity is just like the one size fits all for all but like instead you if you had some other relationship and then uh if you're within this radius that means that you kind of uh you know might also have this relationship and then we store the structure of that yeah it's also interesting yeah I think and um um one thing that I was interested about from from we's perspective is but this is perhaps a little bit off topic but I was just reminded of this but from a retrieval perspective but um what kind of embeddings do you do you currently see so have you seen at we8 you know do you have customers or I don't know users um that actually use or retrieve information and embeddings of tables um I haven't seen it personally oh well actually I do well I remember a conversation like I remember earlier there is a bit of like um how do you evangelize Vector search with the uh SQL people and and that was kind of an idea is like um I guess back then it it was like you would maybe have like an auto encoder and I mean this was like before the zero shop mod I think now the the current prescription would be could you translate your uh your table to text right to put it into these embedding models but I haven't personally seen too much of that that's why I just find this conversation to be so kind of like eye openening to me is I I had never thought before reading your paper on G tables and I had never really thought about this idea of searching through multiple tables or having you know like a million tables it's I think it's quite creative to be thinking like that and yes I would say it's quite novel to search uh to to use like vector search search in tabular structured data I think yeah so one I think Avenue interesting Avenue is now with retrieval augmented uh generation that if you I can assume if you have very accurate embeddings of I don't know maybe table rows or columns or maybe even full tables just one centic vector of a of a table I can imagine that if you would then you know this would help out with with r as well uh from a WEA perspective I can imagine that so much data is eventually stored in tables that is relevant to provide as context to llms I can imagine that that soon people will start to embed their tables as well and I'm just super curious to see how you know how they will retrieve like construct their embeddings and um Keen to see that unfold yeah I I think maybe two things I see on that is the first thing is um with weeva you define a schema where you define which property you're going to vectorize so say I'm vectorizing content but then I also have um I I don't know like metad data about the page like a say I'm I'm vectorizing a the podcast clip and then I also have like what number podcast it is who the speaker is maybe how long the podcast is and then I can I can search with the embedding of just the content and then pass in the symbolic data around the object into then the language model and then one other ID I see from llama index is this kind of recursive retrieval and I think you might find this quite interesting this is where you would uh search through Wikipedia Pages like based on their title and then whichever one is the top match that one might have a a table inside of it and so so like it's like a two-level query where first you're searching through the titles of Wikipedia pages that took me to billionaires let's say and then within billionaires there is a table that was like you know age and exactly how much money they have and then you would do the symbolic query within the linked uh table super cool interesting super cool uh so maybe wrapping up the podcast I I want to ask you kind of like um you know this kind of like what's next question like what kind of future directions are really exciting you yeah I think on that um first I'm just so focused on finishing this PhD and you know starting starting uh starting up new things one one particular direction that interested in is going from you know Insight retrieval from questions to generating questions from tables so basically table to to question I would say um because now um most like data teams let's say they they rely on domain experts to form you know formulate their qu their questions fortunately we can now do that with natural language and then translate that to SQL so that already makes it much easier for domain experts to access relevant data but one thing that I'm interested in is see if we can somehow learn what relevance questions are for a given table to ask so that we can kind of enrich um the expertise um without needing the the query let's say because you need yeah I think there's just I think there there is this kind of stat that says that we only use 1% of the data that we have in in data warehouses or maybe it's 5% I don't know specifically U but we just use really little data and I think if we would be able to learn access patterns you know what kind of questions people ask on certain tables I think we could then kind of try to move towards more recommendation system for insights saying for a given database like hey we see that I don't know the number of of diseases for example in this area has gone up and then I think that could be really powerful so that's something that I'm I'm really eager on to move towards I I love that I think that's so inspiring that kind of offline question Discovery and especially with this perspective on tables and not just kind of like the long tail of documents that's all just so amazing I I also really inspired by that direction going forward of a more offline kind of processing of your data and and that kind of uh like self-directed research it's really amazing matalon thank you so much oh sorry yeah no yeah I'm I'm with you on the excitement and I'm I'm just also very excited to see you know startups now ramp up in this space um more research you know it's just increasing in in embedding uh tables properly and applications of that and you know as we touched on for example internal database applications for example query plan execution optimization I think there's also so much space to F to still explore on the application side um so that's something that I'm very keen on as well but yeah it's been really amazing to talk to you um about this topic I'm really excited matalon thank you so much for joining the podcast I've learned so much from this conversation I'm sure our listeners as well as well and congratulations so much on the on the PHD it's super well deserved so many amazing Publications and this whole table representation learning it's just super interesting thanks so much Conor thanks for having me was really awesome ", "type": "Video", "name": "madelon_hulsebos_on_tabular_machine_learning__weaviate_podcast_72", "path": "", "link": "https://www.youtube.com/watch?v=BMqxJpC4-Co", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}