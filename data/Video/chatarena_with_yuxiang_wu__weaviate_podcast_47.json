{"text": "Hey everyone, thank you so much for watching the Weaviate podcast! I am so excited about this episode! ChatArena is a software ... \nhey everyone thank you so much for checking out the weba podcast I'm super excited about our latest guests we have yushang Wu a PhD student at UCL who's formerly been interned at the Ellen Institute meta Ai and yushing has produced one of the most interesting libraries around this kind of future of large language models where they talk to each other and I think this is such an interesting topic so firstly you Shane thank you so much for joining the podcast thank you Conan thank you for having me here awesome so this chat Arena that's the big uh the title of the podcast and the thumbnail uh so can you dive into the origin story and what it's about yeah so Channel started as a small research tool that I built over a weekend and I was struck by this idea of having multiple chat gpts to talk to each other because that would be really cool if say each chat GPT would play a different role right and we may be able to create a really interesting conversations so normally how we would do that is that well we could open two Chachi PT like web pages one on the left one on the right and we copy and paste between their like responses right that's just going to be like really tedious work so I would say when the AP child gbt API came out would say wait there is something that's really good really cool that we can do here right like so and then I'll just like build this like a small demo uh over the weekend and I show it to researchers around me and they're very excited well with this new tool so we quickly expand this project into a more well-designed and user-friendly package for developing all sorts of multi-aging language games so now it's supporting not just chat gbt but all a lot of like a large language model apis and also we could Define or create different in language game environments with this package so roughly a month ago we released this through publicly and since then we've been released uh receiving lots of feedbacks from our researchers around developers and Industrial partners and this package is still like Fast evolving and we're really excited with like what we can build upon this yeah and I think maybe before we dive into the technical detail and the nuances a little more just setting the stage of um you know like chat like kind of what you and I hope to achieve right now is that um you know in conversation we can explore some new knowledge and um so maybe if we could talk a bit about how this works you you sort of would prompt one language model to say be Lex Friedman and another one to be Sam Altman and then they talk to each other playing these roles is is that kind of the general setup of we have like roles whether you're impersonating a person yeah yeah indeed uh so you could start with say setting the c or this stage for the players by specifying what we call environment description or Global prompt this description would describe the environment or the scenario that these players will be acting in so for example if you want to set up a like a podcast between like scripman and Sam Altman you say well you are now participating in a podcast and what is generally in a podcast is that there is a interviewer or the host and the guest and the host is next Fruitland the guest is Sam Altman and you may start with introducing yourself so this is kind of a description of the scenario and then for each of the players or agents in this environment you give their specific prompts so you give you tell one of the agents or you are next you'll be acting as next frittman and this is something about next treatment so you may give it a bio of extreme learning his interests or his like previous podcasts topics and then for another agent you give a Sam Altman his bio and his latest updates for example right so and then this would said that we just set the scene and then we just let it run so all you need to do is just tell these models scenario they are in and what they should be acting as and the rest would be our child Arena handles all the underlying like mechanisms say prompting and querying cha GPT handling all the communication managing all the status like the game state for example so those things can be similar seamlessly handled so that's the kind of a general use case obviously yeah I'm so excited to dive into the what makes this a game a bit more but first I want to say a little more about maybe we talk a bit more about the retrieval augmented prompting I think our weeviate listeners would be very curious about like what a weeviate system design looks like and so kind of as a fun project I've been doing is I take these podcasts and I transcribe them with whisper and I put them into Eva and so I'm curious if you think like um like say we have one uh database class that contains all podcast transcriptions and it has a symbolic filter for speaker maybe also a symbolic filter for which particular podcast it's sampled from and so you could have that uh like a symbolic wear filter on top of vector search for when you're retrieving from Connor shorten to prompt the language model to say like you said things like this in the past what do you think about that kind of system design for how you tell how you really make the language model like you know to take my ideas so to say yeah well that's actually a very interesting question like having this kind of long-term memory right like as you said that these since that you have like past podcast episodes are like like it's clearly going to exceed the GPT even GPT Force like memory length right so maybe one way it should do it right is you having at the player level you could give it this database as you uh as you mentioned and then at the underlying when it's say in the process of the podcast and it dilemma the queries that database and say well for example when we are talking about say AI safety for example I'm sure that lack street but no like your your podcast will have lots of mention to that and then you just dynamically and advertly search that database and find out what your take what what's your stance in this topic in general and then that could summarize it having some kind of like a summarization model to summarize kind of your take and then that will feedback to your agent or players so I think there is a lot we provide a lot of flexibility on the player side that you could incorporate very complex mechanism into the player so it's not just like say uh just calling open AI chat gbt apis and in fact you could Define and create any like kind of program and as long as that just satisfy the interface and that underlying program can handle all your like long histories and and an oil past experience so I feel that that's a one way to implement what you uh what you have in mind yeah that kind of chat history thing I'm it's so interesting to see what's happening with that even just with the the chat gbt interface as it is um One More Concept I'm curious your opinions are uh we're kind of trying to Pioneer this term generative feedback loops that roughly describes the idea of generally you retrieve from a database to prompt inject into the large language model and then you save that generated result back in the database and you know that continues on and on and things like what we're talking about where their agents are talking to each other because I can imagine like um like from our conversation now I expect to leave with a new stance on multi-agent large language model chat games so it's like when they have these conversations right they should save their their stances and kind of but so then you need to like update the stances is it is it clear this kind of concept like that like so yeah what do you think about that kind of like the evolution of is you start off with your um you know Sam Altman the beginning of all everything he said on the free podcast ever and then and then simulate thousands of conversations and now you kind of develop like this half artificial half real or whatever the just composition of the takes yeah yeah I think that's actually really exciting Direction indeed like having this feedback loop and then modify its like memory right like modified its kind of status and this keep evolving right this kind of like self so I think this is actually really one of the strength of having Ai and AI to interact with each other is that they could simulate first of all you needed this environment for them to to interact in right and then once you have it like you could have simulated loads of loads of like interactions between them and then they could keep evolving and improving their strategy and up updating their history and in those same in another way it's updating their policy as well so in a reinforcement learning sense right this is improving their policies kind of like alphago in a sense that by self-playing that it improve it's like it's go playing a strategy so I guess in the same way that you could do it in language games as well and in the same way as you said like there are different localisms to in to incorporate this kind of uh histories or experience from the past maybe compressing them and then into into some sort of vectors and then that will help improving future of future strategies yeah well I think the all the self-improvement it's it's kind of like teacher student knowledge distillation and or like just that whole idea of kind of yeah reinforce like uh two agents talk to each other maybe a third one judges it I think actually before I even pick your brain more about how the policy improves and whether there's continual learning in this kind of system can we maybe set the stage for the the game like the moderated uh system chat I think it's called could you explain like how the game is set up yeah so in that environment I think this is one of the most novel part of chat arena is that it provides a LOM as part of the environment so maybe I could record back to what you were saying in the kind of like improving sense like self-improvement kind of sense is that you may have one moderator in the environment that's going to achieve give you feedbacks when you are interacting when you're playing in this game right and then with that feedback and by the way this feedback is generated by another larger probably larger LOM and and in that sense you may improve your strategy but this is just only one way to use moderator conversation so but in general this is just like this is a very general purpose environment that the Enviro the game transition is no longer maintained by some fixed program that determines the program or some heuristics but rather it's by a hybrid system with a llm inside so with this the strength of this com this combination is that you could Define very like flexible and open-ended environments so say for example like uh AI dungeon for example like it could have a dungeon master so having an llm to play as a dungeon master and the game transition right is determined by this like gpt48 model that has really good understanding of the game dynamics of pungent and that would allow you to to like create games that's not possible before and this is one use case and I could imagine like there's lots of use cases that you could use this for for so I guess we have to be involved I I think I'm limited in terms of the imagination to be honest so that's why we release it and and we asked like we really welcome like our users to create their own and be imaginative and share their like kind of games that they're creating it it I I think I see two things here with there's kind of like the open-endedness discussion generally where I think uh there's like that work from Jeff Clune Kenneth Stanley and their teams around um you know like there was the poet algorithm which is like bipedal walking agents with uh different environment terrains and you're trying to like have an open-ended exploration of the terrains you walk on and then they did this with Minecraft where it's like you know just go try to explore it it so I think we could come back to that kind of like connection to the expiration part of reinforce and learning but um this kind of concept of like language only games I'm very captivated by this and what you're saying like with the um sort of like the AI dungeon thing where the moderator like proposes the transitions in the game but I kind of want to if we could just stay a little more on this kind of like we're having a podcast or like there was this like there's like this Sports Talk Show where there's like four guys there were men and women and then uh in the grid and they kind of like each have 30 seconds to like make as many points as they can about like the Celtics game or something and they and they like score their points is that kind of like like so you know it's like my agent your agent Sam Altman's agent and you know let's say Elias tutskivers agent and we each get like you know three paragraphs to make points about multi-agent RL is that like the kind of game that might lead to like some intelligent artifacts sort of being produced by it I think that's totally possible indeed like uh but I guess that's having agents so moderator is a special kind of agent that's sitting on top of all the players so I guess one difference that we want to emphasize with this moderative conversation is that moderator is kind of like a super agent it's kind of like the root user in Linux that it could control the on like the game Dynamics and it could do things that like normally normal players can't for example it could terminate again it could choose who to speak next or it may even kick out like one of the players like not behaving properly right likes you may imagine that the game that you were talking about like maybe there is this kind of this moderator or the host of that show for example that he has the privilege actually or she has that privilege to uh to to do like certain things that's fascinating and I think there's kind of two angles I'd like to stay on this moderator concept the first of which is scientific literature scientific reviewing and the peer review process I'm sure as a PhD student an awesome time with that but like um as we see like oh obviously like with archive it's already kind of giving us an example of what this looks like with humans who can just upload blogs dressed up as research papers and then pretty soon probably the language models will be able to do this like just generate things so we probably need some kind of review system in place and I I don't know if it could just be like a like because I don't think it can just be like a classifier trained on you know iclr versus anything else so do you think maybe this system could be like a solution to say scientific uh peer review well I think it could be but I would be very cautious if like we are using so I would insist that like like I don't want my papers to determine buy a gpt4 because that could it's because you may be able to if you know that like it's gpt4 anything that could be it could be easily a hacked or somewhere like but I think on the up on on the on the like positive side I think it could at least alleviate a lot of like reviewing burdens but um because like me also being like a reviewer for like lots of conferences and like I I feel that pain too like I'm sure that's the area chair or PCS right they will have like even more loads on them to determine that so having this sort of systems maybe one like maybe maybe helpful to to reviewing systems and I could imagine this is not just be useful for reviewing but say ma like marking right like I do some like teaching assistant like remarks say hundreds of like assignments and it could help it could be helpful to just to to do some sort of things um I guess one way that chat Arena could be useful in say reviewing systems could be that you could create like different reviewers from different backgrounds and having them to have like abundant discussion so you know how difficult to discuss yeah right right so but if you could have say like AIS but like maybe moderate like of course you have to moderate them like but then you have moderate a conversation between these AI reviews you could have really good conversations and discussions of that of a submission and then you may actually come up with a more like a more balanced and a more comprehensive review if that makes sense no yeah that I love that uh sorry I love that perspective it's like um you know like instead of it the the like in the review process they'll like nitpick some subtle detail or maybe their opinion about it and maybe the chat arena is saying you know you argue for the paper you are you against it based on this reason and then they go at it and then the moderator says reject except kind of I think yeah that kind of thing I think is very fascinating and then so then the other thing you said about the the Linux example is another thing I think this will be extremely impactful for is kind of like the code like the code application domain where you know you're making pull requests and there's a the moderator is sort of like the uh looking at the architecture the the maintainability of this code and so and I mean that is the this concept of like large language models because I think the other thing about when you're doing the code thing and and it doesn't quite exactly map to the chat Arena thing because I think they can write some code and then they can chain the code output into python or whatever to test it and then see that it works so just that one little tool use thing that I think is in the middle of these kind of systems but yeah what do you think about this General kind of thing of like chat Arena but for pull requests and uh like a master of the Repository could be actually really like really useful like case application like you could have like um I may see in this way uh so for example you may have um a moderator let's just say oh well I have some sort of um a requirement that I need to implement right and then it just gives it to well it manages this kind of a workspace and then we and then you may have like different agents or code like to implement different parts of it and they would you may ask them to like work together like by pull requests and then there are like tests you need some but some some major May write the unit tests the other agent May write the code itself and then they may end up and then all the moderators is doing is just check whether this the produced code like the repository can end up satisfying all the requirements and but I I think there is a lot to do here like it's very it's way more complex than that like you may have to do all the kind of unit tests but also integration tests like having putting all the different components together and um and version management like so lots of dependencies [Music] um but yeah I I don't think this is kind of a a very like a one of probably one of the most potential like the use case that has the most potential yeah let me so I think kind of a transition topic for I think people out there hopefully are starting to think about a certainly understand this concept of role-playing large language models that chat with each other and are moderated them let's talk about scaling this out like how many agents are we talking about yeah so theoretically this is like the the package supports like almost infinite number as long as the as long as they like length the it fits the kind of like context nav of the large language model right so but we do found out that like at least the current ROMs are very are still Limited in terms of what we call agency so when we scale out like the having too many number of players in an environment they may be find it hard to remember what their own role because I think the contextness would be like populated by the things that the other agents saved and the natural thing is that they would they it's very easy that they forgot like like like what what their what their role they are assigned to so I think that means that there are two aspects in this in this question like one is on the LOM or on the agent itself whether it has that kind of capability to adapt to to play in this like large number for for this big group of eight of AIS and the second is how well does your environment support the scaling so some games for example may not be very like uh like like like suitable for scaling for example tic-tac-toe right that's just only two things you can't fit three players certain games will have the kind of upper limit so which comes to the second question is how do we defined in game environments that's going to support or at least would benefit from scaling number of Agents hmm yeah I mean it's it's so fascinating like I can't even just think like about like a company and like you know say like we V8 the experience that I've had it's like as it's grown like I joined at 11 people and now I think it's about like 28 and growing and it's like you see the the roles what what is it what constitutes being a job evolves over time like someone who just maintains the clients or the modules maybe some particular climate just that kind of evolution and it's not it's not just like you have as many agents as you can fit right from the start because that's probably not the best way to do this role based multi-agent uh system uh yeah so that's so fascinating I'm really curious like um what led you to this were were you studying multi-aging systems already so this is actually a really fascinating topic like because like me ML and alcohol like core developers and we get a lot of feedback from UCL dog Group which they like study a lot of multi-aging IR problems and continuous control and all kind of RL problems and so so this is really fascinating area and the question is whether I do think like that we still need to create that kind of environment that so the real world scenario it's like it's hyper complex and the task it's solving is also like very complex like a company that like so like a revert like the product that you're building and all there are so many rows and so many like requirements right whereas the kind of games that RL area is not studying is still relatively toilish right in a way that's it's like they're all in similar environments and so I guess the question so right in chaturina I think one thing is that we do want to tackle the kind of this chat this Challenge and see whether we could create environments that could fit more agents and because that part is the scalability part is actually the more interesting scientific question here and which also comes with a lot of challenges that we do found that these current AI I mean even the largest uhms like gpt4 would often fall short in handling agency in such environments not a known could never known like collaborating and finding the optimal strategy in in in this in these environments so I feel that there's a lot to do in understanding how LM behave in this large scale I mean like large group uh AI environment and I feel that this is still around the very early stage so child arena is at the moment is just wanting to build environments and that would be the first step to explore multi-agent RL problems for llms um yeah I mean that it's so fascinating that marriage of multi-agent RL with the capabilities of the large language models and yeah when I when I also first came across multi-agent reinforced learning it was mostly you know like very simple grid World kind of environments and now we're seeing the this open-endedness enabled by large language models is yeah it's it's really inspiring and um yeah I I guess um I I wanted to kind of do a long range reference to something you said earlier about alphago I think this is very fascinating because of um like alphago the way it works is it uh takes you know it takes the board State as input and it predicts an action that's like the neural network policy part but then what they do is they add a uh like a Monte Carlo tree search on top of that where you know you you make your move then you send me then you you know sample like four different moves and then you make a move on all those let me do the tree top down but if you see me but like you know you simulate all these games and then when you're at the leaf nodes you're like the moderator in this case would say like this conversation path because it's like right now in our conversation it's like there are different things I could say to you to continue our conversation I could say like let's go back to talking about you know continual learning in this or let's talk about llm providers like I have all these decisions of like as as we're chatting then the next thing I could say right so so will this tree search thing be something that because I I understand that that tree search thing is like Paramount to the success of alphago yeah well I feel that this is one thing if not the biggest thing that's lacking in lom's is that they don't have this research and planning planning ahead right like so looking ahead this kind of capability is really lacking because so just as an example we when I play the tic-tac-toe in chat Arena right you have two to gpts and the the first player would like place the like at the place the their bark at the center of the tic-tac-toe board so that's that's a reasonable action but then they start to just like randomly putting their their marks like there's you don't really see that sort of like a planning and the incentive to win like to connect three three marks right so but I would say if any like if the lrm has any capability that to do MCTS right and to do something look ahead right it would be able to figure out that which place is the like it is it's the optimal or at least better like a place to play their Mark to right so which I feel that this is actually something that's really like lacking in llms if they want if we want to get to them to do really well in say in not just tic-tac-toe but any sort of game Real World games that read that requires planning ahead for example we may want to like schedules and meetings in the in the weeks ahead and we may need to like move things around like that sort of things like oh how would I if I would be what would I lose if I if I if I don't go to this conference or yeah that other conference right this kind of real life planning thing although I would say degenerative agent paper that you refer to that shows some early that primitive behaviors on planning a party or kind of thing but that is like a but that is still like like very primitive and doesn't have the kind of search required that kind of search kind of thing so I feel that this part is really fascinating uh area I could imagine that these there are these like I'm open AI or these big Tech like big this Lan companies may be looking at the into this because it seems to be a natural move as and also open AI is like they did a lot of Il right and dmont did a lot of IO so I didn't feel that it's natural that they in the next generation of ROMs they may put this sort of mechanism into your arms yeah and I think um I think the term the the research area that we're getting into now is model-based reinforcement learning and and maybe maybe some people would like to call that theory of mind if it's purely we're talking about a conversation but like model based reinforcement learning roughly describes being able to predict uh State transition state action transitions to the next state maybe reward potentially some sometimes they set it up that way sometimes they don't but it's like um yeah it's so fascinating what you're saying because with the tic-tac-toe example it's like when I put my circle in the middle of the board the other agent has to have some policy of where they're going to put their EX for me to start doing this tree search and with the with me trying to tree search a conversation I need to have a good model of like what you're going to say next in order for me to really see like where are all these conversation topics would end up taking us at the very end yeah yeah oh wow yeah I mean so much exciting yeah the modeling part I feel that that's also just fascinating that one thing that I found in some in the conversation kind of environment like having into like creating podcasts I feel that it kind of demonstrates start to demonstrate this Behavior by like say if you are giving like the podcast like the host the bile of their guest they are more likely to produce more better conversations right so which I feel that that suggests that makes it indicate that it is possible like modeling like having this like model based style is possible but is it good enough at the moment I don't know and I my take is that we still need to improve on this aspect like not just by prompting but really training optimizing our irms to um to learn that kind of behavior yeah if I doing another long-range reference is kind of like generative feedback loop concept kind of the ideas like um so in the database I have uh you know all of my papers I publish all the papers you've published and and I'm and I'm using it to sync up questions to ask in the podcast and then I save those questions back to the database so that I can retrieve those questions for prompting when needed so like you know we're chatting and maybe I need to like have like the three Mo the three best transitions send into questions just like these kind of this kind of like offline computation you can do to prepare and then have it and then have it there for when you when you would need that kind of thing but but stuff that wasn't already in the database like if I you know upload this podcast uh the podcast I can summarize it maybe doing one of these like chunk by chunk kind of iterative refining prompts or something but I like process the data and create artifacts that I then can reference to cause the language model to actually continue playing the role like stay focused on what it's doing so let me ask about uh maybe as this I am very impressed by the large language models but do you have any cynicism in their ability to maintain a role so I think when I play with Chad Arena like my take is that it's like it's there are two things like one thing is that so for some models like Cloud for example from empopic like you could almost like in the first try or two like you could get it to like to understand the role and they keep and they have that kind of remembering but for some models like for chap GPT as from my experience is that and sometimes well maybe like it depends on it depends on the kind of game environment that's into and also the configuration but we do need to like carefully prompt engineer the chargerbt to to to stick to its own rules so that's why I'm saying that there's like two aspects here one is the kind of configuration that that they're interacting in and the second is how much effort you put into the like into the prom engineering to make that work so well I think we could remove this friction by providing some examples but just in general that I think that LMS at the moment because the way that they are trained on with is this iohf and this like chatting with just one one user and being a helpful assistant well they may still be knacking in terms of understanding the roles that they are assigned to especially under multi-aging environments so they are used to talk to One customer one user but if they are put into like a large group where other agents are probably AIS some of them may be humans they may end up getting like um confused especially over long terms like long Horizons if their interaction keeps going and going and that means that they're like contact sniff is like longer and longer and their attention will make a diffused then I do found that like at the at later stage of the conversation it tend it it becomes more plus like more likely to confuse it's um it's on um its own rows so which I think this may be able to help by like having Vivid or like this Vector databases and retrieval augmented system to keep reminding yourself the kind of status that I mean the role that they are assigned to but I guess even now like we neck we still lack of the kind of understanding of agency and we neck a kind of a Benchmark as well to really check in what kind of case like in what kind of scenarios at what percentage of the time that they would confuse themselves and then we and then we optimize and fix those problems so I feel that this is at the early stage that we both have to develop environments benchmarks and also better methods including the retrieval augmented methods to improve the agency yeah that's amazing I mean I also I like I kind of think like the solution to hallucination which is very closely related to following your role in the context yeah is just to change the reinforce and learning objective from is it useful to the hallucination thing but as you mentioned then it becomes well how do you collect a data set like that at scale yeah that's why that's kind of what brings me into like why I think Chad Arena these kind of ideas are going to be so valuable is because you you the bent the benchmarking of these systems is like really hard like I think like the big bench thing was like one of the most impressive efforts to this big bench data set it came up with all these tasks tons of examples I think it took them like three months or so to beat all the tasks so there's that so there's that and but the the thing about that that I think is very like immediately valuable and should have will just have so much impact is um there were all these new language models coming out you mentioned anthropics cloud and obviously we have like chat gbt gbt4 we have models from cohere we have models from hugging face we have the Llama models we have open Assistant you can just go on and on so can we like plug these models into this game and then you know have our little tournament because I think I think uh collectively right now we're all looking for the best AGI sort of the best like just what is the smartest model like yeah so that's actually spoiler that we are actually we are planning to work on this Benchmark to like to uh to evaluate the kind of like all sorts of not just agency but also cial intelligence capabilities of these llms and because by Design our chat Arena supports like a lot of different like apis including those what we said like Cloud open AI hug and face and cohere these are already that are supported in the uh in in our package and that's also just from the start that we actually are really curious about evaluating different language models but also evaluating how well they will work together or communicate against each other so it's kind of like the tournament you're saying but it's not just competitive tolerance but it could be collaborative tolerance right so if they would be like you could ask so I think one thing that would treat about like is that I ask the ask cloud and open and check GPT to discuss how they would they could collaborate so it's asking them to collaborate to discuss how they will collaborate so and kind of like recursive problem but like and then they just come up with some really really nice like like um nice nice conversations on how we have AIS to collaborate so this that thing is really possible uh with chadarina and similarities and then we want to see how AIS would behave in these scenarios they may be different like hypothesis like they may worked better if they are like from the same API or training similar data but we're also curious to see if they are having like trained with different data have you know Specialties like they may be I come from very diverse backgrounds would that be beneficial or not right like you were you know my take is that it could be it should be like if we have more diverse agents to interact in the environment but that's still a big research question yeah that's amazing I mean it's just like with real humans like how you we all know someone who helping everyone thinks me this way but like it was like smart but then they are very like you know they they're so stubborn in their ways that they can't accept another idea or things like this that would that like it's not being a great software engineer isn't just about like how well can you reverse a linked list is about like can you also work with the team and I like how there's like this Dimensions to measuring intelligence and yeah it's also interesting um so maybe kind of wrapping up I really want to get your opinion on a kind of like a a direction of the kind of like large language model tool use space is how you see the difference between the chat gbt Marketplace and then uh you know like uh software that helps you write your own code designing tools like uh Lang chain or llama index or maybe kind of Auto gbt as being like Auto gbt to me is like similar to the chat gbt Marketplace in spirit like kind of how are you thinking about that kind of emerging uh area of this well I think that's actually like very promising Direction indeed like having this tool use it's kind of like the it's very intuitive idea to be honest right like we use lots of tools but maybe a different so I think that on on that line of research and also product I think there will be a lot more products or projects or tools that will come out in that domain and that's really fascinating uh Direction but I think what what more interests me is how do you have different um agents that's going to use maybe different tools different chain of tools right or they may have different expertises right like it's a bit different from True use that using two tools but actually it's having multiple agents that they could do different to different things right like they could use different tools or maybe they they don't have to share the same tools by the way like and they may have different expertises right like that's it's more like like real life like in companies I'm sure that like programmers use different tools than the like a customer service right then I I then even like developers like front-end developer may have these different tools than back-end developers right so you will see that so that part of the the the um Direction which is kind of a focus note to the tool use that means that having more diverse to use and uh between different agents would be probably a compliment to what you to the um chat gbt Market space or Lang chain for example and to me I feel that that's uh another very interesting Direction too but I would say these two are like very well complement each other and the better the better to use agents the more tools that's available to the agents that means that each of these agents will have better capability uh to fulfilling like even more complex tasks but also how do you to get multiple agents to collaborate in a environment would be another kind of like a interesting question yeah I mean amazing I mean it's like the next level of the abstraction but I like how you said the orthogonal thing really stuck with me because it's it's kind of like um like when we started doing this there was like retrieve and read and uh you know retrieved and read meant like you know Vector search or sparse search and then uh read like re-ranking models that take each querying document as input at once you know or like questionnaire extractive question answering models and that had like this dag flow and now this like Auto gbt thing has more of like a tree structured computation flow but now you're taking the tree and you're like I don't I don't know quite what this looks like yeah but it seems like yeah yeah [Laughter] and it's like the next abstraction Yeah well yeah you Shang thank you so much I think you know Visionary pioneering this Cutting Edge technology and it was so interesting to talk to my simulated version of me has the updated stance I could really say like a simulated uh podcast for this one if we have put this summarize it and and give it to chaturina I was curious to see how it works yeah awesome thank you thank you for having me indeed talk with you thank you so much maybe before we uh conclude do you want to maybe give links to anyone listening to where to follow your work or maybe some recent I mean obviously chattering is what we're talking about yeah so you could try out our Channel Arena like uh from our hugging face space or you could just go to chatarena.org that will direct you to our GitHub homepage and there will be a link to that our demo and you can also find updates on me on yushang.me adopt me so uh for for my latest updates as well and uh it also follow me on Twitter uh and yeah I think this is really exciting uh direction that and we are really want to uh and we really want to welcome our community to join us to pushing forward the boundary of multi-agent language games and also multi-aging collaboration in general and uh and for that only with Community participation and and contribution we could build more diverse environments and more interesting use cases uh for for these agents to play awesome thanks everyone for watching thank you oh ", "type": "Video", "name": "chatarena_with_yuxiang_wu__weaviate_podcast_47", "path": "", "link": "https://www.youtube.com/watch?v=_0ww8Q0Bq2w", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}