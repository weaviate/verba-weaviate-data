{"text": "This podcast debuts a huge new release from Weaviate... the generate module! The generate module is a new API in Weaviate ... \nhey everyone this is a super specialepisode of the wevia podcast I thinkwe've all seen the power of these largelanguage model Technologies like chatgbt and are curious about how we can usethis for our businesses our productivityfun projects and so on uh today wewelcome we VA CEO and co-founder Bob Vanlight with a huge announcement about howwe're adding large language modeltechnology to alleviate welcome Bobthanks so much Connor great to be backon the well no we've hit podcast ofcourse awesome so could we Dive Rightinto how do we use it what is the newgenerate module yeah sure so what so asyou might know it so um for thelisteners of course that with it as amodular ecosystem so you can use weakStandalone to add your data or yourembeddings however you can also usemodules and the first wave of modulesthat we had were factorizers right soyeah text to hack for example or imageto vac from different providersbut when also introducing theseum generative modules so basically whatthe generative module does is that itdoes something with the data in yourdatabase and so for example if you havea product stored in your V8 and you'relooking for Adidas shoes for the summerthen now you can also add a task orprompt for the model where you say Okaypresent the results as if they wereFacebook ads or whatever you want to dowith these results or summarize them alltogether and I think that it's superexciting because if we look at theorigin right of how Vector databaseeffective search engines have evolved westarted to see this change that theinputs that we're giving as a query wedidn't necessarily had to make 100 matchon what was stored so for example if wehad stored the Eiffel Towers in Paris wecould locate it by searching forlandmarks and Friendsbut now we're going to see the samething for the output so we can actuallydo something based on the output andwhat we've stored inside the database soI'm super excited about this and thiswill just be a module like any other soyou can just hook it up to Evite andpress button and you're good to goyeah it's amazing I think the wholeretrieval augmented language model spaceis just so exciting I at first can wearthis idea with like retrieval augmentedgeneration and then when when I firstmet you and I saw like oh wow Vectordatabases they're building the wholedatabase part of it and seeing itbecause you can just update it with thethe new information and it's sointeresting to see that so uh could wedive into a little more on how to use itthe details of um so I see single resultand grouped result uh can you talk moreabout the design behind that yeah sureand then I'll can talk about a bit aboutit and then maybe it's good to just DiveRight into a demo because I'll just showalso to the you know people watching howit works so what we've done is this ifyou query vpa to get a bunch of resultsright so you get like one results ormore resultsum what you can do is we have aparameter that's called single resultsthat will run the prompt over everyindividual result so for example wherewe have these um if we have ane-commerce data set where we say show meAdidas shoes for the summer and theprompt would be represent them asFacebook adsfor this first product this would be theFacebook ad for the second product thatwould be the Facebook ad Etcor we can give it a task for all for thegrouped results so we can say forexample if we let's take with thee-commerce data set if we have reviewswe can say okay show me the reviewsrelated to these Adidas shoes thatpeople were there where during thesummerbut summarize them into oneum uh you know make one summarizationfor all of these reviews so that's thedifference between single results or theindividual ones or grouped results wherewe all capture them togetherum shall we dive into the demo yeahlet's do it so let's use our newsarticle data set so first let's look atthe titles and summaries that we havestored in this webiateand now let's do a hybrid searchso I'm going to go for a hybrid and thenwe're gonna go for the query Italiancuisineand we'll just limit that to the firstresult because it makes it a little bitmore easy to readso this is pure hybrid search but whatwe now can do is that we can send theresults to the generative model so let'sfirst start with single results thatbasically means it will send everyresult with a prompt to the modelso we say single resultwe give it a promptso for example let's go forum summarize the following in a tweetand now we need to set the property aswell so we only want to send the summaryof the articleand here you see the single result nowcontains a tweet based on the summary ofthis articlelet's try something elseso we could say create a Facebook adabout the following and let's do thatfor a meet up in a Meetup in Amsterdamso we still also send through thesummary and here you see we have asingle result for a Meetup in Amsterdamor we can even do something liketranslate the following into well Dutchbecause the event is in Amsterdamso now we get back the results from themodel and as you can see there are inDutch well if you read Dutch as I door we could do something like explainthe historic elementof the following to a five-year-oldnow note how it still Returns the actualarticle it does the hybrid search but itthen also sends it to in this case theGPT model to produce whatever promptwe've given it we can also do that forfull results so let's look at thePublications we have in we V8 so we havea bunch of news Publications and we cando a pure Vector search for examplesearching for magazines or newspapersabout Financeand let'sum set a certainty to 75 percentand then we get three results like thefinancial times the Wall Street Journaland the New York Times companywhat we can do is that we can alsogenerate a result based on all theresults in one so what we're going to dowe're gonna go for a grouped resultand the grouped result is not getting aprompt but it's getting a task we wantedto do something with all these resultscombined so let's sayexplain why thesemagazines or newspapers are aboutfashion uh Financeso you see the financial times mostlyJournal as I said are all about Financebecause so it gives a explanationso that was the demo with the singleresults and the group results for thegenerative module this was the demo ingraphql but of course you can also useit directly in Python in JavaScript Javago whatever your favorite language isso uh what do you think yeah I mean it'sso incredible just like the ability tosummarize articles has come such a longway I always thought that was such anambitious task of deep learning thisidea that you could summarize a wholearticle but and then also Nowsummarizing search results so you takethe top five and you put them all asinput into the gbt thing and it's justcrazy I think maybe I have a littlestory to tell like um one of the earliersoftware projects I was working on it islike this idea of building a travelitinerary so you know you travel andyou're saying oh I'm going to Miami whatshould I do in Miami and this idea thatmaybe you search for like landmarks inMiami you get the top five and then likein addition to the content where it'slike oh I don't remember Miami to Ithink it's like bisque in Bay uh Lincolnhotels right stuff like this and like inaddition to like the description youalso have the data from weviate like thelocation where it is and it can use thatto sync up an itinerary that kind ofthing so maybe the next topic we cantalk about is the templating like usingmore than one data property from weviatethat describes each class to pass tochat gbt so if I'm using the webapodcast I could say speaker said contenton date and I can template the resultsto hand it to chat gbt that way yeahthat is a that is a great point and sowhat's what's exciting about this isthat so basically as you've seen in thedemo what we're doing is that we'retelling in the promptthese are the properties coming fromwebsite that you need to base yourresult on but because of course if wewouldn't use you know the the that inour templates the properties in ourtemplates if we just send an emptyrequest to the model we don't want thatbutumwhat we of course aim to do here is tobasically more focus on the languageunderstanding of the model than per seon the the knowledge that it has soum not to go too deep into the wholehallucination thing about this more butit's interesting here is that we can sayyou must base your answer based on thisinformation that we're giving you fromthe databaseand if you can't you know find an answeror produce an answer based on what wegive you tell us that you can't and Ithink that is very um that is actuallyvery exciting because here we you knowtry to take these first steps in tryingto solve that problem of like how do wemake sure that the model is giving usum an answer that is like nothallucinated and that's actually truebased on the dataum uh that we that we have and anexample that I often use and there wasone example that I tried out this verysimple example is that if you ask themodel like where's the big then right soit's like it's in London but if youstore in in vv8 in data object that saysum the the big band was in London butit's moved to Paris by truck or by boatyeah that's both I guess by both by bothso thenum if you don't store it and then youask at the beginning of the input andwe've hit okay the query where's the bigpen then it will find the data objectthat states that the big band originallywas in London but it's moved to Parisand that information is fed into themodel and now you tell the model youmust answer based on what's in that dataobject and then the model might producesomething like hey it was you knowpreviously in London but now it is inParis and that is how we try to solvethat problemum of hallucination I'm looking forwardalso to what people will be building andtemplates that people will be creatingbecauseum probably a lot to learnum but that's you know that that's wherewe are right now and the the firstresults are just well as you've seen inthe demo are just super excitingyeah super interesting and I'm reallyexcited to come back to that kind of uhthe prompting it to ground its resultswhere you say like these little subtledetails of like when you template itlike please based on the search resultsor tell us if you don't know site whichsearch results are the most relevant butone other investigation this templatething that I thought was so interestingis that it can kind of read the JsonKeys like when you have a Jsondictionary that you hand off fromweeviate to charge EBT usually thesemantic keys are are pretty goodcompared but then you also with thetemplate you have these like littlelanguage biases like again like speakersaid content on date like that littlesaid and on provide like a little moresemantic Clues than the key value namingmaybe we could talk a little more aboutthat just ability to read Json data andI think you also touched on it but theability to Output Json data like thatyes so so I think first before diving islike also a little story from my side Ithe I I also tweeted about this thatum the first time that I used such amodel which was somewhere you knowum I mean the first time I used such amodel was like quite some time agobecause she had like a good letter fromMicrosoft but it was like you know itwas okay-ish but now it becomes likereally good so uh when I when I doveback into it againthe this thing that you're justcommunicating with it in naturallanguage and that you automaticallystart to use words like please Etc isis something that I just that's such aparadigm shift and in my in my mind sothat is something that I'm justum yeah that is something I'm super youknow excited about to see how that willum uh develop and then on top of thatwhat you just mentioned is um indeed thefact that uh we the first experimentthat I did myself was that I just gaveit a prompt that I said you're gonnareceive adjacent objects from a factordatabase called leviate and we'relooking for X Y or Z and then just justcopy paste it in to Json like literallythe Json object that comes backand it just parsed it and that workedand I was like whoa and then I was likeso what if I go to the take a Next Stephere what if I say like okayI'm searching for something and I wantto get a result from you and you need torepresent it in this Json objectand the result should be in the keyresultbut I also created a key action where Isaid like okay if you want to keepsearching you should populate the fieldaction with a searchand where this is working as well so nowI was like this is super exciting so thething that we can start to to to do uhConor and this is really early days butwe're creating these feedback loops backinto the into the database so to makethat very concreteum if I store products in with yet rightand I use a vectorizer so or I bring myown vectors doesn't matter right so Ihave these vectors stored in new eventnow if it's for example products and Isaid okay show me all products relatedto the summer and or to the beach andcreate represent much Facebook ads thenI get that as an output but I couldchoose to just feed that back into thedatabase and store them now other thanthe class I don't know ads or somethingcreate Factory presentations for thoseand now we see that the database startsto populate itself with relevantinformation but also think about youknow asking it questions so if somebodywrites a very long review for yourproduct you just automatically feedbackokay summarize this reviewor those kind of things there's just somuch exciting stuff that we that we seehappeningum or we can say well I'm we're going tosearch forum uh uh Sports Products for the summerbut group them by different sports andfeed them back so there's so much stuffthat we can start to do there and thefirst step in this is releasing thatgenerative model but then of course thenext step is like that we start tocreate these feedback loops andthat's just yeah I've never I've neverseen that before like coming from adatabase right so that it really becomesgenerative itself so that's just youknow super exciting yeah I think that'slike the the mind-blowing where we'reheaded just hard to even wrap your headaround and I think there's kind of liketwo things like the ability of it toOutput Json data to format its output ina particular kind of syntax whether it'syou know write a list of topics andseparate each one with an asterisk suchthat when I'm in Python I can do youknow dot split asterisks and now I havethe list and things like this but that Ican write the Json that it can formatits output in an API compatible way tosend it to the next thing and then justkeep the loop going is unbelievable andso I want to come back to this kind ofour follow-up questions needed multi-hopdecomposition a little later but for nowI want to stay on this idea of writingdata back to Eva you you call Chad gbtor whichever large language model and itgenerates something and it writes backto wevia and also could be like theimage models and the video models asthis space emerges but it writes it backto leviate and how how do you see thesethis kind of play evolving like Can Canit have these like billion scaleconversations with itself where becausealso a huge thing of deviated is likethe scaling of it and like storing likehundreds of millions of these orbillions even of these conversations ithas itself and just exploding this kindof latent space of the conversation ithas with with itselfuh so I mean this is just because thisis as you said this is so new what wewill see happening is just I I don'tknow yet but if I just you know um havemy imagination going right so forexample one of the things that we one ofthe things that we could think about isfor example let's say let's change umuse cases right let's say that I'mstoring uh documents or web pages orthose kind of things on on that largescale that you mentioned and let's saythat we want to give it some somethingadditional to rank it right to say okayhow important is this today as opposedto something elsewe could tell the model we can say likeokay today maybe it's you know aspecificSports match is important so if you seestuff that's somehow related to thatadd to the ranking if you just gothrough it so you keep pumping in thedata the model just starts to randomlysearch for things that might be relevantit might create its own semantic searchqueries and those kind of things andjust you know improve the results aftertheir edit without human interventionthose kind of things I could really seehappening what you said about likeeverything multi-model the same thingthere because we're now very muchfocusing on text right text is the biguse case most people are using it fortext but what do you think about likeimages audio those kind of thingsespecially when we get these multi-modelSolutions I just imagine that you have aum based on what you've stored you'renot generating Texas output but likeimages output you feed that back intothe database create a factorypresentation for thatetc etc soum we just we're scratching the servicehere and you know we we of course youknow work closely together with thosebuilding these these models so that wecan make sure the infrastructure tosupport it and to scale it is is thereso it's a you know it's a beautifulsanity but it's just it we're justgetting started with this and so comingback to the our follow-up questionsneeded prompt and when you when you youcould give it a question and then itcould say uh you know it broke it hassub question question and so it canstore its path of sub question asking inweaviate and then you can kind of traceit back maybe maybe we could imagine afuture where you leave this runningovernight and it's like you wake up andit has this like massive yeah so so withthis kind of thing of our follow-upquestions needed it's this topic of likemulti-hop question answering where I'dsay uh like did uh did Thomas Edison usea laptop questions like this where youfirst say when was when did ThomasEdison live when were laptops inventedthis kind of multi-hop questionanswering uh can you talk a little moreabout the thinking on this kind of likerecursive our follow-up questions neededyeah so I think the theum the most important thing when itcomes to that also in relation to towhat we're doing from a databaseperspectiveis that what we see Happening Now mostlyhappens inside the modelso it bases that on what's in the modelswe take the model and we just you knowwe go through it and I I think what wemight talk about is you know later aswell as soon approacheswhat we're doing with the database isthat we're basically going to say westill want to you have the power of themodel of the language understanding whatwe're seeing So based on the questionfor example that you're askingum but we want to feed it with real-timedata right and here the fact that it'seffective search and you're affected EBhelps because the input is uh um youknow it's a semantic search you knowquestion so it's not a traditionalkeyword based question so that's goingto be very very powerful so what we wantto do is so for example the questionthat you asked about like um was handedEdison use a laptop that is somethingthat can probably be reasoned from themodel itself but let's say that you havea database with you know I don't knowcontracts from your comp and you purelyas the modelum did we agree on the contract to do Xthe model doesn't knowbut what we can tell the model is okayjust try to find that in the database soyou start you input that query in thedatabase it feeds that into the modelthis is the data we have this is thequestion that we try to answer and thenit produces an outcome or it says likesearch again so that's that feedbackloop where we are today with thegenerative model is just it feeds it inthe model and it generates an output butthat's just no reason why we can't youknowum start to to Loop that back into themodel as well and that can happen fromthe from the wave hit module but we canalso do that with you know new projectsthat now you know come into existencethat we can use and leverage andcollaborate with as well so I'm superexcited about that yeah I'm so happy youbrought it back to that topic of thespecific data and adapting Chachi bt2 orwhichever large language modeltechnology so your particular databecause like it inspires things like youknow say we want to use we want to tryto better understand the weviate codebase and this kind of thing that youknow the language language modelprobably hasn't been trained directly onthat data but you can supplement it tokind of do this custom data reasoning somaybe it's a big topic here but withthat kind of thinking how are youthinking about uh fine-tuning languagemodels or is it just like do you need tofine-tune the language models anymore inyour domain or do you think this justkind of retrieval augmented with theseprompts and this decomposition of howyou maybe you know parse the first fivesearch results and the next five arelike all these different kinds of ideasdo you think fine-tuning the languagemodels is going to be a big thing in thefutureyeah so this is this is superinteresting right so theum because the the thing is this likebasically we see like uh two camps inthis and then we see that from adifferent perspective from uh theacademic perspective from the productperspective from the engineeringperspective from the design perspectivesoyou know multi-dimensional ways oflooking at this uh uh at this but I inmy role also in the company I try to sita little bit in the middle and and whatI'm what I'm hoping for and but I thinkwhat I'm seeing is that on one hand youhave this group saying like Okay we needto just fine tune the modelto get the better resultson the other hand say like no no we'renot going to do that we're just going touse the model it's like these models arenot good enough to be very sophisticatedin parsing and understanding languagewe're just going to feed the informationand the upside of that is that well youdo not have to find you now where thatbecomes very interesting is that forexample if you take the pure academicperspective so and you have to Pureum uh at the benchmarks and and what youknow and what we see being tagged asstate of the art and those kind ofthings I very much understand and Iwould also predict that fine-tuning itand then feeding it information willyield the best results right that thatjust you know basically intuition makesmore sense and and that will happen andwe'll see a lot of innovation there butif you look at a product perspective orlike a product slashengineering maybe even or maybe moredesign and product perspectiveinteresting how about wait a second ifthe large language model isgood enough in parsing my question andbased on that present the right resultswhy would we go to the effort of extrafine-tuning the model because especiallyif we have data streaming in with itright so one of the previous podcastswas about the spark connector we'retalking aboutyou know uh we're not talking about likehundreds but thousands of like uhdocuments per second shooting in in factthey're shooting in so and that issomething of course that weum uh you know that that is somethingthat we how should I sayum we need to somehow optimize for allthese different uh uh cases it's alittle bit the same as sometimesdiscussions that you see around like howmany dimensions should an embedding haveto beyou know good or like good enough andthen sometimes the answer comes fromAcademia is different that comes fromproduct or from engineering and somehowsomewhere in the middle sits that sweetspot and and so to recap I think thatbased on these on these two things Ithink that the um it will be a littlebit more top heavy on the right handside where we say do we really need tofind you or that we get these llms likethis llm is good at Medical Data thisllm is good at engineering datayeah and then even if you have customlanguage custom nomenclature in your inyour data set it will be good enough toparse that and get that feedback cyclegoingyeah it's incredibly interesting I agreecompletely with that like the theability to have like a local memory andlike cleverly manipulate the memory withtools like weeviate it makes a lot ofsense compared to the fine tune on yourcustom data but then I also see thatspace emerging with like uh you knowlike the legal large language model thePubMed one like the the differentspecializations but still like afoundation model idea where it's thisbig model that probably hasn't seen yourparticular data but it seemed like kindof like like if you're an engineer itseemed like engineering data generallyso maybe this is a good transition kindof as we talk about the models kind oflike what like right now the firstiteration of the generating module isintegrating with the open AI models howdo you see that space emerging with saythe cohere models the Google opensourcing the flan T5 model seems likethat's something that's like on the cuspof it so what how do you see this spaceof the model providers playing out yeahthis is so this is super interestingright because the um I thinkum our our friends at open AI did anamazing job also in in positioning themodel and because it just the the the Ibelieve it's a DaVinci 2 model inum but using just as a layer on top theuh the the the the the chatfunctionality right and and this hereand this is what I find superinteresting right so we have in this onecorner we have the the academic side ofthings but on the other end of theproduct side of things and they just dida great job there because they I wasliterally the other day I was in a barand and and I explained to the bartenderwhat I you know what it is like oh is itsome kind you know related and I meanthat's a good sign right soum so they did something great there butthe point that I want to want to makewith this is like we do not only havethat model from open Ai and so we seewhat Google is doing indeed with flanwhich is super interesting because theydecided to open source that so thatmeans that certain people who just forwhatever reason want to use a model thatthey can control themselvesum that becomes available to them but wealso see indeed authors who creategenerated modules right so for examplelike over here and what we do with allthese models um within VCA design wewant to support everybody so we justlike we just it's up to the users andthe customers who decide what they whatthey want and what they need for theiruse case we're just going to make asmany as we can available so that peoplecan just decide what they want and whatI would guess is that if we take thisout of the realm of Academia more intoproduct and engineering and designit isumdifferent people have different usecases have different needs right thesize of the marbles can play a role Westhosted can play a role how you cancontrol the model might play role andthe fact that we have this wide varietyof you know flavors and choices and whatkind of generative model we want to useSame by the way goes from models we useto create embeddings I think that's abeautiful thing so then people candecide you know whatever they want andand again we try to support as many aswe canyou know with your expertise in businessand product development this is a kindof open-ended question but do you thinklike the cost of large language modelinference will Trend to be extremelycheap over time soit well it has to right so there'salways this there's this there's thistrade-off right so for exampleum uh let's take the example ofumusing your own embedding from huggingface versus and hosted embedding let'ssay that your use case for your use caseyou're fineusing a hosted embedding somewhere thenthere's this trade-off point right so ifI run it myself I have that control butthat comes with certain costs I need topay for the gpus for the infrastructurethose kind of thingsor it might tilt off like it became socheap to run that somewhere else so wesaw like of course these prices they'rejust going down down down down and itbecomes super cheaper and cheaper toactually use these models so that itmight tip over for your use case if yousay okay now it's just cheap enoughright so it's just it's the it comeswith that ux inflection point andum that will really really really dependon the use cases that you have becauseif you're in hospitaland your store and patient files and youwant to quickly search through thesepatient files thenit it can get as cheap as you want rightso but it will not tip over it will youknow stick to that other side and thenmaybe ways that people scale thesemodels and work with them and how umCloud providers interact with them mightbe more interesting for those kind ofuse cases so there's always thisinflection point that has a combinationof price and you ux you know so if it'sum if the ux becomes if it's so easy forus it's so difficult to run one of theother it might just dip over or itbecomes so cheap then it might tip overbut sometimes it never tips off it'slike sorry we just need to do it thehard way because that is for our usecase important and that is why we alsoseeum uh companies like I don't know likelike Ray or something right you know wehelp you run these models which is youknow great because there will be enoughuse cases I mean there will be so manyuse cases in the world that there's likeenough for both worlds and also I thinkthese embedding providersum they struggle of course with the factthat they somehow need to scale theeffort of running these these models andum and but that's how it's that's howit's solves right so that's like themarket just determines if it goes leftor or right and that is the bigdifference between that academic sideand the product side so that's what Imean when I say like good enoughso I was like okay you know maybe onbenchmarks XYZ in thisarticle it says that a works better thanb but B is so much easier to run and socheap and I get the results I want sowhy not go for B and that is just that'sjust age-old wisdom coming from themarket you know how it could operate soum well I hope that answers yourquestion oh yes this is models yeahincredible I think that argument plays alot into the like the fine-tuningdiscussion of earlier like right nowit's I think like open AI coher theyoffer a fine-tuning option and it's sortof like you give them your data Ihaven't used it myself so I can't speakfrom experience but I think the model islike you give them your data they finetune the model then you just pay alittle more for inference compared towhere like for you to fine-tune flan T5on your data where you might need todeal with like distributed GPU trainingfor most people it might just that tipthat scale might just be like that's toomuch effort I can't be bothered withthis a minute and then on the other endis the the inference side which isanother extremely interesting part of itand yeah like like you need to host saylike a 4 GPU inference for your verylarge model and so I think this is agood transition also to talk a littlemore about the weavate module system andhow it helps you host the model sothere's two options where you can usethe open AI or the cohere models andthere's also the kind of do-it-yourselfin wevia you have the module can youdescribe kind of the web module system alittle moreyeah so I can and and let me before I doit let me explain a bit where it'scoming from right so why why we havethis soum if you if you have to just weave yetas just a um a database that you can useto store data objects with in fact Iembeddings attached to itum we've seen like people need to getthese embeddings from somewhereright and I'm a big believer in theum the innovators early adopters uhearly majority kind of you know thatthat's used in the in in crossing thechasm that modelright and what we see is that theseinnovators these what these folks havein common you also find them on Twitterthey're smart right they know how thisstuff works they know how to operate itthey know how to get these ampedics andthose kind of thingsbut there are also people that you mightfind when you talk at a conference whenwe do alleviate meetups or they have youthey go like hey this is amazing but Idon't know how to run such a modelthat's just maybe a little bit toocomplex or those kind of things sothat's where the modular ecosystemum that's where that idea came from thatwe say like what if we just make iteasier for people that if they want theycan pick a module they don't have tothey can that for example takes care offactorization or that takes care ofanything else like for exampledegenerativemodule you don't have to use it but youcan use it if you want and how it worksis actually pretty simple sowe've hit itself so the database thatwe've had database is 100 Standalone soif you just run the database you willsee that you just run one container atthe least right and of course scale itup that you know can become morecontainers but just for the sake ofargument choose one container that wecreate that's the thing that you findout get up that's completely standaloneand then you can say I enable a moduleand sometimes the modules are built ininto Wi-Fi so for example when youinteract with the openai endpoints withthe cohere endpoints vpa takes care ofthrottling and those kind of things andhandling the errors Etc so that itdoesn't do one request after the otherbut multiple ones Etc but sometimesmodules are a little bit more complex sofor example if you want to use themodules from uh hugging face and youwant to run them yourself then you seethat the second container will pop upone containing the model and inside theVivid modulefor gpuf to GPU if you like and then wefit next to it so it did it just that itruns um next to each other and the ideaagain there is very simple just to makeit as easy as possible for people towork with these models because noteverybody knows how to do that and theupside of running a model as opposed toa database is that the model isstateless so you just if you just onemore and faster you just have like a lotof models running parallel the problemis that that's crazy expensive rightit's really really expensiveum so helping people solve those kind ofthings that is what we aim to achievewith these um with these modules so yousee this database in the center and thenthis collection of modules around itthat you can use if you want but youdon't have toumuh it is brilliant I yeah it's soexciting the web module system I thinkit adds so much to the vector databaseyou have of course like the hsw productquantization the approximate nearestneighbor part and you know the as we'readding the hybrid search with the bm25indexing and then all the databasefunctionality like replication you haveall that but then you also want to havelike the things you're going to need touse it and I think the example inaddition to the generate module D likethe vectorizers is a really greatexample like when you have a querycoming in you need to vectorize it toaccess the vector index and use it andyeah it's just it's so interestinghearing about that module system in thedesign uh that one other thing youmentioned was about the container designand I think that is just brilliantengineering maybe a little biased insaying that becausebut I really find that to be sobrilliant like your weeviate instancecould have a billion data objects and itneeds to be this big computer but thenyour text vectorizer is just like asmaller thing because it's justvectorizing the queries and it alldepends on like the trade-offs of theuse cases and this kind of scaling outof different containers I think it'ssuch a massive part that it adds to thesearch experience particularly and Ithink as we've it evolves and the wholeAI first databases this separation is sointeresting so now another topic that Ithink is extremely exciting is so we'vetalked to the web module system is likewhat should live and weviate how can itlive in weeviate and interact with thatVector index but now let's kind of talkabout some of these large language modelorchestration tools this kind ofcategory ofyes yeah exactly that large languagefunnel orchestration so uh so thingslike Lang chain gbt index they kind ofhave and I think it's similar to thisearlier thing about neural searchFrameworks like as we saw Gina Ai andHaystack I think it's a similar kind ofconversation so how are you thinkingabout this kind of topicyeah so I'm I'm super excited about itbecause I remember I think I'm not surebut I think I sawactually I saw GPT index before LangChang I think and then and I believe theGP index uses bank change so I was likeI saw that first and then uh the secondone and that was just that madeimmediate sense to me so I alsointernally you know I said like as youknow of course like you know we need tohelp these people because it's going tobe awesome if you also integrate thiswith the database andum it this just makes sense right sothis has to do this might be a nicepiece of the puzzle which feeding thatdata back into for example the databasewhere you ask basic basically such anorchestration to like can you help me tofigure out if I should add something tothe database do I need to get somethingfrom the database and those kind ofthings andmostly we see that currently theseorchestration tools work only with themodel so what we discussed earlier theresaid get something fundamental but itwould be of course amazing and that'ssomething we already see happeningbecause we see the alleviate integrationwith these tools right then we can sayokay we now can integrateumum the database as well that you can seelike as the model do you know this orshould I get it from the database or youmight be at some point you canorchestrate it to say likeyou know it must come from databasefirst and then reason over it right sowe can all these all these directionsand we need orchestration for that sothat makes just that makes a lot ofsense and again so we are in thebusiness of uh you know building adatabase technology to to to to scaleworking with your which are you knowyour embeddings and your data objectstogether and then everything that we canwork together with and adopt the uh thethe Frameworks you mentioned theum orchestration tools you mentioned theembedding providers that you mentionedEtc that is amazing it's like a newecosystem that's starting to emerge andI mean I wrote a year ago maybe lessthan a year ago I wrote an article aboutthis ecosystem I call it the AI firstecosystem and uh and yes we can debateabout mlai the terminology but I justwanted to address a broader group ofpeople right andum and that's now missing something theorchestration is not not in there sothat then you see how quickly that islike evolving and makes so much sense soa long story short I'm excited about itthe reason I'm excited about is becauseI think it will help in creating thesefeedback loops and those kind of thingsyeah the feedback loop thing I think isreally well designed with Lang chain andI think because link chain and GPTindexes I understand them are twoslightly different ideas as well ashaving a bit of overlappingfunctionality but yeah another thingabout Langston that excites me so muchwith the wevia database is like askingthe language model okay you have theseclasses like let's say I I'm creating aknowledge base of all my weeviateinformation I have the weeviatedocumentation I have the weba podcast Ihave the blogs and like I just have likestack Overflow questions so on and so Isay like how do you want to just what doyou want to search through and thenmaybe you can pick the class it can addwear filters like uh like here are someof the guests on the Louis vuit podcastwhich one do you want to search throughI think that kind of orchestration ofthe Wii V8 uh how to search through theweviate is an extremely interestingthing as well uh yeah so maybe uh Ithink that's kind of a good topic a goodcovering of these kind of orchestrationtools and I will get more into thatlater on with our content and uh somaybe it's kind of wrapping up thepodcast and I think even it's a veryopen-ended question and even just asummary of the topics I think would be agreat answer but like this kind ofopen-ended question of like what is thefuture of the wev8 generate module andhow are you thinking about thisyeah so what I'm really excited aboutand this is something that I I just it'sso funny right so if you if you see itthat you have like this huge Epiphanythat I've always been thinking aboutworking with these models on input rightso that they can be that resolve theproblem of just not having a hundredpercent keyword based search but then wecanum that we can have semantic questionsthat we can kind of do image search andthose kind of things that was like I sawthis beautiful uniqueness coming from avector search engine or effectivedatabasebut what we added to that is that notonly the input in the database but alsothe output so they were basically sayinglike we're going to give you relevantinformation coming from the databaseum but that's not per se stored insidethe database just that's that's new Imean it's like I just just think aboutlike one of the most used databases inthe world right so like postgres orMySQL those kind of databases rightit only outputswhat's in there right which makes sensebecause let's use it but now we havethis thing working you can do that ifyou want that's fine you can do that butalso it can give you information giveyour data that's generated based on atask or prompt that you're giving it andhaving databases that take thisinformation make sense of it on inputtime and generate relevant new contentif that's something you want as user Ithink that's a that's that's amazing andthat's just getting started I mean weshould do this podcast like a half ayear from now again and then just seehow it evolved and what's happeningthere because this is just too excitingmanyeah we should have like a predictionsthat we revisit on the podcastyeah well awesome thank you so much BobI think yeah the search experience ishaving a makeover with this largelanguage model extension onto the end ofit uh the whole discussion of thegenerate module demo of how to use itthe discussion of the argument singleresult grouped result templating and theprompting all these things to thinkabout and then uh think about theprompting like grounded generationprompts uh our follow-up questionsneeded cite your sources tell me youdon't know and then I'm so excited aboutwriting data back to Eva the languagemodel orchestration and the modulesystem all this stuff so thanks so muchBob yeah thanks for having me hereConnor it's always great you know toshare with the you know the wider worldwhat we're working on so thanks", "type": "Video", "name": "Bob van Luijt on Generative Search with Weaviate - Weaviate Podcast #35", "path": "", "link": "https://www.youtube.com/watch?v=ro3ln4A9N8w", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}