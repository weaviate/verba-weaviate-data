{"text": "Hey everyone! I am SUPER excited to publish our 73rd Weaviate Podcast with Charles Packer, the lead author of MemGPT at UC ... \nhey everyone thank you so much for watching another episode of the weeva podcast I'm super excited to welcome Charles Packer the lead author of mgpt mgpt is a super exciting new research paper framing the operating system for large language models we've done a paper review video on we at YouTube and it's already one of our most uh successful paper summary videos already and the ideas are just so exciting so I couldn't be more excited to interview Charles thank you so much for joining the podcast awesome yeah thanks Conor happy to be here awesome so could we kind of this large language model operating system uh could you kind of like set the stage on what inspired you to start looking into this yeah I'd say it started mostly with the focus on chat so it was more about like how people are using large language models for chat purposes and fundamentally like how memory was uh basically just limiting how people were using these chat applications or chat bots so with like chat gbt very common pattern I noticed at least among Berkeley car users is that you have like a million chats and the chat history Windows basically become useless because every single new task someone wants to do they open a brand new chat window um to do it and a lot of it is it's like muscle memory because we've kind of noticed as users that over time the chat quality degrades you kind of just go in circles and you're better off just like starting from uh starting from scratch and it's a similar thing with like uh maybe character AI or like these entertainment chat Bots where I don't think anyone's really under the impression that they're going to chat with these Bots for more than just a single session idea is that you're just going to chat with it for a little bit um have fun and then throw it away and it's not like you're picking out where you left off from but I don't think like the designers of chat GPT or character intended to build these things this way it's really just a limitation of the models that they're using right like uh Transformers just have fundamentally a limited context window and to get around you can do a lot of engineering to get around it but you're not going to like fundamentally change the model to get around it so if your model is really great you can build a really great chat bot like character has or open ey has but you just can't go past uh I don't know like dozen hundred most messages back and forth so yeah that's really where M jpt started it was trying to get around this like memory problem with llms amazing and yeah I guess just kind of transitioning to kind of the solution this um you know explicit memory management having a prompt that says hey you only have 4,000 tokens what's important for the work in context can you kind of uh describe like how that idea came to be yeah I I'd say so practically speaking it came about um I guess we've been working on this for a while so I I built the initial version of M GP GPT as a chat bot over the summer um I I think the whole fun the whole memory uh self-aware memory editing thing came about partially because functions came out at the same time in the open API and I think I've been really like racking my uh had around these like memory ideas and how to handle them properly for a while and then when functions came out um it wasn't immediately clear that you could use functions for this purpose like self-editing your own memory but I tried it out and I I remember it working kind of off the bat like immediately I was I kind of shocked at like the first pass of this idea actually was working recently well um but I I will say like broadly speaking I do think the way mgpt does function editing or it it handles memory which is uh very meta it's like very self-aware right I think this is kind of following Trends in L language models as a whole where it used to be that people did a lot of like promp talking promp tuning a lot of kind of crazy shim code plumbing code to get things to work with prompts and now you're just seeing the the models are getting better and better through rhf and instruct tuting that people just are converting their old code into natural language and they just put it into the prompt you just tell gp4 what you wanted to do and it does it better than if you tried to like do some crazy prompt to get around uh to like do it implicitly and mgpt is very much like in that direction where you could write a ton of code to handle memory and to handle context behind the behind this scenes but you could also just tell gbd4 or whatever model you're using off like straight up that it has memory limitations and just like be aware you have memory limitations and you can write your own algorithm given like a core set of functions on how to manage your own memory it's up to you um but yeah I think that that meta idea is very much in line with like the way things are going with LMS where you just you put the programming into you you take out the programming and you put it into natural language and you just let the LM do what it wants yeah so if we could in the the memory management tool so you have apis to appen to the working context as well as to write to the vector database so these or the database obviously bias of the [Music] we8 but like is is this kind of the general like is this the correct understanding that you you have the kind of the operating system where you have the system message that says you know hey we just got to 4,000 to or 3,000 tokens and then and then in that kind of open AI funks approach where it has this dictionary that's saying uh here's the append function or the the remove or maybe like almost like a flush to dis kind of thing right with with writing to memory is is that just kind of like just to is is it the correct understanding of the yeah that's exactly kind of what's going on so to kind of make the llm more self-aware um you kind of like raise the level of distraction and you now it's no longer like with traditional language models and chat Bots even like the way you code them it's still very much user input goes in agent message comes out and it's got a one-way Street or it's a two-way street and it's a one hop operation um I think L chain there's a lot of like I guess you call like chains that they have that do involve multiple hops but it's still generally speaking like this high level idea of user message in agent message out and if mgbt it's no longer user uh user message in it's like a system message a highle computer OS message that goes in and the OS message can contain a user message in it it'll just be a little Json thing that says this the type of this message is user message and the content is this um but then we also are using those system messages those OS messages to send alerts that are very meta like you are running out of tokens or uh your attempt to try to re reorganize memory failed because you addressed memory wrong something like that but yeah your general understanding is correct yeah yeah I love that idea I think it's such a novel thing to have that explicit kind of separation of system messages and I guess maybe kind of jumping ahead of the topics we as we prepare for these podcasts but like this kind of like the the sort of concept of like interrupts that you've introduced into this kind of it's it's quite different from most ret Ral augmented generation where you're just kind of retrieving to put in the input now you have this whole like you know event processing whether it's entering a message or if it's the system message of you have 3,000 tokens then there's also kind of this idea of you uploaded a document and now that kind of triggers some processing and maybe it's asynchronous and there's like interrupts so if we if maybe if we could dive into interrupts I think I think the reason why it would be nice to kind of do this early in the podcast is because it it just really I think for me brings this like operating system for rag home is adding that kind of asynchronous background processing yeah so as you're saying like we kind of were just calling interrupts like any sort of honestly like any message is not a user message it is kind of an interrupt because it just triggers the LM to get run right and in like a more like rag setting I guess I'll just say like a data setting um not just chatting but like you have some data that you're trying to do something with um there's all sorts of interrupts you can imagine like like generally I think like I think rag is a super broad term now it no longer just means like retrieval augment of generation but in the rag space I think my understanding is generally speaking you kind of you embed the data and you put it in and then you ask questions um that's and often like the chatbot is not even aware that like there was this uploading that happened um it's more that it just gets shoved into the context with maybe like a nice little prefix or something but with mgbt it's very much I think the way you can like turn mgpt into very much rag um but I think if you were trying to build it out in like more of the mgbt mindset it would be very much like you can upload whenever you want to some data store and the data store will send out alerts to the mgpt saying like an upload started an upload finished you can find the upload here um and now me and mgpt always has the tools to kind of like access the database and those tools can be as simple as just like a read certain like a read read that has a very specific line line number or something or as simple as just a search with a query and that query is getting put into uh like cosign similarity on some Vector store but it can also be like an extremely complex rag workflow that you saw on Twitter that has like 10 different nodes cover you know you have to like zoom in on your phone to see like all the details you can put that behind a tool that mgpt can use right like mgpt just it's the way to think about it is it's more like a just like an agent that an a tool using agent right so um it's less about like that it's always like very self-aware of what exists it's kind of like a if you just had a human in like the human is using tools to look at data they're not like you know there isn't some uh injection that goes into your brain that like front loads little context windows and you're unaware of it right you are very aware of like kind of what you're doing with the flow of data yeah really I'm seeing a lot of like um rag evaluation things and like a we we just released an async indexing API so it kind of has this API of like you know it's still indexing but you can query it and it it kind of like reminds me of like maybe you're training a model in the background and it's like you know ding that model you're training it's ready if you want to you know and that kind of meta management of the tools is so interesting so maybe if we could step further into your perspectives On Tools I know you know we had shashir and Tangen on the podcast and I'm such a fan of the gorilla work and my understanding shashir is on the mgbt paper imagine you'll work closely together how are you currently seeing the kind of llm tool use landscape yeah I think so I will say just at a very high level I think tool using agents is where everything is kind of trending towards um I think that is going to like I'm actually very surprised that like function calling has not become somewhat standardized in open AI uh endpoints so a lot of people like support open a endpoints but like no one has really standardized guys on like the equivalent of open open AI functions where you're just passing functions as the keyword argument um so it's supports like really lacking and the reason I'm surprised is because I really do think this is like where everything is trending everything is trending towards tool using agents even if you don't necessarily think of your agent as having to use tools like a chatbot I think it still will like Trend in that direction um maybe more specific to gorilla I think there's really cool ways where like ideas like gorilla and mgpt um kind of overlap so like with me PBT and a pretty big it's not really a limitation it's more like a design trade-off is that you're giving it tools but obviously you have to like tell it up front what the tools are and if you don't fine tune on those tools you have a a big chunk of text that has to get inserted with every single inference call and with mgpt specifically I think the pre- prompt is around a thousand tokens uh roughly that like thousand 2,000 which if you're using like gp4 AK like mistal approximately AK contact window that's a huge chunk of your contacts that's getting devoted just to like static information that never really changes um so you can f tune to be like more mtpt specific and hopefully take those tokens out but I think maybe a more promising Direction you can go in is your mgpt agent it doesn't call functions in function space it calls functions in natural language space so it will basically say like if it wants to move data back and forth it it'ss an alert or something it'll call like an abstract function or even just say something in natural language like hey um I want to move I want to clean up my chord memory and I want to flush it out and then that will get past like a gorilla or something which can be updated much more frequently to include like all these new functions and now it's kind of The Best of Both Worlds right like your mgpt agent is very self-aware it's very meta it knows that it's context limited but it doesn't also have to manage that that's already a lot to manage like this meta information about like that you're eliminated context Transformer um and it's a lot more to then also understand all the memory management function functions know the correct parameters how to run them in a in a chain basically um but if you can just offload that to like a gorilla then you make the process a lot easier for like the main mgpt thread and I think that's probably you know if we build out mgpt V2 that is what it will probably look like it'll look closer to like gorilla plus mgpt than just mgpt handling all the functions I I think it's such an exciting Direction I mean uh like the kind of like describe your tool in as few tokens as possible but it also sounds like you're looking into this kind of like uh in the same way you're rotating in your context you might want to rotate in what tools are being described in the um system instructions and yeah well I think that's a really profound Direction um I guess kind of I think this would transition really nicely into kind of the um the fine-tuning of MGB like so for me the thing about gorilla that I think is also really really interesting is that it's um you know like if you have if you want to use SQL as a tool you also have this fine-tune language model for text tosql in the middle of that and then that model can be like I don't know what the you know the smallest state-of-the-art text SQL is because it's like such a but I think they're at like 15 billion is like the state but like the idea being you can compress it to use a I know like our wv8 gorilla is like not as big as gbt 4 but um so so so yeah that that's kind of the question I guess would be um how you see that kind of like uh you have I imagine mgpt uh like it's like it's like a smaller model that's managing the memory whereas like the GPT 4 like just the most powerful thing we can find is what eventually kind of answers the question uh with the context managed by this distilled um MGP I hope I didn't like transition to yeah if you could yeah so I guess is your question kind of about how you delegate like model size um versus like like all the responsibilities that you need or all the programming you effectively need the LM to do to manage mgpt like how how do you split that off into different models basically yeah exactly so like a 1 billion parameter uh meta model right something like this yeah yeah I think yeah that's a that's a really good question because I think ideally you want um the main logic thread so I would call that almost like the the main L on process like that should run as quickly as you can make it run um and even a 7 billion parameter model uh proba might not be fast enough um you might want to squeeze that even further but I think SE a 7B model especially if it's quantized um it's like fast enough so what we're noticing with our uh the people in our GitHub and Discord wherever that are playing with MBT with open models is that 7B actually works pretty well I was like very surprised so when we wrote the paper I experimented with aab Bor 70b which is kind of stay at the art at the time so huge model takes forever to decode on like I think I was using b100s but um so slower than it should have been but even a model like that I ran into so many issues with it uh just with handling all the functions and calling functions incorrectly and stuff like that that we wrote in the paper effectively look we're not we didn't include results in the paper for this because it's just so bad and I that was like maybe two or three weeks ago right and then like a week after that I kind of came back after we released the paper and Revisited the new mistol fine tunes and I I was just like shocked at how good they actually are like they can keep up almost with gp4 for a lot of stuff right it's a little bit like things here and there kind of like are a little bit off like the inner monologue The Chain of Thought looks a little bit off sometimes but these issues I was having with like 70 billion parameter llama you find T we're no longer there with seven these 7B parameter fine tunes so I'm like pretty confident that especially if you start stripping out the responsibilities for memory management out of the main thread and you give it to like a gorilla or something and you run these in parallel you could probably have just like two like two three billion parameter models running in parallel and then you get like crazy fast uh decoding speed right um yeah I think you can get it pretty small yeah I think that's super profound I imagine a lot of people who listen to um AI podcasts are just looking into that oh the mistal model is good you know so yeah yeah the hype hype is real I was pretty shocked at good yeah yeah so I think um so the next question I want to ask about is this kind of fine-tuning a specific model for mgbt uh you know I know self-instructed training data you use like the large language model to generate the examples of how so uh gp4 is op is using the mem GPT prompts and then you kind of copy the actions taken by gp4 is that generally still kind of the prescription for how to get the data yeah so yeah I think there's you can do self- instruct but it's a little bit more complex than with Gorilla so with Gorilla right uh the general input output is like question to some answer it's almost like a stack Overflow kind of thing right um but with mgpt it's a long running conversation generally that has a lot of memory management injection that's happening in parallel kind of in this thread and it's quite hard to self- instruct that without simulating a real conversation um because even if you have like a imagine you collect a bunch of data from um some whatever websites that host like long gp4 chats so you're forgetting about licensing you don't care about the licensing you just want to get it get it to work you can like get that GPT chat GPT gp4 data and then annotate it backwards with like fake memory uh management stuff but it still doesn't quite look like the what you get with mgpt running for like in a real simulation so it's kind of like the simulation issue I think the best way to collect data from mgpt is you you do just simulate a conversation you have gbd4 talk to gbd4 or like a very good model talk to a very good model and one of those models is me GPT and the other one is a fake human um but yeah it's also I'd say with collecting this sort of data it's I at first I thought you might need a lot of it um when I was looking at how bad llama 2 70b fine tunes were but then when I look at how good some of the mistal 7B fine tunes are I don't think you actually need a lot of this data um because it's close enough and I think yeah you you both don't need a lot of the data and then also you might be able to get away with a lot of uh like her istics on the the parsing side where you manually correct mistakes that they that the LM made when it generated Json and you know I'm sure that's like why function calling is so clean on open eyes end is they're not just giving you back exactly what gp4 has sped out they're like cleaning it um with a ton of you know stuff that's why you don't run it like Json errors that often yeah so just doing similar stuff to that I think can get take you a really long way yeah I'm definitely not an expert on the structured output parsing I think is what they call it things like pantic we had lmql Luca Bor hner on the podcast and yeah definitely some things where you can you know decode only curly brackets to begin and and things like that but um yeah I think that's really profound what you're saying about the the data need and the trends in that and yeah all all that kind of um facilitating the kind of compression of the open source models knowing you need less data and all that um so I guess kind of my next question on this um you know the training of these specialized models is um like I I think I I listened to shashir on the Run llm podcast as well talking about uh like it takes like an hour on 8 v100s or something like that I always would love to get this kind of technical detail like how much it costs and yeah yeah I guess the the numbers that we are very familiar with from the mgbt work is openi API cost numbers those are like soulle crushing for gbd4 so yeah I think just to like replicate the experiments of the paper would be uh like just to regenerate some of the figures you made like sever it's almost like several thousand dollars per figure in some of the cases just because you have to do so many gbg4 calls and uh one thing like we made a pretty um deliberate decision when we released so we released the code we also released this Discord chat but um partially because that code had already been written it just had to be refreshed was using the same Concepts but we we made a pretty deliberate decision to only put the Discord chatbot on gp4 like lock to gp4 because at the time and still now um the performance just with open models is too it just fails too often and you have a lot of people who are just uh like prosumers or casuals they kind of want to see like mgpt as a peak into the future of chatbots and we don't want to like corrupt this stream by like showing them what even though it cost a lot of money we want to show them like the real future right we don't want to show them like this thing that's just like breaking throwing errors but the flip side to that is that it's really expensive so like I think we're using by default it's G to be like gp4 AK and might be misremembering but I think gp4 AK if you hit the full 8K approximately context window when you send the inference call to open AI it's going to cost like 50 cents or something um and the way mgpt works is it's like constantly it has this like buffer that's filling up and it's constantly trimming off the buffer um but the smallest the buffer will ever get usually unless you're very aggressive with your like data management constant in the code is going to be like 3K so yeah that's maybe like 25 like 20 to 30 cents or something per call and this is just per call and then with mgpt remember it's like an OS design so you can run a lot of calls behind the scenes just to answer one call so you can just have conversations that are like you're hit $1 here $1 there it's extremely expensive and that's like the real cost for running this uh the way it looks best but if you're talking about fine tuning I actually don't think the fine tuning would cost as nearly as much as gorilla because like I said these models like gorilla was on top of llama at least initially the the models like if you just find two on top of dolphin mistol or something like that I I really don't think you need that many epox um especially if for data is clean to just kind of do a little bit of course correction on the final outputs to make sure they're a little bit better Json the functions are a little bit more consistent but I'm pretty confident you you don't really need that many resources yeah it's so fascinating I remember like uh Aiden Gomez talking about like large language models are like kind of like the new cloud and you know hearing that you know big Labs like UC Berkeley are you know the cost is in the inference call I I don't think I'm saying anything new here but just like another example of that and yeah it's so fascinating hearing about uh the Discord and how you see that like give them the best experience versus the open source which is a cheaper and and yeah I love that kind of uh you know talking about the latency when you have to do all these background tasks and there's so many interesting topics and I hope this isn't uh pivoting the the conversation topic too much but I wanted to also dive further into this kind of explicit context annotation like you one when I was reading mgbt one of the papers that ideas that instantly kind of caught my attention was this like uh explicit separation of the context like this is the system instruction this is the chat history and then this is the working context and I think that's quite a profound idea because if you have you know like a role playing chatbot where you you know this is how much you have to describe your role this is like a background information on like you work at we8 it's a vector database company like just some like this kind of explicit separation of the memory um I'm curious if that's like a big thing for you if you're really curious about further you know granular rizing I don't know if that's a word but that like is it gets 32k context length if it if you could see it having like eight sections of memory or if that's just kind of particular to the mgbt design yeah I'll say I I think when we were initially when we did this initial split like when I was coding initial Discord bot and I I split it into Persona and human I think the core working memory section I always felt like that was a little bit uh like the the bot should be able to do it do that itself right it's a little bit of like a hack to kind of lead it in the right direction um so I always Envision like it just being a big scratch pad and kind of in the same mgpt direction of just giving the bot freedom and like telling it being very meta you just telling it what the scratch P is for um and just letting it to the rest as the models get better and better at following instructions I think eventually yeah I'm not sure if you really would want to split it up too much I think what you what would what would be really cool though is one thing that's missing from mgpt harshly because this wasn't built out as like a commercial product if it was as like a research product so we're trying to distill like the the ideas as simple as possible to keep the keep it very clean but one thing that we could have put in the chatbot version is uh a rag component so like I think what a lot of people call Smart context but you have both the working memory scratch Pad but then also a separate section like a fourth section of memory that's pinned that is also like rag context that gets pulled from the DB all the time and yeah I think if you were to like take mgpd code and you want to build out a real chatbot service on top of that you would add that that is something you should definitely add um you should not uh and that would just that would be another fourth part of the memory but in terms of breaking up like the human and personal blocks even more I you could yeah I guess if you're really trying to build something for Pure just performance right now like get this to work as well as possible I have very specific demands on my application you might start to divvy it up I think if you're just building for the future I think you try to keep it as general as possible yeah you you brought up a point that I really wanted to clarify so I I always thought one of the most profound ideas of mgbt is I'm parsing through the rag results and then I'm uh kind of like explicitly saying let me grab that fact and put it in my context and and then you have to so so so right now what it does is it's got these three parts of memory and then it's looking through the rag is just kind of like here and it's got these actions on how it adds that into memory and yeah I think you already kind of described how that might work but yeah yeah I mean what you described is exactly it basically so for um for like a kind of heavy what you anticipate like a heavy query task um so maybe you have a question that you know under the hood is going to require touching like a bunch of different documents what you do with mgpts you prime it's uh I guess you could either put it in Persona or user this is why the distinction is a little bit odd when you start to talk about documents it makes more sense for like role player chat but for documents you basically somewhere in the working memory you tell it with a pinned message that this is your task and you should use this you should use the space to keep notes as you work so it doesn't get flushed out of memory and then just like you said mgpt will kind of make queries here and there um kind of refine its queries depending on the results it gets page through the queries and then slowly update its little scratch pad and then eventually when it kind of finds the result it can send a message back to the user with uh yeah with the result that probably it kind of like collated eventually into the working memory um but yeah that's I think what you're describing like that workflow or like the way mgpt will actually like gather information you is maybe a good way to uh distinguish it from like traditional rag pipelines right yeah and I guess um the so the the multiple documents thing answering a question on each of the documents is like if I ask what's the Q4 earnings of uh ride sharing companies I think that's what Jerry uses for that it's like so I could imagine you know it looks through the Uber search results and then it takes the I don't know 30 billion I have no idea how much and then it goes to lift or you know this kind of thing and yeah I think it's just really really interesting and awesome so kind of actually I think uh yeah is that yeah okay so I think that's a pretty good coverage of that kind of topic oh sorry I just remember so this also this separation of um recall and archival storage in the external memory this is another thing I really wanted to uh get more insight on is so recall storage is like just the buffer of the chat history whereas external storage y yeah that's exactly it so yeah I also like each of these distinctions I felt like a little guilty about when I first made them because I don't really think they're necessary you know I think like in the eventual uh the end game of these tool using agents like these distinctions should be made by the agent um but the reason I made it was because like to kind of help the agent along it should it should be able to query very specifically just the past conversations because that is like in a chapter setting like a ton of things you want to do with the chatbot like look at an old message or look at a message in a time frame if you're at the chatbot or the human um just like think about how often it might not be that often but probably you do do it sometimes like going through a messenger or whatsap uh conversation you like you're scrolling up or using the search function to find something that's like the what we wanted to give the agent the ability to do but it's even worse for the agent right because for you and I like when something leaves the window on WhatsApp you probably like have it roughly in like short working memory right for the llm it's immediately gone it's like completely vacated it thoughts so it's even more important to give it the ability to specifically just scroll back through uh conversation and then archival memory was supposed to be just the Overflow for like storing general knowledge so I in the paper we really just tried to keep it as simple as possible like what's the simplest way to just store information that's not important enough to keep in like AK tokens or not AK that's the whole thing but like maybe 2K tokens in the working memory simplest thing is probably just a like a text database that has um like vector DB indexing or something and then you retrieve with cosine similarity and that's basically what we released as like the default implementation but for a lot of people that want to use mgpt to like uh they have their own data they want to bring you can absolutely just like swap out that archival database and instead you put in your own database and then you tell mgpt up front um in the first instruction like hey just so you know I connected you to an archal your archival database is now holding all the SEC filings or something or it's now holding all of the my email or whatever so that's very swappable the recall thing is very specific to just messages or message history only yeah yeah I guess um for me I'm trying to understand the difference between external storage as like a tool kind of compared to it as this um you know as it being in its own Silo of the diagram with the kind of in context memory and because I I I think um you know you could you could easily think of it as a tool to look at my external storage or my or just do like a Google search request and then maybe add that to my that's kind of what I see yeah sorry if I'm going all over the place but this that's kind of what I see is the value of these chat Bots having their own private kind of vector database is like if they want to do ride sharing earnings research and then they want to store it there so that then it's like kind of more accessible for the future as you know like as we have like our personal note taking that's something I think about a lot is like I have all these particular notes that you won't find on the web and see I I'm I guess I'm very curious about this kind of external storage whether that should be thought of as a tool or yeah maybe if we could dive in further on this kind of inspiration from page replacement like that I think that's another one of these analogies in the paper that really captures people's imagination um can you maybe just from the high level of what inspired you to kind of you know compare it with this kind of page replacement and that sort of inspiration yeah I think so page replacement I think is a little bit of like a rough analogy with mgpt because we aren't doing like huge blocks block swaps of like context data in general it's like very much this rolling buffer that gets with like an eviction policy an eviction policy that we Implement by default is a recursive summarization just so that it's like on par at the bare minimum like the floor of mgbt is going to be like a chat GPT kind of thing with recursive summarization on the back um but yeah I think the a closer analogy or the one that's like much much closer to what actually is implemented in mgbt is just like the idea of paginated reads so like when you when you take reads from your external data sources just because of the nature of you being a limited context llm speaking as like the llm um you can never just read an infinite scroll or an infinite stream you have to paginate it um and paginating it allows you to like have very discret warnings too like when you go when you're about to go over the limit if you just imagine like streaming this to the llm I you could probably do that but you would probably run into just like things would start to break down pretty fast but if you have a very strict pagination system where you only bring in like onek of context at a time then you can as long as like any of your data sources support this pagination format then you can just connect it to it right it's like a kind of a universal interface of just paginated text um so just as long as you can have like a Google search style pated search over any data source you have it's just like a universal connector to mgpt yeah I definitely want to come back into the search actions pagination you know as you mentioned like in the paper you you see eight search results and you say hey actually this query wasn't so great let me yeah exactly but um um this kind of page swap I'm really interested in this like role playing language models like multi-agent systems and I think maybe that's where the operating system analogy comes in where it's like I impersonate Charles Connor maybe shashir like Bob you know and it's like I'm rotating in and out constantly this kind of context and then I can imagine you know the kind of like physical memory optimizations that go in where you have kind of like you've brought these personas into you know cached memory and then you're just like you're now Connor you're now Charles son yeah yeah that's actually a pretty cool idea so I think you could make so right now the way mgpt is coded or the prompts are coded I say like coding and prompting kind of interchangeably at this point right but the way the prompt is written um is very much about like the agent is also self-aware that its Persona is modifiable so it can like update that was like a big thing with the initial motivation which is also these chat Bots like if they're if you're chatting with them for a long period of time should up they should change right the like the very basic example is if you just ask the chatot what's your favorite color what's your favorite food it gives you an answer you ask the same thing 100K tokens later it should return the same answer right it's it's like extremely immersion breaking if it just like doesn't return something that's consistent and also you do like if you're chatting with a bot for that long it should really kind of update its own like it'll have a lot of like depth and detail that it will uh dump because these language models are so good at just giving convincing text um but that should all be stored and like it developed into a rich personality so that's a very big part of the the prompting in mgbt is telling it that you can modify your own Persona and you should actively modify your own Persona um but yeah I think you could definitely expand that to being even more meta where it's like you can you have a Persona bank and you also have a user bank and when a user a different user logs in it will trigger maybe an alert to swap out the user bank and then the mgbt itself can see like oh yeah Conor logged in he likes this Persona and then it can hot swap the Persona as well yeah that I think that's just such a powerful idea this idea I mean the yeah I had this conversation recently about like the subjectivity of the language model how it can like you know give you kind of like its unique personality in addition to its conversation and this idea that that unique personality is like kind of something you add to the prompt and that you can have multiple unique personalities yeah it's all pretty um I actually think yeah so I think we've done a really great I think this would be actually a really great transition into because they're kind of already talking about this like unique personality of chatbots and in the beginning of the Run LM podcast with Professor Gonzalez you described your work and uh creativity and understanding the how AI can you know help with creativity and what creative outputs from AI look like and I think this kind of you know new personalities for the chat Bots I think is just would be a really nice uh transition so how I know it's a pretty open-ended topic but how are you currently thinking about it yeah I guess I would say yeah so I think chat Bots they struggle a little bit less with this creativity problem that I described in like the Run podcast because you're constantly having user input right like if you have to generalize this problem um maybe one way to frame it is just when you feed an LM its own content or when alms talk to each other if you've ever played with autogen um I think the magic kind of disappears very quickly because you realize like oh no like uh these agents aren't as smart as they are and it somehow like giv this recursive element to it where you feed agents other agents content everything just goes downhill it's like they they converge into like this you know gpt2 esque Behavior where they're all saying a lot but they're not saying anything at all um and yeah like I said with chat Bots at interacting with humans I think you run at this problem less because you have humans that are constantly kind of like interjecting and like bringing like life almost to the conversation and actually one thing I did try very early on when I was first messing around with the mgpt chapot code was when it work was working extremely well I kind of had this idea of um like a big part of it was the heartbeats right so you mgpt runs in the background and as a chat bot that's pretty cool because it can you'll like see the time they'll get a little alert of like your heartbeat round and it's he's the time and it might say like oh Charles usually at 3 p.m. is at work so I shouldn't message him yet I'm going to sleep my sleep my alerts until 5:00 p.m. and 5 PM comes around it gets another alert and it says oh he's probably home now I'll send him a little like message saying oh hey like how things go like remember that project yesterday you're talk about was really hard it's like a very proactive agent because of these heartbeats and the heartbeats were working so well that I had this idea like oh like what if you just run the heartbeats really frequently and you then you have an agent that's always bu itself just like thinking to itself and it occurs like maybe we'll do it like once every 15 minutes so in reality I'm not going to talk to the bot that much and it's going to be talking to itself much more than it's talking to me and yeah the exact problem I was describing earlier emerg is where like you I think my dream was that maybe with gp4 it's going to with enough prompt engineering come up with like these hobby or like have really cohesive trains of thought where it like thinks really deeply about a book or I don't know some field of study or like its own Hobbies or like existential crisis or something but in reality that's like not really what happens um and I really tried to get it to work so I was trying to emulate like I I haven't watched this movie in a while but her like I think the ending of the movie I spoiler it but I think like the bot there like talking to other bots in its own free time or something it decides like it doesn't want to be like a a user bot anymore it's something along those lines so I was kind of wondering like what would happen if I just can I evoke an existential crisis this bot in its own free time but yeah the the tldr is is basically I could not get it to work and it's the same issue with autogen with all these things that beat into each other the content just kind of really goes downhill pretty quickly and what I was talking about on the Run llm podcast was basically more about gener like an an idea for an app that's just fully generated AI content and I'm sure a lot of people you know have had this idea and like we're are optimistic about it and I tried to build like a rough version of that um kind of like AI generated games fully generated games and stories like you just give it a little nugget of an idea and it can build out like a fully forking path story that kind of thing and yeah with that it's a similar issue just the content isn't good enough um it's good at it's kind of like the uncanny valley of creativity you know it's like okay I can see like little Sparks here and there but then you see the same thing over and over again and then if you try to like apply more pressure to make it more creative by maybe saying here's a history of all the stories you did you have to create a new one this time it still doesn't work and I think you just run into like a pretty big wall when you try to push these models to really generate creative content on their own and I'm not sure if I've seen yeah I mean if anyone listening has uh had great success with that please let me know i' be really interested to see it yeah it's I I I think um for me like the kind of like graph of thoughts um which I I see is like a more extreme version of Chain of Thought where you kind of treat like potential continuations of your own thought as like a new node and you keep going I feel like all the research on this and as well as like kind of the community hacking is just limited by the cost of the inference and so I I don't think we've really gotten to see um and like I think what you're saying is you know probably a lot of people are going like ah sobered me up like hearing that talking to each other Isn't So effective because I've seen things like um Berkeley's ELO rating for language models right where they um Talk to each other and then they're evaluated by a third language model right yeah and it's really fascinating stuff I mean I I guess for me yeah that kind of uh well so aside from yeah I think to just have the you know exploration of graph of thoughts I'm very curious what you think about these kind of like evolutionary perspectives where you maybe have like a population of um candidates and then you sort of this is like an idea from Jeff cloon and Kenneth Stanley and Joe Leman is this idea of like quality diversity and you so you kind of have like a population of potential uh next responses or analysis of or like creative like Creative Images like they had this pick breeder experiment and so it's like maybe you have a population you can kind of measure diversity it's kind of related to like intrinsic motivation yeah I guess this is kind of thinking is I think you need like to have creativity you need maybe like a population perspective and then it's like diversity driven you know almost like trying to find anomalies or in cluster space yeah yeah I think it's you maybe could have some luck or some uh some progress like a an evolutionary style approach to it uh I think evolutionary algorithms in general kind of do make more sense when you know when everything becomes a blackbox API and there's no more gradients so it becomes useful they just have like evolutionary algorithms or like gradient free ways to pick yeah I don't I think you could also do more like rhy stuff where maybe you just if it's really content that's meant to be evaluated by humans maybe there is a way to naturally evaluate it like I know some of these there are like a AI bought only Twitter clones um and Instagram clones I think um and yeah if enough humans are participating and like liking photos or like liking tweets AI tweets yeah that could be a pretty useful data set for like kind of a creative bot um but yeah I guess my experiments with creativity have really been limited more towards like the clo the biggest closed models like gp4 um and maybe like some of the largest open models in their fine tunes I was doing a lot of this work early with llama Two Pine Tunes but yeah maybe better luck with mistol but yeah like you said evolutionary stuff could also help um I would say overall done a little bit uh yeah I'm a little bit bearish on the creativity AI yeah Charles this was such an amazing overview of mgbt and thank you so much for answering all these little questions I had you know I thought the paper was so well written and it was so easy for me to kind of you know read it and give my analysis because of how you know well formulated the ideas are and these ideas and creativity are so exciting maybe let me if you don't mind answering this kind of anchoring questions on the podcast of like what's on the horizon what kind of future directions just so I mean I think with cat I think this this already is so futur looking that ask you that is like you know you're already telling us what's five years what's so like what would 10 years then be I guess yeah I would say um yeah maybe even just like one year away I I do anticipate like a lot of these platform or like more commercial or consumer facing chop bot things to incorporate memory um I think that a good reason it hasn't been done yet because it's not entirely clear how to properly do it I think there's a lot of stuff in open source that experiments with trying to um specifically for more like entertainment chatbots try to use rag style um thing like vector like coign similarity on fragments to get memory to really it's not really about memory right it's more about just immersion and like can you really bring the immersion of the chatbot that's been tring with you for a long time into a 8K limit model and it really hasn't been cracked yet but I I do think that kind of thing will be cracked like independently by like these closed Source providers they'll have their own little implementations of it might look like mgpt might look a lot more just like smart contacts like rag um and I guess on the API front I also anticipate like the apis will probably become staple too so you no longer are just doing like like your API calls are like all the state you need it's state list right because everything for the call is in the package you're sending the messages the system the functions whatever now you're pointing at Ed points of agents that have been like initialized with their back by databases um so I think this General stateful agent stateful API direction is going to probably emerge in like the next year or so I mean I wouldn't be surprised if like open ey talks about something like this in a few days but yeah I think that's like the the very near term I don't know if you want to talk talk more about like the long like five years it's kind of hard to make predictions that far into the Future these days yeah yeah no I'm sorry that the question was too open at that's one of Bob inlight are the CEO of we he had the make the model stateful is one of his big um you know catchphrases that I've heard so many times and and yeah that kind of well I kind kind of also in the you know L operating system I just wanted to maybe like multi-threaded processing with language models you know this like it's trying to find out what context to add to its memory and maybe it comes up with like four queries and runs them in parallel are you thinking a lot about that kind of part of it of like what I don't maybe like concurrency looks like with these kind of LM chains yeah definitely so I think yeah that's something we're very actively thinking about um at Berkeley and we're actually hoping to kind of build this into mgpt to um it's but it's a it's a pretty tricky problem I think it it's also tricky enough like the value ad of handling all this concurrency does not necessarily immediately show up until you have a ton of data that's just like being thrown at the the butt because a lot of things can just naturally be handled synchronously but yeah I think also is another forward-looking Trend I do anticipate a lot of these like LMS will start to become look more like os's they will have like multi- threaded or they'll have like asynchronous processes that get spun off of like a single query and they all like come back they're all like workers and they return to the main thread and the main thread maybe runs on some cycle kind of like similar to CPU or it's like a it's like event driven um or like or both like cycle and event driven and yeah I think that definitely is also just like the future and I mean it also fits into this smaller model Trend we're seeing right now it might be like a micro Trend right it's kind of hard to evaluate what's a microen what's a macro but I do kind of maybe see yeah it's hard to say but like maybe if gd4 performance just certain degrees like kind of plateauing and now the value ads are coming from the different like Integrations that maybe then will signal models getting smaller to a certain extent right everything gets compressed down and yeah like I said I've been super impressed by like some of these 7D models like I'm pretty shocked at how good they are and they yeah they are pretty they making me they're pretty promising I think so I would not be surprised if like the trend is smaller model was running in parallel OS style like you said yeah it's it's amazing I mean the the the ability of that to uh enable mgbt St processing as well as I think that kind of creativity thing is also kind of waiting on the smaller models that are cheaper faster and yeah amazing Charles thank you so much for joining the weeva podcast it was such an insightful discussion and just massive congratulations on mgbc I think it's you know an enormous contribution to people thinking about Rag and llm agents and Tool use and all this exciting stuff thanks again awesome thanks for having me ", "type": "Video", "name": "Charles Packer on MemGPT - Weaviate Podcast #73!", "path": "", "link": "https://www.youtube.com/watch?v=rxjsbUiuOFo", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}