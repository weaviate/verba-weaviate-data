{"text": "Hey everyone! I am SUPER excited to publish our 73rd Weaviate Podcast with Charles Packer, the lead author of MemGPT at UC ... \nhey everyone thank you so much forwatching another episode of the weevapodcast I'm super excited to welcomeCharles Packer the lead author of mgptmgpt is a super exciting new researchpaper framing the operating system forlarge language models we've done a paperreview video on we at YouTube and it'salready one of our most uh successfulpaper summary videos already and theideas are just so exciting so I couldn'tbe more excited to interview Charlesthank you so much for joining thepodcast awesome yeah thanks Conor happyto be here awesome so could we kind ofthis large language model operatingsystem uh could you kind of like set thestage on what inspired you to startlooking intothis yeah I'd say it started mostly withthe focus on chat so it was more aboutlike how people are using large languagemodels for chat purposes andfundamentally like how memory was uhbasically just limiting how people wereusing these chat applications or chatbots so with like chat gbt very commonpattern I noticed at least amongBerkeley car users is that you have likea million chats and the chat historyWindows basically become useless becauseevery single new task someone wants todo they open a brand new chat window umto do it and a lot of it is it's likemuscle memory because we've kind ofnoticed as users that over time the chatquality degrades you kind of just go incircles and you're better off just likestarting from uh starting from scratchand it's a similar thing with like uhmaybe character AI or like theseentertainment chat Bots where I don'tthink anyone's really under theimpression that they're going to chatwith these Bots for more than just asingle session idea is that you're justgoing to chat with it for a little bitum have fun and then throw it away andit's not like you're picking out whereyou left off from but I don't think likethe designers of chat GPT or characterintended to build these things this wayit's really just a limitation of themodels that they're using right like uhTransformers just have fundamentally alimited context window and to get aroundyou can do a lot of engineering to getaround it but you're not going to likefundamentally change the model to getaround it so if your model is reallygreat you can build a really great chatbot like character has or open ey hasbut you just can't go past uh I don'tknow like dozen hundred most messagesback and forth so yeah that's reallywhere M jpt started it was trying to getaround this like memory problem withllms amazing and yeah I guess just kindof transitioning to kind of the solutionthis um you know explicit memorymanagement having a prompt that says heyyou only have 4,000 tokens what'simportant for the work in context canyou kind ofuh describe like how that idea came tobe yeah I I'dsay so practically speaking it cameabout um I guess we've been working onthis for a while so I I built theinitial version of M GP GPT as a chatbot over the summer um I I think thewhole fun the whole memory uh self-awarememory editing thing came aboutpartially because functions came out atthe same time in the open API and Ithink I've been really like racking myuh had around these like memory ideasand how to handle them properly for awhile and then when functions came outum it wasn't immediately clear that youcould use functions for this purposelike self-editing your own memory but Itried it out and I I remember it workingkind of off the bat like immediately Iwas I kind of shocked at like the firstpass of this idea actually was workingrecently well um but I I will say likebroadly speaking I do think the way mgptdoes function editing or it it handlesmemory which isuh very meta it's like very self-awareright I think this is kind of followingTrends in L language models as a wholewhere it used to be that people did alot of like promp talking promp tuning alot of kind of crazy shim code plumbingcode to get things to work with promptsand now you're just seeing the themodels are getting better and betterthrough rhf and instruct tuting thatpeople just are converting their oldcode into natural language and they justput it into the prompt you just tell gp4what you wanted to do and it does itbetter than if you tried to like do somecrazy prompt to get around uh to like doit implicitly and mgpt is very much likein that direction where you could writea ton of code to handle memory and tohandle context behind the behind thisscenes but you could also just tell gbd4or whatever model you're using off likestraight up that it has memorylimitations and just like be aware youhave memory limitations and you canwrite your own algorithm given like acore set of functions on how to manageyour own memory it's up to you um butyeah I think that that meta idea is verymuch in line with like the way thingsare going with LMS where you just youput the programming into you you takeout the programming and you put it intonatural language and you just let the LMdo what itwants yeah so if we could in the thememory management tool so you have apisto appen to the working context as wellas to write to the vector database sothese or the database obviously bias ofthe[Music]we8 but like is is this kind of thegeneral like is this the correctunderstanding that you you have the kindof the operating system where you havethe system message that says you knowhey we just got to 4,000 to or 3,000tokens and then and then in that kind ofopen AI funks approach where it has thisdictionary that's saying uh here's theappend function or the the remove ormaybe like almost like a flush to diskind of thing right with with writing tomemory is is that just kind of like justto is is it the correct understanding ofthe yeah that's exactly kind of what'sgoing on so to kind of make the llm moreself-aware um you kind of like raise thelevel of distraction and you now it's nolonger like with traditional languagemodels and chat Bots even like the wayyou code them it's still very much userinput goes in agent message comes outand it's got a one-way Street or it's atwo-way street and it's a one hopoperation um I think L chain there's alot of like I guess you call like chainsthat they have that do involve multiplehops but it's still generally speakinglike this high level idea of usermessage in agent message out and if mgbtit's no longer user uh user message init's like a system message a highlecomputer OS message that goes in and theOS message can contain a user message init it'll just be a little Json thingthat says this the type of this messageis user message and the content is thisum but then we also are using thosesystem messages those OS messages tosend alerts that are very meta like youare running out of tokensor uh your attempt to try to rereorganize memory failed because youaddressed memory wrong something likethat but yeah your general understandingis correct yeah yeah I love that idea Ithink it's such a novel thing to havethat explicit kind of separation ofsystem messages and I guess maybe kindof jumping ahead of the topics we as weprepare for these podcasts but like thiskind of like the the sort of concept oflike interrupts that you've introducedinto this kind of it's it's quitedifferent from most ret Ral augmentedgeneration where you're just kind ofretrieving to put in the input now youhave this whole like you know eventprocessing whether it's entering amessage or if it's the system message ofyou have 3,000 tokens then there's alsokind of this idea of you uploaded adocument and now that kind of triggerssome processing and maybe it'sasynchronous and there's like interruptsso if we if maybe if we could dive intointerrupts I think I think the reasonwhy it would be nice to kind of do thisearly in the podcast is because it itjust really I think for me brings thislike operating system for rag home isadding that kind of asynchronousbackgroundprocessing yeah so as you're saying likewe kind of were just calling interruptslike any sort of honestly like anymessage is not a user message it is kindof an interrupt because it just triggersthe LM to get run right and in like amore like rag setting I guess I'll justsay like a data setting um not justchatting but like you have some datathat you're trying to do something withum there's all sorts of interrupts youcan imagine like like generally I thinklike I think rag is a super broad termnow it no longer just means likeretrieval augment of generation but inthe rag space I think my understandingis generally speaking you kind of youembed the data and you put it in andthen you ask questions um that's andoften like the chatbot is not even awarethat like there was this uploading thathappened um it's more that it just getsshoved into the context with maybe likea nice little prefix or something butwith mgbt it's very much I think the wayyou can like turn mgpt into very muchrag um but I think if you were trying tobuild it out in like more of the mgbtmindset it would be very much like youcan upload whenever you want to somedata store and the data store will sendout alerts to the mgpt saying like anupload started an upload finished youcan find the upload here um and now meand mgpt always has the tools to kind oflike access the database and those toolscan be as simple as just like a readcertain like a read read that has a veryspecific line line number or somethingor as simple as just a search with aquery and that query is getting putinto uh like cosign similarity on someVector store but it can also be like anextremely complex rag workflow that yousaw on Twitter that has like 10different nodes cover you know you haveto like zoom in on your phone to seelike all the details you can put thatbehind a tool that mgpt can use rightlike mgpt just it's the way to thinkabout it is it's more like a just likean agent that an a tool using agentright so um it's less about like thatit's always like very self-aware of whatexists it's kind of like a if you justhad a human in like the human is usingtools to look at data they're not likeyou know there isn't some uh injectionthat goes into your brain that likefront loads little context windows andyou're unaware of it right you are veryaware of like kind of what you're doingwith the flow ofdata yeah really I'm seeing a lot oflike um rag evaluation things and like awe we just released an async indexingAPI so it kind of has this API of likeyou know it's still indexing but you canquery it and it it kind of like remindsme of like maybe you're training a modelin the background and it's like you knowding that model you're training it'sready if you want to you know and thatkind of meta management of the tools isso interesting so maybe if we could stepfurther into your perspectives On ToolsI know you know we had shashir andTangen on the podcast and I'm such a fanof the gorilla work and my understandingshashir is on the mgbt paperimagine you'll work closely together howare you currently seeing the kind of llmtool uselandscape yeah I think so I will sayjust at a very high level I think toolusing agents is where everything is kindof trending towards um I think that isgoing to like I'm actually verysurprised that like function calling hasnot become somewhat standardized in openAI uh endpoints so a lot of people likesupport open a endpoints but like no onehas really standardized guys on like theequivalent of open open AI functionswhere you're just passing functions asthe keyword argument um so it's supportslike really lacking and the reason I'msurprised is because I really do thinkthis is like where everything istrending everything is trending towardstool using agents even if you don'tnecessarily think of your agent ashaving to use tools like a chatbot Ithink it still will like Trend in thatdirection um maybe more specific togorilla I think there's really cool wayswhere like ideas like gorilla and mgptum kind of overlap so like with me PBTand a pretty big it's not really alimitation it's more like a designtrade-off is that you're giving it toolsbut obviously you have to like tell itup front what the tools are and if youdon't fine tune on those tools you havea a big chunk of text that has to getinserted with every single inferencecall and with mgpt specifically I thinkthe pre- prompt is around a thousandtokens uh roughly that like thousand2,000 which if you're using like gp4 AKlike mistal approximately AK contactwindow that's a huge chunk of yourcontacts that's getting devoted just tolike static information that neverreally changes um so you can f tune tobe like more mtpt specific and hopefullytake those tokens out but I think maybea more promising Direction you can go inis your mgpt agent it doesn't callfunctions in function space it callsfunctions in natural language space soit will basically say like if it wantsto move data back and forth it it'ss analert or something it'll call like anabstract function or even just saysomething in natural language like heyum I want to move I want to clean up mychord memory and I want to flush it outand then that will get past like agorilla or something which can beupdated much more frequently to includelike all these new functions and nowit's kind of The Best of Both Worldsright like your mgpt agent is veryself-aware it's very meta it knows thatit's context limited but it doesn't alsohave to manage that that's already a lotto manage like this meta informationabout like that you're eliminatedcontext Transformer um and it's a lotmore to then also understand all thememory management function functionsknow the correct parameters how to runthem in a in a chain basically um but ifyou can just offload that to like agorilla then you make the process a loteasier for like the main mgpt thread andI think that's probably you know if webuild out mgpt V2 that is what it willprobably look like it'll look closer tolike gorilla plus mgpt than just mgpthandling all thefunctions I I think it's such anexciting Direction I mean uh like thekind of like describe your tool in asfew tokens as possible but it alsosounds like you're looking into thiskind of like uh in the same way you'rerotating in your context you might wantto rotate in what tools are beingdescribed in the um system instructionsand yeah well I think that's a reallyprofound Direction um I guess kind of Ithink this would transition reallynicely into kind of the um thefine-tuning of MGB like so for me thething about gorilla that I think is alsoreally really interesting is that it'sum you know like if you have if you wantto use SQL as a tool you also have thisfine-tune language model for text tosqlin the middle of that and then thatmodel can be like I don't know what theyou know the smallest state-of-the-arttext SQL is because it's like such a butI think they're at like 15 billion islike the state but like the idea beingyou can compress it to use a I know likeour wv8 gorilla is like not as big asgbt 4 but um so so so yeah that that'skind of the question I guess would be umhow you see that kind of like uh youhave I imaginemgpt uh like it's like it's like asmaller model that's managing the memorywhereas like the GPT 4 like just themost powerful thing we can find is whateventually kind of answers the questionuh with the context managed by thisdistilled um MGP I hope I didn't liketransition to yeah if you could yeah soI guess is your question kind of abouthow you delegate like model size umversus like like all theresponsibilities that you need or allthe programming you effectively need theLM to do to manage mgpt like how how doyou split that off into different modelsbasically yeah exactly so like a 1billion parameter uh meta model rightsomething like this yeah yeah Ithink yeah that's a that's a really goodquestion because I think ideally youwant um the main logic thread so I wouldcall that almost like the the main L onprocesslike that should run as quickly as youcan make it run um and even a 7 billionparametermodel uh proba might not be fast enoughum you might want to squeeze that evenfurther but I think SE a 7B modelespecially if it's quantized um it'slike fast enough so what we're noticingwith our uh the people in our GitHub andDiscord wherever that are playing withMBT with open models is that 7B actuallyworks pretty well I was like verysurprised so when we wrote the paper Iexperimented with aab Bor 70b which iskind of stay at the art at the time sohuge model takes forever to decode onlike I think I was using b100s but um soslower than it should have been but evena model like that I ran into so manyissues with it uh just with handling allthe functions and calling functionsincorrectly and stuff like that that wewrote in the paper effectively lookwe're not we didn't include results inthe paper for this because it's just sobad and I that was like maybe two orthree weeks ago right and then like aweek after that I kind of came backafter we released the paper andRevisited the new mistol fine tunes andI I was just like shocked at how goodthey actually are like they can keep upalmost with gp4 for a lot of stuff rightit's a little bit like things here andthere kind of like are a little bit offlike the inner monologue The Chain ofThought looks a little bit off sometimesbut these issues I was having with like70 billion parameter llama you find Twe're no longer there with seven these7B parameter fine tunes so I'm likepretty confident that especially if youstart stripping out the responsibilitiesfor memory management out of the mainthread and you give it to like a gorillaor something and you run these inparallel you could probably have justlike two like two three billionparameter models running in parallel andthen you get like crazy fast uh decodingspeed rightum yeah I think you can get it prettysmall yeah I think that's super profoundI imagine a lot of people who listen toum AI podcasts are just looking intothat oh the mistal model is good youknowso yeahyeah the hype hype is real I was prettyshocked atgood yeah yeah so I think um so the nextquestion I want to ask about is thiskind of fine-tuning a specific model formgbt uh you know I knowself-instructed training data you uselike the large language model togenerate the examples of how so uh gp4is op is using the mem GPT prompts andthen you kind of copy the actions takenby gp4 is that generally still kind ofthe prescription for how to get the datayeahso yeah I think there's you can do self-instruct but it's a little bit morecomplex than with Gorilla so withGorilla right uh the general inputoutput is like question to some answerit's almost like a stack Overflow kindof thing right um but with mgpt it's along running conversation generally thathas a lot of memory management injectionthat's happening in parallel kind of inthis thread and it's quite hard to self-instruct that without simulating a realconversation um because even if you havelike a imagine you collect a bunch ofdata from um some whatever websites thathost like long gp4 chats so you'reforgetting about licensing you don'tcare about the licensing you just wantto get it get it to work you can likeget that GPT chat GPT gp4 data and thenannotate it backwards with like fakememory uh management stuff but it stilldoesn't quite look like the what you getwith mgpt running for like in a realsimulation so it's kind of like thesimulation issue I think the best way tocollect data from mgpt is you you dojust simulate a conversation you havegbd4 talk to gbd4 or like a very goodmodel talk to a very good model and oneof those models is me GPT and the otherone is a fake human umbut yeah it's also I'd say withcollecting this sort of datait's I at first I thought you might needa lot of it um when I was looking at howbad llama 2 70b fine tunes were but thenwhen I look at how good some of themistal 7B fine tunes are I don't thinkyou actually need a lot of this data umbecause it's close enough and Ithink yeah you you both don't need a lotof the data and then also you might beable to get away with a lot of uh likeher istics on the the parsing side whereyou manually correct mistakes that theythat the LM made when it generated Jsonand you know I'm sure that's like whyfunction calling is so clean on openeyes end is they're not just giving youback exactly what gp4 has sped outthey're like cleaning it um with a tonof you know stuff that's why you don'trun it like Json errors thatoften yeah so just doing similar stuffto that I think can get take you areally longway yeah I'm definitely not an expert onthe structured output parsing I think iswhat they call it things like pantic wehad lmql Luca Bor hner on the podcastand yeah definitely some things whereyou can you know decode only curlybrackets to begin and and things likethat but um yeah I think that's reallyprofound what you're saying about thethe data need and the trends in that andyeah all all that kind of umfacilitating the kind of compression ofthe open source models knowing you needless data and all that um so I guesskind of my next question on this um youknow the training of these specializedmodels is um like I I think I I listenedto shashir on the Run llm podcast aswell talking about uh like it takes likean hour on 8 v100s or something likethat I always would love to get thiskind of technical detail like how muchit costs and yeah yeah I guess the thenumbers that we are very familiar withfrom the mgbt work is openi API costnumbers those are like soulle crushingforgbd4 so yeah I think just to likereplicate the experiments of the paperwould beuh like just to regenerate some of thefigures you made like sever it's almostlike several thousand dollars per figurein some of the cases just because youhave to do so many gbg4 calls and uh onething like we made a pretty umdeliberate decision when we released sowe released the code we also releasedthis Discord chat but um partiallybecause that code had already beenwritten it just had to be refreshed wasusing the same Concepts but we we made apretty deliberate decision to only putthe Discord chatbot on gp4 like lock togp4 because at the time and still now umthe performance just with open models istoo it just fails too often and you havea lot of people who are just uh likeprosumers or casuals they kind of wantto see like mgpt as a peak into thefuture of chatbots and we don't want tolike corrupt this stream by like showingthem what even though it cost a lot ofmoney we want to show them like the realfuture right we don't want to show themlike this thing that's just likebreaking throwingerrors but the flip side to that is thatit's really expensive so like I thinkwe're using by default it's G to be likegp4 AK and might be misremembering but Ithink gp4 AK if you hit the full 8Kapproximately context window when yousend the inference call to open AI it'sgoing to cost like 50 cents or somethingum and the way mgpt works is it's likeconstantly it has this like bufferthat's filling up and it's constantlytrimming off the buffer um but thesmallest the buffer will ever getusually unless you're very aggressivewith your like data management constantin the code is going to be like 3K soyeah that's maybe like 25 like 20 to 30cents or something per call and this isjust per call and then with mgptremember it's like an OS design so youcan run a lot of calls behind the scenesjust to answer one call so you can justhave conversations that are like you'rehit $1 here $1 there it's extremelyexpensive and that's like the real costfor running this uh the way it looksbest but if you're talking about finetuningI actually don't think the fine tuningwould cost as nearly as much as gorillabecause like I said these models likegorilla was on top of llama at leastinitially the the models like if youjust find two on top of dolphin mistolor something like that I I really don'tthink you need that many epox umespecially if for data is clean to justkind of do a little bit of coursecorrection on the final outputs to makesure they're a little bit better Jsonthe functions are a little bit moreconsistent but I'm pretty confident youyou don't really need that manyresources yeah it's so fascinating Iremember like uh Aiden Gomez talkingabout like large language models arelike kind of like the new cloud and youknow hearing that you know big Labs likeUC Berkeley are you know the cost is inthe inference call I I don't think I'msaying anything new here but just likeanother example of that and yeah it's sofascinating hearing about uh the Discordand how you see that like give them thebest experience versus the open sourcewhich is a cheaper and and yeah I lovethat kind of uh you know talking aboutthe latency when you have to do allthese background tasks and there's somany interesting topics and I hope thisisn't uh pivoting the the conversationtopic too much but I wanted to also divefurther into this kind of explicitcontext annotation like you one when Iwas reading mgbt one of the papers thatideas that instantly kind of caught myattention was this like uh explicitseparation of the context like this isthe system instruction this is the chathistory and then this is the workingcontext and I think that's quite aprofound idea because if you have youknow like a role playing chatbot whereyou you know this is how much you haveto describe your role this is like abackground information on like you workat we8 it's a vector database companylike just some like this kind ofexplicit separation of the memory um I'mcurious if that's like a big thing foryou if you're really curious aboutfurther you know granular rizing I don'tknow if that's a word but that like isit gets 32k context length if it if youcould see it having like eight sectionsof memory or if that's just kind ofparticular to the mgbtdesign yeah I'll say I Ithink when we were initially when we didthis initial split like when I wascoding initial Discord bot and I I splitit into Persona and human I think thecore working memory section I alwaysfelt like that was a little bit uh likethe the bot should be able to do it dothat itself right it's a little bit oflike a hack to kind of lead it in theright direction um so I always Envisionlike it just being a big scratch pad andkind of in the same mgpt direction ofjust giving the bot freedom and liketelling it being very meta you justtelling it what the scratch P is for umand just letting it to the rest as themodels get better and better atfollowing instructions I thinkeventually yeah I'm not sure if youreally would want to split it up toomuch I think what you what would whatwould be really cool though is one thingthat's missing from mgpt harshly becausethis wasn't built out as like acommercial product if it was as like aresearch product so we're trying todistill like the the ideas as simple aspossible to keep the keep it very cleanbut one thing that we could have put inthe chatbot version is uh a ragcomponent so like I think what a lot ofpeople call Smart context but you haveboth the working memory scratch Pad butthen also a separate section like afourth section of memory that's pinnedthat is also like rag context that getspulled from the DB all the time and yeahI think if you were to like take mgpdcode and you want to build out a realchatbot service on top of that you wouldadd that that is something you shoulddefinitely add um you should not uh andthat would just that would be anotherfourth part of the memory but in termsof breaking up like the human andpersonal blocks evenmore I you could yeah I guess if you'rereally trying to build something forPure just performance right now like getthis to work as well as possible I havevery specific demands on my applicationyou might start to divvy it up I thinkif you're just building for the future Ithink you try to keep it as general aspossible yeah you you brought up a pointthat I really wanted to clarify so I Ialways thought one of the most profoundideas of mgbt is I'm parsing through therag results and then I'm uh kind of likeexplicitly saying let me grab that factand put it in my context and and thenyou have to so so so right now what itdoes is it's got these three parts ofmemory and then it's looking through therag is just kind of like here and it'sgot these actions on how it adds thatinto memory and yeah I think you alreadykind of described how that might workbut yeah yeah I mean what you describedis exactly it basically so for um forlike a kind of heavy what you anticipatelike a heavy query task um so maybe youhave a question that you know under thehood is going to require touching like abunch of different documents what you dowith mgpts you prime it's uh I guess youcould either put it in Persona or userthis is why the distinction is a littlebit odd when you start to talk aboutdocuments it makes more sense for likerole player chat but for documents youbasically somewhere in the workingmemory you tell it with a pinned messagethat this is your task and you shoulduse this you should use the space tokeep notes as you work so it doesn't getflushed out of memoryand then just like you said mgpt willkind of make queries here and there umkind of refine its queries depending onthe results it gets page through thequeries and then slowly update itslittle scratch pad and then eventuallywhen it kind of finds the result it cansend a message back to the user with uhyeah with the result that probably itkind of like collated eventually intothe working memory um but yeah that's Ithink what you're describing like thatworkflow or like the way mgpt willactually like gather information you ismaybe a good way to uh distinguish itfrom like traditional rag pipelinesright yeah and I guess um the so the themultiple documents thing answering aquestion on each of the documents islike if I ask what's the Q4 earnings ofuh ride sharing companies I think that'swhat Jerry uses for that it's like so Icould imagine you know it looks throughthe Uber search results and then ittakes the I don't know 30 billion I haveno idea how much and then it goes tolift or you know this kind of thing andyeah I think it's just really reallyinteresting and awesome so kind ofactually I think uh yeah is that yeahokay so I think that's a pretty goodcoverage of that kind of topic oh sorryI just remember so this also thisseparation of um recall and archivalstorage in the external memory this isanother thing I really wanted to uh getmore insight on is so recall storage islike just the buffer of the chat historywhereas external storage yyeah that's exactly it so yeah I alsolike each of these distinctions I feltlike a little guilty about when I firstmade them because I don't really thinkthey're necessary you know I think likein theeventual uh the end game of these toolusing agents like these distinctionsshould be made by the agent um but thereason I made it was because like tokind of help the agent along it shouldit should be able to query veryspecifically just the past conversationsbecause that is like in a chaptersetting like a ton of things you want todo with the chatbot like look at an oldmessage or look at a message in a timeframe if you're at the chatbot or thehuman um just like think about how oftenit might not be that often but probablyyou do do it sometimes like goingthrough a messenger or whatsap uhconversation you like you're scrollingup or using the search function to findsomething that's like the what we wantedto give the agent the ability to do butit's even worse for the agent rightbecause for you and I like whensomething leaves the window on WhatsAppyou probably like have it roughly inlike short working memory right for thellm it's immediately gone it's likecompletely vacated it thoughts so it'seven more important to give it theability to specifically just scroll backthrough uh conversation and thenarchival memory was supposed to be justthe Overflow for like storing generalknowledge so I in the paper we reallyjust tried to keep it as simple aspossible like what's the simplest way tojust store information that's notimportant enough to keep in like AKtokens or not AK that's the whole thingbut like maybe 2K tokens in the workingmemory simplest thing is probably just alike a text database that has um likevector DB indexing or something and thenyou retrieve with cosine similarity andthat's basically what we released aslike the default implementation but fora lot of people that want to use mgpt tolike uh they have their own data theywant to bring you can absolutely justlike swap out that archival database andinstead you put in your own database andthen you tell mgpt up front um in thefirst instructionlike hey just so you know I connectedyou to an archal your archival databaseis now holding all the SEC filings orsomething or it's now holding all of themy email or whatever so that's veryswappable the recall thing is veryspecific to just messages or messagehistory onlyyeah yeah I guess um for me I'm tryingto understand the difference betweenexternal storage as like a tool kind ofcompared to it as this um you know as itbeing in its own Silo of the diagramwith the kind of in context memory andbecause I I I think um you know youcould you could easily think of it as atool to look at my external storage ormy or just do like a Google searchrequest and then maybe add that to mythat's kind of what I see yeah sorry ifI'm going all over the place but thisthat's kind of what I see is the valueof these chat Bots having their ownprivate kind of vector database is likeif they want to do ride sharing earningsresearch and then they want to store itthere so that then it's like kind ofmore accessible for the future as youknow like as we have like our personalnote taking that's something I thinkabout a lot is like I have all theseparticular notes that you won't find onthe web and see I I'm I guess I'm verycurious about this kind of externalstorage whether that should be thoughtof as a tool or yeah maybe if we coulddive in further on this kind ofinspiration from page replacement likethat I think that's another one of theseanalogies in the paper that reallycaptures people's imagination um can youmaybe just from the high level of whatinspired you to kind of you know compareit with this kind of page replacementand that sort ofinspiration yeah I think so pagereplacement I think is a little bit oflike a rough analogy with mgpt becausewe aren't doing like huge blocks blockswaps of like context data in generalit's like very much this rolling bufferthat gets with like an eviction policyan eviction policy that we Implement bydefault is a recursive summarizationjust so that it's like on par at thebare minimum like the floor of mgbt isgoing to be like a chat GPT kind ofthing with recursive summarization onthe back um but yeah I think the acloser analogy or the one that's likemuch much closer to what actually isimplemented in mgbt is just like theidea of paginated reads so like when youwhen you take reads from your externaldata sources just because of the natureof you being a limited context llmspeaking as like the llm um you cannever just read an infinite scroll or aninfinite stream you have to paginate itum and paginating it allows you to likehave very discret warnings too like whenyou go when you're about to go over thelimit if you just imagine like streamingthis to the llm I you could probably dothat but you would probably run intojust like things would start to breakdown pretty fast but if you have a verystrict pagination system where you onlybring in like onek of context at a timethen you can as long as like any of yourdata sources support this paginationformat then you can just connect it toit right it's like a kind of a universalinterface of just paginated text um sojust as long as you can have like aGoogle search style pated search overany data source you have it's just likea universal connector tomgpt yeah I definitely want to come backinto the search actions pagination youknow as you mentioned like in the paperyou you see eight search results and yousay hey actually this query wasn't sogreat let me yeah exactly but um um thiskind of page swapI'm really interested in this like roleplaying language models like multi-agentsystems and I think maybe that's wherethe operating system analogy comes inwhere it's like I impersonate CharlesConnor maybe shashir like Bob you knowand it's like I'm rotating in and outconstantly this kind of context and thenI can imagine you know the kind of likephysical memory optimizations that go inwhere you have kind of like you'vebrought these personas into you knowcached memory and then you're just likeyou're now Connor you're now Charles sonyeah yeah that's actually a pretty coolidea so I think you could make so rightnow the way mgpt is coded or the promptsare coded I say like coding andprompting kind of interchangeably atthis point right but the way the promptis written um is very much about likethe agent is also self-aware that itsPersona is modifiable so it can likeupdate that was like a big thing withthe initial motivation which is alsothese chat Bots like if they're ifyou're chatting with them for a longperiod of time should up they shouldchange right the like the very basicexample is if you just ask the chatotwhat's your favorite color what's yourfavorite food it gives you an answer youask the same thing 100K tokens later itshould return the same answer right it'sit's like extremely immersion breakingif it just like doesn't return somethingthat's consistent and also you do likeif you're chatting with a bot for thatlong it should really kind of update itsown like it'll have a lot of like depthand detail that it will uh dump becausethese language models are so good atjust giving convincing text um but thatshould all be stored and like itdeveloped into a rich personality sothat's a very big part of the theprompting in mgbt is telling it that youcan modify your own Persona and youshould actively modify your own Personaum but yeah I think you could definitelyexpand that to being even more metawhere it's like you can you have aPersona bank and you also have a userbank and when a user a different userlogs in it will trigger maybe an alertto swap out the user bank and then themgbt itself can see like oh yeah Conorlogged in he likes this Persona and thenit can hot swap the Persona aswell yeah that I think that's just sucha powerful idea this idea I mean theyeah I had this conversation recentlyabout like the subjectivity of thelanguage model how it can like you knowgive you kind of like its uniquepersonality in addition to itsconversation and this idea that thatunique personality is like kind ofsomething you add to the prompt and thatyou can have multiple uniquepersonalities yeah it's all pretty um Iactually think yeah so I think we'vedone a really great I think this wouldbe actually a really great transitioninto because they're kind of alreadytalking about this like uniquepersonality of chatbots and in thebeginning of the Run LM podcast withProfessor Gonzalez you described yourwork and uh creativity and understandingthe how AI can you know help withcreativity and what creative outputsfrom AI look like and I think this kindof you know new personalities for thechat Bots I think is just would be areally nice uh transition so how I knowit's a pretty open-ended topic but howare you currently thinking aboutit yeah I guess I wouldsay yeahso I think chat Bots they struggle alittle bit less with this creativityproblem that I described in like the Runpodcast because you're constantly havinguser input right like if you have togeneralize thisproblem um maybe one way to frame it isjust when you feed an LM its own contentor when alms talk to each other ifyou've ever played with autogen um Ithink the magic kind of disappears veryquickly because you realize like oh nolike uh these agents aren't as smart asthey are and it somehow like giv thisrecursive element to it where you feedagents other agents content everythingjust goes downhill it's like they theyconverge into like this you know gpt2esque Behavior where they're all sayinga lot but they're not saying anything atall um and yeah like I said with chatBots at interacting with humans I thinkyou run at this problem less because youhave humans that are constantly kind oflike interjecting and like bringing likelife almost to the conversation andactually one thing I did try very earlyon when I was first messing around withthe mgpt chapot code was when it workwas working extremely well I kind of hadthis idea of um like a big part of itwas the heartbeats right so you mgptruns in the background and as a chat botthat's pretty cool because it can you'lllike see the time they'll get a littlealert of like your heartbeat round andit's he's the time and it might say likeoh Charles usually at 3 p.m. is at workso I shouldn't message him yet I'm goingto sleep my sleep my alerts until 5:00p.m. and 5 PM comes around it getsanother alert and it says oh he'sprobably home now I'll send him a littlelike message saying oh hey like howthings go like remember that projectyesterday you're talk about was reallyhard it's like a very proactive agentbecause of theseheartbeats and the heartbeats wereworking so well that I had this idealike oh like what if you just run theheartbeats really frequently and youthen you have an agent that's always buitself just like thinking to itself andit occurs like maybe we'll do it likeonce every 15 minutes so in reality I'mnot going to talk to the bot that muchand it's going to be talking to itselfmuch more than it's talking to me andyeah the exact problem I was describingearlier emerg is where like you I thinkmy dream was that maybe with gp4 it'sgoing to with enough prompt engineeringcome up with like these hobby or likehave really cohesive trains of thoughtwhere it like thinks really deeply abouta book orI don't know some field of study or likeits own Hobbies or like existentialcrisis or something but in realitythat's like not really what happens umand I really tried to get it to work soI was trying to emulate like I I haven'twatched this movie in a while but herlike I think the ending of the movie Ispoiler it but I think like the botthere like talking to other bots in itsown free time or something it decideslike it doesn't want to be like a a userbot anymore it's something along thoselines so I was kind of wondering likewhat would happen if I just can I evokean existential crisis this bot in itsown free time but yeah the the tldr isis basically I could not get it to workand it's the same issue with autogenwith all these things that beat intoeach other the content just kind ofreally goes downhill pretty quickly andwhat I was talking about on the Run llmpodcast was basically more about generlike an an idea for an app that's justfully generated AI content and I'm surea lot of people you know have had thisidea and like we're are optimistic aboutit and I tried to build like a roughversion of that um kind of like AIgenerated games fully generated gamesand stories like you just give it alittle nugget of an idea and it canbuild out like a fully forking pathstory that kind of thing and yeah withthat it's a similar issue just thecontent isn't good enough um it's goodat it's kind of like the uncanny valleyof creativity you know it's like okay Ican see like little Sparks here andthere but then you see the same thingover and over again and then if you tryto like apply more pressure to make itmore creative by maybe saying here's ahistory of all the stories you did youhave to create a new one this time itstill doesn't work and I think you justrun into like a pretty big wall when youtry to push these models to reallygenerate creative content on their ownand I'm not sure if I've seen yeah Imean if anyone listening has uh hadgreat success with that please let meknow i' be really interested to seeit yeah it's I I I think um for me likethe kind of like graph of thoughts umwhich I I see is like a more extremeversion of Chain of Thought where youkind of treat like potentialcontinuations of your own thought aslike a new node and you keep going Ifeel like all the research on this andas well as like kind of the communityhacking is just limited by the cost ofthe inference and so I I don't thinkwe've really gotten to see um and like Ithink what you're saying is you knowprobably a lot of people are going likeah sobered me up like hearing thattalking to each other Isn't Soeffective because I've seen things likeum Berkeley's ELO rating for languagemodels right where they um Talk to eachother and then they're evaluated by athird language model right yeah and it'sreally fascinating stuff I mean I Iguess for me yeah that kind of uh wellso aside from yeah I think to just havethe you know exploration of graph ofthoughts I'm very curious what you thinkabout these kind of like evolutionaryperspectives where you maybe have like apopulation of um candidates and then yousort of this is like an idea from Jeffcloon and Kenneth Stanley and Joe Lemanis this idea of like quality diversityand you so you kind of have like apopulation of potential uh nextresponses or analysis of or likecreative like Creative Images like theyhad this pick breeder experiment and soit's like maybe you have a populationyou can kind of measurediversity it's kind of related to likeintrinsic motivation yeah I guess thisis kind of thinking is I think you needlike to have creativity you need maybelike a population perspective and thenit's like diversity driven you knowalmost like trying to find anomalies orin cluster spaceyeah yeah I thinkit's you maybe could have some luck orsome uh some progress like a anevolutionary style approach to it uh Ithink evolutionary algorithms in generalkind of do make more sense when you knowwhen everything becomes a blackbox APIand there's no more gradients so itbecomes useful they just have likeevolutionary algorithms or like gradientfree ways topick yeah I don't I think you could alsodo more like rhy stuff where maybe youjust if it's really content that's meantto be evaluated by humans maybe there isa way to naturally evaluate it like Iknow some of these there are like a AIbought only Twitter clones um andInstagram clones I think um and yeah ifenough humans are participating and likeliking photos or like liking tweets AItweets yeah that could be a prettyuseful data set for likekind of a creative bot um but yeah Iguess my experiments with creativityhave really been limited more towardslike the clo the biggest closed modelslike gp4 um and maybe like some of thelargest open models in their fine tunesI was doing a lot of this work earlywith llama Two Pine Tunes but yeah maybebetter luck with mistol but yeah likeyou said evolutionary stuff could alsohelp um I would say overall done alittle bit uh yeah I'm a little bitbearish on the creativityAI yeah Charles this was such an amazingoverview of mgbt and thank you so muchfor answering all these little questionsI had you know I thought the paper wasso well written and it was so easy forme to kind of you know read it and givemy analysis because of how you know wellformulated the ideas are and these ideasand creativity are so exciting maybe letme if you don't mind answering this kindof anchoring questions on the podcast oflike what's on the horizon what kind offuture directions just so I mean I thinkwith cat I think this this already is sofutur looking that ask you that is likeyou know you're already telling uswhat's five years what's so like whatwould 10 years then be Iguess yeah I wouldsay um yeah maybe even just like oneyear away I I do anticipate like a lotof these platform or like morecommercial or consumer facing chop botthings to incorporate memory um I thinkthat a good reason it hasn't been doneyet because it's not entirely clear howto properly do it I think there's a lotof stuff in open source that experimentswith trying to um specifically for morelike entertainment chatbots try to userag style um thing like vector likecoign similarity on fragments to getmemory to really it's not really aboutmemory right it's more about justimmersion and like can you really bringthe immersion of the chatbot that's beentring with you for a long time into a 8Klimit model and it really hasn't beencracked yet but I I do think that kindof thing will be cracked likeindependently by like these closedSource providers they'll have their ownlittle implementations of it might looklike mgpt might look a lot more justlike smart contacts like rag um and Iguess on the API front I also anticipatelike the apis will probably becomestaple too so you no longer are justdoing like like your API calls are likeall the state you need it's state listright because everything for the call isin the package you're sending themessages the system the functionswhatever now you're pointing at Edpoints of agents that have been likeinitialized with their back by databasesum so I think this General statefulagent stateful API direction is going toprobably emerge in like the next year orso I mean I wouldn't be surprised iflike open ey talks about something likethis in a fewdaysbut yeah I think that's like the thevery near term I don't know if you wantto talk talk more about like the longlike five years it's kind of hard tomake predictions that far into theFuture these days yeah yeah no I'm sorrythat the question was too openat that's one of Bob inlight are the CEOof we he had the make the model statefulis one of his big um you knowcatchphrases that I've heard so manytimes and and yeah that kind of well Ikind kind of also in the you know Loperating system I just wanted to maybelike multi-threaded processing withlanguage models you know this like it'strying to find out what context to addto its memory and maybe it comes up withlike four queries and runs them inparallel are you thinking a lot aboutthat kind of part of it of like what Idon't maybe like concurrency looks likewith these kind of LMchains yeah definitely so I think yeahthat's something we're very activelythinking about um at Berkeley and we'reactually hoping to kind of build thisinto mgpt to um it's but it's a it's apretty tricky problem I think it it'salso tricky enough like the value ad ofhandling all this concurrency does notnecessarily immediately show up untilyou have a ton of data that's just likebeing thrown at the the butt because alot of things can just naturally behandledsynchronously but yeah Ithink also is another forward-lookingTrend I do anticipate a lot of theselike LMS will start to become look morelike os's they will have like multi-threaded or they'll have likeasynchronous processes that get spun offof like a single query and they all likecome back they're all like workers andthey return to the main thread and themain thread maybe runs on some cyclekind of like similar to CPU or it's likea it's like event driven um or like orboth like cycle and eventdriven and yeah I think that definitelyis also just like the future and I meanit also fits into this smaller modelTrend we're seeing right now it might belike a micro Trend right it's kind ofhard to evaluate what's a microen what'sa macro but I do kind of maybeseeyeah it's hard to say but like maybe ifgd4 performance just certain degreeslike kind of plateauing and now thevalue ads are coming from the differentlikeIntegrations that maybe then will signalmodels getting smaller to a certainextent right everything gets compresseddown and yeah like I said I've beensuper impressed by like some of these 7Dmodels like I'm pretty shocked at howgood they are and they yeah they arepretty they making me they're prettypromising I think so I would not besurprised if like the trend is smallermodel was running in parallel OS stylelike yousaid yeah it's it's amazing I mean thethe the ability of that to uh enablemgbt St processing as well as I thinkthat kind of creativity thing is alsokind of waiting on the smaller modelsthat are cheaper faster and yeah amazingCharles thank you so much for joiningthe weeva podcast it was such aninsightful discussion and just massivecongratulations on mgbc I think it's youknow an enormous contribution to peoplethinking about Rag and llm agents andTool use and all this exciting stuffthanks again awesome thanks for havingme", "type": "Video", "name": "Charles Packer on MemGPT - Weaviate Podcast #73!", "path": "", "link": "https://www.youtube.com/watch?v=rxjsbUiuOFo", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}