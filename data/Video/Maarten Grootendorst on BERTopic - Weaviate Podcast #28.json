{"text": "Thank you so much for watching the 28th Weaviate Podcast! This episode features Maarten Grootendorst, developer of the ... \nthank you hey everyone thank you so much for checking out another episode of the wevia podcast I'm super excited to welcome Martin gruchendorf to the podcast uh Martin has created this incredible uh Library educational content around Bert topic so this idea of topic modeling using an analysis in Vector space to extract high-level topics to understand what is in these Vector clusters and what makes them distinct from each other so firstly Martin thank you so much for joining the podcast oh thank you thank you for having me here I'm really looking forward to this awesome man so could we dive into the I think it's about four steps to producing the bird topic analysis could we kind of walk through the algorithm yeah yeah of course uh uh so generally four steps uh depending on your view a little bit more and extend it to 10 or so but let's keep it straight forward um so so what often is happening is if you get a bunch of documents right there are maybe a few thousand hundreds of thousands millions of them especially in the context of we V8 for example there can be many more um we embed those we need to have some sort of numerical representation and I'll go into that a little bit later but it really doesn't matter necessarily which type of embedding technique you use that kind of depends on the use case so when we have that numerical representation it's typically in high dimensional space right and uh that's generally fine because it gives a lot of information about the document but doing something in high dimensional space can be tricky so before we go to the clustering step which talk about a little bit later we first reduce the dimensionality of these n dimensional factors that typically works works out well it it can be a time consuming step so that's still something we need to take into account um but it makes sure that some of the the global information is you know is being kept in low dimensional space where we don't have the curse of dimensionality where we can use even euclidean distance measures with which obviously we cannot use in high dimensional space so so we can do something with that um after that we're doing the clustering the dimensionality reduction of course is done with umap which is now currently you know mostly state of the art there and the clustering is being done with hdb scan it has the nice property of of generating outliers but that depends on the use case because not necessarily everyone agrees that it's a nice feature to have right um so so then you have clustering so I have these three initial steps we have clustered our documents into semantically uh uh into topics with semantically similar documents and that's nice and all but then we need to do some extraction of these topics to get some representation out of that and there are quite a number of techniques that you can use for that but from the context of per Topic at the very least um we wanted to have something that doesn't necessarily make a lot of assumption on what happens before that now if you take hdb scan for example it's in the name it's a density-based algorithm so these clusters decant they can be circles they can be lines they can be squares or anything you can imagine um and because they are so different in structure we wanted to have a topic extraction method that doesn't make any assumptions on how those how those clusters might look like or might not look like with the ID of later introducing modularity but again that's something for later so then we resort to something that has been done quite for for quite some time and it's just a generic bag of words approach with the small Twist of not considering documents but considering uh topics instead clusters so to say and same thing applies with the the CTF IDF that's done to score these words again we're not looking at individual documents because we don't necessarily care about those but we're more interested in their abstract Global representation so also there we focus on clusters instead of documents and yet those four steps are essentially how birdtopic works yeah and I'm sorry to distill it into just four I think this is kind of how we've been starting to wrap the foundation of we being where we have you know embed the embed the data into vectors using say a sentence Transformer then uh compressed into mentality with umap or tsne hdb scan clustering and then concatenate the Clusters into cluster documents and then extract and then you say TF IDF to get the keywords I just kind of been my Foundation guiding thing uh I attended to talk at cohere where you presented this really interesting diagram of kind of the building blocks of this and you touched on this density based clustering compared to k-means you might quickly just touching on that a little more say the difference between uh you know what after you do you know vectors then umap and then say hdb scan versus k-means how they have different structures you mentioned say you know circles in your data could you explain that a little more the difference between those two clustering algorithms yeah sure so um an assumption of hdb scan or not necessarily an assumption it takes into account that certain clusters can have different forms and shapes and sizes and um you know it works rather well when you have a piece of data that starts here and goes all the way up to a certain other point and it follows that density along the line and using that it can essentially make sure okay we still have that cluster because it's difficult to capture those clusters that aren't necessarily in in one side small dense structure okay means does something entirely different and basically draws lines over all of these uh clusters and assumes that everything within you know let's say square or certain form that the very centroid of that is the most representative of that cluster and hdb scan doesn't necessarily have that assumption so when you for example extract the centroid from a cluster found by hdb scan it doesn't necessarily have to be the most representative one because you know if you have a circle so all all points around the circle and there's one single point in the middle and see this game most likely will find all of those maybe not the the middle one but if you take the the centroid of that it's not really representative of everything that happens on the outside right so then a centroid based method for topic extraction doesn't work it might work if you use gay means because that assumption is more built into the algorithm but we don't care about you know all of the assumptions that all of these clustering algorithms have there's way too much taken to account so so we separate them yeah that's a super interesting Insight the uh you know say the circle shape with the dot in the middle and this sort of describes this idea of Representative documents so what might be the problem with that where where you also love the example of the line and if you have K means it's going to try to like cut that up into four parts of the line with the centroids yeah wow so the the density thing is incredibly interesting uh can we maybe touch on the final product the keyword listen and come back to the hierarchical the topic trees but um so so as we you know concatenate each cluster into a long cluster document and then we use tfid you have to find the unique keywords I've seen ideas like setting the topic labels where you go through the list then you find the label through it can you talk about sort of what you get by doing that when you when you go through a list of keywords like say medicine Healthcare and you say okay let me call this the medicine cluster uh Sports basketball baseball the sports cluster I can talk about that kind of idea of setting the topic label and how that helps search through the keyword lists yeah of course so so the thing with topic modeling is that's a rather subjective technique right it's uh first of all it's unsupervised so it's really hard to have a ground truth and objective evaluation metrics and the second thing is what you consider to be a topic I don't necessarily really agree with now the the entire idea of having all of these words in in a topic description helps you understand oh this is what the topic really is about it already already provides you with some context about you know what you can find in that topic because if you would give it a single topic label like like sports I still don't know what we're exactly talking about in that topic so there's a lot of human evaluation um a human in the loop is still very necessary in these kind of techniques because I can give you some sort of description but you still have to interpret it yourself and understand what the topic is about um and I think that's very important with these kind of techniques because people tend to look for evaluation metrics and then do some grid search on that and find the so-called best method that that really doesn't work in topic modeling you can try if you have a very specific use case with a very well defined evaluation metrics but even then it's it's so subjective that the person really is necessary to do something with these words and these labels and you know ideally create them theirselves yeah is that human in the loop I've seen ideas like use like a gbt3 to try to guess do you like that idea yeah yeah I've heard that one before of course I mean it makes sense it's it's text generation so if you provide it with either some of these words or perhaps some of of the representative documents whatever those might might be then you can get some sort of description from there the difficulty here in lies um you know gpg isn't always necessarily that accurate in creating topic representations it's not specifically trained for that um from an API and and open source development perspective you would need a very large gpt3 model in various languages on top of that which you know makes it not really that easy to use out of the box so hopefully I can provide a basic pipeline where you can tweak and change whatever it is you want and if you feel like you need gpt3 to do some fine tuning go at yeah it's really I think maybe the idea is like with the few shot learning we could give it a few examples and and maybe that would work um but really I I find this idea of labeling the Clusters so interesting with with say uh with say the way that we search through Wikipedia articles we vectorize each of the paragraphs and then we still have the title of the article as like a symbolic filter so you could ask say uh what year did Barack Obama become president and you can filter that by having article Barack Obama is the title and then that helps reduce the search space a lot so do you see maybe labeling these clusters with uh with the summarization of the keyword lists I guess as being a way to similarly kind of say just search through this cluster and unsupervised yeah you could definitely the the one thing to note here is is that you had need to have some ID beforehand what you're looking for uh with topic modeling that isn't necessarily always the case you know you have uh tickets for some software hundred thousands of tickets and you just want to see what's in there without any guidance okay then it's completely unsupervised um with few shot learning of course you can say okay I have some ID I don't necessarily know the entire thing because otherwise it's a classification task but with few short learning you can then say okay I have some ID let's see if we can do some semi supervised view shot learning on top of that but then again you have to define those labels very well beforehand because if you don't uh again then it becomes difficult I've always been I haven't quite wrapped my head around how semi-supervised Learning Works in this sense do you mind explaining that a little more and I think that would be a great topic to go into so there there are roughly two ways to do semi-supervised uh topic modeling and the thing is with your topic I'm trying to keep it as simple as possible without any without making way too complex for the user the first one is a dependency on umap new map in itself does some semi-supervised dimensionality reduction and by leveraging that uh you know hdb scan finds those uh those things rather well the other thing you can do is essentially saying okay I have a topic that I know is in there it's about sports or whatever and then you create some keywords or sentence yourself and you embed that one and then it's simply a cosine similarity with all of these documents and searching for the ones that are you know that are above a certain threshold and simply say okay I know these labels uh those are these in these topics um and then you average them out by nudging it a little bit more to the topic that you have to find yourself and by averaging out those uh documents towards that specific topic most likely something like hdb scan will capture it so sorry for misunderstood so you try to embed a single word so say um you know I I'm searching through my tweets and I want to have like deep learning let's say a single phrase so I embed that into the same Vector spaces the sentence Transformer is going to vectorize the tweets and then I use the nearest neighbors of that to say this is a topic and then hdb scan like it can take that signal to kind of structure the whole Space around it sort of yeah so what you're essentially doing is um you embed them in the same space and when you find documents using some sort of nearest neighbor approach that are very similar to deep learning you average the embeddings between that document and the Deep learning and betting and every effort to them and use that instead of the original you know document embedding then you nudge it slightly towards the Deep learning um input and if you do that with a certain amount of documents hdbs can of course will pick that up because you kind of have notched it towards the same embedding hmm yeah I think that's incredibly interesting and it kind of is inspiring my interest further in this idea of say kind of recursive partitioning like where first we have all of our data cluster cluster and then we want to go with it so say it's all of Wikipedia and we have like sports history medicine and then we want to take the medicine cluster and then do it do it again and now it's like different kinds of medicine how do you think about that kind of recursive verb topic like keep going into the Clusters when it's really big data so so so that's something that you can actually naturally do with of course hdb scan but because within their topic we're not trying to be too dependent on a specific clustering model it's a post-hoc analysis so what you can do is you can say I have 100 000 documents I want eventually some fine-grained hierarchy in that so what we do is we say with okay means for example we're going to generate a thousand or or five thousand small topics and after we have created those 5000 topics we we simply do some sort of hierarchical analysis on top of that the the exact one that you want to do that that's up to you of course um and build those 5 000 topics up until you get you know less and less and less and less and then you can slice them at different levels uh and from there extract the hierarchy that's in there and zoom in whenever necessary so instead of going from one topic to very small ones we're going from very small ones to a single topic uh so so when you you're concatenating each cluster to make the cluster document that is where how you run the tfidf algorithm to get the keywords so with the hierarchy is each small slice the inverse document frequency is compared against all the data we started out with or sort of like its neighbors in the tree on the same level so to say so so essentially what we're doing is we have with the CTF IDF from those 5000 topics we just have a a topic to our Matrix with some scores and within that topic term Matrix we're essentially comparing which ones are most similar to one another and we iterately iteratively merge them and at each step of merging we get another layer and get another layer again another layer um and because we've already done the clustering whenever you combine two topics uh together the only thing you have to do is recalculate the CTF IDF representation you don't have to do anything with the clustering whatsoever because the CTF IDF is based on the documents not necessarily on the Clusters that's just split and if we know which Blitz to combine we just recalculate the CTF IDF representation and you have your new higher abstract cluster could we step one so the way the topics are merged do you mind sorry I'm not cut the way that it's merged just one more time yeah yeah of course so so what we're essentially doing is you have for each topic you have a vector right uh in this case it's a sparse Matrix uh for for the entire topic term Matrix um but for each topic you have some values and we have 5 000 topics some are bound to be similar to one another especially if you use just cosine similarity between two topics you get certain topics are very similar so if you do simple linkage some hierarchical linkage what you basically can say is okay I'm gonna search for the two topics that are most similar to each other and these two topics I'm going to find the documents for all of for for both of them and I'm going to combine them together into one new long document and then recalculate the CTF IDF representation and if we do that plenty of times uh then we suddenly get a little bit less uh less topics and uh more abstract and more General representation super interesting and and yeah that way of the unsupervised kind of sub-population Discovery is so interesting uh can we talk also about generalizing this to image embeddings or say we have a vector that describes the image but then we also maybe have some text for each of the image too like captions or maybe it's linked to an article uh can you describe how we could use this algorithm to explore other kinds of vector spaces like yeah like image vectors Maybe audio vectors would have an Associated text yeah so so what were topics essentially doing is saying okay look I'm gonna make the clustering step in some way independent from the topic extraction step and what that means is that we normally say okay I'm gonna convert my documents into some sort of numerical representation through language models but what if we have other metadata that we can cluster instead well we can simply throw those in instead of you know the document embeddings and cluster whatever else is interesting and whether that's metadata or images for example doesn't really matter again we don't care how we do the embedding extraction step we just want data to Cluster and whether that's the document embeddings or images that doesn't matter and then when we have clustered all of these data whether that's images or text or streaming data or what have you then we take the documents for each of those clusters and do the topic extraction step so so what you essentially can do is you can say beforehand that you want you know images to be clustered and those can be from uh you know booking.com or Amazon or whatever you know what have you and you cluster dose instead of the the document descriptions and the great thing about that is is that you know an image typically represents one sort of concept one sort of topic and with very long documents that's not necessarily the case then we get a lot of different topics and we have to split them into sentences and if you do the images you know you get one thing and then you can use the documents and see which parts of that document mostly represents that image yeah I think that idea is super powerful the decoupling of clustering and topic extraction slash kind of metadata analysis like if we have patients we could uh put say their uh you know like images like medical images would be a good one to vectorize or I don't know maybe we have like clinical notes so we can vectorize and then we'd also have the metadata like age weight height pre-existing conditions and so with also this cluster analysis we can you know have these sort of like histograms uh yeah all the violin all the kind of things for each of the metadata each of the Clusters as well do you think about that kind of thing also like symbolic data visualization achieved through the clusters of metadata on them oh that's interesting especially the the example you mentioned with with clinical data so if you have a number of patients uh and you cluster dose instead of um the text related to those pages you can say okay we have found certain subgroups of patients and within those patients they typically talk about decent decent these topics and that might make it you know even more interesting to do things like that it's more Advanced Techniques so to say so I haven't actually seen it being used like that but yeah I mean when you do a fit transform you provide documents and some sort of data typically embeddings but throw in your metadata I'm very curious to see how something like that would look like yeah I sort of brought this up accidentally but one of the questions I have written down to ask you about and I think we'll come back to the technical questions after this is uh so you're also a psychologist do you use this in your work how have you found like has this kind of been inspired by that uh of to certain extent so there's a lot of psychology that indeed tensed up back tends to to get back into the package itself and it really comes from making sure that it's to use that you communicate things properly um API development things like that without necessarily looking at what is state of the art or what is best it's really practical approach so to say and it really stems from my own needs when constantly needing to install different types of topic modeling techniques for different use cases which it can be difficult at some point because if you install if you pip install a it has a different feature set then you pip install B especially when you compare for example a hierarchical topic modeling with Dynamic topic modeling they typically end up with two entirely different topic shots and then I cannot combine them or compare them or you know and that makes it difficult and um I then start to focus okay what do users typically want to be using for for these kind of things what makes it easy what makes it simple what makes it fun maybe um so at some point I figured okay when we create a topic model I want to have included Dynamic topic modeling hierarchical topic modeling semi-supervised topic modeling uh online topic modeling if it's possible uh just make it if possible a One-Stop shop for topic modeling so that you can create a baseline with everything you you do and then if you want there are more specialized topic modeling techniques that you maybe can use for very specific instances that's fine but this should provide you with with most things needed inside of a topic model um so so yeah I've mostly focused on things from a user perspective what do users need uh what do they want if I hear about a feature in in the issues page typically I write it somewhere down and see if I can create it um so yeah it typically it often tends to get back to the psychological background into development and Communications and documentations and things like that so is it like with the perspective of looking through psychological literature uh and trying to break it up to keep up with it because I know like with trying to keep up with machine learning literature it's pretty exhausting so I would love something like this to yeah no that would be perfect but unfortunately I haven't found a way to do exactly that because I've I agree fully with you that it's exhausting to keep up with literature I mean even in a very specific soft field like topic modeling it's it's oh it's so difficult to keep up and we're of course in a very large natural language processing domain which gets even larger when you consider machine learning and the transition from Transformers into computer fission all these other types of fields uh no I mostly focused and that's my my pragmatic approach on things that I can use right now so state-of-the-art is awesome state of the art is great and at some point uh you know it's necessary because that's those are the things that we're going to end up and using but I really like to focus on the things that I can use in practice the things that are performant um that simply work but to get back to your original question I've mostly used topic modeling not in psychological domain but now mostly in uh in clinical research yeah super interesting and I I want to come back to you mentioned Dynamic and online topic modeling which are two topics I know you understand that I'd like to ask you about but uh kind of on this topic of applications also I I think this kind of sub population identification could be super useful for the general thing of generalization testing with deep learning where we want to know like what is in distribution what is out of distribution and uh say we you know put our data through hdb scan and then we only train on data that isn't defined as an outlier and then tested on these outlier points or different kinds of ideas like that where you things like say you train in one hospital's medical images then you test on a new hospital and the Machine learning model fails you think about that kind of generalization testing as a application for this a bit uh generally topic modeling is approached as in a very explorative uh way of getting to understand your documents um it really helps that you understand okay this is my data these are potential clusters we can of course use hdb scan to get more to the very core of these topics but it often throws out a lot of documents that yeah could be or most likely are in um in the cluster so it's rather strict from uh from the default settings which is fine because it really depends on on your approach but there are more and more packages that I've seen developed that focus on on the explorative approach of essentially bird topic so creating a 2d representation and do the do labeling yourself and see if some things make sense um so that's that's what we're topic for example also gives back to you there are visualizations where you can have a 2d representation of the documents and the related topics uh and there are some other packages that go beyond even that where they say okay now that we have those potential topics let's see if they make sense let's label them ourselves um so that that human labeling becomes more and more important yeah that's extremely interesting I I think also I hope this isn't too tangential but like this exploratory data analysis I think it's really useful for like data cleaning deduplication when I first saw vert topic I put the chord 19 data set into it and then I saw I was like oh I didn't even realize there were languages other than English in this data set until I did this because I didn't really like look through it because like when web scrape data or are you talking about like going to PubMed and getting 300 000 papers for your data set it's like you don't really know what's in it and so yeah exactly and and I think that's that's also something that has gained popularity over the last few years right the quality of the labels that you have and what what is it exactly in all of those standard data sets that everybody has been using and nobody knows really if there's something in it that shouldn't be in there I think even the 20 News Group State the set has some has some Dutch articles or some Dutch language somewhere in there that I found recently you know know these kind of things are important because we're using them constantly in research and we don't always know exactly what's in there so to give to use such a method whether it's per topic or something else to have an idea okay but we're missing this information or these labels potentially shouldn't be in this cluster but or in this class what should be in a separate cluster or are they connected to one another that kind of information is is way more important than I think people realize mm-hmm yeah and with like this self-supervised language modeling where yeah you have unlabeled data but the quality of it yeah it's not like the UN like the quality of your labels in the same sense of like an ner model where you're like labeling each thing but you still want to have good data for the language model yeah yeah exactly and uh spending time on labeling a little bit more than you do on fine-tuning your model I think that you will get the main advantage of going through your data understanding what it means uh those labels are exceedingly important because they are often in other subjective still in a way because you look through a document and you give the label no I I mean that's that's my interpretation you know and another labeler might disagree so spending time on these kind of things is just important yeah that's do you see that a lot of disagreement within label it like you have a list of keywords right and then to to psychologists would disagree with what the list of keywords that what it would conclude to so yeah so so it's not necessarily that I see psychologists a lot with topic modeling uh I see that more in policy and politics but what you definitely see in Psychology quite a lot is uh now if you have observers that observe certain Behavior if you're a certain data or certain things that that humans do that that need human interpretation yeah that then we need several people making that judgment to see if there's an overlap and if two or three don't agree over the same instance something is going on at the very least we can say it's not a very clear label or something that isn't uh clearly defined or cannot even be clearly labeled and as such we can say okay it's an outlier or it's not something that represents the thing that we have in mind um and that's also something that indeed you see more and more popping up in Industry so so Prodigy is doing amazing things with the with the labeling tools um and I think that's where it needs to start looking through your data seeing what's what's happening there ideally if you have the time have two people look at the same date and see if they come to the same conclusions if they understand the use case well and understand what the label should represent well because you know if we talk about certain labels I might have have a certain Concept in mind because of my history and experience with that concept but your experience with that concept might be different so you know you have your own subjective experience involved in in labeling and in a way we might need to throw that out or you know average them across labelers people who look at the data um a jacket yeah I think the idea of across human labelers and then there's also this interesting idea of having multiple models embedding spaces so this topic of like domain adaptation like if I embed my core 19 data set with the all mini LM L6 train on all sorts of data like compare like the general model compared to the one that's been trained directly on PubMed papers and I look at the topic spaces of two different models have you explored this kind of thing yeah so that's also often what you see happening with something like the topic is that there are a lot of embedding techniques that you can use and I should benefit to that because you know you can use it for your specific use case and you can check what what fits but there's also the disadvantages which that with that in that you know you can end up with quite different topics and uh then the question Becomes of course which one is correct now the definition of correct as we mentioned is difficult because who decides what is the correct topic and who doesn't but the main thing here I think is that you consciously and purposefully choose which embedding technique you use and you know some might represent it better than others but it's you who choose for a very specific method for very specific reasons and that can be because you have fine-tuned the model on your specific data and you've tested it with a pre-trained general model that doesn't capture that domain as well as you thought it would um you can also throw a lot of models you know in in their topic or something else and see what comes out but then you run a little bit the risk of you know choice overloads you have so many choices you don't know what what to do and what to choose and then you know I give a lot of um responsibility to to the users it's up to them to decide okay I'm gonna use this model for this and these Reasons I'm you know trying to motivate the users to really think about Which models are you going to be using and why are you using that specific model do you understand the model do you know that when you use you know uh TF IDF as your input documents that you're constrained with your vocabulary but if you use fast task fast text you have a little bit more you know flexibility with respect to those words and if you use long former then you can use a little bit longer documents instead of you know the regular Transformer models that that have small token limits and if you use certain sentence Transformer models are rather fast and and others are very slow uh the ones are some are more accurate some more are trained to more data this is tricky and it's sucky that there isn't a single solution but that's just the way it is um and as such it's up to the user to really dive deep into okay this is my data and for this data I think this type of embedding more would work best yeah it's extremely it's such an interesting interpretability of the models to see where how they're clustering things what they think are the nearest neighbors of things and so something that I want to pick your brain about also is how do you evaluate the topic models that there are benchmarks this is the different things yeah so I've gotten this question quite a lot before that's all right because whenever you you know develop a model people are gonna ask is it accurate is it performant is it doing what what we want to be doing and my answer is also it's always uh you know maybe not the most fulfilling answer but it depends because what does it mean to have a a good topic model does it mean that the topic coherence is as best as it could be so that the topics you know are easily interpretable by by humans does it mean that the right documents are are clustered in the right clusters does it mean that it's performant you know I I we could maybe create a model that runs for two weeks or create one that runs in a few hours um there's also new valuation metric we can optimize for diversity for topic diversity uh we can optimize for add depends also on on the underlying algorithm right if you use something like a means how many topics are going to optimize for and what does it mean to to have 100 topics versus 50. because you know for some use cases you just want 20 topics or so and with HTTP scan you kind of have to tweak to make sure you get roughly around that 20. and you can fine tune based on that so so it really depends on the use cases but what I would generally recommend to do is talk with your stakeholder stock with your audience talk with the people who are actually going to be you know using this model reading about this model um they are the ones who need to do something with that so for my use cases in in clinical researcher and clinical research I talk with medical professionals I show them you know something that I thought was logical a number of topics a number of granularity also with respect to those topics that can also be evaluation metrics and I often then tell me that's wrong and that's fine because that helps me really iterate and see okay it's it's not granular enough they have very specific demands that's fine sell 50 topics we're gonna do 200 and see if that's makes a little bit more sense um so I I really want want to do it but there isn't one topic evaluation metric uh that works best because also well what is the definition of best in the context of topic modeling that really depends yeah super definitely like a human in the loop a strong component to it and I I think maybe like when we would present a human a surge system and we'd say hey does this query document pair match so it's like well relative to what else and it's like maybe you show a query in a document but then so you want to show like documents two three four as well and it's like these very long paragraphs attacks it's like I can't read through this whereas if you have the keyword list so it's like query and then keyword list comparative keyword lists maybe that's a better way to like get a human judgment or something like that no no I I definitely uh agree with that because the thing is we're still we're still humans and we're lazy we're not going to read through hundreds and hundreds of documents to see if everything matches up so so things you can do of course is you know you have a topic you have certain keywords you read through those keywords you think yeah I'm not still I'm still not sure what this is about and then you can show a few maybe randomly sampled documents and not too many but just a few together an intuitive understanding of oh it means these in these kind of models and these these uh types of topics can then be extracted from those um so so it's still you know like you mentioned a way of approaching it taking a perspective from the user how can you make sure that they have the easiest time making sure that everything works as intended that is the approach of the topic it of course doesn't always succeed in that so that's what development is for um but also that that iteration and that feedback process to make sure that um that makes it a little bit easier for the user to understand what is happening and for that I provide many many functions maybe too many you know visualizations uh diving deep into certain topics but it's always nice if you're just presented with you know the keywords and just a bunch of documents and say okay okay these make sense these do not make sense just from you know a single glance at those topics and those keywords so that is the intention but it doesn't always succeed in that yeah it was I mean it's super interesting I think there are so many applications for doing this Vector analysis this way of bubbling up the keywords and then having that be kind of like the layer above it that lets you see the Clusters I think that's just brilliant uh could we kind of for my understanding could we get into the two uh could you explain to me what dynamic topic modeling is yeah sure so what is essentially what you're doing is uh you have your topic modeling and let's say you get a topic from that and the topic is about cars so you have a bunch of tweets uh the in those tweets you find a topic about cars and you think okay that's interesting we have something about car great now the thing with tweets is is that there's a timestamp attached to it and that might be interesting because the way we talk about cars today and a few years ago might be entirely different the topic is still exactly the same it's still about cars but today Tesla is way more popular than it was a few years ago for example so we're still talking about the same thing about the same same concept the same topic cars but the way we talk about this that is different and you know you can do that in a dynamic way so um over time that you see if a certain topic has increased popularity over time and if it has it's the way we talk about that topic different but you can also split thin classes for example so if we have a certain political topic uh China for example then Obama would talk quite differently than Trump about that topic it's still the same topic they still talk about China in a certain way but the way they approach is it might be entirely different and the entire ID with Dynamic topic modeling and for example cloud-based topic morning is that we say okay we have a certain time stamp for our documents and we take only the documents in that timestamp and then do the CTF IDF analysis on top of that we don't have to do clustering anymore we don't have to do any of those embedding steps we can simply slice up our data a little bit further so we still have the same cars topic but instead of this entire line we're taking this small step and from that we essentially say okay we're going to recalculate the ct5df representation and maybe it's different in order to not have to recalculate the Clusters you would need to have say 2014 to 2020 in the initial set and then you can 2018 to 2020 slice right yeah that's super interesting one of my things was to ask about how the topics evolve over time and see a dynamic topic being the phrase to describe that and yeah that is just amazing especially like as you think about continual learning data Centric Ai and managing these data sets how are they evolving you know if we're searching through software support tickets uh for Wii day let's say and then we introduce a new feature and then we see how the discussion evolves around it over time helps us to like search and understand the just our data set of support tickets open uh so now can we dive into online topic modeling and what that means yeah so that's very similar to to what you've mentioned before right so uh if you get a bunch of topics or sorry a bunch of tickets for for your software that you have you can do Dynamic topic modeling on that and that's when you already have all of that data and you just see if there's a trend but you know there is a Tomorrow there's new data coming in there and you might want to know a little bit more about these new topics or this new data whether the Clusters change or whether they become more about something entirely different within the same topic of course so what online learning is doing is basically sidekits scikit-learns partial fit function it's when you train your data set on a small part and then you continuously update it whenever new data comes in to make sure the for example the Clusters get better aligned whether it discovers new topics which which is also possible um and and the basic usage for that is again rather straightforward because we have a pre-trained language model we don't need to necessarily fine tune that for for new data that comes in um it generally captures the rep station well uh with a small side note of course that if you know there are models trained before covid so whenever kovit comes in it can have difficulty capturing that but setting that aside we can then use for example incremental PCA to continuously update how they should be you know reducing dimensionality we can use many batch k-means to continuously update the k-means representation sctf IDF is is rather straightforward that's just recalculating it and then there's a gun factorized step before that to make sure that whenever new words come in we simply add it to the bag of words and that sets you know you don't have to do much to make sure it gets updated and the one thing to note here is that you can introduce a Decay Factor because if we have trained for the last 10 years on some data and now suddenly a new topic comes in then we still have 10 years data of worth in our topic model so so what happens if you have you know back and forth representation with 10 years of data it tends to focus on those 10 years of data because it's quite a lot and that small new data that comes in doesn't really get that much attention so you can introduce a Decay Factor by essentially saying so whenever we update the model all all data gets a little bit smaller because it's back of words it's a count right we decrease the count width one or two percent so it doesn't get slowly smaller and smaller and smaller all the older data and newer data gets a little bit more attention and becomes therefore also a little bit more accurate that's super yeah as we've been thinking about the design of bird topic and we V8 and how interface this that really made me think about like the symbolic filter like adding them as like a wear filter for year after 2018 that kind of thing would be really important to the design and this whole conversation has been really enlightening to thinking about the design of trying to build this kind of vector analysis in weeviate and what people will need um so you mentioned you have this user perspective and you're building the bird topic it's a python Library can you tell me about your experience building out that library that was a very interesting experience it's it's the I think one of the first packages that I developed outside of my Master's thesis um and it has been quite a ride for uh for the last few years because there are a lot of dependency issues uh because of numpy some other uh things that were need to taken into account but it was really really interesting really fun to do because there's so many people that want to contribute to the package that have very interesting suggestions um by focusing on those users and by focusing on what their experience is with the model I make it more than just something for myself right I don't I don't want to bring out a package that I'm only using myself I'm not doing it just for me um and because there are a lot of people using that uh you know I need to listen to them I need to make sure that I take into account the features that are looking for the experience that they look for um so for me that psychological background I think has helped tremendously in not only listening to the feedback that has been giving but also taking their perspective and also understanding okay if I gonna write documentation for example how should I do that how should I make sure that you know when I communicate certain Concepts I do that clearly and in a well-explained manner and obviously I don't always succeed in doing that and I see that back in the issues which is great because then I see okay there are way too many issues about this even though I think it's clearly in the documentation uh that means I'm wrong it's not clearly in the documentation I I should re-examine it you know and look for ways to improve it ask for feedback things like that it's a very similar experience with keyboard and polyfuss where you know there's a focus on transparency modularity user experience these kind of things all of these packages they're not necessarily the most state-of-the-art the most complex uh algorithms out there that nobody understands now we're going back to easily explainable topic modeling techniques or or packages giving control back to the developers having them giving giving them the opportunity to build whatever it is that they want to do you know we might to say that you should do your topic modeling and this in this way I don't know every use case I don't know what you're working on and who am I to say what it should look like so that has mostly been the the design philosophy behind these packages and sometimes they work because it gives a lot of options to uh to developers sometimes it gives a little bit too many options as a choice overload which can be difficult and balancing that out having a great out of debug experience while still giving you know thousands of options so to say that has been that has been tricky because it doesn't always align with one another and yeah you know you have to make some hard choices here and there yeah super cool well yeah and I I do think kind of in the space of topic modeling there are like these LDA like Matrix factorization approaches and I think kind of these steps of uh you know bird embeddings new map compression hdb scan tfid I think that stack is a little more approachable than having to construct a big topic term and then you know singular value decomposition to get out and I also really want to compliment you on your medium articles that explain bird topic for because I you know I didn't really know that this kind of thing existed and your articles are just super clear on helping me get up to speed with this so I definitely want to thank you for that thank you and I think in general you've documented this extremely well the python library is so interesting there's so much to look through so many interesting topics with this I think it's a huge idea for understanding Vector spaces and all the applications we've talked about so Martin thank you so much for joining the weba podcast I'm so happy with this one I think this so much information with it and I couldn't be more excited about the development of bird topic and leviate oh thank you very nice being here talking about it to you about this a really nice conversation and as always if there's any feedback that you have anything that you find okay this is stupid you should change it tell me because I'm really open to anything I cannot make any guarantees of course but I'll do my best Thanks Martin ", "type": "Video", "name": "Maarten Grootendorst on BERTopic - Weaviate Podcast #28", "path": "", "link": "https://www.youtube.com/watch?v=IwXOaHanfUU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}