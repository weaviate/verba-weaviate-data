{"text": "Hey everyone! I'm super excited to present a paper summary of HNSW-FINGER! HNSW-FINGER presents a clever technique to ... \nhey everyone thank you so much for \nwatching this paper summary video of hsw \nfinger finger is short for fast \ninference for graph based approximate \nnearest neighbor search the authors \npresent a super clever technique that \nextends the hnsw algorithm perfectly by \napproximating distance calculations so \nwe're going to approximate these \ndistance calculations by Computing a lot \nof values offline using these cool \nalgorithms like singular value \ndecomposition all sorts of details that \nwe'll explore in this paper summary \nvideo but to give more of a tldr hnsw \nfinger trades off additional memory for \nfaster Vector search so when using this \nalgorithm that's the trade-off basically \nso we'll get into exactly how much \nmemory and exactly how much of a speed \nup you get in terms of the evaluation \nyou're especially going to see the \nbenefit of hsw finger when you're \ndealing with you know higher dimensional \nvectors so they find the biggest \nImprovement on just 960 dimensional \nvectors but you know say just at the \ntime of recording this the open AI Ada 2 \nembeddings are super commonly used and \nthey are 1500 dimensional vectors so you \ncan expect a huge speed up on using \nhigher dimensional vectors like that \nwith an algorithm like this and all that \nwill be evident as we step into the math \nso I had so much fun reading this paper \nand I hope this video helps you you know \nunderstand the math as well it really \nhelped my intuition on approxine years \nneighbor search as we look into the like \nthe hsw stop condition and all this cool \nstuff so let's dive into it thanks so \nmuch for watching okay so here's a quick \noverview of the algorithm in two minutes \njust in case you want to get the high \nlevel concept behind it so the core \nvalue out of vector databases is \napproximate nearest neighbor search we \ntake a query we turn it into a vector \nand we want to find the most similar \nVector to our query in our database of \nvectorized documents we don't want to \nhave to compare the distance between our \nquery and every single Vector in our \ndatabase so we build up these data \nstructures to facilitate approximate \nnearest neighbor search so shown on the \nleft is the hnsw hierarchical proximity \ngraph to Route these distance \ncalculations such that instead of say we \nhave you know a billion vectors in our \ndatabase instead of doing a billion \ndistance calculations we do say you know \nten thousand or so or however many but \nso that's the core idea as we build up \nthese data structures So within hnsw we \nhave the search layer algorithm for how \nwe're going to Traverse the graph and we \nhave this upper bound between the \ndistance of the candidate and then the \nneighbor that we're exploring and so we \nuse those distances for how we you know \nappend it into the queue or terminate \nthe search so the authors find that over \n80 percent of these distances here when \nwe're exploring these neighbors towards \nthe mid phase of the search they usually \ndon't contribute anything to the actual \nend result so we can get away with \napproximating these distances so the key \ninsight for how to approximate these \ndistances is we're going to project the \nquery and the neighboring node onto the \ncenter node so again the way that hsw \nsearch works is we find some Center node \nlike say this blue node shown in my \nmouse and you're exploring the neighbors \nof that blue note so this blue note is \nthe center node C so we project the \nquery onto that Center node as well as \nits neighbors now the cool thing is that \nwe can then compute the projection of \nthe neighbors onto the center node \noffline and store these offline and then \nwe you just look it up and quickly \ncalculate the distance so that's done by \ndecomposing L2 distance between the \nquery and the neighbor into the \nseparating into the projected and \nresidual components so you know this is \nthis is the key detail that we'll be \nexploring in this paper summary video is \nunderstanding how each of these four \nterms are computed this last one the uh \nyou know the angle between the residual \nuh components that's the key meat behind \nit but you compute these most of it is \nstored offline and we'll get into the \nmemory overhead but this is the key \nbehind how it works uh so there's also \nthis clever technique of using a \ndistribution matching where you look at \nthe you know the distribution of the \nangles between the real data and then \nonce you have the low rank projection \nwhat the angle then becomes and doing \nthis kind of normalization thing it's a \nsuper common thing to see in deep \nlearning so I think it's just cool to \nsee this in general so I I maybe should \nmention that we measure this angle of \nthe distances by uh with the data \ndistribution so we you know have the SVD \na low rank projection by looking at the \nactual uh residuals in the distances all \nthis will be clear from the paper \nsummary video but just to give an \noverview we use the data distribution to \nhelp with this approximation so then \nfinally with the results I think looking \nat this just 960 is the most interesting \nthing you see a huge benefit in queries \nper second at different recall levels \ncompared to just Baseline \nimplementations of hsw the benefit being \nnot not as big on Lower dimensional \nvectors 96 100 128 but these higher \ndimensional vectors I don't really know \ntoo much about like the information \nretrieval benchmarks and how those react \nto higher dimensional vectors generally \nbut you know as I mentioned in the \nbeginning of the video the open AI ada2 \nembeddings are 1536 so makes it seems \nthat they would bet that would benefit \nfrom this enormously so let's dive into \nthe details further this video will \nexplain the technical details behind the \nhnsw finger algorithm to give a quick \noverview of the presentation we're going \nto start off by exploring the hsw search \nalgorithm and particularly the stop \ncondition and how we're exploring the \nneighbors to our current Center node and \ncomparing that with the upper bound \nwhich is the furthest distance in our \nworking queue so far so the key Insight \nfrom that is that over 80 percent of \nthese distance calculations don't \ncontribute anything to the final search \nresult unless we can get away with \napproximating these distances so that's \nwhere the devil is in the detail is in \nlooking at how exactly we approximate \nthese distances so they first show the \ndecom composition of the L2 distance \ninto the projected and residual \ncomponents we'll get into how exactly \nwe're going to compute our basis by \nhaving the SVD of the residuals as we \nbuild a matrix of all the edges in our \nsearch graph and then you know low rank \napproximate that and then use that to \nproject the vectors into the space and \nthen have the projected and residual \ncomponents and so there's a lot of \ndetails behind this but I think it's so \ninteresting once you finally wrap your \nhead around it and I think in addition \nto understanding just what values need \nto be pre-computed you see the memory \noverhead as well which is the third \npoint is understanding the details \nbehind the memory overhead that this \ncreates and I think that further just \nhelps you understand the algorithm so \nthen we'll get into this distribution \nmatching technique it's you use the data \ndistribution in that SVD decomposition \nto project the vectors so it's pretty \ninteresting to you know then align the \nthe real angles with the projected \nangles by using this kind of \ndistribution matching technique which \na super common thing to do in machine \nlearning and so it's really interesting \nto see it in this algorithm as well so \nthen we'll get into the results I think \nthe most interesting takeaway is \nmentioned in the beginning is that the \nyou get the best performance from higher \ndimensional vectors which makes a lot of \nsense as we look at the math because \nobviously you're not having to do you \nknow all the distances on a 960 \ndimensional vector and so it makes a lot \nof sense for why that is the one that \nperforms the best but I think it's just \ninteresting to see I think we'll talk \nabout some future directions \nparticularly maybe comparing this with \nproduct quantization to understand the \ndifference between the two algorithms as \nwell as just maybe what we can do \nfurther with this kind of distribution \ndistribution of the data to speed up \ndistances okay so once we've built up an \nhsw proximity graph we're going to be \nexploring it by using the algorithm \nshown here the search layer algorithm so \nsearch layer takes its input the query \nthe entry points from the previous layer \nsay Layer Two down to layer one or layer \n1 down to layer 0 we start with these \nentry points that come from searching \nthe top layer and that's where the \nhierarchy of the approximators neighbor \nsearch comes into this so then we have \nthe ef ef is one of the hyper parameters \nto be looking at as your say like tuning \nweeviate and looking at you know EF it's \nthe size of the queue as you're \nsearching so you know if you have a \nsuper big Q then you're going to have a \nlonger search and so on so and then you \nhave the layer number that you're \nsearching through particularly because \nusually you'll store the proximity graph \nyou know as like a dictionary where you \nindex it with the layer number and \nthings like this so the output is going \nto be the EF closest neighbors to the \nquery so we initialize the visited set \nthe candidates and the the dynamic list \nof found nearest Neighbors The CW The V \nset so then while we still have elements \nin the candidates we're going to pop the \nnearest element from C to Q from that uh \ncandidate queue then we're going to f \nwe're going to peek at the furthest \nelement from W to Q \nthen this is going to be the terminate \nthe search condition if the if the \ndistance of that nearest neighbor is \ngreater than the furthest element then \nthat means that we've evaluated all the \nuh all the reasonable candidates to be \nsearching through so now we're stepping \ninto uh probably the most important \nthing to be looking at with particularly \nthis paper is so for each e in the \nneighborhood of C so we've popped up C \nit's the nearest element to our query \nand now we're going to be exploring the \nneighborhood of C so you know say this \nred point is our query and um uh we'll \nbe an example let's say oh yeah so so \nthis is our query this red point and \nthen we bring this blue point with us \ninto the layer one so now we're \nexploring the nearest neighbors uh to \nthe red point which this is our query \nagain so now this node is the closest \nnode to this one so you know this \nbecomes our new furthest element and \nthis ends up being the entry point as we \ncome here or I guess the green one is \nsupposed to be our query but anyway so I \nthink you get the idea the green one is \nsupposed to be the query in the top \nlayer where we you know this is the \nnearest neighbor on layer two and then \nthis is the nearest neighbor on layer \none and then take this into layer zero \nor so on \nanyway so that's basically the idea I \ndon't I don't know if that picture is \nsuper clear but but basically so once \nwe're there we're going to add this \nneighbor to our visited set and then \nwe're going to get that furthest element \nfrom W to q and we're going to be \ncomparing the distance between each of \nthese neighbors with that upper bound \nand the furthest element from W to Q so \nonly if e is closer to our furthest \nelement in that Dynamic listed found in \nthe Earth's neighbor so you know say we \nentered the graph with three entry \npoints from layer one and now we're in \nlayer zero and we're exploring the \nneighbors back closest one if it's not \nuh if the distance isn't less than the \nthird you know that third as if the \nthree that higher highest distance then \nwe're not going to add it to the queue \nand so on so basically what they find is \nthat when you get to the mid phase of \nthe search say you have 10 of these \nnodes in your queue now and you're \nlooking for that 11th as you're \nexploring or you're looking to you know \nadd a tenth and then prune out one of \nthe ten what they find is that over 80 \npercent of these distances you aren't at \nis lower than the upper bound \nthe distances further I mean so you're \nnot adding it to the queue unless it \ndoesn't it's not even worth Computing \nthe distance so we approximate the \ndistance so in conclusion because most \nof these distance calculations don't \ncontribute to the search we can afford \nto approximate these calculations so now \nit's time for the devil and details the \nI think the most important thing to \nunderstand about Labor so how are we \ngoing to be approximating distance so \nwe're going to be showing how to \napproximate L2 distance with projected \nand residual components so let's start \noff by just a quick recap of that idea \nof projected and residual components so \nthe core intuition is that we have this \nquery vector and then we have the \nneighbor of the center node C that we're \nexploring we always have this reference \nwhere we're looking at four e Neighbors \nfrom C so there's always that kind of \nrelationship as you're exploring nodes \nso we're going to be projecting the \nquery and the uh my arms have been that \nwell but like to the center node C so we \nhave the projected and residual \ncomponents so basically I think the key \nthing to understand is that the \nprojected component is like how much of \nthis Vector is this other vector so it's \ngoing to be a scalar times the original \nVector so Q sub proj is T times the \nvector C so you know and similarly D is \nB times the vector C so that one is \npretty straightforward and then the the \nresidual ends up being the Q minus the \nprojected component is how you then \nderive the residual \nso with the D projections we can compute \nall of that offline because we build a \nbig Matrix of the um of all the edges so \nyou know we we already know what D \nprojected onto C is going to be and we \nalready have these edges to compute that \nwith so let's actually let's let's get \ninto the calculation and then we'll step \nthrough each of the four key uh terms in \nthe equation and then you know see how \nit's computed so \nL2 distance Q minus d uh so we're going \nto break that into the projected and \nresidual components and then you kind of \nlike multiply that out and you end up \nwith these other terms so the first \nthing to note so if you'll see my mouse \nis we you know first we split apart just \nthe basic thing of you know Q becomes \nthe projected plus the residual and then \nD similarly is the projected times \nresidual and you multiply that minus \nsign through it I don't know how much of \nthe algebra I should walk through when \nyou're separating it out but so you know \nthen you continue separating it you end \nup with this term as you see this again \ncomes like here as you're breaking into \nthe LT distance between vectors you'll \noften write it as like you know a minus \nB transpose times a minus B and then you \nmultiply that out and you end up with \nthe uh you know the the plus two a \ntranspose t b sorry with the T again but \nso you end up with this term and because \nthe projected components are orthogonal \nto the residual components this term \njust you know exits out but I think the \nonly thing to be real to be seriously \ninterested in is what you end up with \nwhich is this final thing so we have \nthese four terms terms that we need to \ncompute \nso similarly if you're approximating the \ndot product you don't need to have these \nadditional Norms in the final \ncalculation so you have these just kind \nof inner products so you know if you're \ninterested in L2 distance versus cosine \nangular distance personally I in my \nexperiments with playing with you know \nVector search for a while now I've never \nfound that you know especially with deep \nlearning produced vectors that are \nalready kind of scale normalized for the \nsake of optimization I just use LT \ndistance maybe somebody has an opinion \nabout that and I'd be happy to hear it \nbut I think let's just stick with LT \ndistance for now all right so as we \nlooked at the derivation of L2 distance \ninto projected and residual components \nwe're left with these four key terms and \nthis is the key detail to understanding \nthis paper is understanding how each of \nthese four terms are computed offline \nokay so the first term is going to be \nthe L2 distance between the query \nprojected and then the neighboring node \nprojected onto the center node the \nprojection components of each of these \nvectors so the first Insight is that \nboth of these query projected and the \nneighbor projected are some scalar times \nthe center don't see so we have t times \nC and we have B times C where T and B \nare scalars so from there we're going to \nbreak the L2 distance we're going to \ntake out that c that's common to both \nand then we just have T minus B squared \nand then the L2 Norm of C so we \npre-compute the the norm of each of the \nnodes so you know for every node in our \ndatabase we've computed the note the the \nnorm of it so you just look this up this \nis a part of the extra memory cost that \nwe'll look into later so then T minus B \nsquared is just a subtraction \nmultiplication to itself so it's not \nlike we don't do any computation but \nthis is you know as you see in the top \nof the memory reason the arithmetic is \ncounting how many um you know the low \nlevel of how many additions and so on \nthat we need to compute so B can also be \nprecalculated by looking at the same \nequation so you know B is going to be \nthat component of the neighboring node D \nof C in that you know and you can \ncompute that offline so let's get a \nlittle more into this so \nso this T equals query transpose times C \ndivided by the norm of C that's going to \nbe like the coefficient when you project \na vector onto another Vector would just \nbe this then times the C again I think \nis yeah so so from there you can just uh \nbreak down so then remember we already \nloaded in the norm of C from that we \npre-computed so now we just need to do \nthis top part the query transpose times \nC so that just ends up being the norm of \nthe query again the norm of the center \nnode that we already computed and then \nwe do need to do this L2 distance \nbetween the query and the center node \nbut we only need to do that once to \nexplore the neighborhood of this Center \nnode so in these H and SW graphs they \noften would have like 32 64 edges per \nnode so you know we just compute this \nonce to then explore the 64 neighbors of \nthe center node and node to each of \nthese D's as We're looping through the \nneighbors so that's how we get the first \nterm and hopefully it's clear that just \nthe uh you know the decomposition into \nscalars how we're able to pre-compute \nthe nor form and then you know how how \nexactly we compute the T by having it \nit's the coefficient of the projection \nkind of and you know then we break the \ntranspose into this so the next two \nterms are pretty quick to uh derive so \nwith the residual Norm we just compute \nthat offline we just look it up from \nmemory to add it to our four terms to \ncalculate the uh you know the Q res \ntranspose D res so then we have the norm \nof the residual component of the query \nso the way that we do this is again the \nquery equals the projected plus the \nresidual components you've separated the \noriginal Vector into the residual and \nprojected components just like post each \nother and so so to get the residual \ncomponent we'll just subtract the \nproject the query from the projected \ncomponent so the projected component uh \nso again we calculated that t value in \nstep one so we're now going to square T \nand multiply it by that Norm of C that \nwe've pre-computed and loaded into \nmemory and so now we'll just um you know \nwe just have the projected component \nthat we calculated from t squared times \nthe norm of c and then we just subtract \nback to query from that \nof the the norm of the query sorry and \nagain the norm of the query is um \nsomething that we've already computed so \nthese are these are scalars as we've \ncomputed the norm hopefully that's clear \nokay so now for the most interesting of \nthe four terms the angular distance \nbetween the residual components of the \nquery and the neighboring node so first \nwe're going to break out this transpose \ndot product into the norm of the query \nplus the norm of the uh the neighboring \nnodes residual component times the \ncosine distance between the residual \ncomponent of the query and the residual \ncomponent of the neighboring node so \nthis is where now we're going to look \ninto the singular value decomposition \nthat is used to do this approximation so \nwhat we're going to do is first we're \ngoing to create a matrix this d d sub \nres the residual Matrix where each entry \nin The Matrix is the difference between \nthe vectors so you know if there's an \nedge from A to B \nthe first entry in The Matrix is going \nto be a minus B and so and you know then \na to F the next one is the difference \nbetween a to F so we construct this big \nMatrix that way \nand then we get the low rank basis by \ndoing singular value decomposition where \na singular value decomposition you \ndecompose The Matrix into the \neigenvectors and the you know like the \ntop R singular values they capture most \nof like the variance in the vector so \nit's like you know like about project \nit's kind of like how tsne and PCA and \nlike low rate low dimensional algorithms \nwork it works like that where you say \nthese are the components that capture \nlike the variance in the data so the \ndata being the residual Matrix the uh \nthe yeah like the distance Matrix \nhopefully that's clear so like that is \nthe you know the the top components of \nthat distance that you then use to \nproject the vectors into that space so \nokay so now let's look at how we get the \nother half of that term which is going \nto be the projected residual component \nof the query so first what we're going \nto do is we're going to leverage that \nwe've already computed a lot of the \nstuff that we can use to derive this \nwithout having to do the multiplication \nso or or having to compute the residual \ncomponent and so on so so we We Begin by \nknowing that the um that the residual \ncomponent is going to be the query minus \nthe projected component so so we \ndecompose That Into You Know acute \ntranspose B minus Q projected transpose \nB and then from there we expand the Q \ntranspose projected again remember is T \ntimes the center node that's the that's \nwhat the projected Vector is this T \ntimes C thing and T is the scalar of \nlike how much of the center node the \nprojected component of the query is so \nso then we break that up into again the \nt is calculated like this where QTC and \nagain we've already calculated that so \nwe already have that calculation and \nthis um so this qtb the the reason that \nthat's interesting to put in the front \nis because we can just compute this once \nfor the query to then do our entire \nsearch with \nbecause um none of these are dependent \non the center node C you know when we're \nprojecting or the residual component \nthere's always going to be that \nreference C that we're doing this from \nwhereas the qtb that's just Universal to \nevery single traversal we're going to do \nso then we get the Q res uh TB from this \nthese subtractions and then we take the \nsign of it and then we just have the \nHamming distance between the residual \ntranspose B that we derived from this \nand then again the Dres TB that we've \ncomputed offline and saved as this \nbinary representation okay so hopefully \nthat's a clear explanation of where we \nget each of these four terms from then \nwe just combine them by adding them \ntogether and then we have the distance \nof the query and this neighboring node D \nso they show uh later on when they \nablate the comparison between that SVD \nof the residual and compared to say if \nyou know if you don't have these \nadditional terms as well so you only \ntook the the sign of the Hamming \ndistance between the um you know the \nresidual the query and the residual the \ndistance they'll show some ablations on \nwhy having all these terms helps with \nthe stability of this algorithm and the \naccurate approximation of the distance \ncalculation so let's get more into the \nmemory cost of doing this and I think \nthat'll really help clarify what's \nhappening here so for each node we're \ncalculating the \nuh the projection of it onto that low \nrank basis so this is what we would then \nuse as reference in in those CTB so this \nis this is computed for each node if \nwe're then going to be exploring from \nthat node to its neighbor so this node \nis going to be the C in our reference \nand then we're exploring the D neighbors \nof C so then we also compute the uh the \nnorm of each uh of each of these nodes \nthat would again look up several times \nin the in the calculation so this is the \nextra memory for each node now the \nreally the memory comes for each Edge so \nwe have for each Edge we're going to \nhave the sine code so again we have that \nD res TB so we're Computing that and \nstoring that offline so that's our \nbinary uh representation of the residual \nprojected with the B then we have four \nbytes of the pro projection coefficient \nB so again we use that that b to have \nthe T minus B squared in the um in the \ncalculation of the original distance of \nthe projected query in the projected \nnode and then we also store the no the \nnorm of the residual component for each \nof the nodes for in the edge so the \nresidual component with respect to this \nSource uh so like if it's a to B and \nwe're looking at it from the perspective \nof B and sorry a is like our C Center no \nlowercase C so we're storing the \nresidual of that the norm of that for \neach Edge that again we look up several \ntimes with this calculation putting that \ntogether that results in the additional \nmemory being the number of nodes we have \nthe Delta V for vertices graph being \nmade of vertices and edges we have the \nnumber of vertices times four R plus one \nand then the number of edges times R \nover eight plus eight so what that ends \nup oh sorry what that ends up meaning is \nso let's say for example we have the \ndata set that just one million vectors \nwith 960 Dimensions per vector and say \nwe have a maximal 96 edges per node so \nwe end up having one million times and \nthen the four times say we use 64 as the \nlow rank for that projection so we keep \nthe top 64 singular values of that \nprojection and then we and then we add \nthat with the 96 million edges of which \nwe then have in this case 16 additional \nbytes per each of these edges so \nso you can see how kind of the \nrelationship between how many vectors \nyou have and how many edges per node you \nhave and how that scales with this so I \nguess kind of interestingly yeah so you \nknow you have this 96 times 1 million \nfor the edges so maybe when you're using \nthis you'd want to have I guess the more \nedges you have the more computation you \nwould save when you're exploring the \nneighbors of that Center node but then \nyou know that would lead to more memory \noverhead is you have 96 and then you \nknow going on into whatever number but \nso in the end we end up having 1.7 \ngigabytes extra added with this finger \nindex so the offline values for the \nfinger index and so with respect to this \njust example where the it would \noriginally be 3.6 gigabytes for the data \npoints and so you know you're talking \nabout like adding like half so in \naddition to the memory overhead there is \nthe time overhead of calculating all \nthose values they find their experiments \nthat it adds about 10 extra time so \nthat's really not too bad if you look \nfurther into the detail they have the \nderivation of you know all those memory \nreads and arithmetics if you want to \nlook into the distance between just \ndoing full L2 distance and then you know \nthe series of steps that we looked at \nwith calculating those four components \nso so another clever technique that they \nuse is distribution matching between the \nreal distances between the neighboring \nnode and the center node and the \napproximated distances so oh sorry so \nwhat this ends up looking like is shown \nin the green you have the real distances \ntend to be gaussian distributed whereas \nonce you approximate them with this \nprojection they end up being a little \nright skewed so what you end up doing is \nyou calculate the mean and the variance \nof the real distances with that residual \nMatrix and then you also calculate the \nmean and the variance of the \napproximated distances and so then you \nwould normalize this approximated \ndistance score by having Tu to use the \napproximate distance not the scalar the \ncoefficient from the projected thing \nearlier but so this approximated \ndistance becomes you know what it \noriginally was minus the mean of the \napproximated distances for all of the \ndistances and then you know the variance \nover the mean of the very audience and \nthen you know plus the new means so this \nis a way to try to you know align the \ndistribution and make it more like the \nreal and the real distribution of the \ndistances so now let's get into the fun \npart the results of the experiment so \nthey're going to be testing this with \nsix different data sets and two \ndifferent uh distance metrics euclidean \nas well as angular distance so just in \ncase you were worried about that from \noriginally looking at the difference \nbetween the L2 distance derivation and \nsay you know cosine distance and so on \nso they also do test it with the angular \ndistance so I think the most interesting \nthing to see is the gist 960 shows the \nbiggest benefit shown in the red is the \nhsw finger what you're looking at is \nqueries per second versus recall so in \nthe a n benchmarks evaluation protocol \nyou look at different hyper parameters \nwhere you could you can get really good \nrecall by trading it off speed by say \nincreasing that EF and so on so so they \nthey Loop through the hyper parameters \nthen put a plot on each of these curves \nwith um the recall and then the speed so \nyou always are going to have that kind \nof like accuracy versus speed trade-off \nwhen configuring approximate nearest \nneighbor search algorithms so anyways I \nthink the interesting thing is that \nshown in the top right the higher \ndimensional vectors get much better \nresult that's also consistent with the \n784 from the fashion mnist \nbut this one is you know the most \nsignificant probably here as well \nlooking at you know you know like 1500 \nversus uh you know 500 so you know \nsomewhere like in this particular you \nknow measurement of it it's a pretty \nmassive speed up but generally they say \nsomething like 20 to 50 faster but you \nknow these lower dimensional 96 100 128 \nthey don't seem to see as much of a \nbenefit from this so I think it's also \njust worth mentioning that the text \nembedding uh 802 they're 1536 \ndimensional so it makes sense to think \nthat they would the finger would look \nlike this with those particular \nembeddings so some additional results of \nthe authors comparing hsw finger with \ntwo other techniques that I personally \nhaven't looked into so I can't speak to \nyou too much but they also add some kind \nof uh distance approximation on top of \nthe hsw proximity graph they also test \nthe importance of using the finger \nalgorithm compared to say random \nprojection locality sensitive hashing or \nsay you don't do the full derivation of \nthe terms and you just measure that Q \nres t uh d-rez part at the end so that's \nwhat the Asian SW SVD thing is so they \ndo show that you're getting much better \nrecall by using the um the finger as it \nis where you use the um you know the \nactual distribution of the data to do \nthe low rank approximation compared to \njust like random projection where you \nrandomly sample vectors to project it \ninto the space into the lower \ndimensional space and end ideas like \nthis so here are some of the reflections \nI had after reading this paper uh \nfirstly I think it's very interesting to \nconsider uh hsw finger and product \nquantization so product quantization is \nwhere you compress vectors by you know \nyou have this vector and then you'll \nslide these windows and then you'll \ncluster each of the windows and then you \nwill represent the window with the \ncentroid ID so by doing this you know \nsay you have like zero you know two \n64-bit values and then you've compressed \nit to like an 8-bit ID too that's \nbasically the idea and so product \nquantization is about saving memory and \ntrying to reduce the memory overhead of \nhnsw \nbut also kind of what's interesting \nabout it is you end up using it for disk \nbased Solutions so like disc NN is about \nyou you load these pre-computed I'm \nsorry you load the um the compressed \nrepresentations and this way you get \naway with not needing to have so much \nRAM for doing it and I think hnsw finger \ncould also have a similar kind of \napplication to disk where you don't \nreally need the real vectors anymore for \nthe actual traversal of the vector as we \nsaw you're just doing the distances \nbetween these uh pre-computed values \nthat don't require the full Precision or \nyou know whatever the original Vector \nwas rather you just have these \ncomponents so you know even though \nyou're adding memory to the thing if you \nwant to preserve the original vectors \nyou don't I don't think you need those \noriginal vectors for the actual \ntraversal part so this is kind of some \nquick thinking about I haven't really \nput too much thought into that \nparticularly but I think the next \ninteresting thing is just measuring the \nonline maintenance of this kind of low \nrank projection in that residual Matrix \nyou know what happens as you add more \ndata that's kind of one of the big \nthings that separates Vector databases \nfrom Vector libraries is \nyou know people continually add data \ninto the index so how often are we going \nto need to recompute all these values \nbecause we would need to like reproject \nit and so on that's also the problem \nwith product quantization is you're \ndoing that K means to Cluster those \ncentroid IDs and then it's like well how \nmany of these do we need to load before \nwe have a representative sample so I \nthink also that kind of distribution \nshift could be a really powerful uh \nlever for that online maintenance \nbecause if you just know the \ndistribution you see the the \ndistribution starts to skew you can you \nknow just kind of align it with that \nnormalization trick and then further I \njust think finally this like using the \ndata distribution in these a n indexes \nthey already kind of you know do that \nwith how the edges are constructed but I \nthink explicitly doing things like \ncompression with the data itself thank \nyou so much for watching this paper \nsummary video of hnsw finger this paper \nis such an exciting way to speed up \napproximate nearest neighbor search by \npre-computing these values to \napproximate that distance calculation uh \nthere are a lot of details to this paper \nsome memory and I hope that I got a lot \nof them right if you find anything wrong \nplease don't hesitate to leave it in the \ncomments and you know help my \nunderstanding as well as everyone \nlistening hopefully so again thank you \nso much for watching if you want to \nlearn more about weediate you can check \nit out on weevia i o Open Source on \nGitHub weekend and then on Twitter at \nwebiate underscore IO also join our \ncommunity slack and discuss these ideas \naround approximate nearest neighbor \nsearch I think it's so exciting to see \nmore research with this and I it's just \nsuch an exciting part of Libya is how do \nwe you know compute these Vector \ndistances efficiently so thanks so much \nfor watching \n", "type": "Video", "name": "HNSW-FINGER Explained!", "path": "", "link": "https://www.youtube.com/watch?v=OsxZG2XfcZA", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": [{"text": "hey everyone thank you so much for", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 0, "tokens": 0, "vector": null, "score": 0}, {"text": "watching this paper summary video of hsw", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1, "tokens": 0, "vector": null, "score": 0}, {"text": "finger finger is short for fast", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 2, "tokens": 0, "vector": null, "score": 0}, {"text": "inference for graph based approximate", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 3, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest neighbor search the authors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 4, "tokens": 0, "vector": null, "score": 0}, {"text": "present a super clever technique that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 5, "tokens": 0, "vector": null, "score": 0}, {"text": "extends the hnsw algorithm perfectly by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 6, "tokens": 0, "vector": null, "score": 0}, {"text": "approximating distance calculations so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 7, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to approximate these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 8, "tokens": 0, "vector": null, "score": 0}, {"text": "distance calculations by Computing a lot", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 9, "tokens": 0, "vector": null, "score": 0}, {"text": "of values offline using these cool", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 10, "tokens": 0, "vector": null, "score": 0}, {"text": "algorithms like singular value", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 11, "tokens": 0, "vector": null, "score": 0}, {"text": "decomposition all sorts of details that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 12, "tokens": 0, "vector": null, "score": 0}, {"text": "we'll explore in this paper summary", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 13, "tokens": 0, "vector": null, "score": 0}, {"text": "video but to give more of a tldr hnsw", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 14, "tokens": 0, "vector": null, "score": 0}, {"text": "finger trades off additional memory for", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 15, "tokens": 0, "vector": null, "score": 0}, {"text": "faster Vector search so when using this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 16, "tokens": 0, "vector": null, "score": 0}, {"text": "algorithm that's the trade-off basically", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 17, "tokens": 0, "vector": null, "score": 0}, {"text": "so we'll get into exactly how much", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 18, "tokens": 0, "vector": null, "score": 0}, {"text": "memory and exactly how much of a speed", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 19, "tokens": 0, "vector": null, "score": 0}, {"text": "up you get in terms of the evaluation", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 20, "tokens": 0, "vector": null, "score": 0}, {"text": "you're especially going to see the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 21, "tokens": 0, "vector": null, "score": 0}, {"text": "benefit of hsw finger when you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 22, "tokens": 0, "vector": null, "score": 0}, {"text": "dealing with you know higher dimensional", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 23, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors so they find the biggest", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 24, "tokens": 0, "vector": null, "score": 0}, {"text": "Improvement on just 960 dimensional", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 25, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors but you know say just at the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 26, "tokens": 0, "vector": null, "score": 0}, {"text": "time of recording this the open AI Ada 2", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 27, "tokens": 0, "vector": null, "score": 0}, {"text": "embeddings are super commonly used and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 28, "tokens": 0, "vector": null, "score": 0}, {"text": "they are 1500 dimensional vectors so you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 29, "tokens": 0, "vector": null, "score": 0}, {"text": "can expect a huge speed up on using", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 30, "tokens": 0, "vector": null, "score": 0}, {"text": "higher dimensional vectors like that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 31, "tokens": 0, "vector": null, "score": 0}, {"text": "with an algorithm like this and all that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 32, "tokens": 0, "vector": null, "score": 0}, {"text": "will be evident as we step into the math", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 33, "tokens": 0, "vector": null, "score": 0}, {"text": "so I had so much fun reading this paper", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 34, "tokens": 0, "vector": null, "score": 0}, {"text": "and I hope this video helps you you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 35, "tokens": 0, "vector": null, "score": 0}, {"text": "understand the math as well it really", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 36, "tokens": 0, "vector": null, "score": 0}, {"text": "helped my intuition on approxine years", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 37, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor search as we look into the like", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 38, "tokens": 0, "vector": null, "score": 0}, {"text": "the hsw stop condition and all this cool", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 39, "tokens": 0, "vector": null, "score": 0}, {"text": "stuff so let's dive into it thanks so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 40, "tokens": 0, "vector": null, "score": 0}, {"text": "much for watching okay so here's a quick", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 41, "tokens": 0, "vector": null, "score": 0}, {"text": "overview of the algorithm in two minutes", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 42, "tokens": 0, "vector": null, "score": 0}, {"text": "just in case you want to get the high", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 43, "tokens": 0, "vector": null, "score": 0}, {"text": "level concept behind it so the core", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 44, "tokens": 0, "vector": null, "score": 0}, {"text": "value out of vector databases is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 45, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate nearest neighbor search we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 46, "tokens": 0, "vector": null, "score": 0}, {"text": "take a query we turn it into a vector", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 47, "tokens": 0, "vector": null, "score": 0}, {"text": "and we want to find the most similar", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 48, "tokens": 0, "vector": null, "score": 0}, {"text": "Vector to our query in our database of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 49, "tokens": 0, "vector": null, "score": 0}, {"text": "vectorized documents we don't want to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 50, "tokens": 0, "vector": null, "score": 0}, {"text": "have to compare the distance between our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 51, "tokens": 0, "vector": null, "score": 0}, {"text": "query and every single Vector in our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 52, "tokens": 0, "vector": null, "score": 0}, {"text": "database so we build up these data", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 53, "tokens": 0, "vector": null, "score": 0}, {"text": "structures to facilitate approximate", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 54, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest neighbor search so shown on the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 55, "tokens": 0, "vector": null, "score": 0}, {"text": "left is the hnsw hierarchical proximity", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 56, "tokens": 0, "vector": null, "score": 0}, {"text": "graph to Route these distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 57, "tokens": 0, "vector": null, "score": 0}, {"text": "calculations such that instead of say we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 58, "tokens": 0, "vector": null, "score": 0}, {"text": "have you know a billion vectors in our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 59, "tokens": 0, "vector": null, "score": 0}, {"text": "database instead of doing a billion", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 60, "tokens": 0, "vector": null, "score": 0}, {"text": "distance calculations we do say you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 61, "tokens": 0, "vector": null, "score": 0}, {"text": "ten thousand or so or however many but", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 62, "tokens": 0, "vector": null, "score": 0}, {"text": "so that's the core idea as we build up", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 63, "tokens": 0, "vector": null, "score": 0}, {"text": "these data structures So within hnsw we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 64, "tokens": 0, "vector": null, "score": 0}, {"text": "have the search layer algorithm for how", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 65, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to Traverse the graph and we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 66, "tokens": 0, "vector": null, "score": 0}, {"text": "have this upper bound between the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 67, "tokens": 0, "vector": null, "score": 0}, {"text": "distance of the candidate and then the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 68, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor that we're exploring and so we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 69, "tokens": 0, "vector": null, "score": 0}, {"text": "use those distances for how we you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 70, "tokens": 0, "vector": null, "score": 0}, {"text": "append it into the queue or terminate", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 71, "tokens": 0, "vector": null, "score": 0}, {"text": "the search so the authors find that over", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 72, "tokens": 0, "vector": null, "score": 0}, {"text": "80 percent of these distances here when", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 73, "tokens": 0, "vector": null, "score": 0}, {"text": "we're exploring these neighbors towards", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 74, "tokens": 0, "vector": null, "score": 0}, {"text": "the mid phase of the search they usually", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 75, "tokens": 0, "vector": null, "score": 0}, {"text": "don't contribute anything to the actual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 76, "tokens": 0, "vector": null, "score": 0}, {"text": "end result so we can get away with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 77, "tokens": 0, "vector": null, "score": 0}, {"text": "approximating these distances so the key", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 78, "tokens": 0, "vector": null, "score": 0}, {"text": "insight for how to approximate these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 79, "tokens": 0, "vector": null, "score": 0}, {"text": "distances is we're going to project the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 80, "tokens": 0, "vector": null, "score": 0}, {"text": "query and the neighboring node onto the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 81, "tokens": 0, "vector": null, "score": 0}, {"text": "center node so again the way that hsw", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 82, "tokens": 0, "vector": null, "score": 0}, {"text": "search works is we find some Center node", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 83, "tokens": 0, "vector": null, "score": 0}, {"text": "like say this blue node shown in my", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 84, "tokens": 0, "vector": null, "score": 0}, {"text": "mouse and you're exploring the neighbors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 85, "tokens": 0, "vector": null, "score": 0}, {"text": "of that blue note so this blue note is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 86, "tokens": 0, "vector": null, "score": 0}, {"text": "the center node C so we project the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 87, "tokens": 0, "vector": null, "score": 0}, {"text": "query onto that Center node as well as", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 88, "tokens": 0, "vector": null, "score": 0}, {"text": "its neighbors now the cool thing is that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 89, "tokens": 0, "vector": null, "score": 0}, {"text": "we can then compute the projection of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 90, "tokens": 0, "vector": null, "score": 0}, {"text": "the neighbors onto the center node", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 91, "tokens": 0, "vector": null, "score": 0}, {"text": "offline and store these offline and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 92, "tokens": 0, "vector": null, "score": 0}, {"text": "we you just look it up and quickly", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 93, "tokens": 0, "vector": null, "score": 0}, {"text": "calculate the distance so that's done by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 94, "tokens": 0, "vector": null, "score": 0}, {"text": "decomposing L2 distance between the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 95, "tokens": 0, "vector": null, "score": 0}, {"text": "query and the neighbor into the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 96, "tokens": 0, "vector": null, "score": 0}, {"text": "separating into the projected and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 97, "tokens": 0, "vector": null, "score": 0}, {"text": "residual components so you know this is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 98, "tokens": 0, "vector": null, "score": 0}, {"text": "this is the key detail that we'll be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 99, "tokens": 0, "vector": null, "score": 0}, {"text": "exploring in this paper summary video is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 100, "tokens": 0, "vector": null, "score": 0}, {"text": "understanding how each of these four", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 101, "tokens": 0, "vector": null, "score": 0}, {"text": "terms are computed this last one the uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 102, "tokens": 0, "vector": null, "score": 0}, {"text": "you know the angle between the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 103, "tokens": 0, "vector": null, "score": 0}, {"text": "uh components that's the key meat behind", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 104, "tokens": 0, "vector": null, "score": 0}, {"text": "it but you compute these most of it is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 105, "tokens": 0, "vector": null, "score": 0}, {"text": "stored offline and we'll get into the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 106, "tokens": 0, "vector": null, "score": 0}, {"text": "memory overhead but this is the key", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 107, "tokens": 0, "vector": null, "score": 0}, {"text": "behind how it works uh so there's also", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 108, "tokens": 0, "vector": null, "score": 0}, {"text": "this clever technique of using a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 109, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution matching where you look at", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 110, "tokens": 0, "vector": null, "score": 0}, {"text": "the you know the distribution of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 111, "tokens": 0, "vector": null, "score": 0}, {"text": "angles between the real data and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 112, "tokens": 0, "vector": null, "score": 0}, {"text": "once you have the low rank projection", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 113, "tokens": 0, "vector": null, "score": 0}, {"text": "what the angle then becomes and doing", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 114, "tokens": 0, "vector": null, "score": 0}, {"text": "this kind of normalization thing it's a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 115, "tokens": 0, "vector": null, "score": 0}, {"text": "super common thing to see in deep", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 116, "tokens": 0, "vector": null, "score": 0}, {"text": "learning so I think it's just cool to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 117, "tokens": 0, "vector": null, "score": 0}, {"text": "see this in general so I I maybe should", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 118, "tokens": 0, "vector": null, "score": 0}, {"text": "mention that we measure this angle of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 119, "tokens": 0, "vector": null, "score": 0}, {"text": "the distances by uh with the data", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 120, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution so we you know have the SVD", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 121, "tokens": 0, "vector": null, "score": 0}, {"text": "a low rank projection by looking at the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 122, "tokens": 0, "vector": null, "score": 0}, {"text": "actual uh residuals in the distances all", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 123, "tokens": 0, "vector": null, "score": 0}, {"text": "this will be clear from the paper", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 124, "tokens": 0, "vector": null, "score": 0}, {"text": "summary video but just to give an", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 125, "tokens": 0, "vector": null, "score": 0}, {"text": "overview we use the data distribution to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 126, "tokens": 0, "vector": null, "score": 0}, {"text": "help with this approximation so then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 127, "tokens": 0, "vector": null, "score": 0}, {"text": "finally with the results I think looking", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 128, "tokens": 0, "vector": null, "score": 0}, {"text": "at this just 960 is the most interesting", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 129, "tokens": 0, "vector": null, "score": 0}, {"text": "thing you see a huge benefit in queries", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 130, "tokens": 0, "vector": null, "score": 0}, {"text": "per second at different recall levels", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 131, "tokens": 0, "vector": null, "score": 0}, {"text": "compared to just Baseline", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 132, "tokens": 0, "vector": null, "score": 0}, {"text": "implementations of hsw the benefit being", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 133, "tokens": 0, "vector": null, "score": 0}, {"text": "not not as big on Lower dimensional", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 134, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors 96 100 128 but these higher", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 135, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vectors I don't really know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 136, "tokens": 0, "vector": null, "score": 0}, {"text": "too much about like the information", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 137, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval benchmarks and how those react", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 138, "tokens": 0, "vector": null, "score": 0}, {"text": "to higher dimensional vectors generally", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 139, "tokens": 0, "vector": null, "score": 0}, {"text": "but you know as I mentioned in the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 140, "tokens": 0, "vector": null, "score": 0}, {"text": "beginning of the video the open AI ada2", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 141, "tokens": 0, "vector": null, "score": 0}, {"text": "embeddings are 1536 so makes it seems", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 142, "tokens": 0, "vector": null, "score": 0}, {"text": "that they would bet that would benefit", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 143, "tokens": 0, "vector": null, "score": 0}, {"text": "from this enormously so let's dive into", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 144, "tokens": 0, "vector": null, "score": 0}, {"text": "the details further this video will", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 145, "tokens": 0, "vector": null, "score": 0}, {"text": "explain the technical details behind the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 146, "tokens": 0, "vector": null, "score": 0}, {"text": "hnsw finger algorithm to give a quick", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 147, "tokens": 0, "vector": null, "score": 0}, {"text": "overview of the presentation we're going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 148, "tokens": 0, "vector": null, "score": 0}, {"text": "to start off by exploring the hsw search", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 149, "tokens": 0, "vector": null, "score": 0}, {"text": "algorithm and particularly the stop", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 150, "tokens": 0, "vector": null, "score": 0}, {"text": "condition and how we're exploring the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 151, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbors to our current Center node and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 152, "tokens": 0, "vector": null, "score": 0}, {"text": "comparing that with the upper bound", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 153, "tokens": 0, "vector": null, "score": 0}, {"text": "which is the furthest distance in our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 154, "tokens": 0, "vector": null, "score": 0}, {"text": "working queue so far so the key Insight", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 155, "tokens": 0, "vector": null, "score": 0}, {"text": "from that is that over 80 percent of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 156, "tokens": 0, "vector": null, "score": 0}, {"text": "these distance calculations don't", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 157, "tokens": 0, "vector": null, "score": 0}, {"text": "contribute anything to the final search", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 158, "tokens": 0, "vector": null, "score": 0}, {"text": "result unless we can get away with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 159, "tokens": 0, "vector": null, "score": 0}, {"text": "approximating these distances so that's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 160, "tokens": 0, "vector": null, "score": 0}, {"text": "where the devil is in the detail is in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 161, "tokens": 0, "vector": null, "score": 0}, {"text": "looking at how exactly we approximate", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 162, "tokens": 0, "vector": null, "score": 0}, {"text": "these distances so they first show the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 163, "tokens": 0, "vector": null, "score": 0}, {"text": "decom composition of the L2 distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 164, "tokens": 0, "vector": null, "score": 0}, {"text": "into the projected and residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 165, "tokens": 0, "vector": null, "score": 0}, {"text": "components we'll get into how exactly", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 166, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to compute our basis by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 167, "tokens": 0, "vector": null, "score": 0}, {"text": "having the SVD of the residuals as we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 168, "tokens": 0, "vector": null, "score": 0}, {"text": "build a matrix of all the edges in our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 169, "tokens": 0, "vector": null, "score": 0}, {"text": "search graph and then you know low rank", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 170, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate that and then use that to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 171, "tokens": 0, "vector": null, "score": 0}, {"text": "project the vectors into the space and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 172, "tokens": 0, "vector": null, "score": 0}, {"text": "then have the projected and residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 173, "tokens": 0, "vector": null, "score": 0}, {"text": "components and so there's a lot of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 174, "tokens": 0, "vector": null, "score": 0}, {"text": "details behind this but I think it's so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 175, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting once you finally wrap your", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 176, "tokens": 0, "vector": null, "score": 0}, {"text": "head around it and I think in addition", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 177, "tokens": 0, "vector": null, "score": 0}, {"text": "to understanding just what values need", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 178, "tokens": 0, "vector": null, "score": 0}, {"text": "to be pre-computed you see the memory", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 179, "tokens": 0, "vector": null, "score": 0}, {"text": "overhead as well which is the third", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 180, "tokens": 0, "vector": null, "score": 0}, {"text": "point is understanding the details", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 181, "tokens": 0, "vector": null, "score": 0}, {"text": "behind the memory overhead that this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 182, "tokens": 0, "vector": null, "score": 0}, {"text": "creates and I think that further just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 183, "tokens": 0, "vector": null, "score": 0}, {"text": "helps you understand the algorithm so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 184, "tokens": 0, "vector": null, "score": 0}, {"text": "then we'll get into this distribution", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 185, "tokens": 0, "vector": null, "score": 0}, {"text": "matching technique it's you use the data", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 186, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution in that SVD decomposition", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 187, "tokens": 0, "vector": null, "score": 0}, {"text": "to project the vectors so it's pretty", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 188, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting to you know then align the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 189, "tokens": 0, "vector": null, "score": 0}, {"text": "the real angles with the projected", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 190, "tokens": 0, "vector": null, "score": 0}, {"text": "angles by using this kind of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 191, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution matching technique which", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 192, "tokens": 0, "vector": null, "score": 0}, {"text": "a super common thing to do in machine", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 193, "tokens": 0, "vector": null, "score": 0}, {"text": "learning and so it's really interesting", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 194, "tokens": 0, "vector": null, "score": 0}, {"text": "to see it in this algorithm as well so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 195, "tokens": 0, "vector": null, "score": 0}, {"text": "then we'll get into the results I think", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 196, "tokens": 0, "vector": null, "score": 0}, {"text": "the most interesting takeaway is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 197, "tokens": 0, "vector": null, "score": 0}, {"text": "mentioned in the beginning is that the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 198, "tokens": 0, "vector": null, "score": 0}, {"text": "you get the best performance from higher", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 199, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vectors which makes a lot of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 200, "tokens": 0, "vector": null, "score": 0}, {"text": "sense as we look at the math because", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 201, "tokens": 0, "vector": null, "score": 0}, {"text": "obviously you're not having to do you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 202, "tokens": 0, "vector": null, "score": 0}, {"text": "know all the distances on a 960", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 203, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vector and so it makes a lot", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 204, "tokens": 0, "vector": null, "score": 0}, {"text": "of sense for why that is the one that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 205, "tokens": 0, "vector": null, "score": 0}, {"text": "performs the best but I think it's just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 206, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting to see I think we'll talk", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 207, "tokens": 0, "vector": null, "score": 0}, {"text": "about some future directions", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 208, "tokens": 0, "vector": null, "score": 0}, {"text": "particularly maybe comparing this with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 209, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantization to understand the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 210, "tokens": 0, "vector": null, "score": 0}, {"text": "difference between the two algorithms as", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 211, "tokens": 0, "vector": null, "score": 0}, {"text": "well as just maybe what we can do", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 212, "tokens": 0, "vector": null, "score": 0}, {"text": "further with this kind of distribution", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 213, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution of the data to speed up", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 214, "tokens": 0, "vector": null, "score": 0}, {"text": "distances okay so once we've built up an", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 215, "tokens": 0, "vector": null, "score": 0}, {"text": "hsw proximity graph we're going to be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 216, "tokens": 0, "vector": null, "score": 0}, {"text": "exploring it by using the algorithm", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 217, "tokens": 0, "vector": null, "score": 0}, {"text": "shown here the search layer algorithm so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 218, "tokens": 0, "vector": null, "score": 0}, {"text": "search layer takes its input the query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 219, "tokens": 0, "vector": null, "score": 0}, {"text": "the entry points from the previous layer", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 220, "tokens": 0, "vector": null, "score": 0}, {"text": "say Layer Two down to layer one or layer", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 221, "tokens": 0, "vector": null, "score": 0}, {"text": "1 down to layer 0 we start with these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 222, "tokens": 0, "vector": null, "score": 0}, {"text": "entry points that come from searching", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 223, "tokens": 0, "vector": null, "score": 0}, {"text": "the top layer and that's where the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 224, "tokens": 0, "vector": null, "score": 0}, {"text": "hierarchy of the approximators neighbor", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 225, "tokens": 0, "vector": null, "score": 0}, {"text": "search comes into this so then we have", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 226, "tokens": 0, "vector": null, "score": 0}, {"text": "the ef ef is one of the hyper parameters", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 227, "tokens": 0, "vector": null, "score": 0}, {"text": "to be looking at as your say like tuning", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 228, "tokens": 0, "vector": null, "score": 0}, {"text": "weeviate and looking at you know EF it's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 229, "tokens": 0, "vector": null, "score": 0}, {"text": "the size of the queue as you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 230, "tokens": 0, "vector": null, "score": 0}, {"text": "searching so you know if you have a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 231, "tokens": 0, "vector": null, "score": 0}, {"text": "super big Q then you're going to have a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 232, "tokens": 0, "vector": null, "score": 0}, {"text": "longer search and so on so and then you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 233, "tokens": 0, "vector": null, "score": 0}, {"text": "have the layer number that you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 234, "tokens": 0, "vector": null, "score": 0}, {"text": "searching through particularly because", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 235, "tokens": 0, "vector": null, "score": 0}, {"text": "usually you'll store the proximity graph", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 236, "tokens": 0, "vector": null, "score": 0}, {"text": "you know as like a dictionary where you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 237, "tokens": 0, "vector": null, "score": 0}, {"text": "index it with the layer number and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 238, "tokens": 0, "vector": null, "score": 0}, {"text": "things like this so the output is going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 239, "tokens": 0, "vector": null, "score": 0}, {"text": "to be the EF closest neighbors to the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 240, "tokens": 0, "vector": null, "score": 0}, {"text": "query so we initialize the visited set", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 241, "tokens": 0, "vector": null, "score": 0}, {"text": "the candidates and the the dynamic list", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 242, "tokens": 0, "vector": null, "score": 0}, {"text": "of found nearest Neighbors The CW The V", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 243, "tokens": 0, "vector": null, "score": 0}, {"text": "set so then while we still have elements", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 244, "tokens": 0, "vector": null, "score": 0}, {"text": "in the candidates we're going to pop the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 245, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest element from C to Q from that uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 246, "tokens": 0, "vector": null, "score": 0}, {"text": "candidate queue then we're going to f", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 247, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to peek at the furthest", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 248, "tokens": 0, "vector": null, "score": 0}, {"text": "element from W to Q", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 249, "tokens": 0, "vector": null, "score": 0}, {"text": "then this is going to be the terminate", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 250, "tokens": 0, "vector": null, "score": 0}, {"text": "the search condition if the if the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 251, "tokens": 0, "vector": null, "score": 0}, {"text": "distance of that nearest neighbor is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 252, "tokens": 0, "vector": null, "score": 0}, {"text": "greater than the furthest element then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 253, "tokens": 0, "vector": null, "score": 0}, {"text": "that means that we've evaluated all the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 254, "tokens": 0, "vector": null, "score": 0}, {"text": "uh all the reasonable candidates to be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 255, "tokens": 0, "vector": null, "score": 0}, {"text": "searching through so now we're stepping", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 256, "tokens": 0, "vector": null, "score": 0}, {"text": "into uh probably the most important", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 257, "tokens": 0, "vector": null, "score": 0}, {"text": "thing to be looking at with particularly", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 258, "tokens": 0, "vector": null, "score": 0}, {"text": "this paper is so for each e in the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 259, "tokens": 0, "vector": null, "score": 0}, {"text": "neighborhood of C so we've popped up C", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 260, "tokens": 0, "vector": null, "score": 0}, {"text": "it's the nearest element to our query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 261, "tokens": 0, "vector": null, "score": 0}, {"text": "and now we're going to be exploring the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 262, "tokens": 0, "vector": null, "score": 0}, {"text": "neighborhood of C so you know say this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 263, "tokens": 0, "vector": null, "score": 0}, {"text": "red point is our query and um uh we'll", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 264, "tokens": 0, "vector": null, "score": 0}, {"text": "be an example let's say oh yeah so so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 265, "tokens": 0, "vector": null, "score": 0}, {"text": "this is our query this red point and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 266, "tokens": 0, "vector": null, "score": 0}, {"text": "then we bring this blue point with us", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 267, "tokens": 0, "vector": null, "score": 0}, {"text": "into the layer one so now we're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 268, "tokens": 0, "vector": null, "score": 0}, {"text": "exploring the nearest neighbors uh to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 269, "tokens": 0, "vector": null, "score": 0}, {"text": "the red point which this is our query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 270, "tokens": 0, "vector": null, "score": 0}, {"text": "again so now this node is the closest", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 271, "tokens": 0, "vector": null, "score": 0}, {"text": "node to this one so you know this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 272, "tokens": 0, "vector": null, "score": 0}, {"text": "becomes our new furthest element and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 273, "tokens": 0, "vector": null, "score": 0}, {"text": "this ends up being the entry point as we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 274, "tokens": 0, "vector": null, "score": 0}, {"text": "come here or I guess the green one is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 275, "tokens": 0, "vector": null, "score": 0}, {"text": "supposed to be our query but anyway so I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 276, "tokens": 0, "vector": null, "score": 0}, {"text": "think you get the idea the green one is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 277, "tokens": 0, "vector": null, "score": 0}, {"text": "supposed to be the query in the top", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 278, "tokens": 0, "vector": null, "score": 0}, {"text": "layer where we you know this is the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 279, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest neighbor on layer two and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 280, "tokens": 0, "vector": null, "score": 0}, {"text": "this is the nearest neighbor on layer", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 281, "tokens": 0, "vector": null, "score": 0}, {"text": "one and then take this into layer zero", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 282, "tokens": 0, "vector": null, "score": 0}, {"text": "or so on", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 283, "tokens": 0, "vector": null, "score": 0}, {"text": "anyway so that's basically the idea I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 284, "tokens": 0, "vector": null, "score": 0}, {"text": "don't I don't know if that picture is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 285, "tokens": 0, "vector": null, "score": 0}, {"text": "super clear but but basically so once", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 286, "tokens": 0, "vector": null, "score": 0}, {"text": "we're there we're going to add this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 287, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor to our visited set and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 288, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to get that furthest element", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 289, "tokens": 0, "vector": null, "score": 0}, {"text": "from W to q and we're going to be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 290, "tokens": 0, "vector": null, "score": 0}, {"text": "comparing the distance between each of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 291, "tokens": 0, "vector": null, "score": 0}, {"text": "these neighbors with that upper bound", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 292, "tokens": 0, "vector": null, "score": 0}, {"text": "and the furthest element from W to Q so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 293, "tokens": 0, "vector": null, "score": 0}, {"text": "only if e is closer to our furthest", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 294, "tokens": 0, "vector": null, "score": 0}, {"text": "element in that Dynamic listed found in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 295, "tokens": 0, "vector": null, "score": 0}, {"text": "the Earth's neighbor so you know say we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 296, "tokens": 0, "vector": null, "score": 0}, {"text": "entered the graph with three entry", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 297, "tokens": 0, "vector": null, "score": 0}, {"text": "points from layer one and now we're in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 298, "tokens": 0, "vector": null, "score": 0}, {"text": "layer zero and we're exploring the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 299, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbors back closest one if it's not", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 300, "tokens": 0, "vector": null, "score": 0}, {"text": "uh if the distance isn't less than the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 301, "tokens": 0, "vector": null, "score": 0}, {"text": "third you know that third as if the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 302, "tokens": 0, "vector": null, "score": 0}, {"text": "three that higher highest distance then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 303, "tokens": 0, "vector": null, "score": 0}, {"text": "we're not going to add it to the queue", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 304, "tokens": 0, "vector": null, "score": 0}, {"text": "and so on so basically what they find is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 305, "tokens": 0, "vector": null, "score": 0}, {"text": "that when you get to the mid phase of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 306, "tokens": 0, "vector": null, "score": 0}, {"text": "the search say you have 10 of these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 307, "tokens": 0, "vector": null, "score": 0}, {"text": "nodes in your queue now and you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 308, "tokens": 0, "vector": null, "score": 0}, {"text": "looking for that 11th as you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 309, "tokens": 0, "vector": null, "score": 0}, {"text": "exploring or you're looking to you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 310, "tokens": 0, "vector": null, "score": 0}, {"text": "add a tenth and then prune out one of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 311, "tokens": 0, "vector": null, "score": 0}, {"text": "the ten what they find is that over 80", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 312, "tokens": 0, "vector": null, "score": 0}, {"text": "percent of these distances you aren't at", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 313, "tokens": 0, "vector": null, "score": 0}, {"text": "is lower than the upper bound", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 314, "tokens": 0, "vector": null, "score": 0}, {"text": "the distances further I mean so you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 315, "tokens": 0, "vector": null, "score": 0}, {"text": "not adding it to the queue unless it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 316, "tokens": 0, "vector": null, "score": 0}, {"text": "doesn't it's not even worth Computing", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 317, "tokens": 0, "vector": null, "score": 0}, {"text": "the distance so we approximate the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 318, "tokens": 0, "vector": null, "score": 0}, {"text": "distance so in conclusion because most", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 319, "tokens": 0, "vector": null, "score": 0}, {"text": "of these distance calculations don't", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 320, "tokens": 0, "vector": null, "score": 0}, {"text": "contribute to the search we can afford", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 321, "tokens": 0, "vector": null, "score": 0}, {"text": "to approximate these calculations so now", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 322, "tokens": 0, "vector": null, "score": 0}, {"text": "it's time for the devil and details the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 323, "tokens": 0, "vector": null, "score": 0}, {"text": "I think the most important thing to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 324, "tokens": 0, "vector": null, "score": 0}, {"text": "understand about Labor so how are we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 325, "tokens": 0, "vector": null, "score": 0}, {"text": "going to be approximating distance so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 326, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to be showing how to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 327, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate L2 distance with projected", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 328, "tokens": 0, "vector": null, "score": 0}, {"text": "and residual components so let's start", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 329, "tokens": 0, "vector": null, "score": 0}, {"text": "off by just a quick recap of that idea", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 330, "tokens": 0, "vector": null, "score": 0}, {"text": "of projected and residual components so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 331, "tokens": 0, "vector": null, "score": 0}, {"text": "the core intuition is that we have this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 332, "tokens": 0, "vector": null, "score": 0}, {"text": "query vector and then we have the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 333, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor of the center node C that we're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 334, "tokens": 0, "vector": null, "score": 0}, {"text": "exploring we always have this reference", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 335, "tokens": 0, "vector": null, "score": 0}, {"text": "where we're looking at four e Neighbors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 336, "tokens": 0, "vector": null, "score": 0}, {"text": "from C so there's always that kind of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 337, "tokens": 0, "vector": null, "score": 0}, {"text": "relationship as you're exploring nodes", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 338, "tokens": 0, "vector": null, "score": 0}, {"text": "so we're going to be projecting the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 339, "tokens": 0, "vector": null, "score": 0}, {"text": "query and the uh my arms have been that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 340, "tokens": 0, "vector": null, "score": 0}, {"text": "well but like to the center node C so we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 341, "tokens": 0, "vector": null, "score": 0}, {"text": "have the projected and residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 342, "tokens": 0, "vector": null, "score": 0}, {"text": "components so basically I think the key", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 343, "tokens": 0, "vector": null, "score": 0}, {"text": "thing to understand is that the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 344, "tokens": 0, "vector": null, "score": 0}, {"text": "projected component is like how much of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 345, "tokens": 0, "vector": null, "score": 0}, {"text": "this Vector is this other vector so it's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 346, "tokens": 0, "vector": null, "score": 0}, {"text": "going to be a scalar times the original", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 347, "tokens": 0, "vector": null, "score": 0}, {"text": "Vector so Q sub proj is T times the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 348, "tokens": 0, "vector": null, "score": 0}, {"text": "vector C so you know and similarly D is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 349, "tokens": 0, "vector": null, "score": 0}, {"text": "B times the vector C so that one is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 350, "tokens": 0, "vector": null, "score": 0}, {"text": "pretty straightforward and then the the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 351, "tokens": 0, "vector": null, "score": 0}, {"text": "residual ends up being the Q minus the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 352, "tokens": 0, "vector": null, "score": 0}, {"text": "projected component is how you then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 353, "tokens": 0, "vector": null, "score": 0}, {"text": "derive the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 354, "tokens": 0, "vector": null, "score": 0}, {"text": "so with the D projections we can compute", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 355, "tokens": 0, "vector": null, "score": 0}, {"text": "all of that offline because we build a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 356, "tokens": 0, "vector": null, "score": 0}, {"text": "big Matrix of the um of all the edges so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 357, "tokens": 0, "vector": null, "score": 0}, {"text": "you know we we already know what D", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 358, "tokens": 0, "vector": null, "score": 0}, {"text": "projected onto C is going to be and we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 359, "tokens": 0, "vector": null, "score": 0}, {"text": "already have these edges to compute that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 360, "tokens": 0, "vector": null, "score": 0}, {"text": "with so let's actually let's let's get", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 361, "tokens": 0, "vector": null, "score": 0}, {"text": "into the calculation and then we'll step", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 362, "tokens": 0, "vector": null, "score": 0}, {"text": "through each of the four key uh terms in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 363, "tokens": 0, "vector": null, "score": 0}, {"text": "the equation and then you know see how", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 364, "tokens": 0, "vector": null, "score": 0}, {"text": "it's computed so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 365, "tokens": 0, "vector": null, "score": 0}, {"text": "L2 distance Q minus d uh so we're going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 366, "tokens": 0, "vector": null, "score": 0}, {"text": "to break that into the projected and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 367, "tokens": 0, "vector": null, "score": 0}, {"text": "residual components and then you kind of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 368, "tokens": 0, "vector": null, "score": 0}, {"text": "like multiply that out and you end up", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 369, "tokens": 0, "vector": null, "score": 0}, {"text": "with these other terms so the first", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 370, "tokens": 0, "vector": null, "score": 0}, {"text": "thing to note so if you'll see my mouse", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 371, "tokens": 0, "vector": null, "score": 0}, {"text": "is we you know first we split apart just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 372, "tokens": 0, "vector": null, "score": 0}, {"text": "the basic thing of you know Q becomes", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 373, "tokens": 0, "vector": null, "score": 0}, {"text": "the projected plus the residual and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 374, "tokens": 0, "vector": null, "score": 0}, {"text": "D similarly is the projected times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 375, "tokens": 0, "vector": null, "score": 0}, {"text": "residual and you multiply that minus", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 376, "tokens": 0, "vector": null, "score": 0}, {"text": "sign through it I don't know how much of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 377, "tokens": 0, "vector": null, "score": 0}, {"text": "the algebra I should walk through when", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 378, "tokens": 0, "vector": null, "score": 0}, {"text": "you're separating it out but so you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 379, "tokens": 0, "vector": null, "score": 0}, {"text": "then you continue separating it you end", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 380, "tokens": 0, "vector": null, "score": 0}, {"text": "up with this term as you see this again", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 381, "tokens": 0, "vector": null, "score": 0}, {"text": "comes like here as you're breaking into", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 382, "tokens": 0, "vector": null, "score": 0}, {"text": "the LT distance between vectors you'll", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 383, "tokens": 0, "vector": null, "score": 0}, {"text": "often write it as like you know a minus", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 384, "tokens": 0, "vector": null, "score": 0}, {"text": "B transpose times a minus B and then you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 385, "tokens": 0, "vector": null, "score": 0}, {"text": "multiply that out and you end up with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 386, "tokens": 0, "vector": null, "score": 0}, {"text": "the uh you know the the plus two a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 387, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose t b sorry with the T again but", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 388, "tokens": 0, "vector": null, "score": 0}, {"text": "so you end up with this term and because", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 389, "tokens": 0, "vector": null, "score": 0}, {"text": "the projected components are orthogonal", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 390, "tokens": 0, "vector": null, "score": 0}, {"text": "to the residual components this term", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 391, "tokens": 0, "vector": null, "score": 0}, {"text": "just you know exits out but I think the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 392, "tokens": 0, "vector": null, "score": 0}, {"text": "only thing to be real to be seriously", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 393, "tokens": 0, "vector": null, "score": 0}, {"text": "interested in is what you end up with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 394, "tokens": 0, "vector": null, "score": 0}, {"text": "which is this final thing so we have", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 395, "tokens": 0, "vector": null, "score": 0}, {"text": "these four terms terms that we need to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 396, "tokens": 0, "vector": null, "score": 0}, {"text": "compute", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 397, "tokens": 0, "vector": null, "score": 0}, {"text": "so similarly if you're approximating the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 398, "tokens": 0, "vector": null, "score": 0}, {"text": "dot product you don't need to have these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 399, "tokens": 0, "vector": null, "score": 0}, {"text": "additional Norms in the final", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 400, "tokens": 0, "vector": null, "score": 0}, {"text": "calculation so you have these just kind", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 401, "tokens": 0, "vector": null, "score": 0}, {"text": "of inner products so you know if you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 402, "tokens": 0, "vector": null, "score": 0}, {"text": "interested in L2 distance versus cosine", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 403, "tokens": 0, "vector": null, "score": 0}, {"text": "angular distance personally I in my", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 404, "tokens": 0, "vector": null, "score": 0}, {"text": "experiments with playing with you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 405, "tokens": 0, "vector": null, "score": 0}, {"text": "Vector search for a while now I've never", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 406, "tokens": 0, "vector": null, "score": 0}, {"text": "found that you know especially with deep", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 407, "tokens": 0, "vector": null, "score": 0}, {"text": "learning produced vectors that are", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 408, "tokens": 0, "vector": null, "score": 0}, {"text": "already kind of scale normalized for the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 409, "tokens": 0, "vector": null, "score": 0}, {"text": "sake of optimization I just use LT", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 410, "tokens": 0, "vector": null, "score": 0}, {"text": "distance maybe somebody has an opinion", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 411, "tokens": 0, "vector": null, "score": 0}, {"text": "about that and I'd be happy to hear it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 412, "tokens": 0, "vector": null, "score": 0}, {"text": "but I think let's just stick with LT", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 413, "tokens": 0, "vector": null, "score": 0}, {"text": "distance for now all right so as we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 414, "tokens": 0, "vector": null, "score": 0}, {"text": "looked at the derivation of L2 distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 415, "tokens": 0, "vector": null, "score": 0}, {"text": "into projected and residual components", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 416, "tokens": 0, "vector": null, "score": 0}, {"text": "we're left with these four key terms and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 417, "tokens": 0, "vector": null, "score": 0}, {"text": "this is the key detail to understanding", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 418, "tokens": 0, "vector": null, "score": 0}, {"text": "this paper is understanding how each of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 419, "tokens": 0, "vector": null, "score": 0}, {"text": "these four terms are computed offline", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 420, "tokens": 0, "vector": null, "score": 0}, {"text": "okay so the first term is going to be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 421, "tokens": 0, "vector": null, "score": 0}, {"text": "the L2 distance between the query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 422, "tokens": 0, "vector": null, "score": 0}, {"text": "projected and then the neighboring node", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 423, "tokens": 0, "vector": null, "score": 0}, {"text": "projected onto the center node the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 424, "tokens": 0, "vector": null, "score": 0}, {"text": "projection components of each of these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 425, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors so the first Insight is that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 426, "tokens": 0, "vector": null, "score": 0}, {"text": "both of these query projected and the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 427, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor projected are some scalar times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 428, "tokens": 0, "vector": null, "score": 0}, {"text": "the center don't see so we have t times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 429, "tokens": 0, "vector": null, "score": 0}, {"text": "C and we have B times C where T and B", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 430, "tokens": 0, "vector": null, "score": 0}, {"text": "are scalars so from there we're going to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 431, "tokens": 0, "vector": null, "score": 0}, {"text": "break the L2 distance we're going to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 432, "tokens": 0, "vector": null, "score": 0}, {"text": "take out that c that's common to both", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 433, "tokens": 0, "vector": null, "score": 0}, {"text": "and then we just have T minus B squared", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 434, "tokens": 0, "vector": null, "score": 0}, {"text": "and then the L2 Norm of C so we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 435, "tokens": 0, "vector": null, "score": 0}, {"text": "pre-compute the the norm of each of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 436, "tokens": 0, "vector": null, "score": 0}, {"text": "nodes so you know for every node in our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 437, "tokens": 0, "vector": null, "score": 0}, {"text": "database we've computed the note the the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 438, "tokens": 0, "vector": null, "score": 0}, {"text": "norm of it so you just look this up this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 439, "tokens": 0, "vector": null, "score": 0}, {"text": "is a part of the extra memory cost that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 440, "tokens": 0, "vector": null, "score": 0}, {"text": "we'll look into later so then T minus B", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 441, "tokens": 0, "vector": null, "score": 0}, {"text": "squared is just a subtraction", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 442, "tokens": 0, "vector": null, "score": 0}, {"text": "multiplication to itself so it's not", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 443, "tokens": 0, "vector": null, "score": 0}, {"text": "like we don't do any computation but", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 444, "tokens": 0, "vector": null, "score": 0}, {"text": "this is you know as you see in the top", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 445, "tokens": 0, "vector": null, "score": 0}, {"text": "of the memory reason the arithmetic is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 446, "tokens": 0, "vector": null, "score": 0}, {"text": "counting how many um you know the low", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 447, "tokens": 0, "vector": null, "score": 0}, {"text": "level of how many additions and so on", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 448, "tokens": 0, "vector": null, "score": 0}, {"text": "that we need to compute so B can also be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 449, "tokens": 0, "vector": null, "score": 0}, {"text": "precalculated by looking at the same", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 450, "tokens": 0, "vector": null, "score": 0}, {"text": "equation so you know B is going to be", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 451, "tokens": 0, "vector": null, "score": 0}, {"text": "that component of the neighboring node D", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 452, "tokens": 0, "vector": null, "score": 0}, {"text": "of C in that you know and you can", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 453, "tokens": 0, "vector": null, "score": 0}, {"text": "compute that offline so let's get a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 454, "tokens": 0, "vector": null, "score": 0}, {"text": "little more into this so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 455, "tokens": 0, "vector": null, "score": 0}, {"text": "so this T equals query transpose times C", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 456, "tokens": 0, "vector": null, "score": 0}, {"text": "divided by the norm of C that's going to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 457, "tokens": 0, "vector": null, "score": 0}, {"text": "be like the coefficient when you project", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 458, "tokens": 0, "vector": null, "score": 0}, {"text": "a vector onto another Vector would just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 459, "tokens": 0, "vector": null, "score": 0}, {"text": "be this then times the C again I think", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 460, "tokens": 0, "vector": null, "score": 0}, {"text": "is yeah so so from there you can just uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 461, "tokens": 0, "vector": null, "score": 0}, {"text": "break down so then remember we already", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 462, "tokens": 0, "vector": null, "score": 0}, {"text": "loaded in the norm of C from that we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 463, "tokens": 0, "vector": null, "score": 0}, {"text": "pre-computed so now we just need to do", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 464, "tokens": 0, "vector": null, "score": 0}, {"text": "this top part the query transpose times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 465, "tokens": 0, "vector": null, "score": 0}, {"text": "C so that just ends up being the norm of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 466, "tokens": 0, "vector": null, "score": 0}, {"text": "the query again the norm of the center", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 467, "tokens": 0, "vector": null, "score": 0}, {"text": "node that we already computed and then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 468, "tokens": 0, "vector": null, "score": 0}, {"text": "we do need to do this L2 distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 469, "tokens": 0, "vector": null, "score": 0}, {"text": "between the query and the center node", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 470, "tokens": 0, "vector": null, "score": 0}, {"text": "but we only need to do that once to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 471, "tokens": 0, "vector": null, "score": 0}, {"text": "explore the neighborhood of this Center", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 472, "tokens": 0, "vector": null, "score": 0}, {"text": "node so in these H and SW graphs they", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 473, "tokens": 0, "vector": null, "score": 0}, {"text": "often would have like 32 64 edges per", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 474, "tokens": 0, "vector": null, "score": 0}, {"text": "node so you know we just compute this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 475, "tokens": 0, "vector": null, "score": 0}, {"text": "once to then explore the 64 neighbors of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 476, "tokens": 0, "vector": null, "score": 0}, {"text": "the center node and node to each of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 477, "tokens": 0, "vector": null, "score": 0}, {"text": "these D's as We're looping through the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 478, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbors so that's how we get the first", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 479, "tokens": 0, "vector": null, "score": 0}, {"text": "term and hopefully it's clear that just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 480, "tokens": 0, "vector": null, "score": 0}, {"text": "the uh you know the decomposition into", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 481, "tokens": 0, "vector": null, "score": 0}, {"text": "scalars how we're able to pre-compute", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 482, "tokens": 0, "vector": null, "score": 0}, {"text": "the nor form and then you know how how", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 483, "tokens": 0, "vector": null, "score": 0}, {"text": "exactly we compute the T by having it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 484, "tokens": 0, "vector": null, "score": 0}, {"text": "it's the coefficient of the projection", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 485, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of and you know then we break the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 486, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose into this so the next two", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 487, "tokens": 0, "vector": null, "score": 0}, {"text": "terms are pretty quick to uh derive so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 488, "tokens": 0, "vector": null, "score": 0}, {"text": "with the residual Norm we just compute", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 489, "tokens": 0, "vector": null, "score": 0}, {"text": "that offline we just look it up from", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 490, "tokens": 0, "vector": null, "score": 0}, {"text": "memory to add it to our four terms to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 491, "tokens": 0, "vector": null, "score": 0}, {"text": "calculate the uh you know the Q res", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 492, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose D res so then we have the norm", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 493, "tokens": 0, "vector": null, "score": 0}, {"text": "of the residual component of the query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 494, "tokens": 0, "vector": null, "score": 0}, {"text": "so the way that we do this is again the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 495, "tokens": 0, "vector": null, "score": 0}, {"text": "query equals the projected plus the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 496, "tokens": 0, "vector": null, "score": 0}, {"text": "residual components you've separated the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 497, "tokens": 0, "vector": null, "score": 0}, {"text": "original Vector into the residual and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 498, "tokens": 0, "vector": null, "score": 0}, {"text": "projected components just like post each", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 499, "tokens": 0, "vector": null, "score": 0}, {"text": "other and so so to get the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 500, "tokens": 0, "vector": null, "score": 0}, {"text": "component we'll just subtract the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 501, "tokens": 0, "vector": null, "score": 0}, {"text": "project the query from the projected", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 502, "tokens": 0, "vector": null, "score": 0}, {"text": "component so the projected component uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 503, "tokens": 0, "vector": null, "score": 0}, {"text": "so again we calculated that t value in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 504, "tokens": 0, "vector": null, "score": 0}, {"text": "step one so we're now going to square T", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 505, "tokens": 0, "vector": null, "score": 0}, {"text": "and multiply it by that Norm of C that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 506, "tokens": 0, "vector": null, "score": 0}, {"text": "we've pre-computed and loaded into", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 507, "tokens": 0, "vector": null, "score": 0}, {"text": "memory and so now we'll just um you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 508, "tokens": 0, "vector": null, "score": 0}, {"text": "we just have the projected component", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 509, "tokens": 0, "vector": null, "score": 0}, {"text": "that we calculated from t squared times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 510, "tokens": 0, "vector": null, "score": 0}, {"text": "the norm of c and then we just subtract", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 511, "tokens": 0, "vector": null, "score": 0}, {"text": "back to query from that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 512, "tokens": 0, "vector": null, "score": 0}, {"text": "of the the norm of the query sorry and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 513, "tokens": 0, "vector": null, "score": 0}, {"text": "again the norm of the query is um", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 514, "tokens": 0, "vector": null, "score": 0}, {"text": "something that we've already computed so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 515, "tokens": 0, "vector": null, "score": 0}, {"text": "these are these are scalars as we've", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 516, "tokens": 0, "vector": null, "score": 0}, {"text": "computed the norm hopefully that's clear", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 517, "tokens": 0, "vector": null, "score": 0}, {"text": "okay so now for the most interesting of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 518, "tokens": 0, "vector": null, "score": 0}, {"text": "the four terms the angular distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 519, "tokens": 0, "vector": null, "score": 0}, {"text": "between the residual components of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 520, "tokens": 0, "vector": null, "score": 0}, {"text": "query and the neighboring node so first", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 521, "tokens": 0, "vector": null, "score": 0}, {"text": "we're going to break out this transpose", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 522, "tokens": 0, "vector": null, "score": 0}, {"text": "dot product into the norm of the query", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 523, "tokens": 0, "vector": null, "score": 0}, {"text": "plus the norm of the uh the neighboring", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 524, "tokens": 0, "vector": null, "score": 0}, {"text": "nodes residual component times the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 525, "tokens": 0, "vector": null, "score": 0}, {"text": "cosine distance between the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 526, "tokens": 0, "vector": null, "score": 0}, {"text": "component of the query and the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 527, "tokens": 0, "vector": null, "score": 0}, {"text": "component of the neighboring node so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 528, "tokens": 0, "vector": null, "score": 0}, {"text": "this is where now we're going to look", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 529, "tokens": 0, "vector": null, "score": 0}, {"text": "into the singular value decomposition", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 530, "tokens": 0, "vector": null, "score": 0}, {"text": "that is used to do this approximation so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 531, "tokens": 0, "vector": null, "score": 0}, {"text": "what we're going to do is first we're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 532, "tokens": 0, "vector": null, "score": 0}, {"text": "going to create a matrix this d d sub", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 533, "tokens": 0, "vector": null, "score": 0}, {"text": "res the residual Matrix where each entry", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 534, "tokens": 0, "vector": null, "score": 0}, {"text": "in The Matrix is the difference between", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 535, "tokens": 0, "vector": null, "score": 0}, {"text": "the vectors so you know if there's an", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 536, "tokens": 0, "vector": null, "score": 0}, {"text": "edge from A to B", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 537, "tokens": 0, "vector": null, "score": 0}, {"text": "the first entry in The Matrix is going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 538, "tokens": 0, "vector": null, "score": 0}, {"text": "to be a minus B and so and you know then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 539, "tokens": 0, "vector": null, "score": 0}, {"text": "a to F the next one is the difference", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 540, "tokens": 0, "vector": null, "score": 0}, {"text": "between a to F so we construct this big", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 541, "tokens": 0, "vector": null, "score": 0}, {"text": "Matrix that way", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 542, "tokens": 0, "vector": null, "score": 0}, {"text": "and then we get the low rank basis by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 543, "tokens": 0, "vector": null, "score": 0}, {"text": "doing singular value decomposition where", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 544, "tokens": 0, "vector": null, "score": 0}, {"text": "a singular value decomposition you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 545, "tokens": 0, "vector": null, "score": 0}, {"text": "decompose The Matrix into the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 546, "tokens": 0, "vector": null, "score": 0}, {"text": "eigenvectors and the you know like the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 547, "tokens": 0, "vector": null, "score": 0}, {"text": "top R singular values they capture most", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 548, "tokens": 0, "vector": null, "score": 0}, {"text": "of like the variance in the vector so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 549, "tokens": 0, "vector": null, "score": 0}, {"text": "it's like you know like about project", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 550, "tokens": 0, "vector": null, "score": 0}, {"text": "it's kind of like how tsne and PCA and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 551, "tokens": 0, "vector": null, "score": 0}, {"text": "like low rate low dimensional algorithms", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 552, "tokens": 0, "vector": null, "score": 0}, {"text": "work it works like that where you say", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 553, "tokens": 0, "vector": null, "score": 0}, {"text": "these are the components that capture", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 554, "tokens": 0, "vector": null, "score": 0}, {"text": "like the variance in the data so the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 555, "tokens": 0, "vector": null, "score": 0}, {"text": "data being the residual Matrix the uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 556, "tokens": 0, "vector": null, "score": 0}, {"text": "the yeah like the distance Matrix", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 557, "tokens": 0, "vector": null, "score": 0}, {"text": "hopefully that's clear so like that is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 558, "tokens": 0, "vector": null, "score": 0}, {"text": "the you know the the top components of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 559, "tokens": 0, "vector": null, "score": 0}, {"text": "that distance that you then use to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 560, "tokens": 0, "vector": null, "score": 0}, {"text": "project the vectors into that space so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 561, "tokens": 0, "vector": null, "score": 0}, {"text": "okay so now let's look at how we get the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 562, "tokens": 0, "vector": null, "score": 0}, {"text": "other half of that term which is going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 563, "tokens": 0, "vector": null, "score": 0}, {"text": "to be the projected residual component", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 564, "tokens": 0, "vector": null, "score": 0}, {"text": "of the query so first what we're going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 565, "tokens": 0, "vector": null, "score": 0}, {"text": "to do is we're going to leverage that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 566, "tokens": 0, "vector": null, "score": 0}, {"text": "we've already computed a lot of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 567, "tokens": 0, "vector": null, "score": 0}, {"text": "stuff that we can use to derive this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 568, "tokens": 0, "vector": null, "score": 0}, {"text": "without having to do the multiplication", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 569, "tokens": 0, "vector": null, "score": 0}, {"text": "so or or having to compute the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 570, "tokens": 0, "vector": null, "score": 0}, {"text": "component and so on so so we We Begin by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 571, "tokens": 0, "vector": null, "score": 0}, {"text": "knowing that the um that the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 572, "tokens": 0, "vector": null, "score": 0}, {"text": "component is going to be the query minus", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 573, "tokens": 0, "vector": null, "score": 0}, {"text": "the projected component so so we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 574, "tokens": 0, "vector": null, "score": 0}, {"text": "decompose That Into You Know acute", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 575, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose B minus Q projected transpose", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 576, "tokens": 0, "vector": null, "score": 0}, {"text": "B and then from there we expand the Q", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 577, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose projected again remember is T", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 578, "tokens": 0, "vector": null, "score": 0}, {"text": "times the center node that's the that's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 579, "tokens": 0, "vector": null, "score": 0}, {"text": "what the projected Vector is this T", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 580, "tokens": 0, "vector": null, "score": 0}, {"text": "times C thing and T is the scalar of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 581, "tokens": 0, "vector": null, "score": 0}, {"text": "like how much of the center node the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 582, "tokens": 0, "vector": null, "score": 0}, {"text": "projected component of the query is so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 583, "tokens": 0, "vector": null, "score": 0}, {"text": "so then we break that up into again the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 584, "tokens": 0, "vector": null, "score": 0}, {"text": "t is calculated like this where QTC and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 585, "tokens": 0, "vector": null, "score": 0}, {"text": "again we've already calculated that so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 586, "tokens": 0, "vector": null, "score": 0}, {"text": "we already have that calculation and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 587, "tokens": 0, "vector": null, "score": 0}, {"text": "this um so this qtb the the reason that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 588, "tokens": 0, "vector": null, "score": 0}, {"text": "that's interesting to put in the front", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 589, "tokens": 0, "vector": null, "score": 0}, {"text": "is because we can just compute this once", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 590, "tokens": 0, "vector": null, "score": 0}, {"text": "for the query to then do our entire", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 591, "tokens": 0, "vector": null, "score": 0}, {"text": "search with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 592, "tokens": 0, "vector": null, "score": 0}, {"text": "because um none of these are dependent", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 593, "tokens": 0, "vector": null, "score": 0}, {"text": "on the center node C you know when we're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 594, "tokens": 0, "vector": null, "score": 0}, {"text": "projecting or the residual component", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 595, "tokens": 0, "vector": null, "score": 0}, {"text": "there's always going to be that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 596, "tokens": 0, "vector": null, "score": 0}, {"text": "reference C that we're doing this from", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 597, "tokens": 0, "vector": null, "score": 0}, {"text": "whereas the qtb that's just Universal to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 598, "tokens": 0, "vector": null, "score": 0}, {"text": "every single traversal we're going to do", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 599, "tokens": 0, "vector": null, "score": 0}, {"text": "so then we get the Q res uh TB from this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 600, "tokens": 0, "vector": null, "score": 0}, {"text": "these subtractions and then we take the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 601, "tokens": 0, "vector": null, "score": 0}, {"text": "sign of it and then we just have the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 602, "tokens": 0, "vector": null, "score": 0}, {"text": "Hamming distance between the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 603, "tokens": 0, "vector": null, "score": 0}, {"text": "transpose B that we derived from this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 604, "tokens": 0, "vector": null, "score": 0}, {"text": "and then again the Dres TB that we've", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 605, "tokens": 0, "vector": null, "score": 0}, {"text": "computed offline and saved as this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 606, "tokens": 0, "vector": null, "score": 0}, {"text": "binary representation okay so hopefully", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 607, "tokens": 0, "vector": null, "score": 0}, {"text": "that's a clear explanation of where we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 608, "tokens": 0, "vector": null, "score": 0}, {"text": "get each of these four terms from then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 609, "tokens": 0, "vector": null, "score": 0}, {"text": "we just combine them by adding them", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 610, "tokens": 0, "vector": null, "score": 0}, {"text": "together and then we have the distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 611, "tokens": 0, "vector": null, "score": 0}, {"text": "of the query and this neighboring node D", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 612, "tokens": 0, "vector": null, "score": 0}, {"text": "so they show uh later on when they", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 613, "tokens": 0, "vector": null, "score": 0}, {"text": "ablate the comparison between that SVD", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 614, "tokens": 0, "vector": null, "score": 0}, {"text": "of the residual and compared to say if", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 615, "tokens": 0, "vector": null, "score": 0}, {"text": "you know if you don't have these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 616, "tokens": 0, "vector": null, "score": 0}, {"text": "additional terms as well so you only", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 617, "tokens": 0, "vector": null, "score": 0}, {"text": "took the the sign of the Hamming", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 618, "tokens": 0, "vector": null, "score": 0}, {"text": "distance between the um you know the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 619, "tokens": 0, "vector": null, "score": 0}, {"text": "residual the query and the residual the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 620, "tokens": 0, "vector": null, "score": 0}, {"text": "distance they'll show some ablations on", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 621, "tokens": 0, "vector": null, "score": 0}, {"text": "why having all these terms helps with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 622, "tokens": 0, "vector": null, "score": 0}, {"text": "the stability of this algorithm and the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 623, "tokens": 0, "vector": null, "score": 0}, {"text": "accurate approximation of the distance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 624, "tokens": 0, "vector": null, "score": 0}, {"text": "calculation so let's get more into the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 625, "tokens": 0, "vector": null, "score": 0}, {"text": "memory cost of doing this and I think", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 626, "tokens": 0, "vector": null, "score": 0}, {"text": "that'll really help clarify what's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 627, "tokens": 0, "vector": null, "score": 0}, {"text": "happening here so for each node we're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 628, "tokens": 0, "vector": null, "score": 0}, {"text": "calculating the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 629, "tokens": 0, "vector": null, "score": 0}, {"text": "uh the projection of it onto that low", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 630, "tokens": 0, "vector": null, "score": 0}, {"text": "rank basis so this is what we would then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 631, "tokens": 0, "vector": null, "score": 0}, {"text": "use as reference in in those CTB so this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 632, "tokens": 0, "vector": null, "score": 0}, {"text": "is this is computed for each node if", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 633, "tokens": 0, "vector": null, "score": 0}, {"text": "we're then going to be exploring from", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 634, "tokens": 0, "vector": null, "score": 0}, {"text": "that node to its neighbor so this node", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 635, "tokens": 0, "vector": null, "score": 0}, {"text": "is going to be the C in our reference", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 636, "tokens": 0, "vector": null, "score": 0}, {"text": "and then we're exploring the D neighbors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 637, "tokens": 0, "vector": null, "score": 0}, {"text": "of C so then we also compute the uh the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 638, "tokens": 0, "vector": null, "score": 0}, {"text": "norm of each uh of each of these nodes", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 639, "tokens": 0, "vector": null, "score": 0}, {"text": "that would again look up several times", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 640, "tokens": 0, "vector": null, "score": 0}, {"text": "in the in the calculation so this is the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 641, "tokens": 0, "vector": null, "score": 0}, {"text": "extra memory for each node now the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 642, "tokens": 0, "vector": null, "score": 0}, {"text": "really the memory comes for each Edge so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 643, "tokens": 0, "vector": null, "score": 0}, {"text": "we have for each Edge we're going to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 644, "tokens": 0, "vector": null, "score": 0}, {"text": "have the sine code so again we have that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 645, "tokens": 0, "vector": null, "score": 0}, {"text": "D res TB so we're Computing that and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 646, "tokens": 0, "vector": null, "score": 0}, {"text": "storing that offline so that's our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 647, "tokens": 0, "vector": null, "score": 0}, {"text": "binary uh representation of the residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 648, "tokens": 0, "vector": null, "score": 0}, {"text": "projected with the B then we have four", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 649, "tokens": 0, "vector": null, "score": 0}, {"text": "bytes of the pro projection coefficient", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 650, "tokens": 0, "vector": null, "score": 0}, {"text": "B so again we use that that b to have", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 651, "tokens": 0, "vector": null, "score": 0}, {"text": "the T minus B squared in the um in the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 652, "tokens": 0, "vector": null, "score": 0}, {"text": "calculation of the original distance of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 653, "tokens": 0, "vector": null, "score": 0}, {"text": "the projected query in the projected", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 654, "tokens": 0, "vector": null, "score": 0}, {"text": "node and then we also store the no the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 655, "tokens": 0, "vector": null, "score": 0}, {"text": "norm of the residual component for each", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 656, "tokens": 0, "vector": null, "score": 0}, {"text": "of the nodes for in the edge so the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 657, "tokens": 0, "vector": null, "score": 0}, {"text": "residual component with respect to this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 658, "tokens": 0, "vector": null, "score": 0}, {"text": "Source uh so like if it's a to B and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 659, "tokens": 0, "vector": null, "score": 0}, {"text": "we're looking at it from the perspective", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 660, "tokens": 0, "vector": null, "score": 0}, {"text": "of B and sorry a is like our C Center no", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 661, "tokens": 0, "vector": null, "score": 0}, {"text": "lowercase C so we're storing the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 662, "tokens": 0, "vector": null, "score": 0}, {"text": "residual of that the norm of that for", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 663, "tokens": 0, "vector": null, "score": 0}, {"text": "each Edge that again we look up several", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 664, "tokens": 0, "vector": null, "score": 0}, {"text": "times with this calculation putting that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 665, "tokens": 0, "vector": null, "score": 0}, {"text": "together that results in the additional", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 666, "tokens": 0, "vector": null, "score": 0}, {"text": "memory being the number of nodes we have", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 667, "tokens": 0, "vector": null, "score": 0}, {"text": "the Delta V for vertices graph being", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 668, "tokens": 0, "vector": null, "score": 0}, {"text": "made of vertices and edges we have the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 669, "tokens": 0, "vector": null, "score": 0}, {"text": "number of vertices times four R plus one", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 670, "tokens": 0, "vector": null, "score": 0}, {"text": "and then the number of edges times R", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 671, "tokens": 0, "vector": null, "score": 0}, {"text": "over eight plus eight so what that ends", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 672, "tokens": 0, "vector": null, "score": 0}, {"text": "up oh sorry what that ends up meaning is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 673, "tokens": 0, "vector": null, "score": 0}, {"text": "so let's say for example we have the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 674, "tokens": 0, "vector": null, "score": 0}, {"text": "data set that just one million vectors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 675, "tokens": 0, "vector": null, "score": 0}, {"text": "with 960 Dimensions per vector and say", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 676, "tokens": 0, "vector": null, "score": 0}, {"text": "we have a maximal 96 edges per node so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 677, "tokens": 0, "vector": null, "score": 0}, {"text": "we end up having one million times and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 678, "tokens": 0, "vector": null, "score": 0}, {"text": "then the four times say we use 64 as the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 679, "tokens": 0, "vector": null, "score": 0}, {"text": "low rank for that projection so we keep", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 680, "tokens": 0, "vector": null, "score": 0}, {"text": "the top 64 singular values of that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 681, "tokens": 0, "vector": null, "score": 0}, {"text": "projection and then we and then we add", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 682, "tokens": 0, "vector": null, "score": 0}, {"text": "that with the 96 million edges of which", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 683, "tokens": 0, "vector": null, "score": 0}, {"text": "we then have in this case 16 additional", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 684, "tokens": 0, "vector": null, "score": 0}, {"text": "bytes per each of these edges so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 685, "tokens": 0, "vector": null, "score": 0}, {"text": "so you can see how kind of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 686, "tokens": 0, "vector": null, "score": 0}, {"text": "relationship between how many vectors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 687, "tokens": 0, "vector": null, "score": 0}, {"text": "you have and how many edges per node you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 688, "tokens": 0, "vector": null, "score": 0}, {"text": "have and how that scales with this so I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 689, "tokens": 0, "vector": null, "score": 0}, {"text": "guess kind of interestingly yeah so you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 690, "tokens": 0, "vector": null, "score": 0}, {"text": "know you have this 96 times 1 million", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 691, "tokens": 0, "vector": null, "score": 0}, {"text": "for the edges so maybe when you're using", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 692, "tokens": 0, "vector": null, "score": 0}, {"text": "this you'd want to have I guess the more", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 693, "tokens": 0, "vector": null, "score": 0}, {"text": "edges you have the more computation you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 694, "tokens": 0, "vector": null, "score": 0}, {"text": "would save when you're exploring the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 695, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbors of that Center node but then", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 696, "tokens": 0, "vector": null, "score": 0}, {"text": "you know that would lead to more memory", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 697, "tokens": 0, "vector": null, "score": 0}, {"text": "overhead is you have 96 and then you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 698, "tokens": 0, "vector": null, "score": 0}, {"text": "know going on into whatever number but", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 699, "tokens": 0, "vector": null, "score": 0}, {"text": "so in the end we end up having 1.7", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 700, "tokens": 0, "vector": null, "score": 0}, {"text": "gigabytes extra added with this finger", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 701, "tokens": 0, "vector": null, "score": 0}, {"text": "index so the offline values for the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 702, "tokens": 0, "vector": null, "score": 0}, {"text": "finger index and so with respect to this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 703, "tokens": 0, "vector": null, "score": 0}, {"text": "just example where the it would", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 704, "tokens": 0, "vector": null, "score": 0}, {"text": "originally be 3.6 gigabytes for the data", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 705, "tokens": 0, "vector": null, "score": 0}, {"text": "points and so you know you're talking", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 706, "tokens": 0, "vector": null, "score": 0}, {"text": "about like adding like half so in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 707, "tokens": 0, "vector": null, "score": 0}, {"text": "addition to the memory overhead there is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 708, "tokens": 0, "vector": null, "score": 0}, {"text": "the time overhead of calculating all", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 709, "tokens": 0, "vector": null, "score": 0}, {"text": "those values they find their experiments", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 710, "tokens": 0, "vector": null, "score": 0}, {"text": "that it adds about 10 extra time so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 711, "tokens": 0, "vector": null, "score": 0}, {"text": "that's really not too bad if you look", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 712, "tokens": 0, "vector": null, "score": 0}, {"text": "further into the detail they have the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 713, "tokens": 0, "vector": null, "score": 0}, {"text": "derivation of you know all those memory", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 714, "tokens": 0, "vector": null, "score": 0}, {"text": "reads and arithmetics if you want to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 715, "tokens": 0, "vector": null, "score": 0}, {"text": "look into the distance between just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 716, "tokens": 0, "vector": null, "score": 0}, {"text": "doing full L2 distance and then you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 717, "tokens": 0, "vector": null, "score": 0}, {"text": "the series of steps that we looked at", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 718, "tokens": 0, "vector": null, "score": 0}, {"text": "with calculating those four components", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 719, "tokens": 0, "vector": null, "score": 0}, {"text": "so so another clever technique that they", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 720, "tokens": 0, "vector": null, "score": 0}, {"text": "use is distribution matching between the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 721, "tokens": 0, "vector": null, "score": 0}, {"text": "real distances between the neighboring", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 722, "tokens": 0, "vector": null, "score": 0}, {"text": "node and the center node and the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 723, "tokens": 0, "vector": null, "score": 0}, {"text": "approximated distances so oh sorry so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 724, "tokens": 0, "vector": null, "score": 0}, {"text": "what this ends up looking like is shown", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 725, "tokens": 0, "vector": null, "score": 0}, {"text": "in the green you have the real distances", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 726, "tokens": 0, "vector": null, "score": 0}, {"text": "tend to be gaussian distributed whereas", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 727, "tokens": 0, "vector": null, "score": 0}, {"text": "once you approximate them with this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 728, "tokens": 0, "vector": null, "score": 0}, {"text": "projection they end up being a little", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 729, "tokens": 0, "vector": null, "score": 0}, {"text": "right skewed so what you end up doing is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 730, "tokens": 0, "vector": null, "score": 0}, {"text": "you calculate the mean and the variance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 731, "tokens": 0, "vector": null, "score": 0}, {"text": "of the real distances with that residual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 732, "tokens": 0, "vector": null, "score": 0}, {"text": "Matrix and then you also calculate the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 733, "tokens": 0, "vector": null, "score": 0}, {"text": "mean and the variance of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 734, "tokens": 0, "vector": null, "score": 0}, {"text": "approximated distances and so then you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 735, "tokens": 0, "vector": null, "score": 0}, {"text": "would normalize this approximated", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 736, "tokens": 0, "vector": null, "score": 0}, {"text": "distance score by having Tu to use the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 737, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate distance not the scalar the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 738, "tokens": 0, "vector": null, "score": 0}, {"text": "coefficient from the projected thing", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 739, "tokens": 0, "vector": null, "score": 0}, {"text": "earlier but so this approximated", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 740, "tokens": 0, "vector": null, "score": 0}, {"text": "distance becomes you know what it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 741, "tokens": 0, "vector": null, "score": 0}, {"text": "originally was minus the mean of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 742, "tokens": 0, "vector": null, "score": 0}, {"text": "approximated distances for all of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 743, "tokens": 0, "vector": null, "score": 0}, {"text": "distances and then you know the variance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 744, "tokens": 0, "vector": null, "score": 0}, {"text": "over the mean of the very audience and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 745, "tokens": 0, "vector": null, "score": 0}, {"text": "then you know plus the new means so this", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 746, "tokens": 0, "vector": null, "score": 0}, {"text": "is a way to try to you know align the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 747, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution and make it more like the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 748, "tokens": 0, "vector": null, "score": 0}, {"text": "real and the real distribution of the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 749, "tokens": 0, "vector": null, "score": 0}, {"text": "distances so now let's get into the fun", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 750, "tokens": 0, "vector": null, "score": 0}, {"text": "part the results of the experiment so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 751, "tokens": 0, "vector": null, "score": 0}, {"text": "they're going to be testing this with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 752, "tokens": 0, "vector": null, "score": 0}, {"text": "six different data sets and two", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 753, "tokens": 0, "vector": null, "score": 0}, {"text": "different uh distance metrics euclidean", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 754, "tokens": 0, "vector": null, "score": 0}, {"text": "as well as angular distance so just in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 755, "tokens": 0, "vector": null, "score": 0}, {"text": "case you were worried about that from", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 756, "tokens": 0, "vector": null, "score": 0}, {"text": "originally looking at the difference", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 757, "tokens": 0, "vector": null, "score": 0}, {"text": "between the L2 distance derivation and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 758, "tokens": 0, "vector": null, "score": 0}, {"text": "say you know cosine distance and so on", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 759, "tokens": 0, "vector": null, "score": 0}, {"text": "so they also do test it with the angular", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 760, "tokens": 0, "vector": null, "score": 0}, {"text": "distance so I think the most interesting", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 761, "tokens": 0, "vector": null, "score": 0}, {"text": "thing to see is the gist 960 shows the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 762, "tokens": 0, "vector": null, "score": 0}, {"text": "biggest benefit shown in the red is the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 763, "tokens": 0, "vector": null, "score": 0}, {"text": "hsw finger what you're looking at is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 764, "tokens": 0, "vector": null, "score": 0}, {"text": "queries per second versus recall so in", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 765, "tokens": 0, "vector": null, "score": 0}, {"text": "the a n benchmarks evaluation protocol", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 766, "tokens": 0, "vector": null, "score": 0}, {"text": "you look at different hyper parameters", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 767, "tokens": 0, "vector": null, "score": 0}, {"text": "where you could you can get really good", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 768, "tokens": 0, "vector": null, "score": 0}, {"text": "recall by trading it off speed by say", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 769, "tokens": 0, "vector": null, "score": 0}, {"text": "increasing that EF and so on so so they", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 770, "tokens": 0, "vector": null, "score": 0}, {"text": "they Loop through the hyper parameters", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 771, "tokens": 0, "vector": null, "score": 0}, {"text": "then put a plot on each of these curves", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 772, "tokens": 0, "vector": null, "score": 0}, {"text": "with um the recall and then the speed so", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 773, "tokens": 0, "vector": null, "score": 0}, {"text": "you always are going to have that kind", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 774, "tokens": 0, "vector": null, "score": 0}, {"text": "of like accuracy versus speed trade-off", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 775, "tokens": 0, "vector": null, "score": 0}, {"text": "when configuring approximate nearest", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 776, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor search algorithms so anyways I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 777, "tokens": 0, "vector": null, "score": 0}, {"text": "think the interesting thing is that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 778, "tokens": 0, "vector": null, "score": 0}, {"text": "shown in the top right the higher", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 779, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vectors get much better", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 780, "tokens": 0, "vector": null, "score": 0}, {"text": "result that's also consistent with the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 781, "tokens": 0, "vector": null, "score": 0}, {"text": "784 from the fashion mnist", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 782, "tokens": 0, "vector": null, "score": 0}, {"text": "but this one is you know the most", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 783, "tokens": 0, "vector": null, "score": 0}, {"text": "significant probably here as well", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 784, "tokens": 0, "vector": null, "score": 0}, {"text": "looking at you know you know like 1500", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 785, "tokens": 0, "vector": null, "score": 0}, {"text": "versus uh you know 500 so you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 786, "tokens": 0, "vector": null, "score": 0}, {"text": "somewhere like in this particular you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 787, "tokens": 0, "vector": null, "score": 0}, {"text": "know measurement of it it's a pretty", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 788, "tokens": 0, "vector": null, "score": 0}, {"text": "massive speed up but generally they say", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 789, "tokens": 0, "vector": null, "score": 0}, {"text": "something like 20 to 50 faster but you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 790, "tokens": 0, "vector": null, "score": 0}, {"text": "know these lower dimensional 96 100 128", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 791, "tokens": 0, "vector": null, "score": 0}, {"text": "they don't seem to see as much of a", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 792, "tokens": 0, "vector": null, "score": 0}, {"text": "benefit from this so I think it's also", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 793, "tokens": 0, "vector": null, "score": 0}, {"text": "just worth mentioning that the text", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 794, "tokens": 0, "vector": null, "score": 0}, {"text": "embedding uh 802 they're 1536", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 795, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional so it makes sense to think", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 796, "tokens": 0, "vector": null, "score": 0}, {"text": "that they would the finger would look", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 797, "tokens": 0, "vector": null, "score": 0}, {"text": "like this with those particular", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 798, "tokens": 0, "vector": null, "score": 0}, {"text": "embeddings so some additional results of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 799, "tokens": 0, "vector": null, "score": 0}, {"text": "the authors comparing hsw finger with", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 800, "tokens": 0, "vector": null, "score": 0}, {"text": "two other techniques that I personally", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 801, "tokens": 0, "vector": null, "score": 0}, {"text": "haven't looked into so I can't speak to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 802, "tokens": 0, "vector": null, "score": 0}, {"text": "you too much but they also add some kind", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 803, "tokens": 0, "vector": null, "score": 0}, {"text": "of uh distance approximation on top of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 804, "tokens": 0, "vector": null, "score": 0}, {"text": "the hsw proximity graph they also test", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 805, "tokens": 0, "vector": null, "score": 0}, {"text": "the importance of using the finger", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 806, "tokens": 0, "vector": null, "score": 0}, {"text": "algorithm compared to say random", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 807, "tokens": 0, "vector": null, "score": 0}, {"text": "projection locality sensitive hashing or", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 808, "tokens": 0, "vector": null, "score": 0}, {"text": "say you don't do the full derivation of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 809, "tokens": 0, "vector": null, "score": 0}, {"text": "the terms and you just measure that Q", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 810, "tokens": 0, "vector": null, "score": 0}, {"text": "res t uh d-rez part at the end so that's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 811, "tokens": 0, "vector": null, "score": 0}, {"text": "what the Asian SW SVD thing is so they", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 812, "tokens": 0, "vector": null, "score": 0}, {"text": "do show that you're getting much better", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 813, "tokens": 0, "vector": null, "score": 0}, {"text": "recall by using the um the finger as it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 814, "tokens": 0, "vector": null, "score": 0}, {"text": "is where you use the um you know the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 815, "tokens": 0, "vector": null, "score": 0}, {"text": "actual distribution of the data to do", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 816, "tokens": 0, "vector": null, "score": 0}, {"text": "the low rank approximation compared to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 817, "tokens": 0, "vector": null, "score": 0}, {"text": "just like random projection where you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 818, "tokens": 0, "vector": null, "score": 0}, {"text": "randomly sample vectors to project it", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 819, "tokens": 0, "vector": null, "score": 0}, {"text": "into the space into the lower", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 820, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional space and end ideas like", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 821, "tokens": 0, "vector": null, "score": 0}, {"text": "this so here are some of the reflections", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 822, "tokens": 0, "vector": null, "score": 0}, {"text": "I had after reading this paper uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 823, "tokens": 0, "vector": null, "score": 0}, {"text": "firstly I think it's very interesting to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 824, "tokens": 0, "vector": null, "score": 0}, {"text": "consider uh hsw finger and product", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 825, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization so product quantization is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 826, "tokens": 0, "vector": null, "score": 0}, {"text": "where you compress vectors by you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 827, "tokens": 0, "vector": null, "score": 0}, {"text": "you have this vector and then you'll", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 828, "tokens": 0, "vector": null, "score": 0}, {"text": "slide these windows and then you'll", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 829, "tokens": 0, "vector": null, "score": 0}, {"text": "cluster each of the windows and then you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 830, "tokens": 0, "vector": null, "score": 0}, {"text": "will represent the window with the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 831, "tokens": 0, "vector": null, "score": 0}, {"text": "centroid ID so by doing this you know", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 832, "tokens": 0, "vector": null, "score": 0}, {"text": "say you have like zero you know two", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 833, "tokens": 0, "vector": null, "score": 0}, {"text": "64-bit values and then you've compressed", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 834, "tokens": 0, "vector": null, "score": 0}, {"text": "it to like an 8-bit ID too that's", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 835, "tokens": 0, "vector": null, "score": 0}, {"text": "basically the idea and so product", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 836, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization is about saving memory and", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 837, "tokens": 0, "vector": null, "score": 0}, {"text": "trying to reduce the memory overhead of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 838, "tokens": 0, "vector": null, "score": 0}, {"text": "hnsw", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 839, "tokens": 0, "vector": null, "score": 0}, {"text": "but also kind of what's interesting", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 840, "tokens": 0, "vector": null, "score": 0}, {"text": "about it is you end up using it for disk", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 841, "tokens": 0, "vector": null, "score": 0}, {"text": "based Solutions so like disc NN is about", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 842, "tokens": 0, "vector": null, "score": 0}, {"text": "you you load these pre-computed I'm", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 843, "tokens": 0, "vector": null, "score": 0}, {"text": "sorry you load the um the compressed", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 844, "tokens": 0, "vector": null, "score": 0}, {"text": "representations and this way you get", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 845, "tokens": 0, "vector": null, "score": 0}, {"text": "away with not needing to have so much", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 846, "tokens": 0, "vector": null, "score": 0}, {"text": "RAM for doing it and I think hnsw finger", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 847, "tokens": 0, "vector": null, "score": 0}, {"text": "could also have a similar kind of", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 848, "tokens": 0, "vector": null, "score": 0}, {"text": "application to disk where you don't", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 849, "tokens": 0, "vector": null, "score": 0}, {"text": "really need the real vectors anymore for", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 850, "tokens": 0, "vector": null, "score": 0}, {"text": "the actual traversal of the vector as we", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 851, "tokens": 0, "vector": null, "score": 0}, {"text": "saw you're just doing the distances", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 852, "tokens": 0, "vector": null, "score": 0}, {"text": "between these uh pre-computed values", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 853, "tokens": 0, "vector": null, "score": 0}, {"text": "that don't require the full Precision or", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 854, "tokens": 0, "vector": null, "score": 0}, {"text": "you know whatever the original Vector", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 855, "tokens": 0, "vector": null, "score": 0}, {"text": "was rather you just have these", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 856, "tokens": 0, "vector": null, "score": 0}, {"text": "components so you know even though", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 857, "tokens": 0, "vector": null, "score": 0}, {"text": "you're adding memory to the thing if you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 858, "tokens": 0, "vector": null, "score": 0}, {"text": "want to preserve the original vectors", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 859, "tokens": 0, "vector": null, "score": 0}, {"text": "you don't I don't think you need those", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 860, "tokens": 0, "vector": null, "score": 0}, {"text": "original vectors for the actual", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 861, "tokens": 0, "vector": null, "score": 0}, {"text": "traversal part so this is kind of some", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 862, "tokens": 0, "vector": null, "score": 0}, {"text": "quick thinking about I haven't really", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 863, "tokens": 0, "vector": null, "score": 0}, {"text": "put too much thought into that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 864, "tokens": 0, "vector": null, "score": 0}, {"text": "particularly but I think the next", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 865, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting thing is just measuring the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 866, "tokens": 0, "vector": null, "score": 0}, {"text": "online maintenance of this kind of low", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 867, "tokens": 0, "vector": null, "score": 0}, {"text": "rank projection in that residual Matrix", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 868, "tokens": 0, "vector": null, "score": 0}, {"text": "you know what happens as you add more", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 869, "tokens": 0, "vector": null, "score": 0}, {"text": "data that's kind of one of the big", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 870, "tokens": 0, "vector": null, "score": 0}, {"text": "things that separates Vector databases", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 871, "tokens": 0, "vector": null, "score": 0}, {"text": "from Vector libraries is", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 872, "tokens": 0, "vector": null, "score": 0}, {"text": "you know people continually add data", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 873, "tokens": 0, "vector": null, "score": 0}, {"text": "into the index so how often are we going", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 874, "tokens": 0, "vector": null, "score": 0}, {"text": "to need to recompute all these values", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 875, "tokens": 0, "vector": null, "score": 0}, {"text": "because we would need to like reproject", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 876, "tokens": 0, "vector": null, "score": 0}, {"text": "it and so on that's also the problem", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 877, "tokens": 0, "vector": null, "score": 0}, {"text": "with product quantization is you're", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 878, "tokens": 0, "vector": null, "score": 0}, {"text": "doing that K means to Cluster those", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 879, "tokens": 0, "vector": null, "score": 0}, {"text": "centroid IDs and then it's like well how", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 880, "tokens": 0, "vector": null, "score": 0}, {"text": "many of these do we need to load before", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 881, "tokens": 0, "vector": null, "score": 0}, {"text": "we have a representative sample so I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 882, "tokens": 0, "vector": null, "score": 0}, {"text": "think also that kind of distribution", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 883, "tokens": 0, "vector": null, "score": 0}, {"text": "shift could be a really powerful uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 884, "tokens": 0, "vector": null, "score": 0}, {"text": "lever for that online maintenance", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 885, "tokens": 0, "vector": null, "score": 0}, {"text": "because if you just know the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 886, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution you see the the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 887, "tokens": 0, "vector": null, "score": 0}, {"text": "distribution starts to skew you can you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 888, "tokens": 0, "vector": null, "score": 0}, {"text": "know just kind of align it with that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 889, "tokens": 0, "vector": null, "score": 0}, {"text": "normalization trick and then further I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 890, "tokens": 0, "vector": null, "score": 0}, {"text": "just think finally this like using the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 891, "tokens": 0, "vector": null, "score": 0}, {"text": "data distribution in these a n indexes", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 892, "tokens": 0, "vector": null, "score": 0}, {"text": "they already kind of you know do that", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 893, "tokens": 0, "vector": null, "score": 0}, {"text": "with how the edges are constructed but I", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 894, "tokens": 0, "vector": null, "score": 0}, {"text": "think explicitly doing things like", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 895, "tokens": 0, "vector": null, "score": 0}, {"text": "compression with the data itself thank", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 896, "tokens": 0, "vector": null, "score": 0}, {"text": "you so much for watching this paper", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 897, "tokens": 0, "vector": null, "score": 0}, {"text": "summary video of hnsw finger this paper", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 898, "tokens": 0, "vector": null, "score": 0}, {"text": "is such an exciting way to speed up", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 899, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate nearest neighbor search by", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 900, "tokens": 0, "vector": null, "score": 0}, {"text": "pre-computing these values to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 901, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate that distance calculation uh", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 902, "tokens": 0, "vector": null, "score": 0}, {"text": "there are a lot of details to this paper", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 903, "tokens": 0, "vector": null, "score": 0}, {"text": "some memory and I hope that I got a lot", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 904, "tokens": 0, "vector": null, "score": 0}, {"text": "of them right if you find anything wrong", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 905, "tokens": 0, "vector": null, "score": 0}, {"text": "please don't hesitate to leave it in the", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 906, "tokens": 0, "vector": null, "score": 0}, {"text": "comments and you know help my", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 907, "tokens": 0, "vector": null, "score": 0}, {"text": "understanding as well as everyone", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 908, "tokens": 0, "vector": null, "score": 0}, {"text": "listening hopefully so again thank you", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 909, "tokens": 0, "vector": null, "score": 0}, {"text": "so much for watching if you want to", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 910, "tokens": 0, "vector": null, "score": 0}, {"text": "learn more about weediate you can check", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 911, "tokens": 0, "vector": null, "score": 0}, {"text": "it out on weevia i o Open Source on", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 912, "tokens": 0, "vector": null, "score": 0}, {"text": "GitHub weekend and then on Twitter at", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 913, "tokens": 0, "vector": null, "score": 0}, {"text": "webiate underscore IO also join our", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 914, "tokens": 0, "vector": null, "score": 0}, {"text": "community slack and discuss these ideas", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 915, "tokens": 0, "vector": null, "score": 0}, {"text": "around approximate nearest neighbor", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 916, "tokens": 0, "vector": null, "score": 0}, {"text": "search I think it's so exciting to see", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 917, "tokens": 0, "vector": null, "score": 0}, {"text": "more research with this and I it's just", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 918, "tokens": 0, "vector": null, "score": 0}, {"text": "such an exciting part of Libya is how do", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 919, "tokens": 0, "vector": null, "score": 0}, {"text": "we you know compute these Vector", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 920, "tokens": 0, "vector": null, "score": 0}, {"text": "distances efficiently so thanks so much", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 921, "tokens": 0, "vector": null, "score": 0}, {"text": "for watching", "doc_name": "HNSW-FINGER Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 922, "tokens": 0, "vector": null, "score": 0}]}