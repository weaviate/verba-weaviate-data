{"text": "Hey everyone! Thank you so much for watching the 55th episode of the Weaviate Podcast with Aleksa Gordic! This episodes dives ... \nhey everyone thank you so much for watching the Wii gay podcast I'm super excited to welcome Alexa gordich Alexa is one of the most well-known AI uh I don't want to say influencers because it you know kind of how the term has evolved now I mean like here are 10 ways Chachi BT can make you a million dollars but you know Alexa I like to think of this cohort of uh I guess myself Alexa Yannick Tim and latita at there was this time where we were making a paper summary deep learning paper summary videos on YouTube and it felt like we were kind of the cohort doing this and it was a really fun kind of time in the evolution of my career and so always been like where what Alex is doing and recently his story with um you know joining Deep Mind from that and then leaving deepmind to start orders this whole thing is so inspiring I love how you have these YouTube videos where you you know hey I'm in Japan and I've just got out of Y combinator and I'm here hacking all night I love the storytelling of it it's so much fun so before going any further Alexa thank you so much for joining the podcast thanks thanks a lot for the beautiful introduction and yeah please don't call me an influence right it definitely has a negative connotation in my mind as well yeah why I do let me I do want to give you some some credit into the technical chops that you have quickly on this YouTube thing um so you know playing this game with you and Yannick and you know and we were in this race to like you know summarize a paper try to get as much attention for this summary as you can to build the YouTube channel and all this and I think a couple things that you did that really stood out to me as like you know watching what you were doing across the fence and you know competing with you as well as saying like how what can I still in this guy I never consider this competition to be honest like I I like I think the the space was big enough like it's a global scene and like there were only a couple of us so I I I really never considered the competition and like I'm also very bullish on Peter thiel's like competition is for losers so that's it yeah I didn't know it yeah I agree with that super strongly I think there's a lot of things that markets are underserved in competition I don't think of it as only one of us can win but even with Vector databases I think it is like you know what are these other people doing and competition I think is a big force that shows you like these ideas and it would be foolish to just not even look at the other people doing the thing right but but two things I want to really give you credit for is um first I remember uh when you started diving into the graph of neural network stuff you did some really impressive paper summaries and to kind of read a couple of off them the um the neural sheath diffusion one as well sorry my thing yeah that one was very hard and there was nothing in the early days like in the first batch of My Graph ml videos it was more like the the the the popular ones like the graph attention Apple from Petro Valley Church graph convolutional networks from uh Thomas keep a couple of those um I guess uh we would hire a number of say patients and then this one came I think way like after that for first wave of like the initial series but yeah that one was super tough and if you ask me now like the details about the paper like I haven't done it in a while so it would be very hard to recall all the details but I did understand it back then yeah well yeah I mean it was such an impressive I mean because graph neural networks uh you know this kind of like manifold learning and the uh like when you're processing meshes it's such a complex so I think you know it's a really impressive thing and I don't know and also sorry I'm noticing that I'm trying out a new camera so for our listeners I usually not along a lot with when I'm listening to people speak and this camera is following my head so I'm gonna try not to do that to keep this camera in place but another thing you did was um I remember you did this uh explanation of Gina AI you had done this video I think it was like a half hour video where you just went through the entire code base and for the time because you know most of us in this cohort we're just summarizing papers and I think you showed this kind of dynamic of like you know I understand a code base as well as how to read these research papers can you talk me through like the evolution in your career when you when just like that decision when it was like today I'm gonna walk through the Gina code base I don't remember exactly like how that came to be but like I knew like I really wanted something a bit like more interesting something novel that's not just paper is also just to give myself a little bit of break and and find some some drawing in some other types of videos and so that one like I know the Dina AI folks actually reached out to me and asked whether I could do something like that and I actually wanted I didn't know whether that was my first video I don't remember but I know that later I had very varied like deep Dives like hour and a half two hours long of like whisper code base and and uh I don't even remember all of the ones I I kind of covered but um it's it is as you said it's very complimentary like I I realized that early early on in my ml career that if I um after I read the paper if I check out the code sometimes a single equation uh creates me like much more like denser mental model of what's going on in the paper than just reading the whole thing and and like being confused oftentimes and and uh so so I knew that's a great way for me to learn and also I wanted to see whether other people are going to enjoy that because like I was literally stepping through the code like line by line by line explaining every single variable it was also I guess even for beginners they could probably follow because I was explaining even basic python stuff not just like hardcore ml stuff but yeah um don't don't exactly remember why I made that first one but I'm I'm happy I did yeah well super cool so I think all that just um you know paying a quick tribute to the to your YouTube career which you know that's how I first came to know you and I thought oh that was just so great and so then coming into deepma and take me through like the you know the early day you're maybe initial expectation I mean deepmind is like you know Stanford and I don't know it is it's d mine it's the biggest thing in the world so like what were your initial thoughts and you mean why did I Choose deepmind Or well for my initial like how did the preps look like or what in particular do are you curious about I'm really curious about kind of mentally like okay so you I think uh like this decision to I I don't know what you're in addition to when you're doing these YouTube videos what you were maybe additionally doing or if that was the only thing you were doing but that kind of evolution of like now I'm in Deep Mind did you feel like you just got drafted into the NBA like yeah I already felt fairly comfortable to be honest like because um The Journey started I guess it was the Inception like uh happened back in 2018 that was the first time where I attended this machine learning summer camp organized by Microsoft folks and there were a couple of at least one lecture from from deepmind and all of them were like fellow serbians and so back then I was like oh my God this is this is kind of those guys like alphago and the whole Fame and like I really want to be there I want to be at the Forefront of where people are building exciting AI stuff and so that's what when the the Inception like happened if that's how I can phrase it and then um a couple of years later like I really started learning um like getting into much more depth and and papers were definitely instrumental to to getting there because um I was doing kind of breadth first search across all of these different areas and and also kind of going in depth as much as possible and and and encoding stuff from scratch and so that really helped me ground and have some decent understanding of various different different um subfields and coupled that with my software engineering skills and like background electrical engineering I was already fairly grounded so to speak so so yeah for for like a research engineering role uh you don't obviously don't have to be like PhD postgrad or something like depth and so uh it was I guess enough for me to to to to land the job so I was I'm always really curious about how this like do you have a particular niche of deep learning that you enjoy the most like I know with the paper summary things you you have to kind of cover a lot like you know audio clip and then Dolly do you know I'm looking at your channel on there on the left side Like You cover so such a breadth of the topics and and I feel like you kind of have to do that to make the YouTube channel to hit a decent audience if you just narrowed into Active Learning or something like that right but when you got to deepmind was it still very breadth first or was I imagine it's quite yeah like yeah for me to be honest because in that period many of those fields were that was the first time I I ever started reading papers or anything about those fields so it was not really with with audience in mind to be honest it was fairly selfish I wanted to do like a I wanted to have a decent understanding of all of these fields so I can create cross-connections and and like uh transfer ideas from one field to another field and so to get your question even even like when the last preps for deepmind started I did not converge into one single field although at Microsoft I was in computer vision like by my role because I was working on the following and so I did uh work more with convolutional neural networks and and such things um but um but yeah I wouldn't say I ever converge too much into any any particular uh subfield maybe computer vision kind of uh is standing out a little bit hmm yeah super interesting so yeah so and I'm gonna ask you some questions later about the new Apple headset and Holo lens and Jet I'm sure you'll have an interesting perspective on that but let's dive into it ordis the decision to leave deepmind start orders what is the what is the compelling Vision that just made you say I have to do this like I Can't Live Another Day of working on this yeah so so for me like even before I joined deepmind and not even deepmind like Microsoft like I knew I want to ultimately build my own like startup that's the same reason I dropped out of my Master's study as well like I I like I am not the person who operates super well under these structured environments where you have so so much levels of supervision above you and people telling you what to do I love this unsupervised space so to speak and and like and because of that like character of mine and and the way I learn I think the most natural thing for me was to to decide hey I wanna early on I I decided I want to build my own company and then I was like okay let's first get some get some experience in the in the real world so to speak in in the in the industry and then it's okay Microsoft and deepmind so yeah this has been a long way of of saying this was like a very very something I've been planning for for a while and um and then getting back to to orders uh I guess it kind of connects a lot of my different vessels one of them is obviously the the thing we spoke about a lot of times so far and that's that's the YouTube career like I really like being close to people and users like the the b2c component is kind of attractive and uh and then there is a full multi multimodal space and uh like the interesting stuff happening with large language models and and as well as like uh well multimodal models in general and so like understanding videos which is what what tortoise is kind of about you ask a question and you get immediately you're watching a video just for your audience for people who probably never heard of it uh you basically open up a YouTube video currently it's just a like a small Chrome extension and you can type in a question and ask hey what's going on in this video what what did they talk about and then you you get an instant reply you get where that thing is happening the video you get some suggested questions a summary there's a bunch of details that help you basically uh more search more efficiently of what's going on uh in in that video content um and and yeah and like one thing probably worth mentioning is that the Chrome extension is obviously not the end goal like uh I I do have a bigger Vision which I will not disclose at this point of time but uh I'm really enjoying the learning and then I think it's an interesting space yeah I think and the connection you you're drawing between vision and language and your unique expertise in computer vision I really want to come back to that but this is why I kind of as I was designing these discussion topics really wanted to open with kind of your YouTube background and now we have all these new tools with obviously like weaviate and and these llms and stuff to build these search indexes so first before we dive a little more into uh maybe just describing the stack behind ordis and how you produce summaries how you build question answering systems let's like if we could continue on your background in you know making paper summaries deep deeply you know I think your channel is like nearly 50 000 subscribers which you don't get to without obsessing over how to like do it so how do you think like um the whole content creators space is going to evolve with these new technologies yeah getting back to your subscribers mentioned I I think I I think it's actually super easy to to get 50k or more if you decide to to optimize for that and if you just like go a bit more higher level like for example if he's the two of us were just to start covering python pythorp tensorflow latest trends latest stuff in AI news all of that is super trendy and popular and like I know that that content goes very well I can just see by the viewers on my channel as well uh and and types of video where I described hey how was my experience with Microsoft deepmind all of those are very very uh like uh popular yet I'm not doubling down on that just because like I also have selfish interest with my YouTube channel I never wanted to be a YouTuber and I never considered myself a YouTuber for me YouTube was an outlet for me to learn stuff and at the same time share with the community and build some like core a community of passionate ml folks so that's how I think about it honestly and and then what was your um question actually I kind of went on a tangent then I never came back yeah well I think that's the right way of thinking about it though is building the community it's you know but my question is like um so you know like now using ordis you can basically turn the AI Epiphany into a chat bot that you you know people can I think they're kind of two things to this there's firstly yeah the the chat bot and the summaries I liked what you said on Ken G's podcast about how long form content shouldn't be consumed sequentially I agree I like this podcast is like we're going to talk about so many different topics is like what's relevant to you just watching it sequentially probably not the best way to do it exactly so and then if I can just add one third thing to that is the multilingual translation part I think there's a huge potential in that with these kind of things so you're just like how do you think the the experience for Content consumption is about I think it's about to totally transform oh yeah 100 I mean like I I like to think that tortoise is kind of trying to demonstrate some of those um possibilities at the moment and you also mentioned uh like uh languages like it's it's so easy with with powerful large language models which because we know that the Corpus that they were trained on contains in some percentages various various uh languages uh and so it's actually not not that hard to to add multilingual support I would say um although the quality would probably be uh like dropping uh in by one way or another which I can't quantify right now but but yeah definitely super exciting uh time because For the First Time like video is this um fairly complex medium right like just just from the standpoint of like the memory and the computing power it takes uh to for you to process that and so historically we were not really good at understanding what's going on in the videos and like even the transcription was uh not that great right like until whisper uh like like came out like I think people are struggling even with transcription which is just a text and ignoring the whole visual space and then and then when you go like even which like maybe with shorter videos like 30 seconds or something um YouTube and other platforms could use some heuristics to analyze the visual components but like it's nothing more than heuristics and I think we're finally getting to the point where we'll be able to to to to use models uh like maybe Flamingo maybe maybe like 254 we're still waiting for the for the image feature to to to drop uh and and yeah I think I think it's gonna be very interesting to see how this space uh evolves and what we can do with like analysis of video content yeah I think like um like when Stanford engineering like uh Chelsea Finn's lectures on multitask learning and meta learning it's like I'm so interested in that but then it's like I or like Andy pavlo's database course from Carnegie Mellon it's like I love like I'm so interested in it but I can't just 25 hours I'm sitting I don't have the attention stand for honestly like it's quite hard so yeah this can you tell me about how artists like just walk me through it I'm a user and you know how how what can we do to make you know these courses easier to digest mm-hmm so are you asking for like a brief digest of how the thing works or just like how it looks like from the user perspective um yeah I suppose uh just like um hopefully the question's not too redundant from what we're already talking about but just kind of like any General Vision on how we can take these 25-hour courses and just I don't know create a more personalized experiences to just build that layer on top of that that makes it easier to process it maybe like if I could set the stage more with how I'm thinking about it is like if you cut if you cut it up into Clips like you use the language models to automatically identify chapters and then you kind of like reorganize it already to convert it instead of just the sequential flow that's kind of one idea this is like the chatbot idea which kind of gives you something to you know like re like have your questions answered in a pretty novel way and I suppose a general question it and we can move on if it's not no I think I think well like long term like I think ideally we'll just we'll just have like a big neural network and we'll just pass like video frames through that neural network maybe sub-sampled using some sales and heuristics not just like dummy uniform sampling or something and then it just spits out the answer I I think unless the video is like super super long I think that these super big neural networks will be able to do that and so I think we're currently in this maybe transitionary stage where we are doing um these hybrid systems but I I actually do believe that that that long-term um we'll see more Paradigm shifts I'm not sure about that maybe like maybe that's that's kind of how how I see it it's still prohibitively expensive to to do what they just said and and and I definitely think that that things such as um external memories uh one of those examples being Vector databases and vb8 I do have a place to play because ultimately uh we know that that's the weak point of of these systems same as with humans right like I think we shouldn't dismiss just because it's like not neural network not biology inspired we should definitely not not like ditch those ideas I think some of the papers like uh was it neural Turing machines there was one of the early ones uh from Alex Grieves if I'm not mispronouncing his name uh that was one of the early like papers that really sparked my imagination for for these types of hybrid systems where you're combining solo memory and then later we had retrievals like retro from deepmind or or some of those ideas So like um that's that's going to be a component but like I wouldn't be surprised if we just had pure networks that could analyze the video like just um in a single forward pass or something or yeah the the yeah the the I think kind of separating it a bit Yeah the idea of like uh Vision language model that just like watches a video that I think that's a pretty exciting idea I know like with flamingo and I think there's recently a new model from character AI That's like they're making a lot of progress in this thing and I think that's a hard thing for people even to wrap their heads we're already still kind of like recovering from The Hangover of chat gbt it's already so much that it's like still I think wrapping our heads around what we can even do with this like just you know like I'm curious like what you think about like you know Lang chain llama index just these kind of ideas of like taking the chat gbt into an API and then plugging it into all this data and it seems to me like that's still just even before the flamingo stuff gets better it just flips everything on its head again I feel like there's still a lot no I think that's super powerful like we we've seen the adoption of LinkedIn and and it's definitely democratizing like machine learning for for a lot of the developers and and um we we were seeing more I think in in the app development space one could even argue that like if you're a great web developer if you're just great software engineer you might have like an advantage compared to animal engineers and and obviously like later when you want to optimize for if you want to reduce the cost if you want to fine-tune neural models if you want to do all of that that's where the ml expertise comes into the picture but for the initial stages we're just trying to like um roll out an MVP or something like being a great software engineer or web developer might be like even like a better than being a ml engineer if that makes sense um but yeah like all of those LinkedIn lamba index Vector like uh bb8 uh pine cone all of those systems are definitely currently uh with this current technology with the levels where we are they are they're Pro they are being the shovels for this for this gold rush and and I think there's a lot of value that's gonna um uh like be acquired by the humanity over over the next couple of years but I wouldn't bet on on the in the long run I'm not sure how this is going to roll out to be honest um I I think that we are we're like kind of getting into this software 1.0 mindset with some of these Frameworks uh which is not necessarily bad uh but like we went from Pure we were just like deep learning everything is going to be just deep learning deep learning and and then there was Gary Marcus who was like no it's going to be hybrid systems and then all of a sudden it is conference systems which is not super surprising even people who were very bullish on people already knew that eventually as I said you like for perfect memories much better to have actual external memory other than like let the Network store the the the the memory the coefficients so yeah I'm gonna stop here I was rambling too much you definitely mined out a ton of super interesting ideas the whole that was kind of one of the things about wavier does stick out to me when I first saw it is that you have this like symbolic Vector surge so it's a vector search where you build an index of vector representations but you also have symbolic traversal and so you know you with filter and search and so and then there's also like the neurosymbolic systems where you parse the scene to get symbolic attributes so you can then put into logic parsing I love all those ideas but um so I think we're getting now into this like evolution of I I recently did a podcast with Charles fry that will come out after this one the title is going to be full stack deep learning and you know they they have a course called Full stack deep learning and we really dived into like the evolution of um you know like the ml Ops and how that's all changing now and it's kind of like like this thinking that it's like the perfect minimum viable product tool the zero shot models and how you can get a sense of it but then if you do build this data engine to keep training it it offers the potential to have you know that unique Model Behavior that gives you that unique product Advantage so are you think about that thing with like and it seems like ortis is a great example of that where you can take YouTube videos put it into whisper get the train like so many zero shot models are in the middle of it right and put it into a zero shot embedding model that goes to a zero shot LM and then you get like here's what this thing could look like are you thinking about then also having that data engine and what that could then take it to mm-hmm no 100 and uh like obviously there are some like privacy issues currently we don't even have Google sign in so there isn't no way for us to to actually uh couple any personal information with the data but like obviously if you were to just collect the conversations if you were to collect the likes dislikes of like messages and and like summaries there is plenty of information there and Signal we could we could collect to to then uh like fine-tune improve models uh fine tune them for the particular Channel although there will be I guess probably less maybe for category for a class of podcasts or something one could probably fine-tune and get some some defensibility uh by doing that as opposed to just just being completely like zero shot like zero shot is obviously the the best way to do an MVP and and now the problem is a lot of these closed um closed apis such as open AI like they are you you have to pay premium price for for fine tuning so I think for for like open United 6X for like if you fine-tune the model so that's not economically really um uh like feasible for for many startups and and and that's where we can maybe get into the full Mosaic ML and all these exciting startups as well we're training these systems to allow you to have more control uh do stuff like uh constraint sampling guidance from Microsoft uh fine-tune the model without having to have the sex of uh the price uh etc etc so that's why I'm thinking about this it's very exciting super dynamic yeah the Mosaic um when they announced that 30 billion parameter open source model and then you know seeing the infrastructure they built around the training Cloud you know because I read the blog post where they're saying basically it's between 700 and 800 dollars to do a billion tokens of fine tuning on your instruction tuning and so you know I imagine um who I don't know how many a billion tokens is I don't have a great sense of how money that is but I guess I I would have to guess that like my YouTube channel like the Wii VA YouTube channel transcripts are under that you know I'm guessing maybe you know them all the transcripts and all the tokens you've been processing they were like around 1 trillion right at least for the 7B model I know they were around 1 trillion for fine tuning I I don't know on top of my head how much did they use but I did saw that it's sub thousand dollars in price so probably like I I think even more than just PV PB probably doesn't have that you don't you guys don't have that many videos yet yeah we're working on that but you're working on it yeah it's like it's a long conversation but yeah yeah yeah but yeah it makes me think like um you know having a fine-tuned checkpoint from MPT for each of these YouTube videos built into orders would be maybe maybe that's an idea for how this chat bot gets even more powerful in this kind of system like you know because the I I have to I have to think that if you fine-tune the MPT 30 billion checkpoint on you know Chelsea Finn's lectures of the multitask and meta learning course I have to think that that llm performs better than the zero shot open AI llm are you sure that's the part where I'm like really not not sure because if you take a look at the leaderboard from hogging face the what's the name the open llm leaderboard or something I think the best model currently there is uh well llama 65b and Falcon 40b and and and those are so much better at least across those couple of benchmarks that they're using for testing there then then the MPT uh 30b and so there is a gap there and and there there is additional gap between obviously between the the the the the biggest Lemma and and what uh open AI is offering through gpt4 especially and and so I don't know like there is this gap which open source models are kind of closing but then open AI is running away and then one would have to test and and fine tune and see how much actually you get so how closer you get to to what open AI is doing out of the box and then is it worth it in the sense which is not going to happen that soon but like I don't know you know what I mean it's it's a it's a it's ultimately a Trader you do have to spend those 700 for fine tuning for our Channel or sell channels and then keep on doing that as the new episodes are coming out as well and and and hope that there is no no zero shot model that can just outperform you because because ultimately that's what we're doing right like it's not unimaginable that if you have like a generally enough system that you don't really have especially for these like videos it's not that complex it's not like you're talking Nuclear Physics or something like so in that sense maybe maybe you don't need to even fine-tune them if you have powerfully enough General model I don't know just just a guess yeah no that's a great Insight I've heard that argument before as well the um it's not worth the investment for fine tuning because yeah the the Next Generation zero shot model just makes all that money and data collection effort just totally not worth it at all it's a race and that's actually what brings my inspiration into thinking that fine-tuning embedding models is quite a powerful thing to do because I don't I don't I find it unlikely that you know that you know without saying open AI cohere or a particular company just like I find it unlikely that the the big zero shot model off the shelf is going to be able to just do better at your model at embeddings particularly so yeah like have you thought about training embedding models with all the stuff you're doing like you know with like the huberman transcripts like because I remember when you first did the human transcripts you annotated as ml op series and that made me think that maybe you were thinking in that kind of headspace uh let me think like I'm trying to like I think currently the bottleneck for my system is probably less has less to do with the quality of if I like give a certain paragraph and I'm looking for a neighboring similar paragraphs I think that deviating combination with some of these models is doing the fair ly decent job I think they're they're probably easier things to attack at least when it comes to these types of applications then then like tuning a embedding model that's my thinking for example the trunking logic like where do you like if you just chunk the sentence in the middle like and you kind of break down the semantics of that whole sentence that's probably gonna hurt you more than the fact that you maybe are not using the best possible embedding model in the world and and and so because of all of that if you were to just the sword the the bottlenecks I'm not sure this one will be on top of the list uh although you probably know more than me I haven't been following the research that I don't know like the leaderboard what what are the best ones I know that ADA uh zero zero two from from open AI is very good and they they were the best one that was the best model when it came out when like five months ago or something I don't remember but like I'm not sure how the space evolved maybe you can tell me a bit more you know I'd recommend um there's a paper called uh benchmarking commercial embedding apis but is Professor Jimmy Lane I don't know the exact title but but yeah so the data sets are like beer uh beer is like you know for is I think it's like 14 open data sets like Financial questions nutrition facts Ms Marco and then there's Miracle which is like uh multilingual same kind of concept so the they're definitely I think even with the state of llms the benchmarking and saying you know open AI has defeated everyone that like a cohero like Whoever has defeated everyone that there's not really a great sense of that yet I don't think even in embedding so and embeddings would be a tough one to do as well because to build the embedding benchmarks you talking about a crazy data collection effort like annotating the query relevance for a document saying no it's only relevant to these you know these documents and so on so so you know it's like track if people are interested in learning more about uh how people annotate these data sets and yeah all that is really interesting but I want to uh the text chunking idea this is definitely some yeah you're that's something we see all the time it's one of the most common I think First Steps um do you see any like what do you think about this idea where you use an llm to parse a document and say Here's a split for a chunk and like you give it some kind of prompt about like hey you're splitting this you know you're splitting up this document for Reserve semantics um please like give us this special token when you want to split it do you think that idea is worth maybe the cost of all those llm inferences for that that that's an interesting question I I to be honest I never thought about it because the expense and the the simple heuristics I'm using it are seem to be like doing a decent job I guess that's similar that's similar in a way to the thing I mentioned before with the saliency when you were trying to trunk the videos I extract certain frames that you want to ultimately feed to this multimodal model so here we're kind of trying to understand where you want to chunk these so that you can then use whatever embedding logic or whatever you want to do I'm not sure do you have like are there any papers doing this already like I haven't been following that that closely yeah well I'm kind of like a meta note since I've joined weeviate I don't really read papers as much to get to get this my information like my information diet is really not papers as much anymore it's more like I you know you just like Converse like I'll have conversation with someone who's building something from alleviate that's like about as random you can imagine I have tons of calls like this and so I and this is kind of where I pick up these nuggets is just like where people are kind of trying out there in more of a hacking hacking kind of sense than like something that I'm gonna say like there's paper from Stanford and MIT they tested it with as rigorously as possible Right but I guess like another kind of cool idea to float out there about text chunking is people aren't thinking about like putting metadata into the chunks so like you would you'd find the title and then you'd keep putting the title in there uh there's there's maybe some stuff too with like visual document layout parsing but I don't know if it generalizes that well it's YouTube unless you're like I guess what what you're explaining to me in this podcast that I hadn't pre I hadn't understood about orders previously is that you're trying to do something with the visual aspect of YouTube as well so and so well ultimate like my goal is to to like provide this type of like insight and like extract information you know one instead of you having to historically you have to go through the thumbnails and see where was the thing that happened and then trying to kind of you're using bunch of heuristics to find information like obviously for some type of content for for this class of content where you have more like sedentary like people sitting down in a podcast and just like chatting like the two of us right now probably like it's it's probably like the visual component does not add that much other than maybe emotion interpreting like whatever like in in that sense but most people don't care about it right like you just you're kind of invariant to the you're just like focusing on the on the knowledge and you you try and ignore like the perks of each each person is like like Behavior or whatnot like so so I'm not sure it would add that much due to these videos but like in general it's a no-brainer that for some maybe action more action driven videos shorter videos like sometimes the visual component all of a sudden becomes much more important than text local porn right especially when you don't have that when you don't have voice so uh I'm definitely thinking about this and I used to work on Vision language models a deep mind like I was uh closely working with flamingo folks and I was actually helping um bring flamingos to the real world I can't really dig into too much details but uh uh like I'm very definitely super passionate about the space and I was even before I joined and uh maybe getting back to the to the initial question we had I think that's kind of my niece like I I found this combination of language and and and and like uh imagery or videos and audio like the multi-modal space the most exciting uh like research Direction at least over the next couple of years I think it's exciting yeah I think like maybe to tell a quick story like um before I was doing deep learning I was playing basketball and I used to love doing like these um like you you try to like dunk as well as you can and they're like trick dunks you can do like you could throw it off the backboard and dunk it you could do like a windmill dunk you could do like a 360 dunk and so you and like this site and people up their like YouTube channels called like dunkademics and stuff like that where people search for similar dunks and I can like like this idea of searching for similar dunks would be quite a novel idea and so I think there's certainly like a huge thing I guess like I'm so biased in thinking about this kind of like information heavy stuff which brings me back into it yeah yeah and you worked at bb8 so you're you're kind of yeah definitely definitely biased in that respect but like um yeah there is exciting stuff to be done in the individual space uh I think one company that's doing a tremendous work although they're uh like Gunk you might have heard of them they're they are in the sales vertical and what they're doing is they're helping understand what they're what they're saying representatives in your company how confident are they like brand reputation all of this information they're they're kind of under like extracting the data using AI I guess in the background what like the problems using some heuristics and maybe maybe since recently they started using more neural networks at all uh but like that's one clear example where where like people are using uh like visual component in in in in Industry to to analyze and extract information from the video yeah I think I know we're touring all sorts of topics but yeah like crms I think are are like just how you process a call and all that is just and it kind of brings me into like what like what I love my like favorite project to work on which I feel like is kind of adjacent to ordus is like I've turned this these podcasts into a data set I have a we did a podcast search on GitHub and like I I'm so excited about thinking about what what can be done with these podcast transcriptions and I want my compensation man for the data I've provided I'll pay you in two GitHub Stars however I'll transfer the currency but yeah the the there's one I there's like these two ideas I so I had you Shang woo on the podcast who's working on something called chat Arena which is where you like simulate conversations do you think there could be anything to that I know we're talking like just totally broadly and like about whatever now simulating conversations um with like with the idea of like generating more data or or with the idea of entertainment or like or just yeah there could be many wives yeah right now we're calling this generative feedback loops to like broadly describe this idea of like the feedback loop is in reference to saving the generated data back into the database to then search through it in the future and so the idea would be you simulate these conversations and then you like save the new conversations back and you blow up the this data space this way and you know like I guess the idea being that in simulating like a million conversations between like Sam Altman and David silver you know just like taking people to just chat about these topics with that you create like this new uh space and and because I kind of think like you know it reminds me back to like early days of training Gans where I'd be like what kind of Novel images Has It produced and so I would need to generate those images and then you know this is way before I knew about something like their database or I'd even thought about that kind of idea but you would just like it was kind of a natural intuition to try to like sample models from the Gan and then embed them and you know compare compare the nearest Neighbors from your Gan to your training set and just say like especially like we're debugging mode collapse hopefully that sets the station yeah yeah it makes sense well yeah like I I guess this this space of of conversations and language might be even much tougher right to find the nearest neighbor of the conversation than of a like 256 by 256 image or a thousand by thousand whatever with against they they did improve um but yeah definitely interesting like research idea and and you can definitely imagine products uh coming out of that that direction immediately like I'm sure people would be willing to pay to hear like I don't know historical figures like Nikola Tesla speaking with Albert Einstein or you know what I mean like so something similar in similar in spirit to what character AI is doing but more multi-agent more like more more of that that could be one interesting product area and the research is also interesting in and of itself yeah I guess it's like by simulating conversations can you discover new like ideas kind of like maybe like like another kind of thing I like a lot about is like to take these podcast transcriptions you know automatically take out the chapters and maybe prompt it by saying like you know uh Alexa and Connor are talking about vision and language models like retrieve from all the other podcasts and say did they say anything unique is there anything like new in this conversation prompts like that and then you kind of from there the things that are new I don't know like how many new ideas you discover in conversation yeah we might get depressed man we might get depressed I think we're giving ourselves much more credit than than yeah neural networks so they're just interpolating data and like humans like if you think carefully enough like you just you just find a snippet information you picked up five years ago and then you connected it with some snippet information you found out two days ago and all of a sudden this this seems novel and interesting but yeah yeah existential yeah yeah I mean if like this kind of synthetic data if I can I so I saw this interview with Aiden Gomez CEO of cohere um talking about synthetic data and I I sampled this quote out where he says I think there's a way in which synthetic data leads to the exact opposite of model collapse like information and knowledge Discovery expanding a model's knowledge beyond what it was shown in its human data that feels like the next Frontier the next unlock for another very steep increase in model performance getting these models to be able to self-improve to expand their knowledge by themselves without a human having to teach them that knowledge so that's like the end of the quote I read but I would like be I like this a lot because I think whether you're simulating conversations or you're putting them in an environment system and this is kind of like a deep-minded idea right like this open-endedness I think they have these stimulus it's like this kind of synthetic data like I guess I think that quote maybe is does a better job of explaining that I do but like having these conversations is like creating synthetic data and maybe there's new ideas in there 100 and I'll ultimately if you think about it when you're when you're trying to solve a problem I don't know about you but oftentimes I do SUB vocalize I I do talk with myself like I do have inner characters like communicating with each other right and trying to to get to the conclusion or or when you're trying to debate out an idea in your head right you're rolling out a discussion like a hypothetical future how would that what would be like the uh like if you had an adversarial or maybe a better word to be like a super smart uh like opponent and and like how how would you reply to all their questions and where would you like how would you Traverse that whole like tree of potential outcomes and and so like in that sense I think this is also more fundamental than than just like data or or like it might be a methodology to improve the reasoning uh like capabilities of these systems it's definitely super fun super interesting yeah I think um like also staying on the Deep like like the mute the alphago how I did this tree search to look into the future of the moves it could make and I don't know if you've seen this tree of thoughts paper where it's like a language model is like um yeah like so yeah what do you think that tree of thoughts is a I mean to me that seems like one of the most craziest ideas I've ever heard is combining the yeah definitely super exciting it's kind of the generalization of the of the chain of thoughts but just going from a linear process to a more like tree-like process in that sense conceptually it's it's not that like well I don't want to say big of a deal because all of these ideas in retrospect are just connecting a couple of dots uh the pro I actually wanted to try out that idea in in in our system in orders uh but the thing is that's super expensive that that type of um like a tree like you you you need so many inference steps and that's more for some offline processing of some reasoning tasks uh but but definitely interesting yeah yeah well that's I mean I think the cost of inference with large language models is so frustrating because it feels like there's so much we could do if it costs nearly nothing to just run yeah yeah but it's also liberating because it constrains a lot of the potential methods I could be trying right like when you have the real-time constraint when you're interacting with the users when there is a latency component in the full picture then you start thinking in a completely different direction and you realize that there is not that many great ideas that focus on like low latency real-time type of of like uh applications it's mostly you're trying to get the model to be better and then and distill it and make it make it faster than all of these techniques they're more for these mathematical logical reasoning benchmarks than for like communication and stuff I don't know like um yeah like kind of like the tool use and the well yeah and the whole distillation yeah and all these covers I mean it's like how exactly are they going to uh compress these models and get to the point where it's super cheap to run it like I've seen like this you know like 4-bit inferences getting really good and like the stuff that Tim detmers does is always like you always see that tweet and you're like why that's just insane like you know I think it's like you know they're at like 60 billion on a single GPU stuff like this and it's like but yeah so yeah this whole kind of topic and I so I think kind of uh I I think we've done a nice like just open-ended touring of topics around ordis um is there anything maybe before moving on I wanted to ask you kind of about some personal or personal self-organization things I took away from your podcast with Kenji recently um but is there anything maybe you want to cover as well about orders before we kind of move on topics um yeah I encourage people to try it out I encourage people to try it out we just added a couple of cool new features uh like we added we added like suggested questions for each video like there there's like a couple of relevant suggested questions because there is this blank page syndrome I think that's why it's called like that's what writers usually have but like also when you're interacting with these systems people don't know what to ask right even though like you can actually ask the agent and you can tell you what they can do but people don't come up with that idea and so this small UI Tech so to speak helps I think a lot we also added Jeremy Howard today there is a bunch of new channels coming up so I think um it's it's exciting I'm learning a ton and I'm learning a ton about also just typical back-end business for example I spend the full day today trying to figure out the the Google sign-in like even though that's super conceptually easy right it turns out it's very difficult because of versioning like it's a version detail like there is the Manifest version too in Chrome extensions version three and so like a lot of documentation is just outdated and so people don't give Engineers enough credit we like in in this ml space like we focus too much on these like interesting ideas like getting done is is so much more difficult sometimes than than they would like you would like to think even when it's conceptually super easy yeah maybe that's some like a tangent I wanted to convert sorry everyone we had a little bit of connection crash but uh so back online the the question I really wanted to ask you and I hopefully the as the connection cut out it got out the last part of what you're saying about um you know recently adding Jeremy Howard's uh YouTube channel into ordis and how you you know as I've been following along with you you've been adding all these new channels into it and it's like a nice like continual updating of it to follow along with and so I really wonder about this idea of like an embedding Marketplace and it's kind of like an interesting new category I've been having conversations with a few entrepreneurs who are who are exploring this idea where it's like you know say you want like the almanac of Naval ravacan if you want like that the embed open AI embeddings of that book you can just kind of like grab it from this Marketplace and I think that makes a lot of sense because then you don't have to deal with you know vectorizing the thing and that's already been done for you do you think about that as being some kind of aspect of Oris as well maybe like you is someone's exciting I never thought about it because I guess it always looked in my mind as a very custom thing right like you you have a lot of paper parameters you have to pick to do that type of embedding uh like Marketplace as you called it in the same like like how big are gonna be the paragraphs like sometimes you want to have smaller ones sometimes you want to have bigger ones where do you trunk like the trunking decisions matter maybe later people figure out better methods like for example the llm saliency method you mentioned and then there is also the choice of the embedding model and then we were discussing also the quality of embedding models so what happens if if you all of a sudden some much better embedding model comes out what do you do you have to re-index the full marketplace and so in that sense I'm just thinking why did maybe a like a valid question would be why didn't we ever do the same thing with other types of data sets for example I don't know for for imagenet why didn't we create a Marketplace of the embedding certain layer certain like layer inside of resonance 50. there was a such a common test right people were constantly using resonance back in the day and and you always had to do this this Pro pre-processing to save on compute and then you would locally uh deal with that data like so why didn't nobody come up with with that type of um like Marketplace for other types of models not just for embedding ones I guess that's the only question I don't know how you think about it yeah no I think that's a perfect I think like the way that I understand imagenet maybe maybe this is a hot take but I they put a ton of effort into labeling the data set and and it's kind of like you you need to like kind of apply for it with like like it's not just something you can download on uh you know like tensorflow data sets and I I feel like they kind of get pay Wallet not pay wallet but you know they it's kind of like with and yeah I don't know if I'm stepping on people's toes with what I'm saying but it's kind of like with the mimic data set like you have to um like get this certificate from physio net and then you have to go and apply for the data set it's not just you know so that's kind of my opinion of imagenet got it it's like you know more more gatekeeping mentality I mean that's that's fairly annoying I don't think you're stepping on anyone's toes that's I think that's a shared understanding yeah so I'm yeah but I think like with um you know with these kind of YouTube transcript data sets it's like if you open source a data set then scientists can like you could publish a paper where you try different text chunking with some kind of metric like maybe you generate synthetic queries for the Jeremy Howard videos and then that's how you kind of like you know measure it and then you and then you can like publish science and like present it in nerves and I I see well and stuff like that right and so I guess like it's kind of interesting to me like as especially like with as I think about wig a development it's like what kind of data set do we want to you know like with a n benchmarks it's like we make some Innovation on product quantization it's like okay we're going to tell you about like the sift vectors recall and it's like that's pretty academically sound but then I worry about if you can tell the whole story like it compared to like the data set ordis has if like we could show something like some Innovation and embeddings that you know creates this better experience for orders kind of like by using these transcripts as the data set and then and then also get like the academic credit of like oh we did this clever technique because we're Geniuses yeah so yeah I'm definitely not in that game like I it should come on the PHD route but I took a completely different direction yeah yeah so anyway so yeah I I think it's quite an interesting idea and there's I think there's all sorts of cool things you can do with this orders you know when I first saw your Cuban huberman transcripts podcast uh uh uh demo with the website I thought that was such a cool demo and I'd encourage everyone to check out ordis of course and so transitioning topics a bit to your I think you have a lot of interesting ideas in personal organization obviously you know you've reached the height of machine learning success and deepmind and your startup CEO founder you know you need to be you obviously need to think about this quite a lot so I one idea you mentioned in Ken's podcast was about analogs of periodization and weightlifting and how you think about your information diet and you know the periodization maybe you you want to explain the idea yeah sure I mean um the idea is fairly simple when you're trying to build muscles in power lifting you you're not going to try and and increase your your weights every single workout because ultimately you're going to saturate and you're probably going to hurt yourself right and so yeah what they have is some type of like uh you you keep on increasing like maybe if you have a periods like so-called macro cycles of like three month periods and you keep on increasing the weight maybe every two workouts increase to two and a half kilos or something and then at the end of that period what you do is you drop by some percentage for example your One Max strap is maybe 300 kilos and you like your last workouts for maybe like 80 percent of that of that number and then it dropped to maybe like 60 and then you start from there like you do the so-called deloading and then you you start another another cycle um and uh I basically borrowed the terminology when when I was learning new subjects uh because I I like to treat the treat brain as a physical thing as it is right like ultimately you do have to form those synapses and that's a biological process and metric has to move around and things have to be built up and so because of that I think it's reasonable to make these types of breaks and periods and like chunk your your your uh like kind of organizing structure learning in that way that's why I think about it I think it's a fairly simple uh like uh analogy and I would be surprised if nobody came up with this like already I did pick it up myself but like I would be surprised if nobody is already talking about it's fairly obvious connection well I think of um like when I was listening to you speak about originally I thought it was so interesting because I think kind of like in weightlifting there I think like rep ranges are the other thing to think about like you have like a hypertrophy cycle you know you know where you would do like two to four reps four to eight reps eight to twelve and it ends up being an entirely different workout and so I think the analog here is like whether you're reading papers or if you're like hacking together on a project or if you're um you know writing deeply or if you're say uh interviewing like you know uh talking to customers or your product so sorry so these are like four separate tasks exactly different dimensions whereas in workout maybe you have like a volume and intensity like I could be increasing the weights or I could be increasing the volume I need a number of repetitions maybe like you definitely have more X's when you're learning but like there there's also this workout and rest you have to sleep if you have to like nutrition has to be proper all of that combined I think that also translates into the learning space you do have to sleep nicely and like we do know that the Eureka The Epiphany moment uh no pun intended uh like do come off on when you're just chilling and like having a hot shower or taking a look outside in the nature uh and and and and yeah I think there is a lot of cool insights you could pick up from from like that other space is it do you think about organizing your time that because like for me honestly it's just like a chaotic mix-up of those tasks there's no order to like what is done like I don't have like a reading week uh engineering week uh talking to people week but do you think about organizing your time in that way uh currently it's more on a day-to-day basis like again it depends on the stage of your life like back then I was trying to learn so many different topics and I think that was the best approach for that currently I still do have some structure but it's more on a on a daily basis like I I know when they have a workout like I just had a workout immediately before this this this podcast and then like I I have certain nutrition after the workout uh like I have regular sleeping hours and like I have maybe cold shower on like 5 p.m and and so like I do have some structure around the structure I'm trying to put in everything else uh and I do try to if I don't have it I feel I'm not as productive I think it's very important to have some type of rigidity to constrain your time in one way or or another but that's what works for me yeah I think like something that's worked for me just like little little things is like trying to I try to have like meetings every day in like two time slots like between you know like eleven to one and four to six if you know if it allows itself to be organized that way and and then I like to have those in the calendar and then I have like my morning session I have my afternoon session and then the pressure of being like if I don't do my deep work before the 11 to 1 then I'm then it's lost and and so that's kind of just like a little thing that I do in addition to things like you know I maybe don't do cold showers as often as I should but yeah yeah I mean I mean again it depends whether I think I think Paul Graham had this uh like distinction between like the the builders the makers and then was it the managers I might be missing out the other group because I'm not part of the group but like the whole point is when you're a maker and Builder you really need to have these prolonged periods of time with no interruptions and and so if you do have a chance and I likely do have that like I can just schedule or or like not yet meetings at all and usually I don't I rarely have meetings to be honest I have these I started having attending podcasts a bit more like on Fridays but like most of my time I try and get into this flow and for that flow you you do you need like spans of time or like three four hours to just get deeply into something otherwise or even more um otherwise I don't feel as productive yeah I I guess like um yeah I used to like oh it's so interesting like I I also agree like um for me it's like more than three hours is like uh I'll probably like not really be I'll probably like be on my computer but like I'm like half you know like after three hours so that's what I kind of like to just do like three hours at a time and then meetings and that kind of thing but the the other kind of meta topic is I'm curious as you're building ordis how your perspective has changed on breadth first thinking and depth first thinking like um you know something like you mentioned debugging this uh sign in error with Google how would you categorize that kind of task yeah well well again I would categorize it as as bread for a spill because it's one day right like like I do a bunch of stuff I have to take care of I currently I'm a single employee and my girlfriend is like doing the product design and she's also helping around different other stuff but but like the technical component I'm basically building the whole system so that means I have to be all around the place I have to do the the full data pipeline uh the robustness of the data pipeline the back end the again the some SLA like and then the front-end part and and thinking about UI and having user studies actually started having more and more user studies and some of those as a consequence some of those UI decisions I made were a consequence of those user studies and so it's fairly broad like in that perspective there is the marketing component obviously um like community outreach all of that so it's very very all around the place it's not focused like in in in the same sense as some PhD guy or somebody working at deepmind right now on a particular like research is doing right like even though on this micro like in in this if you take a look just at as a day as a Time unit then I was just doing this obsessively the whole day like for like six seven hours already or something first and yeah I think well I think my personality and I think maybe you share this is like that kind of if I was doing six to seven hours of thinking about uh like I have a gradient spiking error and I'm like trying to debug it for the last time I don't know I don't really have the intention to do that have like a little bit of marketing a little bit like I I for me the breadth first it kind of like keeps me having fun with it like if uh but yeah yeah I definitely can can empathize with you but like I I think I I can still I can pull it through like I think it's very important like oftentimes there will be issues where you're stuck with something and you have to push it through and do just single thing for for days and I think I do have that skill uh it is harder it does require like there is like a physical manifestation of pain sometimes like just because like oh my God you're just pissed off with everything and you just but you have to push through it and so um it's a skill I think it can be built as anything else but probably yeah definitely more enjoyable when you're doing like when you're having this this broader understanding of everything and just yeah yeah I think like in the psychology of like the most painful thing you can do that's for sure I think like the most painful thing is when you're solving a coding error that like the the so when you do solve it it's not intellectually satisfying at all it's just like I can't believe that was the thing right like but like I I think when when you when you're an engineer when you're a software engineer you learn to appreciate those moments because most of your job looks like that for example here I really like like Greg Greg Brockman at least according to what I can see according to his tweets he seemed to be that type of person he's like like pushing through these very painful boring details nitty-gritty details there was on some off by one error or like some some like some redundant copying between the GPU and the CPU host or whatnot like and he after seven hours of digging deeply he found like uh the the problem was like obvious in retrospect but until find it right it's like the asymmetry between verifying versus finding the solution very very exciting yeah yeah oh yeah there are a lot of people who do that better than I do and I just respect it enormously it looks hard but every now and then I find myself doing like doing problems like that but yeah that like just you know getting into the CPU profiling and all that kind of stuff is really a huge skill one other thing you said that's really interesting that I relate to a lot in my life is my fiance also works at uh we VA and we work together as a couple who also like talks a lot about work and so I'm really interested to hear that like your girlfriend is doing the product design it has all that like my experience has been it's like just a ton of fun and maybe we talk about work a little more often than normal couple would I would say in like 100 hahaha yeah but it also ends up being a nice conversation topic I think in your relationship I I don't know how my relationship would look like if we were not like connected on this project like most of my time like I like since like the moment they wake up until 2 A.M 3 A.M I'm literally constantly working in why one way or another with a couple of these breaks I mentioned like because they are important so like I'm not sure we like where I could squeeze in that additional time to to keep the relationship healthy so because of that I'm very grateful we are actually super aligned on on that front and she she and I we are both aware of the dynamic and um yeah I think that's exciting you know like I mean maybe a thing that popped into my mind talking about this whole thing is if you know that the guy who is uh the CEO of ruplet I think I'm I'm Judd is his name he's actually I don't know if you knew this but his uh his wife is his co-founder so and then that's that's super exciting and they they know they've now crossed the like they are a unicorn company now already and and they've been in the game for like seven years and since recently they've been just exploding and I think I really love to hear those those stories where people are not inside of the common pattern I really like respect that because the pattern is you want to be two to three founders uh like mostly guys uh not not like and then like like preferably Stanford Etc like you know what I mean like those like like YC has this better matching and you have these companies and like they're all these expectations and statistics and so when you hear such a outlier like succeeds it's very it's very um like motivating as well right because that means okay now maybe maybe we can do this or or same with me like I came from like Serbia and like this guy was like just self-studying and then all of a sudden he's like in the in the best top AI like lab in the world like okay maybe I can do this and so I like I think those are very important for like just like like full in the world I guess awesome well Alexa man thank you so much for joining the podcast I had so much fun talking about all the technical ideas as well as hearing about how you're managing your time or to such an exciting project I'm so excited to see how it evolves and thank you so much again thanks a lot man I really enjoyed the conversation ", "type": "Video", "name": "Aleksa Gordic - Weaviate Podcast #55!", "path": "", "link": "https://www.youtube.com/watch?v=pGrP87gE8XU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}