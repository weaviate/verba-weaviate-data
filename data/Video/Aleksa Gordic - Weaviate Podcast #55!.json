{"text": "Hey everyone! Thank you so much for watching the 55th episode of the Weaviate Podcast with Aleksa Gordic! This episodes dives ... \nhey everyone thank you so much forwatching the Wii gay podcast I'm superexcited to welcome Alexa gordich Alexais one of the most well-known AI uh Idon't want to say influencers because ityou know kind of how the term hasevolved now I mean like here are 10 waysChachi BT can make you a million dollarsbut you know Alexa I like to think ofthis cohort of uh I guess myself AlexaYannick Tim and latita at there was thistime where we were making a papersummary deep learning paper summaryvideos on YouTube and it felt like wewere kind of the cohort doing this andit was a really fun kind of time in theevolution of my career and so alwaysbeen like where what Alex is doing andrecently his story with um you knowjoining Deep Mind from that and thenleaving deepmind to start orders thiswhole thing is so inspiring I love howyou have these YouTube videos where youyou know hey I'm in Japan and I've justgot out of Y combinator and I'm herehacking all night I love thestorytelling of it it's so much fun sobefore going any further Alexa thank youso much for joining the podcast thanksthanks a lot for the beautifulintroduction and yeah please don't callme an influence right it definitely hasa negative connotation in my mind aswellyeah why I do let me I do want to giveyou some some credit into the technicalchops that you have quickly on thisYouTube thing um so you know playingthis game with you and Yannick and youknow and we were in this race to likeyou know summarize a paper try to get asmuch attention for this summary as youcan to build the YouTube channel and allthis and I think a couple things thatyou did that really stood out to me aslike you know watching what you weredoing across the fence and you knowcompeting with you as well as sayinglike how what can I still in this guy Inever consider this competition to behonest like I I like I think the thespace was big enough like it's a globalscene and like there were only a coupleof us so I I I really never consideredthe competition and like I'm also verybullish on Peter thiel's likecompetition is for losers so that's ityeah I didn't know it yeahI agree with that super strongly I thinkthere's a lot of things that markets areunderserved in competition I don't thinkof it as only one of us can win but evenwith Vector databases I think it is likeyou know what are these other peopledoing andcompetition I think is a big force thatshows you like these ideas and it wouldbe foolish to just not even look at theother people doing the thing right butbut two things I want to really give youcredit for is um first I remember uhwhen you started diving intothe graph of neural network stuff youdid some really impressive papersummaries and to kind of read a coupleof off them the um the neural sheathdiffusion one as well sorry my thingyeah that one was very hard and therewas nothing in the early days like inthe first batch of My Graph ml videos itwas more like the the the the popularones like the graph attention Apple fromPetro Valley Church graph convolutionalnetworks from uh Thomas keep a couple ofthoseum I guess uh we would hire a number ofsay patients and then this one came Ithink way like after that for first waveof like the initial series but yeah thatone was super tough and if you ask menow like the details about the paperlike I haven't done it in a while so itwould be very hard to recall all thedetails but I did understand it backthen yeahwell yeah I mean it was such animpressive I mean because graph neuralnetworks uh you know this kind of likemanifold learning and the uh like whenyou're processing meshes it's such acomplex so I think you know it's areally impressive thing and I don't knowand also sorry I'm noticing that I'mtrying out a new camera so for ourlisteners I usually not along a lot withwhen I'm listening to people speak andthis camera is following my head so I'mgonna try not to do that to keep thiscamera in place but another thing youdid was um I remember you did this uhexplanation of Gina AI you had done thisvideo I think it was like a half hourvideo where you just went through theentire code base and for the timebecause you know most of us in thiscohort we're just summarizing papers andI think you showed this kind of dynamicof like you know I understand a codebase as well as how to read theseresearch papers can you talk me throughlike the evolution in your career whenyou when just like that decision when itwas like today I'm gonna walk throughthe Gina code base I don't rememberexactly like how that came to be butlike I knew like I really wantedsomething a bit like more interestingsomething novel that's not just paper isalso just to give myself a little bit ofbreak and and find some some drawing insome other types of videos and so thatone like I know the Dina AI folksactually reached out to me and askedwhether I could do something like thatand I actually wanted I didn't knowwhether that was my first video I don'tremember but I know that later I hadvery varied like deep Dives like hourand a half two hours long of likewhisper code base and and uh I don'teven remember all of the ones I I kindof covered but um it's it is as you saidit's very complimentary like I Irealized that early early on in my mlcareer that if I um after I read thepaper if I check out the code sometimesa single equation uh creates me likemuch more like denser mental model ofwhat's going on in the paper than justreading the whole thing and and likebeing confused oftentimes and and uh soso I knew that's a great way for me tolearn and also I wanted to see whetherother people are going to enjoy thatbecause like I was literally steppingthrough the code like line by line byline explaining every single variable itwas also I guess even for beginners theycould probably follow because I wasexplaining even basic python stuff notjust like hardcore ml stuff but yeahum don't don't exactly remember why Imade that first one but I'm I'm happy Ididyeah well super cool so I think all thatjust um you know paying a quick tributeto the to your YouTube career which youknow that's how I first came to know youand I thought oh that was just so greatand so then coming into deepma and takeme through like the you know the earlyday you're maybe initial expectation Imean deepmind is like you know Stanfordand I don't know it is it's d mine it'sthe biggest thing in the world so likewhat were your initial thoughts andyou mean why did I Choose deepmind Orwell for my initial like how did thepreps look like or what in particular doare you curious aboutI'm really curious about kind ofmentally like okay so you I think uhlike this decision to I I don't knowwhat you're in addition to when you'redoing these YouTube videos what you weremaybe additionally doing or if that wasthe only thing you were doing but thatkind of evolution of like now I'm inDeep Mind did you feel like you just gotdrafted into the NBA likeyeah I already felt fairly comfortableto be honest like becauseum The Journey started I guess it wasthe Inception like uh happened back in2018 that was the first time where Iattended this machine learning summercamp organized by Microsoft folks andthere were a couple of at least onelecture from from deepmind and all ofthem were like fellow serbians and soback then I was like oh my God this isthis is kind of those guys like alphagoand the whole Fame and like I reallywant to be there I want to be at theForefront of where people are buildingexciting AI stuff and so that's whatwhen the the Inception like happened ifthat's how I can phrase it and then um acouple of years later like I reallystarted learningum like getting into much more depth andand papers were definitely instrumentalto to getting there becauseum I was doing kind of breadth firstsearch across all of these differentareas and and also kind of going indepth as much as possible and and andencoding stuff from scratch and so thatreally helped me ground and have somedecent understanding of variousdifferent differentum subfields and coupled that with mysoftware engineering skills and likebackground electrical engineering I wasalready fairly grounded so to speakso so yeah for for like a researchengineering role uh you don't obviouslydon't have to be like PhD postgrad orsomething like depth and so uh it was Iguess enough for me to to to to land thejobso I was I'm always really curious abouthow this like do you have a particularniche of deep learning that you enjoythe most like I know with the papersummary thingsyou you have to kind of cover a lot likeyou know audio clip and then Dolly doyou know I'm looking at your channel onthere on the left side Like You cover sosuch a breadth of the topics and and Ifeel like you kind of have to do that tomake the YouTube channel to hit a decentaudience if you just narrowed intoActive Learning or something like thatright but when you got to deepmind wasit still very breadth first or was Iimagine it's quite yeah like yeah for meto be honest because in that period manyof those fields were that was the firsttime I I ever started reading papers oranything about those fields so it wasnot really with with audience in mind tobe honest it was fairly selfish I wantedto do like a I wanted to have a decentunderstanding of all of these fields soI can create cross-connections and andlike uh transfer ideas from one field toanother field and so to get yourquestion even even like when the lastpreps for deepmind started I did notconverge into one single field althoughat Microsoft I was in computer visionlike by my role because I was working onthe following and so I did uh work morewith convolutional neural networks andand such thingsum but um but yeah I wouldn't say I everconverge too much into any anyparticular uh subfield maybe computervision kind of uh is standing out alittle bithmm yeah super interesting so yeah soand I'm gonna ask you some questionslater about the new Apple headset andHolo lens and Jet I'm sure you'll havean interesting perspective on that butlet's dive into it ordis the decision toleave deepmind start orders what is thewhat is the compelling Vision that justmade you say I have to do this like ICan't Live Another Day of working onthis yeah so so for me like even beforeI joined deepmind and not even deepmindlike Microsoft like I knew I want toultimately build my own like startupthat's the same reason I dropped out ofmy Master's study as well like I I likeI am not the person who operates superwell under these structured environmentswhere you have so so much levels ofsupervision above you and people tellingyou what to do I love this unsupervisedspace so to speak and and like andbecause of that like character of mineand and the way I learn I think the mostnatural thing for me was to to decidehey I wanna early on I I decided I wantto build my own company and then I waslike okay let's first get some get someexperience in the in the real world soto speak in in the in the industry andthen it's okay Microsoft and deepmind soyeah this has been a long way of ofsaying this was like a very verysomething I've been planning for for awhile and um and then getting back to toorders uh I guess it kind of connects alot of my different vessels one of themis obviously the the thing we spokeabout a lot of times so far and that'sthat's the YouTube career like I reallylike being close to people and userslike the the b2c component is kind ofattractiveand uh and then there is a full multimultimodal space and uh like theinteresting stuff happening with largelanguage models and and as well as likeuh well multimodal models in general andso like understanding videos which iswhat what tortoise is kind of about youask a question and you get immediatelyyou're watching a video just for youraudience for people who probably neverheard of it uh you basically open up aYouTube video currently it's just a likea small Chrome extension and you cantype in a question and ask hey what'sgoing on in this video what what didthey talk about and then you you get aninstant reply you get where that thingis happening the video you get somesuggested questions a summary there's abunch of details that help you basicallyuh more search more efficiently ofwhat's going on uh in in that videocontentum and and yeah and like one thingprobably worth mentioning is that theChrome extension is obviously not theend goal like uh I I do have a biggerVision which I will not disclose at thispoint of time but uh I'm really enjoyingthe learning and then I think it's aninteresting spaceyeah I think andthe connection you you're drawingbetween vision and language and yourunique expertise in computer vision Ireally want to come back to that butthis is why I kind of as I was designingthese discussion topics really wanted toopen with kind of your YouTubebackground and now we have all these newtools with obviously like weaviate andand these llms and stuff to build thesesearch indexes so first before we dive alittle more into uh maybe justdescribing the stack behind ordis andhow you produce summaries how you buildquestion answering systems let's like ifwe could continue on your background inyou know making paper summaries deepdeeply you know I think your channel islike nearly 50 000 subscribers which youdon't get to without obsessing over howto like do it so how do you think likeum the whole content creators space isgoing to evolve with these newtechnologies yeah getting back to yoursubscribers mentioned I I think I Ithink it's actually super easy to to get50k or more if you decide to to optimizefor that and if you just like go a bitmore higher level like for example ifhe's the two of us were just to startcovering python pythorp tensorflowlatest trends latest stuff in AI newsall of that is super trendy and popularand like I know that that content goesvery well I can just see by the viewerson my channel as well uh and and typesof video where I described hey how wasmy experience with Microsoft deepmindall of those are very very uh like uhpopular yet I'm not doubling down onthat just because like I also haveselfish interest with my YouTube channelI never wanted to be a YouTuber and Inever considered myself a YouTuber forme YouTube was an outlet for me to learnstuff and at the same time share withthe community and build some like core acommunity of passionate ml folks sothat's how I think about it honestly andand then what was yourum question actually I kind of went on atangent then I never came backyeah well I think that's the right wayof thinking about it though is buildingthe community it's you know but myquestion is like um so you know like nowusing ordis you can basically turn theAI Epiphany into a chat bot that you youknow people can I think they're kind oftwo things to this there's firstly yeahthe the chat bot and the summaries Iliked what you said on Ken G's podcastabout how long form content shouldn't beconsumed sequentially I agree Ilike this podcast is like we're going totalk about so many different topics islike what's relevant to you justwatching it sequentially probably notthe best way to do it exactly so andthen if I can just add one third thingto that is the multilingual translationpart I think there's a huge potential inthat with these kind of things so you'rejust like how do you think the theexperience for Content consumption isabout I think it's about to totallytransformoh yeah 100 I meanlike I I like to think that tortoise iskind of trying to demonstrate some ofthoseum possibilities at the moment and youalso mentioned uh like uh languages likeit's it's so easy with with powerfullarge language models which because weknow that the Corpus that they weretrained on contains in some percentagesvarious various uh languages uh and soit's actually not not that hard to toadd multilingual support I would sayum although the quality would probablybe uh like dropping uh in by one way oranother which I can't quantify right nowbut but yeah definitely super excitinguh time because For the First Time likevideo is thisum fairly complex medium right like justjust from the standpoint of like thememory and the computing power it takesuh to for you to process that and sohistorically we were not really good atunderstanding what's going on in thevideos and like even the transcriptionwas uh not that great right like untilwhisper uh like like came out like Ithink people are struggling even withtranscription which is just a text andignoring the whole visual space and thenand then when you go like even whichlike maybe with shorter videos like 30seconds or somethingum YouTube and other platforms could usesome heuristics to analyze the visualcomponents but like it's nothing morethan heuristics and I think we'refinally getting to the point where we'llbe able to to to to use models uh likemaybe Flamingo maybe maybe like 254we're still waiting for the for theimage feature to to to drop uh and andyeah I think I think it's gonna be veryinteresting to see how this space uhevolves and what we can do with likeanalysis of video contentyeah I think like um like when Stanfordengineering like uh Chelsea Finn'slectures on multitask learning and metalearning it's like I'm so interested inthat but then it's like I or like Andypavlo's database course from CarnegieMellon it's like I love like I'm sointerested in it but I can't just 25hours I'm sitting I don't have theattention stand for honestly like it'squite hard so yeah this can you tell meabout how artists like just walk methrough it I'm a user and you know howhow what can we do to make you knowthese courses easier to digestmm-hmm so are you asking for like abrief digest of how the thing works orjust like how it looks like from theuser perspectiveum yeah I suppose uh just like umhopefully the question's not tooredundant from what we're alreadytalking about but just kind of like anyGeneral Vision on how we can take these25-hour courses and justI don't know create a more personalizedexperiences to just build that layer ontop of that that makes iteasier to process it maybe like if Icould set the stage more with how I'mthinking about it is like if you cut ifyou cut it up into Clips like you usethe language models to automaticallyidentify chapters and then you kind oflike reorganize it already to convert itinstead of just the sequential flowthat's kind of one idea this is like thechatbot idea which kind of gives yousomething to you know like re like haveyour questions answered in a prettynovel wayand I suppose a general question it andwe can move on if it's not no I think Ithink well like long termlike I think ideally we'll just we'lljust have like a big neural network andwe'll just passlike video frames through that neuralnetwork maybe sub-sampled using somesales and heuristics not just like dummyuniform sampling or something and thenit just spits out the answer I I thinkunless the video is like super superlong I think that these super big neuralnetworks will be able to do that and soI think we're currently in this maybetransitionary stage where we are doingum these hybrid systems but I I actuallydo believe that that that long-termum we'll see more Paradigm shifts I'mnot sure about that maybe like maybethat's that's kind of how how I see itit's still prohibitively expensive to todo what they just said and and and Idefinitely think that that things suchasum external memories uh one of thoseexamples being Vector databases and vb8I do have a place to play becauseultimately uh we know that that's theweak point of of these systems same aswith humans right like I think weshouldn't dismiss just because it's likenot neural network not biology inspiredwe should definitely not not like ditchthose ideas I think some of the paperslike uh was it neural Turing machinesthere was one of the early ones uh fromAlex Grieves if I'm not mispronouncinghis name uh that was one of the earlylike papers that really sparked myimagination for for these types ofhybrid systems where you're combiningsolo memory and then later we hadretrievals like retro from deepmind oror some of those ideas So likeum that's that's going to be a componentbut like I wouldn't be surprised if wejust had pure networks that couldanalyze the video like justum in a single forward pass or somethingor yeahthe the yeah the the I think kind ofseparating it a bit Yeah the idea oflike uh Vision language model that justlike watches a video that I think that'sa pretty exciting idea I know like withflamingo and I think there's recently anew model from character AI That's likethey're making a lot of progress in thisthing and I think that's a hard thingfor people even to wrap their headswe're already still kind of likerecovering from The Hangover of chat gbtit's already so much that it's likestill I think wrapping our heads aroundwhat we can even do with this like justyou know like I'm curious like what youthink about like you know Lang chainllama index just these kind of ideas oflike taking the chat gbt into an API andthen plugging it into all this data andit seems to me like that's still justeven before the flamingo stuff getsbetter it just flips everything on itshead again I feel like there's still alot no I think that's super powerfullike we we've seen the adoption ofLinkedIn and and it's definitelydemocratizing like machine learning forfor a lot of the developers and and umwe we were seeing more I think in in theapp development space one could evenargue that like if you're a great webdeveloper if you're just great softwareengineer you might have like anadvantage compared to animal engineersand and obviously like later when youwant to optimize for if you want toreduce the cost if you want to fine-tuneneural models if you want to do all ofthat that's where the ml expertise comesinto the picture but for the initialstages we're just trying to like um rollout an MVP or something like being agreat software engineer or web developermight be like even like a better thanbeing a ml engineer if that makes senseum but yeah like all of those LinkedInlamba index Vector like uh bb8 uh pinecone all of those systems are definitelycurrently uh with this currenttechnology with the levels where we arethey are they're Pro they are being theshovels for this for this gold rush andand I think there's a lot of valuethat's gonnaum uh like be acquired by the humanityover over the next couple of years but Iwouldn't bet on on the in the long runI'm not sure how this is going to rollout to be honestum I I think that we are we're like kindof getting into this software 1.0mindset with some of these Frameworks uhwhich is not necessarily bad uh but likewe went from Pure we were just like deeplearning everything is going to be justdeep learning deep learning and and thenthere was Gary Marcus who was like noit's going to be hybrid systems and thenall of a sudden it is conference systemswhich is not super surprising evenpeople who were very bullish on peoplealready knew that eventually as I saidyou like for perfect memories muchbetter to have actual external memoryother than like let the Network storethe the the the memory the coefficientsso yeah I'm gonna stop here I wasrambling too muchyou definitely mined out a ton of superinteresting ideas the whole that waskind of one of the things about wavierdoes stick out to me when I first saw itis that you have this like symbolicVector surge so it's a vector searchwhere you build an index of vectorrepresentations but you also havesymbolic traversal and so you know youwith filter and search and so and thenthere's also like the neurosymbolicsystems where you parse the scene to getsymbolic attributes so you can then putinto logic parsing I love all thoseideas butum so I think we're getting nowinto this like evolution of I I recentlydid a podcast with Charles fry that willcome out after this one the title isgoing to be full stack deep learning andyou know they they have a course calledFull stack deep learning and we reallydived into like the evolution of um youknow like the ml Ops and how that's allchanging now and it's kind of like likethis thinking that it's like the perfectminimum viable product tool the zeroshot models and how you can get a senseof it but then if you do build this dataengine to keep training it it offers thepotential to have you know that uniqueModel Behavior that gives you thatunique product Advantage so are youthink about that thing with like and itseems like ortis is a great example ofthat where you can take YouTube videosput it into whisper get the train likeso many zero shot models are in themiddle of it right and put it into azero shot embedding model that goes to azero shot LM and then you get likehere's what this thing could look likeare you thinking about then also havingthat data engine and what that couldthen take it to mm-hmm no 100 and uhlike obviously there are some likeprivacy issues currently we don't evenhave Google sign in so there isn't noway for us to to actually uh couple anypersonal information with the data butlike obviously if you were to justcollect the conversations if you were tocollect the likes dislikes of likemessages and and like summaries there isplenty of information there and Signalwe could we could collect to to then uhlike fine-tune improve models uh finetune them for the particular Channelalthough there will be I guess probablyless maybe for category for a class ofpodcasts or something one could probablyfine-tune and get some somedefensibility uh by doing that asopposed to just just being completelylike zero shot like zero shot isobviously the the best way to do an MVPand and now the problem is a lot ofthese closedum closed apis such as open AI like theyare you you have to pay premium pricefor for fine tuning so I think for forlike open United 6X for like if youfine-tune the model so that's noteconomically reallyum uh like feasible for for manystartups and and and that's where we canmaybe get into the full Mosaic ML andall these exciting startups as wellwe're training these systems to allowyou to have more control uh do stufflike uh constraint sampling guidancefrom Microsoft uh fine-tune the modelwithout having to have the sex of uh theprice uh etc etc so that's why I'mthinking about this it's very excitingsuper dynamicyeah the Mosaic um when they announcedthat 30 billion parameter open sourcemodel and then you know seeing theinfrastructure they built around thetraining Cloud you know because I readthe blog post where they're sayingbasically it's between 700 and 800dollars to do a billion tokens of finetuning on your instruction tuning and soyou know I imagineum who I don't know how many a billiontokens is I don't have a great sense ofhow money that is but I guess I I wouldhave to guess that like my YouTubechannel like the Wii VA YouTube channeltranscripts are under that you know I'mguessing maybe you know them all thetranscripts and all the tokens you'vebeen processingthey were like around 1 trillion rightat least for the 7B model I know theywere around 1 trillion for fine tuning II don't know on top of my head how muchdid they use but I did saw that it's subthousand dollars in price so probablylike I I think even more than just PV PBprobably doesn't have that you don't youguys don't have that many videos yetyeah we're working on that but you'reworking on it yeah it's like it's a longconversationbut yeahyeah yeahbut yeah it makes me think like um youknow having a fine-tuned checkpoint fromMPT for each of these YouTube videosbuilt into orders would be maybe maybethat's an idea for how this chat botgets even more powerful in this kind ofsystem like you know because the I Ihave to I have to think that if youfine-tune the MPT 30 billion checkpointon you know Chelsea Finn's lectures ofthe multitask and meta learning course Ihave to think that that llm performsbetter than the zero shot open AI llmare you sure that's the part where I'mlike really not not sure because if youtake a look at the leaderboard fromhogging face the what's the name theopen llm leaderboard or something Ithink the best model currently there isuh well llama 65b and Falcon 40b and andand those are so much better at leastacross those couple of benchmarks thatthey're using for testing there thenthen the MPT uh 30b and so there is agap there and and there there isadditional gap between obviously betweenthe the the the the biggest Lemma andand what uh open AI is offering throughgpt4 especially and and so I don't knowlike there is this gap which open sourcemodels are kind of closing but then openAI is running away and then one wouldhave to test and and fine tune and seehow much actually you get so how closeryou get to to what open AI is doing outof the box and then is it worth it inthe sensewhich is not going to happen that soonbut like I don't know you know what Imean it's it's a it's a it's ultimatelya Trader you do have to spend those 700for fine tuning for our Channel or sellchannels and then keep on doing that asthe new episodes are coming out as welland and and hope that there is no nozero shot model that can just outperformyou because because ultimately that'swhat we're doing right like it's notunimaginable that if you have like agenerally enough system that you don'treally have especially for these likevideos it's not that complex it's notlike you're talking Nuclear Physics orsomething like so in that sense maybemaybe you don't need to even fine-tunethem if you have powerfully enoughGeneral model I don't know just just aguess yeah no that's a great InsightI've heard that argument before as wellthe um it's not worth the investment forfine tuning because yeah the the NextGeneration zero shot model just makesall that money and data collectioneffort just totally not worth it at allit's a raceand that's actually what brings myinspiration into thinking thatfine-tuning embedding models is quite apowerful thing to do because I don't Idon't I find it unlikely that you knowthat you know without saying open AIcohere or a particular company just likeI find it unlikely that the the big zeroshot model off the shelf is going to beable to just do better at your model atembeddings particularly so yeah likehave you thought about trainingembedding models with all the stuffyou're doing like you know with like thehuberman transcripts like because Iremember when you first did the humantranscripts you annotated as ml opseries and that made me think that maybeyou were thinking in that kind ofheadspace uh let me thinklike I'm trying to like I thinkcurrently the bottleneck for my systemis probably lesshas less to do with the quality of if Ilike give a certain paragraph and I'mlooking for a neighboring similarparagraphs I think that deviatingcombination with some of these models isdoing the fairly decent job I thinkthey're they're probably easierthings to attack at least when it comesto these types of applications then thenlike tuning a embedding model that's mythinking for example the trunking logiclike where do you like if you just chunkthe sentence in the middle like and youkind of break down the semantics of thatwhole sentence that's probably gonnahurt you more than the fact that youmaybe are not using the best possibleembedding model in the world and and andso because of all of thatif you were to just the sword the thebottlenecks I'm not sure this one willbe on top of the list uh although youprobably know more than me I haven'tbeen following the research that I don'tknow like the leaderboard what what arethe best ones I know that ADA uh zerozero two from from open AI is very goodand they they were the best one that wasthe best model when it came out whenlike five months ago or something Idon't remember but like I'm not sure howthe space evolved maybe you can tell mea bit moreyou know I'd recommend um there's apaper called uh benchmarking commercialembedding apis but is Professor JimmyLane I don't know the exact title butbut yeah so the data sets are like beeruh beer is like you know for is I thinkit's like 14 open data sets likeFinancial questions nutrition facts MsMarco and then there's Miracle which islike uh multilingual same kind ofconcept so the they're definitely Ithink even with the state of llms thebenchmarking and saying you know open AIhas defeated everyone that like a coherolike Whoever has defeated everyone thatthere's not really a great sense of thatyet I don't think even in embedding soand embeddings would be a tough one todo as well because to build theembedding benchmarks you talking about acrazy data collection effort likeannotating the query relevance for adocument saying no it's only relevant tothese you know these documents and so onso so you know it's like track if peopleare interested in learning more about uhhow people annotate these data sets andyeah all that is really interesting butI want to uh the text chunking idea thisis definitely some yeah you're that'ssomething we see all the time it's oneof the most common I think First Stepsum do you see any like what do you thinkabout this idea where you use an llm toparse a document and say Here's a splitfor a chunk and like you give it somekind of prompt about like hey you'resplitting this you know you're splittingup this document for Reserve semanticsum please like give us this specialtoken when you want to split it do youthink that idea is worth maybe the costof all those llm inferences forthat that that's an interesting questionI I to be honest I never thought aboutit because the expense and the thesimple heuristics I'm using it are seemto be like doing a decent job I guessthat's similar that's similar in a wayto the thing I mentioned before with thesaliency when you were trying to trunkthe videos I extract certain frames thatyou want to ultimately feed to thismultimodal model so here we're kind oftrying to understand where you want tochunk these so that you can then usewhatever embedding logic or whatever youwant to do I'm not sure do you have likeare there any papers doing this alreadylike I haven't been following that thatclosely yeah well I'm kind of like ameta note since I've joined weeviate Idon't really read papers as much to getto get this my information like myinformation diet is really not papers asmuch anymore it's more like I you knowyou just like Converse like I'll haveconversation with someone who's buildingsomething from alleviate that's likeabout as random you can imagineI have tons of calls like this and so Iand this is kind of where I pick upthese nuggets is just like where peopleare kind of trying out there in more ofa hacking hacking kind of sense thanlike something that I'm gonna say likethere's paper from Stanford and MIT theytested it with as rigorously as possibleRight but I guess like another kind ofcool idea to float out there about textchunking is people aren't thinking aboutlike putting metadata into the chunks solike you would you'd find the title andthen you'd keep putting the title inthere uh there's there's maybe somestuff too with like visual documentlayout parsing but I don't know if itgeneralizes that well it's YouTubeunless you'relike I guess what what you're explainingto me in this podcast that I hadn't preI hadn't understood about orderspreviously is that you're trying to dosomething with the visual aspect ofYouTube as well so and so well ultimatelike my goal is to to like provide thistype of like insight and like extractinformation you know one instead of youhaving to historically you have to gothrough the thumbnails and see where wasthe thing that happened and then tryingto kind of you're using bunch ofheuristics to find information likeobviously for some type of content forfor this class of content where you havemore like sedentary like people sittingdown in a podcast and just like chattinglike the two of us right now probablylike it's it's probably like the visualcomponentdoes not add that much other than maybeemotion interpreting like whatever likein in that sense but most people don'tcare about it right like you just you'rekind of invariant to the you're justlike focusing on the on the knowledgeand you you try and ignore like theperks of each each person is like likeBehavior or whatnot like so so I'm notsure it would add that much due to thesevideos but like in general it's ano-brainer that for some maybe actionmore action driven videos shorter videoslike sometimes the visual component allof a sudden becomes much more importantthan text local porn right especiallywhen you don't have that when you don'thave voice so uh I'm definitely thinkingabout this and I used to work on Visionlanguage models a deep mind like I wasuh closely working with flamingo folksand I was actually helpingum bring flamingos to the real world Ican't really dig into too much detailsbut uh uh like I'm very definitely superpassionate about the space and I waseven before I joined and uh maybegetting back to the to the initialquestion we had I think that's kind ofmy niece like I I found this combinationof language and and and and like uhimagery or videos and audio like themulti-modal space the most exciting uhlike research Direction at least overthe next couple of years I think it'sexcitingyeah I think like maybe to tell a quickstory like um before I was doing deeplearning I was playing basketball and Iused to love doing like these um likeyou you try to like dunk as well as youcan and they're like trick dunks you cando like you could throw it off thebackboard and dunk it you could do likea windmill dunk you could do like a 360dunk and so you and like this site andpeople up their like YouTube channelscalled like dunkademics and stuff likethat where people search for similardunks and I can like like this idea ofsearching for similar dunks would bequite a novel idea and so I thinkthere's certainly like a huge thing Iguess like I'm so biased in thinkingabout this kind of like informationheavy stuff which brings me back into ityeah yeah and you worked at bb8 soyou're you're kind of yeah definitelydefinitely biased in that respect butlike um yeah there is exciting stuff tobe done in the individual space uh Ithink one company that's doing atremendous work although they're uh likeGunk you might have heard of themthey're they are in the sales verticaland what they're doing is they'rehelping understand what they're whatthey're sayingrepresentatives in your company howconfident are they like brand reputationall of this information they're they'rekind of under like extracting the datausing AI I guess in the background whatlike the problems using some heuristicsand maybe maybe since recently theystarted using more neural networks atall uh but like that's one clear examplewhere where like people are using uhlike visual component in in in inIndustry to to analyze and extractinformation from the videoyeah I think I know we're touring allsorts of topics but yeah like crms Ithink are are like just how you processa call and all that is just and it kindof brings me into like what like what Ilove my like favorite project to work onwhich I feel like is kind of adjacent toordus is like I've turned this thesepodcasts into a data set I have a we dida podcast search on GitHub and like II'm so excited about thinking about whatwhat can be done with these podcasttranscriptions and I want mycompensation manfor the data I've providedI'll pay you in two GitHub Stars howeverI'll transfer the currency but yeah thethe there's one I there's like these twoideas I so I had you Shang woo on thepodcast who's working on somethingcalled chat Arena which is where youlike simulate conversationsdo you think there could be anything tothat I know we're talking like justtotally broadly and like about whatevernow simulating conversationsumwith like with the idea of likegenerating more data or or with the ideaof entertainment or like or just yeahthere could be many wives yeah right nowwe're calling this generative feedbackloops to like broadly describe this ideaof like the feedback loop is inreference to saving the generated databack into the database to then searchthrough it in the future and so the ideawould be you simulate theseconversations and then you like save thenew conversations back and you blow upthe this data space this way and youknow like I guess the idea being that insimulating like a million conversationsbetween like Sam Altman and David silveryou know just like taking people to justchat about these topics with that youcreate like this new uh space and andbecause I kind of think like you know itreminds me back to like early days oftraining Gans where I'd be like whatkind of Novel images Has It produced andso I would need to generate those imagesand then you know this is way before Iknew about something like their databaseor I'd even thought about that kind ofidea but you would just like it was kindof a natural intuition to try to likesample models from the Gan and thenembed them andyou know compare compare the nearestNeighbors from your Gan to your trainingset and just say like especially likewe're debugging mode collapsehopefully that sets the station yeahyeah it makes sense well yeah like I Iguess this this space of ofconversations and language might be evenmuch tougher right to find the nearestneighbor of the conversation than of alike256 by 256 image or a thousand bythousand whatever with against they theydid improveum but yeah definitely interesting likeresearch idea and and you can definitelyimagine products uh coming out of thatthat direction immediately like I'm surepeople would be willing to pay to hearlike I don't know historical figureslike Nikola Tesla speaking with AlbertEinstein or you know what I mean like sosomething similar in similar in spiritto what character AI is doing but moremulti-agent more like more more of thatthat could be one interesting productarea and the research is alsointeresting in and of itselfyeah I guess it's like by simulatingconversations can you discover new likeideas kind of like maybe like likeanother kind of thing I like a lot aboutis like to take these podcasttranscriptions you know automaticallytake out the chapters and maybe promptit by saying like you know uh Alexa andConnor are talking about vision andlanguage models like retrieve from allthe other podcasts and say did they sayanything unique is there anything likenew in this conversation prompts likethat and then you kind of from there thethings that are new I don't know likehow many new ideas you discover inconversation yeah we might get depressedman we might get depressed I think we'regiving ourselves much more credit thanthan yeahneural networks so they're justinterpolating data and like humans likeif you think carefully enough like youjust you just find a snippet informationyou picked up five years ago and thenyou connected it with some snippetinformation you found out two days agoand all of a sudden this this seemsnovel and interesting but yeah yeahexistentialyeah yeah I mean if like this kind ofsynthetic data if I can I so I saw thisinterview with Aiden Gomez CEO of cohereum talking about synthetic data and I Isampled this quote out where he says Ithink there's a way in which syntheticdata leads to the exact opposite ofmodel collapse like information andknowledge Discovery expanding a model'sknowledge beyond what it was shown inits human data that feels like the nextFrontier the next unlock for anothervery steep increase in model performancegetting these models to be able toself-improve to expand their knowledgeby themselves without a human having toteach them that knowledge so that's likethe end of the quote I read but I wouldlike be I like this a lot because Ithink whether you're simulatingconversations or you're putting them inan environment system and this is kindof like a deep-minded idea right likethis open-endedness I think they havethese stimulus it's like this kind ofsynthetic data like I guess I think thatquote maybe is does a better job ofexplaining that I do but like havingthese conversations is like creatingsynthetic data and maybe there's newideas in there 100 and I'll ultimatelyif you think about it when you're whenyou're trying to solve a problem I don'tknow about you but oftentimes I do SUBvocalize I I do talk with myself like Ido have inner characters likecommunicating with each other right andtrying to to get to the conclusion or orwhen you're trying to debate out an ideain your head right you're rolling out adiscussion like a hypothetical futurehow would that what would be like the uhlike if you had an adversarial or maybea better word to be like a super smartuh like opponent and and like how howwould you reply to all their questionsand where would you like how would youTraverse that whole like tree ofpotential outcomes and and so like inthat sense I think this is also morefundamental than than just like data oror like it might be a methodology toimprove the reasoning uh likecapabilities of these systemsit's definitely super fun superinteresting yeah I think um like alsostaying on the Deep like like the mutethe alphago how I did this tree searchto look into the future of the moves itcould make and I don't know if you'veseen this tree of thoughts paper whereit's like a language model is like umyeah like so yeah what do you think thattree of thoughts is a I mean to me thatseems like one of the most craziestideas I've ever heard is combining theyeah definitely super exciting it's kindof the generalization of the of thechain of thoughts but just going from alinear process to a more like tree-likeprocess in that sense conceptually it'sit's not that like well I don't want tosay big of a deal because all of theseideas in retrospect are just connectinga couple of dots uh the pro I actuallywanted to try out that idea in in in oursystem in orders uh but the thing isthat's super expensive that that type ofum like a tree like you you you need somany inference steps and that's more forsome offline processing of somereasoning tasks uh but but definitelyinteresting yeahyeah well that's I mean I think the costof inference with large language modelsis so frustrating because it feels likethere's so much we could do if it costsnearly nothing to just run yeahyeah but it's also liberating because itconstrains a lot of the potentialmethods I could be trying right likewhen you have the real-time constraintwhen you're interacting with the userswhen there is a latency component in thefull picture then you start thinking ina completely different direction and yourealize that there is not that manygreat ideas that focus on like lowlatency real-time type of of like uhapplications it's mostly you're tryingto get the model to be better and thenand distill it and make it make itfaster than all of these techniquesthey're more for these mathematicallogical reasoning benchmarks than forlike communication and stuff I don'tknowlike umyeah like kind of like the tool use andthe well yeah and the whole distillationyeah and all these covers I mean it'slike how exactly are they going to uhcompress these models and get to thepoint where it's super cheap to run itlike I've seen like this you know like4-bit inferences getting really good andlike the stuff that Tim detmers does isalways like you always see that tweetand you're like why that's just insanelike you know I think it's like you knowthey're at like 60 billion on a singleGPU stuff like this and it's like butyeah so yeah this whole kind of topicand I so I think kind of uh I I thinkwe've done a nice like just open-endedtouring of topics around ordisumis there anything maybe before moving onI wanted to ask you kind of about somepersonal or personal self-organizationthings I took away from your podcastwith Kenji recently um but is thereanything maybe you want to cover as wellabout orders before we kind of move ontopicsumyeah I encourage people to try it outI encourage people to try it out we justadded a couple of cool new features uhlike we added we added like suggestedquestions for each video like therethere's like a couple of relevantsuggested questions because there isthis blank page syndrome I think that'swhy it's called like that's what writersusually have but like also when you'reinteracting with these systems peopledon't know what to ask right even thoughlike you can actually ask the agent andyou can tell you what they can do butpeople don't come up with that idea andso this small UI Tech so to speak helpsI think a lot we also added JeremyHoward today there is a bunch of newchannels coming up so I thinkum it's it's exciting I'm learning a tonand I'm learning a ton about also justtypical back-end business for example Ispend the full day today trying tofigure out the the Google sign-in likeeven though that's super conceptuallyeasy right it turns out it's verydifficult because of versioning likeit's a version detail like there is theManifest version too in Chromeextensions version three and so like alot of documentation is just outdatedand so people don't give Engineersenough credit we like in in this mlspace like we focus too much on theselike interesting ideas like gettingdone is is so much more difficultsometimes than than they would like youwould like to think even when it'sconceptually super easyyeah maybe that's some like a tangent Iwanted to convert sorry everyone we hada little bit of connection crash but uhso back online the the question I reallywanted to ask you and I hopefully the asthe connection cut out it got out thelast part of what you're saying aboutum you know recently adding JeremyHoward's uh YouTube channel into ordisand how you you know as I've beenfollowing along with you you've beenadding all these new channels into itand it's like a nice like continualupdating of it to follow along with andso I really wonder about this idea oflike an embedding Marketplace and it'skind of like an interesting new categoryI've been having conversations with afew entrepreneurs who are who areexploring this idea where it's like youknow say you want like the almanac ofNaval ravacan if you want like that theembed open AI embeddings of that bookyou can just kind of like grab it fromthis Marketplace and I think that makesa lot of sense because then you don'thave to deal with you know vectorizingthe thing and that's already been donefor you do you think about that as beingsome kind of aspect of Oris as wellmaybe like youis someone's exciting I never thoughtabout it because I guess it alwayslooked in my mind as a very custom thingright like you you have a lot of paperparameters you have to pick to do thattype of embedding uh like Marketplace asyou called it in the same like like howbig are gonna be the paragraphs likesometimes you want to have smaller onessometimes you want to have bigger oneswhere do you trunk like the trunkingdecisions matter maybe later peoplefigure out better methods like forexample the llm saliency method youmentioned and then there is also thechoice of the embedding model and thenwe were discussing also the quality ofembedding models so what happens if ifyou all of a sudden some much betterembedding model comes out what do you doyou have to re-index the fullmarketplaceand so in that sense I'm just thinkingwhy did maybe a like a valid questionwould be why didn't we ever do the samething with other types of data sets forexampleI don't know for for imagenet why didn'twe create a Marketplace of the embeddingcertain layer certain like layer insideof resonance 50. there was a such acommon test right people were constantlyusing resonance back in the day and andyou always had to do this this Propre-processing to save on compute andthen you would locally uh deal with thatdata like so why didn't nobody come upwith with that type ofum like Marketplace for other types ofmodels not just for embedding onesI guess that's the only question I don'tknow how you think about ityeah no I think that's a perfect I thinklike the way that I understand imagenetmaybe maybe this is a hot take but Ithey put a ton of effort into labelingthe data set and and it's kind of likeyou you need to like kind of apply forit with likelike it's not just something you candownload on uh you know like tensorflowdata sets and I I feel like they kind ofget pay Wallet not pay wallet but youknow they it's kind of like with andyeah I don't know if I'm stepping onpeople's toes with what I'm saying butit's kind of like with the mimic dataset like you have to um like get thiscertificate from physio net and then youhave to go and apply for the data setit's not just you know so that's kind ofmy opinion of imagenet got it it's likeyou know more more gatekeeping mentalityI mean that's that's fairly annoying Idon't think you're stepping on anyone'stoes that's I think that's a sharedunderstandingyeah so I'm yeah but I think like withum you know with these kind of YouTubetranscript data setsit's like if you open source a data setthen scientists can like you couldpublish a paper where you try differenttext chunking with some kind of metriclike maybe you generate syntheticqueries for the Jeremy Howard videos andthen that's how you kind of like youknow measure it and then you and thenyou can like publish science and likepresent it in nerves and I I see welland stuff like that right and so I guesslike it's kind of interesting to me likeas especially like with as I think aboutwig a development it's like what kind ofdata set do we want toyou know like with a n benchmarks it'slike we make some Innovation on productquantization it's like okay we're goingto tell you about like the sift vectorsrecall and it's like that's prettyacademically sound but then I worryabout if you can tell the whole storylike it compared to like the data setordis has if like we could showsomething like some Innovation andembeddings that you know creates thisbetter experience for orders kind oflike by using these transcripts as thedata set and then and then also get likethe academic credit of like oh we didthis clever technique because we'reGeniusesyeah so yeah I'm definitely not in thatgame like I it should come on the PHDroute but I took a completely differentdirectionyeah yeahso anyway so yeah I I think it's quitean interesting idea and there's I thinkthere's all sorts of cool things you cando with this ordersyou know when I first saw your Cubanhuberman transcripts podcast uh uh uhdemo with the website I thought that wassuch a cool demo and I'd encourageeveryone to check out ordis of courseand so transitioning topics a bit toyour I think you have a lot ofinteresting ideas in personalorganization obviously you know you'vereached the height of machine learningsuccess and deepmind and your startupCEO founder you know you need to be youobviously need to think about this quitea lot so I one idea you mentioned inKen's podcast was about analogs ofperiodization and weightlifting and howyou think about your information dietand you know the periodization maybe youyou want to explain the ideayeah sure I meanum the idea is fairly simple when you'retrying to build muscles in power liftingyou you're not going to try and andincrease your your weights every singleworkout because ultimately you're goingto saturate and you're probably going tohurt yourself right and so yeah whatthey have is some type of like uh youyou keep on increasing like maybe if youhave a periods like so-called macrocycles of like three month periods andyou keep on increasing the weight maybeevery two workouts increase to two and ahalf kilos or something and then at theend of that period what you do is youdrop by some percentage for example yourOne Max strap is maybe 300 kilos and youlike your last workouts for maybe like80 percent of that of that number andthen it dropped to maybe like 60 andthen you start from there like you dothe so-called deloading and then you youstart another another cycleum and uh I basically borrowed theterminology when when I was learning newsubjects uh because I I like to treatthe treat brain as a physical thing asit is right like ultimately you do haveto form those synapses and that's abiological process and metric has tomove around and things have to be builtup and so because of that I think it'sreasonable to make these types of breaksand periods and like chunk your youryour uh like kind of organizingstructure learning in that way that'swhy I think about it I think it's afairly simple uh like uh analogy and Iwould be surprised if nobody came upwith this like already I did pick it upmyself but like I would be surprised ifnobody is already talking about it'sfairly obvious connectionwell I think of um like when I waslistening to you speak about originallyI thought it was so interesting becauseI think kind of like in weightliftingthere I think like rep ranges are theother thing to think about like you havelike a hypertrophy cycle you knowyou know where you would do like two tofour reps four to eight reps eight totwelve and it ends up being an entirelydifferent workout and so I think theanalog here is like whether you'rereading papers or if you're like hackingtogether on a project or if you're umyou know writing deeply or if you're sayuh interviewing like you know uh talkingto customers or your product so sorry sothese are like four separate tasksexactly different dimensions whereas inworkout maybe you have like a volume andintensity like I could be increasing theweights or I could be increasing thevolume I need a number of repetitionsmaybe like you definitely have more X'swhen you're learning but like therethere's also this workout and rest youhave to sleep if you have to likenutrition has to be proper all of thatcombined I think that also translatesinto the learning space you do have tosleep nicely and like we do know thatthe Eureka The Epiphany moment uh no punintended uh like do come off on whenyou're just chilling and like having ahot shower or taking a look outside inthe nature uh and and and and yeah Ithink there is a lot of cool insightsyou could pick up from from likethat other spaceis it do you think about organizing yourtime that because like for me honestlyit's just like a chaotic mix-up of thosetasks there's no order to like what isdone like I don't have like a readingweek uh engineering week uh talking topeople week but do you think aboutorganizing your time in that wayuh currently it's more on a day-to-daybasis like again it depends on the stageof your life like back then I was tryingto learn so many different topics and Ithink that was the best approach forthat currently I still do have somestructure but it's more on a on a dailybasis like I I know when they have aworkout like I just had a workoutimmediately before this this thispodcast and then like I I have certainnutrition after the workout uh like Ihave regular sleeping hours and like Ihave maybe cold shower on like 5 p.m andand so like I do have some structurearound the structure I'm trying to putin everything else uh and I do try to ifI don't have it I feel I'm not asproductive I think it's very importantto have some type of rigidity toconstrain your time in one way or oranother but that's what works for meyeah I think like something that'sworked for me just like little littlethings is like trying to I try to havelike meetings every day in like two timeslots like between you know like elevento one and four to six if you know if itallows itself to be organized that wayand and then I like to have those in thecalendar and then I have like my morningsession I have my afternoon session andthen the pressure of being like if Idon't do my deep work before the 11 to 1then I'm then it's lost and and sothat's kind of just like a little thingthat I do in addition to things like youknow I maybe don't do cold showers asoften as I should butyeahyeah I mean I mean again it dependswhether I think I think Paul Graham hadthis uh like distinction between likethe the builders the makers and then wasit the managers I might be missing outthe other group because I'm not part ofthe group but like the whole point iswhen you're a maker and Builder youreally need to have these prolongedperiods of time with no interruptionsand and so if you do have a chance and Ilikely do have that like I can justschedule or or like not yet meetings atall and usually I don't I rarely havemeetings to be honest I have these Istarted having attending podcasts a bitmore like on Fridays but like most of mytime I try and get into this flow andfor that flow you you do you need likespans of time or like three four hoursto just get deeply into somethingotherwise or even moreum otherwise I don't feel as productiveyeah I I guess like um yeah I used tolike ohit's so interesting like I I also agreelike um for me it's like more than threehours is like uh I'll probably like notreally be I'll probably like be on mycomputer but like I'm like half you knowlike after three hours so that's what Ikind of like to just do like three hoursat a time and then meetings and thatkind of thing but the the other kind ofmeta topic is I'm curious as you'rebuilding ordis how your perspective haschanged on breadth first thinking anddepth first thinking like um you knowsomething like you mentioned debuggingthis uh sign in error with Google howwould you categorize that kind of taskyeah well well again I would categorizeit as as bread for a spill because it'sone day right like like I do a bunch ofstuff I have to take care of I currentlyI'm a single employee and my girlfriendis like doing the product design andshe's also helping around differentother stuff but but like the technicalcomponent I'm basically building thewhole system so that means I have to beall around the place I have to do thethe full data pipeline uh the robustnessof the data pipeline the back end theagain the some SLA like and then thefront-end part and and thinking about UIand having user studies actually startedhaving more and more user studies andsome of those as a consequence some ofthose UI decisions I made were aconsequence of those user studies and soit's fairly broad like in thatperspective there is the marketingcomponent obviouslyum like community outreach all of thatso it's very very all around the placeit's not focused like in in in the samesense as some PhD guy or somebodyworking at deepmind right now on aparticular like research is doing rightlike even though on this micro like inin this if you take a look just at as aday as a Time unit then I was just doingthis obsessively the whole day like forlike six seven hours already orsomethingfirst and yeah I think well I think mypersonality and I think maybe you sharethis is like that kind of if I was doingsix to seven hours of thinking about uhlike I have a gradient spiking error andI'm like trying to debug it for the lasttime I don't know I don't really havethe intention to do that have like alittle bit of marketing a little bitlike I I for me the breadth first itkind of like keeps me having fun with itlike if uh but yeah yeah I definitelycan can empathize with you but like I Ithink I I can still I can pull itthrough like I think it's very importantlike oftentimes there will be issueswhere you're stuck with something andyou have to push it through and do justsingle thing for for days and I think Ido have that skill uh it is harder itdoes require like there is like aphysical manifestation of pain sometimeslike just because like oh my God you'rejust pissed off with everything and youjust but you have to push through it andsoum it's a skill I think it can be builtas anything else but probably yeahdefinitely more enjoyable when you'redoing like when you're having this thisbroader understanding of everything andjust yeahyeah I think like in the psychology oflike the most painful thing you can dothat's for sure I think like the mostpainful thing is when you're solving acoding error that like the the so whenyou do solve it it's not intellectuallysatisfying at all it's just like I can'tbelieve that was the thing right likebut like I I think when when you whenyou're an engineer when you're asoftware engineer you learn toappreciate those moments because most ofyour job looks like that for examplehere I really like like Greg GregBrockman at least according to what Ican see according to his tweets heseemed to be that type of person he'slike like pushing through these verypainful boring details nitty-grittydetails there was on some off by oneerror or like some some like someredundant copying between the GPU andthe CPU host or whatnot like and heafter seven hours of digging deeply hefound like uh the the problem was likeobvious in retrospect but until find itright it's like the asymmetry betweenverifying versus finding the solutionvery very excitingyeah yeah oh yeah there are a lot ofpeople who do that better than I do andI just respect it enormously it lookshard but every now and then I findmyself doing like doing problems likethat but yeah that like just you knowgetting into the CPU profiling and allthat kind of stuff is really a hugeskill one other thing you said that'sreally interesting that I relate to alot in my life is my fiance also worksat uh we VA and we work together as acouple who also like talks a lot aboutwork and so I'm really interested tohear that like your girlfriend is doingthe product design it has all that likemy experience has been it's like just aton of fun and maybe we talk about worka little more often than normal couplewould I would say in like 100hahahayeah but it also ends up being a niceconversation topic I think in yourrelationship I I don't know how myrelationship would look like if we werenot like connected on this project likemost of my time like I like since likethe moment they wake up until 2 A.M 3A.M I'm literally constantly working inwhy one way or another with a couple ofthese breaks I mentioned like becausethey are important so like I'm not surewe like where I could squeeze in thatadditional time to to keep therelationship healthy so because of thatI'm very grateful we are actually superaligned on on that front and she she andI we are both aware of the dynamic andumyeah I think that's exciting you knowlike I mean maybe a thing that poppedinto my mind talking about this wholething is if you know that the guy who isuh the CEO of ruplet I think I'm I'mJudd is his name he's actually I don'tknow if you knew this but his uh hiswife is his co-founderso and then that's that's super excitingand they they know they've now crossedthe like they are a unicorn company nowalready and and they've been in the gamefor like seven years and since recentlythey've been just exploding and I thinkI really love to hear those thosestories where people are not inside ofthe common pattern I really like respectthat because the pattern is you want tobe two to three founders uh like mostlyguys uh not not like and then like likepreferably StanfordEtc like you know what I mean like thoselike like YC has this better matchingand you have these companies and likethey're all these expectations andstatistics and so when you hear such aoutlier likesucceeds it's very it's very um likemotivating as well right because thatmeans okay now maybe maybe we can dothis or or same with me like I came fromlike Serbia and like this guy was likejust self-studying and then all of asudden he's like in the in the best topAI like lab in the world like okay maybeI can do this and so I like I thinkthose are very important for like justlikelike full in the world I guessawesome well Alexa man thank you so muchfor joining the podcast I had so muchfun talking about all the technicalideas as well as hearing about howyou're managing your time or to such anexciting project I'm so excited to seehow it evolves and thank you so muchagainthanks a lot man I really enjoyed theconversation", "type": "Video", "name": "Aleksa Gordic - Weaviate Podcast #55!", "path": "", "link": "https://www.youtube.com/watch?v=pGrP87gE8XU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}