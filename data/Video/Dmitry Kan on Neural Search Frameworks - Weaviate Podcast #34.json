{"text": "I am so excited to host Dmitry Kan on the Weaviate Podcast!! Dmitry is a world class expert on emerging trends in search ... \nhey everyone I'm super excited to bepublishing our latest podcast withDimitri Khan we're discussing some ofhis latest Works around his keynote talkat the haystack European conference andthis latest blog post on neural searchFrameworks a head-to-head comparison soI think it would help a lot to see thevisual that Dimitri's created todescribe the neural search pyramid soyou see from this visual of the uh thepyramid going from the parks and nearestneighbor algorithms to the vectordatabases neural Frameworks encoders andapplication business logic and userinterface so a big part of this podcastis going to be Dimitri and I debatingthese components uh you know what shouldgo where and then sort of theabstractions around it but hopefullythis visual helps a lot with what we'regoing to discuss in the podcast I alsothought this would be the perfectpodcast to debut the Wii V8 podcastsearch app searching through the weviapodcast with weaviate of course sohere's the GitHub repository with theEva podcast search all you would need todo is clone this repository then runDocker compose upd and then python3restore.pi to restore the backup withthe full transcript with this podcastwith Dimitri in it so I'm really curiouswhat people think about these two linesof code for restoring data sets becausethis is kind of the thinking so fararound how we're planning to package upthe beer data sets so if you've testthis out please let us know how youthink about this experience and I reallyhope you enjoy searching through thepodcast so once you're running thepodcast search app and weaviate you canask it all sorts of questions like whatis the neural surge pyramid and it'llsemantically match it with the part ofthe conversation that talks about it andall sorts of other topics that werementioned in the podcast so maybe if youdon't have time to listen to the entirehour and 45 minute podcast you can justsearch through it with the wevia podcastsearch app so thanks so much forchecking this out and I really hope youenjoy the podcast hey everyone thank youso much for checking out the wevapodcast I am beyond excited for thisepisode we have Dimitri Khan one of themost influential speakers in searchtechnology Dimitri is the host of thevector podcast he's a senior productmanager at TomTom and he's recentlygiven this incredible keynote uh thehaystack European conference 2022 sofirstly Dimitri thank you so much forjoining the weba podcast hey Conniethanks for having me it's always it wasalways a pleasure to talk to youawesome so could we maybe kick thingsoff with uh the big the keynote whereVector searches uh taking us and some ofthe key ideas behind that yeah for sureuh so the keynote I had an honor to givethis keynote at the haystack conferenceas you mentioned in Berlin in lateSeptember last year and uh we've been abunch of uh actually people from Vectorsearch Community including bb8 andPinecone and quadrant and also usersthis was especially interesting to seehow far ahead users gotten and theythey've been asking very precisequestions you know like how do I choosea model and and which database to preferand so on and so forth this was veryinteresting and some of them have beenalready trying things and so in thatsenseI wouldn't say like a year ago maybe Ifelt like I couldum share more and educate more and evenexplain the basics uh nowadays it's morelike okay we already we alreadyunderstand the basics okay can youexplain what what what practical step Ican take to actually Implement Vectorsearch or I have tried you know doctorquery it doesn't work that well whatshould I do you know and one of the keypoints in theum in the Keynoteuh key points in the keynote I have uhhad was uh this um work that was done bymckinsian and and Google in 2021 soalmost like two years ago nowuh where they call out the issue ofsearch abandonment costs in for the U.Sretailers so it's only U.S retailum which kind of like loses 300 billiondollars a year uh and and why they dothis why why this happens is because ofthe search abandonment issue so you knowpractically speakingusers start typing it you know a querythey probably see some autocomplete somesome Dynamics going on on the websitethen they check the results and theycannot find what they look for and wediscuss with you in the vector podcastjust recentlyum that the query language the the userlanguage is so different right user touserum I have a bunch of examples on thisfront as well when when when search ande-commerce doesn't workumand sowhat's interesting also is that64 percent 64 of retail website managersdo not have a clear plan for improvementso they kind of lose the money theydon't know what to do with it how to fixthis and that's like more than half ofthem right it's like a big big numberum and another issue that kind ofsurfaces now that I have this productmanagement had onumit's interesting to see that 85 percentof global online consumers view a brandcompletely differently after this searchis unsuccessful so in some sense thebrands themselves have nothing to dowith the search engine which isbasically like let's say an aggregatoror whatever like Amazon type of thingright but like if search doesn't workthey are they think it's brand problembecause they cannot find the item theyare looking for right and so they changetheir perception of the Brand This ishow important it is to make the searchworkyeah yeah it's super fascinating is itreminds me maybe like these kind ofnumbers there's something about likemaybe 98 of data is private and themotivation of the sort of indexing andsearching through private data and as aswell as this retail thing like havingthese kind of numbers butum I'm kind of thinking like so with theretail and fixing it is it theresponsibility of the brands like whoseresponsibility is it to implement theseThe Cutting Edge search engines I meanyou know we think like with alleviatedit's our responsibility to build it andmake it available and you see it asbeing like more uh more independent uhe-commerce retail stores so like notjust Amazon you know being sort of thefront layer but more and more uhindividual retail sites taking on uh youknow this pipeline of as we'll talkabout neural surge Frameworks likehaving their own uh we V8 Gina AI kindof setup yeah I think that's that's anexcellent question and I think it kindof like depends on the situation thePractical situation with engineering andand sort ofum assets and resources that thiscompany has and also like the focus thatthey want to have right in some casescompanies might want to like Outsourcethis and just ask somebody to build itfor them and and this is this is aninteresting opportunity you know forum players like for example semi orovestpa you know if if you guys have acloud offering which is kind of like endto endyou know solving a particular issue foryou know starting from actually creatingthe embeddings all the weight of allthese backups every infra element istaking out care of and then on top ofthis you can actually prove that youknow I can actually retrieve the theum the items with with higher relevancythen I would do myself because what doesit mean for me to make it myself I wouldstart like scrambling reading stackOverflow hiring engineers and that'slike a long path right and maybe I'drather pay money and just get to themarket soonerand so I think uh that's an excellentquestion but there's another facet tothis um I guess is it like in yourquestion is it Brandsum concern or is it like uh uh let's saya neural search framework a vectordatabase concern or is it like aretailer concern in some sense I thinkit's like a it's a joint ecosystem rightit's not like you can just say heyplease fix me the house and and I'll payyou but they might fix it their own waythey might also break some things whilethey do this but you are paying so moneydon't always buy everything so I I thinkI still believe thatit's better if these players wouldcollaborate in some ways for example youknow if we're talking talking aboutneural search implementation you knowwhat's important is like for example howyou catalog an item what metadata youhave right and so and also how up todate it is right so somebody needs to besupplying this data to you and so maybethe brands could be supplying this datato you as they change to introduce newproductsum but then everything else you know thepipeline should be already in place andit should be easy to use you know be itan API or some other way like Amazon Iremember they they have an office theyhave a service of delivering data ontracks right because it's much faster isit deliver on trucks than to upload itbecause it's a lot of databut if it's like a medium-sized storelike maybe you don't need a truck todeliver your data you know on batchlevel or whatever like you could buildan APIum I hope I answered I answer yourquestion there is another anotheranother perspective also to keep in mindeven if you have the engineering forcein place like in-housebuilding uh like if you take like anopen source databaseor open source neural framework it mighttake you a while to to gain the you knowto to accumulate the knowledge to gainthe momentum to realize okay this iswhat we can build from POC to actuallyproductizing thisum maybe it's easier if you just go andkind of like Outsource this resourcethis cost to a managed database like incase of vbait or in case of Pineconeumand focus on something else right focuson that specific you know catalogingissue or maybe bringing a classifierthat will do the product classificationon the Fly and things like that rightit's kind of like put your effort andfocus on what mattersand then later maybe you can change yourmind you know the moment you grow maybeyou will decide to build your own Vectordatabase but but before you before thathappened you need to kind of like payyour bills right and so don't don't getahead of yourself and also if youpartner with a clever you know playerwhich is like we have a lot of them nowon the marketumyou know you might win and they willalso learn you will learn together so Ithink that that's an interestingperspective to to also think aboutyeah it's a it's a brilliant way to openup this kind of as we're also talkingabout neural surge Frameworks and you'vewritten this great blog post thatoutlines a different neural surgeFrameworks and as you mentioned I meanit's just a you did a brilliant job justcovering it and this idea of uh you knowthe overhead for learning it thelearning curve is something beingsomething that's important and atweviate there's a huge focus on uh uxand being developer friendly creatingcontent to try to educate especiallywith the new releases we try to haveeven alleviate Air Show to you know tryto explain how to use all the stuff andwhat it is as much as possible and Ithink this is going to be such aninteresting discussion because it'sthere there are parts of it that arethat should live outside of leviate Ithink parts that I think maybe should bebuilt into weed and I also want to justquickly set this up before we get intoit that like this what I say on thepodcast about the relationship ofwebgate and neural search Frameworks ismy personal opinion it's not like anofficial statement of with respect tolikehow I see what should be built where soI really want to kind of transition thisinto maybe we could kind of do the tourof the neural search framework startingoff by maybe just the high level of howare you currently defining a neuralsearch framework oh yeah that's that'san excellent question and and maybe Ican also intro like I created this youknow mental diagram for myself and Ikept selling it everywhere and seemslike people get it and some of them evenlike reach out on LinkedIn and say hey Igot your vector search pyramid thank youfor creating it but really I you know mygoal was just to put things in theirplace like on a bookshelf so you canlike reach out and and and and givecontext and and and and ground yourdiscussion and so in this Vector searchpyramid which probably can also shareyou know essentially like on the base onthe base level you have the KN and a nalgorithms and to some extent I alsocovered some of them not all of them youknow I know that Pinecone for exampledid a great job publishing a lot ofmaterial on this you know how eachalgorithm works we also happen to inventone algorithm by gpq which is just amodification of product quantizationum and then the next the next layer andI did publish a year ago now a Blogabout not all Vector databases are madeequal and so you have mailbox bb8Pinecone you know GSI quadrant Vespabald and also those players that kind oflike yeah I I didn't find yet the properphrase I I kind of say catch up but onthe other handit's not like ketchup it's like beingbald and actually going into this spacefor existing databases like uh redis andelasticsearch and solar and they addVector search functionality as well fortheir users and then there was this nextlayer that I couldn't like quite wrap myhead around and I was thinking whatexactly is this and of course genomeand Haystack sort of like in some sensethe pioneers of of creating theterminology and so I think at some pointthey were calling themselves neuralsearch Frameworksum recently I saw that Gina is callingthemselves something like amylopes forneural search so so of course thesethings morph but but I kind of likedecided to stay with the same term likeneural search framework and I kind oflabeled every system I could come acrossbut there are some exceptions as well bythe way there and I'll get there butbasicallythe way I Define it and I guess we canshare the the blog post itself is thatbasically reading from the blog neuralsearch framework is an end-to-endsoftware layer that allows you to createa neural search experience includingdata processing model serving andscaling capabilities in the productionsettingso like just to unpack thisso let's say if you take a SQL databaseand you want to build a website rightyou will still need to figure out okaywhere do you get the data how do youprocess it before it gets in the SQLdatabase then how do you normalize thetables if you do that right like foreignkeys and all this thing which index typeto choose and things like that so sothat it actually breatheses and worksand can scaleum but like this definition may sound tosome people as uh Emma lops machinelearning operationsbut there is a key difference that firstof all mlops it's like a wide area it'sit's a wide field you know it itconcerns itself with a lot of thingslike I don't know model training youknow model versioning deploymentsserving monitoring you know data driftfine-tuning a lot of a lot of thingsright and and the application is alsoquite diverse like I don't know I couldbe buildingum I don't know face recognition systemor something like that right so but likeneural search framework focuses only onneural search so it's like and and alsoanother question that frequently comesup is like what's the difference betweenneural search and Vector search in a waythere is no difference it's just likehow you take which angle let's sayneural search you could think of it okayI have a deep Learning Network and sothat's probably why it's neural becauseit's like deep learning the you knowneural networkbut if you take the stance of let's saygeometric space right so you you embedyour object into multi-dimensionalgeometric space and now you need to andeach point is a vector so now you needto basically find a vector which isrelevant for your query Vector so youare doing a vector search right but butthis is kind of like mechanics of itum so yeah I think this is how I Defineityeah I think I'd want to start withconnecting with our earlier conversationof the lost money in retail and more andmore brand stores trying to build theirown retails and I'd even maybe extendthat to people with their own blogslooking to have searchable things ontheir blogs and you know also paying thebills and not worrying about this thingI kind of want to start off with saylike the uh data pre-processing layerlike I see kind of with these neuralsearch Frameworks they Define thesepipelines and I think pipelines is sortof the key uh term here and I I'm goingto talk about what I what other pipelineI think should live in weaviate and whatI think should live outside obviate andI think maybe starting off with justlike the data ingestion part like maybeyou have some kind of API that you queryto get the data you have maybe like aPDF parser with some kind of OCR how areyou thinking about that first part ofthe data ingestion layer because maybeif I could just add one more thing totransition the question when and cominginto like running things in productionuh Gina AI they have these executorpattern and you know I learned a lotabout this on the wevia podcast withMaximilian work I highly recommend thatif you're curious about learning moreabout this pattern for listeners butthis kind of way of scheduling like aCron job that say you know every twohours it's going to query this API likeor say every day it's going to hit thearchive API to get the new batch machinelearning favors parse out the text andchunk it in the PDF then vectorize thosechunks and and then maybe put that toWii game and then yeah I don't want tolet's start just on that first part ofyeah I think it's it's another excellentyou know topic to think about becauseum I've been Consulting a few startupsthat are trying to build Vector searchright and uh they sort of get quicklyfar ahead you know because they havelet's say a database a vector databasethey have their data obviously they'vechosen the model to vectorize withum they're already scratching therelevancy side of things but but thensomeone comes in and says hey we justreceived another batch of uh objects wehave half half a million you knowobjects to to index can you please indexthem and and by the way I have a demotomorrow right so so what options do youhave right and and and literally some ofthe developers which would reach out tome and say hey any any options anythingto save this situation and you know likeof courseum naively what you can do is that youcan start writing a python or Java youknow concurrent app which will startunpacking this you know data sets youknow reading from S3 or something likethat uh and then vectorizing you hearthe problem that oh you need to use GPUto speed things up and that's quitecostly so we need to kind of likerethink a lot of things and not make amistake if we launch this in batch modeand it will run for two weeks so you goback to your manager and say it's gonnatake two weeks and they're like what andhow much is it five thousand dollars ohmy God so like each time we crawl thedata you're gonna need five thousanddollars in two weeks it's like going outof hand right and soum especially what you what youmentioned in Gina and also there is aframework called txtai which I learnedjust you know by kind of like Googlinginside GitHub if I can say thatso so they have this notion ofum kind of this workflowso for example as you said in Gina youcan doum you you can have an Executor thatwill uh read uh kind of like an archiveand and basically iterate PDF files andthen transform uh parse the textualcontent out of a PDF file and then itproceeds to the next stage rightum and and a txti for example also hasyou know some connectors for other typesof data like in computer vision space orautomatic speech recognition space andso they have different like workflowsthat will help you set things up reallyquickly they have one demo appum on hugging face spaces uh whichessentially what it does is that it goesto Hacker News front page it scrapes youknow the top linksand then it indexes the titles you knowof that top page the top on that frontpage and then it shows shows a searchbox so it basically indexes all thesetitles you know embeds them uh on theFlyum and and and then basically when it'sready you have the search box appearingon the screen and now you're ready toquery it and so it is that easy and theyshow you know how easy it is of courseit's not what you will use in productionsetting most likely you know like inproduction you want to have like aworkflow that routinely goes and checksthat front page you know like a cron Taband then indexes that and you still havethe the index that is serving thequeries so you have some offline indexwhich is being prepared and then you dothe swap you know and things like thatbut they also simplify things likedeploying on kubernetes so you can scalethings up because like literally if youif you write your own python app and oneof the startups by the way there was a abottleneck specifically in thiscomponent that would read the objectsone by one and then it would try toclassify the object and then embed itand then it proceeds to the next stepand it was like I think it was likesingle thread application which wouldkind of like take forever and it wasvery convoluted right because if youdon't have the framework in your handsyou start Reinventing the wheel and somost likely you will kind of cut thecornersand you will be basically wasting timeunless you have a lot of time whichusually is not the case in startups likeyou need to build something reallyquicklyum and so this is this is something thatI think is probablyumyou know hasn't been in the mindsum of the makers maybe like more thethan a year ago but I think it becomesmore and more important that you don'tjust bring the vector search corefunctionality you don't just sell thestatement that hey move to neural searchand all your problems will be solved butyou can actually show the path to getthere right and with these workflowsthat process the data access the dataquicklyum and allow you to do this repeatedlyis going to win more customersyeah and I think um well yeah I'm sorryif maybe I'm slowing it down too muchbut I I think maybe from The Next Stepif we've gotten the data and now we'revectorizing it I kind of want to if wecould talk a little more about thedecisions with vectorizing the data Ithink it's so interesting you mentionedlike a single thread approach whereyou're not taking advantage of likebatching on the GPU or parallelizationon the CPUs and we've recently addedthings like Onyx support for thetextavec um thanks to March and antiswho who got this done and like this kindof model inference for thevectorization's sake also I mentioned onthe vector podcast that I'm reallyexcited about our partnership withneural magic and what they're doing tosparsify these models so they can runsuper fast on CPUsand so I'm and maybe one more referencesin our Levy podcast with Sam bean fromyou.com he describes how they combine uhthe spark Big Data technology with theOnyx acceleration for the CPUs and howthey vectorize that way I know you'vedone a podcast with Max from mighty uhcan you tell me how you're thinkingabout the vectorization layer sorry onemore thing is uh with weeviate I thinkkind of another interesting thing aboutthis is how we have separate Dockercontainers for weviate as well as thesedeep learning model inference containersso you can kind of scale them updifferently with I think things like thekubernetes helm chart and it's a littlemore complicated about that like you canscale them up oh you can just use webacloud service if you know as you say youwant to pay your bills some other way souh can you tell me about how you'rethinking about the vectorization spaceyeah for sure and I thinkum so I think it's kind of like it'sit's great when you describe how youguys build it uh I I take the stancelike of looking at it as an outsider andin some cases I'm basically the themiddle level between you know the thecustomer and and then sort ofparticipating in the decision making andI'm not fully aware of how things areimplemented inside the vector databasefor example but I know that somebody'sgot to pay the bill in the end righteven if even if you use a vector sorry ACloud solution still the bill will comeyour way right and guess what it'seither you or your manager and that willhave to pay it and and also guess whatuh because of the low margins and I justhad a podcast uh with the uh GSI productmanageruh where he says that uh uh you know alot of these things are now on theRaiders of even big players like Amazonuh or any any big player that you thinkis a big player they still might havevery low margin like Google might havevery low margin on their web searchright so it's very important for them tooptimize things and so I think thisarticle in the budget if I can say so isvery important as you build the umum the neural search experienceum and so if you need to pay like as Iwas saying five thousand dollars uh youknow each time uh it's going to beprohibitively high and so it will slowyou down right like eventually you willsay hey maybe we don't evolve you knowas frequently maybe we will just do itonce a half a year and and may also dieout so it's kind of like important toaddress these heads-on and in one of thestartups I actually recommended Marx'swork and so I said hey let's umsupport them can you port the model toto Onyx and basically make it availableas part of Mighty and what Mighty doesis that it basically moves yourcomputation from GPU to CPU at acomparable so the quality is exactlysame you know get the same embeddingsbut you pay less right and the speed ofdoing this on CPU is comparable as wellas it would be on GPUso in that sense maybe you can dedicateGPU cluster more to things like modelfine tuning with matters but to uh butto that production side of things likewhen you compute the embeddings alreadyon the existing model and then how youproductize how you serve things youdon't need gpus necessarily maybe insome edge cases you do uh but then youknow like okay why we do this probablyit pays the the bill and also bringsomething on top so it makes sense to todo this right so so I think this is thisis interesting that I've also learned inthe past year thatumyou know how things kind of get createdright so first you get that hype of newtech like on a big date a few years agoand then comes this realization that ohyeah yeah we do have a lot of data ohsounds like Hadoop is the way to go butthen all this data shuffling or how do Iupload the data into hdfs like you knowand all these connectors arise and likeall of these thingsand then somebody comes over and sayshey no no Hadoop anymore like let's dosomething elseso but but but I think every step inthis in this journey is important youknow if there was no hyper so to say inthe beginning saying like you know likeBob uh one Lloyd was saying I was justin the airport of the circumference withGoogle and I've realized hey there issomething here you know let me buildthis model and maybe it can reasonsemantically about text uh and even ifeven if it wasn't doing 100 perfectly itwas already showing the the way to moveforward right but then all this otheritems which are more like mundaneinfrastructure level and sexy no onetalks about them on sales presentationsso like product level maybe even rightso you don't say this to users hey youknow what I spent five thousand dollarsto embed the items and now you can findthem and you don't do that right it'susually devops people it's usually youknow heads of units that will say heydid we spend five thousand dollars againcan you do something about itum so that you go back and say how whichoptions do I have and so I think then itbecomes important to focus more and moreand I think Max by the way gave anexcellent presentation and he showedalso how he scales so it's not just aDocker image of Mighty that you know youcan send a an object and get anembedding but he also shows how to scaleit out and and basically still save onon on on money and and and and make itefficient in terms of time time so itbecomes like a trade-off of how soon youneed it how much money you have you knowhow much money you can burn on this andthings like that but basically he's isworking on a very efficientimplementation so I can recommend thatyeah it's so interesting I think likeyou could completely abstract it bysending the embeddings to the open AIembeddings API or coheres embeddings APIand there's like that model as a servicemodel on the cloud API thing or thereare these you know do-it-yourselfoptions and I think one thing that Ithink the Frameworks contribute a lot iswith the ease of like dock array embedor you know the Deep set cloud withHaystack and how you can just have yourpython code to embed and then put it inthe database layer so I think I'mskipping over a little bit over thatlittle layer of you have the vectors andnow you need to import them into ev8because I think um you know and I we wehave like a new python client and uhdirt cool wyek is the expert on this andhopefully he'll be back on the podcasthe was on our 1.15 release podcast wecan talk about that but uh passing thatimport layer let's talk aboutum the a n index part and I'm curiouslike how you see the entanglementbetween the A and index and the databasepart like is there a chance that itcould be separated I don't know if weget like the you know hnsw productquantization it's written in golang it'svery like in the core of wevia do youthink these two things could be separatelayers of the pyramid one day yeahthat's also a great question uh and andthe podcast that I mentioned with yeahfrom from GSI is one example where thein an index can become its own entityum because JSI is basically JSI offers aan APU component right so associativeProcessing Unit so think of it as thesameum you know system in in the family ofprocessing units like CPU GPU and it'skind of like next uh stage in a waytargeted specifically atumuh neural search but not only that andand so in principle uh vv8 or likequadrant or Pinecone what have you orelasticsearch could be basically thatcomputation layer so in some sense it'slike a middle layer which receives thedata it knows where the data is it knowseverything about relations betweenobjects and so on but it doesn't need toselect on a certain scale it could alsodo the vector search for you right andso for example using quite efficienthnsw algorithm or uh productquantization or something like thatum and I know that you guys alsoimplemented dknn is that right yeah solike I mean so this is when companieswillconcerned with themselves with the costissue and they say hey for our use caseit seems like you know Ram is way tooexpensive can we actually move closer tothe disk and we have plenty of ssdsthey're cheaper uh and dknn which Ithink is kind of like a a derivativefrom Zoom paper essentially basicallymoves closer to the disk it does thatexpensive uh sorting of uh fullPrecision vectors as the last step buteverything uh before that happens uh onother layers like with lower granularityof vectors and they also solve theproblem in hnswum and again sorry you remarkov but likehe might he might he might disagree forsure but like uh in that paper theyclaim in in this scan and paper theyclaim that thousand nodes in the hnswgraph that they have built wereunreachable from any point from anyentry point and so they have they havefixed this problem so they increase theconnectivity of the graphand so you know this fundamental issuesare being solved and you can then focuson things like okay how do I quantize myvectors uh to what extent and this againis a trade-off betweengranularity and and sort of like laterissues that you will have right so forexample with uh precision and vectorsoverlapping uh to the single point soyou need to disambiguate them in someway and there are ways to do this butit's also may become expensive in somecasesum so so this is interesting that Ithink and this was also one of thequestions on my keynote as well is therea placefor Hardwarecompanies and maybe startups even toappear on this scene of course we knowthat Nvidia and Intel are working onthis they've been competing head Zone onbillion scale and then competitionchallenge last year but also of courseGSI does it and I think yes of coursebuilding a hardware startup today maysound scary but at the same timeI think this could be very interestingto tap into and so maybe in the futurealready today you know like uh there isa connector between elasticsearch opensearch and GSI Hardware so basically theway I think about it is that inelasticsearch you can compute facetsright so you can build I don't knownightly jobs that builds facets and thendisplays them in some dashboard or sendsthem to the usersso all of this computation could happenin elasticsearch but that otherexpensive computation with neural searchCould Happen outside so you don't needto kind of like suffer from the factthat now you need to balance betweenthese two it's fairly expensiveprocesses at scaleuh but you could kind of like uh uhdistribute them you know how we do withvacuum cleaners we charge them and thenthey go around the house and clean rightso they don't use the electricity andyou can use the electricity for someother purpose so exactly the same idea Ithink may may kind of like enter thescene uh at some pointso immediately I thought of just so manythings as you're talking so packed withknowledge I think um well I really wantto kind of understand the Apu a littlemore because I don't quite understand Ithink I think I want to quickly touch onsome other things and we could come backto thatum so I think a very interesting thingis about the incremental nature of the an index in database entanglement the thekey distinction between like vectordatabase and Vector Library amongstother things in my opinion is that youhave to incrementally update the vectorindex compared to like build once andthen you have the static index searchand I think that's I think hnsw isamenable to that but like productquantization making it like online uhbecause what product quantization is isyou have the vectorsand you're clustering them for each ofthe dimensions to reduce the Precisionby representing say 32 bits with insteadthe centroid ID of that index in thevector and then you can like couple itand slide it that way to like have theKings and I know that you understandthat I'm just kind of saying that forthe listenersbut so the kind of incremental thing ishow I see that distinction but um butyeah could we come back to the hardwareand what makes it different I know thatlike Sarah Bross is building this bigchip with the thing of you know we'reyou know like gbt3 is limited I think Ithink 4096 is the token limit at thetime of this and I know it's I wasrecently reading deepmind Sparrow paperand it's fascinating to see thesemassive props like when you see a promptthat's like you know a 1200 token promptyou're like wow that's quite a problemlike this idea of building customHardware to overcome the quadraticattention or I know there's like sparseattention but like generally to havemassive inputs to Transformers so sothat's kind of my frame of reference forunderstanding custom hardware for deeplearning and I think the tpus are asimilar idea where it's like a big GPUso what are the details behind the Apuhow is it optimized for vectorizationyeah that's a great question I think wecan share a couple links on that we'vealso happen to build a demo which wepresented at Berlin passwords last yearso we tookum you know 10 million images and fromLeon data set and we have used clipmodel to vectorize them and then build ademo where you can compare how you knowin image Vector search compares to let'ssay in title Vector search versuscomplete keyword approach right so novectors involved and so we've used Apuas our backend uh you know far back anduh for storing these vectors andactually uh you know Computing uh thenearest neighbor set and so basicallythe way uh Apu looks all sort of like onthe inside is that uh first of all it'sit's kind of like this Paradigm ofcompute and memory so if you take kindof like a traditional server in a waytraditional um where you have a CPU onRAMum when you will run the uh let's sayhnsw algorithm or some other algorithmwhatever it will have to kind of like goback and forth between memory and CPUright because like some things are inmemory that you keep as a state but thenin CPU you still need to do thecomputation right and so you youbasically constantly like change the uhthe context and soum you kind of lose some time uh indoing that uh in in the Apu they theypushed as far ahead as possible to goafter uh massive computation likebasicallyum they do it entirely in memory so theydon't involveum any CPU or any other U units right soum and and and so they have like 48millionum Ram cells so it's highly packed maybewe can provide an image you know likeone one chip that you can insert intothe server and I think you can insert acouple of these toyou should insert a couple of these toscale to 1 billion items right and ifyou have less you can insert maybe oneumand so so basically each of these unitsuh contains like 48 millionum Ram cells and thenand then they have like so they rollroll up to like units that basically dothe programmatic bit logic computationand uh in principle if youumif you quantize the vectors to the bitlevel then basically you are what youneed to do is kind of like bit logicright so like big computation likemultiplications or what have youum as you do the vector search and sobasically like you can sendum let's say 20 queries at at one singletime and you might have one billionitems to check against and they canmassively basically run this parallelcomputation for all 20 queries at thesame time so you will have topre-compute the vector representationfor your vectors but beyond that theywill do this math massive computationand then they will return you resultsfor each of these query vectors and thenyou can do whatever you want on the onthe front end right so for example oneuse case could beyou have stored queries right and youwant to like see what uh new data itemsare going to be hit by these queriesevery single day right so for examplefor financial industry this might bevery important to stay on top of thingswhat's happening do I need to sell mystock or buy stock or do I need to donothing and soum so this basically then becomessuitable not only for similarity searchbut also forimage processing itselfso I think they're using the same unitseven in space in some casesbecause so if you don't have I I don'tknow I'm getting beyond my knowledgehere but like if you have like thiscomplex Hardware uh with like CPU andlike all these magnetic fields involvedlike in space you might get hit by theradiation which like shines directly onthat device and so it melts or whateverbut like if you have less of that so youhave you only have memory you can sealit in certain way and then you don't youdon't need like a cooler maybe even likebecause you don't have the CPU itselfbut of course you do need some cooler Iguess or whatever so I think they'reusing it also in space so it's kind oflike a versatile Tech uh but it's alsonow purposed uh for Vector search and wewill likequite surprised I don't want to likeoversell because I don't work for JSIbut I had the exposure and and kind oflike first-hand experienceum and what surprised me is that it goesto like millisecond level and you haveindexed like 10 million objects so if Iif I was usingum let's say elasticsearch withoutscaling without sharding and indexing 10million objects it wouldn't probably gowith millisecond it would probably Idon't know like it would probably belike tenths of milliseconds or hundredsof milliseconds I'm guessingum it depends on query of course uh butlike here I was like super supersurprised like it was going like I don'tknow 10 milliseconds or something likewhat did it even do anything or maybepre-cache everything but no it didcompute from scratch so that wasinteresting yeah yeah that'smind-blowing and that kind of frontiersof computation thing is so fascinatingreminded me of this the joke we hadwhere when we decided to name weviateair weviate air and Ian goes now wecan't build airplanessending the weevier satellitebut yeah so I think um yeah it's reallyfascinating I think kind of coming outof the approximate nearest neighbor youknow the data structures the vectorcompression such an interesting topic Ifeel like this is kind of the mosttechnical aspect of it in my view so socoming up one layer then we would havesay how you vectorize the queriesgenerally and you mentioned with thecustom Hardware how you could have someparticular way of batching the queriesand you know with the offline query usecase but so coming up maybe one morelayer and this is sort of the part withthe neural search Frameworks or maybeI'm going to get myself in troublebecause I think that this kind of stuffshould live in weviate we have well italready kind of does like we have the Qa Transformers uh Library where you canyou Loosely couple the vector searchwith then passing it to the you knowextractive question answering model wehave summarization and this kind ofthing so how do you see that next levelof the pipeline where you you have theresearch results and now you want toprocess the search results a little moreso you you might well I guess maybe oneother little thing I'm not a littlething that I missed was the in thecombination of vector search withsymbolic filters and you know as aminute with how that would work with thea n index but so just as a note of forthe completeness of the coverage but sonow we have the results and we want toprocess them with maybe questionanswering summarization uh and and andwe'll kind of if we could start fromthere and then talk about other thingswe could do yeah actually maybe I cantake a step backum Iuh it knew when I was working on thisblog post about neural search Frameworksuh it took me several months because Ididn't see the picture coming togetheryetum when I when I got the idea ofpublishing this and and just to giveexamples Beyond Gina and umHaystack you also haveum managed neural Frameworks likeVictoraalso relevance AIum but but and Muse but I also includedhabiaum so and and like this is where I myyou know my my head was blown away likeI was like hold on a second like so wemove we basically if we are looking atthe vector search pyramid uh as we stepas we take a stepum you know upwards basically we aremoving closer to the user right sobecause we we don't concern ourselvesanymore we kind of like assume that nand layer is solved to an extent we canfine tune it but it's solved Vectorsearch database is solved because itexists and I can pick a variety of themum so what what is unsolved right so whydo we need another layer like why can'tI just like you know sit down and haveall these components in my hands andkind of use it as a Lego building blocksand come up with my app in principle Icould right I could take vd8 I couldtake quadrant whatever and I could thenbuild everything and vb8 offers a lot ofthese opportunities like um as you saidlike for vectorization inside thedatabase so I don't even need to worryabout that part rightum and then you have these componentsfor summarization and things like thatand things of course blend uh now thatwe move to neural search frameworklevelum but it still was very logical if youlook at if you take a look at the blogyou will see each cardum you know for each of these neuralFrameworks will have a specific fieldsaying does it use any existing Vectordatabaseand if not what is being used if it'skind of publicly available and so if youlook at for example GinaJune is using uh vv8 quadrantelasticsearch and radius using as in you canchoose one of them right depending onyour settingHaystack kind of the same but they alsooffer an opportunity to implementdirectly with files and coming back toyour earlier Point why you need tochoosea vector database overum and an algorithm is because NNalgorithm might not support the symbolicfilters right so like if you take H ands w libum you know of the Shelf it won'tsupport the symbolic filters right andthe same goes to files it doesn'tsupport symbolic filters so it meansthat you will have to have some externaldatabase maybe SQL databasewhere you will have to do this postprocessing step so after retrieving thenearest Neighbors From the somaticperspective nearest to your query nowyou need to pause filter them you knowusing the metadata filters but that canactually kill the whole list right soyou will have to either over queryand then hope that after post filteringsome items will remain or you'll have torepeat it several times as effectivelydelaying the response to the user rightso you don't want to do that so like youknow databases like vv8 quadrant and soon have the support to do this in placeright in the same stage as they saidyeah so I think this is important rightyeah and that that actually did changemy perspective a bit because I'm I couldsee like with the with the doc arrayhaving a connection to like a graphdatabase separately from wevia where youaggregate the things and then those gointo the re-ranking layer the questionanswering layer and yes I can see that Ithink but then coming back to our notworry about too much and just your corevalue if if we can offer that kind oflike how hybrid search is now in weviaand you can have the keyword search andthe vector search and that kind of flowinto your ranking thing that is veryinteresting um so kind of one emergingthing with the neural search Frameworksand it comes back to this idea oflooking at different indexes a graphdatabase a vector index uh maybe theface static and maybe you have someapplication where your data doesn'tchange and so then the face index makesa ton of sense so so you so there arethese new things called Lang chain wherethe idea is it's uh the search frameworkis around something the the chat you Ithink I like to say Chad gbt instead ofgbt3 because gbt3 is impressive but atgbt is super impressive so maybe wecould call it gbt 3.5 or or four orwhatever but like so basically the ideais it's like the orchestration layerwhere you tell the language model uh solike one way of doing it is this Chainof Thought prompting where uh you youget the few shot examples are showingyou how to like decompose questions suchas to like illuminate thecompositionality like if you're askingumuh did uh Thomas Edison use a laptopso you you'd want to break the questiondown first to like okay when did ThomasEdison live when were laptops inventedand then you've taken the two facts soit's like this layer on top that tellsthe language model like here are thedifferent data sources you have accessto uh so what do you think about thatkind of like how how does chat gbttechnology will influence uh the neuralsearch Frameworks and then I and thenafter that I want to get into like thegeneralization to images audio G likeGene maybe like other kinds of datatypes but I think maybe just stickingwith text would be a good way to sort ofset the stage for this yeah for sureum and I wanted to still blend also withum kind of like what the value prop isin this neural Frameworks and and maybeas a segue to chat GPT how Chad GPDcould change things so like if we takethe example ofum Haystackum so for example what they allow you todo is that query comes in you can have anode and and the way they model this isthey have a dag type of thing right sothey have a directed The cyclic graphand so they the query gets classifiedlet's say with a query classifier that'sone node and then after this query isclassified it can depending on the classthat is predicted it can either go todense retriever or it can go to akeyword retriever right let's say maybeit's based on length or some otherfeatures that you know work so you youhave a boundary in your classifier andand then but maybe in some cases even itcould go to both of theseand then you will have a further nodethat will read the results from thisretrievers and will merge them and thenpresent them in some way uh using Idon't know RF method or some reciprocalrank Fusion or some other method so andyou can like play with this you can youhave you can have like different nodesdo different things likeum OneNote could be if you classifiedthe query as a question you could do aquestion answering but if it was like atable uh related like SQL table so youclassified it as a SQLcompatible query so you could go to thatnode and say hey can you also query thetableum you can also do like documentsimilarities new documents come in so itdoesn't need always to bethat doesn't always need to be like onthe retriever side it could be as partof your backend pipeline uh somewherewhere you need to do document similarityand then decide whether or not to evencompute an embedding for this documentmaybe it didn't change or maybe itdidn't change enough to Warrant a newembedding and so you might discard itand so on but you also have these othernotes which we talked about earlierabout document extraction process so youextract things and you know proceed toto the embedding layer coming back toyour question about chat GPTum I I had an exposure to it of course II actually uh well asked it can you namemy blog post because I was still stuckthere and and I grounded it and I saidhey I wrote another blog post aboutVector databases and this is how it wascalled not all Vector databases that maytake well maybe you can play on thosewords or something but it decided not touse the same sort of words and just gaveme neural search Frameworks I had to hadcomparison I was like oh boom coollike you cannot imagine like you can dothe work and then it leads up to theposting and you're like how should Iname it when you go to your friends yourwife and they'll how should I name myblog post like how do I knowso in this like really strangesituations you can reach out tosystems like chat dpd like if I went onuh tactical or being a Google orsomething and I asked the same questionI probably wouldn't get an answer Iwould get a bunch of links and like whatshould I do with these things likeso this is this distracts me more thanit gives me value but in chat GPD I gotan instant answer and I was like I likeit I spent maybe five minutes thinkingabout it and I liked it and I slapped iton the on the title that was fine soso I think in some sense maybe to methis wasn't even a search experience uhin this kind of basic definition or sortof uh the way we used to it uhdefinition that okay I I need to typesomething and then I need to examinelinks or examine some output go checkthe results and then decide myself likeam I satisfied or not uh in chat Deputyyou don't have any URLs coming back toyou not yet at least maybe they will beadded who knows but like today it's morelike a companion that you can talk toand in some sense I was dreaming of sucha companion maybe you know when youstudyyou have all these books and papers andeverything but can you really quicklymake sense of oh can you can you likefind an answer to that specific you knownagging question like you you had duringthe lecture uh it's super hard right soyou of course you can go to searchengine and start typing all thesequeries but here you can have like umkind of like a sensible discussion in away of course I know some people uh evenlike hysterically are laughing at theresults and so on and so forth so maybeit's not uh purposed for all situationsand also for all audiences it wasactually a discovery for me uh there wasone linguist uh that I was followinghe said thatum he cannot use General web searchengines because every time he typessomething they don't understand what hethey don't have the data it's not it'snot even about understanding they don'thave the data and so he needs to go tolibraries and like read books that arenot indexed in this search engines andthings like that so for this veryspecific Niche use cases Maybeuh chat GPT might not work it depends onthe data againum but I think it was surprisinglyclever right if I can say so about AIumuh it wasn'talways static and you you explained itwell that it takes different paths inthe tree when it computes the answerum and and the other question I askedlike can you find a bug in this codethat I wrote and it just licks memory atsome point and it gave some sensiblesuggestions and and I felt like I knowthat it's kind of like a silicon therebut like I cannot maybe like yeahum like I I still need to examine somecaution and sort of not fully trustum maybe for Life sensitive situationsor something like that you know ormedicine or insurance or something likethat but like things that I know it hasindexed and and and humans have writtenthatyou know and and and and it has beensort of vetted multiple times and soalso uploaded a bunch of times on stackOverflow if you were talking aboutcoding and so there are some there issome evidence that this might be theanswer but but I think it was stillsurprising that how it changes theperception of search even if we can talkabout search in this casethat it it actually generates the answeryou know search engines don't generateanswers today like Beyond maybe okayyou.com and Google the youtube.com Ithink is more advanced in this but likeGoogle has this Snippets you know whereit says you know probably the answer isthisum and so they commingle it with URLs uhbut like in charge GPD you don't haveany URLs it just talks to you and thenyou can continue the discussion I don'tknow it was fascinating but I stilldon't know ifif this will make it into thenecessarily search experience like so insearch I I think it's very functionalyou know if I walk down the street and Isee something on uh like on the shopwindow I take a picture and I say I wantthisum and so it finds by the imageum so that that is still a searchexperience for me so in some sense maybein the future you know we will havecontrol F on everything in the worldright so like as I walk everywhereum I can kind of mentally press thatCtrl F maybe in some device maybe on topof me or like a glasses or something Idon't know uh VRuh but like today a lot of places missthis and and still there are a lot ofcontexts and situations when you askyourself what is this do I know this youknow and you have some other like uhsubsequent questions but there is no waytoask them because you don't like you canpull up the phone and start typing andit's freezing weather and you're like ohmy Godit's like not it's kind of like adeteriorating experience but I think itcould be so much moreuminteractive and multi-modal and I thinkneural search especiallyenables multimodality situations rightand experiences so that you can actuallylike not constrain yourself to to thepoint that am I uh asking like a textualquery or I just have a query I havesomething on my mind right or maybe Isaw something can you tell me more aboutitum so I think I think maybe chat GPTmight push us in that direction that notonly it will find things but it willalso reason about things and help youreason but but the creativity partI don't think it will it will disappearI I don't think at least not now I don'tI don't see how AI can solve creativitypart like create things for you yeah itdid create the titleum you know but but maybe a morecreative person than me could actuallycreate a better title right and thingslike that so yeahit yeah there's a lot that I want tounpack and I I do think this thecreativity is kind of like acharacteristic of compositionalgeneralization and novel I suppose but II want to just kind of tell you aboutone other idea that relates to how youhad chat gbt uh come up with the titlefor your blog post and so I want tocredit uh Bob Van light and Jerry Liuthe creator of gbt index they includedme on this call where uh they were youknow hashing out their understanding ofthe gbt index top level indexing and Ijust think this idea is so profound onhow we use chat gbt and it's the idea ofwhen we search and we get like 15results as you mentioned we need to likeparse through the result and so like onethinking was like how about we use aCrossing like a high capacity crossencoder which is like going to beanother like let's say it'd be likemaybe like an 80 million parameterTransformer they there are papers wherethey use like big T5 models like billionparameter T5 models to re Rank andthere's like this paper where you havethe density on yes or like query andthen you put the query document documentand then yes no and you re-rank withthat and you use high capacity modelssimilar log prop that kind of idea butso this idea of like how do we parsethrough a bunch of results and thenanother idea was like okay well maybe weuse a question answering model and we'llre-rank it based on the confidence ofthe extractive question answering modeland we'll try to calibrate the questionnow answering models to to demonstrateuncertainty maybe Bayesian networkssomething like that but this new idea ofhaving gbt summarize the results byhaving the original question and thensaying please summarize these resultsyou'll receive it one by one and then itreceives it one by one updates a summarymaybe as you mentioned like you wouldwant to have the reference it couldmaybe say like oh and also please likeyou know keep a cue of the mostinfluential uh results as you've beenparsing through it and it's like abilityto reason and do this I've been playingaround with this a little bit I think isjust super profound and that so thatkind of summarization across resultswhat do you think of that idea because Ijust am mind blown by it yeah this isamazingum I'm not as deep in this topic yet butI just understand surface of itlistening to what you just explained youknow there is still this trust componentas well that and again this trust isjust how we perceive it it was designedthat way and we think this is thetrustworthy way to uh that theinformation that I'm getting so if I getthe URL from the search engine I canclick and then see it with my own eyesand see when it was published by whomand maybe I can even reach out to thatperson and ask some questionsum so if I have not provided with thisinformation and evidence how do I knowthat this is true right so um or maybedoes it even apply to my specificsituation uh maybe it gave me way toogeneric answer and so I thinkumit would be interesting to see if if Ihave a list of people that I follow onTwitter let's say and I trust them onspecific topic you know let's say theway I trust how you Corner publish youknow thinks about specific papers orsome breakthroughs and recentimplementation in Vector search spaceum so when I have a specific questionmaybe I could say hey let me first checkwhat corner thinks about this right soif chat GPT could kind of like bias theanswer and include some of the hintsfrom youfrom your timeline not not from yourtimeline but from the things that youpublished on Twitterum on that specific topicum and then include that as asupplementary material or maybe like achapter sort of you know I mean theanswer so I canI don't need toum you know go and check Twitter now I Ican actually go directly to theinformation rightum and I can read itum and then if I have a question maybeif I reach out to you I might ask a veryspecific question rather thansaying saying like can you point me to apaper you knowum in this topic soso I thinkI thinkum maybe Chad DPT made that firstimportant stepit created also a lot of likemaybe controversy or some people uh Iremember like one case on on stacker umon uh Hacker News was uh so this guy isparking his car in in wrong I guess inthe wrong lot so like in the wrong spotin the in the parking lot and then hegets a fine uh and then he's like out ofoptions and he's thinking okay what ifChad GPT can help me here and so heasked Chen TPT to write an email to thisofficial uh you know saying oh yeah Iput on my app and I paid for it butapparently I I put my car in the wrongum you know slot and a spot and so andso it was like like it's you know likehow in certain cases certain situationslike we when we zoom in on a situationand we're a little bit like stressed welose words and phrasesand that's probably why psychologistsand Consultants exist because you runtowards them and you say hey I have aproblemcalm down you know what happened thatthey will help you to walk through thesituation and then they will say saylike this you know dear officialwhatever I happen to park my car in thewrong spot I understand this is a bigmistake uh however I paid for it in myapp here is the receipt do you think andthenit's like the computers they don'tum I think this is also a good thinglike to some people it's bad thing andit can beum I guess developed towards that theydon't feel that I have a lot of emotionsright they may pretend to have emotionslike in ex machina movie right but likebut I thinkumthey are very calm and like okay yourproblem is this you know like SheldonCooper okay here is the answer and andsometimes it may help you and actuallyin that case the official came back andsaid yeah I understood the situationhappens sometimes you know I will justissue a warning this time you don't needto pay fine and you are good don't do itnext time that's fine right so probablyI got carried away a bit but but I thinkbut I think that coming back to yourquestion like if I canif I know that there is a veryinterestingbook or blog postand it's in my browser history it'saccessible and I can give access to ituh to chat GPT it can go and personalizeto my interest however biased it is Idon't care maybe I do want to be biasedI don't want a randomblog post published somewhere well youcan add it if you want but still can youbias to what I have read and I havealready forgotten you know in severaldecades that I leave I've forgotten theyread the book can you remind me of thatuh snow yeah I think there is a way totake chat GPT to the next level in interms of personalizing the answersyeah and I think well personalizing theanswers I think it comes well coming toour other podcast where we talked aboutref to VEC and the personalizationvector and how that can filter thesearch results and then those are theresults that go into chat gbc's contextbut I think the other thing you'resaying one I think like this promptingis so interesting like one thing I'veplayed with is write a write an argumentbetween Ilya sutzka CEO of or I don'tknow what his job title is it open AIbut I write an argument between Ilyasatsgiver and Clement de lang fromhugging face about closed versus opensource models right like you promptedlike that you give it like a backgroundabout each of them and the argument andI think also what you say about politewriting like one of my favorite ways touse chat gbt is I'm writing something Igive it a sentence and I say could yousuggest seven writings of this and it'sfunny you mentioned that it's justsilicon because sometimes I'm like I'mlike oh seven that's kind of a tall taskmaybe just threeI think that kind of comes into alsolike when it's no longer free it mightchange how we use it a little bit toolike like the way I use the GPS 23 APII'm like well I'm paying for the tokensgenerated so let me not prompted to givesome long generation but so I think thishas been a great coverage of Chad gbtand continuing on the pyramid I kind ofwant to hit what I see at the top levelwhich is just the user interface likethe you know like someone with CSSskills how they contribute and how theyfit into this and I've I've seen uh likeGina now uh you know I know we have somestuff that's not out yet but like onthis kind of the search interface and Iknow like usually you know you just havelike a search box right like it's justthe bar is like kind of the interfacebut say you're doing like image searchand you want to like click on the imagesyou want to fuse that with the searchbox and I don't know do you see like alot of in I know like you.comand it kind of comes into what you'resaying with how you have the evidence aswell like you.com they have thisinterface where they split the searchresults and then the chat gbt like thisinterface do you think there'sopportunity for Innovation at that layeryeah uh I think one one part isinnovation and another thing that I'vebeen thinking about is let's say thereis a existing player and they have asearch engine let's recommendrecommender system or something andthey're thinking okay can weexperiment with Vector search but we areprobably not like hundred percent sureyet is it going to fly or you know canwe expose it only to sort of like thepower users in some sense uh I thinkgenome had this kind of like um earlystage Demos in some sense early stagesin maybe you don't go with this in intoproduction but it helps you to reasonaboutum and and testum what's more important I thinkum the influence of neural search onyourum you know search engine experience sothey had um I think they had this searchengine where like a demo where you typea queryum and then you have this slider I guessso you can sayyou know have more weight put moreweight on keyword results and then youslowly blend this into the neural searchand then and then you can choose likeokay it's going to search directly inthe images let's say using clip modelum but still combine the results sostill ask the keyword Retriever and thencombine the results from the danceretriever from the clip model and sortof like show me where these results landright so if because for some queries itdoesn't make sense to check the imagebecauseit's succinct enoughand it looks like it's going to match aspecific metadata you know item filteror maybe title of that object so thereis no reason really to go and examinethe image because it doesn't containthis information and vice versa 2 likein some cases when I sayI don't know like can you give me apicture of a bear eating a fish in thebeaver you know and there is no suchstyle because you do have an image of avaries in the fish in the river andyou're like yeah maybe if the model andwe have done this in the clip searchenginedemo that essentiallyit it surprises you blows your mind thatthe clip model canum summarize its understanding so to sayto this level that it will matchanything you type like that so you say abear and it understands what the bear isit's not an author and things like thatright so this is very interesting ofcourse it goes back to you knowcontrastive learning and people haveenough negative examples which aresemantically negative and not justrandom negative examples and things likethat but they also uh came across Iwonder if I can pull it upumbut when I published this blog postabout neuralum searchFrameworksumuh I came across uh this company calledNuclear So I didn't didn't yet includethem in the blog post I need to studythis a little more but there was someinteresting thing that they offerum a way to compose the UI as well rightso it's not only this is coming back toyour question you know can we uh sort ofmake some break breaks throughs there ofcourse if it's an established playerthey have the dedicated front-end teamthey will probably figure out what theywant to do and they have an existingproduct but if you are on the verge ofexperimenting right so you're stillthere you you have your your like mindopenin many ways you you don't know what UIwill be in the end they offer Beyond youknowum a database font structured data theyalso offer you a number of components onthe front-end side so you can basicallycompose the UI the way you wantum and I think like you.com I think youmentioned also experiments with chat GPTlike answers right so not only the URLsbut also kind of like an answer which ismore interactive and maybe you cancontinue the discussion there in thatboxum I also want to like give an examplewhich which was like pre-neural searchera in many ways at Alpha sense likelike when I look at document searchengines you know let's say it's anarticle search engine or patent searchengine uh usually you will have like umseveral stages as you go through the UIas a workflow so first you need to typethe query then the screen changes to thelist of documents sorted in some waythen you click on the document again thescreen changes and it opens the documentright what alphasense did really reallyearly on like2010was to have what we called a three paneUI so you have like you have a searchbox box at the topuh you type the query press enter youget a vertical uhcolumn you know a column with theresultsnot too narrow you can still figure outwhat is what you can read titlesyou click on that it gets the snippetpane so you can actually quickly gatherokay is this relevant to me or not soyou have like several stages but it'sall on the same screen almost like anAmazon checkout page right kind of andthen as you click on the snippet itpulls up the document however big it ismaybe let's say PDF document thousandPages it will load only the necessarychunk of that document and it will jumpfrom that clicked snippet to therelevant section of the document so nowyou basically have all these you knowtools in the same view and I thinkthis is very powerful becauseit saves a ton of time you know becauseyou you need to always kind of walk thein the shoes of the user what does theuser want to achieve with your not withyour product they hire your product uhto get some job done right and so isyour UI efficient enough uh in in in uhyou know in satisfying that specific uhrequest and so so I think this was veryinteresting and then some competitorstried not only tried but copied you knowthis this View and and then the historygoes on but but but I think this was avery interesting breakthrough even likebefore uh neural search but with neuralsearcha lot more doors open becauseand also it bringsthat complexity layer that now productmanagers engineersgotta simplify so like you need tosimplify the complex alwaysbecause users will not have timeto figure out really complicateddesigns or uis however flashy flashyyour UI is if it's not functionalit's going it's not going to fly so youneed to kind of like simplify thecomplex and now these open doors withmulti-modality right so like all of asudden your query can go directly intoinside the image now it pulls up theimage you need to explain to the you youcannot highlight like a snippet insidethe image right and say hey there is anarrow here that's the bear you will youare asking forso like inside the patent like in patentsearchI spent some time uh I was part of theboard in one big Enterprise basicallyexamining the patent to be the patentapplications and a big chunk of work fora patent presenter would go intoexamining the prior art and so they needto examine a ton of patents and figureout whether or not they overlap withthat specific button or not right and sothis means thatthe searchthe search workflow changes from get mesomething on the screen and I'll decideif it's good enough to can you give meeverything there is on this topic soit's like a long long search youpaginate like how until like 200 page200 or something and you gotta have like100 results on the per page or somethinglike that so they spend like daysexamining just one query and then youcould go back and say oh my query ismissing this term you know let me changemy query boom I have again the new listof results and now it would be cool ifthe systemshowed me the difference right and thiswas another feature we had at Alphasense you know as new documents come inlet's say you have auh let's say if it's a public companyand they publish uh a 10K report whichis like a yearly SEC filingum it might include portions of aquarterly report from a quarter priorand so and also like that 10K which waspublished a year ago they don't actuallyrewrite it they just change some numbersright you know like performance our TopLine whatever so like you don't want toreread 700 Pages again to learn hassomething change with this guy you justwant to see oh the Top Line changed andalsoyou know they spend a lot more onproduction of that sort and like okaynow I need to go back to my Excel andinput these numbers and see what happensto the stock price prediction right so Imean always think I don't know if Ianswer your question well enough butlike always like forget about Vectorsearch forget about learning to rank youknow however sexy those are and thoseare super cool I mean I'm excited myselfalways go back to what user wants rightlike if they're driving to thatdestination as we compute in TomTomalways remember I'm sitting in the carit's freezing it's dark I want to getthereso so show me that top result as soon aspossibleso I don't need to type that long youknow uh sitting in that freezing bed orwhatever so so it's not I think it's agood exercise to always kind of go backand maybe talk to the users as wellum in some cases it's Momuh maybe complex but I think still thatpipeline could be established and youcan start asking questions okaywhat are you trying to find what is yournormal sort of workflow and use casewhat are you trying to optimize forand they will give you very interestingsometimes confusing answers maybe so youcan drill in and find a sort of a moredetailed version of what they wanted tosayum but then it comes to it rolls up tothis bigger picture ah I got it uh weare just missing one button heresomething like that and thenyeah yeahum Barbara taught me about this jobs tobe done framework for thinking aboutthis and and I think at the use and thejobs to be done it's like this businessschool thing about like why did you hirethe donut to do the job of uh somethingto eat on the way to work I think theuser interface layer you think the mostabout the job being done so I think thatwas a great and yeah the job to be donehas cascading effects to the wholepyramid and the different requirementsall the way down I think this is a greatuh summary of the pyramid and then atransition into a really fun topic towrap up with which is um this idea ofrenaming Vector search to mayberelevance application yeahyeah no I actually wanted to pick yourbrain on that because I know you themoment I posted uh that podcastand if you have uh responded and thatwas like a long answer and I was like ohI got Connor and he's like reallypassionate about this topic I think thisis important like I I will I will tellthis disclaimerit's not my idea butI like to throw in some thoughts whichare of higher levelum and maybe the goal is to not changethe course of the industry but more likein form and give another perspective andI think this perspective came from DougTurnbull on on one of the episodes inone of the episodes of vector podcastwhere he said if I was to give an advicetoday to the vector search engines tothe vector databases I would say stopcalling yourself a vector database andit was like a cold shower already likestop calling yourself a vector databaseand call ourselves what and whybut he spent a lot of time in searchright he wrote the book relevant searchas well corrodedum and he's uh co-writing AI poweredsearch as well and sohe said well think aboutthe nutshell of what you're buildingright it's like whatum new area you are discovering right onone hand we are all building orparticipating in the construction sortof like rise of new industry but in theend of the day it either solves ordoesn't solve some use case or plethoraof use cases right so we claim thatwe are moving to semantic search levelright something that didn't happenbefore something that was hard toachieve andyou know maybe with custom synonyms uhsynonym tables or with bootstrappinganother Shard to handle that languagenow we have multilingual models so theyhandlemultiple languages and the samerepresentation and so it's the sameshared geometric space which is kind oflike super cool like enhance I can askmymy question in one language and get itsearched in another language then youstill need to deal with the answers likedo I need to translate them back to thesource language or something but that'sanother storyumand so so he claimed or he kind of likesuggested thatin a way we aresolving towards uh relevancy and so hesaid why don't you call yourself arelevance oriented application and hewasn'tstubborn on that specific term or likethat specific phrase but I guess the keyword for me that stood out its relevanceright becauseand then I I also weared my hat of aproduct manager and thought okay if I goto my boss at Tom Tom and I say heylet'sum bring this semantics into the mix andguess what we need a back to database solet's let's acquire back today basedlicense or something I think the firstquestion would be what the heck is avector database it's like vector clocksI used to have some quarries orsomething no I'm just I'm just I'm justjoking here but I'm saying that you knowor likeit becomes like this kind of uhuh engineering uh lingoum or like they say Greek right so speakEnglishI don't understand you and so then yousay oh you know Vector databases it'slike a new breed of databasesum it's like the next stage Sequel andit's like sequel wait a sec let's justforget all this it's it'sum it's basically like moving everythingusing deep learning moving everything todeep learning okay uh hold onum so semantics you get the wordsemantics right so like we move tosemantic uh level searching and um bythe way we can ask natural languagequestions now oh natural languagequestions what is that so it's like welljust just normal questions instead oftyping keywords you can basically yousee what I'm doing I'm basically likestepping back and back and back and I'mkind of like degrading the terminologyfromoh this is like a super cool aircraft uhyou know and I've used all thesematerials to build it all these glowingbuttons like what can it do it can flyyou to Mars Mars I don't I don't want togo too muchthis is what I'm saying like like stepback as far as possible back and sayyou know remember we have this problemin in in TomTom sometimes people askquestions so they say can you drive meto a lake or something so it's like theydon't type like an address because theydon't know the address of the lake likedoesn't have an address maybe it has thecoordinates and so we have certainpercent of these queries and maybe wecan tackle them with this new tag thenyou can maybe say Vector databases arethe new breed of databases but likeyeah I guess when you when you enter adiscussion withon a prepared customeruh you might not start maybe it's not agood idea to start with Vector databasessome technical term insteadyou knowtalk about semantics or relevance orsomething like of that sortyeah let me see if I can do uh can youdrive me to the lakeI think maybe let's see if that examplecan show the different intents that thatcould entail so so maybe you would wantit to be asking it like are you capableof this task and it would say like yes Icould show you how to drive to the lakemaybe maybe it would find anotherquestion where someone else had askedsomething like that or you know what youwant probably is like the Google Mapsdirections current location to thenearest lakelike so I've been seeing this likeintent ranking papers like task awareretrieval with instructions and theinstructor model where uh yeah likethere's different intents for differentsearch tasks like so with core Iduplicate question detection like theacademic data set you're looking foranother question not the answer to thequestion and and so it's I don't knowtoo many k like it's kind of like theidea where you encode The Domain in thetask like you say search me a paragraphin scientific literature compared toin Reddit like it could have like findme a you could say like find me aconversation on Reddit which is adifferent intent than um find me theanswer from Wikipedia is this helpingwhen I'm like this kind of so I don'tso that's kind of how I'm thinking aboutit I mean I still thinkI I still think the vector searchdatabase I like that so much because itkind of comes all the way back to thepyramid where it's like this coupling ofthe a n and then the database stuff andjust maybe it's particularly how it'sdone in weeviate but that those two areso tightly coupled sort of I see it asthat that's sort of like what I see asthe novelty but yeah it's reallyfascinating I think relevance podcastswelcome to season three of the welcomeuh relevance podcast yeahactually I was I was I was surprised ormaybeum it confirms the bias in a way thatwhen I was writing this blog post aboutneural search Frameworks one of theplayers is called relevance Aiand when I was talking to Daniel vasilevwho is the CEO of this company andco-founderum he was advising me to even stop usingthe word vector and embedding and I waslike what do you mean and he was sayingwell you know our user baseand our Target user base is notnecessarily Engineers it's notnecessarily deep learning researchersit's umanybody it's uh someone working in HRand they have a bunch of CVS and I guessthey want to like take a look at themfrom a different angle quickly find acandidatemaybe plot some characteristics you knowquickly cluster them things like thatand so and so they don'tum they don't uh you know so theprogression of thought is not like thisI have a bunch of CVSand then based on the embeddings I willcompute the Clusters and then I will runVector search no they don't even knowwhat these things are they go onrelevance AI platformthey uploadCV so they point to some archival likeCloud URL and then the system pulls themdown and basically extracts all of thesethings that we described in this in thisepisode you know the workflows it doesit behind the scenes so you don't needto worry about it and then it embeds theuh the documents and then it basicallygives you the search prompt so you cansearch them right so so they they targetI guess a completely differentum user base right so like if you if youif you contrast that for example whatHaystack is doingand I was also talking with Malta a lotas I was prepping the blog postum he was saying that this is kind oflike a development kind of like an IDEin a way right so like um deep set cloudis kind of like an ID for integrateddevelopment environment forum an engineer or researcher or maybeboth of them collaborating and they caneven chat so you can find references ofthe discussion that happened earlier andlike go through that and things likethat and make decisions together andthen plot metrics so it's a differentit's a different like user base rightlikethe target user ideal user is somebodywholike understands coding andunderstands the concerns of scaling andcost management and whatnot and so theyare much closer to the actual uhplatform creation rightso but like if you took like someonereached out recently to me on LinkedInuh in product management capacity andthey said yeah we know that youpublished all of this but can you giveus like a couple blog postsum or maybe a podcast which introducesus to this space so I I don't think Iwill send them like HaystackURL right like because it will be waytoo technical for them and and hashtaghas like excellent documentation butit's purposed toengineers and researchers in a way rightand then of course there is and andthere is a product for every of theseumchoice or sort of business model rightso like a product to be created so forin in the case of haystack they havedeep set Cloud so you can basicallysubscribe pay for it and don't need tohost and like worry about how I scale ifsomething breaks whatever right samewith vb8 you know you guys have a cloudas well and things like thatumso so I guess to wrap up this thought isthat it kind of like depends onwhat your ideal Target user is rightum and alsowhatumuse cases you have uh tested your Techwith you know thatanother use case like this we know howto how to work through it and so that'swhy in each card in the blog post youwill also find use casesum list right and and I tried toFocus not on if I could not only on sortof tech level or kind of like algorithmlevel thing but actually specifically onthe end user facing use case for examplein the case of haystack they have youknow document information extraction butthey also haveumyou know getting Revenue numbers from afinancial report this sounds more like aspecific use case now right or likereason for a legal claimso it's not it's not it's not like umokay I have this neural networkhow do I plug in that into quadrant ofV8 Pinecone rightumis there a plug-in architecture that Ican Implement you know what I mean likeso it's it's a different level ofabstraction and it's a different levelof discussion as well and so so I thinkwhen DougI believekind of like deciphering his thoughtprocess was to kind of stop talking onlymaybe only about techand and by the way I love Vectordatabase myself that termmy podcast is Vector podcast many peoplethink it's about Vector search but it'snot only Vector search it's it's like Iin the in the about uh on YouTube Iactually write that it's like a vectoras in what Vector you have in yourprofession and life in a waybut many people come back and sayit's metric on the creator of vectorsearch podcastum it's not Vector search but it's justVector podcast but but but that's okayyeahVector podcast very cool so I guess towrap up again uh really close on oftenthis thatumso first of all a it's it's about theniche it's it's the not the niche butthe sort of your ideal user that you'regoing after at Bthink about are you limiting yourselfunnecessarilyin the way of sort ofhow many users what type of user youcould reach with yourum with your system with your enginebecause you said for example bb8 code inprinciple eat away some functionalityfrom neural search Frameworks so it kindof like begins to occupy these twolayers and this Vector search pyramidrightum or Bland them and that's why andthat's fine but like is it is itlimiting to limiting to say that it'sonly a database and it's only a vectordatabase maybe it's more than that rightso that's just a couple thoughts thereyeah it's really enlightening and I wantto give credit to Sebastian Whitlock andthe devrel team at weviate that'shelping me think like this like um Iguess like me personally I have abackground in like doing academicresearch in the PHD and you know readingmachine learning papers and thinkingvery along the lines of like vectorsearch database makes a ton of senseright well like um like I think oneexample is um Erica Cardenas on the webateam also she created a like a dog imagesearch demo and so it's like there couldthere are like layers to how you want topresent this you could it could be likejust point us to a folder with images init right that was like the the mostsimple thing to do or it could be likeokay well we're gonna actually encodethis into a base64 encoding we're gonnause a resnet we're going to use therezna 18 is you know probably don't needthe 32.so it's like how much detail do you wantto cover and I think it's superinteresting and and like bycommunicating dating that way you'llunlock the like creativity of the peoplewho are thinking it at the higherapplication layer and you know payingthe bills the other way is good becauseI wonder how many times we've said thatphrase in the hour and a halfyeah yes it's like decision makers rightsometimes yousometimes it actually is going theopposite way it's likeumyou may spare some time as an engineeror researcheruh test some algorithm show resultsimpress yourself impress your colleaguesand then this rumor will travelto the level of product managementdecision making above product managementas well and they will say wow this issuper coolcan we release this to prod now rightum does it happen frequently I don'tknow it depends on the company I guessit depends on the culture and I guess wecould also spend some time talking atsome point you know how companies arestructured and how you have this I thinkit's Conway law right so thatumyour product is a result of how you haveuh organized people in the companybecause they will have like teams silosmaybe at some point even and some teamsmight not be talking to each other asmuch as you think they could and so yourproduct will be a product architecturewill be a result of this informationarchitecture which is also veryinterestingum but for startups it's probably notthe problem for startups you can talk toanybody anytimeright but you still need to get job doneso that's that's also anotherperspectiveumso yeah I mean this is very interestingtopic and in generaluma lot of angles to take and if youalways like remember whom are youtalking to and and just to wrap up onthe thought like if the if theBreakthrough doesn't happen from theengineering levelcan it happen let's say and productmanagement levelbecause you have resonated with how theythink and you know what type of issuesthey're trying to solveand you have stepped back from thetechnical terminology and you startedtalking the lingo and they said here iswhat Vector search actually isthen they willgo back to the the drawing board and sayah this is what it enables us to do andnow we can search inside the images wowyeahyeah well amazing I think this was anamazing podcast beginning from talkingabout the opportunity cost of bad searchin retail and then digging it into okayso you're building a neural searchframework there's all these componentsto it your famous pyramid diagram andwalking through every step in detailthen coming to thoughts on chat gbtyeah and I think just the user interfacethe job is to be done this whole thingand the renaming of vector search hasbeen such an incredible podcast uhDimitri thank you so much for your timecoming on the weba podcast and thanksalso so much for hosting me on thevector podcast I'm such a fan of thevector podcast and what you're doingit's so it's so interesting to hear allthe different characters and I thinksort of the role you're playing andbeing like the mediator of the marketthis way and hearing all the diversevoices hopefully I didn't give up toomuch of what we're thinking butthis kind of diversity of hearing whateveryone's thinking it's just sofascinating and thank you so muchthank you so much Connor for hosting uhthe end this was amazing time always uhglad to and happy to exchange with youall these thoughts and uh almost like inthe brainstorming fashion yeah and I'mexcited for the future of this with Chadgpg and all the breakthroughs that youguys are working on and and many playerson the market as well thank you", "type": "Video", "name": "Dmitry Kan on Neural Search Frameworks - Weaviate Podcast #34", "path": "", "link": "https://www.youtube.com/watch?v=1ebCUCUJraE", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}