{"text": "Hey everyone! I recently spoke with Aleksa Gordcic about his vision for the future of video content on YouTube and it really ... \nhey everyone thank you so much forwatching the Wii gay podcast I'm superexcited to welcome Alexa gordich Andrebondarev Stephanie horvachesky andgunjan batarai Jana wellender Gregkamrat and Colin Harman email and FinnProfessor Laura Dietz Brian RaymondErica Cardenas Siva and Roman yushang WuJohn dagdollen both wivier co-foundersBob Van light and Eddie and dilockerhey everyone thank you so much forchecking out this update on the Wii VApodcast search uh hopefully from theintroduction reel you saw that our nextuh weaving podcast is going to featureAlexa gordich Alexa has such aninteresting story of beginning as aYouTube content creator making deeptechnical paper summary videos thenjoining deepmind the top AI lab in theworld arguably and then leaving deepmindto start ordus so ordus is aboutcreating these next Generation contentcreator tools so building questionanswering or chat Bots over particularYouTube channels like say JeremyHoward's YouTube channel and ideas likethis so this really inspired me to givean update on what I've been doing withthe wevia podcast search I've beentaking these podcasts putting them intowhisper and then taking the transcriptsand you know searching through them andnow with large language models andgenerative feedback loops I think it'sright for an update so generativefeedback loops broadly the ideas wherewe retrieve data to pass the largelanguage model and then we save theresulting Generations from the largelanguage model back into our database sothere are two really like kind of bootson the ground immediately usefulapplications of this which is firstly towrite a summary of the podcast and thensecondly to identify the chapters in thepodcast these are just like two tasksyou have to do every time you upload apodcast as you're managing somethinglike a podcast but at the end of thevideo I want to conclude with some Ithink directions for future work thatcan really take this to the Moon I thinkthe future of content creation andconsumption this kind of you know videoYouTube podcasting I think all this isjust you know gonna totally flip on itshead with large language models and allthis cool exciting stuff so I hope youenjoy the video we're going to startwith some code and then we're going toconclude with some kind of big ideasabout where I think this is going sothanks so much for watching beforediving into it all the code for thisproject has been open source on GitHubwe get slash weavate podcast search allthe data the podcast transcript Jsonfiles can be found in this data folderthe generative feedback loops folder hasall these different scripts for writingthe clip summaries the auto chapters thefull podcast summaries recommendation isa demo that I did at odsc East where youshow ref to VEC through the differentpodcast Clips as well as uh pickingsearching with the ref to VEC vector andthen doing retrieval augmentedgeneration with the nearest neighbors tothe user Vector chat Vector DB Langchain that's from Erica's blog post soif you want to chat with this podcastthis is how you do that and then someother things like how you do a weeviatebackup or how you get the data out ofwevia into a Json with the cursor APIhow we create the schema which we'll getinto right after this and then all sortsof things from how you upload the dataand missing school thing so if you docheck this out please leave a star itmeans the world to me and um yeah Ireally hope you enjoyed this this videowill show you how you can applygenerative feedback loops to the weevierpodcast transcriptions so when we firstpresented generative feedback loops wehave the example of Airbnb listings wehad a data set that mostly containedtabular symbolic features like thenumber of bedrooms in the Airbnb listingwhat neighborhood it's in the minimumnumber of nights you needed to stay inand so on and so the first thing we didwith generative feedback loops is wetook this tabular data and then we putit into a prompt that wrote a textdescription of the Airbnb listing whichwe could then vectorize as say the zeroshot open AI or cohere models and thenembed into our wevia index to searchthrough another thing that we did withgenerative feedback loops in this firstpresentation was we took these summariesand then we wrote a personalized summaryby retrieving from a user class that hadsay Connor who likes to travel with hisdog or Bob who needs a powerlifting gymwhen he travels so we showed kind of twothings of how you build this index outof tabular data by retrieving data fromthe database feeding it into thelanguage model and then saving thatgeneration back into the database aswell as retrieving from another classand all those kind of ideas of how wetake data from our database put into alanguage model and then you know savethe resulting generation because we'regoing to want to use it in the futureso I'm so excited to show you how I'vebeen using this concept for the weeviatepodcast search maybe you're working witha similar data set or maybe this willjust kind of inspire your thinking onwhat generative feedback loops arecapable of and the role that this willplay in the future of you knowgenerative models Vector databases andall this cool exciting stuff so we'regoing to start off with the data schemashowing how we design the classesproperties cross references for thisparticular example then we're going tobuild a summary index of Clips where wetake the raw what was said in thepodcast and we transform it into asummary of the content that was said andthen it's actually better to searchthrough this summary index thevectorized representations of thesummaries rather than the vectorrepresentation of just kind of the rawtranscript so we're going to be savingthese summaries back into the databaseand then using these summarized Clips tofeed into our summarization chain forthe entire podcast so it's a niceexample of where we save something backinto the database then keep feeding itinto future chains and this whole ideaof you know this kind of cascadingGenerations that we've saved back intoour database so we're also going to usethe clips to do the chapter segmentationAuto chapter analysis at the end as wellso finally after the video with thePractical like just the Hands-Onexamples with that we see the resultsand we've tested things I want topresent some future directions so here'sa data schema for the wevia podcastsearch we have three classes pod clippodcast and chapter highlighted in greenis the property that's used to vectorizeeach instance of the class so for everypod clip we have a clip summary a textproperty and that's what's passed intoour vectorizer model that produces thevector that will represent each instanceof the podcast clip similarly for thechapters the description that's writtenwill represent the chapter thedescription will be vectorized torepresent each individual chapter eachdescription is vectorized RF is superredundant and then with the podcast thesummary will be vectorized so also shownin red are the data types for eachproperty so content is text speaker istext pod number is int there's someinteresting things you can do whenyou're indexing a text to use as acategory so for example with speaker wemight want to use that as a categoricalvariable rather than you know like atext thing so so you can configure thisin weviate to have the inverted index onusing speaker as a categorical thing ifyou want to query like where speakerequals Bob inlight or Eddie and dylockeror something like this so you can dothat with these text properties sosimilarly you can do say duration tohave like a filter on say you want toonly see chapters that are longer thanfive minutes because you know or bloggerthan let's say 10 minutes because that'smore likely to be I don't know maybe adeep discussion I'm not sure but likeyou can use these properties to filteryour vector search so as you'researching through the vectorrepresentations of the podcast clip youcan also add these uh these filters aswell which is something I always foundwas so interesting about weavate is thiscombination of filtered Vector indextraversal so additionally we have crossreferences between classes so the waythat this works is you can first searchfor you know a podcast that matches yourquery and you can see which Clips arecontained in the podcast to then get outthe clips or so on you could linkchapters to pod clips and all sorts ofother stuff I think there's aninteresting discussion to be had aboutrepresenting podcastclasses with the summarization Chainversus ref devec but first let me showyou the example of the summarizationchain and then we'll come back to thatdiscussion so I hope this is a gooddescription of the data schema that'sgoing to be used for this example nowlet's see quickly the Json dictionarythat you use to create it and weeviateso we'll start off with a quick look onhow to create these schemas with Wi-Fiso the first thing we do is we connectthe Wega client wherever wherever thisis running in my case I'm just runningit locally on this laptop but you canalso have weeviate embedded or say theWii VA cloud service running it yourselfthese kind of things so first youconnect to your we get instance and thenyou define the schema dictionary whereyou have the different classes that youwant to create again we want to createthree pod flip podcast chapters so withchapters we're going to turn on the texteffect Transformers to vectorize eachinstance of our class and then we'realso going to enable the generative openAIto do that thing where we are going toparallel I'll get into this more laterbut we select which model we want to usein this case I like the text DaVincizero zero three uh so here's the nextinteresting thing is we're so we'redefining our property so see summaryversus content in this case we have skipfalse this means we're going tovectorize the class based on summarywhereas content we're going to skip thiswe're not going to vectorize contentspeaker we're going to skip as well andspeaker I did mention that you can havethis you can enable inverted indexing ontext properties to use them ascategories I haven't done that quite yetbut just quickly noting that this iswhere you would do that so after youdefine all the kind of you know text indate these normal properties now weDefine cross references so we have inpodcast which has the data type podcastthat we're about to Define and you havein chapter with chapter that we're aboutto Define so I don't think there'sanything else to novel about this youknow podcast again we uh skip the otherproperties we only vectorize the summaryuh these are kind of older properties Ihad when I was originally working onthis but um so yeah so has clip haschapter chapter you know time start timeand so on so now that we've defined ourdata schema we're going to be uploadingthe data that we do have and keep inmind that a lot of this data in theschema is going to be produced by an llmthat we're then going to save back intothe database but we start off by loopingthrough this original data uh where wehave say the content the speaker and thepodcast number and then we're also goingto be creating a clip number key thatwe're going to be using later to get theclips out and put it into the file sowe're just going to be you know creatingthese objects creating cross referencesbetween pod clip in podcast podcasts andpodcast podcast has clip pod clip andthat's all we're going to be doing fornow and we're going to be creating a lotof this data again with our LMS okay sonow that we've defined our schema andimported data into Eva we're going to besummarizing each of the raw podcastclips into a summary and quickly beforeI show you the prompt to use that let'shave a look at the final result maybejust to wake you up if we've been divinginto the code too much so what we'redoing is again so for each of these umeach of the contents we write thissummary so we can take a look at howwell that um that works uh so in thisclip we are talking aboutum competition and this paper summary soConnor shorten agrees that markets areunderserved and competition is a bigforce that can show ideas he givescredit to the speaker for diving intograph neural network stuff so that was apretty good summary uh here's anotherone or let's see one that maybe has morecontent to it[Music]umokay so this is Alexa talking about Ialready felt fairly comfortable uh sothis is uh Alex is talking about how hegot the deepmind so and the summary isAlexa gordage began his journey intomachine learning in 2018 when heattended a summer camp organized byMicrosoft he was inspired by thelecturers from deepmind and wanted to beat the Forefront of AI development soand so on so this also is a pretty gooduh summary so so basically you get theidea of how um you see how thesesummaries are like you know morecompressed information packed than kindof you know just raw how people speakand I think this is a really interestingcomponent of this because you vectorizethis to represent the classes and thensearch through and it gives you a betterVector because it's cleaner data sowe're kind of using like the largelanguage model to clean our data andthere's all sorts of interesting thingsthere's an interesting paper on usingthese to supervise training embeddingmodels the summary and the originalcontent as the positivesa lot of interesting stuff to this solet's get into how we do this okayhere's the code to write a summary foreach of the podcast clips and then savethe resulting summary back into Eva sowe start off by connecting to leviatethen we write our prompt to use the Evagenerative search module generate promptplease write a short summary of TheFollowing podcast clip speaker and thenwe template in the speaker value podcastclip and then we template in the contentvalue so we select the properties thatwe want to select from the we gate classto put into the uh The Prompt then thisis something I did I originally had aloop but what I found is it costs abouta dollar to do this so if I did it forall I think 15 podcasts in there so I'mjust doing one podcast at a time for thedemo so a podcast goes 55 and you knowjust putting it into the wear filtertemplate so first we get the total clipsand again I just kind of hard coded thatin quickly but so then we get the totalClips in the podcast now we're going tobe looping through the clips with thisoffset so the way that this works isbuilt in this generate search moduleinto go language makes it really good athandling the parallel go Lang requestswhich makes it really fast but if youtry to put in like all 70 Clips at onceyou're going to end up getting a readtimeout if like one of those requeststakes too long and so on so I do this 10at a time by using the following whereyou Loop through the clips with thisincrement of you know plus 10 step sizesand then with limit 10 and then withoffset so the offset just pushes it youknow through the the data objects so umyeah so you just grab the podcast clipyou subset sample the generateproperties then you pass in pass it intothe prompt defined above and it's prettymuch as easy as that you get the ID outand then this is just what I did to kindof monitor how it's going and then youjust update the data object by creatingthis new property for each of thesummaries with the summary and then thegenerate a single result that comes outof the prompt you get the ID and thenyou update the the data object with thisnew property the class name and then theuuid for this object okay so next stepis to write a summary for the entirepodcast gas by using a summarizationchain so firstly again we connect toalleviate I will pass in our openai keyhere because we're going to do this justwith the the open AI API here in Pythonbecause we're doing it sequentiallyrather than parallelizing the requestacross the search results so we justpass in this is just a little wrapper Ifound that the I actually prefer theresults of DaVinci to 3.5 turbo maybesomeone has a comment but I didn't likeexplore it that that much so temperatureof zero passing in the prompt Max tokensand all this kind of stuff so so firstthings first thing to do is to get allof the uh the clips and again we wantthe summaries not the original contentso we get these clips with our weevierquery and then what we're going to do isthis local memory create and refineprompt so maybe if I or hopefully that'suh you can see that well but so we startoff with an empty string for the currentsummary and we have the prompt pleasewrite a summary of the following podcastyou will receive the clips one at a timeas well as a summary generated so farcurrent summary so far and then we putin our local memory that we're going tokeep writing by saving the output ofthis call back into that current summaryvariable in the next podcast clipspeaker percent speaker and then you putin the the next clip speaker saidcontent so We're looping through theclips putting in the speaker set contentas well as our local memory of thecurrent summary of the podcast so farso hopefully that makes sense so thenwhat we do is so what would happen withthis originally is it would just keepadding sentences onto the end of thesummary so you know then you end upgoing over the 4096 token window so inthe middle of this while you're loopingthrough the clips you then have pleaserewrite the summary to make it shorterplease be careful about losing too muchinformation when rewriting I found thatthat kind of works that second thing ofbut because it I think the currentlimitation of this is that it often willcompress it to just writing these longlists with commas of each of the thingsand you know that's not great for thesummary but so there are someinteresting ideas but this is the firstthing I tested is this kind ofsummarization chain thing so you justcontinue looping through that againprinting it just so I can see it as it'srunning in the consoleand then saving it so we get the podcastID that we want to be linking as we'resaving back into the podcast object sowe um you know we add this new summaryuh property and then we update it byputting in the summary that comes out ofthis that current summary object aswe've exited the loop and then we passin the IDso I think the first thing to note aboutrunning this is about how you're goingto be visualizing it and maybe there'san opportunity for a startup I've heardof tools like Lang flow and things likethis I just haven't personally had thetime to get into it yet but this is whatI've been doing is just as it's loopingthrough each podcast clip it takes thatfirst podcast clip it writes the summaryof the whole podcast from it then itrewrites it and I'm just kind ofprinting it to the terminal and I'm youknow just watching it on the side as itruns and so I do think that you get apretty good debugging with this like umI've learned from just watching thisthat when you rewrite it often the waysthat this fails and the reason why theresulting summary is like okay isbecause it'll compress it into like alist you know like just like commas todescribe terms and I mean at the end ofthe future work I want to talk aboutthis kind of General understanding andhow it that clearly doesn't understandwhat it's talking about really and Ithink there's a lot of interesting Ithink that's quite an interesting pointbut anyway so just the the Practicalexample I want to show you is justlogging it to the terminal to visualizethe chain honestly I think this gets thejob done but I can't imagine withcomplex chains and you know when you'rereally looping and then Branch like eachLoop has this kind of nested like youknow summarize and then rewrite I canimagine maybe you want these moreadvanced tools for visualizing thesekind of things so now let's get intowhat I think is the most interestingtask for these generative feedback loopsto be doing which is to automaticallyidentify the chapters in the podcastthis is probably the most useful timesaving thing about this to be doing soagain we start off with all that samekind of connect to evade and Define thisopen AI thing and there's probably acleaner way of doing this but I don'tthink it matters for this so again weget the podcast Clips out and now we'regoing to be looping through these clipsso here's the interesting thing so westart off with this empty dictionary ofchapters that we're going to be puttingin these dictionaries too so we're gonnahave a list of dictionaries then at theend of the loop we'll Loop through thislist and then we'll take out thesedictionaries to write the key valuesinto into the weva data objects so wehave the keys chapter and then start andend which is going to be you know hugefor how we then use this to annotate thepodcast and then we have the Pod clipIDs to create those cross referencesfrom pod Clips to Chapters and theninversely chapter has pod clip so here'sthe prompt that I found to work okaywith this and hopefully I find thisinteresting so your task is to annotatechapters in a podcast you will receive apodcast clip in the current chaptertopic if the conversation in the clipdiscusses the same topic please output 0if the content in the clip is very shortsuch as a joke or a thank you orsomething minor like this please output0 however if the conversation in theclip discusses a new topic please outputone the current topic is and then youtemplate in the current clip that you'reatyou'll receive the current clip as wellas the previous and next clip foradditional reference so previous clipnext clip current clip and then so youput the current clip again twice as areminder please only output either zeroor one as described above so I thinkthere are kind of two things to thisprompt that make it interesting thefirst of which is showing how you canhave this if else just in naturallanguage to have it you know if thiskind of natural instruction I find thatto be very interesting and then I thinkthis is the idea behind a structuredoutput parsing there are you know morenuanced things you can do like where yououtput Json dictionaries and then youhave like Json dot loads and then youparse out the key and things like thatwhere it would um you know kind ofgenerate like multiple things with onecall but generally I found this to worksurprisingly well every time I triedthis it did only output 0 or 1 and Ijust you know see how I wrap theresponse in an in Typecast so I didn'tfind that this that it broke it or thatit said um I don't know like a new toplike say it would write a new topicinstead of zero or one and not followthe instructions I found that thisworked pretty wellso then what you do is if topic responseequals equals one now you're going tocut the ending of the current topicappend this dictionary to the chaptersand now you're going to be creating thenew chapter object so you have this umplease write an abstract description ofthe uh conversation topic discussed inthe current podcast clip for the sake ofreference you'll receive the previousand next clips as well to help furthercontextualize I think the abstractdescription of the topic so againpassing in the previous current nextplease write a maximum six worddescription of the conversation topicdiscussed in the current clipso again we template all this stuff andthen we you know save the chat theoutput into our chapter for the currenttopic which is what goes into the um theuh oh sorry what goes into the currenttopic template so earlier I misspoke andsaid that this was here as well but thisis actually uh the current topicobviously but so anyway so so then weexit the loop and now we're going to besaving the new chapter objects so firstwe get the podcast ID that this wassourced from with this query you knowrun this and then um so then we have theuh four chapter in chapters We'relooping through that list ofdictionaries we have our properties thatwe extract the chapter the start the endthen we get a uuid for this chapter IDwe create the chapter object and nowwe're going to link from a pod clip inchapter chapter has clip pod clipchapter from podcast podcast has chapterchapter so that's how we you know againconnect that graph full of crossreferences to add this structure to ourdata so that's all we need to uh extractthese chapters from our podcast okay sowe're similarly gonna just kind ofvisualize this in the terminal which Ifound to be a fine solution for this sowhat it's doing is it's executing thatif else if we need to switch the topicor not it starts off with building aYouTube channel explaining ml Conceptsthrough videos then it transitions to ohstays on that one for a while creating astartup ordersand so on so so this is the idea of itexecuting this if else logic with thetopics is it passes in these topics uhby looping through each of the clips andhaving that if else kind of uh promptingthat and then the structured outputparsing of if zero if one and then howthat leads to being able toautomatically create these um thesechapters in the podcast okay so that'sthe end of the latest update on how farI've made it so far with uh summarizingthe clips then applying a summarizationchain on the clip summaries to summarizeentire podcasts as well as extractingchapters from the clip so again it wouldmean the world to me if you check outthe GitHub repository that contains allthe code for doing all this you justneed to replace your openai key butmaybe you're probably just moreinterested in seeing the example andthen applying it to whatever data setyou're working with so anyway so hereare some directions I think of what Iwant to do next with this project that Ithink are really interesting and I thinkyou'll find that interesting as well sostarting off with topic modeling forpodcast summaries I really want to showyou this ad atlas map and I think thattopic modeling where you cluster theclips and then you look at the Clusterscould have a nice structure instead ofthis kind of sequential summarizationchain I I don't think the sequentialsummarization chain is going to be thebest way to summarize these podcastsgoing forward then I want to talk aboutself-ask prompting we're usuallythinking about it with questiondecomposition but I think it's reallyinteresting for summarization as well Iwant to show an idea that I've beenlearning about from Lama index onretrieving from multiple informationsources I think there's a lot of nuanceto this I think I want to talk aboutpersonalized summaries podcasted blogposts and generally how working on thisproject has led to a new understandingfor me on fine-tuning llms and hopefullyyou'll agree or have some feedback onwhat I'm getting wrong okay so whatyou're looking at is atlas from nomec AIwhich is a visualization of embeddingsprojected into a lower dimensional spaceso that we can visualize the Clustersyou see these high level tags generativeadversarial networks the neuralarchitecture search topic modeling whichis funny because that's what we'retalking about these are the high leveldescriptions given to these categoriesso this is a pretty big topic map as yousee in the title this is all of theabstracts of papers and nerves from 1987to 2022 but you could imagine doing thiskind of thing so if we zoom in on thegenerative adversarial Network thinglike imagine all the podcast Clips arelike this and they have some kind ofcluster structure within the clips andthen so I think summarizing each of theClusters and then just kind of mergingthem into the one Summer from thepodcast I think most likely that's thebest way to summarize long content withthese llms going forward so the firstthing I want to do next is add in aprompt when it's summarizing the podcastclip to ask do are do you need moreinformation more background knowledgeabout certain terms that you'resummarizing so one thing I noticed justfrom watching the summarization chain inthe terminal is that it doesn'tunderstand say what graph neuralnetworks are and so it'll combine thegraph neural networks thing into thediscussion of like just creating YouTubecontent broadly in a way that totallydoesn't make sense demonstrates nounderstanding of what graph neuralnetworks are which brings into the lastthing on fine-tuning LMS but I thinkthis general idea of we in questionanswering it makes quite a lot of sensewho was the President of the U.S whensuperconductivity was discovered youknow and then you asked when wassuperconductivity discovered and then inthat year who was the president so youbreak up the question I thinksummarization change should adopt thissame perspective to how that works whichthen brings me into a super interestingthing I've been learning about from Lamaindex which is about routing queries todifferent information sources so purelyfrom the vector uh the we gatestandpoint I think just the idea ofselecting from different classes so sayI have one class this week a blog postand other classes like archive and thensay another thing is Wikipediaand then if I want to retrieve about youknow I want to get like a definition ofgraph neural network say I retrievedthat from archive if I want to get someuh maybe definition on just like whenmachine learning was invented maybe Iget that from Wikipedia but this idea ofrouting these queries to differentinformation sources I think this hashuge potential in how this kind ofsummarization chains could improve andhow you can retrieve from differentsources to retrieval augment togeneration pack The Prompt thatfacilitates a better summarythe next topic is quite different butthis is more this is more so a bigger uhproject that kind of hopefully when I dogenerative feedback loops we've apodcast search part three I have thiskind of thing ready where uh what I'mreally dreaming of is to do personalizedsummaries so you give it the chaptersmaybe a short description of the chapteras well then you have something like youknow a list of people who are interestedin the podcast newsletter subscribers soyou have the chapters of the podcast andyou retrieve Alexa gordich is anentrepreneur building ordis or this isan interactive way to watch videos learnfaster by using question answeringcapabilities and high quality summariesand the prompt is which of thesechapters do you think would interestAlexa if none please output notinterested so then you write thispersonalized summary to email Alexa tosay hey do you want to watch thispodcast but if they're not interestedthen you know don't spam them don't sendthem an email for the podcast that theywouldn't want to watch so I think thisis this whole idea ofyou know this virtuous cycle theaggregation Theory from Ben Thompson Ithink this is that thing this you knowpersonalization of content and this isyou know this is particularly how I'mthinking about using it so hopefullythat's useful for you to see like a realworld example of how I think this canimprove our podcast and our content uhso the next thing I think is superinteresting is to write blog posts fromthe podcast and I see kind of two waysof why this would be interesting thefirst of which is to say like what isunique about this podcast so pleasewrite an analysis of what this podcastsays uniquely about chapter and then yousearch within this podcast to get thetop K from this podcast and then you sayhere are clips from other podcasts tocompare this podcast as anything uniqueand then you do the top K from all theother podcasts from all podcasts and soI think that's quite interesting becausenow you have this comparison kind ofthing that you're doing with with thesemantic search so I I really love thatidea then I think another thing is umyou know I like to listen to like DavidSinclair and like these kind of likebiology things but I I often like Idon't really know what they're talkingabout so I think this kind of likeretrieving from some information Sourcelike archive to write a background blogpost so you know when I'm reading aboutlike metabolic pathways or crispr stufflike this where I hardly understand anyof it having some kind of likepre-flight blog post for me before Ilistened to one of these podcasts Ithink that could be really cool thisproject transformed my understanding oflarge language model fine tuning so Ithink on one end we're kind of just youknow waiting around when is GPT 5 comingor when is you know cloud or cohere orsome open source model going to just bethis impressive model that can just dosomehow understand topics like graphneural networks like specific things foryour specific information needs so itgot me thinking about you know you couldimagine you take the prompts again likeplease write a summary current summaryso far and then you know the localmemory and then the next clip and thenext summary and it outputs some kind ofnext summary and you would label that asI like this or I don't like this andthat's the general a labeling frameworkof reinforcement learning from Humanfeedback that makes this so appealing isyou just need to say like it don't likeit and it can you know do that sequenceof sequence learning and update thelanguage model but I don't think thatthis will ever get you to thatunderlying language understanding so onthe top is kind of what I think is theconventional wisdom that you would takesome uh you know some model that'salready been trained with reinforce andlearning from Human feedback unlikeGeneral preferences of writing summariesof things and then you would just kindof try to like steer it in direction ofyour domain by annotating this kind ofthing but I think the alternative ideais you have a pre-trained language modeland then you language model some of yourdata set and then you do the reinforcedlearning from Human feedback sothis is really inspired by my thinkingthe kind of the the news of the time asI'm recording this this uh video isMosaic ml being acquired by databricksfor 1.3 billion dollars and I justrecently recorded a video looking at theMPT 30 billion uh language model thatthey open source and a detail of it thatjust blew my mind was the open sourcingof the language model and then theinstruction tuning it just really helpedme separate these ideas and you knowI've had some conversations withJonathan Franco on this podcast where hediscussed um you know convincingcompanies to language model their datathat's where you predict the next massedout token on you know say I just tooklike all of archive or I filtered it forinformation retrieval approximatenearest neighbor search like this kindof like weevier domain you know justlanguage model podcast transcripts blogposts and so on I think that then youwould have this base Foundation thatthen you could rlhf onto that so I'mcurious what people think of that that'smy latest understanding in what LM finetuning might look like and how thisproject kind of thinking about how mightget a better result from this kind ofled me to appreciate that kind ofcontinued pre-training concept a littlemore thank you so much for watching thislatest update on the wevia podcastsearch and applying generative feedbackloops to this data set to summarizeClips summarize podcasts and extractchapters from podcasts I think thatthese ideas of personalized summariespodcasts to blogs overall just for me atleast having a data set helps justcement all these kind of ideas andground them in some kind of applicationso please subscribe to this YouTubechannel and leave a like on the video Ifyou enjoyed it you can check out weviateweva.io also it's an open source GitHubproject we get slash weavate and alsoplease follow on Twitter at weeviate IOthank you again so much for watching", "type": "Video", "name": "Weaviate Podcast Search meets Generative Feedback Loops!", "path": "", "link": "https://www.youtube.com/watch?v=I4Jle80AOaU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}