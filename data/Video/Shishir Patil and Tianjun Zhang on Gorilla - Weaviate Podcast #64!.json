{"text": "Hey everyone! Thank you so much for watching the 64th Weaviate Podcast with Shishir Patil and Tianjun Zhang, co-authors of ... \nhey everyone thank you so much forwatching the wva podcast I'm superexcited to welcome the co-authors of thegorilla large language model shashir andTian JN this is one of the most excitinglarge language models out there I thinkit's so cool how this enables largelanguage models for Tool use and allsorts of exciting topics so beforediving into it shashir and tanen thankyou so much for joining the weba podcastyeah thank you so much for having usConor appreciate it and looking forwardto it awesome so could we kick this offwith kind of like this uh LOL LS forTool use kind of like treating tool useand properly formatting API calls iskind of like a new task in deep learningthis vision of gorilla being the a theAPI app store for llms I think it's sucha compelling Vision could you kind ofyou know tell the story ofgorilla yeah for sure uh so I think thestart off sometime around the end oflast year uh maybe November December2022 when there was like you know Charwas the rage and lot of people weretrying it including us uh and as someearly adopters what we soon realized wasthat like a lot of uh these tools atleast from a chatting modality was goodto maybe as a demonstration of thetechnology of what LMS can do but wefelt that probably this is not what thefuture would look like right in ourminds an llm is a powerful tool powerfulnonetheless but still a tool right andthen now you need to have tools need tointeract with other tools to get morestuff done and in computer science uhthe way different tools interact witheach other is through API calls andthat's that was The Germ of the ideawhere we were like hey you know this isa tool this needs to talk to otherapis um and that's how we got started sothis was like the original uh the storyof the origins ofcorilla yeah amazing I love that um likethe the video demo you have where youshow like how it can use a CLI like youyou have this example where in naturallanguage you ask I want to download thegorilla data set from an S3 bucket andall those API requests all thatintermediate orchestration is handled bythis model and uh T and I remember whenwe met at Berkeley you you showed methis like GitHub CLI and how it canformat the GitHub CLI request couldmaybe talk a little more about theparticular kind of apis that you you twohave started to explore uh using Gorillafor yeah so we have been initiallybecause as a PhD and also machinelearning researchers for the paper sidewe choose hugging phase models and alsotensorflow and also torch up so thosemodels are pretty particular for ummachine learning audience and usuallythe case is like they know they want toknow actually some model they use forimage classification but not exactlywhat model they want they may also havesome uh specific requirements forespecially the model size I oh I want asmaller model under 10 millionparameters or I want specific the resentfamily or what so on so forth so that'salso some constraint uh that's for thepaper side and the afterwards we're kindof moving towards uh think about howpeople in general are having a pretty uhit's just having not very goodparticular sense of what the exact umAPI to use the kind sort of rememberssomething as also we discussed a littlebit with shishir and theespecially for this GitHub stuff rightyou want to know if I want to check outsome of the project base last Friday yousort of know the command basicallyroughly but not the exact command alsosomething like kubernetes AWS so thathas been our Focus for the second waveespecially in terms of the gorilla SI wehave been working on the Linux commandline uh GitHub and the AWS Ager um alsothe gcpcetes is uh kind of the supports we arehaving fromthere yeah that's really I mean I lovethat so much I think all the time I havelike you know I might have like apicture of this podcast thumbnail andI'd be like could you make a pollrequest to the we v. website to add thisto the podcast and it's like that littlelike the little bit of doing the newbranch and then putting it in that partall it's like a bit of overhead thatthis gorilla model I think can justsimplify that uh dramatically and Ithink you know I really want to diveinto kind of using Gorilla for the we8apis but I guess kind of I want to takeapart a little like in the gorilla paperyou have the torch Hub tensor Hubhugging face as you mentioned youspecify kind of like what model you wantto use and it has constraints like youknow I need a 85% Plus image netaccuracy res net but please make it likeless than 20 million parameters so Idon't have to like break my bank servingthis and then there's kind of like theapis like you know GitHub kubernetes youmentioned like get can you tell me howyou see like apis for you knowkubernetes GitHub cloud storagedownloads and then kind of modelinference like picking the right modelfrom huggingface yeah so I think like it's It'sTricky and it's uh it's similar indifferent ways right so one example isif you look at the machine learningspace of apis that we serve throughgorilla a lot of times like for one taskyou have so many different models thatthey are doing almost the same thing butslightly different all right so it'slike oh I have an optic detection modelone could be for animals and the othercould be for plants say for example oryou know it could be like differentmodels like you know almost the samething one uses a res 18 backbone theother us a res 50 backbone as anotherexample so the fact that they're sosimilar and we still able to likediscern between the different apis isactually pretty interesting rightbecause that's a challenging part if Iask you to differentiate between astripe payment APIand say a gcp API it's easy to do insome sense like very different differentdomains diverse functionalitiesdifferent modalities but to say hey lookfrom the two very similar apis can younow differentiate and satisfy theconstraints that I give you and that'squite tricky and challenging right sothat's why uh that's also what makes theinitial API bench that we have uh quitetricky um because you're trying to liketease apart these differences among thedifferent apis that exist now on theother side oflike T mentioned it's not it's not everyday that you go and ask oh how do I do atext to speech all right but on theother hand you know as researchers and alot of people very often tend to use uhall the apis that uh T mentioned so inthose scenarios it's like very verydifferent use cases like one is morepractical more useful and like lookingahead like this was more like from adaily uni developer or like a commonuser perspective uh but the good thingis we have like this Discord Communitywhere we get a lot of feedback and a lotof users uh using it and so now the newthing that we learned is that oh likepeople are interested in um Salesforceand like service now and like all ofthese apis and like the open API specand stuff like that so now we liketrying to you know like train modelswith these new apis and add that intothe gorilla ecosystem aswell yeah I love what you've done withthat this like API Zoo thisI you know I see a lot of the thumbnailsyou know like YouTube video you there'squite a lot of reaction to gorilla and Ithink that kind of API app store forllms is the thing that like the headlinethat people are loving um so yeah sopeople you're starting to so startingfrom the model apis and I think there'squite a lot of interesting things thatyou've done with like the abstractsyntax tree for how you evaluate if youformatted that particular requestcorrectly but I guess they just want tokind of maybe even stay on this just forour listeners to say like this API Zooyou're building up a big data set of ofdifferent apis whether it's you knowkubernetes or GitHub CLI how do you seethat kind of API Zooevolving yeah so soak the other theother interesting point is that a paperis a snapshot in time whereas the opensource project evolves almost dailyright uh so so and and we have this atthe back of our mind uh even when youstarted off which was like look but atthe same time you want something that'sset in stone to Benchmark againstbecause if you have a moving Target thenyou know how do you know how well you'reperforming Etc so this was a thoughtprocess where you would have like theAPI bench which released as a part ofthe paper this would be like one yardstick that you can use to measure youknow all the different uh molds thatcome out and that's why we have tried tomake it as easy as possible we put outthe evaluation scripts and we have allthe Train the eval split neat and cleanuh so people can try try the differentmodels bench Market Etc and this wouldevolve much slowly right uh on the otherhand what we also learned is thatthere's way more apis than what you andme or the three of us could do or evenyou know like a small subset of peoplecan do so the idea was that you knowpeople can contribute their own apis uhand then we can now use this train themodel and then serve many other peopleand one thing that's critical is thatunlike you know there's been like a lotof oh legal questions around can youscrape this scrape that Etc is it okayto like for an llm to learn this dataand serve it apis are meant to bedistributed right like the more peopleuse a particular API the more in Boundit is for the people whose apis peopleare being used right uh people whose APIare being used right so in some senselike this is the incentives are purelyaligned right like in fact peopleactually put out uh documentationtutorials Swagger documents that otherpeople can use to actually use theirapis and build on top of it so this wasthe idea and uh and there's been like alot of interest in like oh how can wecontribute our apis into the API Zoobecause then we can train the model andthen many other people can use thismodel uh to then you know um get gettheir work done with a very small orlike very quick ramperperiod yeah add a little bit alsoanother Point like this uh apis likepeople are building apis every day thereare new apis or or maybe even changingthe API versions and then like this thisis not um one time shot uh time stamplike static data set it's like meant tobe dynamic and people can building theirnew apis people can update theirversions of apis or even the usage ofthe apis so that's also an anotherinteresting question we want to study byempowering this API Zoo because peopleare now freely to update and then wewant to also we can also study how thelanguage model can the to the bestsupport this Dynamic change of theapis yeah so it's super interesting Ithink kind of quickly before we gofurther into the training of the llmsthe gorilla LMS let's let's kind ofdifferentiate between this gorilla LMSand like the open AI funks with the Jsonwhere you kind of give it like this Jsondictionary of how to format thearguments like obviously it's like zeroshot versus fine tune but maybe like doyou have any thoughts on like what thelimitations of that kind of open AIfunks approach might be compared to thiskind of train a llm specifically for uhdata for the AP yeah that's that's agreat question and I think the way Ithink of open functions is that you knowyou know what API to call you just wantto fill in the arguments into that APIand you and you get the response rightand con there's also very similar towhat they did with plugins in the chatGPT scenario where you go and pick a fewplugins that you want and uh then youknow to give a question it would answerwhat we're trying to address is the StepZero which is API Discovery right uhlike we have a friend who's trying tobuild an app and you know now he wantsto integrate Payment Processing intothat while stripe has a bunch of apisand there's like a bunch of other peoplewith different apis which one do youeven call right like how do you do thediscovery and in many scenarios youdon't even know what's a good Discoverymechanism right like if you want a gooddatabase on your for a react app thatyou have on your iPhone what do you useuh if you're in the domain then yesprobably you know what your colleaguesare using but otherwise how do you knowso it's like API Discovery is somethingI think that's I think is an an openproblem that we're trying to solve withGorilla which is that you know you gowith a you go with an intent and thencan you get the right API and it's evenbetter where if you can also like fillin the right documents itself and thenyou just get thatas in a single attempt kind of thingyeah that vision is incredibly uhcompelling to me and especially like aswe step into the details of how youtrain these gorilla llms this kind ofretrieval aware training you say APIdiscover Discovery how do I find theright API I take a natural command likehey I want to add a you know securepayment processing in JavaScript ininterface something like this and thenyou retrieve from this database to getthe API can we kind of Step into thedetails like how you're seeing thisretrieval awaretraining yeah so we see this retrievalaware training is uh actually slightlydifferent from just a f so in the paperwe have two versions We compare to oneis purely zero shot basically we don'tdo any information retrieving but one ofthe bottom neck for this is as most ofthe language models are still they arealso having today is like they cannotkeep their knowledge up to date if I askanything that is late happen later thantheir training data set end date theyhave no clue what's going on herealthough there are a lot of the uh otherstudies like retriever aware generationor um different varus of retrieversbasically enabling Google search andother various sours of informations toconnect between this upto-dateinformation and also the language modelitself but what we think the retrieverWorld Training is like the beauty ofthat lies mostly in you can actuallyread your documentations like you thedocumentations can be updated like dailyor even week daily or weekly right it'smuch lower the frequency you will wantto train your large 70 billion languagemodel or 170 billion language model sowe can actually we want to actuallytrain the model to read thesedocumentations and actually figuring outhow you can from these documentationswrite the corresponding apis and thenthe users or the developers can updatetheir documentations every day or givingnew function names or even update theirversions and uh this kind of is what wesee also sort of missing in the currentum language model scenarios because wehave actually identified a couple paperssaying that if you put a bunch of theretrieving results and some of them areincorrect or some of them are Irrelevantthis would definitely dramatically hurtthe current language model's performanceeven in gbd4 so that's the part weactually want to dive into and try tosolve using the retriever World trainingthat part of the conyeah and the and you can think of thekey inside with a with an example rightso for example you say look I want toclassify uh an image uh and then if Iand you use a retriever and thenargument your prompt with what theretriever gave you so the retriever toldyou hey why don't you use this uh youknow like a V Vision Transformerbackbone then you're like well okay thisis relevant information I'm going to usethis this if the retriever is correctbut if the retriever is wrong and itsays oh you want to detect you want toclassify this image excuse me uh whydon't you use this text to speech APIthen in some sense what we train themodel to do is to actually ignore thatto say hey look recognize that theretriever can be wrong so I'm firstgoing to determine if the retriever iscorrect or wrong if it's correct thenI'm going to use that API if it's wrongthen I'm going to discard that retrievedAPI and instead rely upon my knowledgebase to then generate the right call forthis particular task so there's likethis high level one bit informationshould I use this information or shouldI discard this information is what we'retrying to teach the uh llm which I thinkis pretty critical because retrieversare never accurate right we we all knowthatuh yeah I mean like kind of especiallyin our world of weeva we think a lotabout like rag pipelines and what thatlike you might um ret like yourretrieval might be like bm25 and Vectorsearch Hybrid search some waitingespecially if it's like a you you knowhow do I use the pipe API like how do Iuse the hybrid search API that thosekeyword matches I imagine especially forthis application but then you have saymaybe you want to rerank you know rerankwith a cross encoder the top results oras you mentioned like you could havesomething where you pass in the query ina candidate document to the llm and justask it is this relevant please say yesor no and if no throw it out and there'sdefinitely so many interesting ideasthere which which is exactly what I wantone thing I wanted to ask you is thiskind of like there was this paper calledLost in the middle which is about youcan't really just fix it by retrieving alot to put into the language model rightso like are you thinking about trying tojust put one API in the you knowhopefully the perfect API referenceright the one API or do you maybe havesome K API to put in that inputwindow right so I think uh so in our atleast in in our evaluations and numberswhere so this is like basically recallat K right and we were like hey let'slet's look at recall at K where k equalsone because we're not trying to like insome sense rank to retriever Etc andthat's also why like we do comparisonwith bm25 which is a popular Retrieverand then one that uses like some GPTembeddings to compare which today mostpeople consider to be pretty good if notthe state of the art and we also have aOracle retriever right so like if Godgave you the correct API then how canyou do and the and the idea is becausewith this we're trying to justdemonstrate that there's going to besome noise in the process what we wantis to so there is a community that'strying to like reduce noise right I'msure uh for uh for VV this would be comein terms of how well can you improveyour recall at K uh but in thosescenarios where you have this long tailwhere you still cannot fit this becauseyou know the queries are UND spec Etc inthose scenarios can we like make themodel itself robust go ahead and Tacklethis so if you make a better retrieveryou benefit from it and in thosescenarios where the retriever fallsshort you can still determine what's theright analysis is and get the result oftheuser yeah and also um if this is likefor one of the if if you determine yourtask where you know for sure your taskonly requires one API but ofing the caseyour taskrequires um like stacking together wordsa mixture of multiple apis let's saylike five 10 apis and then in this caseyou would definitely need moreinformation in your retri process thereare I think definitely a lot of otherVAR of retrieving process you can um youcan add to make this process moreaccurate but often the times it's likeum is it's is going to be a little bittricky to or or even harder to deal withwhen you're actually your your contextof API is requiring multiple documentsor multipleapis that's amazing I mean I I thismixing apis thing is what that's whatblows my mind more than anything else isto have a natural language command whereI'd say could you build me like a anindex of archive papers using we8 andllama index and gorilla does everysingle thing in the middle of thatcalling the we8 apis as well as the Lindex apis as well as maybe thesearchive data downloader apis yeah I lovethat and something else is kind of likethere's there's this thing about likelate like with search you typically tryto optimize throughput and you knowoptimize latency to make it as fast aspossible because most of the time you'rethinking about like web search or likee-commerce but I think with applicationslike this I think that latencyconstraint kind of eases off and it'sway more important to rerank and makesure you have that top you know that topone is really great do you kind of agreewith that opinion that that latencymaybe that this is a good example of oneof those tasks where you would bewilling to tolerate a slower response ifmore accurateyeah Conor this is critical for tworeasons right one is what you justmentioned which is lost in the middlekind of stuff where it's been shown thatif you have too many contexts uh thenyou tend to lose a lot of informationthat's in between um and retain the onesthat is at the front of the back so inour case in terms of apis if you were tolike give uh 10 different apis then youknow a lot of things that's in betweengets lost uh so that's one and thesecond is and this is informed from thedownstream task right like when you dosearch today and if the search resultshows you 10 different uh links then theburden of proof is on the user to pickthe right link and follow it Downstreamwhereas in the case of like a lot ofthese llms where if you're want to likechange these apis together then in somesense like you are going to pick thebest API that comes out so basically thetop one is roughly what matters and thenyou're going to like uh pursue that andthen proceed with the rest of your stepsright now suppose the top one is wrongand you have like an fail early kind ofmechanism that's good because at leastyou get a signal and then you can likego cycle through the remaining but whatif it's like it's not wrong but it'sinaccurate right or what if it doesn'tfail but then it continues on like somelong Loop that keeps uh regressing sothat's bad right because now you're justwasting time and resources withoutreally getting close any closer to youruh result SL answer than you were beforeso I think for these two scenariosespecially as we try to automate moreand more stuff uh it becomes criticalthat you get it right uh and in in thefirst yeah and I so I think just usingone IPI by itself can be extremelypowerful like just you know the GitHubCI kubernetes you mentioned but thiskind of like combined archive with weatewith llama index is super compelling andso I wonder about the the kind of thesystem architecture like does GPT 4 orlike you know the most powerful cutcapable like diversely reasoning abilitythat LM does that kind of orchestratethe intermediate calls to say likearchive gorilla we8 gorilla llamagorilla or even just the same gorillamodel for all three all you know trainon everything in the API Zoo so you knowthis kind of like would you still usesome other language model to kind oforchestrate the steps and have almostlike a you know Chain of Thought like tokind of do this then this then this yeahI think I think uhwe are actually not tied to um tied toeither one of this let mean we couldsupport we could imagine in one case isif you want a really complex task thetask involves a lot of reasoning andinvolves a lot of uh to like basicallylike breaking down St tasks into a lotof sa subtasks and uh this involves alot of reasoning then we could imaginelike at least I'm not aware of any ofthe current open source model that canreally achieve very good performance aswell as gbd4 or even gbd 3.5 like Chechat gbt so this is like one of theunique benefits of even you do Chain ofThought like this your unique benefit ofreasoning capabilities in there so Iwould say imagine like a task is reallyhard and you need a lot of reading stepsCH of thought steps then probably thebest usage is you take the most powerfulmodel up to date like gbd4 breaking thisdown into some sub small steps and thenyou could call and under internal likegorilla for example that can give youvery reliable and accurate tool usage orapis for these small steps and then youcould chain them together afterwards butI would imagine also for some relativelyeasier tasks that involves only maybetwo or three or a couple more steps ofuh training apis then actually smallermodel maybe can handle this well I meanwe don't have any results for today upto now but I believe we could uh as alsothe open source models progress uh wecould do better and better in thisdomains aswell yeah I'd love to hop in on that uhso so let's get into it I mean I thinklike the 15 billion parameter iscurrently the stateof the r lolm at texttosql and SQL I think is a pretty toughAPI for this right like that might belike the the goalpost for all this butso let's talk about um kind of self theself- instruct curation of training datalike how do can can llama 7B be trainedto uh write we8 queries better than gp4and how does thiswork yes the answer to your secondquestion is yes 100% And that's alsowhat we show in the paper uh andobviously like having a specific domainuh gives us the benefit but the pipelineis the following right so you have thedocumentation and a lot of the times umthis might come in prettydiverse uh formats and how thesedocumentations are right so what we haveis a pipeline for training where we takeall of these documentations and thefirst thing that we do is like we createa pretty dense representation of all ofthis information and this is humanreadable I think of it as a Json formatbut Json are pretty hard especially ifyou have code involved New Alliance andyou know I mean it's it's doable but itit might be hard to make in consistentlyso we have like uh small unique uh flagsthat we use and by the way Al is opensourced in our repository so then wecreate like these dense representationsof all the data we have and thisincludes stuff like oh you know uhhere's how the performance metrics areor like here's latency numbers here'sthroughput here's the QC etc for each oftheseapis um in terms of V8 or like any ofLama index it would be like oh here'sthe authentication that's required etcetc and once we have this this serves ustwo purpose now one is I can use this tonow generate some self- instructinstruct API pairs uh and for that youwould use like any Jal purpose llm thatdoesn't necessarily have to be good atapis but it has some uh languageunderstanding that it can like you knowread some apis and come up with uhpotential US based questions and wefound that it's pretty good if we seethis with some uh in context examplesourselves so we create a six I meanthere's no reason to be six but we havelike six instruction API pairs fromwhich we sample three stochastically forevery generation so we give these threeas you know in context learning and sayHey you have seen these threeinstruction API pairs now given this newAPI can you please come up with aninstruction that would be a good PA tothis uh so that's so this is how likeyou can generate self instruct uh API PSbut also this dense API representationnow goes into our uh API Zoo which wecan then use in the retrieval phase uhso in the inference phas for theretrieval argument retrieval uh awareGenerations right so that's that's howwe use this and once you have the selfinstruct then you would then go aheadand you would train the model and fortraining the model we use uh what I saidis R the retrieval a training uh whichis pretty critical in you know gettinggetting accurate numbers even when theretrievers me or may not give you theexact value so this is the trainingphase in the in phase that two there aretwo ways one is where the user asks aquestion a prompt then you find the mostuh relevant top K documents uh whichwould be apis in this case you find thetop K most relevant apis give thistogether to the gorilla llm and thengorilla will come up with a responsethat you can just execute the code andget the response but there's alsoanother way and this is the most popularuh among our open source Community whichis a zero shot approach you ask aquestion directly to the L M and itcomes up with an API from what it knowsthat can help you answer the questionyeah I think even just kind of theretrieval database of apis for the zeroshot is useful as well but yeah so kindof to talk a little bit about myperspective on adding this to we8 andbuilding we8 Guerilla what I've beendoing is you know I have a data set ofeach of the we8 search apis and then ILoop through toy schemas and I you knowgenerate it for each of the schemas andthen that becomes the training data andI guess the big question that I'm socurious with your perspective on is likeyou know so so I am kind of validatingthese queries and so on and I'm I'mcurious if you think like if gorillawill be one model or if like you knowwe8 llama index say rise AI unstructuredLang chain like all these companiesmaintain their own gorilla and then theykind of and then gorill there's likegorilla Hub where I put my gorilla aweeva gorilla into to then when you sayhey uh could you you know get archiveput it into we8 put it into a llamaindex query router maybe visualize itwith a rise AI or like you know likelike do you think everyone will maintaintheir owngorilla yeah uh for real okay beforethat con I I want to really appreciatehow quickly you guys were able to turnaround and build your own gorilla uh webecause I remember we just ched uh Ithink less than a month ago and then youwere like oh what's this going on andand the next time you ping me it waslike oh we have all of this ready so itwas pretty yeah top job withthat well if I can butt in quickly Imean this has completely changed myperspective on how companies can trainllms for their custom tasks like um yeahand yeah I mean thanks for that Ibecause I just I love this idea it's socool yeah yeah thanks Conor uh and yeahthat's a good question and so when westarted off out right initially our ideawas that like we're going to have maybeone or like a few models that's going toserve most apis and then when the usercomes uh we get them the apis butincreasingly I thinkour at least have started to think uhbelieve what you mentioned which is theygoing to have a with multiple babygorillas and came about yeah this cameout from uh two interactions we had oneis we're part of a PhD lab where we likeyou know like we have a retreat where welike give presentations and a lot ofsponsors and people are interested comein and they here and in one such Retreatwhere we were discussing gorilla someonesome institutions came up to us and saidhey can we have a gorilla train for ourown private apis and so initially I waslike well why would you do that that'sslightly counterintuitive but then werealized that the way you know they werelike look we have multiple divisionswithin our Enterprise and each of themhave their some API producers some APIconsumers but they don't talk very muchor like there's no free flow ofinformation right even within anEnterprise uh it's quite possible thatyour like your customer successEngineers are not aware of all the apisthat your engineering team is coming upwith so then in this scenario like youwould have Gorilla just have internalapis to different teams within the sameinstitution right that also just changedmy because you could do this with um youknow all of the functions and all theclasses in a code base right like howyou want to like if I'm saying um youknow with we8 if I'm like hey I want toimplement scan quantization or whateverand it's like you have to now you haveto go interface with like how we8 isgoing to do that how it combines thedatabase with the quantizationscheduling and all this so yeah I meanit's it's funny to think about but yeahyeah and the and the second one is whatyou mentioned which is like you knowatate uh there's a new person who comesin and they're like they know how to useall the other tools very well but notthe new apis in that scenario then youcan be like hey you want to use vb8here's a smooth onboarding experiencefor you where you can just talk to Goanatural language it's going to give youan API call and you can get the job doneso in the scenario you're getting thejob done ASAP but at the same timeyou're also like learning through theprocess right so for both learning andlike a smooth onboarding experienceespecially when you have newapis uh this would be a goodexperienceright yeah I think M maybe I steppedinto it too like I think still just atthat high level of uh you use there'sdifferent like like levels to the apisand yeah it's so interesting I mean thatIntegrations of like we8 and llama indexis different from like then within welike how does the LSM store interactwith the hsw so yeah yeah it's it'sreally fascinating stuff um see so Iguess my next question then well yeah soyou mentioned the baby gorillas and kindof it sounds like you also kind of sharethis thing Gorilla by the way is justthe best name for a paper you got theEmoji and all but um this kind of likeyeah like would there be a maybe ahierarchy to gorillas like like somelike the there's a gorilla that knowsthat some of these baby gorillas fittogether like particular like to stay onthis we8 maybe like let's add like coherlike you want to use coher models we8Vector database and then index clientframework so like there was maybe agorilla that knows that these things fittogether as well as the baby gorillaspecific to each thing does that maybesound like how the gorilla how thegorillahierarchy could play with eachother yeah great question and this isthe kind of research questions that wealso trying to understand this like wedon't have an answer yet uh but you knowit's like yeah like you know what do theinteractions look like right because ifyou're using like you mentioned likejust CER for models llama index for allthe uh connectors to different datasources or like vv8 individually maymake sense but if you want to use allthree of them then what would you needand oh what if I want to like use thisinformation to then use some other setof apis so then who's the orchestrationengine here it's uh it's all yeah it'sit's open research we're thinking intothat uh and I think we touched upon alittle initially where you could use athird party or like even own llm whichis more general purpose it just needs toknow how to route it but notnecessarily how what needs to be rout itand it's yeah open openresearch yeah I guess like anotherquestion I wanted to ask so like thisevolution of Guerilla what like Iforecast it could become is kind ofseems similar to the promise of huggingface sort of can you maybe tell me yourperspective on Guerilla versus huggingface how they're different from eachother or if you yeah or or cuz like Icould imagine hugg and face how theyhave like image classification uh youknow like all the segment all the taskslike API usage could become another taskbut then I also think as you mentionedthis kind of like hierarch like therethere's and then there's probably moreNuance to this particular task so how doyou see that kind of like gorilla andhuggingface yeah I like it's also my personalview of things con is like huging faceis like more like developers are mindsharing they're sharing what model theyhave trained they're sharing their umlike basically the how the model isperforming on different vars of datasets but gorilla is more like in my viewa communication between the API itselflike also another example is uh I thinkthe Stanford AI tal paper they alsorecently released open source code soimagine if you have a ton of different Idon't know language model agents andthen the sort of will have happy will behaving some ways to talking with eachChar or to communicating and toeventually to solve a task like but Hingface in my point of view is like greattool for sharing your capabilities forsharing your results but the ultimatelythe people or the different modelshaven't been or it might be hugging faceare trying to do something wrong butdifferent models hasn't been groupedtogether in order to solve a task that'smy opinion I I feel like in order tosolve a task you may need some forexample managers engineers and you mayneed some salesp person and then youknow this is uh communication betweendifferent levels of uh future agents orfuture apis like have a sales API have aengineer API where um various of likeapis they're trying to communicatebetween each other and eventually it'sit's about tasksolving yeah I've Loved this kind oflike I think GPT team is one of theselike viral GitHub projects thatdescribes this kind of idea of like roleplaying gpts I'm the marketer I'm theengineer I'm the product manager andyeah like the the way you've abstractedthis into thinking about apis has madethis idea so much clearer for me somelike more tangible kind of uh yeah it'sreally compelling I love how youconnected it with the like westw Worldpaper I never would have made that kindof connection but you can think of likeI could think of shashir as an API thatI ask questionsto and yeah so um so sorry if I'mpivoting the topics kind of hard youknow I wanted to ask about the kind ofstructured output parsing I know this isa pivot in topics like you know peopledo things like look for like back tickback tick back tick Json and I'm curiouslike what kind of stuff goes into thegorilla uh for doing that kind of makingsure it follows the uh this the syntaxyeah so I think this is actually a Quiquestion Conor um what we think well atleast what we are currently thinkinggorilla is like it's definitely notcompatible with gbd4 because gb4 is umwe comparing to gorilla is like a superagent or it's more like a generalintelligence bot that can do everythingbut this has good things and bad thingsgood things is like uh it can doeverything basically whatever you askchat GPT or gbd4 it gets you some kindof pretty good response but one of theum this advantage of that is um it's itsoutput is very diverse like for exampleif you ask it's um if if you just chatwith them every time usually if youdon't adding a specific deterministicsampling uh to G4 every time output iskind of is from different structuredifferent content but sort of answeringyour same question it's like like morelike natural language but this thing canbe a little bit tricky for actually ifyou want to generate Json files forexample or if you want to generate APIcosts because you need to follow theexact syntax and also you need to getevery domaincorrect so what we think is like uh forthe first thing is like fine tuning or aspecial model for this structure mayhelp a little bit because now the modelknows I need to follow specificstructure and I don't uh um like alsolike gorilla is doing right now itdoesn't care about maybe chattingcapability right now um so it it knowslike here is a structure output and uh Ineed to get the structure correct alsothe second point is with this retrieveraware training you're providing somedescription of your output like themodel basically reads documentationknows what the structure should be likein your outputs so the model should havea little bit more context about howoutput is structured and getting thesethings more reliably and clearly betterthan in my point of view like a generalchatbot although General chatbot arekind of can they do this task in apretty good manner I think well that'skind of the that's something about thegeneral chatbot and then like okay sothere's this idea of reflectionprompting where I uh you know like I hadit right at we query it didn't executeand I show it the error message and itsees the error message and goes oh sorryand here's the correct one and I I worrythat if you fine-tune the model in andcompress it you might lose the abilityof it to do that kind of like reflect onthe error message unless you had anothermodel that's been specialized on lookingat the errormessages yeah I think I think that's agreat question honestly but I um I thinkokay my actually to my study of the uptoate models uh even GB even chat gbt isnot good at this reflection like GPT 4is very good it's to some extent muchbetter than GPT Chad GPT 3.5 because I Idid actually did some of the studies onthe big bench tasks from the chat gbtpoint of view the accuracy improves fromI say 20% to 40% after you output thearrow messagebut for gbd4 it actually improves from20% to 60 or 70% so I would say this isa very open like a um research questionhere on how to on even how to get modelsto reflect itself reflect its answersand the getting the correction partbased on the error message at least forthe open source models because we don'tknow how open I did that but this isactually a huge research question so weare we one way is to imagine you have aseparate model that can do this taskanother way is how you can also in themeanwhile not only teach the model to dothis structure output but also in addingother capabilities of to the model thatis crucial to your tasksolving it's also something like we'rekind of exploring as well yeah I thinkit's kind of like well that last thingyou said about like the adding newfunctionality and kind of like themaintenance the continual learning Ithink it all becomes so interest I thinkit becomeslike uh novel in this particular kind oftask compared to most deep learningtasks because you have like kind of liketest cases like past fail whereasusually the generalization testing forcontinual learning is so abstract kindof but yeah I think all that is justyeah really interesting how it will beable to reflect I know there's likepapers where they like have a they trainlike a code repair model where theypurposely break the code and it learnlearns those kind of differences andyeah all all that kind of discussion isreally fascinating um so awesome socould we maybe conclude with kind oflike some like what's on the horizonlike what kind of things are you guysjust thinkingabout yeah I think uh one thing that wewant to like Explore More uh is thisthing that we touched upon in our paperwhich is uh hallucination which we knowthat it's a big problem for llms and Ithink with you know like if you asktoday oh how D before hallucinatethere's no good answer right uh there'sno number as such it's mostly peoplehave objectives so we with abstractsyntax Tre we have like a clear PL basedapproach that you can vure hallucinationso that's something that we want to likedouble down and explore more uh and seeyou know what can we learn from it howwell can we extend it and then retrievala training is another approach uh whichI think has shown a lot of promise forus uh with apis and just doubling downon that and trying and seeing howgeneralizable it is you know does ithold as we scale beyond what we have sofar and then besides that I thinkthere's just like a lot of inboundinterest on you know what apis do weinclude uh and then the differentmodalities to like surve it like weinitially had a collab notebook that youcan talk to the model and then a lot ofpeople were like hey can I try it uhinto my workflow so we gave came up withthe CLI tool and there's a spotlightthat we just doing some finishing t onthat we want to get into people's handsyeah so different modalities how peoplecan you know if you think of it allthese are just different ways to useapis and once you have the pipelinebehind then you can like build this butotherwise yeah we're committed to theopen source project uh so if people wantto contribute uh we'd love to havepeople on board and it's yeah it's likea lot of it we're just listening to thecommunity from our GitHub from ourDiscord and then just uh taking it onestep out atime yeah I hope uh I hope we we arefirst WEA but I do also hope thispodcast inspires more people to addtheir apis to this because yeah I'm soexcited to see how this kind of yeah theAPI Zoo develops and all the research onwhat happens as you continue to scale ityeah those are all really interestingquestions t let me let me get yourresponse as well on the same question ofum like kind of the future directionsthat inspire you the most yeah I think aBea down top a little bit adding sh'spoint is like uh we have already we havealso received or a lot of the greatadvice from the I think either GitHubissues or the Discord communities arecoming to us so that's also kind of uhshapes what we are heading to to someextent but in in general I feel likethis U RM like agencing is veryinteresting but we have a lot problem tosolve to make it fullyautonomous and also fully reliablesuccessful uh agent for RMS and a lot ofthem including like long contacts alsomemory uh sorry the memory of theprevious stuff and also tool usage andchaining together apis these are likealso great research and open openresearch questions and we kind of wantto also explore how gorilla can bettersupport Al not only uh the researchDirection into this area but also someopen source Community like whether theyadopt gorilla as um a back a backend themodel or it gorilla as one component asyou see moving forward in the future tobuilding this RM agents to for tasksolving yeah I mean I I I hope thisisn't too redundant but yeah like thatkind of long context reminds me again ofthat like retrieve enough API referencesfor how to import data into WEA and thenretrieve enough enough API referencesfor how to set up the query engine andllama index and then combine that intojust generating doing the whole entiretask and one kind of forward pass andyeah and then that kind of I love thatkind of thinking of like what how howwill it fit into the existing ecosystembecause you know like I I imagine likewhat the I think llama index calls adata agent or Lang chain is reallyfamous for this kind of agentorchestration I think it could eitherjust be like the future of Integrationsis all these things have like a languagemodel in front of them that translatesnatural language into the thing but thenyou also kind of have to have somedescription of like what you could dowith you know like you have to be likeUA could do this these kind of thingsbefore you even would think to formulatethe question like how do I bm25 searchand then rerank with Co here like itwould need to have some description ofthat but yeah amazing shashir and Tgenen thank you so much for joining theWEA podcast I think you have such anamazing project gorilla one of thecoolest projects I've ever seenespecially in the space of agents andlarge language models so much funbuilding this for the we8 apis and Ihope people will find this interestingand yeah I can't wait to see where thisyou know how thisevolves yeah thank you Conor it's agreat yeah and thank you so much Conorfor doing this it's always a thrillchatting with you so looking forward tochatting again", "type": "Video", "name": "Shishir Patil and Tianjun Zhang on Gorilla - Weaviate Podcast #64!", "path": "", "link": "https://www.youtube.com/watch?v=HUtYOLX7HZ4", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}