{"text": "Thank you so much for tuning in to another Weaviate Release podcast! Weaviate 1.18 is packed with new features! Bitmap ... \nhey everyone thank you so much forwatching another weeviate releasepodcast I'm super excited about Ouija1.18 the big theme of this is beingspeed memory savings some uximprovements like adding filters tohybrid search uh so I'm super excited towelcome we've a CTO and co-founder Eddieand dylocker to explain some of the newupdates to Eva 1.18hey Connor thanks for having meawesome so we have such an exciting listfrom bitmap indexing and update to hswwith adding product quantization andthen the wand algorithm for bm25 andhybrid search so can we kick things offby diving into bitmap indexing andwhat's new about that yeah sure bitmapindexing is is one of those things thatthe first time we saw it was almost toogood to be trueum I think at some point I I tweeted outwhere we had like a thousand times aspeed Improvement on filter query andthat was not just some marketing stuffthat was really we had a filter in aspecific combination on 100 million uhdata set where a filter could take uh Ithink something like five seconds andnow that same filter would take fivemilliseconds so it's really a 1 000times Improvement and the idea isbasically we use for for filtering weuse the inverted index and the invertedindex is basically the the ground truthof what is allowed or disallowed andthen we pass that we call internally wecall it an allow list we pass that allowlist to the hnsw index and say like heythese are the X number of objects thatyou are allowed to to use in your searchbasicallyum and the problem there was if a filtersuddenly matches the entire database on100 million objects then you would haveor you would spend so much time buildingup that filter from the inverted indexthat all of a sudden like even if thevector search for for a filter thatmatches the entire database the vectorsearch doesn't really care right it'slike it's almost the same as anunfiltered one or it is the same asnon-filtered one if it matches literallyeverything in the database but that merefact of building up the filter that tookso much time and then we thought okaywhat what's going on what what is uhhappening with our currentimplementation and what could we improveand we came across roaring bitmaps whichis basically a a perfect sort of fitbecause bitmaps or bit sets in generalare made exactly for this like issomething contained yes no and uh itworks with with basically withincreasing IDs which is exactly what wehave because with the inverted indexalready so perfect fit only problemthere wasum that sort of if you store your yourinverted index in a specific way andthen you convert it into a roaringbitmap which is what some otherdatabases do then you still have thatcost of storing it in a in a differentway basically you still have thatretrieval cost and we said hey there'sthis one thing and and that's that'sanother tweet that I put out where atsome point I said like we made thatcrazy decision to basically buildeverything from scratch in nvidate andand that is one of the points where itreally really pays off right now becausewe just put those roaring bitmapsstraight into the storage layer like inour LSM store itself and that means wewe don't have to do any kind ofum and he kind of retrieve then turninto a bitmap so so so for exampleum if you you could do it that way ifyou had um say a classical storageengine that would just Store The Roaringbitmap then you could still sort ofretrieve the Roaring bitmap and youcould do fast intersections like for anand or or operations once you have thebitmap that would still be fast butyou'd always have that that cost upfront but because we could build itstraight into the LSM Store that cost iscompletely gone and that gives uslatencies in the in the single digitmilliseconds for that that Filter partso I think on the the 100 million was umour evaluation case because there beforewe ran into those five second latenciesand then on that same case now a simplefilter that matches everything issomething like a millisecond or maybetwo and then even if you have like somecomplex operations like like rangequeries or or merging different filtersthis and that or that like with multipleoperands that's all super fast right nowwhich is is incredibly coolum one more thing to say about thisum of course this is this is a verydifferent way of storing and handlingdata in VBA in 1.18 than it was in 1.17so listeners might now think wow what doI have to do like is that is that goingto break my my entire VBA instance thegood news is no it's not so if you don'tdo anything if you just upgrade to 1.18it will just fall back to what it'salready what it's already used to butthen you also won't have the speedbenefits but we also have a migrationoption which you can basically run onetime you just start a bb8 with an optionsay like hey migrate my my index is toRoaring bitmap indexes and then it willrun through your objects once basicallywith the first time it starts up and vv8will be in in read-only mode during thatphase because of course when it rebuildsthe entire index then you can't haverights coming in but you can still useit normally it's it's only read-only andonce that is complete a readout onlymode is gone and you have the benefitsof super fast filters in VBA 1.18 withyour data that you imported in in 1.17. yeah that's extremely interesting andyeah that detail is super cool that youdon't that you can just kind of updateit and um yeah so maybe kind of comingback into the application and motivatinga little further I remember like readingyour article about pre-filled aboutpre-filtered uh Vector search and 50milliseconds and this kind of thing andI always thought initially this idea ofadding symbolic filters to the vectorsearch was such an interesting idealearning more about how you use thisallow list structure with the hsw likehow technically that's implemented somaybe kind of talking a bit about theapplications and the tests a little moreum I really like these things like whenwe interviewed Sam bean from you.com hedescribed this idea of like a verticallyintegrated search engine so say you wantto search through just Reddit or justWikipedia that's one case where you thenwould put this filter on the vectorsearch and maybe if we could just talkthrough some more examples of filteredVector search and what that looks likeyeah that that's a great exampleum one that I always think of because Ithink where where users are most used tofilters is e-commerce like if you ordersomething from a web shop you wouldlet's say you would filter the pricerange because you want your object tomatch a specific price range or youwould filter it by a specific uh productattributes so if you're looking for anew uh VBA t-shirt it has to be navyblue and then you put navy blue on itand then you'll you'll get the the rightoneum not not for me I only wear blackshirts I guessum no but but these are these are thekind of applications where users are soused to applying filters maybe withouteven being aware of it because it's justit's just natural and then yeah as yousaid I really like this idea of having amassive data set and sort of narrowingit down on the Fly you're saying wellnow I just want to filter by yeah onlyonly search through through Reddit forexample and um by having that that sortof big Vector space and having theability to set those filters on the Flyyou also don't necessarily need to knowup front right because you could alsosay if say a vector search enginewouldn't support filtering you couldjust say okay I'm going to split it upup front I'm just going to here is mycollection for Reddit here's mycollection for uh I don't know the nextthingum and then you search them one at atime but that only works if you canpredict entirely what these kind ofcombinations are but if you candynamically sort of combine thesefilters and that is also something thatthat that vv8 already supports but thatwill be way faster with bitmap indexingjust because it's so cheap such a cheapoperation to do like an intersection ona on two bitmaps basically so you can dothat dynamically so it gives you sort ofmore uh flexibility later on like yesthere are cases where you maybe want tooptimize something by splittingsomething up up front like I'm not notsaying that those don't exist like inthose hyper optimized cases for when youuse case but in the general just throwsomething at it let VBA deal with it andfigure out what you want to do laterwithout being sort of blocked by aprevious decision that's that's nice andthat's going to be much faster now thanit was beforeyeah that example of uh chainingtogether the wear filters is sointeresting like uh Navy like a t-shirtnavy blue uh price between 20 and 40dollars I'm not sure how much a sure itcosts but but we're using my shirt butyeah so another question I got uh when Iwas at the New York Meetup we get Meetupwas about role-based access control uhwould this enable thatinteresting interesting uh question yeahso so yes and no soum thereif you want to door it depends a bit sort of where you doyour role-based access course so maybefor for people who aren't awarerole-based access control is basically avery fine-grained Access Controlmechanism where different users havedifferent roles and then one role grantsyou rights to specific things sobasically by default you have no rightsto do anything but then you could haveright it could have specific roles andbasically through those roles youinherit permissions to to accesssomething whatever that something isthat could be something in in thecontext of of the application could besomething in the context of a vv8basically a specific object so if you doset such a property on your vv8 objectand then in your application you wouldmake sure that youum that you set those filters to matchthe specific either the specific rolesor the specific permissions you coulddefinitely do that with with thosefilters the sort of downs are maybe notdownside is just so if it's a it's anengineering decision and it hastrade-offs and basically what you needto do then is make sure that the usercan never find a path where they canbasically skip that kind of filterbecause like if if for example there wasa way that they could all of a suddenhave an unfiltered search and they wouldthey would search acrossum basically everyone's data which is ofcourse what you want to prevent so umdepending on your kind of securityrequirements it may also make sense tohave the the role-based access controldirectly in the database and not sort ofon top of it but that that that'sbasically that that you need to decidethat from a use case to use caseperspective perspective of how you wouldwant to integrate this this by the wayalso a question that also comes up umevery once in a while and I've beenmeaning to write a blog post about itbut I haven't yet is multi-tenancybecause I guess sort of the therole-based access control is verysimilar to to the multi-tenancy casewhere you would haveum say your users are grouped bysomething and then how do you representthose user groups or their companies orwhatever it is that Associates them toone thing how do you group that in bb8and typicallyum what we do there is we do it on a ona class basis because that sort of givesyou and and that's why I'm bringing thisup as opposed to doing it in a sort ofMonolithic large class and then setindividual filters if you have it perclass then you have that separation likethe the way that a class is created inmediate it's very it's like everythingis isolated basically it's it's aseparate folder on disk it's separatefiles on disk and there's basically noway that that one tenant could influenceanother attendantbut that said multi-tenancy is also notthe exact same thing as a sort offine-grained access control so but butthese topics overlap so I thought thatwasthat would be worth mentioning as wellat that point yeah that's extremelyinteresting so I think that's a greatcoverage of uh bitmap indexing um youknow beginning with the technicaldetails and then you know talking aboutthe applications the filtered search andI yeah just I think it's important forpeople to know that you can filter thevector search it's not just Vectorsearch you can also add these symbolicproperties add things to your data likeyou would with any kind of datamanagement system and you can achievefaster Vector search by filtering withthe properties and that's probably oneof the most exciting things that we'vein my opinion I love this kind of filterVector search thing uh so so thenstepping into the meat of the vectorsearch the vector index so H and swpqwhat does product quantization add tothe tableyeah such a such a cool big topic andI'm so happy that we we finally have theuh the first release so I think we weteased something late last year alreadywhen when all of us were together inItaly and this was one of our ourpresentations that we had thereum where the overarching goal isbasically to reduce the operating costwhich is mainly driven by by memoryconsumption so sort of goes hand in handlike if you want to look at it from Techperspective we want to reduce memoryusage if you want to look from thebusiness perspective we want to reduceoperating costs but really it's the samethingum that was driven by by sort of okayhow can we get the the usage downbasically without without sort of anymaking any sacrifices I mean what youcould do is turn off the vector indexlike that would that would reduce yourmemory index but it would also make itkind of pointless to to use VBAum so so yeah how can we give the samekind of uh uh quality to the user whilemaking it a bit cheaper to run and therewe have basically this this two-stepapproach to it in hnswpq is that thefirst step the two step or the secondstep starting with the the sort oflonger goal is a fully disk basedsolution so disk based solutionbasically means what's on disk doesn'thave to be in memory so therefore it'sit's cheaper and ssds are fast and ifyou optimize it for ssds there arecertain ways where you can you can makebenefits off those disks and still havea very similarum experiencethat said there's also sort of like youyou can you can never run any kind ofprogram without memory right like ifevery little thing was loaded from diskthe minute or the second or themillisecond or nanosecond that it wasused it would become very very slow soyou can basically put parts to disk andyou keep some parts in memory and putsome parts to disk and the kind of ideain any disk based system so so Abdel forexample published this comparison ofvamana which is what what Microsoft'sdisk and uses which technically is quitesimilar to hnsw because it's also graphbased single layer graph instead ofmulti-layered graph but it's still stillvery very similar so basically with allof these systems you need to keepsomething in memory and and the idea isyou keep sort of something small andcheap in memory and have the largeinexpensive stuff put to to disk and nowto loop back sort of what is the thesmall and cheap stuff that you can keepin memory and what you find in all ofthese these ideas is compressed vectorsand this is where product quantizationcomes in so we had matiz Do's on on thepodcast uh who which is basically justdiv dive into into product quantizationso he explained this way better thanthan I could and then I could in in like30 seconds but the general idea is thatthat product quantization is a form ofcompression it's lost full compressionso it's not lossless compressions Lostfull compression and you can tune it umin in the simplest case you would haveum a single float 32 Dimension which waswhich originally in the continuousVector is four bytes would be turnedinto a single byte so we you'd have afour to one compression but then you canyou can basically compress it further byhaving a multiple multiple Dimensionsper segment so you could get to likeeight to one sixty to one thirty two tooneum and this comes at the cost ofdropping recall so as with anythingthere's some sort of a sweet spot whichis if you if you want to have the exactsame kind of quality as you have withhnsw right now then The Sweet Spot isprobably four to one compressionum but if you say well I care less aboutrecall I care about running billions ofvectors cheaply then maybe your personalsweet spot is at eight to one or sixteento one or thirty two to one and whereabdell is currently working on a blogpostum illustrating these these kind of kindof trade-offs anyway long story shortum compression is a vital part of anydisk based system and we we thought wellwe we we're currently developing thisdisk based system and it has a certaintimeline but can we create value for theuser sooner than that and then wethought like wellhnswpq is basically half of this picnicslike the 50 of this skin and it has thecompression it still has the the uh thevector index and the only differencereally is that the the vector index isstill in memory and not on disk but thevectors if they are compressed four toone then fictional example let's sayyour current memory usage is 10gigabytes of those 10 gigabytes two isthe vector index and eight are the thevector embeddings thenum and now I'm glad I chose roundnumbers that are easy to calculate thenif you compress those eight gigabytes ofvectors uh by four to one and then theywould turn into two so basically your umyou still have the two gigabytes for thevector index plus the two gigabytes forthe compressed vectors so instead of 10gigabytes overall you now have fourgigabytes so you basically had a sixtypercent reduction in memory usage andfour to one is such a low compressionthat you're probably not even going tonotice the the the um the drop in recallso it's like almost almost free almostfor free you've got a 60 reduction incost and then said you can drive it evenfurtheryeah that's incredible and ABDO has donesuch an incredible job with this blogpost I'm not sure if this is uh the blogpost is published when we're publishingthis but I highly recommend peoplechecking this out uh this blog postreally helped me firstly understand thememory requirements of hsw uh the blogpost describes the calculations of uhwith hnsw you have this Max connectionsparameter and then you have to storethis number of parameter uh connectionsand with like n16 and describing thedetails of what that creates an overheadas well as the compressed Vector as yourcalculation with the eight gigabytes twogigabytes and that reduction um yeah andthen I really liked what you said aboutlike if your goal is just to run abillion vectors compared to a millionwith the recall trade-offs uh basicallyyou have this decision of whether howyou want to group the vectors so like ifthis is a 32 dimensional Vector you youknow segments of two right and so that'sthat's how whether you increase thatyou'll compress it more but at the costof lower recall and it comes back tothat I think a n benchmarks thing youdid with the you know showing the recallof approximate nearest Neighborsyeah I think all that is just sointeresting um something I'm reallycurious about is explaining further theum the K means and how that's used toCluster the vectors and kind of what theoverhead and the thinking is behind thatyeah so for for the compressionalgorithm basically to reduce the amountof data you need to sort of build groupsyou you just uh said that example oftaking two dimensions and putting theminto into like groups of two so then thequestions becomes what identifies agroup like how do you pick your groupsbecause you could pick them very verybad basically where the distance betweentwo points in a single group would bevery large and then if you put all ofyour your groups served on top of eachother in a graph all your groups wouldsuddenly be identical and then you'dhave the problem that that well what'sthe point of having this many groups ifthey're all the same so basically youneed to to pick your groups for andwithout going too deep into what uh howproduct quantization works under thehood but basically you need todistribute your data in groups that haveno overlap and where something that'swithin a group is actually similarbecause if you if you use that forapproximationum then yeah if if it's dissimilar thenbasically you you that's why you recalldrops and k-means is a very simpleclustering algorithm to that basicallydoes exactly that so if you imagine allyour your vectors like a 2d graph plotit somewhere there are naturally goingto be clusters and then k-means is justan algorithm that identifies thoseclusters and it's it's by no meansperfect but um it has like a an exitcondition basically where it stopsrunning if it can't improve furtherum and then you have ways to toum sort of run it over and over again toto find like the the the best possibleclusters and that is essentially what'sused in PQ these kind of kind of it'slike the I would say the initializationin PQ is is this K means uh or these Kmeans clusters because these clustersthen represent the individual segmentsin in um in product quantization and uhthen something that that I think thatwill also be uh mentioned in uh abdel'sblog post or has been mentioneddepending on whether it's been publishedalreadyumyou don't need you don't necessarilyneed all your vectors to produce good PQproduce a good PQ code book or good uhPQ clusters so in the example that heruns in his blog post I think he uses 20of the data and um then it runs underthe assumption that the remaining 80 ofthe data is distributed in a similar wayas the initial 20 and like this thisassumption becomes true depending on thesize that data set and of course if youif you think of umyeah if you think of your your data setin real life topics if your first 20happen to be aboutum navy blue vv8 t-shirts and then yourremaining 80 percenter all of a suddenabout a car parts or somethingthen that distribution that thatassumption doesn't doesn't hold true buttypically that's not the case liketypically you have like a slice of yourdata that's somewhat distributed andthen if you add a like a light bluet-shirt then it makes sense that thatyou would find the existing group forfor the light blue t-shirt and then ifyou add a new uh I don't know headlightthen the headlight the LED headlightwould be close to the thewhatever incandescent headlight that'salready in the not sure if they're stillused anymorebut uh yeah it kind of runs under theassumption that umthese clusters still make sense andtypically they do which is niceyeah that that notion of likedistribution shift and how it applies toVector index structures are superinteresting I've read this paper Ooddisk a n that yeah touches on thisproblem and I definitely think that'llbe something that uh to keep an eye on II found that find the k-means thing tobe so interesting uh like for example wewere comparing k-means with umap on ourBert topic podcast and in the case ofBert topic you're trying to ClusterVector spaces to understand thesimilarity between clusters so uh sok-means has a bias on trying to evenlydistribute the space with the centroidswhich makes a ton of sense for productquantization because you're trying tocompress the vectors with the centroidIDs so it works great for that whereasumap is better for like if you want tohave some odd shape where Martin usesthis example where it's like a circlewith a dot in the middle and K meanswould just try to like cut that uprather than umyou know clustering the circle aroundthe dot so it's very interesting tothink of the trade-offs between theclustering algorithms is very cool tosee the k-means implementation in goLang and leviate and seeing theclustering coming as a part of thevector uh analysis stuff as well so soawesome so I think that's so excitingthe opportunities with reducing thememory requirements of vector indexesand yeah all that making it moreaccessible to create billion scale maybeif we like dream a bit about this likehow much how much can these kind ofsavings help people with you knowscaling up their clusters or the thingsthey imagine doing but limited with thecost and thus needing optimizations likethis yeah yeah I I think the the biggestuh sort of enabler or this is going tobe a big enabler for cases that don'tnecessarily have a lot of traffic buthave large data sets so if you think ofthe other data let's say someone'sbuilding a new type of search engine andthat would hit millions of requests persecond they would probably probably notmind that the setup is relativelyexpensive because just to be able toserve millions of requests per secondyou need large infrastructure anyway soit doesn't matter if the memoryrequirement is a bit higher because youhave I don't know tens or hundreds ofCPUs anyway so that kind of goes hand inhand but for those cases that are maybeand I think we also find them a lot inthe sort of more analytical space andmaybe on the research side where youhave a massive data set but yourrequirement is not necessarily to getlike real-time information if the querytakes a bit longer you do it asyncthat's fine your your goal is basicallyto get that information and then youcan't justify having a cluster thatcosts like multiple thousands of dollarsa month then you need a cheaper way andand in that case you're also probablyvery happy to to trade off performancebecause well you don't have that manyconcurrent queries and that is I thinkthese cases are going to be enabledbecause you can easily just say likeokay here 50 60 70 cost reduction andthat's only the first step right likewith um if we get the the go for for thefull blown disc based solution then thereduction will be even further butalreadyum I think we we can enable these thesekind of cases where vv8 maybe right nowwould be sort of a nice solution butjust isn't viable and then it becomesmore viable for for theseyeah that's super exciting uh super coolso if we're pivoting topics a bit uh wehave two more uh like kind of updatethings then coming back into a speedImprovement another algorithm to talkabout um could you explain the cursorAPI and what that adds to aviate yeah sowe have I think in in this release andthe other one we haven't talked aboutyet but in this release we had the twohighest or most requested featurerequests from our community and uh thesecond one that we're going to talkabout later um is now the the highestthe most upvoted one but before that wasthe case this one the cursor API was thethe most upvoted oneum and the the cursor API is if youthink about it it's a super super simpleconstruct but it's so uh useful sobefore the cursor API existed if a userused vv8 as their primary databaseum then at some point they they mighthave a requirement could be for forauditing purposes could be for somethingcompletely different but basically therequirement is how do I go or thequestion that they would ask is how do Iget all of that data out of vv8 againand then in the past we would say wellthat's kind of like maybe it isn'tdesigned to get your your data out maybeit is designed to to get your data inand then search your data and you canlike if you find the right searchqueries you can find everything that'sthat's in that uh database but there wasbasically no no way to get it out andthen um people would try to use like thepagination feature as a workaround butthe pagination is is built in a waywhere basically each each higher pagebecomes more expensive than the last soyou could do that to a certain degreebut then typically after 10 000 elementsyou would run into some sort of an errormessage where V8 would tell you umyou've reached your I think it's calledquery maximum results and you couldincrease that but there's also warningthat that comes with higher costs andthat you shouldn't necessarily do thatand now if you want to get a million or10 million or 100 million objects out ofbasically there there just was no wayand then you could build a workaroundwhere you would every 10 000 object youwould assign a a field to a unique valueso you could set like a a page propertyon your object like a fictional page andthen every 10 000 you increase the pageand then you could set a filter give mepage seven or something and then youcould get those 10 000 that would matchthe the fictional page seven but that'sof course super complex so all of thatthrow it out of the window don't have todo it anymore now we have the cursor APIthe cursor API is a super super simpleconstruct you basically start somewherewith an ID and if you don't know whereto start then you just start withnothing basically with an mtid and yousay give me a thousand objects from thedatabase and then from that list athousand objects they are in a specificguaranteed order and the last one youcan take the last ID and then you canjust take that ID for the next page soto speak to bb8 and say give me theresults after this ID and then you getthe next ten thousand and the cool thingis that this this query has a constantcost so it doesn't matter if you'vealready retrieved 500 million objectsand now you want the the I don't knowhow how many if page basically to getthe number next object it always startsa new sort of retrieval process at thatpoint that you specify and now you canin constant time basically get everyobject out of your database which makesit we've added the backups feature whichallows you to get every object out ifyou want to get it back into Evabasically but now you can also if youwant to pipe it into a different systemlike you could you could use that tostream your data to something let's sayyou would have a specific or let's sayyou want to train a model Based on datathat's in bb8 then how would you get allthe data out of it you get well you cando that now with the cursor API and youcould either do it in one go andbasically just export it and put itmaybe in a parquet file and use that oryou could yeah do it on the Fly and sortof go through the cursor and dosomething with ityeah that case of training the model iswhat inspired me to click on the thumbsup on the on the roadmap thing and uhyeah it's very interesting like gettingthe data out like imagine like just forthe case of you maybe just want to haveyour data somewhere else again justbecause it's your data and you want tohave it as secure as possible and aseffective as many times in as many waysas you can think of I guess but um thiskind of idea of getting the data out forthe machine learning models I thinkthat's so interesting I I also think youcould use we V8 to retrieve the nextbatch of training data kind of similarto Mosaic ml released this streamingdata set thing and I think we could beused in a similar way to get batches ofdata for training so so yeah all of thatI think is extremely interesting um soif we also come in now uh pivotingtopics again um so adding the filters tohybrid search uh maybe first we couldstart with just like what it is and thenI'm very curious what the technicalchallenges behind this wereyeah so this this is the other one thatwas most requested so in in 1.17 we umreleasedum or we had bm25 support before alreadybut I think it was consideredexperimental and we removed that flagand then we said like here it's Generalavailability in in 1.17um but it did not support settingfilters yet so it's exactly the the samekind of use case as you as we talkedabout before on unfiltered Vector searchso same we can use the same example ofthe navy blue t-shirt or combine it withprice tags and everythingum and you couldn't do that on a bm25search and in turn because a hybridsearch is both a bm25 and a vector surgethat also meant you couldn't do it on ahybrid search so in one at 17 we havethis awesome new feature um of hybridsearch which um we we see that it canimprove the results running it over overa specific data set benchmarks to enableit you see that you can get a higherndct score and higher recall andeverything which is super awesomebut now you're missing that kind ofother functionality that Vivid alreadyhas for for Vector search so it was onlya matter of time and um this wasaccelerated by I think our community ofvoting that ticket like crazy and it itreally became the the most upvotedticketum very very quickly andum yeah that's that's in Viva right nowso you can now nothing changes from asearch or if you let me put it this wayif you've used a filter in vb8 beforeyou already know how to use the newfeature like it's literally the samewear filter and the only thing that'sdifferent now compared to 1.17 is thatthat error message goes away that tellsyou uh filtered search is not supportedyetum and then now you can you can do it uhfrom an implementation perspectiveumfilter filtered bm25 search is actuallynot that difficult because we alreadyhave the inverted index which we use forfor Vector search which by the way alsomeans that that these features thathappen in parallel like if you set afilter that's uh that's using the bitmapindex that we talked about before thenall of a sudden these will also now bemuch much faster so there the good thingis that these two parts are a bitdecoupled so that wasn't necessarily A abig change to get them working into vv8however we've also completely Rewrittenthe way that we do bm25 scoring becausein 1.17 the initial release was a umsort of a let's call it a primitiveapproach where we'd literally scoreevery term that was matched um but nowwe've introduced the wand algorithmwhich is um yeah another way to toimprove the retrieval a bit and thenthat tied in nicely with the filtersbecause we just did that that all inoncesuper cool and um yeah awesome so yeahthat's very interesting how the like Iwas very curious like how the allow listkind of concept generalized to the bm25scoring with the inverted index and theother connection to the bitmap indexingthat's also interesting um so yeah somaybe stepping now into the wandalgorithm um I I had to give DimitriKhan credit for he's the first one whokind of taught me about this kind ofidea where he's like oh you couldprobably have some way of uh sorting theterms so when in bm25 you have a querylike how to catch an Alaskan pollock Ilike this car and you like um you knowyou start scoring how to catch with thematching and you can probably you knowhave some efficient way of scoring thedocuments like these have matched somany words so far that it's like highlyunlikely that the match would be highenough so I don't know if that's theexact algorithm behind Wanda could youexplain like uh what what the idea iswith one scoring yeah yeah that'sexactly the idea so you have in a bm25index or in a in a let's say in a infull text search and this is somethingthat traditional search engines havebeen been uh or have provided for forquite some time already now you can alsoget that in in viviate in full textsearch you have specific keywords so soin very simple terms TF IDF or bm25basically rewards terms that are rare Soin the how to catch Alaskan pollock uhthe theum how to is probably super super commonand doesn't really add any any value uhto the the um the search query butAlaskan already sort of narrows it downquite a bit so ideally in your searchand so so maybe to to step one step backscoring everything that's in that termhas a certain cost right so if webecause we use the inverted index thatmeans the inverted index will tell usevery single document that contains aspecific term so for for Alaskan that'svery few documents compared to overallunless your entire database is aboutAlaska and I guess you know that thatwouldn't um be true anymore but but thenyou you'd have another query in thatterm that would be or if your entiredatabase is about phishing then yeahsame thing so so basically there'salways going to be frequent and rareand ideally you want to give more weightso to speak but I'm not talking aboutweight in the sense of of um changingthe calculation because the calculationlike the score is going to be the samebut more weight in the sense of I wantto tackle this first because it addsmore more value and then maybe I canskip something else so that's why it'salso called Dynamic pruning algorithmsbecause you you want to prune the stuffbasically that that you don't need so ifin a classical inverted list or invertedindex a kind of scenario the thedatabase doesn't know upfront whichterms which right like it doesn't have asort of semantic understanding and itdoes with hybrid search because of thewhole Vector search partum but the the full text part doesn'tum so so now you have these like howwhich matches so many documents then youhave Alaska I'm just going to narrow thequery down for for example say it's justgoing to be how Alaska now doesn't makesense anymore of it makes it easier toexplainum that then um yeah basically you havethese mini matches for forum for how in these few matches forAlaska and you know how much each termcan potentially contribute to it basedon uh the the bm25 scoring so basicallythere's a maximum and this is from thistfidf calculation it's also part of bm25there's a maximum contribution that eachterm uh can make so now if you've let'ssay you've not had one but you'vealready started scoring 20 documentsmaybeum and your your top K so basically theuser defined limit is let's say it's 20.so you already have 20. that means younow have 20 scores already so now youknow basically that let's say the bm25score of the the worst of those 20objects that you have is 17 made upnumber now you know that if an object ifa new object cannot reach score 17 youcan discard it and how would you findout if a new object can can reach 17 isbasically you look look at the maximumcontribution of each term so let's saythe word how and this this gets nicer ifyou have a longer example let's just sayI'm going to stick with this how we'llask him let's say the term how has amaximum contribution of three and theterm Alaskan has a maximum contributionof I don't know 15. then if those twoare combined that's 18 that's good butif they're not combined if you only havehow you can no longer reach yourthreshold so basically what that tellsyou and this is everything the onealgorithm does it tells you skip everyobject for how that doesn't also matchAlaskan and and this means that if youhave the these like sort of relativelydense list which is the one with howwhich is dense because there's so manymatches and then you have the sparselist for Alaskan which is rare at somepoint those lists are going to overlapand basically it allows you to to sortof move that pointer ahead to the nextpoint where they're overlap where youhave the the minimum possible score toreach and thenum same same goes on basically let's sayyou managed to skip 5 000 matches forhow because only then you would find thenext ID that matches both how in Alaskaand then after that there's another 5000which only match how can do the samething again in this way you can reducethe amount of scoring drastically likein the most extreme case you couldreduce it to the number of scores forthe word Alaskan and almost sort ofignore the word how but of course if theif if the difference is not that extremethen you still you don't want tocompletely ignore it you just want tosort of yeah not score it if you knowthat it's mathematically impossible toreach a higher score and then you wantto want to skip it and and that is whatmakes that algorithm super cool becausein the context of vector search we dealwith approximate algorithms a lot butthis is not an approximate one this isreally a just a smarter way of scoringbasically in the the score in the end isgoing to be exactly the sameyeah that is so interesting to hearabout this sparse scoring algorithm andmaybe uh talk a little more about as faras vectors but just quickly like I'veplugged in this wand test into the beertest with natural questions and for meevaluating natural questions is 2.6million documents and this time is howlong it takes to evaluate the ndcg of3500 queries and the difference beforeand after wand is like five and a halfhours to like 14 minutes and this letsyou yeah I missed so I was like wow thisis pretty exciting just anytime you seethat kind of thing it's similar back towhen you had the Thousand speed up withfiltersyeah those things are always like theEureka thing to see but yeah I think itis very it's so interesting like um Idid a little research into one and I sawthe paper from 2003 that uh proposedthis and I think it's so interesting tosee it uh still being used and I alsosaw this other idea of splade sparsevectors or used deep learning models touh to create sparse vectors so the ideabeing uh you have how to catch anAlaskan pollock and you put the languagemodeling head on each of the tokens andthen you get a distribution over thevocabulary that comes out of thelanguage model so I think Pollock wouldprobably be the best one because maybelike in addition to Pollock the languagemodel might have thought it was likesalmon that would make some sense rightso it would um so you'd have this sparsedistribution and it would be the samekind of scoring building blocks as faras I understand for uh how you wouldindex those that particular kind ofsparse vectorand then you know retrieve itefficiently but yeah the whole thinghearing about the thresholding algorithmit's all so fascinating um so super coolso yeah I think uh coming out of thesome of the speed things and nowsomething that is into the databasething uh so what's new about replicationyeah yeah so I think todayum like uh depending on on who theaudience is either you have to wait avery long time to to uh to get to theparts that are interested in or they'rethey're going to learn somethingcompletely new because we we have somany like this is such a diverse kind ofrelease like we have we provide value inso many different areas like the thebitmap indexing I guess was sort of alsomore on the database side but maybeeasier easier to to grasp and uh yeahthe theum PQ is sort of completely in the inthe nitty-gritty uh um Vector indexingthing kind of side but yeah coming backto sort of the the good old uhdistributed system kind ofum uh um yeah replication topic so wereleased replication in 1.17 and andsomething that we made very clear in thebeginning is basically this is thefeature set of what replication can doand this is if you if this is sort ofgood enough for you then use it this iswhat we're going to do in the nextcouple of releases and if you have acertain point where you say okay I needthis particular feature then you can youcan sort of start using it that specificpoint it's just going to get better andbetter over again so sort of the theidea is to release this in in chunks orin incrementsum where it constantly gets better andyou don't have to sort of wait over andover again because1.17 probably covered 80 of cases butthen you have those remaining uh 20basically that take take much longer butalso that there may be a requirement forit for some cases depending on what youwant to do with with replicationreplication to me is is such a aninteresting one becausethe the motivation of why someone needsreplication in their database can goanywhere from they have a specificfailure scenario that they need toprotect and where they need to make surethat if a happens the database doesn'tgo down and then a database can stillread or can still write into these kindof things all the way to they need tosign off some sort of a corporate sheetwhere there there's some sort of acompliance policy that they cannot use asystem that has a single point offailure so everything needs to bereplicated and we're really seeing we'reseeing all of those we're seeing likepeople who who need replication for theactual value of replication we're seeingpeople who just need replication so theycan take some sort of box and say likeokay vvn has has replicationum and yeah depending on onum where you sit on that that line Ithink different different points anddifferent features add more more valueum that said that was all these sort ofthe long introduction of how we releasereplication in in smaller chunks butwhat's new in replication in thisrelease is we now now have tunableconsistency for every single input or Ithink almost all endpoints and and thisis um so tunable consistencies ismodeled after Cassandra which in ouropinion like basically we looked at okaywhat's out there in the space and whatbehaves in the kind of way that we wantVBA to behave and then Cassandra withits hyper scale kind of capabilitieswith a very good good role model for forthis basically so tunable consistency issomething that's modeled after Cassandrawhere basically you as the user can makethat kind of trade-off how consistentdoes this read or write have to be andthe the most extreme case would be allwhere you say like you have yourdatabase replicated three times and thenyou make a a write with consistencylevel all that means that request isonly going to be successful if everysingle one of those three nodesacknowledge your your right and if onedoesn't then the request fails but thenyou could also have the Other Extremewhich would be consistency level onewhere the idea is that only a singlenode has to acknowledge right thatdoesn't mean that only that node ownsthe data like the data is still going tobe replicated to the other nodes butlet's say node 2 failed and now it canonly be replicated to node well let'ssay you're hitting Node 1 and it can bereplicated to Note 3 that and node 2 iscurrently down this would still beallowed with with a consistency level ofone so basically in this case your yourrequest would still succeed and that canbe desirable because this gives you akind of scenario where you can stillwrite even if a note is down and whywould a node be down well could bebecause it actually like Hardwarefailure or something is broken but itcould also be something that's that'splanned where it's down for a very shorttime for example because you're doing arolling update so you could say like Iwant to upgrade vb8 from 1.17 to 1.18um then each node would be in this thisrolling restart kind of fashion would bedown for a very short time and if inthat short time period something happensnow you have a full control do you winstrong consistency then you you youprobably right with consistency allwhich means this request will fail andyou have to retry once it's back upagain or you could do it with one wherebasically it will be replicated later oryou could do it with a quorum which werethe idea behind a quorum is basicallythat that it's it's a fancy term for amajority basically so a majority of thenotes has to be present and then if youuse the majority both during writing andreading then you always have toguarantee that that it has to matchbecause if a majority of the nodes havereceived an update and have confirmedreceiving an update then when you readwith the majority there's mathematicallyno way to get the the old stale data sothese are the kind of um trade-offs thatyou can do and and really configure thisthis for your for your needs and thenthere's the the second new part which isread repairs which to me is like thefirst time I used it I was blown away byhow simple it is and how effective it isso if we're sticking with this kind ofsituation where a specific node was downduring an update and you accepted itbecause you said okay my the consistencylevel is say just Quorum or maybe evenone then how do you deal with it whenthe node gets back like because at somepoint that that node is going to be outof date right and if then you you readwith just consistency level one andthere's very good motivation to readwith just one because that means yourthroughput can go up like if you ifbasically every data is alwaysreplicated and you read with just onethen now you have not one node that canserve all the data but now we have threenodes and you could also add a fourthand a fifth and so on so there's there'svery good motivation to read with withconsistency level one but now whathappens if that node is is out of datelike is it if you happen to hit the notethat didn't receive the update you wouldbe serving stale data and you canprevent this by setting a a higherconsistency level of course but alsothis is where the eventual consistencyof ofum a VBA basically you know that thatwhole design comes in if you don't wantto read immediately with the highconsistency level because it has ahigher cost and lower throughput you canrely on the fact that eventually thiswill be consistent and one way to repairthe data and this is new in 1.18 is theread repair in the read repair basicallysays if you query the object with aum let's say with a quorum consistencylevel and VV it realizes that let's saythree nodes and two are queried and oneof them is out of date viviate will justrepair it and VV it knows exactly basedon on timestamps and based on other kindof metrics of what happened DV8 knowswho of those two nodes is basically iswrong who who missed the update and thenif you query it with that read repairby the time that your query is returnedthe data is already repaired so youwon't even notice like you can queryexactly the note that had the stale databut as part of the query and that's whyit's called a read repair basically aspart of reading the data VB had alreadyrepaired it in the background you you'llreceive the right request and that wasthe moment when I tried this out for thefirst time like I tried to tospecifically get my my database in aninconsistent state by actively killing anode then making an update making surethat the node missed it we started itum try to query it and and forgot to toset the the one consistency and thendefault it I think to to either Quorumor all and immediately it was alreadyrepaired by the Moon that I I got theresponse and I was like wow this isexactly how it should be like this isthis is so cool becauseum yeah if you really want to fine tuneyou've got all the ways but also if youjust want your data not to be out ofsync then let's just read it just justlet it repair itself yeah it's amazingand I really liked how when we firststarted talking about um replication youhad like the um the Black Fridaye-commerce example and understandingthese kind of uh trade-offs with readwrite and when you need certain levelsof consistency yeah that read repairthing is so interesting I think thiswould be also a great transition ofyou've recently given this amazinglecture on our journey to build a vectordatabase and go and this is published onYouTube if people are interested inchecking this out um so a question Ihave with uh replication these kind ofthings is um you can touch on whatfeatures of the golang programminglanguage help build things like thislike distributed database systemsyeahum that's nice because my my uh talk wasbasically about what what features of goum are hindering us from building thebest possible database no that's nottrue because it also it also hassolution for all of those challengesum features in in go that really workwell is I think the main two things thatthat um come to my mind right now is oneis dealing with concurrency becauseespecially if you have these kind ofkind of background operations you mayhave to spawn like in in go you don'tspawn a new threat but you spawn a goroutine a go routine is basically like alightweight threat but then you can havebecause it's so lightweight you can haveway more than than actual physicalHardware threats and then the go runtimewill just manage it for you and it givesyou lots of tools to basically make surebecause the moment that you haveconcurrent processes there's always arisk of data races and the whole toolset and go both during development aswell as for for how the language isstructured really makes it easy to writethreat safe or or sort of safelyconcurrent codeum so that's that's one of the partsthat that um really really helped whilethereum the second is the strong standardLibrary so this is something thatdepending on on so I way back before I Istarted writing goum I used node.js because that was sortof the thing at the time and and I alsodid some front end work and then somepoint moved into back-end work and thenit was yeah it was node.js and innode.js you have the exact same oppositethe exact opposite sorry um so sobasicallyanything that you do you have to importa package there was this I think it wascalled the left pad Fiasco at some pointwhereum a day a package that would pad astring on the left side which is likeone line in any language even inJavaScript that's just one line that wasan external package and then thisparticular package had a securityvulnerable or I think it wasn't asecurity vulnerability in this case Ithink it was just deleted I think it wasjust the author decided to delete thisthis package uh but the problem was thatthousands upon thousands of packages oror a node uh programs and packages thatwere used everywhere in productiondependent on that one package and all ofa sudden all the bills started failingum so coming from node like way way backin the day like I was an early adopterof go so that I don't even remember whenthat when that was but it was reallylike like way back coming from node togo seeing how strong the standardlibrary and go is and not needing thesekind of third-party dependencies and andthese these kind of third-party packagesthat was such a such a both aneye-opener that you can do it just withthe standard library but also such anenabler because there's all of a suddenyou don't have to learn framework afterframework after framework anymore youjust know that the the standard libraryof go and it is it is somewhat sort oflimited but over time you you yeahyou'll feel like you know all of itthat's probably not true it's probablyway bigger than what people typicallyuse but um it gives you a nice yeah sortof the the com commonly use things youjust know how to use them and don't haveto look stuff up and just by either byjust typing it or relying maybe on youryour code editor IDE to do someautocompleting you can build basicallyan entire database and that's that's noteven a fictional example because that'sbasically what we we do in in V8 and toto loop back in the beginning when wetalked about bitmaps we said that wetook that crazy decision to um to buildeverything from scratch and not havemany external dependencies and thatworks super super well with go because Ithink that's also the philosophy and gothat the language is so powerful on itsown that you don't need thesethird-party tools but just with thelanguage provides is there and verypractical example in replication becausewe're we're dealing with the distributedsystems where nodes have to talk to eachother there's so much Network trafficgoing on and then there's multiple waysof how to do that um but basically beingable to do all of that just with toolsthat the standard Library provides is issuper powerful and really he keeps theiteration time down so those would be mymy two favorite points about go um for afeature such as replicationyeah that's that's so interesting it'sso interesting like going into thegolang and yeah I mean the whole end toend as we start off by talking about thebitmap the P hsw like vector search deeplearning and then coming into thefeatures of golang It's amazing Andum maybe one other detail on your talkthat I was curious about is um see asyou mentioned you you're talking aboutthe hindrances of going in them and onething was the um the stack versus theHeat memory escaping to the Heap and andI know we talked about the garbagecollector uh maybe talk a little moreabout like the state of I know the gomem limit and all these kind of thingsand like uh how that's been because Iunderstand that it's getting better andyeah yeah let me try to answer that fromthe perspective of a vv8 user amazingbecause I think the vb8 user has twointerests well or basically in in V8 butin turn then also in in go uh one is theapplication shouldn't just randomly runout of memory like that's that'sbasically the worst case you you sizedeverything correctly you plan foreverything and then all of a sudden vbhjust goes bam out of memory kill and theother is you want high performance andand these these things are closelyrelated becauseum performance in go often is a topic ofof memory management which may not besuper obvious because if you think ofperformance you think like thebottleneck is your CPU right like ifyour CPU does this many things per cycleuh then it's it's fast and if you canreduce the amount of things that it hasto do per cycle or I don't know use asmarter way of doing it like in the talkI talked about simd for example whereyou could do eight operations for thecost of same operation that is what youimmediately think about but in a garbagecollected language like go often it'sit's not even it's not CPU but or it istechnically still CPU bound but becauseof something that you do with memory andthat is where where memory allocationscome in and um the idea between or thesplit between the stack and the Heap thestack is basically represents yourfunction Stacks so as you move throughfunctions you move through that stackand you have variables with a very veryshort life cycle they they are as youstart calling the function basically thevariables are created or are avoidingthe word allocated right now but they'rethey're assigned basically and then whenthe function is over those variables canjust go away so they have a very fixedlifetime whereas the Heap is everythingand that's why go uses the term escapingwhich I kind of kind of like because itescapes that clear function stack andnow and this could be for examplebecause it's shared between differentfunction calls or because the lifestylecycle is meant to be longer than theseindividual functions called so basicallysomething escapes and this escapingmakes it way more costly so both theprocess of escaping because now the thego runtime Master like okay this is thisneeds to be tracked basically and thisneeds to we need to find some spacesomewhere on the Heapum but also then it needs to bedeallocated again because it's it's it'slike now now that it's escape thefunction stack it's no longer in thiskind of predictable life cycle of whencan we free it and if you couldn't or ifyou would ever lose that kind ofAssociation of how it could be free thenyou'd essentially have a memory leakyou'd have memory that's assignedsomewhere that you don't need anymorethat's still around and and then youryour memory starts ballooning and youdon't know why and that's that'sum yeah there are some things youdefinitely want to avoid and then toavoid this basically go use the garbagecollector it's a very good garbagecollector but nevertheless somethingthat's allocated on the Heap is alwaysslower than something that's that'sallocated on the stack so this is thethe kind of perform performance abackgroundin this kind of setting but then I alsosaid you don't want your application tojust randomly run out of memory and thiswas the the biggest change in go 1.19I'm almost getting confused with theversions of like bb8s at 1.18 right nowgoes ago is actually at 1.20 right nowat some point we have to start releasinga releasing V8 faster than goes so wecan hire her numbers which I think thatthe bb-8 release Cycles are way fasterso that's only a matter of timeum but yeah in go 1.19 uh the go runtimeintroduced this go mem limit thing thatwe have a blog post aboutum also and go mem limit does somethingthat's that's actually is one of thosethings that are super simple in inhindsight or once you know and it'ssuper simple go mem limit just says thisis the limit of memory that you haveavailable in the garbage collector willtry to respect that limit and now thequestion is like Why didn't it beforethat like why wouldn't the garbagecollector do that before and before thegarbage collector had um a tuningparameter that was relative to thecurrent Heap so basically in the defaultwas a hundred percent which would meanthat if you have a machine with 64gigabyte of memories and you currentlyhave 33 gigabytes of memory allocatedthe next hundred percent increase wouldbe to 66 gigabytes bam out of memory soso now you're at like 51 usage and justbecause of the way that the garbagecollector would try to allocate or tryto umThe Collector doesn't allocate memorybut it would just delay running again sobasically now would say like okay I'mgonna run again once the memory is at 66gigabytes but your machine only has 64.so that that doesn't work and all thatgo mem limit does is basically give thegarbage collector that kind of hint ofwhere the the limit is and go call thisa soft limit because it's really it'sjust a hint to tune the garbagecollectorum to to run fasterand now the garbage collector basicallyknows okay I'm at 33 gigabyte my limitis 64. so I'm not going to wait till 66but maybe I'm going to run at 60 alreadyand all of a sudden like you you madeuse of that memory that that memoryis there to yeah to serve whateverpurpose you want whether it's apurposeful Heap allocation so forexample in bb-8 uh the vectors or withagents wpq also the compressed vectorsthey stay on the Heap because that'swhat we want right we want them to stayaroundum but something that we do for examplea filter that's used as part of a partof a single call stack that doesn'tstick around so we don't want that thaton the heat but either way no matterwhether it's intended Heap or unintendedHeap now with go mem limit vv8 can canor or any Go app basically can respectthat and make sure that it doesn'tquote unquote accidentally run out ofmemory again because that's really whatit was like it it was it just set thewrong target basicallyand that's that's prevented with thatand I think at some point we also addeda a feature into vb8 specifically thatmarks your objects as read-only if ifthat if you get close to that thresholdso I think it's it's getting more andmore like as vv8 improves and as as goimproves it's getting more and moredifficult to actively manage to run outof memory which is awesome for a userbecause that essentially means it's it'smore stable and and harder to kill andif you still manage to kill it then youhave replication and then all is goodbecause that that one note death doesn'tmatter because it's replicated soyeah it's so amazing it's so amazinglike the depths of the languages thatbuild databases the features ofdatabases and then the whole searchtechnology more broadly and uh soawesome Eddie and thank you so much foranother weeviate release podcast it'svery inspiring for me working on Wi-Fito hear the depths of your knowledgewith all these things and I'm sure itinspires people who are using levatoralready or are interested in checkingout alleviate and I think we've 1.18 ispacked with so many awesome featureswith this bitmap indexing to have thesefilters just as these like thousandtimes faster is obviously like just soincredible the wand the way that speedsup bm25 and sparse search I've seen thatmyself it's incredible and hswpq allthese things replication and that's justso exciting so Eddie thank you so muchthank you for for having me and also bigthank you of course to the entire teamthat that actually built this I am justhere basically summarizing everythingthat that we've done as a team in thisthis print but of course we have theseindividual experts on on all of thesetopics and and then that that allows usas you just said to have a a releasewith so many different topics thatprovide value in this is this is reallycool and I'm super happyum with our team and super proud of ourteam so thank you everyone both bothinside bb8 but also of course outside orCommunity for for all the input and fortelling usum what the kind of features you needwhat kind of features you benefit themost from and and yeah any kind offeedback like use vv8 and tell uswhether you like it also tell us if youdon't like it so we can improve it butplease also tell that tell us if you dolike it because that's that's awesome tohearum so it's so motivating both for for meand I think everyone on the team to hearthe success stories with bb-8 and thiskind of there was a tweet the other daywhere uh sort of Father and Son uhpairing did some experiment with with V8and just reading that and reading theactual stories this is so cool to toyeah change people's lives one at a timewith reviateyeah that was an awesome tweet be yeahthe whole the moment of like thefather-son hacking with Ouija amazingawesome thanks everyone for watchingthank you", "type": "Video", "name": "Weaviate 1.18 Release Podcast - Weaviate Podcast #40!", "path": "", "link": "https://www.youtube.com/watch?v=Q7f2JeuMN7E", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}