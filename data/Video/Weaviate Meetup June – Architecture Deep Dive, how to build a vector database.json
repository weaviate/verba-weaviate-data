{"text": "Weaviate is a full-fledged vector database with full CRUD support. In this meetup, Etienne Dilocker of Weaviate explains how ... \nthanks thanks a lot for joining and uhtoday i will asbob just said i will really give you abit of a more of adeep deep dive on uh basically how vb-8works under the hooduh what its architecture is but alsowhat our roadmap isand also focus on the whole aspect ofcloud native a bit moreso why do we do such a deep divemeetup um so as i just said this isreally going to be about moresort of in looking at the inside of bb8uh if you haven't heard of vba did orhaven't used yet um just to let you knowthere's also a new introduction videoout that i bought recorded i thinkuh one or two days ago and that justwent live and it basically shows you allof the things that you can dowith uh vv8 in like a 10 minuteintroductionuh for today i'm going to assume thatyou have a very rough understanding ofwhat vv8 is so that i can umtell you basically how it works and howit works under the hoodso why do we do this first up this isbasically been based on on your feedbackso based on community feedback andthere's been very positive feedbackwe've heard people say that while thearchitecture is one of the reasonsof why i want to use vba or maybethey've even used something else beforebut that doesn'tmaybe isn't compatible uh with what theyexpect forfrom a search engine architecture-wiseso that's very good for us to hearbut there were also critical voices thatsaid well you aren't very open about thearchitecture you should highlight it abit moreor maybe explain the architecture a bitmore so basicallythis is us being vocal about thearchitectureand highlighting what's going on underthe hood so that you don't have to readthe the codeto get an understandinganother thing is just overall sort of ifyou look at the ml and lpfield uh nlp field um and if you look atthis sort of research versus productionthing a lot of projects are in a veryvery early stagewhere basically um the teams at thecompany at large enterprise companiesevery large enterprise company needs tohaveat least one a team focusing on ml stuffand nlp stuffbut a lot of these projects aren't inproduction yet there'smaybe a bit of research going here andmaybe it's because the business hasother prioritiesor maybe because the the quality ofthose nlp tools maybe they're not goodenough yetbut another part of that is also becausegetting stuff to production is very veryhardthere's a lot of things that arecurrently or that that suddenly getintroduced when you want to move toproductionthat simply aren't the case if you'rejust doing sort of a spike ordiscovery with some stuff locally sobasically you can't just take thejupiter notebook and put it intoproduction and even if you could youprobably shouldn'tbut uh the good thing is that there'ssolutions such as bb-8that really are meant for production sobasicallywhat i want to convey today is that ifyou havethose production requirements which canmean large scale it could mean that youneed redundancyfault tolerance it could mean that youhave specific securityuh requirements that you want your stuffto be observable then thatis really what vba is meant for and alsoby beingopen about sort of how we achieve all ofthat and giving you a bit more insighti also want to convey that basically thepeople behind vvatethat they make conscious decisions andthat while we do sort of what we do thatwe reallyalso know what we're talking about so itgives you a bit of trust in us as a teambuilding a solution that's meant forproductionso this is a graphic that i just tweetedout maybe some of you have seen it umyesterday and basically this is a verysimplebenchmark of uh importing a specificdata set into vbaand i will sort of tie this into ourcurrent architecture roadmapof where we are and what's beenhappening but the main takeaway for thisat this point is basically justwe've been improving things and thingshave been going going fasterand basically as you can see on thisroadmap sort of each new version reducedthe time that it took to import a dataset into v8and um yeah you'll see in a second howthat ties into our architecturalroadmap so before we getto the roadmap itself i also want totalk about how data is stored in bb8sort ofat a very very rough aspect like the 30000feet view just to to show you sort ofwhat happens in vbawhen something gets stored and animportant thing or an importantdistinctionbetween vv8 as a vector search engineand as databaseif you compare it to for example just aa an library vba really as a as ayeah as a database it returns the entireobject and this object can beon disk and not just maybe a referenceto that object not just an idbut not just that you can also combinethe vector search itselfwith a structured filter so we call thatscalar search so for an exampleyou could say well give me all the usersthat are close to this specific userwhich would be the vector search partsort ofthe fuzzy part in the vector space butonly if the account balance of that userisin this example less than or equal totwo thousandand basically we can do that efficientlyand not umsort of uh what we wanna do is basicallydo this sort of uh pre uh uhfilter where we say like okay first weto know what those usersare and then limit the vector search tothose users because if you do it theother way aroundif you do a post filter then you firstdo your vector searchbut then maybe none of the results thatwere returned in that limited searchmaybe none of those match the filter sobasicallywe want to do this pre-filtered or we dodo this pre-filterand also because it's a database anymutation that you do so any importanything that you do in in viviate bythe time that we have returned or by thetime vba has returned a successfulstatus code to youyou can be sure that that data iswritten somewhere on disk so itbasicallygives you the right guarantees that youget from a database as opposed to idon't know like a library that wouldonly run in memory for exampleand as a result this means that um whenwe storedata per index so you see here isbasicallyone index that we have per class andwell we'll see this graphic a few timesmore todayum generally there are three partsthere's a vector indexright now the vector index that wesupport is h and swso that's sort of a very common indexsuits areour purpose very well because it allowsmutability it'ssort of relatively easy to customize butalso because we surf the objectwe need to store the object so that'sthe object storage and we need to buildup this inverted index so that'sbasically what allows us to do thesepre-filters that we can then combinewith the vector index so essentiallythese are the three thingsthat we storeso what you see here is an overview of aroadmap and the cool thing about thisis um other than the nice visualizationsthat we havethe cool thing about this is that we'renot starting at step zero right now sobasicallyum yeah you've seen the the uh thegraphic with the import times that we'regoing downum we're already so this is alreadygoing on so some things are alreadycomplete and other things are basicallyin development right nowoh sorry that was that was too quick sohere if we start with step one so stepone the first thing that we we did andthis was also triggered a bit bycommunity feedback soum a few what was it i don't know abouttwo or three months ago i think umwe were trending on github for for acouple of days and a lot of new userscame into vvad and it was really cool itwas sort ofthe first time that we got a lot offeedback like of course people haddiscovered vba before already but thatwas the first timethat we got a lot of users in and theywere able to give ussort of feedback very different feedbackon very different parts some of thedocumentation some onthe implementation and one of the thingswas basicallyone of the feedback points that we gotwas basically hey this is hmsw that'spretty coolbut i noticed that if i import a largedata set it'skind of slow like it doesn't it doesn'tget the kind of performance that i wouldexpect from hnsw and thenwe sort of took that feedback seriouslyand compared and saw that okay yeahthat this is true like it's it'sfast-ishbut it's not as fast as maybe hnsw couldbeuh so basically the first step that wesaid on this this sort of thethe end goal of the roadmap is justscaling in general and as you'll seelater scaling includes horizontalscalingbut scaling in general for us also justmeans being able toto work with larger data that's likeobviously when the space ofof big data so we need to be able to tohandle large data setsand one part of being able to handlelarge data sets is if we'rebuilding this sort of expensive vectorindex at import timeit just means we need to do it fastenough so um the first step wasbasicallyoptimizing the h w index implementationthis was mostly fixing a few bucks hereand there justgeneral performance optimization viva itis written in go so there are a coupleof things that we could doand also one thing that i findparticularly coolis if we have one assembly file rightnow in our implementationuh where uh the the dot productcalculation that we usethat we also use for for cosine distanceof course and distance invba is just a normalization of thevector and thendoing a dot product calculation which isthe same thing as cosine distance butit's a bitfaster if you only have to normalizeonce um yeah andthis is uh there we have an optimizationnow forum for avx-2 compatible cpus whichdoesn't work by default in go so we hadto write it in assembly which then youcan integrate and gowhich is i think this was the majordifference then if you compared alibrary like hmswlip which is likethe reference implementation is theimplementation that that came along withthe paperand that's written in c plus plus if youcompared that to vb8 before or to vba'sh and sw implementationuh while we were just not using thesehardware acceleration i'm not theseusing theseavx2 instructions and that's where we welost a lot ofspeed so basically we have completedthatand this was released with all the otherperformance improvements inv 1.4 so if you look at the the road mapuh sorry no the roadmap at this graphicof the benchmarkuh 1.2 uh was basically yeah that wasthe the controller sort of the basebefore we started optimizing anythingum and it's the time was so high thatyou can't even see it in this graphicanymore it moved off the the top of thescreenand then in 1.3 we took care of a coupleof performancefixes and then 1.4 i'm using 1.41 herebecause it was the latest 1.4 versionbut that the fixes themselves or theoptimizations were introduced in 1.4alongside with the uh image2vec moduleby the wayso if you want to use um if you want tovectorize images out of the box that hasbeen possible since 1.4um yeah and there you see the the majordrop-off from from 1.3 which doesn't fiton the screenanymore two to one point four sobasically these changeswere step one on the roadmap but as youcan seeuh there's something else on the horizonand umyeah and that's basically the next stepsolet me get into thatso when you sort of design a databasecompletely from scratch or when you planout a database you have to makea couple decisions you have to make alot of decisions but one decision thatyou definitely have to makeis like is my database gonna be readpreferring or is it right preferringand this this has a lot of impact andessentiallyby the time we decided to build vb8 umh and sw just came out or was justsort of just gained i think it's beenout for longer but it just gainedpopularity in the communityand people were using it and we werebasically thinking that's a really coolstart we need to builda product around this like we need tobuild a whole database around itso sort of this focus on these fastquery performancesthat you could get with h w was prettyclear for us like okay that'sthat's the the sort of benefit of avector search that we need to to offerlikeit needs to be fast at query time sobasicallywhen we started out we were saying okaythat's the the first goal that we needto achieve it needs to be fast toto read um but turns outthat if you if you do these things thatwe do with vbawhich also means that if you also storethe object and if you alsoum build up this inverted indexand if you're generally in a space wherethere's a lot of datait turns out that you also write a lotof data and that they just can easilybecome the bottleneckso basically what good is the fastestreading databaseif importing data or ingesting data intothat databasetakes so long that you can never get toa very large use case thatthe database could basically easilyhandle fromfrom a read perspective but you just cannever get there because it'sit's or i don't know because you you inuh you create more data maybe that youryour database can ingest for exampleand um that's basically the point wherewe said okay now that we fixedsome of the performance issues that weregoing on in the vector indexand where that we're building now theactual bottleneck is just storing theobjects itself so now we need to addressthis and this has been aa pretty big change so this it justmerged the the pull request that had ithink it wasexactly 100 commits then they had had tofix something else then it was 101 butso sort of just to put this intoperspective this is like a major changethat's beenbeen happening in vva and essentially wewent from umfrom sadie's b-bolt which is a fork ofthe i don't knowwho it's by the original bold which is aum yeaha key value store that's written in gothat uses a b plus tree approachso essentially sort of a very commonpatternthat you have for for yeah disk accessor for fordata access on disk that works prettywellthis data data store this key valuestore also supports transactions whichis something we haven't actually neededat all in in vba so farand then we made the decision okay weneed something now that works better onon writing we write a lot of data weneed something that's notthe bottleneck there this is why we wentwith an lsmtree approach and essentially in lsm3approach it's actually it's actuallyquite simple but at the same time it'salsoalso kind of genius it's also in use bya lot of databases basically all thedatabases that youyou know that are really good atingesting a lot of datain in very little time they probably useeither an ls m3 directly orsomething similar to to an lsm tree andthe idea is in an osm tree thatbasically you start out with anin-memory structureso you you import your data and just putit intoa memory structure and in this memorystructure the only thing that you dowhen you add somethingis you make sure that that structureitself is sortedso whenever you have something sortedit's pretty easy to access it likei don't know if you have a sorted listthen you can do a binary search andthat's pretty efficient to access itso that's the only thing that needs toneeds to happen in anuh in this memory store it needs to besortedonce this memory store grows too big yousimply write it to disk as is you takethis thing that's already sortedwrite it to disk one go so if writing inone go ononto your disk super fast if you have anssd diskdefinitely but even on a spinning disclike just one seekright i don't know 10 megabytes of datapretty fastuh the problem with an in memorystructureis that it's in memory so you don't havethe theguarantee of having something on disk uhif it's never been written andif we're saying that the efficiencycomes from the fact that you import intomemory for let's sayi don't know 15 seconds then there'salso 15 seconds of data that couldpotentially bebe lost if if the database crashes and ijust said in the beginning like vb-8 isthe the tool that really wants to be thedatabase and that um yeah we can't justsay okay oh well sorry you lost the last15 seconds ofum of your data that you wrote sowe can fix that by writing into a writeahead lockand basically write a headlock orsometimes also called commit logis another file that we write intothat's also append only so we only neverseek in that file but basically juststart writing into and just writeat the end of it so basically this datathat we ingestthat was sorted in memory we're alsowriting it into a filewhere it's not sorted just sort of as aas a backup basically if somethinghappens and then if if nothing happenswe can just write the sorted part ontodiskcreate this kind of segment and thenstart with a new segmentand the cool thing is that basicallyeven if you've just writtenhundreds of gigabytes or terabytes ofdata when you start with a new segmentyou basically startfrom scratch you start with a new fileit's a new file that you're writing intoso essentially this simply doesn'tcongest it doesn't slow down it has asort of constantuh write speed and that is veryimportant because that was exactlythe issue that we had with the b plustree before and good read performanceuh but when writing at some point itwould justuh um yeah it was basically it wouldbasicallyslow down so if we look at the the roadmapthat's what we're seeing so in in from1.4 to 1.5which is out now by the way as a releasecandidate you can you can start using itum by the time we we this this goes fromthe release candidate to thethe full release there'll probably besome smaller changes we're going to addone or two features but those areunrelated to the ls entries which isthings that we still want to get in thereleaseum that we make um but from the sort ofperformance aspect you can start usingthisand and it should work well and if itdoesn't then please do tell us that'swhy we have the release candidateso that we can make sure that ifsomething goes wrongthat we can fix it so this makesimporting this dataabout 130 percent faster on on thisparticular data set of course thesethese numbers are very specific to onedata set um but it's more about the sortof the relative comparisonum yeah that made it 130 fasterand this is sort of only from writingthe data so thethe expensive thing that we're doing isbasicallyum it's basically building the agents windexum but as you could see sort of becausewe're writing so much data that was thebottleneckthat we had to to take awayso something else that i i want to sayisright now uh i was talking aboutsegments inan lsm tree and basically these segmentsi'm not sure if ieven said that but these segments canalso be merged over time and then youbasically combine a lot of smallsegments into a larger segment and thenyou havesort of one sorted file which is again abit more efficient toto um yeah to to useif you've heard of um for example thehsw implementationin open distro or if you've beenfollowing what's happening with leucinethen you might not be saying oh segmentsnotnot good for a vector surgeon so let melet me explain whyon the one hand we have the vector indexwhichum has a o of log in order this isspecific to hmswwhich has an o of log n time complexityat query timeso essentially what that means is biggeris better you want to have onelarge index and um with thissort of very primitive examplecalculation where i'm pretendingthat there's a thousand objects well ifyou have log of a thousand which isthreetimes one then your cost is three and ifyou were to now split this intexin index into a hundred small parts thateach just containten then log of 10 is 1 but you have todo 100 searchesso now your total cost is 100. sobasically it's a veryvery made up example with very made upnumbers but to illustratethat really on on this kind of vectorindex it's much betterto have one large one than multiplesmall onesin addition when when you mergesomethingan hms w index unfortunately at least noone has really figured out how to do itefficiently yet you can't really combinemultiple h and sw indexesinto um into one big one i mean you canof coursebut is is as expensive as building themin the first place or even slightly moreexpensive because like the the new indexis now going to be bigger than theindividual onesso um basically for h and sw that'sthat's a problem and what we want to dois we want to avoid that our vectorindex gets segmentedso this one we really want to have oneone big one nowon the ls entry that's on the other sideof the screen it's exactly the oppositelike we we justshow uh showed that basically umthese small sectors or these smallsegments are exactly what keeps thatthing fresh and what keeps it fast atright speed so here we do have thosesegmentsand um while we have those segmentsthere's asuch a thing called a bloom filter whichis really cool too it's a probabilisticsort of way of telling whether data iscontained in a specific segmentand the cool thing about bloom filtersis that it never has false negativesit can have false positives so it mightbe the case that it tells you yes thedata is in there and then you open thisthing up and you look for it andwas a false alarm data wasn't there butit can never have false negatives soyou can never sort of misstate it thatway and this bloom filter can besort of used to make looking up datain very many small segments veryefficientum and and then even sort ofyeah over time you can even merge thosesegments intointo smaller segments sorry into fewerbut larger segmentsand then basically over time uh you havethe same as if there were never any anysegments in the first place and that's arelatively cheapprocess because as we said before likeeach segment is basically just a sortedfileand if you take two sorted files and uhtry to put them into sort of a next filewhich is again sortedthat's basically like a like a mergesort so that's a relatively uhcheap and easy uh process so on the lsmsidewe're accepting the segmentation we'resaying this is what we're not justaccepting it we're really saying thisis by design of how an ls tree worksand we say that we can also just improveit asyncbut if you look at the entire thingservant this is really what would tellthe vvat storage uh apart from forexample that the problem that lucine oropen distro which is based on leucineare currently seeingis that we don't tie so while this stufflives closely together and i'll get tothat more when you talk about chartingwe never tie the vector index to a uhlsm3 segment that's very importantbecause then we don't run into thesekind of issuesthat suddenly you have a lot of yeahsegmented vector indices that you needto somehoweither combine or accept that they'reslowerso that was step two on the road map sothe next stepthat we want to take is then umsharding so basically sharding orpartitioning um i'm gonna explain whatthat is andi'm gonna start with the motivation ofwhy we would even want to do thisonce you've defined that you want to dothis there are a couple of questionslikehow do you do it how do you partitionhow do youonce you have those partitions how doyou distribute them amongsomething basically like how do you signownership how do you give someoneownership of a partitionand then once you've done all thesethese things um yeah what are theeffects of thosedecisions like there are probablytrade-offs involved and how does thataffectreal life data so the main motivationfor partitioning data is basically wewant to splitsomething up and split it into smallerunitsthat are basically the same as thelarger unit but just only containparts of the data so basically insteadof having one databasewe would have sort of three smallerdatabases in a very verysimplistic way and and one of themotivations for this is basicallythat if you have those three charts theysince they're all self-containedthey don't have to live on a singleserver anymore so you could for exampleput them onon multiple servers umthe advantages of something basically ofpartitioning your data orsharding your data is yeah as i justsaid you can spread itamong sort of not even it doesn't evenhave to be servers it might also just bethat you have a machine that has a lotof cpu coresand that you're noticing that yeah okayi can i don't know useutilize 8 or maybe 16 cores efficientlybut with 32 cores i can't anymore andthen if someonefor whatever reason if you have amachine with 128 cores then it mightmake sense to justcharge your your workloads so that theycan use those more efficientlybut as we're sort of moving towardshorizontal scalabilitythe main motivation is probably going tobe that you want to distribute thoseshards onto various servers and it couldpotentially even be on different datacenters or somethingso basically as long as we decided thatsomehowwe're partitioning the data we can thenmove it into different placeshowever it does not come withoutdisadvantagesso the the first question basically thatyou have if you havelet's say you have 100 charts and youwant to accesssomething some object with an id uh johndoe one two threehow do you know where that is like maybethere's rules somewhere maybe you haveto test something i've also talked aboutplume filters before so potentially thisis something that that could be usedum to to sort of figure it out where thedata could be lyingbut essentially we need some sort of arule andthe other thing is well right now in myexample i was looking for a key with iduh john doe one two three but what ifyou don't know what you're looking forand we're a search engine so basicallyor vba is a search engineso basically we're dealing with a lot ofcases where people don't know whatthey're looking forso these are the kind of problems withpartition data thatneed to be solved so for partitioning ingeneral i have this very very simpleexamplewhich is just a modulo function andwe're using modulo 2and there's this nice sort of stream ofnumbers and some of them are already inbuckets andbasically what you can immediately seeis like bucket zero contains theeven numbers but one contains the oddnumbers so basicallymy my hash function or my mypartitioning functionis a simple modulo two and then i'm justusing the remainder i'm gonna put itwith the remainder of zero i'm gonna putit into bucket zero and if the remainderis onei'm to put it into a bucket one there isone advantage or one one very bigadvantageon such a distribution functionif i import something or if i'm lookingfor a keyi can just use that exact same functionand uhsort of immediately determine where ihave to look somy stream here ends at 17 so let's sayi'm looking for key18 don't know if it exists or not butwhat i do know is thatif i just use this key the next one andapply the module functionsince the remainder is going to be zeroi know that i have to look in bucketzero if it's not therethen um well then it just doesn't existso this is this is one of the theadvantages howeverthere is also a problem and the problemis basicallywell what if i say nowthat instead of two buckets i would wantto have three bucketsso in this case the the easy thing to dowould be well let's say let's just turnthis modulo 2 into modulo 3and all of a sudden the values that cancome out could be 01 or 2. but the problem is that youdon't start from scratchlike you might have already importeddata and now if we're looking at wherethe data goesum while zero modulo anything is alwayszero so that's going to stay in the samebucketbut as the numbers go up so umfor for one for example that also staysbut for twoso uh two modulo three is nowtwo that's the new bucket so two wouldhave to be moved even though it wassort of somewhere it needs to be movedumif we go to three that's in bucket oneso that was a different bucketbut modulo three is now uh zero so thisalso needs to be moved into a bucketthat even existed alreadyso basically what you're saying is if wehave such a function and if we everchange how we partition it basically weneed to change the entire database andthat's a that's a problem becauseespecially if we have such a thing thatthat's a problem for any distributeddatabasebut it's even more of a problem if wehave something such an hw indexwhich is costly to to build so we need asolutionfor that problem now before we get intothat solutionjust in general a shard as i saidis a self-contained sort of mini indexit's a self-contained unitand um for us i said that we we havesort of this motivation to keep stuffthat belongs together very closeso if we have some sort of a function wedetermineum that something goes into chart twothen this chart contains everything itcontains the vector index the objectthe inverted index basically everythingis in in that chartand all of these charts together formthe index soto the user to the outside if they senda query andwhether that query touches a singlechart or all of the chartsuh to the user it will just feel likeone index like they won't knowwhether this was cert or maybe they willknow because it's contained in theresponseum but the response will be the same itwill be the same as if this was all oneindexand they don't care if it came from fromyeah from one chart or from multipleshards andwhether these were local charts orcharts that were maybe on a differentserverso that's the general idea that once wehave a sharded indexthat um yeah basically an index is madeupof those of of basically what currentlyis an index so these all havethe same capabilities of an index andthen of courseon a search we need to combine them buton a vector search for example we havethethe distance which we translate to acertainty and that's something that wecan use toto sort themso now for that problem that we haveabout changing the amount of of chartsumbasically that we saw with the with theum module functionand here this is something that we'recalling vba's virtualcharts and this is very very muchinspired by cassandra'svirtual notes so the difference betweencassandraand and vb8 is extender is not a searchengine soit doesn't need sort of an index byspanningmultiple data points which we do so weneed something such assuch as chart but we can still take someof the concepts that they dothat basically help us find a sort ofsmart way of how todistribute data in the chart so what ihave herein this this ring fashion is basicallyanother hashing function that that ijust made up that doesn't existthat produces values between 0 and11 999 the idea whywhy this odd numbers is basicallybecause it's a ring and um if wewere to pretend this is a clock facethen we would immediately know sort ofwherethe three is and where the six is andthen it just because i thought likeonly 12 numbers so that's a very badhash function so i'm going to make it 12000.so knowing this we can introducesomethingthat we could would call a virtual chartand as of now this doesn't changeanything aboutsort of what we do we don't now go outand produce i don't know 100 chartsbecause as we learned in the in the partabouth and sw we want as few large agents wuh index parts as we can so we can'tjust sort ofmake these virtual uh shards or we canmake those virtual charts uhvery small but we can't make the actualcharts very small sothese virtual charts are basically nowsort of randomly distributedon this ring and each chart owns onesegment of this ring and the segment isdefined like the shardonly has an upper limit and it it ownseverything sort offrom the previous virtual shards upperlimit so if we take as an example thethe sort of green one around the the3000 mark herethat very roughly that the previous oneends at like 2800and the new one starts at 3200something like that roughly so why do wedoall of this um basicallythe the cool idea is now if we were tointroduceone new virtual node so once we wouldadd a sorry one new virtual chart if wewere to adda new shard then we'd probably add muchmore than one but let's sayfor the sake of argument that we woulduh addone new chart uh virtual chartand this virtual chart has the sort ofupper limit of exactly three thousandthen what you would see is that it wouldbasically splitthis green one here in half and why doesthat matterthis is sort of as we see how wedistribute these virtual chartsinto actual chart so a chart as we saidwe need to have relatively few shardsbecause we want to have large indexeson there um that means a chart needs tosort of own virtual charts whichessentially justtells us that if the sharding functiontells us you would go into virtual charti don't know something then we knowbasically from a lookup tableokay this is the actual chart in thiscase one and just for the sake ofsimplicity i've just decided that chartsbasically own a specific color so shardone would own the color bluechart two would on the color green andand we can go onand then if for for whatever reason weintroducenew uh virtual chart we can cut them inhalfand basically now is sort of now is themajor benefit if we look at thosebuckets with a modular functionlike even if we add or even though weadded new bucketsnothing has to be moved across bucketsthat already existed likeyes if we sort of if we go from two tothree and we say we wanna populate threeyes three will have to take somethingaway from one and we'll have to takesomething away from two at some pointthere's an equilibrium and it will stopbut it can never be the case that wehave to move something from one to twoor from two to oneso basically a lot less movement has tohappenif we ever change these these thingsand now you might be thinking sort ofbefore i said well one of the problemsof an hnsw index is that you can'treallycombine it or that you can't sort ofmerge one into twoso now i'm talking about potentiallychanging the shardswon't we have that exact same problemand yes we douh but there's there's two things thatto keep in mind hereso first of all this is a much morelong lift sort of process that is muchmore rareif you import into a segment you willimport for a minute or import for a fewminutes and you will already havei don't know probably 10 segments orsomething like that so that's a veryvery commonthing where this is a problem changingthe charts orchanging the clusters so most likely thereason why you would change the numberof shards is because you've changedthe cluster size that's a much rareroccurrence and if it isthen it's also much more acceptable tomaybe have a background process thereto to readjust so this is this is apretty rare processwhere the cost of sort of rebuilding anindex might be more acceptablethat's the one reason to justify thisthe other one is thathmsw is basically just the one indexthat we currently havein h in in v8 but we don't know what thefuture will bringmaybe there's a new index at some pointwhere we sayoh wow the the cost to build this isjust a tenth of that of hmswmaking these sort of rebalancing acts uhmuch morefeasible so this is sort of a very coredecisionin in the design and we want to bepreparedto sort of not be not have therestrictionof never being able to to change heartsand there are some some databases outthere where basicallyyou can only select the the number ofshards up front and then you can neverchange itand we want to sort of be more thecassandra in this in this casewhere we can say yes um we are preparedto to scale dynamically and we arepreparedto sort of do things that maybe youcouldn't predict already uhwhen you initially uh set up youryour clusterso when you partition like that so sobasically now we've talked aboutwhat happens or how you partition um butalso another question is what do youpartition byso basically you need to take somethingto make that decision and in intwo slides back on that or three slidesback on that modulo function we werejustusing numbers and numbers well i don'tknow we could say that this was the idor this was the only propertyum but basically you just need to makethat decision of what do you use topartitionand what we have in our plans and i'msaying sort of this is thethe first version because i thinkthere's there's definitely potential toalso extend that in the futureuh at first what we want to go by isjust the object id so everything in vb8needs to have every object needs to havean idand um using that iduh yeah we can sort of easily identifywe can easily identify that's the pointof an id but we can access each objectby an idand if the id is also the partitioningkey we basically knowthat on each on each axis we have thepartitioning key with usso for example why do you want to accesssomething by id so on a search itdoesn't matter so much because thesearch we said thateach chart is self-contained so if weuh sort of combine searches fromdifferent chartsthen it doesn't matter so much becauselike the shard will already give us thewhole object so we just need to combinethe searchbut there is a scenario where we need todo those lookups by idand this is vba's cross-referencefeature so since we can't controlif a cross-reference ends up on the samenodeit could potentially be but it couldalso not be the casewe need to sort of when we resolve across-reference we need toquickly grab that data and in this caseit's much much more efficient if weknow if we can do the partitioningcalculation in front and if it will tellus okaythis particular id lives in this virtualchart which belongs to this actual chartwhich as we'll get there in the nextstep belongs to maybe this nodeand that's much much nicer thedisadvantageis that if you have fuzzy information umyou will probably touch multiple shardsbut that that's okay also if weif we look at replication in a second uhthat will basically showthat um yeah that there are ways aroundthis uh one of the ways of how we couldpotentially improve this in the futureis if we just give that decision of howto make the partitioning if we just givethat to you the user becauseonly you really know what you're usingvba forand let me give you an example so let'ssayum we're coming back here this is sortof how this all ties together if we'recoming backto vva's feature of using aum a structured filter then you couldpotentially make the key that you'refiltering on or the property that you'refiltering onyou could make that your partitioningkey so for example amade-up example in e-commerce use caseand we're sayingwe're partitioning by a field that isthe averageshopping cart total so i don't knowthese are these are past shopping cartsand um the total is is what we'repositioning byand we're not using now a hashingfunction such as murmur 3which by the way is also inspired bycassandra i think it didn't even didn'teven mention that but umit works well there so why not also useit in in our caseum and but we're using more of a rangefunctionwhere we're saying like if this is a lowvalue it goes into partition one if it'sa mid value it goes into partition twoif it's high volume it goes intopartition threewhat's low mid high doesn't matter fornow so now if we know that our querieswill always set this kind of filterwe can basically triple the the searchcapability of our searchof our search engine because if we'resaying now give me the users that aresimilar to x and that's the the vectorsearch partthat have a high average shopping carttotal which would be expressed in thewhere filters such as i don't know whereshopping cart totaluh equals more than whatever thethreshold is for highthen potentially you could be in asituation where this entire queryis served by a single partition and thatmeans that if your data is partitionedlet's say across 10 partitionswhich are on living on 10 nodesthen you could potentially sort of uhyeahsort of up your your intake or yourthroughput by 10 becauseeach of those nodes can conserve thosequeries individuallyso in the partitioning strategy therethere's a lot of potential in in sort ofreallyhigh usage cases so i think it would bereally cool if we could open this up inthe future and just sort of let the userdefine how you want to partition but fornow just to get startedwe just want to go with the the objectid so that we have something to sort ofevenly distribute the datathe major motivation of that umis really clear than in the in the nextstep so so by the way step threeis now under development so step one andtwo is basically released either as afull release or a pre-release a stepthree is currently under development andtherefore alsothe next steps so now now that we havethose chartsum this is probably the part that we'vebeen waiting for all the time is stepthree like why do i have shards if ican't do anything with themnow that we have them in step four wewant to distribute themacross notes and this will finally getus to the pointwhere all of that load can be spreadacross multiple nodes in a clusterso for example um if you have a data setthat you say like yeah with one ev8 nodeit justi know just it's too large for for whatwe canum yeah for for what it could handle ormaybeit's not too large for what it couldhandle but maybe it's too large for forhow fast we could import itso there the benefit really is that inthis case you can nowum once we we are at step four you candistribute thatamong multiple nodes in your in yourcluster and clusterbeing the the key word here like this isthe first time that we can really talkabout a vb8cluster cluster of sort of yeah where wehave horizontal scalability and and alsowhere we see that horizontal scalabilityitself does not necessarilymean high availability so yesat this point the cluster is distributeduh but it's not necessarily faulttolerant yet or at least not a hundredpercent because replication is stillmissing at this pointso if out of those three servers onewere to dieum then we could still serve two thirdsof the data setwhich is sort of i don't know like it'sbetter than nothing but it is not whatwe want of course we want to be able toservethe entire data set which is thenwhat we will get in step five so so bythe way between step three and fourthis is sort of i only have one slideonly saying now we distributebut once we implement this uh there is alot more things that we need to dothere's all the stuff in the backgroundlike we need to make surethat a schema changes for example thatthey are fully consistentwhereas other stuff might not have thesame consistency requirements sobasically this islarge enough from an implementationperspective to give it its ownstep on the roadmap even um yeahif if sort of i talked a lot about stepfour and then very little aboutuh oh sorry i talked a lot about stepthree but very little about step fourthe next step then and i think this isthis is reallythis is where it starts to get getreally cool and really excitingthe next thing is then once we have areplicationand the way that we want to do so it's areplication in general just meansas you can also see in this this graphicso if you compare it to the previous oneeach node owned like one color the colorof a chart hereuh and then in the next step each nodenow so here we would have a replicationfactor of threeeach node now owns basically a copyof all three charts so in this setup ofjust three nodestwo nodes could die and you would stillbe able to serve the entire data setlike maybe not at the same throughputbecause you'reyou're missing two machines but you canstill serve requestsand and that's basically the the majorbenefit ofhaving replication and this is also thepoint where we can say okay now it'shighly availablesomething can happen a server can godown and we can stillbe able to serve the data set and umas always with these things thereplication factor is something that youcan controlyou could potentially go to to someextreme measures where you havemaybe 10 nodes and every node contains acopy of every chart then you would havea super highly available setup like atthis point it would probably be moremore realistic than i don't know youjust have an outage of the entire datacenteruh then that all 10 nodes go downindividuallyso this is sort of the decisions thatyou can make basically what i'm sayingiswe as as developers in vva and want togive you that kind of control and justsort of design the system and you canuse itum according to your your budgetrequirements according to yourslas according to your your availabilityrequirementsum there is also yes also i haven'ttalked about the fact yet thatthe way that we're planning uh thereplication thing is completelyleaderlessso basically this means that there is nosort ofwrite-only notes and read-only notes butallnotes or all shards that are containedon several notesare completely equal in that case and umthat means there's there's nobottlenecksbut there's also a potential forsomething uh that we've tried so farlike in the very beginning actually wedid an experiment witha distributed uh server orbuilding up an hmsw vector index in adistributed fashionum which works surprisingly well like itneeds needs more experimentationbut there is a way of sort of spreadingthat costout of building the index by spreadingthat out across multiple serverswithout then even ending up intomultiple charts so the idea is that youbasically just have a single chart thatis replicated across serversbut still that those servers share thecost of building the index so this is abit experimentalbut i think there's a lot of a lot ofpotential but even even without thatthat idea that the benefit ofreplication i think isis pretty clear which is uh basicallyhigh availability to single or notefailuresuh with regards to consistency uh theplan is to just have this eventuallyconsistent as we're seeing sort ofall of our use cases tend to be in theeither in the analytical space or insort ofum yeah these typical search cases whereyou replicate your data from anotherdata storeso very eventual consistency isabsolutely fineif we ever see that we need more thaneventual consistencyuh we could very easily or not easilybut we could definitely again sort ofcopy from cassandra or be inspired bycassandra where they have a model oftunable consistencyum where the idea is that you can sortof control the cost of writing datawhere you could sayuh i don't know i for example write witha a quorum of nodes and then i also needto read for a form of nodes but thenit's consistent or you could saythat i don't know i need a replicationof at least xy or c for our right but for now that'snot really the planit's something that that sort of ourarchitecture allows us to doif we see the need for it but for nowbased on the cases that we're seeing umwe're not spending any resources on thisum so still in inin the idea of replication as i saidbefore we really want to give you thecontrol of how you set up your yourclusterand i just came up with two exampleshere one is scenarioone um let's say that you have sort ofa workload where you import your datamaybe it's i don't know trained with aspecificmodel and you know that you retrain thisevery 30 daysso basically your typical workload islike import onceand then you you start querying which issomething that we sometimes see but ofcourse also you get is database and youcan mute hit it so it'sin no way a restriction uh what you cando thenis um you could say okayi want to have one chart per node atimport timeimport my data set and then once theimport is donei want to turn up my replication so thatlet's say we have three nodesthat we end up with the picture on theright here where each node is able tohandleum an entire request based on data thatit has locallyand the benefit of that besides highavailability is that you have this thismassive throughput at query time becauseeachnode can serve a search query across allshardsum in in isolation without needing anetwork request and without talking toother nodesscenario two is something differentlywhere you would say okay we have a lotof writes and we have a lot of readshappening simultaneously and there's notan import phase in a query phase and inthis caseyou could just say okay i want thishighly available from the beginning iwant replication from the beginningand then you'd have something that ishighly available at any time sobasicallyas soon as you yeah your cluster is liveit will be highly available whereas inthe first one is a bit cheaper to buildand a bit faster maybebut then only it becomes highlyavailable once you you start turning onthe replicationthe final step on the roadmap is thendynamic scaling so this is sort of theholy grail or maybe the holy grail ismulti-data center which is alsosomething that that ispossible with this architecture ingeneral um but sort ofthe next part here is dynamic scalingwherethe idea is that uh you can change thecluster size based on the demand thatyou're seeing at runtimeand this is also where we sort of comeback where we then see the the benefitofthis ring thingy here with the virtualchartthat if you dynamically change yourcluster and you can't predicthow you're going to change it then youmight also have these these sort ofthese situations where you need torebalance and potentially sort ofcombine shards or split charts upand this is then where the virtualcharts will help in sort ofminimizing the movement because yes sortofchanging something about an hsw indexand potentially othervector index types in the future isexpensive but if we can at leastminimize the the changes that have to bedone and then that becomesa lot more efficient and that's sort ofthe the uhyeah final part on that six steproad map where we've seen that one andtwoum are complete and released three is inin under development and then the othersteps we're going to followso that is basically the overviewi've been talking for for quite sometime let me know if you have anyquestionsso that's uh thanks sessionthat's a lot to process so i'm curiousto hear if there are any any questionsalso there as well yeah exactly that wasalso one of the the motivations ofsaying we need to we need to record thisbecausethere is a lot of a lot of stuff crammedinto thisit was almost an hour wow butlet me try to figure out how i can exitviews that i can alsosee you there we go and i think i needto stop presentingyeah so uh so thisthis was great i think it it gives us anidea of what can be donei think we're still in experimentationmode souh some of the some of the practicalconsiderationsuh that we're having when we when we'retrying to implement use cases wasso so the first one is okay whenwe didn't initially look at it as a datastore as the databaseright so persistent storage wasn'tat the top of our mind right like okayand and uhit was more response timesfor your uh for your for your readsright right likeso the right wasn't such a bigfactor but it was still a bigproblem if you're doing the one-offmigrationright so i wanted to get my data fromwherevermy current person's storage is into intovv8 right and and that was athat was a big uh that was a bottleneckright like you know the speed with whichyou could do that one-off migrationright so we were looking at that uh uhalone rightlyand for me right like once i had donethat thenthe additional so and then right wheni'm adding objects directly to theuh to the instance it's not a problembecause it's notyou know in future right like you knowthat load might increase and then itmight become a problembut you don't you don't see that when wearewhen you're using it currently right sothat's that's that's one thingthe second is thethe availability is one thing but alsoright like in a recovery you know rprpo right like you know sort of whathappens if i lose some datahave i got backup how do i recover rightlike you know if i'm using thisas my database right so that onethat was a that was a that was somethingat the back of my mind to say right likeyou knowto prevent me from okay can i use it asa productiondatabase right so for me rightly can isay okaymy uh you know um what i had in mind wasuse something like cassandra neo4j formy persistent storageuh but you but you realize that rightlike you know that's not necessaryif you're using vv8 as the databaserightuh so that's that's one thingand i think depending on the use casethe characteristics will differ rightlike you know we can only we canprobably like you know sort ofexperience that only when we try it andsee what happensbut that's when right like you know thewe need that flexibilityright do you need more sharding soobviously i want uh horizontalscalabilitybut uh my uhi might just write like you can have aone-off big migration loadand then write like you know sort of mymy ongoing right like you know sort ofload for adding objects might notbe that high right so i might need adifferent solution toto get my data on one time into intouh to migrate it onto the v8 instanceand then ongoing that that wouldn't be aproblem so uhthe the flexibility right looking atthat that's comingwill be will be great umand and and of course right like youknow sort of the umavailability for both of thoseright-clicking and i think it's it it'sfor us to see right look at how we cantweak it whether we want faster responsetimesright or right like you know sort of asyou are if you've gotvery less road and you want to writelike you know sort ofconfigure it pretty heavily forfaster response times that's that thatflexibility right like it will be greati said sorry right click and i thinki've taken too much of the time becauseno noit's very cool to to hear sort of howhow all this abstract stuff how thisthis ties into actual use cases andespeciallysort of two takeaways for me is is onesort of theum it might not be clear to everyonethat vvat really is a database and thatthatthere might be something else that youneed or maybeyeah sort of in an experimental mode itmight also make sense to to sort ofstart storing the data or to still havethe data somewhere else oruntil you figure it out how you want touse vvat and then you can throw awayinstances and not not worry so muchbut in the end sort of in thatproduction scenario it's really coolthatthe data can be be safe there andthe second one yeah i'm sort of thisthisuh import heavy load this is alsosomething that i've thought about forcases whereonce we have the really dynamicscalability you could produce aridiculously largecluster and and just sort of run it onlyfor maybe a dayand and like let's say uhif you have a machine that that's 30times as much as the machine that youend up inin the end but you run it for just oneday then it costs you basically onemonth of serving the data in productionand this kind of flexibility i thinkthis is going to begoing to be really cool yeah questionabout that as well uhso do i understand correctly that you'rebasically saying that yourassumption was that you could use withit just for the search functionality butnotas a persistent data store as well do iunderstand that correctlyyeah so i i wasn't umyou know i i wasn't seeing that umyou know basically like you know thehorizontal scalability that you get andand thethe flexibility of using distributedstorage right like you know soso typically like you know sort of youwhatthe the way we do is we we try so wewe plan separately for compute andstorage right like you know sort of inanycloud deployments and right-clicking onthat storage itself is a bigcost that we're right like you know sortof there's a there's a whole uhcapacity management archival blah blahblah right like you know sort of all ofthat and rpoobjectives connected to that right thebackup recovery all that connected tothatuh whereas right like you knowavailability is something differentright like you know it's fine if iit's one thing if right like you know ifi if if thesite goes down right click you know forsome time and then it comes up rightlike instead of it'sit's fine that might be okay from an slapoint of view but if i lose dataif something gets corrupted right likeyou know then my rposo rto and rpo are the two holy grailsofenterprise sls right so and andwe treat each one of that differently soi was fine with theuh rto stuff and and it it was fineright like another of the the kind ofuse cases that i'm i'm guessingum might not write like a make abusiness impact if the site isdown for a read for for a certain periodof time rightbut if i'm going to use it as apersistent storage i don't want to getto i want to make sure because this ismywhere my master data is stored right sowhich is why right like you know sort oftill nowin at least in the experimentation itwas always okay i can i can spin up aclustermigrate the data right uhcheck out the semantic search and do allthat but then right click it i'm fine ifthat goes downi import it again right or andfor now right like once i import it uhthe import is pretty painfuljust now because of the of the time andbecause of theamount of data for the one-time inputbutonce it's on the vv8 instance thenit is just right-clicking on sort ofthose one-off objects that i add rightsotypically like you know sort of whati'll do is i'll i'll set up somemessaging system some event basedsomething that right like you know thatsays okay fine yeah every timea user gets added just go and put itinto right like you know sort of andcreate that object there so that's not abig problem tilland we've not faced that load yet butthat becomes a problem but that's not abig problem just now rightbut if i am to say right like i'll i'llneed to trust vv8with my production data and that's thedata store and all mybackup recovery rpo will betied into that then that you know it'sso whatever you presented today givesthat confidence but it wasn't therebeforenice nice thank you yeah that wasdefinitely one of the goals to just sortof convey that we're we'retaking these kind of things very veryseriouslyand of course something that thata decision that i can't make for forpeople that use vbais always like do you use vb8 as youronly database or is there a casewhere you have something like we're notsaying that just because vv8is a database that you should never useanother database it reallyneeds to fit the the use case so forexample i don't know if you haveuh very transactional data then it itprobably makes more sense if you have atransactional data storeand then replicate into vba so verysimilar as you would today maybe see inin sort of a hybrid setup of thecassandra and thenusing maybe an elastic search orsomething so that's also very muchpossible with with vv8 and somethingthat just needs to be donedecided on it on a case by case basiscorrect yeah yeah i think yeah makessense and andprobably like you know sort of in thatcase we just need to think of right likeyou know sort of how wereplicate and you know if i'vebuilt my knowledge graph for myenterprise on vv8and i don't want to lose and it's thesame amount of datasomewhere else then yeah yeah and ofcourse also backups play play roles orbesides that the sort of livereplication you can also just do do sortof old schoolbackups exactly which we've by the wayjust implemented in theuh in the wcs so in the vba cloudservice if you use the the hosted uhvb8 service okay i think from thestandard tier onuh everything they're just sort ofsnapshots that are that are currentlyreplacedand you can restore snapshots and itit's a sort of very simple backup systemfor nowum the idea is that in the future wecould have incremental backups and allthat that kind of stuffum but just in general it's also a niceproof of concept of justhaving yeah how do you do backups withwith vba and of course not just how doyou backups but how good is the backupif you never train the restore processbut sort of do the the whole the wholeintune thing um yeah which we we havethere as well andi think our documentation is maybe notup to speed yet with regards to to whatto do on on backups andlibrary stores but uh yeah it's a goodpoint and we'll definitely also lookinto itokay thank you okay thanksa lot for for your feedback was reallyreally cool also it's it's it's alwaysso cool to justget that kind of connection just see vvabeing used andand see what the pain points are seewhat the the the cool things are andjusti don't know just in general to hearthat vivian of course it's being usedbutlike to put a face to to a user is veryvery coolso thank you very much for for sharingas wellcool thank you i think it's like becausewe went likealmost 10 10 minutes over soum there's a few more things hm may benice to mentionbecause i think you haven't mentionedany uhexpected or estimated timelines have youjust just ballpark timelinesyeah yeah yeah i thought i thought icould get away with itno so we so we do have a a sort of umone date on the timeline that that ithink that's also on the websitewhere we said the the end of q3 sobasically by the end ofseptember um is where we sort ofyeah aim for for this this timelinewhich definitely meansum yeah it needs to be horizontallyscalable and i'm pretty sure it alsoit will also have replication in it um idon't know if dynamic scalingmight be in that so so maybe not butsort of the the target point that wereally say like isby the end of september we want to be atthe i think it was step five out of sixwherewhere uh replication is in and then seewhere it goes maybe also on dynamicscalingso this is pretty pretty soon uh alreadywhichi like from a from a feature perspectivewhich every time i check the calendarthing from an implementation perspectivewell where's the time gone but i meanwe're we're not starting from scratchwherewe've already just released step two ofthat six step pipelinecool thank you so much and also thankyou for your questionum i think we're gonna wrap up and sowe'll uh publish this also on on youtubebecauseuh you'll see it on our slack channeletc and on twitter people asking forthis sothey can they have enough materialinstead of watching a movie they canwatch thisthe architecture thank you so mucheverybodyand um well i hope yeah thanks for forjoiningalso for those that have already leftthere's a couple of people that leftlike right right atthe one hour mark sorry for using up allthe timeand thanks for staying", "type": "Video", "name": "Weaviate Meetup June \u2013\u00a0Architecture Deep Dive, how to build a vector database", "path": "", "link": "https://www.youtube.com/watch?v=6hdEJdHWXRE", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}