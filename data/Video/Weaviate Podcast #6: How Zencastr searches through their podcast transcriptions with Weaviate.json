{"text": "Alex Cannan, a Machine Learning engineer at Zencastr, talks with Connor Shorten about a really exciting use case of applying ... \nhey everyone thanks so much for checkingout the sixth episode of the we vapodcast today i'm joined with alex kanana machine learning engineer at zencasterwhere they're bringing all sorts of coolapplications of deep learning uh searchapplications to podcasting such as whatwe're recording this podcast on rightnow so alex thank you so much for uhbeing a guest on the podcast and couldyou please tell us about zencaster andthe kind of things that you're using thewv8 search engine for hey connor umyeah thanks for having me in the pandawe viet podcast uh my name is alex i'm amachine learning engineer at zancasterum and zancaster is basically for thosewho don't know just a podcast recordingplatformum among other thingsum butyeah basically we've uhbeen working on transcriptions umover the past few months or we releasedtranscriptions a few a few months agoreally um andwe have sort ofstarted to employ wev8 as a way tosmartly search through podcasttranscriptionsumbutyep you mean before we beat umthis is something we've been attemptingto do forquite a whilesowe went through a lot of like reallyearly iterations ofour own idea of like a vector searchdatabaseumi remember i started out with just liketf idf keywords and word to vacon those keywordssoumyou knowseeing like afully managed like vector databasesystem likewev8 uhreally just knocked my socks off andit's been wonderful to use so far yeahthat's super cool that the um trying tobuild your own vector search database iused to do things like that too wherewhen i was experimenting with say uhgans and c410 i'd uh generate the imageencode it into the latent space with animage classifier and then search througha vector representation of my own dataset just with the dot product witheverything i had in the database andthat kind of transition of trying to umlike build up your own vector searchdatabase compared to these platformslike we v8 and then plugging into sayhey or a haystack pipelines or the ginaflow of connecting it to these wholesearch engines it's really interestinghow little of that kind of stuff youhave to build yourself so how easy hasit been for you plugging in the vvacomponents like the vectorizer themodules and all that into the podcasttranscriptions um it's been great uh weactuallyended up settling on a sentencetransformer before we even knew aboutuv8 that we v8 supported soit was very simple umsetup in terms of justyou know the way the install page haslike a docker compose where i could justselect the exact transformer we've beenusingbut yeah um it's wonderful to havereallyi mean a lot of like machine learningtools umtend to have like prettyloose ideas of deployment meanwhile vv8has been pretty rock solid for usumwhich is something we really appreciatebutyeah it's beenvery easy to set up and i like it yeah ithink the case of uh podcasttranscriptions is a really interestingtopic around this idea of whether youcan just use an off-the-shelf model orwhether you need to fine-tune it on yourdata set and because i think with withpodcast transcriptions you're not goingto be able to have a massive data setunlessmaybe you use something likefederated learning where you don't storeeveryone's conversation in yourzencaster database because you knowmaybe people don't want to have theirpodcast in a central database that'sused to fine-tune the sentencetransformer so have you found a prettygood result of just using the how thewev8 has the docker compose that youjust point to say a hugging face modelweights and that's all you need to getup and running with this pretty much umi meanmy reasoningpersonally is basically podcasts areessentially just conversationsso if we just if there i mean there arelike plenty of conversation data setsout thereumlike fisher for one it's likea pretty great conversation data set onthe small side i guess butum they're out there andif we just use a sentence transformerthat's trained on like casualconversation i'm pretty we're prettyconfident that it'll haveyou knowgreat performance on podcasts as welland you know there'sthere's alwaysyou knowmore performance you could probably ekeout ofyou know fine tuning it onuh perfectly in domain data so that'sdefinitely something we'rethinking about so i actually haven'theard of this fischer data set and i'msorry about that i've seen uh likedialogue gpti've studied things like the menachatbot the facebook's internetaugmented dialogue generation i'm notreally uh too caught up with the chatbotdata sets do you mind telling me alittle more about the fischer data setand what kind of uh benchmarks are beingused for chat bots sure uh well yeahfischer isumnot really achatbot data set per se it'sit's a very old data set it's like fromthat the linguistic data consortium umlike 95 or something butumyeah it was just like some likeexpositionthatpeople went to about speech and i thinksome people like set upa little booth where two people would goin and record like a few minutes ofdialogue togetherover about like random topics yeah i'veread some really funny papers about howthey set up these data collectionpipelines for uh the chatbot data setswhere they haveuh they they call it like wizards of uhwizards of turns it's something withwizards in the thing and it's about howyou have these randomly assignedcontexts and the way that they try tocrowd source worker annotations to buildup these data sets i think isis really interesting what do you thinkabout just say doing a web scrape ofreddit conversations as a as a data setcompared to these ideas of uh havinglike a scripted character that you readinto and then you record podcasts onthis platform to create these kinds ofdata sets yeah that's actually a veryinterestingumsort of distinction betweenwhat people how people talk online andhow people talk in person umwe've actually like built some likebasic like reddit scrapers previously umor i have ratherbutumi guessonline just online discourse is uh muchdifferent than in person discourse imean just in terms of text it'scompletely different people do likeemoticons umthey like try towrite out things that can't really bereferred aloudi don't know if that made any sense butyeah they use abbreviationsyeah i've been so interested in thattopic as well and i love this like umidea of having say style transfer aslike a sequence of sequence machinetranslation problem and where you saytransfer from a casual style to a formalstyle to and like they can learn itunsupervised and the first paper that iread this paperwhere they translate from python tojavascript with neural machinetranslation completely unsupervised andi i couldn't really i like reallycouldn't believe that works so if theycan translate from python to javascripti'm certain they can transcript fromcasual styles of speaking to more formalstyles of speaking kind of do you thinkthat like that idea of style transferfrom the reddit conversation style couldtransfer in an unsupervised wayinto the uminto say a real conversation like we'rehaving now and thenand then do you think that styletransfer algorithm could then be used assay data augmentation to kind ofuh smoothen out that like interpolationline where you take your data and youhave like levels of how formal it isdoes that sound like something thatmight be able tobootstrap the reddit data into podcasttranscriptions yeah that's that's reallyinteresting umi imagine i meanso for the python to javascript styletransfer i imagine they must have hadsome data set oflike code that is equivalent in bothpython and javascripti'm just assumingi don't did they did youyeah they have this so they do thisround trip consistency thing it's it'ssimilar to cycle gan how you go fromzebra to horses and then back to zebraso you structure the loss with how wellit can go back to the zebra from theintermediate horseand then and then i think you also haveuh you probably also have some kind ofgrounding loss like in the pics depictspaper where they go from the photographof the shoe to the sketch of the shoethey also do like a like a l1mean squared error or over just all thepixels to structure it as well butgenerally that kind of round tripconsistency idea if i translate tofrench and then i take the artifact ofthe french translation and go back toenglish with some other modelso for some reason that seems to workwithout having some kind of shortcut inthe representationwait so it itguesses the transformation to the otherone and then tries to transform it backso is there likei assume there's like loss but from likeeach stepit gets accounted foryeah yeah generally in like the psychogan framework you would criticize howwell it's made the so it's going fromhorse to zebra back to horse you do thein the gan kind of framework you do thereal fake on the zebra and then you alsodo the real fake on the final horse thatcomes back out of the intermediate zebratranslation and that's that kind of wayof thinking about it seems to workreally well fornot only python to javascript orcasual style of talking to formal styleof talking but also forquestion context answer triples whereyou generate some kind of potentialquestion and then you use and then youmask out the uh the answer or thecontext and then you use your generatedquestion to generate a new answer andthen you see if that matched theoriginal tuple and they they can usethat touh to generate that's how they say usegenerative models to produceuh synthetic data for question answeringdata setsokayinteresting and and this all involveshaving likea data set of likethezebra and the horse right yeah what's sointeresting about it to me is howcasually you can label these domainslike you don't need toannotate the data so severely you justkind of say this is python this isjavascript or like this kind of domainannotation for self-supervised or likeuns it's like self-supervised i wouldn'tsay unsupervised machine translationbecause to me that just means likelooking forstructures it doesn't mean likeoptimization but like that kind of freeannotation or like easy at scaleannotation you get from self-supervisedlearning where all you have to do isjust label the domains like this comesfrom books this comes from scientificpapers this is wikipedia right in theway that you can just do that toannotate these domains and you end upannotatinglike a massive amount of datapretty easily compared to say themanual this is the answer within thiscontext for question answering labelingor that kind of thingokay cool yeah that's that's veryinteresting i meanyeah as long as you just have to labelthe the domain of the the data and notit doesn't have to be like a one-to-onerepresentation thenyeah i imagine this could also work forstyle transfer on text as wellumyeah i mean the only thing different i'dsay is that like text issort of a linear thingum or like a sequential thing rather uminstead of like an image i guess in thecase of the zebra horse butumyeah that's a very interesting ideaas as i meani'musually a proponent of beingvery hesitant to includeanother model in the pipeline oftraining a modelumsoyeah i mean this would be essentiallythatso if we want to retrain theuh like transcription model or like theembedding model we would needsome in domain data of likepodcast transcriptions umand style transferringreddit datais sort of a lossy step in that sense umthat being saidit's pretty easy to get a hell of a lotofyou bothout of the main data and in domain dataum you know from reddit or some otherform and thenfromyou know somein domain data which i wanted to saybooks right there but reallyi guess that doesn't like scratch likethe in domain umvibe of like just like podcastdiscussionssoyeah i meanif there i mean if there is uh if wethere is a good data source for indomain like podcast discussionsthenand if if it's enough to actually liketrain the style transfer theni imagine that also would just be usefulto train with by itselfum or to fine-tune like an embeddingmodel that would fit into bb8yeah i love thinking about that conceptof transfer domains and maybe likedomain and affinity how welltransferring fromone kind of say reddit or books or imdbmovie reviews is going to transfer intosome kind of other language domain ithink that's one of the most interestingtopics and i also think you hit a reallyinteresting point that idea of if youuse a generative model in your dataaugmentation pipeline you might havecompounding errors where the bias of thegenerative model justruns away and makes the discriminativemodel even more biased andi guess maybe i've been like interestedin things like in images how we have sayvariational auto encoders where you havethat loss onuh diversity and trying to cover a lotof the data space and tr and hopefullyavoid like a mode collapse in gans andthen using that to augment your datawould be horrible because it's justyou're just collapsing yourdiscriminative model on that kind ofmode that your gan has over fit to or orlike um i don't know if you call thatoverfitting that mode collapse scanthing but that idea the generative modeljust doesn't cover a diverse enoughspace the data distribution that usingit as an augmentation model would justnot be good at all so one other questioni had is um what about using say youtubewhere you could probably get thousandsof podcasts on youtube andand uh and just kind ofdownload it that way well yeah so i meanthere is youtube dl which is a wonderfultool that i think is like nottotally kosheranymore i think youtube doesn't like iti think like try to take it down lastyear i believebut umyeah i mean that's somethingi've thought about a lot i mean there'sa lot of like really great like evenlike long form podcast content onyoutubeum with video as well as audio um whichis sort of an interesting aspect givenyou know we record video podcastsum butumyeah i mean youtube dlthey support just liketaking the audio from youtube videos ithink you cannot even get the captionsfrom youtube videosusing youtube dl as wellso it's a very interestingdata source i would say umgiven itsum you know full band in the sense thatit'syou know good quality audiogood quality video andtranscriptions via whatevertranscription systemgoogle uses there yeah i've been reallyinterested in this idea of like um sayusing copyrighted data for machinelearning and i recently even read a blogpost about it's something like theauthors guild versus google and theysued google over copyright infringementbecause they're using the books and yeahand the recommendation engineso i mean i i do think this is going tobe one of the most interesting topics aswe develop these applications becausethis data is how the models are builtand then it'sit's kind of hard to get your own datasoit's an interesting thing i don't knowif uh like youtube has those kind oflicenses when you upload a video like iknow from uploading my own videos onyoutube i don't think i'm signing anykind of license that says you can't useit fortraining whatever video generation modelof me you want with it orwhatever thing like that but um maybe ifyou're using the captions maybe you'reusing their like google's speechrecognition text model or something likethatyeah that whole kind of thing is prettyinteresting to me thinking about likethe copyrighteduh data and whether you can use that totrain these models have you thoughtabout like as you're developingzencaster in these tools have youthought about open sourcing one of thesedata sets that you're building i meanyes i mean i i personally love opensource umi would love tobe able to open source some of themodels we're working on but also some ofthem do rely onlikeuser datathat we haveof coursetheyi mean we like scrub it scrub with theuser data we use we like anonymize it asmuch we canumwe don'tumwe don't like copy it onto our localmachinesso buti don't knowit's a very weird issue the issue ofyou know can you release a model that istrained on private databecauselike you canif you try an audit like a machinelearning model and like figure out ifit'susing private data that's like basicallyimpossible there's zero way to do thatunless there's some like build logsbuilt into it or something where youhave like file names but yeah i've seeni saw a paper on extracting trainingdata from language models that is um i ithink unrealistic the way that they justkind of prompt it and generate theemails and stuff i i can't imagine anycompany would be that careless with howthey encode and publish the languagemodels but so quickly i do want to getmore into say federated learning andthis idea of how you're how you'reusing data withoutputting it in a centralized database andthis difference further between saycopyrighted data and then private datawhich are two very different things inmy opinion but one idea i think isreally interesting maybe we could talkabout a bit one other interesting thingabout uh data privacy that i think isreally interesting is recentdevelopments in data set distillation sosimilar toknowledge distillation where the idea istolabel data by using a teacher model andthen the student model fits the labelsof that the teacher model has labeledthe way that dataset distillation worksis that you distill the information fromthe entire training set into ainto a compressed representation wheresay you only have 50 images that make upthe 50 000 images of c410 such that youtrain on the 50 images and retain thefull performance of the original dataset and they optimize that bydoing the same kind of gradient ascenttechnique all the way putting gradientsall the way back into the input similarto say adversarial noise maps orheat map activations where you look atsay what part of the image is they'relooking atclassified as an elephant or whateverand so that kind of optimizationtechnique would allow you tomayberetain these data sets so with federatedlearning it seems to me like you sendthe model weights to the local machineyou update the model and then you sendthe new model weights back but that'sdoesn't sound great for if somethingwent wrong if you say continual learningcatastrophic forgetting trying to studyall these thingsso i think maybe this idea ofcompressing the data set and thensending this compressed data set backthat i think would probably beimpossible to invert back to theoriginal data and then you at least havelike some kind of sequence of the datasets that i think is a more usefulartifact than just the sequence of modelweights that have been updated on thelocal federated learning kind of way ofthinking about thisokay yeah that's a very interesting idealike a compressed data set likeit's almost something i likeit sounds too good to be trueumlike so there's like a you mentionedthere's like a 50 000 image data setthat got compressed like 50 imagesare they likeare they images within that data setthat are just selected from like to be adiverse set of the original data set oryeah i can well no they're um they'reoptimized directly and you use theoriginal data you have and theperformance on evaluated on that as thelearning signaland so they're really there there aretwo techniques that i'd say are worthlisteners looking into the first ofwhich is generative teaching networkswhere you have the outer inneroptimization loop whereyou generate you start off by generatingsomething random like again and then youuse the signal for how well the modeltrained on that data set performs on itso it's like a proximal policyoptimization where all you have is thereward signal the final accuracy andthen there's this other paper fromgoogle and i'm not going to talk aboutit too much because i don't reallyunderstand these techniques but it'sit's like the neural tangent kernel andthe infinite width kind of strategy andthat's that's something else that seemsto work but i don't really understand itokay so that's interesting so it'sbasically selects like 50 images thatseem totrain the model in the best directionno it um it optimizes them directly fromrandom noiseso they they all start off with 50random noise images and thenlike gradient ascent back to theinput space sosimilar to like you can stack it all upas a big picture of saylike a giant tensor of 50 by 32 by 32x3and then you can send gradients all theway back into that thingokaywow i am very curious what those imageslook like yeah well they're mostlyrandom noisein the end there's still random noisewith some with some kind of patterns butit's yeah i mean i guess it is just likeessentially just like encoding likebinary information in those imagesinstead of like actual like humanprocessableimagesyeah the idea of having zero one in eachof the i don't know that's such acompression i i doubt that there's stillprobably 32-bit uh or like the you know255so in addition to the topic offine-tuning and thinking about the datasets that we're using i wanted to askabout like your search pipeline and yourretrieval pipeline and what kind ofdifferentmodels you're using you mentionedearlier that you started off by buildinga tf idf retriever we've got thesentence transformers retriever and thenwe've eat has the kind ofsymbolic annotations that you could uselike i imagine in this case a symbolicannotation would bejust who's speaking so if if you and ihave a extremely long conversation maybeit's like a group of ten of us and wehave like a three hour conversationmaybe when we're searching through it wewould want to annotate it bythings that connor said and put thatkind of filter on to it when we're goingback into the database or imaginecollecting like a like we record 10 ofthese conversations in a row which ithink is really exciting for things likesay we have a paper reading group i'veseen these kind of things assembledwhere we have like 20 people in a paperreading group and you'd imagine puttingtogether 10 sessions and then searchingthrough that so maybe you'd want thesymbolic filter through who's speakingorthe datefor just all conversations so what doesyour kind of search architecture looklike for using these differentinformation retrievalcomponents say as someone okay so assomeone sort of unfamiliar withneurosymbolicum aiis thatlikecould you give me like a a 10 secondcrash course on what that meansoh yeah so it it's not even like crazyneurosymbolic ai just the idea of umusing the filtersusing a symbolic filter to facilitatethe vector search souhbefore you search through all your datasay you're looking through scientificpapers where you might have 60 millionpapers and you only want to see uh whatwas published in the symbolic filter inicml 2021 right so now you're onlysearching through now you're only doingyour vector distance search within thatsub population of your data set thatmatches the symbolic filter so i thinkthere's more to the general category ofneurosymbolic ai and i love things likeuh discrete representations and causalinference andand high level ideas like system onesystem two thinking fast and slow andall those kinds of ideas but in thismost basic case of a neurosymbolicsystem we just mean kind of using thesymbolic filters touh reduce the complexity of the of thespace before we do thisvector dot product comparison okay so isthis a like distinctfromso how is this distinct from just like anear a near text query for exampleumrightwith the near text say you've got the 60million papers the icml filter wouldprobably reduce it down to i think fivethousand papers obviously that i hopethat number's right but like it wouldtake it from 60 million to 5000 and thenyou would do then you could just youwouldn't even need an approximatenearest neighbor algorithm anymore likeface or um hmsw at that point you couldjust brute force it okay soyou basically give some like keywordslike whatever the name of thatconference is and it's able to pick outum yeah and what's super cool about thatis you can either use keywords andyou can use keywords in say um in textor you can match it within the dataspace itself but in images or audio thatmight not that analog might nottranslate so well but what we va doeswhich is really interesting is youannotate the metadata so you can use youdon't have to necessarily get thekeyword from the data itself it could bea meta tag on it like the domain it wassort or what or what time you you gotthat dataor any kind of tag you might want to puton it like a sql databases you'rehandling maybe like high velocity datathat you have constantly updating thingsokay so sosymbolic is basic is symbolic just likeintroducing sort of like more classicallike databasefunctionality into vector search yeahwell i guess i guess you could getprettylike into all that kind of symbolicfilte all that kind of logic andmaybe like relational algebra to speedup the retrieval but yeah for now ithink all we're doing is justin the set i mean yeah i mean i uselike symbolic filters like all the timein our data setwe use we have um unfortunately sincewv8 doesn't have a cursor apiyetumthey haveyeah we have a transcripts by um like aa date time stamp andwe can search through likeum each one by day that way um and wesort of like make a cursory api by likereturningall the transcripts from each dayover time so a cursor api is umsomething that traverses a databasebased on the uh like the time encodingum not necessarily the time encodingit's just by something like in inmongodb it's like if you do like a findquery um ittraverses by like the natural insertorderum which is basically i think it's justthethe actual id but like sortedlike the object id like the thehex object it just goes through those umi believe lexigraphicallyumbut yeah that'slike one thingthat v8 doesn't have yet that we'reworking around but how about the um justthe get graphql how's can you tell me alittle more about that because i'm nottoo familiar with the say thelimitations of vba's graphql apiyeah i mean the graphql is is prettypretty great um i always heard goodthings about it but hadn't used it untili started trying out with it um butyeah the wv8 console umit'syeah it's uh basically it's some websitethat we gave host that you can likeconnect it to your local mission localweb instance andbuild queries and it remembers yourhistoryso it's super super nice to like be ableto just like log into that and have allthe queries you've runuh recentlyum but the graphql is great umit hasnice aggregate functions it looks likein the latest version of wev8 weactually actuallyaddedthe ability to aggregate over referenceswhich is pretty bigumfor me at least so like for example ifwe haveumsome text that has like a list of likeentities that appear within the textand those entities are their owndifferent class and they're linked tothe original text withum a cross reference you can justaggregate overum thoseumentitiesandget a total count of entities that waywhich is pretty pretty cool umbut yeah it'sthe graphql interface is is prettyamazing i actually watched umbob's uh did a talk at like a graphqlconference which is really interestingumsomething i'm kind of interested inmyselfbut yeah it's good it's great yeah i'vebeen uh studying a lot of bob's talks ongraphql and laura hamm has a lot ofgreat talks as well on data science withgraphql and showing uh how they use thisgraphql api andto me i guess it's really extensible theidea that you start collecting data andyou flexibly want to update the schemaand then also flexibly want to updatewhat's being returned from the thingas well as what you're talking aboutwith the cross referencing ability andso just quickly before i also want totalk about the semi console a littlemore because i think that's an awesomefeature of it and the gui of getting tohave the client to play around with yourdatabase i know all like the sql thingshave clients where you can query yourdata set and get used to that but it's alot of fun to see it with a vector witha deep learning search engine i think issuper cool to see that client ui so idefinitely want to talk about that butum before getting too off topic i wantedto talk a little more about the crossreferencingand say so i was sold on the idea ofwhen i first started learning aboutgraphql that the reason graphql isbetter than rest apis is because youonly need to make one query to the uhto the to just the api i say to get toto traverse through all the differentkinds of tables you might have in thesense of in graphql and json we think ofit as class property compared to whereasin relational databases we think of itas tables and we'd be using keys to jointhe keys and traverse it so is that isthat really a big selling point for youthat you don't have to make five apirequests you just make one api requestand that kind of difference betweengraphql and rest apis yeah it's it'sit's quite amazing for me um personallyumi i mean i enjoy itit's basically like a nosql database butwith like extra functionality to do likethose reference references within like asingle queryum which is really powerful because likei've been using like mongodband i'd have to likelook for one documentyou know find thethe related field key for like anotherdocument and like do like three separatequeries to get where i need to goum which is hasslebut yeah no this is great you justyou pick outa cross reference you place it ontowhateverclass you want to read it withi mean it has to be like a single classa certain class butyeah that's incredibly powerfulfor me and expressiveumit just sort of feels likethe future you knowit'syou don't waste any time yeah yeah itseems um very intuitive also easier tocommunicate and shareuh what it's doing and how to use it soto say compared tosay sql where you need to like pass aninterview toto know how to query it whereas i thinkthe graphql thing has a is a quickerlearning curvei don't i still can't really formgraphql or sql queries um withoutlooking up like half the things i writeit's it's rough especially joinsgraphwell it's real dead simple yeahyou just say what you want you get ajson object it's magic yeah i remembertaking those classes where you do likethe uh running time complexity of likeinner joy and outer joy and all thatkind of stuffon this topic of kind of like thesoftware engineering tooling and um iwant to ask about like um yourexperience with saydocker containers and the helm chart andif you could just kind of explain allthat to people and what it takes totake your wev88 instance and then deployit and make it accessible throughsomething likeaws or google cloudsure yeah soi mean we've it has like really greatum uh deployment uhmanifests i guessum in both the docker compose that theyhave which is definitely the way to doit if you just want to stand up quicklyand then also the helm chartsand the helm chartsum[Music]arebasically just like kubernetes uminstructions forumlike a kubernetes kubernetes cluster toactually deploy i think umi think it's like on aws it's like eksthat's like their kubernetes serviceelastic kubernetes service i want to sayi don't know it's probably wrongbut yeah souh you can just apply the helm chartand as long as you have enoughyou knowuhpods provisions it'll just pick upall those pods and get them deployed andlet them talk to each otherum i know for us we also had to add justlike a really basic ingressumbutyeah i mean that's something like we weshould do on our side anyway becauseit's sort of specific to our network butumyeah i mean it really is as simple asjust likesetting upa kubernetes cluster anddo likecube control applyand the help and that's it so it's justlikeone click fromwhen you click on uh like get yourdocker compose fileand then just one click on aws so likehow many how many steps is there in themiddle of that for all for the dockercomposethat's just you know you go to thewebsite and you say what yourconfigurationshould be it gives you a curl command tojust download thecompose and then docker compose upandthere you go it's deployed it's crazyandthethe helm chart umyeah i mean so wedidso the helm chart right now is not likebuilt into that like really niceinstallation interface on the ev8documentationso uh what we did was we basically justforkedthe helm chart picked what version wewanted and thenmade some configurations for what wewant so we like disabled some of themodules we didn't usewe pers we also personally disable autoschemajust to keepthe data a bit more rigidbecause it's being written to you by afew different services so havingerror messages is pretty useful thereumyeahi mean once you have the helm chart andit's configuredyou just apply it andbamit's just like that you can get somemonitoring from i think aws theirkubernetes cluster hasmonitoring built in which is niceumand you can zoom into like any of thelogs on each podsoyeahsuper cool and so one other kind of uhmeta question about these things is umhow has your experience been using thewev8 slack to me it seems like slack isgoing to playi guess like slack and also obviouslylike raising issues within github whenyou have issues with these newer kind ofopen source tools do you think the slackchat has beenyou know like pretty well organized tome it seems like a pretty vibrantcommunity as i've been kind of exploringdifferent open source software slackchats and seeing how well they're uhanswering questions that people face anddo you think like uh recently weinterviewed michael westner buildingkatie and we've integrated katie into wev8 anduh and so it's going to be able to doquestion answering within these slackchats which i think is particularly theidea of duplicate question detection ithink could be really useful for slackchats so do you have any thinking aboutjusthow the slack chat question answeringkind of system could be improvedyeah i meanyeah that duplicate question thing isreally interesting becausei mean the thing about a slack is that alot of people don't really consider likesearching through the old conversationsto find previous answers so a lot ofstuff gets answered twice if katie helpswith that that'd be really wonderfulumbutyeah i mean i think in general the slackchannel isa really useful resource umfor me like i've sort of learned to likesearch through old messages firstumbut like a lot of like the basic stuffthe basic problems i ran into i couldsolve with a simple search there umyeah i meanjust talking about some stuff on theslack channel like has like created somebug tickets that got fixed in the latestrelease umwhich is really amazing which means it'sjust a great turnaround just like beingable to like talk to likeis it at etienne is thatokayi hope i'm pronouncing that correctyeah being able to talk to etienne umand bob too of course um it's reallyreally wonderful they're always likepretty they're on top ofall the questions i ask umi do wish sometimes thati would have made an issue on githubinstead of uh asking on slackbecause theni would get the github cloud ofhavingmore issues on my littlelike four axis diagram on my githubprofile but i guesswith just getting what i want yeah iwant to get like a little littlesemi-technologiesbadge my page that'd be nicethat's a really interesting thing thattopic around i mean we're going to get alittle off going talking about this butthat topic around say these questionanswering systems and it kind of comesback to talking about copyrighted dataand data privacy howyou contributing your question answerkind of builds the technology and ithinki don't know if what i think about theselike ideas of dividing up companies opensource products into tokens and thendistributing the tokens based on yourcontribution to things like thatbut that kind of idea ofrewarding people who contribute to theplatform because the platform orcontribute to the product really throughtheir data and their conversations andtheir uhlike user testimonials so to sayyeah that's that's interesting umi mean it's something we've also likebeen considering onat zencaster too um sort of how toincentivize people to sort of help withthe machine learning tasksumyou know we have i mean we've hired likesome contractors to like help likeannotate some datas a few times umbutyeah it's it'sit's it's a weird thing motivatingpeople todo things without likewithout money i guessumbecausei mean likepeoplegettraining data in a lot of different wayslikesay like netflix they have like theirlike star system or they did i don'tknow i think it's like thumbs up thumbsdown now yeah i don't know it's just avery like arbitrary thing that likepeopledon't put much thought into but thatsort oftrains like an entire like monster of arecommendation systemumandi don't knowthat might i think honestly that's likesomething they consider when theyactually design what this looks likethey want people to sort ofnot think about it too muchumwhich i guess is like a natural thing todo you want like the lowest barrier ofentryumit's actually getting the data but it'sinteresting like um there's like howyour liking and even just like yourwatch time on the videos or reading timeon articles how that trains some superrecommendation algorithm and thenthere's things likei've been looking into training alanguage model on the keras codeexamples contribution whereuh contributing to that gives youlike a reputational boost because you'vewritten thistutorial similar to like a githubcontributionso you get more you have more of abuilt-in kind of feedback than justclicking like and training arecommendation algorithm that way butyeah i think this kind of topic arounduh datauh ownership andand then the resulting machine learningproducts is definitelyuh one of the most interesting kind oftopics so kind of wrapping up around uhsearch and thinking about searchingthrough podcasts do you think say theclip model for image text do you thinkthat there'll be any use for say imagesearch within podcasts or do you thinkthat's probably or maybe even audiowherei don't know maybe because i imagineeven audio you always have thetext transcription do you see any kindof multimodal whether it's images oraudio orusing the stack of image audio uh textin video to maybe search through thatkind of way or do you think all theuseful applications are probably justsearching through text yeah so that's umthat's something we've we've you knowwe have a lot of uhmultimedia dataumor like podcasting in itself is sort oflike a multimedia formatumand yeah we are just using text rightnow butthe clip model is really interestingumto consider the ability to sort ofsearch throughvideo with text like sort of describewhat's in the imageum i think the only reason we haven'tlikesort of made more of an effort to likeexplore that is that you know podcaststend to beyou knowa talking head in a random background soi don't imagine there'd be muchsort of video information in therebesides like generallike descriptions of the person talkingi believe but yeah i don't know maybe ifyou've ever thought about like umtreating say like a commentary on asports game as a podcast where you kindof have that uhdual entertainment factor of you havethe two people talking to annotate andthen you have the basketball game orwhatever it is and then maybe you wannaso maybe in that kind of case you wantto search through like a dunk and yougive it like an image of a dotmaybe that kind of setting i'm not surei don't know that's just a really funnyidea to me like searching for a dunkon a on a podcast um butyeah actually yeah that's a reallyinteresting concept i meanumit almost sounds like a gold mine oftraining data for a clip model like thatbutbut yeah i mean for for us we don't umhaveum the ability to like linkum podcasts with like other media at themomentuhbut yeah if we did that'd bea really really interesting way toto actually search through that i meanwe have tons of like sports podcasts ofcourse butumandif we did have access to those likesportsyou knowvideos we could in theory try and likefigure out which podcast goes to whichsports eventit's like live casted or like maybe likeaafter game kind of debrief yeah maybeeven not just sports but just like uhvideo games like uh call of duty and allthat kind of obviously there's such avibrant gaming community around that andand you could imagine you have animage of say a reward a player receivesin the game and you canand you can use that to find out exactlywhen it happened although you could youprobably don't need deep learning searchyou could probably just do an exactmatch if you had something like thatlikesay when you've like won the game you'reon like aplus 5 000 flashes on the screen and nowyou want to index where that happened inthe gamemaybe some idea like that i don't thinkabout commenting and having kind ofpodcast and then alsolive content and i'm trying to imaginesome way in which an image search wouldaid in thatyeah if if this was like twitch wherelike you had like large like streams oflike video game contentwith like audio that'd be veryinteresting to try out also it'sit's a bit trippy to think aboutum doing likeclip likevideo and audio embedding searchona virtual world created by like a fewdevelopers at like adevelopment studioi don't know it'sit seemsvery it seems like you would have totrain a clip modelonlike the video gameto get good results because it is notthe real world yeah that's why we alwayshave to talk about off-the-shelf modelsand fine-tuning that topic i think isbecausei think there's a lot of breakthroughsin off-the-shelf models like especiallythe way that prompting seems toguide language models toto have that generalization and accessinformation that you didn't know itcontained because you didn't know how toask it if it contained itso maybe i think prompting is a reallyinteresting argument for off-the-shelfmodels butthat idea of fine-tuning in domain ithinkit's interesting i mean this idea ithink most people who've studied machinelearning are thinking oh it definitelyneeds to be fine-tuned in domain becausethat idea of being able to be flexibleto any kind of data distribution is justlikeviolates your training sort of and youdon't think that that kind of thing ispossible but i do thinkit's trending towards that way which isdefinitely excitingyeah i mean i mean i always think abouthowyou know as humanswe can understand what's happening inlike just aboutanything like we have context aboutlike you say if we say that we aretrying to processumlike some media asjust as like the clip to vec model isyou know we can like look at like apodcast video and like describe what'shappening like very easilyum we can also look at like a video gameand describe what's happening veryeasilyumsoi mean i take that as proof as there isumthe possibility of like generating amodel likethat generalizes like as well as humansumyou know i think like the architectureis sort of the limiting factor we justgot to like figure out how to actuallyset uplikea neural network tomimic the neural pathways we haveum and on the scale we have i don'treally i don't know like the number i'msure there's some research into like howmany likeumhow many equivalent likeum parameters we have in our brainversus like some like large tone networkyeah i think it's i mean i'm i don'twant to say a number and then be wrongbut i remember lex friedman made a videoon this where it's about comparisoncomparing uh gbt3 with our brain and ithink we have something like on thescale of a trillion parametersthey say i don't know if that's rightbut more than gpt three i think yeah butto anyone interested lex fredman hasmade a good video that uh goes into thatkind of idea of the size comparisonbetween gpg3 and and human brains but ithink there'slike you said the architecture designthere's still like a missing piece forprobably several missing pieces butthere's definitely still more to whetherit's a neural architecture search or ithink ideas liketrying to go past a global backpropagation and things like cellularautomata and a local heavy and learningthese kinds of ideas i think will beinteresting toobut yeah that kind of neuralarchitecture searchesdefinitely seems like something thatwill have a huge impact andand it's interesting because things likesay the division transformers have hadsuch a massive impact and then all thesedesigns now as they're trying to figureout how to go beyond 512 tokens and thesparse transformer long former winformerall these kinds of ideas that seemreally exciting but i find it amazingthat um that a automated neuralarchitecture search like nas net or theevolve transformerstill hasn't uh say taken off and isn'treally leading the newarchitectures have you thought aboutneural architecture search and that kindof area of research and any thoughts onwhether that will take us to like thenext level so to say so by neuralarchitecture search are you talkingabout like the models that like try tomore closely mimic like the human brainmore so like where you um you identifysome building blocks some kind of likecomputational primitives that you mighthave whether it's adepth-wise separable convolutionmulti-head self-attention multi-layerperceptron average pooling along someaxis like or like a batch normalizationor different activation layers and youtry to encode that in like a zero onelike genotype and then you say useevolution where you mutate thosegenotypes and try to render somearchitecture that achieves oh okayokay so it's like evolutionaryarchitecturethat's really interesting umyeah i mean i thinksort of like a combination ofi think that is sort of the next stepbecausei mean if you think about the humanbrain we have like abunch of different like lobes that likeperform different functions that theyseem to be specialized insoum and they all work in tandem i assumei'm not neuroscientist butumyou know if if we can somehowtrain a agrand neural network that can actuallydecide oh this architecture isn't reallyperforming as well as we'd like toumand you knowreplace it with another one or likedecrease its size or something like thatum[Music]i mean it sounds likea pain to efficiently trainwith all those different sort ofarchitectures floating around but ithinkthat should that that should work i meani can't imagine why it wouldn't and iimagine itwould perform better than a lot of theexisting models if large enough yet ithink the current trend of scaling is uhthe mixture of experts thing where it'snot exactly like different parts of yourlobes have different say uh structuralforms but they have differentspecializations so to say and then youhave thekind ofmeta-learned learnedit's like the way the mixture of expertswork is you have an attention layer thatbasically says which which pathways tosend the computation to so it's you knowvery wide rather than very deep say andyou have the attention that routes alongthe width so that you don't have thedents because these models are giganticlike the latest um and they call it glamor some title like that from google islike a trillion parameters because theycan scale that kind of thing up likecrazy and then you have lessons like howsparsity works you have infinite withnetworks it seems likescaling width-wise is promising as wellso definitely a lot of interesting ideasand i really enjoyed talking about allthese ideas with you and i'm reallyexcited to see the evolution ofzencaster did a good job recording ourpodcast now and we'll search through thetranscript and i do i think that thereare so many exciting applications ofsearch throughpodcasts we mentioned a couple of thingslikesay having a paper reading group whereyou have 20 people in discussion and youmeet for say 12 weeks a row in a row andnow you have kind of a something that isworthwhile to search through and thingslike say commentary on events i thinkcould be something that you also end upwith these really interesting data setsso i'm really excited to see howzencaster integrates search and howsearch willhit the kind of podcastinguh medium and what kind of ideas canemerge and i think even just likechunking up the podcast into chaptersit could be a really interesting way toannotate it too and justjust like extracting the salient pointyeah yeah it was wonderful talking todayum thank you for having meumand yeah i'm excited to see how we vietgrows and how we can integrate it morewith zencaster i think it's[Music]i think it's gonna be great[Music]", "type": "Video", "name": "Weaviate Podcast #6: How Zencastr searches through their podcast transcriptions with Weaviate", "path": "", "link": "https://www.youtube.com/watch?v=npdJAxDDtmY", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}