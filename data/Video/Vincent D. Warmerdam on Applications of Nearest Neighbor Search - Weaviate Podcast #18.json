{"text": "Thank you for watching the 18th Weaviate Podcast with Vincent D. Warmerdam! Vincent is an engineer at Spacy working on ... \nhey everyone thank you so much for checking out the wva podcast today i'm here with vincent warmerdam an engineer at explosion ai which is a part of spacey and vincent is working on some really exciting things with nearest neighbor search and the things that we're interested in at we b8 so vincent thank you so much for coming on the podcast and can you tell us about the things that you're doing with nearest neighbor search sure thanks for the introduction um so there's a couple of experiments that i'm doing uh part of those are related to this tool that we make so prodigy you might have heard of it it's a labeling tool um and i have recently found out that for uh like some of my experiments it really helps to have a good approximate nearest neighbor uh look up around um there's two areas that i were there were i was pleasantly surprised where it worked quite well uh so one area is in the case of data deduplication turns out you can do a couple of really neat tricks there um but i also noticed that if you are like starting with labeling let's say an nlp data set and there's also a couple of tricks that you could do within the approximate nearest neighbor look up so um part of my work what i do is uh i i do a little bit of research a little bit of customer support um kind of like doing lots of things over the company um but usually whenever i do a little bit of research that also results in like a plug-in or a blog post and recently i've also been making some youtube videos on this uh stuff um so yeah i've i've been surprised at how flexible approximate nearest neighbor look up tables are for like a really broad set of applications but i but the main thing that i thought was interesting is data duplication and uh labeling weren't the most natural candidates that came up in my mind um so yeah that was like a pleasant surprise yeah i think this is super interesting at looking at how we can do this nearest neighbor search from just the obvious match the query with the documents thing and how we can look at these we'll dive into these two ideas of data deduplication and then bulk data labeling or say weak supervision and we'll have that let's maybe start with data deduplication uh can you tell me about the general kind of setup of this problem yeah so uh let's say that you have a questionnaire and you know there's a name and there's an address and zip code some information let's say and let's say that in this questionnaire i may have gotten interviewed twice but in one situation my name got misspelled um okay so that's a very clear example of a misspelling should not indicate a separate entity in a database so probably this has to get merged and you say this you kind of go like okay questionnaires are kind of cute but does it have business applications um and then you learn very quickly that like when banks merge for example their customer profiles also need to merge and it would be a shame if let's say the same mortgage appears in the data set five times um so this is like a genuinely important business case um but then you kind of think like okay what are the standard ways of solving this and you can go with the rule-based system direction you can kind of say well uh let's only look at people in the same zip code and then if the strings are similar enough of the name you know we can make a little candidate list and that's actually like a fair approach that will work for a large chunk of the data uh but probably not all because you have high precision but maybe not the highest recall when you do that but then if you start thinking well maybe we can do like a little encoding trick where we say let's take a name of a person and let's take three grams like the characters so to say so vin and then i n e and like you basically encode it that way you get this little sparse array um and then even if it's spelled slightly differently like the sparse arrays will still be somewhat similar because there still will be a bit of overlap with all these character engrams so that can get you thinking like hey maybe we can encode some of these categorical variables as text with just a sparse encoding and then if we just index all of that and we have a new candidate and we just say look this new candidate is there a duplicate of it just fetch the 10 nearest items and uh if there's a duplicate that's probably in that set of ten items um and of course you can do fancier things if you're dealing with text um similarly you can also use embeddings let's say but i've noticed just with some of these sparse tricks like the sparse embedding ones the results were quite reasonable um which you can do some fancy things like you can also do thresholding right so you can look at the distance of the items that you get back and you can kind of say well only look at the items where the distance is this big or this small et cetera uh and i was actually pleasantly surprised how easy to set such a thing up and also that it kind of just works um the the way that you encode things especially if it's like names and you're mainly concerned about spelling um like the standard encodings for sparse stuff really lends itself well for these kinds of lookups um so it was like a very pleasant surprise um if folks are interested uh this is something i'm also exploring on the youtube channel using prodigy but just the whole idea of maybe doing data duplication this way i think it's very powerful yeah so it's um so when i hear data deduplication i think of it maybe usually from the perspective of say you're training a language model and you get internet scale text and you want to de-duplicate repeat instances or i guess generally looking at data sets where you don't want to have the same instance repeated twice because maybe with the kind of bias of gradient descent it's going to be overfit to that particular kind of thing but it sounds like you're coming at it from the perspective of say uh knowledge graph construction or uh this kind of customer databases yeah like a little bit more in that wrong yeah yeah really interesting it's really interesting way to kind of summarize the data set too by merging similar vectors how does this differ from say like a k-means kind of clustering sort of compared to just kind of like merging it down with the semantic categories i mean so the download k means is not an unreasonable idea right but you do immediately hit the issue of how big should k be like that's kind of like okay you solve one problem but you also introduce another one and you simply don't have that if you just have a sensible way of encoding things um and again it depends a bit on what your concern is right so if spelling errors are your concern then sparse encoding is like the obvious way to go about it if sentiment is more your concern and it's like a bit of written text and maybe you're a bit more interested in bot behavior let's say like hey is there someone who wrote nearly the same thing uh then at some point you know language models and text embeddings those things become a bit more interesting um but one thing that uh that i realized as i was sort of doing this work is um if you have a tabular data set let's say some names and addresses or a graph right and different nodes you can choose to encode uh each column differently so you are free to say like okay but this is a user with a name okay that's going to be sparsely encoded and what the user is saying right that can be with dense models and you just concatenate the two um maybe do something more fancy with like dimensionality reduction as a post-processing thing but that also can just still be indexed like that's also like a an aspect of like deduplication with approximate errors neighbors that i think is pretty interesting too there's you can use the same column in two different encodings you can encode each column differently and you can actually use a fair amount of domain knowledge to sort of steer the algorithm the way that you like so i think there's a lot to that in this so we're getting on the idea of how we encode the data how we produce the representations and this idea of say sparse representations which are say like bm25 tf the idf or say the counterpart just ones and zeros yeah yeah and and um infusing that with the vector representations that come from usually sentence transformers i think is what we're thinking about with text and dense passage retrieval these kinds of ideas and fusing those two so so maybe we could go a little further on this idea of how are you thinking about the combination of sparse representations that are usually based on some kind of keyword counting what like how and i think they vary mostly in how the vocabulary is constructed and uh and then fusing it with these dense retrieval methods yeah that's a great question because a lot of what you're mentioning there is a bit of an unsolved problem because you you can go ahead and just concatenate the two right you can say i'll just concatenate the spar stuff with the dense stuff and you can wonder well what kind of effect will that have for like distance measures is the distance measure that i'm interested in for like the text is that going to be different than the distance measure for like the users uh it might start getting a bit tricky one thing you can do though and this is like not step one per se but maybe step two so let's say um step one is the the simple trick was just sparse vectors for now but by doing this we have actually been labeling two right so okay this was an actual duplicate this wasn't and this was an actual duplicate and this wasn't okay the moment that we have a couple of these examples then we can say okay part of my input is sparse part of my input is dense i'm going to put a dense layer behind that and then i'm going to have after that like an actual label that i'm going to try to predict um like i think this might be the neatest way to sort of merge the two together because then at least there's some sort of a signal from your label determining what the next layer should be and then you can use that hidden layer as your next embedding for your uh lookup so to say yeah sorry so so that that's an approach that i think uh is quite reasonable um but it does of course always depend on your data how many columns you have etc but yeah maybe we could stay on that a little more the idea of you have your say bm25 representation and then you have the representation that comes from one of these sentence transformers so we have two vector representations and then say we want to put that into another dense layer that is going to do the say we could call this multimodal fusion if we'd like yeah not sure some phrase like that yeah some phrase right yeah so what would that architecture look like we have the two vectors should we maybe uh would it be like an attention layer in that like because we could have the mlp where we just concatenate the vectors like if you're asking mine so i would start simple really right i mean especially because in the beginning you're not going to have millions of data points right um so then keeping it lightweight is probably the most reasonable way to go about it um and also the thing like if you want to do stuff of attention typically you also need an extra tokenizer involved and the order of the tokens might start to matter and stuff so it's not just the it's not just more vectors it's also some of that stuff you got to keep in mind and again like my vantage point at the moment is a little bit more that i have a table with many columns uh and then for one column i suddenly need a tokenizer and for the other one i don't to keep things simple i would just keep it fast forward and dense um and also like a thing that i've noticed with this deduplication stuff um at least on the data sets that i've been demoing on um imagine that we're actually doing this for like a bank let's say we're trying to merge customers together and then at some point it turns out that uh for some people there's like a typo in their social security number let's say but for other people just a completely different number like obviously a different number um okay yeah maybe that's a duplicate but that also should be flagged for fraud right so the business case also whenever you're doing something with duplication there's a lot of the time i would say maybe also like a fraud angle involved and because you're then also in the realm of multiple targets that you might be interested in right um then you kind of want to have a neural network maybe with two output nodes and then again keeping it simple just the dense layer i would argue is probably the first thing you want to do yeah i'm really happy you brought the banking data set idea into the picture because i think our conversation is getting into that realm where having a data set really would help communicate this idea um so the data set to me that jumps out the most and i'd love to get your comments on this is the core of question pairs of duplicate questions but maybe it's not maybe it's not long enough i know those questions are usually only like 10 words long and you know as i've been studying vector search with we v8 i've seen like big and maybe not like massive inputs but only 10 words long is not great for this idea if we're going to combine bm 25 and dpr and have a another density on that it's not really the best data set for that so maybe another example and again the banking example is is great although i i think i'd like to first start with something that's purely text for drawing how we do this so maybe we could use the the same heuristic they use in wikipedia where to train the sentence transformers they use the heuristic of neighboring paragraphs are going to be positive [Music] so and it gives us a good sequence length of say like 200 tokens so we can combine bm 25 and dpr so so say we take the wikipedia data train test split and then we have our bm25 of each paragraph and our sentence transformer embedding and then we train our you know the dense fusion layer on top of that to have the agreement do you think that would be uh a good example of tying this together yeah so i my background's not really in search so much so what i am going to attempt now is a little bit of a guessing game and someone who's more knowledgeable might be able to tell me that i should read another paper but um just for just pragmatically whenever you're going to be doing some merging right um can we guarantee that the labels are of high quality because we are probably going to have to say like okay we have to be super sure that this is an actual answer to that question or we have to be super sure that this definitely isn't an actual answer to that question and because we're dealing with language this is not there can be a whole lot of nuance right um and my impression is that there's a very similar problem in the realm of like queries and so this one query that a user typed and then the user then clicked this one other thing while would the user have also clicked something else you don't always know so i think from my perspective the issue is maybe not so much the architecture that i would be primarily concerned with but maybe more just a data quality like am i really really sure that i have meaningful labels that can actually propagate some sort of knowledge into these layers um having said that the moment you are sure about your layers then it's much easier to iterate because then you can trust your metrics a bit more as well um but especially if you're just getting started with this deduplication stuff i would be more worried about that like are we sure it's a fraud case are we really really sure it's an actual um duplication or is this or is it actually a person who lives in the same street who just has a slightly different name because that also happens yeah the the part of encoding it is so interesting and maybe quickly before we go into the bulk data labeling as well could we could you expand on the idea of the index or half of this one of the most interesting parts of we've eight is that hmsw built in the approximate nearest neighbor benchmarking in that whole world uh could you tell me how like that kind of approximate nearest neighbor search for say large scale deduplication what that kind of picture looks like well so it usually gets started on a small set right and it's also something i've noticed with the annoy library the annoy library is quite good but the moment the data sets get uh fairly bigger um you're going to want to start adding more trees quickly like uh i used to be a bit more positive about this but especially like i've noticed that with word embeddings as well you might want to have 10 000 trees which feels a bit much but that might actually be quite reasonable um so the main thing from my perspective at least because i'm more interested in data quality uh whatever a n solution i have i kind of don't want to think about it too much um so i do think that the stuff that i've been using so far is in the realm of medium data uh and for those sorts of things like in memory stuff like a n pine and descent those things kind of work but i do know if i'm going to go bigger then need like something of a more formal like proper database solution uh like and i can definitely imagine we've yet being a tool to consider there yeah yeah quick quickly before uh could we stay on the the 10 000 trees and maybe explain to our listeners a little more about how the annoy algorithm works for dividing up the space so so to me annoy is very similar to like binary search trees it's just instead of a scalar greater than or less than it's like a hyperplane that divides this n-dimensional space um yes and there's no stochastic algorithm too so you have ten thousand so could you could you explain further how you get to twelve thousand um i could be somewhat wrong but my impression of the algorithm at least is uh you just pick two random points and you to make a plane between those two random points and boom that's your first cut and then from each leaf there you repeat and basically you do this a whole bunch of times and then you have one tree and then you know a binary tree so the lookup in the space can be quite fast and okay you can do that with one tree but then the odds of you being in a leaf and then missing a couple of interesting neighbors is quite big so you know what we do we make a second one of these trees or maybe a third and then we put that in kind of an ensemble to figure out who the nearest neighbor should be um and on smaller data sets you might be able to get away with 10 of these trees but for larger ones i've noticed uh you you definitely might want to increase the number of trees just because otherwise it gets quite approximate i will say like uh i annoy is pretty quick when it comes to indexing like that's something i did notice it was actually you know it's written i think it's written in c plus as well so it's actually quite fast um but uh you do want to keep an eye on this one hyper parameter that's one thing i've noticed you should not uh you should not blindly assume that 10 trees is enough because once it gets bigger it just isn't so you ensemble the nearest neighbors from 10 000 trees to get all of the potential duplicates in the data i believe i believe that's what they do but i uh but i could be mistaken because i didn't i didn't check the c plus source code to know for sure but i believe this is the approach that they do yes yes yeah it's really fascinating i love thinking about this idea of how the deduplication finding nearest neighbors and then how you do it at a very large scale i think that's really interesting and and um maybe quickly we could kind of just entertain this idea around deduplication for language modeling data do you have you thought about that kind of thing and do you think that's interesting yeah so before i used to work at raza this was actually kind of a pretty big topic there like hey when can we understand when someone is saying gibberish like something we've really never seen before but the very simple conclusion i just keep hitting my head on is just that language is hard and there's a book from emily bender which is a little bit more about linguistics for people who are doing nlp and the first chapter just nails it on the head on this topic um a language like language is more than just a bag of words if i take the sentence a lion eats a man and i take another sentence a man eats a lion one of those two sentences feels a bit more probable than the other one but how am i going to teach an algorithm that right and and then language is also like a moving target and then we've got internet slang and oh can we also detect sarcasm and emotion and it it's really just a hard problem so again the way that i would approach this is to just remind yourself that the learning is really in the labels if you want your algorithm to have certain behavior just make sure that that behavior is really encoded nicely in the labels itself and and that's where language models although they're quite useful you're usually predicting like a masked token or something like that and you can wonder well is that really the pattern that you're interested in in your application most of the time it isn't and that's why especially with explosion with a tool like prodigy we really advocate for like okay like focusing on the labels that's probably where you can steer the algorithm the most yeah and language is hard by the way and language is really really hard that's also the reminder that i keep getting uh when working in this field yeah that notion of language is hard and i love that you brought up that uh work from emily bender and it reminds your paper from emily bender and alexander kohler i think it's titled uh something like on meaning form and understanding in nlu sounds like an uh emily bender paper yes it's a great paper it really helped me think clearly about this and and let me quickly tell you a story from the paper that i that i think really does this well the anecdote is this there are two say me and vincent we're stranded on islands and we've got a underwater cable that takes from my island to vincent's island and i'm saying you know and i'm describing the island of vincent you know there's palm trees sand and we're passing language through this cable and as the anecdote in the paper goes there's an octopus that is oh yeah i think yes i i think do go on but i fakely remember this now yeah yeah so the octopus is intercepting what we're saying and so the octopus sees our messages and it learns how to you know cut the cable talk to connor talk to vincent and vincent and i don't know if it's each other or it's the octopus but now you get in i like to think of this as an of distribution event or a domain shift event where suddenly there's a bear on my island i'm like vincent help me there's a there's a bear and how is the octopus supposed to know what a bear is in general emily bender has a lot of these arguments that are like um so so i'm also that's also the thing i don't know what your background is but i'm not a linguist like i was dyslexic i used to hate languages when i was in high school and now i've gotten more of an appreciation for it but i've always i've always noticed like also with some of my colleagues if they have a linguistic background uh there's just so much more of a radar for these sorts of hey language is actually really hard that this can also be happening um but yeah now the the i do remember that paper emily bender is worth uh uh we're keeping an eye on uh because of these kinds of papers he also did the stochastic was he was part of the sarcastic parrots one as well i think right uh i'm i know i should be but i'm not like terribly familiar with that one no but there's a bunch of super influential papers and papers i'll say that yeah and uh we've been working on but yeah um yeah there's definitely lots of language in it and it does make it things like uh adding symbolic structure with like syntax trees all i think all that kind of that stuff could be really interesting and maybe i think a nice transition from here to kind of some topics in wva for our listeners is um is i really like the graph like data model and things like semantic relations and ontologies so kind of maybe to me one way to bridge the linguist knowledge and then make it sort of amenable to deep learning techniques would be to do these ontologies and have semantic relations between data uh have you thought about that kind of thing of say um maybe to draw an example if if i'm modeling my twitter data i might have tweets and then it has the content of the tweet and then it has has article and then this article is this other kind of object that has the content of an article and that's maybe that's an okay relationship uh idea of this another probably better example would be biomedical knowledge graphs where uh you start off with the knowledge graph where you have like uh drug has target uh as bonding target and then so you create the ontology that way and then you put uh text information that describes the genes describes the targets uh describes cities pathways things like that so i guess the question in the conversation topic would be have you thought about semantic web ontologies named relations as a way of adding linguistic style symbolic structure into the way that we're doing nlp so i've dabbled with this but very very briefly and i have colleagues who are way more knowledgeable about this than i am the only thing like from the what i will argue that i'm the novice here but from my novice perspective one thing that i'm really charmed by when i hear these sorts of things is i can imagine that if you have a graph structure you can't put a lot of domain knowledge in and that's actually quite useful like just in general the computer is the octopus who doesn't know what a bear is but at least you can tell the graph that the bears are mammal and dangerous and and hungry uh like stuff like that for example right and that's already nudging the algorithm kind of it feels like you might be adding a nice little constraint to your system and now graphs on the other hand are also still graphs so they're not necessarily like uh they can be complex too right so you're also introducing maybe some complexity but just that aspect of like yeah but we could put domain knowledge in that seems very useful to to me um for sure and so that domain knowledge interface could be useful for deduplication because with similarity labeling right you end up with a graph where you're saying this is similar to this thing it's also similar to this thing so so maybe we could talk about the idea and coming back to labeling too i think it ties it together like how do we label similarity ah that's the eternal question that we've not solved yet i think but um like the way to think the way i like to think about it at least is again sort of coming back to the whole idea of the learning is in the labels so uh before and uh i was talking to a retailer the other day what a very interesting one so um when we are out of normal spaghetti what is a good replacement product well to some people uh it is going to be uh another pasta like any other kind of pasta but to other people it has to be spaghetti so i'll just get like uh the the whole oats like the super fibrous spaghetti instead okay who's right well the similarities in the eye of the beholder in a way right like it depends on the use case too and you can also imagine that um like if you have kids for example the shape little shape of the pasta also matters because kids are stubborn they will only eat the one pasta in a certain type of shape and the food analogy but like but similarity is really also kind of an opinion if you think about it so the way i just really like to think about that is just okay we have some sort of business case we try to define it as clearly as possible and then we try to label with like in a consistent way and we try to achieve some sort of a consensus um there's a very there's a lot of interesting work also happening in this space um if you want to have a fun look uh there is the google emotions data set and what's the data set has lots of interesting label errors at least from my perspective but the interesting thing is they also have the annotators in there so you can actually track like hey when do annotators disagree um a ton turns out like uh just and especially in the realm of emotion detection right um when is it sarcasm when is it humor uh when is it actual joy uh when is it actual anger a lot of that is dependent on culture which is really dependent on where you live um so it's not necessarily a surprise that even if you are a fluent english speaker but you live in the other side of the world and you're 40 that you're not going to understand what 20 year olds in the u.s are posting on reddit or not perfectly at least no one should be able to blame you for it and i think the best example i had while researching this um folks who are interested there's a youtube video i made for prodigy on the techniques that i use but there was one oh my god those tiny shoes i want to boop it snoot like that was like the sentence and then the question is is this about excitement i would argue it is something booping a snoot sounds like there's a photo of pet somewhere and someone wants to gently touch that nose so that sounds like excitement to me but i can't blame anyone for not understanding what booping a snoot is right that's kind of like internet slang in a way so there you so there you already kind of go like what is similarity well i would argue it's similar if a label says it is um but if again but hopefully the way that we encode it correlates with it and that's kind of useful when we have a nearest neighbor look up um so let's say i have a whole bunch of reddit data um i'm just gonna use whatever featurizer uh whatever transformer just sort of index it and odds are if i can just have one sentence about a topic that i'm interested in kind of zero shot i am going to get examples from my actual data set that are at least to some extent similar so if i'm let's say doing social media analysis and i have um i don't know a support desk for a local retailer um then if my delivery is late then i can just type my deliveries late encode that and hopefully what i get back um are things that are in some sense similar um but that then you label and then you might get a better embedding so then you index it again and then you get into this little kind of weird active learning loop where you have a model that makes better embeddings which you can actually use to re-index and uh hopefully by just iterating on this uh you know you you're not just iterating on your model you're also iterating on your data and that hopefully is going to lead to like a very tight definition of similarity but that's at least how i approach the like to think about it at least yeah and i'm so excited to get into that loop of active learning week supervision and how uh say we've yet and vector embeddings can help with that quickly i want to just tell a little more about the annotation disagreement i i was very curious in this idea of semantic relations when i first saw we've eight and i was because i to me the idea of vector embeddings and also adding the kind of named relation thing wasn't an obvious connection i asked bob about it and bob told me the story that uh he was at a semantic web conference and they were building ontologies and they couldn't agree on what a c was or a lake like just see this is a lake to us and it's that kind of disagreement in the relations that i think you can that these embeddings let you really capture because i because you can have two labels where coming back to your example it's sarcasm or it's excitement you can't really read it but you can have the two labels and it can kind of optimize for both the labels and and capture the semantics that could be either thing in that vector representation and then yeah this general idea of annotation disagreement with human labeling i think that's i think there's a lot to that especially when you're uh labeling really complex things like say you're annotating scientific papers and so there's a there's a paper uh i hope i pronounced his name correctly there's a bunch of authors but uh yo of goldman goldberg i forget his last name terribly sorry but uh the the paper's title is something along the lines of uh are we annotating the task sorry are we predicting the task or are we predicting the annotator um which is a really good question if you think about it turns out a lot of the annotated data sets out there not at all all of them but like a good chunk of them you can kind of wonder well how's the annotation in balance is it like a 2080 rule where maybe 20 percent of the annotators annotated like 1280 of the yeah okay turns out for a bunch of data sets this is kind of happening so then you can ask the question uh okay um can we maybe predict who annotated this thing or can we can we make a prediction per annotator so then the model output becomes not just hey what label is this but what would this annotator give for this label so the paper makes a point here to say like hey the label is not perfect that's a genuine concern but another way that i like to think about it uh it would be kind of nice in production if we could say hey the model's just kind of not sure so like won't predict it's kind of like a flag that we can do we're only going to be automating when we're actually sure about our prediction and now suddenly if you have let's say 20 annotators that you're kind of predicting and let's assume for all intents and use cases that you're going to do that correctly pretty accurately then the moment that you know not all predictions agree that would imply that maybe you're able to model that annotators wouldn't agree and that might mean that in production you should raise the won't predict flag yeah that's brilliant that sounds like a really exciting idea to me and maybe like a well annotated data set is one in which you can't predict the annotator well so annotation's hard right but genuinely like um it's it's much harder than i thought uh and also like back when i gave trainings in data science one of my favorite things to do was let's first annotate the data set with sentiment because half the time we're actually going to not agree on the label uh and then what what i also recommend people do is even if you're doing like a toy data set thing trying out the new transformer library just check the data first because label errors are persistent um there's a website labelers.com i don't know if you've been no but like um the quick draw data set like according to their estimates has a ten percent label error or ten right uh i i believe um the amazon sentiment one has like two percent label there and that's well like you know within the margin of state of the art so it's uh it is just a hard problem again the the only cure that i know or remedy i should say it's just uh the name of the game is iterating just every week you try to just have a meeting and you make sure that the data scientist also labels and the business person and then you kind of go like okay let's look at the examples we got wrong okay do we agree with the label that it was predicting yes no and you know that's uh that's the the remedy but it's not easy like the modeling is the easy that's just tense this is an extremely interesting topic and i love exploring this application for we've eaten and how we can tie it into these active learning uh loops and so so here's how i see the picture of how we can help with this and maybe could uh you know add to what i'm missing but so i imagine that we're say we have some uh you know we're looking through our predictions and we see oh this one has been mislabeled then we find the nearest neighbors to that one and that's going to guide our where we're going to go look for more mislabeled points so that's so that's a tactic and that's definitely not a bad one um one thing to keep in the back of the mind like the situation always kind of depends like you might be interested in just sampling more from the rarest class right like that can also be a really good reason so you just say look there's this one class that i'm really interested in but it's kind of rare maybe sample more of those and you can still use again you can use the nearest neighbor lookup trick we're just gonna use it slightly differently another thing you can also definitely do is like hey let's just grab some of the examples where we have the most uncertainty and let's grab more of those um there can be more than just one valid technique um the one thing that i do um the one the one thing i'm trying to sort of figure out and i'm not there yet um is just what's the most pragmatic way to go about it because maybe sometimes you'll just want to do random um that's a because i can imagine for example right um let's say we're doing a social media thing i'm interested in finding texts that are about a failed delivery like the customer complaints use case okay i might have lots of examples where i started out by just looking for the word deliver if the word deliver appears in the sentence it's probably about a delivery and if someone is going reaching out to customer service it's probably a complaint um okay so that can be a very reasonable place to start but then if you're going to look for neighbors that are very close to it you are probably going to get lots of sentences that just have the word delivered in it those aren't bad examples but it might take a while before you have a sentence with the word order in it so so okay how can you protect yourself against that well random is a thing that you could do and just do it a bit randomly make sure the search space is kind of covered uh there are also like some fancier techniques where you kind of do a k means thing first over your entire data set such that you make sure that at least there's a bit of coverage so say um but this is also kind of the tricky thing with active learning um you do want to construct a test set that's not just because we were sampling this way this week and we're going to sample a different way next week so but but but it is still a game of iteration that is something i do think is the pragmatic way to look at it and one thing that i was pleased by is that there are many tricks of going about this but having a nearest neighbor look up is actually like a legitimate um that worked quite well for a couple of the tricks that i was doing which uh which is nice because not every trick works it's nice that you find a trick that doesn't work once in a while um yeah yeah it depends how big your data set is as well like i mean if you only have 2 000 examples to start with then you can probably brute force it on your laptop but definitely the moment where you start hitting like a 10 000 and squaring that becomes a bit expensive so that that's kind of the time where you might want to start investing in the nearest stable lookup i think it's interesting also kind of the combination of the unstructured text like our data like text or images with this metadata as well and it kind of like what i'm imagining is i i really what you said to me about the idea that i'd want to do the nearest neighbor and then but look in the rarest classes go hit the tail end of my data and so that really stood out to me as being an interesting way to come combine the nearest neighbor search with say symbolic filters about you know which class is the rarest class you can add and you can and i don't mean to be too heavy on the features of wba but i i love that part that you can combine nearest neighbor search with symbolic filters to say like which sub which clusters are your data and you could use k means to add the symbolic values of which cluster it's in to do that kind of thing and yes i think so i definitely so the general comment i have here is in general post processing on the query is a good idea and there are definitely many ways of doing it um another like another simple way like in the case of deliveries you can also say give me everything back that doesn't have the word deliver in it but but but stuff that is actually kind of close like it's another way i'm not aware of the super symbolic feature you just mentioned in we've eight but uh but i do like in general i agree doing post processing afterwards can be quite meaningful that's definitely also a trick that's uh should be appreciated more because a lot of people just think oh i'm doing the nearest neighbor look up thing i got 100 items back then you can also still wonder well you don't have to go through all 100 of them maybe maybe just try to find the most 10 most interesting ones in that and then move on to the next uh item um of course depends on your data depends your task etc but uh but give yourself the creative freedom like that's the main point i'm trying to emphasize i guess yeah really interesting and i eddie and didlocker has made something about pre and post processing in the symbolic uh filtering and i'm not quite an expert on it but if people aren't interested in i'll leave it in the link in the description but yeah this combining of nearest neighbor search and symbolic filters very interesting for this kind of data labeling finding problems in data labeling so yeah it's really interesting so let me kind of pivot out a bit and ask you more of a broad question about this whole space of nlp and i'm very curious and something that guides my thinking is do you have a particular application and i do think that chatbot thing is extremely interesting but do you have a particular application that you're usually focusing on developing and you kind of generalize these abstractions into developer tools like uh like spacey and so on um so you mean uh personally or it's spacey professionally because i maintain a couple of personal open source projects as well but my role at explosion is a bit broad at the moment so like one day i'm doing support tickets the other day i'm doing open source stuff the other day i'm doing a couple of pr's to fix a couple of bugs the other day i'm making content so it's exposure my role is quite broad at the moment um but but you know we we also offer a consultancy service these days um and they are typically like uh to whatever problem a client has someone says hey vincent can we just uh you know zuma for a bit and like exchange ideas um but i also think in that realm of nlp that we typically have clients um it is a bit on the classification and entity detection like those kinds of tasks we we don't do generative algorithms i think at all um it's mainly like hey can we detect interesting substrings uh and can we maybe say something general about this uh this bit of text about this document and those are the typical things that we do those that's like definitely our specialty so to say and that's also where like our annotation tools can also kind of make a difference because we have ui elements that are like really really good for those specific tasks um so the that's the most typical thing i would argue in the spacey realm that you see a lot of but then again because i also do a lot of stuff with prodigy like a lot of my work is also making interesting demos um the cool thing about prodigy is in the end you can script it it's just a python backend so you can make your own custom labeling interface and use whatever your favorite python tool is so part of my job in that realm that is actually interesting i suppose also like in the broader sense is you can actually explore like what are cool annotation tricks that you might be able to do and finding bad labels is one for example like hey are there some tricks where we can automatically make a list of candidates that this might be a bad label and again you can use the nearest neighbor lookup thing where you can say hey the label of this one point is let's say class a but all of its nearest neighbors is b okay there you go there's probably something fishy happening there we checked it out um but but that's kind of if i can point out anything that's really fun about the job that i have is a lot of the time i can actually make really cool annotation demos and because i can use whatever tools python can use inside of prodigy i can just sort of do neural like basically anything that python can do and that opens up a lot of the doors um that said um the hardest part is usually what makes a good label like that's a qualitative thing as well that's definitely still the hardest part i think yeah what and then another questions and maybe a little scattered now but i'm sure so what do you think about maybe like a collaborative data labeling interface so like i you know i share it with my team and we all like so we it's like a ui but all of us are together it's kind of like say like notion for data labeling that kind of thing i mean so um depends on how you want to set up prodigy but the way a lot of people like back in the day when i was doing demos when i wasn't working at explosion the way i would just do it is hey data science class we are about to do labeling uh on my own local machine i've got the server running ngrok and it's now public and people can sort of uh join in um so it's just a server you can open it up on your mobile phone uh so that's actually something uh like there are these labeling workshops that is my impression this is something that people actually do like hey um team of engineers get together and they're gonna say like hey we're actually trying to maybe build a new use case um we're going to do a sprint of a week and day one is just going to be labeling and then usually after labeling for a day you kind of have you've seen enough data so you also know some of the exceptions um and like it's not necessarily notion because it is saved in a flat file most of the time but uh but that like i hear stories that people are actually doing this and one thing that i have her one story that i have heard that was actually kind of funny uh there are lots of these examples where you start out with the use case we're trying to do a customer sentiment or something like that but then after labeling you find out that actually there's fraud in here too because you're actually looking at like the raw logs and you're kind of going that's not a customer that's a bot where doing the labeling the use case can actually kind of shift because you are actually confronted with the data uh that is something we've also seen those are stories that i have heard let me put it that way super cool so the next question well quickly let me ask you a quick question just to fill in my knowledge can you tell me a little more about ngrok is that what makes it easy to create these uh you know like web services from python or it's more like a tunnel so it's it's basically like if i have something running on my local host on my laptop that's great but then you can't go to my local host but then i can tell ngrok hey just open up a little tunnel and then ngrok will then have a public uh url basically and that's gonna forward to my local machine so for demos it's really great not for production by the way don't do it for production but for demos and like showing stuff to the people locally right it's great um they have a free surface they also have a paid one uh but for especially for trainings and like just quickly sharing the labeling interface without having to worry too much about security and grocery i can highly recommend it and that plugs nicely with say google collab right where you can is that how like i know um like radio they give you like a temporary web address for your app when you run it in google collab is that how it's done oh i'm not aware so i i've never really used gradio uh and i'm also not the biggest collab user i have my own little linux server at home that i prefer to use but uh it could be i'm not a so can't answer that properly because i've not used radio yet oh yeah yeah i'm just curious i was um when i was looking through uh simcity one of your projects that you're involved in i saw the the way that you have that one line of code to set up the hosting and i was and i've generally been seeing these this that's a fast api server so that's just a fast api server um so the for folks are listening uh some of the ideas that we are mentioning here i made an open source project a while ago called simcity it's misspelled so s-i-m-s-i-t-y uh it's the joke that i had was it's all about building a neighborhood so that's why i call it simcity um it's a bit of a hacky project like it's it's it's a brain fart that's pip installable but it's not like i'm actively maintaining it so feel free to play around with it but don't expect support sorry um but one of the things that you're able to do the the goals that i had there just very quickly was that i was able to sort of do exactly what we just talked about here's a data frame here's a couple of columns here's how i wanted to encode here's i wanted to index go and then you could use all sorts of ui widgets from jupyter notebook or just run it as a fast api server and you'd have your rest endpoint or you can just sort of say hey here's a json object with like a name an address etcetera giving back to the 10 most closest neighbors uh that like that old part it's the thing that tries to automate and sorry do you mind telling me a little more about fast api yeah so fast api is a it's it's basically like flask but has a couple of more modern features that are quite nice now i want to say modern here and i do want to acknowledge like the flash project has also gotten a couple of new features in so both projects have their own pros and cons but uh fast api is relatively fast as the name implies but it's just a very likable python server that's really easy to set up um there's it is a bit newer so the one of the main reasons to maybe still consider flask is that the plugin ecosystem is just a little bit more rich um but for example fast api did have like a sync support right out of the box um i think flask also has it now but they introduced it last year if i'm not mistaken so for all intents and purposes it's like flask it's a little bit more lightweight and you get a bunch of stuff for free so like the docs automatically generate for example for all your api endpoints if you add the docs string but fast api is nice if you want to make a quick web server such that other people can communicate with your machine learning app fast api is a pretty convenient way to just quickly set something up fascinating thank you so much for that really interested in the trending these kinds of tools that are making it so you know you if you're just like kind of a machine learning scientist it's getting easier and easier to share your things with people and and yeah these kinds of tools um so let me ask you another uh sorry well i'm gonna make a little pitch then so uh i do also host this thing called calm code uh so which is basically like a learning center for like stuff that i made uh it's the premise is it's like educational content but not on youtube so i don't want you to get distracted uh but if you're interested in ngrok or fast api i mean there's free tutorials there uh if people are interested in learning it um it's two to five minute videos after watching for half an hour you know how it works uh so ngrok fast api if you want to learn it tons of places where you can learn it but comcode i've made a couple of tutorials so if people are interested those are for free uh please watch they're great tools they really are in addition to the quality of the content i also have to complement the quality of the styling on that website it's not a little cool black and white icon thing um so okay i'll make another pitch there's this project called the noun project and i can and i'm a paying member it is the greatest service effort for every single noun they have a black and white icon both in svg and in black and white it's amazing for presentations the noun project is an amazing amazing uh bit of software that i'm proud to pay money for it is the best and yes every icon that i have on the calm code comes from that website um and i kind of just love how it has like a you know portal the video game it kind of has like that kind of a vibe to it as well yeah but but yeah i don't want to take credit for those icons folks over at the noun project should but non-project's great so on the topic of making content can i ask you about kind of i don't know if it's too into like yours your you know core strategy but could you tell me about content strategy and how you think about that kind of thing and yeah well i mean so the story is a little bit funny um basically uh the way i got into this whole content thing i mean i was definitely like a teacher before so i taught calculus and university and you know there's definitely like a teaching thing i did that for clients back in the day um but the way i got started in this sort of content developer advocacy kind of stuff was i went to this conference called spacey in real life and when i went there i had never done nlp before uh but i figured you know a spacey cool project if i go there i might learn something about nlp um so i you know you uh you hang out with people and i actually met matt and enos like the founder of the explosion company and you know you go to a bar and at some point i make a really bad joke i go up to matt enis i mean i say the previous bar is really busy but this one is nice and spacey you know really really corny joke uh but apparently from my perspective yeah i didn't get hired then but what they told me what they told me was vincent we think he would youtube well you know a little bit about data science you're kind of you have a good voice and you're you know you're kind of funny would you be interested in maybe making some spacey content and i figured you know i can learn from like the two people spearheading this project which is making a huge impact uh if i say yes i'm gonna be able to learn from them that's a pretty good deal and um i'll i can give this whole youtube thing a try that's how i got rolling um but the deal that i did made because i didn't really want to become a youtuber in a sense of click and subscribe like that felt kind of lame i genuinely wanted to just make um like a nice example nice and tangible like if you want to apply spacey let's just show how you can use it to solve a problem and they were super on board with that as well so it was like two hands on one belly as they say in the netherlands um but the funny thing then was i was making some of the spacey content and then right around that time people over this company called raza they were interested in someone who could explain algorithms and then they said hey vincent we like the style we see on the spacey thing that you've made could you do something like that but for chatbots so that's kind of how the ball got rolling but the main thing i really care about is that i just explain things relatively clearly and i think that's enough i'm sure i don't mind if people follow me on twitter and i also speak of pie datas and i like it if the room is full sure but i get a little bit annoyed sometimes where you're looking at like a youtuber trying to explain something in data science there are plenty of really good ones but i wanna but it has to be about the content like i really wanna see like a really nice explainer i love seeing what people have like i found an interesting data set and this one trick works in that data set i don't like it when people regurgitate this i could learn docs um that's the main thing and it's also why on the comcode website i don't want my face in it because i really wanted to be about the content now of course i also make videos for explosion and we put that on youtube and we don't have a coherent style so there it makes much more sense that my face is also perhaps in the video uh but my personal uh preferred style is to just have very calm content that's the thing that i like uh most and i'm trying to do that on youtube as well the only downside of the platform is that every turn it does try to distract you with its recommendations so that's kind of a bit of a downside i suppose but but i don't really have much of a content strategy besides i try to make good interesting content by trying to find interesting examples uh and sure you know we we have a content planning thing where if i've made a 40 minute long video we do want to announce it properly right so yeah we do that but i really just try to find interesting content first that's that's the strategy and one of those and one of the first things i made for explosion was deduplication by the way like how can you do deduplication using prodigy uh because one thing i one thing i uh in general that i have observed is i mean prodigy is great for labeling nlp tasks but there's way more tasks just like with these nearest neighbor lookups um that you can apply it for and really goes well beyond lp uh i mean i can also imagine a m being useful for some computer vision tasks like that wouldn't surprise me at all um but i can but i but i get why there's lots of nlp content out there because i also see those applications uh but uh a n stuff and also like the labeling stuff goes well beyond just nlp this also kind of the point i want to make with some of the prodigy videos that i'm making there now so yeah long story that's our strength that's my strategy the last thing you said i do kind of want to talk about that a little a little more the very last thing you said about the nlp computer vision thing and uh well but sorry but i the story i found really interesting and i actually kind of want to get into that a little bit more so it seems to me like you know you're engineering by day and then you you know you the problems you solve you turn into content and that's kind of the way of thinking about it rather than like the i'm seeking the purpose of this is to make oh yeah so for com for calm code for sure like i've not made content in months because i've not seen it so uh but i will say like for prodigy it's a little bit different uh because for prodigy i am actually sort of actively looking for what would make a really cool demo to show off a little trick um so it wouldn't surprise me if maybe at some point i i show off an approximate nearest neighbor trick let's say because that's something i'm actively sort of trying to figure out and similarly i also i'm also doing some annotator disagreement because i'm pretty sure like if i just have a couple of data sets with google really cool examples of annotated disagreement then i could probably make like a good blog post or a video uh so um like the one thing uh also like calm code and my personal blog those are like my personal projects and i really like having an off switch but from prodigy that's so that means that you know a good chunk of my week i can think about like what would make a really compelling example and what's like a really uh cool feature that we might be able to show off so that i would argue like there's a bit of a difference there in that sense yeah for me this part of showing a really cool example is so much about finding a really cool data set do you agree with that yeah you know for sure if you don't have a cool data set it's kind of like uh oh we can make maybe we can do a benchmark on uniform data you kind of go yeah i know i see i could see why you but yes technically you have a benchmark it's just another very interesting one right um so for sure but finding the data set for sure is like one of the harder parts though yeah yeah i love working at a database company because i to me it's like the algorithms they're awesome but it's like let's find more data sets to hit this stuff with you know like that kind of task of i always find myself drawn to let's go find a data set or let's build a data set you know and that kind of thing always appeals to me yeah and um it's also kind of the thing where you want to have a data set that's also not too small not too big right so this interesting data set is also not necessarily a well-defined definition but you what you're hoping for is that you have a data set where you can sort of tell a story where at some point there's a like a luke skywalker and a darth vader in your data set and at some point you're trying to figure out like who wins let's say uh could be and that was like um i i would like to do a little bit more with fraud data that's like access logs or something like that i think that could be interesting too um also because there there's gonna be some sort of encoding you're gonna wanna have maybe with some urls and timestamps let's say but it's also not really nlp it's structured text but definitely for sure you can do some interesting stuff there i think um yeah maybe quickly we've i had some conversations about maybe turning structured data into text like where you parse the table to try to turn it into text and and this is like horribly off topic but what do you think about it yes i i i i might have heard someone trying something like that um never done it myself to be honest like one like especially when i talk about tables like one thing i have also um so a use case that i'm aware of is that they thought like oh we are going to be scanning documents and then we're going to do ocr and then we're going to try to see what the values are in a table let's say and then you can kind of wonder well is that an nlp problem or is that maybe more of a you know a computer vision problem let's say because maybe you don't have to scan the entire document maybe you just need a pre-processing step that says hey where's the table right yeah so um so i do know a couple of people who are working in that realm uh and also that's not necessarily a solved problem because with tables you gotta imagine yeah you got english but you also have tables written in chinese so you also need to be able to handle those and that's substantially different typical ocr stuff doesn't handle both chinese and english at the same time but again a lot depends on what's the right label and what's the use case that remains the same you have like document structure understanding thing that seems like booming application as well you got the legal documents maybe you got like invoices or medical stuff yeah yeah yeah well thank you so much for uh coming on the eva podcast i love talking about deduplication bulk labeling and just all these topics it's so much fun to chat with you and thanks again happy to hear it ", "type": "Video", "name": "Vincent D. Warmerdam on Applications of Nearest Neighbor Search - Weaviate Podcast #18", "path": "", "link": "https://www.youtube.com/watch?v=Nwh7L4Do0Fg", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}