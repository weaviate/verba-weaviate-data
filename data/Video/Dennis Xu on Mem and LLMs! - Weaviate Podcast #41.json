{"text": "Thank you so much for watching the 41st episode of the Weaviate Podcast with Mem Co-Founder Dennis Xu! Mem is one of the ... \nhey everyone thank you so much for checking out another episode of the weeviate podcast I'm super excited to welcome Dennis Zhu co-founder of mem is one of the most exciting note-taking softwares out there and I think with this latest boom in large language models you know gbt4 and all this this kind of Knowledge Management like the next generation of note taking and just how you organize your information is one of the most exciting applications and so I'm so excited to hear Dennis's ideas and how you're thinking about these ideas so firstly Dennis thank you so much for joining the weekday podcast thanks so much for having me Connor awesome so could we maybe dive in with kind of the the founding vision of mem like this what's new with yeah absolutely yeah I mean so I I think you know the the story goes back pretty far um you know back in 2014 actually my co-founder and I um we uh we were both doing our freshman year and internships right and we were saying we were sitting at a restaurant and uh you know I pulled out my phone and I said given all that you know given how large your digital Footprints are given all that our phones actually know about us and capture about us it's isn't it incredible how little that we can actually leverage that information and that knowledge in order to actually then help us do things in our day-to-day lives even as simple things as you know remembering um remembering things that we wrote down in the past before which fundamentally is what note-taking is about right and and that's kind of like what we started with which is you know what is this Universal behavior that every single person at some point in their life does whether they write it in a note or or they do it by sending you know a text to themselves or whatever that is um to Simply help remember things and that was kind of like the you know the the origin and the beginning of a lot of those ideas and one of the things we imagine is well what if you could actually then uh create the structured representation we called it the me API right where you know you could carry this identity of you right anywhere that you would go um and you know essentially compiling notes into into knowledge into the structured Knowledge Graph this personalized Knowledge Graph um and and yeah that's that's kind of how a lot of the the idea began but um one of the things that we we've kind of always known is that you know notes were would be where we start um but the vision has always kind of been far bigger than that right it's um like what we're building on them is basically it's a personalized knowledge of this thing for every individual for every team every organization um and it's now obviously we live in a super interesting time where you know it feels like I've waited my whole life for this moment in technology is our car um we've always had you know there's always been things that machines have been better at humans at you know we've known that for a long time but those have always you know computation right or their process information faster but we've kind of always assumed that there were just you know these dumb objects that required uh instructions and very explicit instructions that you know had to be programmed by by an individual and now I think we've finally crossed the threshold where machines actually understand human language and you know we can talk about the semantics of whether it's just predicting the next token how much of that is understanding but you know I was having a conversation with a friend recently and and you know he said something that was really interesting which as well if you think about the objective function of a human um it's simply to reproduce but think about all of the different things that we have developed over time that have nothing to do with reproduction right and all of these capabilities right and so um right you know regardless of all that the the premise is now that we've machines that can understand human language the the power of this personal Knowledge Graph that you can build you know this personal assistant that you can build for anyone um is uh that's pretty cool yeah it's super fascinating I think I first came across mem when I would I'd write these like Twitter threads of AI papers and I'd see someone would comment uh at Mehmet to save it to the to them and I and that's how I first came back and wear this and seeing how it extends from just a note taking out to how it connects with other data sources with you know Twitter being the example I just gave but you know I'm sure you're acknowledged by all these different data sources that your you know information could be hooked into and I there's certainly a lot of to unpack in the story I really like that thing you said about the personalized uh kind of Knowledge Graph I like this I like we have this one idea kind of ineviate land called ref to VEC which is about how you you know have a user and then you interacted with these items and that's how you form an embedding for that user and some of these yes yeah yeah and I can imagine these kind of like Pages where you know say I create like a biology page and I start saving some things and then I have this embedding for biology and I hook that up into all these external sources as well and then it's like yeah analyzed yeah and you know I think what you're getting at is like everything that we actually do nowadays is captured in one way or another digitally um and you can create really rich embeddings that represents you know the current context and context really ends up being in most and almost like every assisted experience what what ends up being the the the key piece that's missing right like if you know if you knew exactly what I was thinking at any given point in time um it's actually not you know ridiculously hard to to surface the relevant information um at that point to you but it's just you know do we know what you're thinking at any given point in time right so yeah that that that idea is very interesting yeah so and so I really kind of maybe for the sake of the podcast and being entertaining I want to hop right into this gbt4 topic like how is this just kind of maybe the almost the clickbaity thing like how is this going to change everything uh yeah I think you know I so so here's here's the big thing I think you know I've heard a lot of people talk about how um you know gpt4 versus gpt3 and gpt3 is kind of this you know very vague term at this point because it's gone through you know three different evolutions and people have always called the gpt3 but you know the earliest versions of gpt3 were nowhere near uh you know uh well I guess like turbo 3.5 now or even Da Vinci you know two before that right and I I think it's it's pretty interesting to me um I think there's there's a lot of use cases where you're not really going to notice that many differences between chat GPT and gpc4 um and I think for a lot of use cases it feels oh it's like slightly better it's definitely better it's slightly better but it's slower blah blah blah right and then there's there's one thing in particular that that you know at least we've been experimenting with that we found um that I think is groundbreaking and is obviously being slept on is just the ability um for this to write code uh and to write incredible sound code that is better than extremely experienced Engineers can write when you know it has access to the entire internet's worth of knowledge um and all of that stuff right and so what becomes really interesting obviously when you have a system that can write code right is then all you need to do is give it an environment in theory and I think this is why there's a lot of you know conversation around safety and and all of this stuff right like AGI um uh opinions on on some of those things but I I think what's what's really interesting is if you can have something that can write amazing code and then you can give it an environment where it can actually execute that code now you actually do have this self-improving system that can in theory um do anything and learn anything autonomously right you just have to kind of give it the right tools right so obviously there's there's been a lot of conversation a lot of thinking a lot of um I would I would say it's still like in the early days most of the definitely the experiences and and the products and and a lot of the infrastructure too is uh in its toy phase still um like clearly people have have you know awoken to the possibility so I would just say the main thing with gpt4 for me um is the ability to write code and then I think taking you know one step back um the the way that I I've described kind of this day and age to just you know somewhere because a lot of my friends are like hey I've been hearing about this like you know GPT thing I'm seeing a lot of it um I don't get it like what I mean it's cool right like I you know there's like what is it and and and the thing that I would say is you have when the internet first you know really reached scale it made the cost of moving information affected the zero approach zero so the cost of distribution right and that's what enabled social media it's what enabled you know blogs and like kind of like you know what people would call like web2 right um a lot of that stuff and I think what has happened is now the cost of transforming information has gone to zero um and that is like that's that's that's really interesting obviously you know there are so many industries that are purely just about transforming information so many professions that are about you know just transforming information I've I I've heard there's already legal you know um legal and like you know legal companies and lawyers tend to be the latest to adopt new technology um but a lot of like you know paralegals Junior employees are actually being replaced by this technology even like already today um and you know you have anything that involves moving you know taking taking like all these ETL pipelines elt anything that involves you know previously would have required armies of Engineers and Engineering teams to both build and maintain a lot of that is now effectively free right so I think we're still grappling with the implications of a lot of what that means um and what that will mean all I know is I think things are gonna you know get weird and we'll see yeah I definitely want to come back to that kind of like ETL data ingestion topic but I think that idea to stay on that idea of how it can write code a little more it's been absolutely mind-blowing the ability of it like when we had Harrison Chase from Lang chain on we were talking a lot about uh and also Bob and light at the CEO of weba we're talking about like the the way that it could maintain software like you could see the errors and kind of maintain the software and just the general idea of you know writing some code executing it seeing the output and then chaining that to you know keep writing code better yeah it is yeah so and and then um I guess kind of one topic I want to come on in that writing code sense is like so as I've been trying to adopt it in my life I'm mostly dealing with these big code repositories so I'm thinking a lot about like how would the like the leviate code base which is even bigger than 25 000 tokens like how do I get get it to navigate this kind of thing this one I think a lot of these ideas yeah like blank chain llama index on how do you know exactly and I think this is like where we're embedding uh you know really plays a role too right I think also the whole world was kind of awoken too and since embeddings over the past six months um you know we we've been building um we actually started building on embeddings pipelines before we did actually any better stuff and this was back in December of 2021. um and this was you know back when the the best available generative model was DaVinci II uh and it was at that it was at that point where it was like interesting but not actually useful um you know reliably useful yet but the embeddings models were were obviously you know fascinating right because it in many ways it wiped away you know years of compounding advantages that many search companies had right that they developed like these you know proprietary technology just for search and then you know I think in a lot of ways a lot of that is becoming commoditized right with embeddings whether it's search recommendation systems um yeah I mean there's obviously still a ton of challenges building you know on embeddings with with each of those but yeah amazing and far easier than before yeah I think so obviously with the weave podcast the topic of embeddings is like the number one thing I want to talk to you about and I'm so excited about like I think I figured yeah so so with the to come back into the design of mem I'm very curious about like how you think about kind of like chunking up all the units in that go into the Knowledge Management and you know embedding it yeah yeah I mean there's you know I think here's the really interesting thing there's there's I think currently the primary school of fun um where most people are is you just have this what I call like this like blob of vectors um you have you know Vector index you you vectorize any piece of information as long as you can represent it in text although with multimodal models now you know um I started to make an appearance I think that's going to be really interesting as well but before before we go into that um and then you just dump it all in there and then you do a nearest neighbor search right and then you find the you know those things um and I think that works for a lot of the use cases that we can think about immediately and can think about now and a lot of like the search use cases that actually already exist um in the world um but what happens is you quickly start like for for any like real use cases that um are are deeper you quickly start to run into the limitations of basically just this like one shot nearest neighbors like you know that's what I get right um and you run into that pretty quickly and I think one of the things that we realized and this is this is essentially like you know how how we I think how we think about building our infrastructure you know differently is embeddings are a key piece of the puzzle um but ultimately you also do need structured knowledge underlying it so it's like you have embeddings that overlay in our case it's a structured Knowledge Graph right that we also use language models to build um right so it's kind of like imagine this you know database this actual database um like you know SQL database that you're reading and writing to right reading from and writing to and then you layer on embeddings on top of that and now you can do things instead of just like these one Shadow find you know the nearest neighbors you can actually do deterministic you know multi-hop queries that require knowledge of you know multiple different things all at the same time a lot of the things that you know I think um things like Lang chain right also like thinks about right um but if you think about you know it and I think this is all like you know developing but if you think about something like Lang chain um obviously one of the issues with it is because everything runs sequentially you know a it's expensive but I think that's you know going to become less and less of an issue um but uh latency wise it's expensive right um so but imagine if you could actually convert a user input whatever that is right into a set of deterministic graph reads right or you know database reads that we know are fast right um and and then retrieve information that way and then you um you know blend that actually with like a hybrid index using a netting I think that's a lot of where uh where the world will actually head long term yeah that idea of like question decomposition like are follow-up questions needed um I don't know if I'm gonna remember this off the top of my head but it's like did Einstein use a laptop like yeah yeah so you break it into the two questions to assemble it and yeah and that and there's kind of in the beginning of as I was listening I thought we're kind of getting into like the adding structure to Vector search and this topic I think is so fascinating especially when you're adding the large language model controller on top of this yeah a lot of yeah like a lot of kind of leviating the vector databases having support for the symbolic filters as well as the hsw the vector index and you know like things like in our 118 edian talked about the bitmap index the speed of and all these kind of things and yeah data structures right yeah that yeah that involve embeddings but it's not just this like single flat blob uh yeah yeah and so I'm so curious about this actually there's nothing I'm talking with Harrison about privately is like how do the large language models interface with these symbolic filters have you thought about this yeah yeah I mean so I think this is actually why the fact that it can write code this is really in right right accurate code um really comes into play right because now you can actually imagine you define a data structure you define a certain Knowledge Graph um then you can you can have the language models you can teach the language models right so to speak to know how to interface with it and to know how to query from it and to know how to write to it um and you kind of take that whole process that would have been you know teams of Engineers for each you know each Pipeline and each transformation before um into just like hey yeah so when Chad gbt first came out uh Bob had showed me this thing he's like he shows me his prompt sequence and he's having it write Json like it populates the Json dictionary so it's compatible to the next API call and all that was so fascinating um so yes I think that was a a really great top coverage of like the gbc4 and I I really want to kind of transition to this next topic this is a pretty big one which is the kind of fine-tuning models versus a zero shot debate and I'm curious especially with yeah um so so my my take on this um has been pretty yeah so so here's my take um I think it's clear we're at some point in the S curve of the capabilities of these language models I really don't know where we are on the s-curve are we near the end are we you know towards the beginning if I had to guess I would say there's no reason to believe that we're anywhere close to the to the top of it and that we're probably likely very much still in like the steepest part right and I think when we are in that scenario and and if we if we just play back what has happened over the last you know 12 to 18 months and we assume that you know uh things will continue in in that way then what's happening is every six months literally every six months there is a step change in capabilities and so depending on what you're fine-tuning a model for my my opinion is if you're fine-tuning a model to improve its General capabilities you know with some piece you know of your own data or whatever that is I think that's totally not worth it right now because I think what's going to happen is the next model is going to come out it's not only going to be cheaper it's going to be way faster right um and it's going to be way better and all of the time and effort you spent in actually figuring out how to fine-tune that model we'll go to waste except except and I think you know it's an important question to ask like what will not change um and this is really you know once we do get to the top of the S curve in progress you know slows when we no longer have a new state-of-the-art every six months you know it takes longer um the actual then at that point I think fine-tuning squeeze the you know the additional 20 or 30 percent you know out of out of these models becomes actually really useful and the question the important question to ask right is like what do you need by that point in time like what is the thing you need to act what is the asset you need to build over the course of that time in order to be able to do that and obviously you know it comes down to you know one way or another some form of data right um and you know even that's obviously it's a loaded term in terms of like how you you know what is actually useful data what it's not but um you know depending on how you define it at the end of the day it's the data is useful the actual time spent in in figuring out how to tune these models or even taken you know off-the-shelf open source model to you know try to you know do something with that to squeeze whether it's latency or performance out of it I think a lot of the time doesn't actually make sense um I think that the difference is um if you take something like a like a llama you know with alpaca right I don't know if you saw that that came out of Stanford um obviously that's very interesting because now you can have things that actually just purely run on the edge right you know run exclusively on your phone and that unlocks a whole new set of capabilities um that previously wasn't possible right but if what you're trying to do is replicate a set of capabilities [Music] um at least we we wish I away from from fine-tuning for that purpose we do we do actually do a lot of fine tuning um but that's primarily to make um the the reason we do it is to uh basically get a smaller model to do the job of a larger model at lower latencies and that will just you know obviously that data set continues to scale um as you know as as new models uh as models improve and stuff yeah I thought you said a lot of interesting ideas um I think to quickly I really like that s-curve thing you describe with this step function if it's doubling every six months it doesn't make sense to put the effort into it and Bob started to be referencing you so much in this podcast but he he was recently on uh coheres uh Twitter they had a talk where he said that basically he thinks that like 80 of these cases the zero shot model combined in a hybrid search with like bm25 lexical search that will cover most of these search cases totally yeah it's not completely agree with you but I really want to come there are two more topics that you mentioned that I think are so interesting the Llama Alpac alpaca thing where it's like you know it is related to the next topic of distillation where you're trying to get the large model compressed into a smaller model but um it gets I I think the reason the alpaca thing is so exciting is because people are like running it on their phones right like uh or yeah yeah yeah yeah and it's like the idea of I think when um when GP T when DaVinci 3 came out it was something like two cents per thous I don't know the exact price and like it was it was more it was six cents per thousand yeah it was it was pretty expensive to generate a lot of text so the thinking was like uh you got to be so careful about how you do it but now as it's trending towards zero it's like these language models could have like these massive conversations with themselves and as I think about mem I think about this idea of you know I create a a workspace where I put everything I know about contrast of representation learning and then I just have the language models talk to each other about like sample a paragraph sample paragraph and then build new knowledge over time and yeah exactly totally yeah yeah yeah yeah yeah yeah and that idea I think is incredible so so I I do want to come back to the distillation thing um maybe maybe one topic to begin is I'm very curious about these kind of like ranking models so like the large language model could of course rank these documents with very high Precision like if you have the query and then you have the top 10 it could give you a really great ranking uh so it is maybe I don't I don't know if it's like prying too much into exactly how the sausage is made but like how what kind of tasks are you thinking of distilling from large language models yeah um so there's there's that's one of them uh what you just mentioned um you know historically I think in search it's been called like a cross encoder um and I think there's still a lot of value and you know cross encoders but you can actually spin up like a a purpose-built Crossing coder really easily actually using you know kind of like a smaller uh you know one of these models right um and then you know it returns a lot of probs you can do interesting kind of math on top of that um a lot of interesting things there but there's there's a lot of things where yeah uh I'll give you one example you know someone says something um to their assistant right to their mental system like hey do this for me or you know XYZ um but it's it's kind of you know if we think about the assistant like as a person it's kind of unpredictable what you say to a person um and what you say might have different intents sometimes um what you the even within you know this is a huge problem within search obviously like search intent like is it is this a a keyword based intent right or is this like hey is this a vector intent and then yeah you like you know rank different things differently uh maybe you even uh and this is a lot of our Explorations is um what if you could create Dynamic uis right because depending on what the person is asking you depending on what the person is doing um there's actually totally a different representation of the information that is useful and valuable um but you know being able to even just like classify the intent of the message let's say um obviously you use the the most important use gpd4 on that and it's it's going to get it right like almost you know every time assuming you also give it enough contacts and all that stuff but it's slow it's slow it's expensive and you're actually really run it on their bigquery right and so when you when you have a task like that that usually experience okay you know fine tune is actually valuable right particularly when latency and or cost is the issue and you're okay with causing you know brain damage to the language model and being okay with them for getting everything else and only being able to do this thing right because then you can take a much much smaller model um to you know much yeah yeah to basically just do that one specific task right and then there's also like you know ways where you can use those models to generate training data for the smaller models and it gets really gets really meta but yeah yeah that last one's my absolute favorite idea I mean when you said the um the brain damage thing that interrupted my I love that topic so much that like because you when you fine tune it this like catastrophic forgetting how the robustness of it is gone now and yeah but it's very good at one thing yeah yeah yeah I kind of well I I do want to stay on the ranking thing just a little there's one question I have for you especially as you know product focus with the mem thing is is this latency constraint and how you think about because the cross encoder is really slow compared to you know Vector yeah yeah yeah well I think there's a lot of things um I think a lot of the Innovation that's going to happen over the next year is going to be on the ux side um you know internally we call this like aiux which obviously you know what that means um but it's you know to give you one naive example you look at what Bing does right where you type something in and it's showing you some of the work that it's doing right um I also saw this like in the stripe llm like for their documentation thing they did some really interesting kind of like front-end animations where first they would um because well they actually mirrored the steps of what happens right first they would retrieve a list of documents they would show you those documents first and then when the answer would actually come in it would push those documents down and as you know it kind of tricks you into thinking oh actually this is fast right because something is happening all the time um and I think there's like there's a lot of those tricks you can play you know kind of uh there and then there's separately um and this is where I think you know really having a structured Knowledge Graph in our case uh comes into play um there's a like if you think about most of like what makes search Fast right in search indexes uh it's just it's pre-processing um so if you actually have the data in a structured way such that you can pre-process it um you know into useful indices that's another way to to make sure that certain things that you need to be fast are fast so you know that that little the the knowledge graph topic is a funny one because with weavia it's not like rdf technology with these two full yeah I'd rather talk about hsw but that is very interesting the knowledge graph like does mem use things like neo4java or like tiger graph those kind of things as well no we we actually just we we build all of it on top of postgres yeah I also saw this thing with uh with llama index it's they call it like graph gbt where you could just kind of do like one query it's just like a client-side index yeah yeah like take a thou take a thousand search results and they'll build a knowledge graph in memory kind of yeah yeah yeah yeah yeah super cool so so maybe pivoting topics a bit I'm very curious about the earlier we mentioned this idea of ETL data ingestion to the kind of database part of it and um so yeah I'm really curious about like I I find this like memet Twitter thing to be such a fascinating integration with how you flow data from Twitter into your knowledge management and then yeah so I'm very curious like you know obviously open ai's whisper has unlocked like a massive ETL now people can take YouTube videos podcasts and just you know do it like that uh and then gbt4 I so I'm also talking with Brian from unstructured about hopefully getting him on the podcast as well and uh like gbt4 the ability of it to do OCR right images yeah yeah yeah yeah well I I wouldn't even call that OCR um because it's um at least the way I think about OCR is it just gives you kind of like a snapshot representation back right um this is kind of it's more like actually it's it's as if like a human could read the thing and uh you could you could ask questions based on it and they're just um Works kind of through this like language model right it's it's um so it's it's it's the the idea of multimodal like the encoder being able to actually create a representation um that is shared between texts and images and audio and you know video because if you think about kind of like what people are doing today you know this is another thing that I think is going to become obsolete pretty quickly with whisper is people are doing that on YouTube videos right um and you know it makes sense but you end up losing so much information because you have you capture none of the the visuals right um and so much of YouTube videos is the visuals so um you know you could transcribe and then you could try to stitch together the frames right from you know the the actual visuals um but if you could actually just go directly from an mp4 file format into the embedding that actually is in the same space as you know your text embeddings um that's where things get really really cool and obviously I think that's that's the future right so yeah I think we just saw uh runways is it called Gen 2 I'm sorry if I messed up the name but the this video generation generally the idea of processing videos so I my kind of funny story with this is when I first started doing deep learning I was a basketball player coming to grad school after basketball and after a failed basketball career and so I was like okay how do I build a deep learning software app for basketball and I had this idea yeah you could probably extract all the highlights from the games using like confidence yeah that works but the problem with that like one thing one problem of quite a few problems but like the image data video data it's so high dimensional the idea of like compressing a minute video into uh let's say 1500 dimensional Vector do you think that kind of like will need to be more clever about how we're doing it yeah I think I think that's an issue I I so one of the things I learned about maybe maybe this was Llama Or maybe this is something else um maybe it was llama but I think one of like the fundamental Innovations was it made it uh it it turned it from you know 16-bit um like values right per Vector to um to four bit values right and so it changed kind of like the the granularity of of what could be represented to basically just like eight values right between negative one and one um and that's really how they managed to get something so small um and yet it kind of keeps a lot of the performance so I think I think there's some really interesting you know kind of compression techniques that were just at like the very beginning of of discovering so um yeah I I'm I I have a feeling we'll be able to get to that uh pretty soon yeah that's fascinating I love that you brought that up but one of the big features new features of weave in 1.18 is adding product quantization where like you say we quantize the vector values from 32 bits that or well exactly yeah yeah there's there's like a couple parts to it but I think something about quantization there's kind of like two at first there was this thing called binary passage retrieval where you sort of optimize the contrastive models with that tan H Activation so it's kind of zero one naturally and then you have this kind of binary Vector that's longer but captures information I I think like quantization aware training is another thing that hasn't been realized as much because if you put it in like instead of producing the vectors and now we're going to run k-means tile encoder on the vectors maybe if you put that into the optimization it's like one of these interesting kind of yeah fine tuning maybe there's something to like a hierarchical structure all these kind of yeah this kind of idea of how do we like one of my favorite topics in weave Vector database is like how do you have a like there's we've done like a billion scale thing with like you know like sphere which is kind of like copying the internet and doing that kind of thing but yeah the videos and all that so maybe kind of even continuing on the kind of multimodal I guess I don't know if this topic is too out there for these kind of things but like are you interested in these recent advances in robotics and say things like say can rt1 do you think that will have some kind of role in this as well uh I've been Loosely following it but honestly I haven't been closely following enough to be able to say anything insightful yeah sorry I think that was maybe too tangential the topic I actually one thing I think is really interesting with the Knowledge Management thing is like the biomedical thing let's actually dip into that topic so I think these kind of knowledge graphs like this idea of having structure and unstructured like just these like you know drug drug protein drug like Gene protein interactions and this kind of graph structure right I think it's like the one example of a citation is this paper called Prime kg from Harvard from the biomedical informatics and it's it like if people are out there looking for like an example of what I'm talking about prime kg is like the best one I know of and it's like this kind of way like I I wonder if like with this knowledge management software like mem do you think you would have like your genome your proteome in a in like your note-taking software that I mean that's that's basically the um yeah that that's basically the vision right which is you know really we started with notes and I think over the course of this year it's going to become pretty clear to people as uh with some of the new releases that we have coming coming out that um like notes are just kind of one component of the type of information that you can capture uh and so you know we're building a ton of uh pipelines right from like manual data syncing uh or sorry automatic data syncing of you know your email for you know your calendar like slack messages all of that stuff right to the one time hey I have this PDF I have this video I have this thing um you know and kind of like drag and drop in right uh into that so really yeah the idea is how do we create this Universal Knowledge Graph that represents your entire world of information um and then how do we give you the power of actually being able to hold that in your hands right because I think if you think about it in the past that's been held in the hands of advertisers who then use that to Target us for that right but if you could carry around you know one thing that I think this is on our blog too but that we've thought about is you know you can imagine you sign into Netflix or new flicks right with men um you know in in 2024 and your experience is automatically this person is for you right and today you signed with you know whatever you said with Google or something with all that stuff and you know nothing happens you just manage to sign it um but if we could actually build that personal Knowledge Graph um then it becomes really interesting so yeah I think that's exactly what you've unlocked with mem and in this kind of like you have an embedding of you that you take everywhere that comes from all sorts of things like me from the YouTube videos I like are now synced up with the Amazon things I'm buying and nothing yeah yeah but yeah I'm also very curious like how you think about like privacy preserving AI yep like is do you use things like Federated learning do these kind of topics come up uh I mean I think it's it's one of those things that obviously we're we're super um aware of on on at least kind of the research side um I think the obviously the topic is super fascinating right like being able to actually you know run inference on um on encrypted data right would be would be kind of the dream unfortunately it's it's not really possible right now um I think everything that uh uh it's it's all you know basically that the the viability level of you know being research projects right so um eventually I think that's that is where the world is is gonna head though um you know whether it happens in 2025 2030 uh you know 2035 that's that's to be determined but yeah amazing well Dennis thank you so much for this tour of these technical topics about you're so knowledgeable about this and this was such a fun conversation um maybe to kind of wrap things up could you talk about like kind of your experience founding this company like how's it been it's super successful and all that and well I I mean I feel like we're at just the very beginning of the journey um I mean especially you know given what the kind of the the the vision is for you know the end products if there even is is this idea of an end product right but um yeah it's I think it's been you know I would say one of the things that's been really interesting for us is from the very beginning we kind of knew that um this was the vision this idea of you know how do I build this like personalized Knowledge Graph that I can take with me anywhere um and I think when you have that you know in mind at the very beginning um I think it's a lot of us to be a lot more um I think patient right and make certain Investments That for example in the knowledge graph right because that's one of those things where actually building this structured Knowledge Graph that you know and then teaching language models to know how to interact with it um is is is quite the build right it's it's very complex working with a lot of evolving Technologies kind of all at the same time um but having you know just knowing that hey that's this is we have to do it because this is this is why we started the company this is why we're doing it uh I think has been um you know one of those things uh that have you know made us pretty unique in terms of how I think most startups operate so um that's been you know it's been a really interesting part of the journey obviously in the middle uh it's been you know around three years so far in the middle of the journey is when gpt3 really became a thing um and it totally um I still remember this like this happy hour that we had and this is during covet and we had these virtual happy hours and one of them was just like when it was when the first you know Da Vinci one first came out and we just like sat on you know in the playground he's playing with it uh you know because I got I got access to it like oh this is this is kind of interesting this is you know this is really cool um and just seeing this Evolution and this you know this revolution happened over the course um you know like of this company developing and realizing kind of just how much of an unlock it is for a lot of the things that we were doing um as has truly been a sight to behold right so you know I couldn't be more exciting to to be building what you know what we're building right now so amazing yeah and I'm I'm also so excited to see we're building and Dennis thank you so much for joining the weba podcast and contributing all this knowledge has been so interesting to be talking with you so thank you so much thank you ", "type": "Video", "name": "Dennis Xu on Mem and LLMs! - Weaviate Podcast #41", "path": "", "link": "https://www.youtube.com/watch?v=RujNYB5ZE2c", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}