{"text": "Hey everyone! Thank you so much for watching the 69th episode of the Weaviate Podcast featuring Charles Pierse from Tactic! \nhey everyone I am beyond excited to bewelcoming Charles Pierce back to thewevia podcast Charles was our second weVA podcast guest and now he's back forthe 69th episode of the wevia podcast soa ton has changed in the space of largelanguage models and Vector databases aswell as what Charles has been working onso when we first talked Charles workingon kinius and now Charles is buildingthis incredible tool tactic generates Iwanted to quickly give a tour of whatthis is I think this will also reallyhelp ground the conversation topics inthe podcast to get a little sense of uhwhat this looks like so to get to getstarted I've loaded in three papers thatI'm currently looking at EXA rankerperspectives on large language modelsfor relevance judgments llms canaccurately predict Searcher preferencesand so all I did is I just you knowgrabbed the archive URL from thesepapers click sources add import URL andthen drop the paper in so what you cando is you can ask questions acrossmultiple documents so if I ask thequestion what are some of the challengesof using large language models toannotate search relevance I can get ananswer based on each of these differentpapers so so each of these differentpapers might have found a different kindof conclusion about these questions ifyou have a question like you know sayyou loaded in different retrievalaugmented training papers and you sayyou know how effective is this versusjust fine-tuning without retrieval andthen you have this question answeredacross multiple documents I think it'ssuch an interesting tool the userinterface makes it so easy to kind ofask these really complex questions aswell as to export your summaries andshare it across your team so I thinkthis is going to have a huge impact onresearch and how we use these kind ofretrieval augments generation tools sohopefully that gave you a sense of whattactic generate is about with that saidI love this podcast it's such a funconversation let's dive into it heyeveryone thank you so much for watchingthe weba podcast I'm super excited towelcome Charles Pierce back to the webapodcast Charles Pierce was our second weV8 podcast episode and now we're backwith the 69th episode of the Eva podcastnearly a year and a half later Charleswelcome back to the podcast thanks verymuch Connor it is great to be backum very happy to be back on the podcastand to catch up on what's changedum it feels it's only been what a yearjust a bit over a year and a half but Ithink in the land of ML and AI That'sprobably like 10 years so I thinkthere's a lot to catch up onyeah the the scope of everything I Ire-watched our episode preparing forthis and we were talking about you knowgraph embeddings rotating and and thatwas kind of the most exciting thing ofthe time and now we have these llms andyeah everything is totally different umso maybe to kick things off last time wewere framing our podcast around kiniusand now you're building uh tactic andgenerate can you tell me about whatyou're working on yeah so I'm working attactic working on kind of the on allthings machine learning there and uhtactic hasum you know we kind of have two uh corekind of products that we're working onand the first are our core product oftactic which we've been building uh forthe last two years or so is reallyfocused on kind of sales and marketingteamsand it's really to help them uh do uhkind of enrich their accounts in theircrms and to do research on all of thoseaccounts and that's really really highhigh scale so you know in the tens ofthousandsum and if like you know discover a newnet net new accounts and yeah that kindof stuff but it's very much focused forlike kind of sales marketing rev-upspeopleum and whereas lately the last couple ofmonths we've been building this newproductand it's called tactic generate andtactic generate is really aimed towardsa problem that we've definitely heard alot from our existing customers whichwasyou guys are really good right now atgoing out into the internet and likeretrieving relevant Snippets andinsights for us to help us enrich ouraccounts but we also have all of thesedocuments internally and we have allthese really really big PDFs oryou know Excel sheets or PowerPointswhateverand they wanted to do analysis on thoseand or do some really kind of in-depthresearch on those and we heard thatproblem a lot and we decided to build aproduct for that and that's what tacticgenerators it's built for kind ofresearchers analysts journalists and ingeneral it's it's really for knowledgeworkers people that are doing kind ofFairly in-depth um knowledge work andwhat it isn't is it's not a chat toolyou know it's not exp you know we're nottrying to doum a chat gbt or anything like thatthere's some really great products outthere that do that and that's not that'snot kind of the Wheelhouse that we wantto operate in for this you know whereit's a slightly different Targetuh it's super interesting yeah I'd loveto stay because um you know firstly Ireally like the interface of you knowyou have the kind of like left panel ofupload the documents and you put up youknow let's say five documents and thenyou have the middle interface for theyou know the questions that you'veanswered and yeah I love this um I kindof maybe diving in a bit quickly butthis uh like llama index one of the mostinteresting kind of like llm frameworkthings has been this kind of like uhcomparison across documents prompt whereyou kind of uh like one of the exampleswas um let's say the five PDFs are likeuh laws and I think in the tacticgenerate video it's like uh where wasthis established and it's like this one1930 this one 1940 this one 1960 so thatkind of like uh question answeringacross the documents can you tell memore about how you think about that justlike yeah like question answering acrossmultiple documents yeah like comparingmultiple documents with LMS yeahum I think this is reallythis is really why we we decided tobuild this is because I think a lot ofpeople out there when they you know theycan upload a document or two maybe to tosome of the existing uh chatapplications out there but you know whenyou get in the scale of you know tens tohundreds of documentsit gets kind of hard and a lot of theservices out there actually block youfrom doing this anyway because you knowunderstandably that's a lot of contextand ifif they don't if they're not using alet's say vectors like vector search inthe back end they're trying to fit thisin context and it becomes impossibleso the way we wanted to think about thiswas if you want to do cross documentcomparison that should be super easy todo and we know that there's a lot ofresearchers out there that have kind ofdocuments that might be similar theexample we often think of is annualreports so a public company that's doingannual reports every year you might haveyou might be working for you know afinancial institution and have 100 100annual reports that you have to ask thesame set of questions about extractedthe same side of information acrossand you need to get all that data andyou need to do it fast well in themanual research world this couldprobably be you know our best two dayswork of worst a week or two is worthum but it's it's actually it'srelatively easy task but the the formatthat you extract that data in isactually quite important you know peoplelike to have this in a in a tabular in atabular kind of format or an easy way todo comparisons so this was the initialkind of starting ground for tacticgenerate when we thought about it wewere like we want to enable this onetask first to begin with sowe built it so that you can upload 100annual reports and then ask a set ofquestions of those annual reports andthen bring all of that data backum and then have a nice table uh displaybut then furthering from that you knowwe also want to go with go forward withthe next step of what analysts andresearchers do which is probe that dataand you knowwe're really trying to mimicum and learn from the workflows ofresearchers and the the users we'retrying to build this for so we kind ofkept asking ourselves okay we'veextracted this data and and then whatyou know what do we do next with it sothat's that's what we're really focusingon as well which is actuallyonce we get this data extracted havingsome actions that we can take so if Igive you if you give me a table ofum answers about 100 annual reports Ishould be able to reprompt this or likere-question ask a question now overallof this extracted dataum thatum you know is a more complex piece ofanalysis like given given this dataabove which of these companies is bestpositionedum in you know to utilize AI in a in apositive way or given giving the aboveresults which of these uh which of thesecompanies is sensitive to interest ratechanges you know these types of likemore complex questionsum so that's kind of like what ourthinking around it wasyeah well that's so interesting I meanthe um yeah just the idea of turning youknow you have questions is the columnsand like a CSV and the the value is theanswer to the question for each of thedocuments and then applying some kind ofyou know processing on top of that yeahthat's also amazing I think kind of likeyou know in our theme of catching upafter a year and a half this kind oflike um like llm calls kind of like thisis like chaining this like the core ideaof laying chain where like it does theseintermediate inferences and then fromthere you can do something else with theoutput of that llm call it kind ofsounds like that to me yeah yeah that'sthat's that's a big way kind of in whichwe think of it andanother really tricky part of this thatwhere you know we still kind of verymuch consider ourselves in the beta betaphase you know we're getting a lot offeedback because we had a great responseto it when we released but what wereally are trying to do as well istry to automate as much of this processin the background as well so you knowwhether it's query routing or decidingwhen to chain or when not to chain basedon the data we have or you know as lambindexes we've learned from when to whento create queries and combine those backit's all of these kind of complex thingsare really important when building anapplication like thisum and yeah it's quite exciting and youknow it's pretty much changing changingevery week but um yeahyeah this is music to my ears I thinkthis is so interesting it kind ofrelates to like we have this kind ofleviate land idea called generativefeedback loops where you take the dataTransformer with an LM and then save itfor further processing and I guess likemy question so yeah this whole like subquestion query engine Islam index callsit or this kind of you know questiondecomposition transform the data to useit in some way later it's alsointeresting I mean I yeah I've beenreally trying to reason through thisbecause I know that some people thinkthat you know the kind of like Auto gbtstyle where you just kind of let the llmrecursively decide to split the taskinto more tasks and it goes on and onand people say you know okay that makesfor a great demo but it's quite hard toreally tame that thing for somethingpractical I think what you found whereyou you know break it into kind of thesetasks of first asking a question overall the documents and then trying to youknow reason about how you combine thoseanswers from each of the documents isyeah it sounds really I love this kindof thinking and yeah I'm just curiouslikeso I guess my question so you found thisone this kind of chain of like and wevia also we have like a generate uh APIwhere we would call this like singleresult prompting where you apply it toeach of the search results and then youhave a group drizzleso it's like you found this chain that'sreally useful so yeah that I think myquestion is like what is your sentimenton these chains the discovery of thesekind of chains and yeah I guess how youthink about applying new chains and thisone particularly where you transform uhdocuments into question answering pairsnow you have a structured View and nowyou have some uh comparison promptyeah yeah that's actuallyhow we think about chains has beensomething that's really been on my mindbecauseum I kind of agree with what you saidabout you know these when you hear aboutthings like Auto GPT a lot of the timeis they're really they really are greatfor demosum but for anyone that's tried to shipthem in production and everyone knowsit's a it's a very different situationum and as well as that it can alsobecome prohibitively expensive if you'redepending on you know third-partyum and I think this is whyyou know I've seen I've seen topics onTwitter where people say will Vector youknow are vectorsVector is Vector search needed in thislike constantly evolving world can weeffectively just put everything into uhone big giant context and I'm in thevector searchum and I have a good reason for it andit's because you know llmsum can be used kind of like a hammer foreverything but it can be a veryexpensive Hammer if you use it foreverything when it doesn't needum and you know if uh you know open AIrelease a new model tomorrow which has100 100K uh context length well thensomeone's just going to start wanting toput in 100 documents that have a millioncontext lines and then if they increaseit it's just gonna it's gonna be thiscut and mouse game so I think you knowit's always important to actually keepefficiency in mind when we're designingthese things so when we think aboutChains It's like they're usefulum and doing the kind of chainingchaining sub-actions is a useful task todo but preferably we would like tocontrol as much of that ourselves and alot of the time it usually ends up withus building some micro chains and it'snot maybe not using a chain a frameworkthat will do it for us and just kind ofdoing it ourselves out of the boxum a lot of the time because it can beyou it just gives you that bit offinesse and control that when you havekind of a kind of a verticallyintegrated app you need some sort of uhsome sort of like business kind ofknowledge applied to thatum so we find that helps and yeah we'vejust found that you know if we can if wecan smartly combine Vector search andnot just Vector search but also theembeddings you get back it's reallyimportant remember the embeddings youthat we store in weeviate are very richin themselves and you know if if forpeople out there you know what were onceconsidered like you know big uh normalmachine learning tasks like clusteringthey might be I feel like they're reallyarchaic now but obviously not but youknow if you know how to do a few trickswith embeddings and understanding whatthe you know those latent spaces andcinematic representations mean you cando a lot of these tasks that areexpensive llm calls just using those youknow the embeddings are very powerfulobjects and they're much cheaper to playwith than llm calls a lot of the time sowe've had really good goodum good luck and we'd like to we like touse it that way so I think to summarizewhat I'm trying to say is chainingchaining queries together is great buthaving a bit of uh control over themlike manual control is important inproduction situationsum and also exploring what Avenues areuh cheaper Avenues are there in terms ofinference and overall cost is reallyimportant and for the equivalent resultsI think a lot of the timeyeah I really want to come back to wellthere are two things I want to come backto with the yeah like how you discoverthese micro chains you mentioned and Ihave something interesting for that aswell as then the cheaper inference thingtoo butum yeah maybe the like quickly touchingon these points I think the theclustering the topic modeling thing it'sstill so fascinating to me I love thatkind of topic I see startups I see youknow Martin grutendorf who he still hadon who we had on the podcast he's stillhitting it with the topic modelingadding the llama2 to it and he's doingawesome stuff and then we have likegnomec Ai and arise AI that are and Ithink weights and biases has like avisualize your latent space part oftheir product too but yeah there's Ibecause I imagine this um you knowcoming back to tactic General like I Igive you a hundred annual reports or youknow I I give you a hundred slackmessage or like a customer support thingor something I think about a lot andthen you cluster it and then you tell methe topics I think there's still so muchuse in that and and then one other kindof little thing I wanted to touch onmaybe we'll come back to it later was umyeah yeah like this Vector search thingI'm actually my perspective on weeviatethese days is I'm I'm kind of thinkingof you know my scope of weavate isexpanding for how I personally see itlike um you know we weave has anaggregate API as well so with thisgenerative feedback loop thing what youcould do is um you know you Trend let'ssay um the the one of the questionsyou're asking each of your documents isuh what was the annual revenue for thisyear and then you store that as an inproperty and we V8 like feed it back toev8 and then you can have you knowwhat's the average revenue so you can dojust those symbolic aggregations and soI think especially as retrievalaugmented generation is evolving likewe VA I think it's would be it's coolfor people to know that you can use itjust for like Json retrieval like youcan just apply filters and just get yourdata out of it you can also do SQL styleand then you can also do Vector searchand I think the scope of that is goingto continue to evolve as well you know Ithink I could write like a whole blogpost and diving into that topic but yeahso I really want to come back to sothese these micro chains and I've heardthis I so there's this there's thisthing I've been exploring from omark atop called dspy or dspi I think whereit's about uh you you compile theseintermediate steps for some kind ofchain and so you so as so how do wediscover These Chains to do do teststhat's kind of the question I think isdo do you give the llms like some kindof action space like here's the kind ofthings you can do and then it searchesthrough it somehowyeah I think for us it was it's beenkind of easier to discover these chainsbecause you know we're very much youthis product is very much driven by whatwe think our users kind of want so we'rewe're trying to be very ux-led with thedesign of this product and I thinkthat's quite important with AI uhproduct design these days so because ofthat we're very user-led we're listeningto what uh people that want to use it orpeople that are using it so we're kindof trying to we're trying to look attheir workflows and say what are thecommonly occurring kind of like modulesor like facets of their workflows andthen those are kind of our chains youknow saying oh whether a summary whatdoing a summary or doing like acomparison or doing like a kit like kindof a splitting out key points or doinglike a topic extraction doing anextraction of people or looking for keyfigures these are these are kind of likewhat we would probably consider chainsso it's kind of easier for us to reasonaround them because they are very muchconnected to like requests and you knowus just aggregating in requests we getfrom users so I think that's kind ofthat that's what makes it easier Isuppose for us to specify out thesemicro chains I was talking about becausethey're very much related to things weknow people people want and then youjust kind of have rooting you justfigure out how to root those to theright place when you get a question inum now in figuring out how to do thatmore and more intelligently is difficultum but that's that's kind of the way wethink about itso I think another thing that makes itso interesting is like uh one podcast wehad was with Yana wellender who'sbuilding craftful and so she's like uhshe's kind of like what you're doingshe's marrying these two skills whereshe's a product manager and she's likehas a really good sense of you know llmsand prompting and all this kind of stuffand so she does she combines that tocome up with the micro chains forproduct manager tests like analyzinguser feedback prioritizing a road maplike that kind of thinking and I thinkit sounds like what you're doing withthat but with crms and sales and thatkind of stuff yeah it sounds like areally nice marriage of these thingsyeah and uh yeah sorry I have one otheridea that I forgot maybe we'll come socome coming back to this I I do alsokind of want to talk aboutum so you know there used to be thisthinking around like to have like a moatwith your ml product you would have tolike open AI is just gonna if all youhave is prompts they're just gonnadestroy you eventually yeahhave these conversationswhat's your sentiment I I personallybelieve no because yeah I think this Ithink there's so much to structure likewhere you see the structure and I don'tI don't know but you know obviously theend-to-end Deep learning people thinkotherwise yeah yeah so you knowthis is why we're not building a chatapp you know it's uh it's been done it'sbeen done really wellum it's not where we saw our mode andit's also we we know where our skillsets are and it it was in uh buildingbuilding products that solve kind ofdifficult uh uh problems for researchersand an analysts and extracting keyinsights and then the a huge part ofthat is ux and I think ux's rolein um AI product development has I'm notgoing to say underplayed but it's notlike the the part that gets the mostmedia attention or the most hype aroundit but I think it's like incrediblyimportant and if if there's to be in theworld of like you know open Ai and allof these great providers of largelanguage models if there's if theirmodels or their modes you know the themodes for other companies out thereshould be things aroundum ux and then like just how theycombine all of these little taskstogether in a very user-friendly wayum and you know we when before we evenwrote a single line of code for this newproduct we really just thought aboutwhat's you know what's the userexperience we wanted to to deliver andI'm not and that's not even to say we'renowhere near where we want to be butwe're really thinking about it andtrying to trying to get there isum kind of thoughtfully and fast as aspossibleum but what was a really big uh thingfor us a big kind of aha moment waswe had a realization about what the whatthis generate would be kind of from a uxpoint of view and I think for any datascientists out there are people who arekind of have worked in data science oranalysts it could make sense from a datapoint of view but I was a big consumerof Jupiter notebooks Once Upon a Timejust as a data scientist so I was I'vedone a lot of work in Jupiter notebooksover the years and people that work withdata they understand implicitly how muchof a change those added to the world oflike data analysis and how big a dealthat wasso we kind of asked ourselves we said dowhy does something like this exist forlike kind of language knowledgeextraction where the data the primarydata is actually a natural language andwhat we kind of thought about is no itdoesn'tum sothat's actually a big inspiration forour ux is we are kind of we viewourselves as like an AI notebook forknowledge workers that's kind of likeour house thinking around it and whatdoes that mean well it means we think ofwe think of your application your interms of cells so things are cells justlike the way they are in notebooks andyou can add a question cell or you canadd a question table cell which is likethe comparison stuff you've seen you caneven add in text notes which can bemarked down or whateverbut Beyond just the UI those being likevisual cells there's something elsethat's bigger there and that'sreproducibilityso when we talk about reproducibilitywhat we mean is let's say you've figuredout a really nice way to analyze annualreports you have this workflow kind oflike an application almost you have anAI workflow a way of asking questionsum and conducting analysis onum a bunch of annual reports well that'sgreat annual reports come out annuallyand quarterly reports come out quarterlyso this is actually a repeated tasksomething that you'll want to doum on some sort of time frame and thisis where the notebook ID I think reallyshines because using that we can kind ofyou know use the same structure of yournotebook and reapply those questions toeither new data or updated data and thisis kind of the reproducibility aspectthat we've been thinking about so youknow I can share my notebook schema withyouum and then you can copy that onto yourown type of data as long as you knowhoping that it's from the same sort ofdistributionum we're not there just yet but we havekind of the Scaffolding in place to tobuild out this notebook structure Rickwe have like the notebook visuals and uhwe're getting towards in the kind ofmedium term towards having thisshareability and reproducibility inthere and I think that's a game changerbecauseit not only allows people to do thingslike you know a common analysis overum an annual report but you know itcould allow people to create weeklydigests from an AI you know based off ofuh whether it's reports coming in for anexecutive from uh people that you knowthat are reporting into them or oneother integration we added in at thevery start was GitHub you know what ifI'm a CTO and I want to know what myteam has been working on every threedays well I could conduct have thisreport that runs through scans my GitHubaccount runs it through this report anddelivers it to your email it's that kindof reproducibility that we've beenthinking aboutI'm building these kind of like AInotebooks or AI applications forum kind of a really large variety of endusers and when we think about tryingthis all back to where we started thatisn't really an llm problem that's a uxkind of design problem as well andthere's a lot of other kind ofengineeringum problems that you need to solve inorder to be able to deliver that so Ithink that's where we think our ourmotives and that's what kind ofdifferentiates usyou know firstly that was fantastic thatwas mind-blowing I I know I'm gonna makehim know I'm cutting that out andputting just the last five minutes onTwitterand I'm not even just saying thisbecause we're friends when I saw thetactic generate I had this similar kindof thought that like you have um youknow tamed The Prompt into a UI so tosay this is like a document comparisonthing that makes sense and yeah I thinkum like in addition to Chad gbt I thinkprobably a lot of our listeners knowwhat uh perplexity AI is and uhperplexity AI they have like this kindof like cite your sources a GUI with theuh chai GBC so you know it's a littlemore like search engine llm fusedtogether and you know we've yet we'vebuilt an open source verba which showsyou you know like yeah the the theum the front end and the ux is so muchopportunity and I mean just the lastthing you said really was is reallyexciting to me because um like I thinkabout like um you know with me say Ihave this hypothesis about out likecurrently my hypothesis is like oh Ithink gorilla llms are going to do suchand such a thing and so I might imaginelike you know I one thing that I do likeone of my I've got this from Tim scarfhe said this on the machine learningStreet Talk is um like what's yourinformation diet and so part of myinformation diet is I comb through thethe tweets I've liked for the last weekand I just kind of you knowsee what happened basically and so I canimagine yeah dragging and dropping allof that intoum into tactic and then saying like aquestion of like would any of thischange my hypothesis about the currentthing because like you know when Falcon180b you know arbitrary thing that cameout this week is like maybe that changesmy hypothesis aboutfine-tuning llms or yeah something likethat yeah yeah that's what you kind ofsaid there is exactly how we're thinkingwhich is we know there are people outthere that have kind of like their ownpersonal workflows for how they like anda lot of it could be in your processdata and then the questions you ask ofthat and what we're trying to do is justfigure out a way to like weave all ofthat in together and give you just anapplication to do that so we're like awe're like an intelligent data pipe forworkflowsum yeah so I have a question for youthis is something I've been thinkingabout like with the verba project is umis like does fine-tuning have any rolelike um you know so verba is a quickbackground is like you know it's likearbitrary vlogmens a generation app andwe're dog fooding our own weevia youknow you have to issues for the we V8documentation that's how you do it andso I think about like you know whatwhether you would um you know thumbs upthumbs down the responses and then rohfand whether that still has a role inthese kind of things or if we're justkind of like zero shot LMSgo for it yeah like I think the thumbsup and thumbs down definitely has isimportant but like theI like when I think about this theproblem with it right iseven even though like you knowreinforcement learning with humanfeedback has gotten it's we know howgood it is you still need like acritical mass of data to get goingand I think it's hard to say to peoplewell you need to get like ten thousandten thousand responses like thumbs upand thumbs down to this before you getgoing I think anyone that's developed anapplication where you're looking forlike Thumbs Up In terms then responsesno it's generally it's hard to getclicks and stuff like that even ifyou've got a really busy product a lotof people just don't leave that kind offeedbackum but when it comes to fine-tuning ingeneral and then versus something likeragthe way I've been thinking about it Isaw a really great tweet that like stuckhas like stuck in my head ever sinceI've seen it and I think it was sayingthat you know fine-tuning is for styleand retrieve rag is for facts and like Istick I think that's like that makestotal sense to me and I even seen thework you guys did last week with Gorillathat I think that like still adheres toall of that because you know the stylethere is actually like a structuralstyle of you know emulating graphql sostyle is important in that instancebut if if Foxum and retrieval and just bringing backthe right data is important I thinkretrieval suits more to that need you'regoing to get a lot more out of retrievalthan fine dining because most people'sdata isn't too far out of distributionlike your data has to be fairlysignificantly out of the original datadistribution I think in order forfine-tuning to make a ton of senseum and I know there's a lot of there's alot of people that do fine-tune thesemodels on very particular data and it isof course it has its place but I thinkfor a lot of you know Enterprise usersand stuff like that the value addfrom uh from fine tuning mightn't beexactly what they think it will beespecially if it's like trying to imbuelike if there's a certain if there'slike facts and information figures youwant to be returned I would just use ragright you know that's that's it justseems so much cheaper so much faster toiterate on and to control thanum fine-tuningyeah I think my I have a few a fewthings on this like um so our lastpodcast with farshad fireboxy and theGen AI specialist at AWS he presentedum instead of style he phrased out hisskill versus knowledge and and he used alawyer example where it's like you knowme I could have the world's greatestlike I could have the perfect uh lawsthat I need to help get you out of jailand you're still going to jail if it'sme who that has to reason about the lawsthat help you out so it's like but I Ido agree that like um you know I thinkwith um I think as we think about likethe future of this too I think probablythere's going to be some like let's saygbt5 like what do we think that's goingto look like we we're seeing these longcontext llms like we had ophira press onthe podcast to explain how Alibiattention works and like there's evenlike a week later there's like yarnscaling it like moves that fast and andso so it's like um I think that you'llbe be able to put so much context intoit that it'll really be that that willreally take over and just zero shot withgreat context but so I kind of but um sostaying and yeah the style for so Iguess I'll make you one more point onthe gorilla thing with that thing islike I think there are some for megorilla is aboutum like you don't need a massivelanguage model to write graphql yeahit's like and and there's a lot oflittle tasks like thatthat's kind of how I see the gorillathing yeah and I it's probably becauseyou know graphql the great thing aboutit is it's a structured language so Iimagine when when finding tuning lamb onthat it like it probably really picks upand uh picks up and the the structure ofit fairly fast because it's it's a it'sa programming language so it's actuallynice and has a limited syntax which isgoodyeah I'm so excited about like uhDestiny coder there's like a new codeFoundation model that's it's oh man it'sso interesting how the how you fine tunebut you need like the foundation modelcheckpoint to fine-tune from and it'slike well can someone give me a smallerFoundation modelyeah and it's all really crazy I meanum yeah and like I also think the textto SQL models would probably be smallermodels like you know this yeah but so Ikind of want to talk a little more aboutfine tuning and so you know you I thinkwe both agree that to have your llm youknow reason across your documentsprovide these summaries and likeaggregate the results from the singlequestions in the tactic sense that youprobably don't need to fine tune it toreason about your specific thing itprobably is going to just be such acapable reasoning engine that with someretrieve context and with the currentthing it will get you there but there'sstill this idea of fine-tuning thesearch models maybe yeah like maybe youfine-tune ranking models or embeddingmodels how do you currently think aboutthat yeah Yeah well yeah I see what'sgreat about search models and embeddingmodels and rear anchors is they are likeyou know orders of magnitude easier toto fine tune and they're just likelighter cheaper models in generalum and there is it's they're just somuch smaller and I actually thinkretrieval models are such a fantasticexample of how bigger isn't alwaysbetter for in terms of you know in likelarge language models you know retrievelike retrieval models are just so muchbetter than uh like very very largelanguage models for you know picking atthe top K candidates and I know llmscan't really even do search but you knowjust what if you look at the the the topretrieval models um kind of inbenchmarks out there at the momentyou know open AIS uh Ada two is likekind of in the middle of the results andyou have these open source models thatare likeyou know probably under two gigabytes insizeum like vastly outperforming them like Imean I think that's a really good signshowing that if you've got like specificvery task specific things you knowthat's where there are so still therestill exists exist cases where llms arenot the king it mightgive it a year and let's I'll probablyyou know change my view on that butright now that's still the truthum so when it comes to retrieval modelsthey're they're great they're reallyeasy to to to fine tune so let's say youknow we decide oh we've got a reallygood use case for for law or for HealthCare well then you know to to traintactic for health or tactic for lawthat's a that's a lot easier for us todo and then to pass that into uh uh llmto kind of pick out the passing and theinformation it needs so picking upimproving the retrieval is a much easiertask and you knowfor the right for the right if the ifthe down if the other domain is you knowsignificantly out of domain you know youcan only fine-tune llamaor something like that on on that domainthere's always an option to do that andyou know it there's there's probablylike a strange correlation between theindustries that would require you toself-host the model anyway and how todistribution their data is I'm talkingabout like healthcare and like peoplestuff a lot of the time these might beIndustries where sharing you know thedata is so sensitive it can't be sentover in llm so you might as well justfine-tune your model on it anywaybecause it's it's going to beself-hosted or I think that's what Ithink there is going to be anyway whenI'm seeing what's happened with llamathe last couple of months is it's goingto be a lot of you're going to see a lotof people looking for expertise orcompanies out there that can help themfine-tune and deploy their own specialmodels in-house because they're justthere's just there's a bunch ofIndustries out there and they're justnever gonna allow certain data to moveover the net over their apis no matterhow secureumuh the the API provider is or theservice provider is they're just theycan't you know I live in Europe you knowthere's just there's no ways can allowsome of that data move over move overthe web that easyyeah well I I want to parse out this umyou know easy to up easy to trainretrieval models I think firstly I'mtalking to the wrong guy because Iremember in our other podcast you hadtrained you use the pie torch big graphthing and I mean that is like prettyhard but I I think I think the um for methis is actually kind of the phase shiftin training and betting models I meanfirst the first thing that happened withllms is it was looking like you coulduse the LMS to generate syntheticqueries and that was like the oh now wecan you now we have positive pairs youknow and that was kind of exciting itbut I think and especially for the longtail queries like you know queries thatare sorry documents that are frequentlyqueried on you can kind of even out thedistribution more this way by havingqueries for those documents but I thinkeven that for me you know contrastivelearning I don't think that was going toI don't I don't know I you know like wesee products for fine-tuning in themarket but I think this end to end youtrain the llm the gradients from the LMgo back to the encoder as well thatmakes training embeddings so easy yeahyeahso yeah I think that's reallyinterestingum I I the whole world of fine-tuning tome I think is in fluxum I don't know if you saw this week butyou know there's a new kind ofthere's a new continuation ofreinforcement learning for humanfeedback called the acronym so difficultto remember but reinforcement learningfor AI feedbackum so it's you know the exact same ashuman feedback but just replacing thehuman in the loop with a kind of an AIagent that's prompted to understand thattask somewhatand to memaybe it's not my kind of unpopularopinion on oral HF is that I don't thinkit I think it's actually aitit's it's going to be something thatshouldn't exist in five years because itactually highlights issues with ourcurrent training regiments for finetuning and for training for trainingmodels in that the the latent data thatthe original model is learning fromisn't good enough or the architecture ofthe model isn't good enoughto train a model you know to be able todo these chat tasks in a in a reallygood way you know that so you actuallyneed to do this fine-tuning step whereasmy expectation would be that you know weget enough compute and enough we improvethe architecture enough that in a coupleof years we're kind of just back towhere we were with the originalregressive Auto regressive models whichis you're just passing in the data it'sand you're not giving it any you don'teven necessarily need to do thisreinforcement learning task it's just itit has enough capacity to learn I'm in achat context here or here I'm in ainstruction context or here I'm in anextra context that to me seems more purethan this layer at the end of doing finetuningumnot not that I think you knowreinforcement learning hasn't beenamazing it's been what's given us kindof the last year's worth of improvementsbut it feels like an in-between stephmmyeah I don't I don't really have a greatthought on this my I just I guess for meit's like um uh the difference is alwaysI guess I don't really understand thedifference that well honestly like withreinforcement learning with humanfeedback it's like you like the answerso you could also just kind of languagemodel that answer it's not necessarilythat it has to be plus one minus oneoptimized with proximal policyoptimization and uh you know have areward model and all that kind of stuffI'm not sure I understand you know I Iknow that there is like if people outthere listening are curious like NathanLambert has written a lot of great stuffabout this at hug and face and I just Ihaven't read it yet I I don't know butum this um this kind of like llms versussynthetic data is so interesting I meankind of coming back to tactic I mean Ican imagine like um and maybe not thecurrent generation of albums with themultimodal LMS that like use a UI orwell I mean yeah maybe coming out of theUI and just let's say just with apisright like we could have LMS like amulti-agent kind of systemthis kind of yeah what do you thinkabout this kind of direction of like Ithink there is a paper it's like uh it'slike a large language models content andbehavior language models something likethis but but yeah it's like aboutum the llms like you know they simulateusing because you mentioned like a gbt4eval where the LM is prompted like withthe instruction response pair did theresponse follow the instruction andpeople are that's that's actually like Ithink the most common way peopleevaluate the question answering systemsyeah yeah so like I I do think we'reprobably going to see a world where it'sjust gonna belike it's going to be models callingcalling modelsum I mean what you guys have done withGorilla I think you could you could ifyou think about it you could probablyjust extend that outwards right which isumyour your model gorilla is for kind ofGRA has knowledge of certain graphqlschemas well I I have my private modelwhich I also have trained on my privategraphql scheme or maybe it's the restmaybe it's SQLthose models can now talk to each otherin like natural language they actuallydon't need to know each other's schemasso my one can request data from yoursvia like natural language queries andvice versa and then they can convertthose in the background to the accurateschemers return it so I think there'sthis I've vaguely thought about thiswhere you have this world now where youcan have models effectively umtalking to each other that arefine-tuned on very specific schemas butthey have no knowledge that the otherone has like a specific schema behind itbecause the model would probably stillcome back you know in a natural languageresponse but like it's it's actuallycreating a structured database whetherit's SQL or graphql or whatever it is sothat yeah that's kind of one once what Isaw you did last week I was like oh yeahyou could potentially have this world ofjust like agents talking to each othervery just through natural language butjust distilling it downyeah I'm really gonna like dream intothe future with this one but I I've alsobeen thinking a lot about crms andparticularly like um you know like mydream with the gorilla project is kindof the Integrations angle where youwould say uh you know uh build a llamaindex query engine from my notionworkspace titled biochemistry store thedata in weeviate embed the data withcohere re-rank it with cohere or likevisualize over the rise like I want tosee this like combination of all thesethings together and so I think like umyou know with with like a CRM this haskind of been you know when when Bob wasfirst like pitching like you knowexplaining his vision for generativefeedback loops this kind of idea of likeum personalization has always been likethat I just I love that like we when wedeveloped a blog post it was like Airbnblistings and it's like write anadvertisement for Connor who travelswith his dog Bowen or Bob who's a powerlifter and he's like a special kind ofgym and so it's like uh this kind ofthing of like um you know why would uhdeep set be interested in my gorillablog posts like you know help me youknow come up with something for me rightand so that that's where I see like crmsand you know like thinking about theother agents in your systemwith the future of like API design andyeah and I think the tricky part thereright is the routine systems because nowwe need all these routers and it's likeit's kind of funny thatthese concepts are returning that peoplehaven't really had to think about foryears you know like since the you knowthe initiation of the web so now youhave this now you have rooters in thesense of for for large language modelsand you know sending things to I supposein a way you kind of call them the rightexperts or whateverumand but you kind of still need thisrouting system on topum and I think that that's a problem I'mworking on like today trying to figureout like trying to figure out when whenis the right time to use a routerum how like why should you use one andthen if if they're talking towith these experts like the the onesyou're using how do you represent whatthat expert which which expert can dowhat you know is it just like a is it adescriptor or does the can this routeractually go out there and talk to theseexperts and say which of these ex whichof you is the you know it can providethe best candidate answer to my questionyeah yeah it's just you're in I had justsharing Tianjin from Berkeley theauthors of girl I asked them the sameexact question like are we going to needto have a hierarchy of gorillas likeyeah I feel like just um I I guess it'slike um well for what we've done so farwith the graphql apis I can fit all ofthat into you know it's it's 46 apis butit's like uh you know there there areAtomic apis and then we get a lot ofsome compositionality like how youcombine like you know Vector search witha wear filter limit the results see theobject Vector so you know like you couldfit all the atomic apis in the promptwith some explanation of how thecompositionality works and if you givethat to gbt4 obviously use the strongestthing you can to see if it works at alland then like that yeah yeah and thenthat could give you like the naturallanguage command to then hand to the youknow smaller more economical weviategorilla so yeah that's how I kind of seethat thing and I guess if I can ask onemore question on the crms thing becauseI really like exploring this idea islike I feel like with business kind oflike the most effective thing you can dois kind of like try to make a lot ofpeople more success right like and itkind of like I feel like tree ofthoughts this kind of like planningcould have such an interestingintersection with these CRM kind ofthings where it's likeum you know like I have these differentprojects that I could pursue right andit's like if for each of these ideas youknow the these like CRM reasoners couldlike you know go in and say okay welldeep set probably wouldn't get too muchout of that streamlit might getsomething out of that and then like putit all together and then say hey ConnorI've done the analysis I think youshould do this projectyeah I mean that that's like that's awe've kind of had a very equivalentthought about around crms butspecifically with some of the users wehave in our existing core product whichis kind of sales and marketing peoplewhich is you know they feed usum a list of accounts from from theirCRM and we help thempick which ones are the best ones forthem to Target you know to to do theirjob the best and to have the highestum efficiency and success rate so if youthink about a reasoning agent therewhat tactic does is we pull back in ourcore applications we pull backinformation and data we extract dataabout all these companies so reasonablyyou could hypothesize that using a CRMand then you know using uh you know ifyou specify out like a kind of aa prompter some kind of reasoning aroundwhat ideal customers look like youshould be able to allow this thing youcould feasibly have like a Chain ofThought going on looking at theseaccounts the knowledge you have aboutthem and reasoning giving you like thegiving like a you know you're asalesperson you're an account you youknow account exec you're going to becalling people tomorrow you might comeback in tomorrow morning nine o'clockand you check your CRM and you have likea list of today's Target accounts andthen you have reasonings why and youhave like some explanations in your CRMbeing like we want to I think you shouldtalk to this person at this companybecause uh this change has just occurredthey've just hired this you know thischange has happened in the marketthat'll be really cool and I I don't I Idon't think stuff like that is you knowtoo far off to be honest you know we'veexplored parts of that soyeah I guess maybe the biggest part withthat is um maybe it's I mean you knowthe whole uh connecting data toalleviate that's exploding like you knowwe um we just did a podcast with Davidgarnets from Vector flow you knowthere's uh unstructured we did a podcastwith and there are a few that we'retalking about but this like how do youyou know like how do I keep Charles'slast week updated in my CRM right likeyeah yeah it's really interesting yeahyeah it's such a cool topic I lovethinking about kind of the future ofcrms because I I do feel like that wouldbe the big thing is like if we couldjust better organize business betterorganize our effort better coordinateeveryone sort of right like it it's kindof I mean yeah like I love thinkingabout the multi-agent perspective of LMSof like not necessarily like yeselements but like you know the the waythat things work sort of like it needsto you need at the end of the day yourthing your building needs to like appealto a person otherwise yes yeah 100 likeI thinkyou can kind of tie that back to what wewere talking about at the start witheven with tactically generate in termsof workflows you know people you knowlike leaving the land of just talking interms of Agents uh what llms are tryingto do is or the value I think that youknow people see in them and investorsseeing them is that everyone has allthese workers out there have theseworkflows and there's repetition WithinThese workflows and there's tasks thatneed to be done and these workflows canalso be defined somewhatso using these models you know the theidea is make workers more efficient byautomating the parts of this theseworkflows that can be automated andthere are Parts in there and by actuallydoing that when we make when we automateawayum these parts you make workers moreproductive by allowing them a lot moreof the the deeper the deeper thoughtsthe more complex parts of their job andI think that's that's where we seeum the power in llms is that you know weknow that there's people out there thathave processes that they work throughand it's like okay how do we like bestcapture capture those and like you knowjust solve the the parts of that thataren't enjoyable or that are just realtime suckers you know the things thatreally take up take up your time and Ithink any everyone in most Industriescould like if they think about it can belike what what do I still do every weekthat's manual and there's alwayssomething so something out there that'slike a manual research thing that peopledo and of course anyone can build theirownum if you have the if you have theknowledge you can build your own youknow really intelligent kind ofautomation around that so what we'retrying to do is build those four peopleand you know a lot of that will actuallyend up as well being Integrations on ininwards and outwards Integrations youknow like you know we take in data fromGitHub from Salesforce and we export itto you know wherever so that kind offlow as well will be really importantyou know integrating with a lot ofcommon workflows for peopleyeah that's amazing I just imagine howmuch everyone will be super charged bythat because it's likeit's like not only do you have your ownassistant that kind of manages like youyou have six emails today you have thisme like how you might think about like a1970s secretary now it like uh couldeven organize it could even likeschedule your like you know I have youback to back with Charles and say I havesomeone else working on a similarproject because like it wouldn't be toomuch of a context switch for you to thentalk to someone else similar to Charlesand or like you wake up and it's likeyou have this meeting and here's why youknow likeit can be something as simple as youknow you've been away I was I was awayon holidays last week so you know I comeback and I I just want to know what'sbeen going on in my slack you know and Iknow the fields out there that you knowthat they already do to that but that'sone integration so how do you build atool that can kind of build thoseIntegrations for everythingand repeat that and this is where youknow and the questions you know uh atech person or an engineering personmight ask a slack might be verydifferent to what someone in go tomarket go to market function would wantto askum and again you know extrapolate thatto GitHub and what a CTO might want toknow about you know what how their teamhas been getting on and what bugs havebeen occurring and you know imagine youcould ask okay what bugs have beenoccurring and like what parts of thecode are these occurring in and likethat might help you realize oh and weneed some better testing on like thispart of our database or sorry this partof our code repo because bugs are likeconsistently occurring there and you youknow you could always discover that viayour own analysis but these are thingsyou can actually automate a way as wellwe thinkyeah that is the killer that that'sreally that's really exciting I meanjust yeah like testifying from withweavier and trying to keep up witheverything that happens in the slack andthen yeah and then also trying to tiethat to the code base which is itselflike an entire like city of complexityyeah oh yeah yeah I understand Iunderstand the band I think anyonethat's worked on any kind of projectthat's going in complexity knows youknow I recently looked at the weba codebase and I had looked I'd worked on atiny bit you know maybe two years agosmall contributions I was like oh wowit's completely different I I hadthousands of commits to pull down when Ichange my job so yeah yeah but yeah thatthat um the that that would probably beone of the biggest applications of thatgenerative feedback loop thing I thinkis think is uh summarizing the slackso I one more question I wanted to endwith from our talk uh you know a yearand a half ago we were talking about uhwe talked pretty heavily about graphembeddings and knowledge graphs and Iwant to hear like where is yoursentiment on that now I'm I'm still I'mstill long on on graph embeddings Ithink they're like I think this back towhat I was saying earlier and thatthere's like there's expensive ways todo things and llms are an expensiveHammer brilliant and that's great but Ithink uh in order to really connect datathat's not just language and you knowthat are kind of topics and objects anduh I think that's where graphs graphembeddings are still going to or graphmodels are going to take off or likethat they will be relevantwhat I saw in the last week which waskind of coolum is a lot more people working ongenerating graphs from llms and I wetalked really briefly about this I thinkmaybe two years ago I kind of discussedthat but we're probably now in a placewhere that isway more feasible and that you say to amodelhere's a here's an article uh just writeme every single here's the set ofrelationships that we can haveum between objects and and here's theset of objects types that can exist ornode types that can exist just send mesend me in whatever graph format becausethere's like a million graph formats outthere but just send me send me whateverI want in like you know head relationtail format all the relations you see inin this text and then you can slowlybuild up like a a graph database then ofall of these things and then you couldfurther train this to to model thelatent space of these and that thatwould be a much cheaper way in myopinion than to build like a a KnowledgeGraph understanding of you know what'sgoing on in your data without having tollm absolutely everything and build myopen AI billso I still I I do I I do probably Iwould say graph stuff graph embeddingshas probably not probably fallen out ofthe Limelight a little bit within thelast year or two just because of howhow easyum llms have made it to do a lot of thetasks people were looking looking tothose for but I do think that umthere's a lot of value in them and I II've still used them for little projectsover the last year or so and I justthink it's quite amazing actually whenyou see them train how like those littlelatent spaces of graphs is just so coolto me still so yeah I still I still havea I have quite a bit of belief in themstillyo I guess umfor me the um like the connection ofgraphs and then causal inference hasalways been what keeps me interested inthis topic more than anything elsebecause I like earlier I mentioned thatum you know I get my new week of Twitterand basically the question I'm asking inmy own head is does any of this newschange my world model of how things workand and then thus how how I'm planningto spend my time because of my beliefand how things are and so I do thinklike if you extracted you know and it'slike the comparison across documentsthing if you extract the structure ofthe you know relation uh entity relationentities and then you know compare themwith each other it might be a moreefficient way of saying this documentdisagrees with this other documentcompared to just looping through withthe llm being like does this paragraphoccur this one actually really goodpoint because there is you know awell-knownwell-known problem class in graphs isnot just no classification but also likegraph classification and graphcomparison so if you're building up subgraphs um I think reasonably compare agenerated graph versus a generated graphand you know have a similarity scoreoff of that which is again cheaper thanllming that straight out of the box youknowyeah well I think there is so much thatI mean I guess it's like likeI guess one thing that I'm reallyinterested in is like if uh somesomething happens that changeseverything in your document before thenthen what do you do about that kind ofandyeah I know the whole thing is prettyinteresting I mean yeah graph embeddingsI guess here would be my question aboutgraph embeddings that I've struggledwith is I really like this idea of likeI have all my documents and I connectthem with symbolic structure and maybe Ipropagate that to have better embeddingsomehow but then how do I put my queryinto the graph as wellso how do you query the graph yeah so weI actually have done stuff on this inthe pastumandthere's like I think there's like acouple of there's like a couple of waysin which is likeyou could if you're like embedding agraph intolet's say I'm creating like a evadeinstance and the the vector embedding islike an actual graph well then what Icould have is like the querythe query could link toum some textual representation I have oflike an object in that graph and thenfrom there I could resolve that down tolike an item within the graph so let'ssay let's say you know I search I wantto discover films uh about Ben Affleckwell then the query might be Ben AffleckI have a text object that I knowresolves to the resolve that down toum the maybe it doesn't have to be onebut resolve that down to like a coupleof nodes so one of them might be BenAffleck one might be the you know theBatman films and from there then you cantry and return relevant results fromfrom that graph backum but resolving natural language tothat's one idea maybe I had for I havefor how you could resolve naturallanguage that back downum to graph embeddings but I know it isa tricky thingumum because it doesn't naturallytranslate right you know they're veryvery abstract Concepts like an item or anode embeddingyeah I heard that same idea from uhProfessor Laura Dietz from theUniversity of New Hampshire was on thepodcast and yeah she she explained thatsame kind of idea of uh you know youcould like retrieve with the embeddingsand then re-rank with the graph or viceversa and yeah it does sound like apretty cool way of doing it yeah awesomeCharlotte's been such an interestingpodcast let me ask you one one more bigquestion which is uh oh actually sorrybefore thisI'm very curious because you're buildingyou know an actual product with llms andI'm very curious um where your sentimentis on the Llama CPP ggml this kind oflike um you know would you replace gbt4with llama 2 with those kind ofinference libraries what would it takefor the Tipping Point to hitum I think it's probably more a matterof like when if it when we're gonna dothisum and I think it also is kind of usecase dependent but you know a bigaspiration of ours that we're going todo is we're going to have an Enterpriseoffering of this where we'll we'll Hostthis model for you we'll get that set upand this I spoke about it briefly but inthat world it's not going to be gpt4it's not going to be whatever it's goingto be those models are going to have tobe you know on someone else's on someonesome someone that we're hosting this asfar as Cloud you know on their AWSinstance it's going to have to be theirmodel it's gonna their data can't leavetheir AWS uh VPN or a VPC I should saythis is going to stay within there andin that world when we get to thosebecause we want to help those kind ofEnterprise customers out that have thiskind of they want to use what tacticgenerate can do but the data can't leaveand when we get to solving thoseproblems that's where we know we'regoing to have to to use these types ofmodels and you know we're we're verywell aware of that and we're we'reworking on it looking at llama and we'resaying we're kind of having we have ourplan of action forwhen we need to execute that we're readyto go and kind of deploying those atthat version of that of tactic generateto do that when we need ityeah that's super interesting to hearyeah I think like what Amazon is doingwith that is really interesting I alsowe had a podcast with Rohit Agarwal fromportkey and I think kind of this um likeload balancing between the LM apismanaging updating it and taking one downI think there's another software layerin between there and yeah that soundssuper interesting so so yeah let me askyou kind of the big uh kind ofconcluding podcast question which is uhlike what is sort of the thing that ison the frontier that excites you themostwow that is a big questionumwhat's on the frontier that excites methe mostokay I would sayumI'mI'm a big I I read a lot I like a lot ofcreative things so I'm really excited toseehow creative models can really becomethe point where not that it's like anovel novelty interesting I wanna Iwanna see someI want to see stuff generated by modelsthat's like you know you know effectsaffects you like the way a good book ora good film would affect you I I and Ithink you know people might laugh atthat now or they might find it kind offunny but you know the very first fouryears ago or whenever gpt2 came out Ifine-tuned a model on scripts filmscripts I was able to generate filmscripts and I thought that was amazingand now GPT 3.5 can do that with barelyany specific fine tuning on that so thefact that that's like the change thatoccurs in like three four years I thinkyou know probably in very less thanthree years three years being a highconservative estimate you're probablygoing to seesome really cool art beingum created by these models I don't knowwhat the modality will beum but something will happen so that'slike kind of a fun one of the fun coolthings that I'm I'm waiting to seehappen where people are very happy toconsume media that's generated by thesethingsumnot maybe not all of it but I that'ssomething I'm looking forward to and Ithink it's going to happen soyeah I agree completely it sounds soexciting I mean I I've always likedthinking about like I always talk aboutthis as like compositionalgeneralization like the avocado shapedarmchair is like the concept of avocadocomposed with armchair and yeah I thinkI guess there's like that trying tothink too hard about like what it meansto be new art right and then there'slike I I like the I like this other kindof you know people who are skeptical ofAI art and stuff where they say you knowthere's quite a lot to the humanconnection to it like I like this TravisScott song not just because it soundsgood but it's also like he's putting hisbrand his reputation behind it andthere's something like kind of like thispodcast right like you and I are bothlike you know humans behind the contentsort of yeah so like where where I kindof fall on that is like 100 degree youknow I like to read especially you knowif it's you can feel something personalin there or whatever it is but thecompositional aspect I still would thinkwill probably still exist in there rightyou knowif you probably showed songwriters theequipment that's available nowadays forpeople to create music they would maybesay something similar which is likethat's not creating music becausethey're not using real instruments orit's not you know that that wasn'tthat's not a real piano that's not areal keyboard it's not a real drum it'sgenerated or it comes from a key like acomputer sopeople are going to still have to likeprompt these these stories in a certainway um or there's gonna have to be therewill be some sort of thing in there thatlike will be some compositional elementand I think I think humans will you'regonna have people that are bettercomposers of these tools than others andI maybe maybe that's where we'll seeum people kind of have their footfingerprintum putting their stamp on on their ownart with thisum but yeah who knowsyeah that's awesome Charles and Charlesthank you so much for coming back on theweba podcast is such a fun chat Ilearned so much and I hope everyonelistening checks out uh tactic generateit is you know I think we already kindof talked about it thoroughly but I'dsay it's like the same way perplexity isyou know bringing together search andLMS you're bringing together kind oflike multiple personal documents andthis interface it's super cool so I hopeeveryone checks it out and Charles thankyou so much again thank you so much itmeans a lot cheers thank you", "type": "Video", "name": "Charles Pierse on Tactic Generate - Weaviate Podcast #69!", "path": "", "link": "https://www.youtube.com/watch?v=L_nyz1xs9AU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}