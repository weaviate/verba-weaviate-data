{"text": "Hey everyone! Thank you so much for watching the 69th episode of the Weaviate Podcast featuring Charles Pierse from Tactic! \nhey everyone I am beyond excited to be welcoming Charles Pierce back to the wevia podcast Charles was our second we VA podcast guest and now he's back for the 69th episode of the wevia podcast so a ton has changed in the space of large language models and Vector databases as well as what Charles has been working on so when we first talked Charles working on kinius and now Charles is building this incredible tool tactic generates I wanted to quickly give a tour of what this is I think this will also really help ground the conversation topics in the podcast to get a little sense of uh what this looks like so to get to get started I've loaded in three papers that I'm currently looking at EXA ranker perspectives on large language models for relevance judgments llms can accurately predict Searcher preferences and so all I did is I just you know grabbed the archive URL from these papers click sources add import URL and then drop the paper in so what you can do is you can ask questions across multiple documents so if I ask the question what are some of the challenges of using large language models to annotate search relevance I can get an answer based on each of these different papers so so each of these different papers might have found a different kind of conclusion about these questions if you have a question like you know say you loaded in different retrieval augmented training papers and you say you know how effective is this versus just fine-tuning without retrieval and then you have this question answered across multiple documents I think it's such an interesting tool the user interface makes it so easy to kind of ask these really complex questions as well as to export your summaries and share it across your team so I think this is going to have a huge impact on research and how we use these kind of retrieval augments generation tools so hopefully that gave you a sense of what tactic generate is about with that said I love this podcast it's such a fun conversation let's dive into it hey everyone thank you so much for watching the weba podcast I'm super excited to welcome Charles Pierce back to the weba podcast Charles Pierce was our second we V8 podcast episode and now we're back with the 69th episode of the Eva podcast nearly a year and a half later Charles welcome back to the podcast thanks very much Connor it is great to be back um very happy to be back on the podcast and to catch up on what's changed um it feels it's only been what a year just a bit over a year and a half but I think in the land of ML and AI That's probably like 10 years so I think there's a lot to catch up on yeah the the scope of everything I I re-watched our episode preparing for this and we were talking about you know graph embeddings rotating and and that was kind of the most exciting thing of the time and now we have these llms and yeah everything is totally different um so maybe to kick things off last time we were framing our podcast around kinius and now you're building uh tactic and generate can you tell me about what you're working on yeah so I'm working at tactic working on kind of the on all things machine learning there and uh tactic has um you know we kind of have two uh core kind of products that we're working on and the first are our core product of tactic which we've been building uh for the last two years or so is really focused on kind of sales and marketing teams and it's really to help them uh do uh kind of enrich their accounts in their crms and to do research on all of those accounts and that's really really high high scale so you know in the tens of thousands um and if like you know discover a new net net new accounts and yeah that kind of stuff but it's very much focused for like kind of sales marketing rev-ups people um and whereas lately the last couple of months we've been building this new product and it's called tactic generate and tactic generate is really aimed towards a problem that we've definitely heard a lot from our existing customers which was you guys are really good right now at going out into the internet and like retrieving relevant Snippets and insights for us to help us enrich our accounts but we also have all of these documents internally and we have all these really really big PDFs or you know Excel sheets or PowerPoints whatever and they wanted to do analysis on those and or do some really kind of in-depth research on those and we heard that problem a lot and we decided to build a product for that and that's what tactic generators it's built for kind of researchers analysts journalists and in general it's it's really for knowledge workers people that are doing kind of Fairly in-depth um knowledge work and what it isn't is it's not a chat tool you know it's not exp you know we're not trying to do um a chat gbt or anything like that there's some really great products out there that do that and that's not that's not kind of the Wheelhouse that we want to operate in for this you know where it's a slightly different Target uh it's super interesting yeah I'd love to stay because um you know firstly I really like the interface of you know you have the kind of like left panel of upload the documents and you put up you know let's say five documents and then you have the middle interface for the you know the questions that you've answered and yeah I love this um I kind of maybe diving in a bit quickly but this uh like llama index one of the most interesting kind of like llm framework things has been this kind of like uh comparison across documents prompt where you kind of uh like one of the examples was um let's say the five PDFs are like uh laws and I think in the tactic generate video it's like uh where was this established and it's like this one 1930 this one 1940 this one 1960 so that kind of like uh question answering across the documents can you tell me more about how you think about that just like yeah like question answering across multiple documents yeah like comparing multiple documents with LMS yeah um I think this is really this is really why we we decided to build this is because I think a lot of people out there when they you know they can upload a document or two maybe to to some of the existing uh chat applications out there but you know when you get in the scale of you know tens to hundreds of documents it gets kind of hard and a lot of the services out there actually block you from doing this anyway because you know understandably that's a lot of context and if if they don't if they're not using a let's say vectors like vector search in the back end they're trying to fit this in context and it becomes impossible so the way we wanted to think about this was if you want to do cross document comparison that should be super easy to do and we know that there's a lot of researchers out there that have kind of documents that might be similar the example we often think of is annual reports so a public company that's doing annual reports every year you might have you might be working for you know a financial institution and have 100 100 annual reports that you have to ask the same set of questions about extracted the same side of information across and you need to get all that data and you need to do it fast well in the manual research world this could probably be you know our best two days work of worst a week or two is worth um but it's it's actually it's relatively easy task but the the format that you extract that data in is actually quite important you know people like to have this in a in a tabular in a tabular kind of format or an easy way to do comparisons so this was the initial kind of starting ground for tactic generate when we thought about it we were like we want to enable this one task first to begin with so we built it so that you can upload 100 annual reports and then ask a set of questions of those annual reports and then bring all of that data back um and then have a nice table uh display but then furthering from that you know we also want to go with go forward with the next step of what analysts and researchers do which is probe that data and you know we're really trying to mimic um and learn from the workflows of researchers and the the users we're trying to build this for so we kind of kept asking ourselves okay we've extracted this data and and then what you know what do we do next with it so that's that's what we're really focusing on as well which is actually once we get this data extracted having some actions that we can take so if I give you if you give me a table of um answers about 100 annual reports I should be able to reprompt this or like re-question ask a question now overall of this extracted data um that um you know is a more complex piece of analysis like given given this data above which of these companies is best positioned um in you know to utilize AI in a in a positive way or given giving the above results which of these uh which of these companies is sensitive to interest rate changes you know these types of like more complex questions um so that's kind of like what our thinking around it was yeah well that's so interesting I mean the um yeah just the idea of turning you know you have questions is the columns and like a CSV and the the value is the answer to the question for each of the documents and then applying some kind of you know processing on top of that yeah that's also amazing I think kind of like you know in our theme of catching up after a year and a half this kind of like um like llm calls kind of like this is like chaining this like the core idea of laying chain where like it does these intermediate inferences and then from there you can do something else with the output of that llm call it kind of sounds like that to me yeah yeah that's that's that's a big way kind of in which we think of it and another really tricky part of this that where you know we still kind of very much consider ourselves in the beta beta phase you know we're getting a lot of feedback because we had a great response to it when we released but what we really are trying to do as well is try to automate as much of this process in the background as well so you know whether it's query routing or deciding when to chain or when not to chain based on the data we have or you know as lamb indexes we've learned from when to when to create queries and combine those back it's all of these kind of complex things are really important when building an application like this um and yeah it's quite exciting and you know it's pretty much changing changing every week but um yeah yeah this is music to my ears I think this is so interesting it kind of relates to like we have this kind of leviate land idea called generative feedback loops where you take the data Transformer with an LM and then save it for further processing and I guess like my question so yeah this whole like sub question query engine Islam index calls it or this kind of you know question decomposition transform the data to use it in some way later it's also interesting I mean I yeah I've been really trying to reason through this because I know that some people think that you know the kind of like Auto gbt style where you just kind of let the llm recursively decide to split the task into more tasks and it goes on and on and people say you know okay that makes for a great demo but it's quite hard to really tame that thing for something practical I think what you found where you you know break it into kind of these tasks of first asking a question over all the documents and then trying to you know reason about how you combine those answers from each of the documents is yeah it sounds really I love this kind of thinking and yeah I'm just curious like so I guess my question so you found this one this kind of chain of like and we via also we have like a generate uh API where we would call this like single result prompting where you apply it to each of the search results and then you have a group drizzle so it's like you found this chain that's really useful so yeah that I think my question is like what is your sentiment on these chains the discovery of these kind of chains and yeah I guess how you think about applying new chains and this one particularly where you transform uh documents into question answering pairs now you have a structured View and now you have some uh comparison prompt yeah yeah that's actually how we think about chains has been something that's really been on my mind because um I kind of agree with what you said about you know these when you hear about things like Auto GPT a lot of the time is they're really they really are great for demos um but for anyone that's tried to ship them in production and everyone knows it's a it's a very different situation um and as well as that it can also become prohibitively expensive if you're depending on you know third-party um and I think this is why you know I've seen I've seen topics on Twitter where people say will Vector you know are vectors Vector is Vector search needed in this like constantly evolving world can we effectively just put everything into uh one big giant context and I'm in the vector search um and I have a good reason for it and it's because you know llms um can be used kind of like a hammer for everything but it can be a very expensive Hammer if you use it for everything when it doesn't need um and you know if uh you know open AI release a new model tomorrow which has 100 100K uh context length well then someone's just going to start wanting to put in 100 documents that have a million context lines and then if they increase it it's just gonna it's gonna be this cut and mouse game so I think you know it's always important to actually keep efficiency in mind when we're designing these things so when we think about Chains It's like they're useful um and doing the kind of chaining chaining sub-actions is a useful task to do but preferably we would like to control as much of that ourselves and a lot of the time it usually ends up with us building some micro chains and it's not maybe not using a chain a framework that will do it for us and just kind of doing it ourselves out of the box um a lot of the time because it can be you it just gives you that bit of finesse and control that when you have kind of a kind of a vertically integrated app you need some sort of uh some sort of like business kind of knowledge applied to that um so we find that helps and yeah we've just found that you know if we can if we can smartly combine Vector search and not just Vector search but also the embeddings you get back it's really important remember the embeddings you that we store in weeviate are very rich in themselves and you know if if for people out there you know what were once considered like you know big uh normal machine learning tasks like clustering they might be I feel like they're really archaic now but obviously not but you know if you know how to do a few tricks with embeddings and understanding what the you know those latent spaces and cinematic representations mean you can do a lot of these tasks that are expensive llm calls just using those you know the embeddings are very powerful objects and they're much cheaper to play with than llm calls a lot of the time so we've had really good good um good luck and we'd like to we like to use it that way so I think to summarize what I'm trying to say is chaining chaining queries together is great but having a bit of uh control over them like manual control is important in production situations um and also exploring what Avenues are uh cheaper Avenues are there in terms of inference and overall cost is really important and for the equivalent results I think a lot of the time yeah I really want to come back to well there are two things I want to come back to with the yeah like how you discover these micro chains you mentioned and I have something interesting for that as well as then the cheaper inference thing too but um yeah maybe the like quickly touching on these points I think the the clustering the topic modeling thing it's still so fascinating to me I love that kind of topic I see startups I see you know Martin grutendorf who he still had on who we had on the podcast he's still hitting it with the topic modeling adding the llama2 to it and he's doing awesome stuff and then we have like gnomec Ai and arise AI that are and I think weights and biases has like a visualize your latent space part of their product too but yeah there's I because I imagine this um you know coming back to tactic General like I I give you a hundred annual reports or you know I I give you a hundred slack message or like a customer support thing or something I think about a lot and then you cluster it and then you tell me the topics I think there's still so much use in that and and then one other kind of little thing I wanted to touch on maybe we'll come back to it later was um yeah yeah like this Vector search thing I'm actually my perspective on weeviate these days is I'm I'm kind of thinking of you know my scope of weavate is expanding for how I personally see it like um you know we weave has an aggregate API as well so with this generative feedback loop thing what you could do is um you know you Trend let's say um the the one of the questions you're asking each of your documents is uh what was the annual revenue for this year and then you store that as an in property and we V8 like feed it back to ev8 and then you can have you know what's the average revenue so you can do just those symbolic aggregations and so I think especially as retrieval augmented generation is evolving like we VA I think it's would be it's cool for people to know that you can use it just for like Json retrieval like you can just apply filters and just get your data out of it you can also do SQL style and then you can also do Vector search and I think the scope of that is going to continue to evolve as well you know I think I could write like a whole blog post and diving into that topic but yeah so I really want to come back to so these these micro chains and I've heard this I so there's this there's this thing I've been exploring from omark a top called dspy or dspi I think where it's about uh you you compile these intermediate steps for some kind of chain and so you so as so how do we discover These Chains to do do tests that's kind of the question I think is do do you give the llms like some kind of action space like here's the kind of things you can do and then it searches through it somehow yeah I think for us it was it's been kind of easier to discover these chains because you know we're very much you this product is very much driven by what we think our users kind of want so we're we're trying to be very ux-led with the design of this product and I think that's quite important with AI uh product design these days so because of that we're very user-led we're listening to what uh people that want to use it or people that are using it so we're kind of trying to we're trying to look at their workflows and say what are the commonly occurring kind of like modules or like facets of their workflows and then those are kind of our chains you know saying oh whether a summary what doing a summary or doing like a comparison or doing like a kit like kind of a splitting out key points or doing like a topic extraction doing an extraction of people or looking for key figures these are these are kind of like what we would probably consider chains so it's kind of easier for us to reason around them because they are very much connected to like requests and you know us just aggregating in requests we get from users so I think that's kind of that that's what makes it easier I suppose for us to specify out these micro chains I was talking about because they're very much related to things we know people people want and then you just kind of have rooting you just figure out how to root those to the right place when you get a question in um now in figuring out how to do that more and more intelligently is difficult um but that's that's kind of the way we think about it so I think another thing that makes it so interesting is like uh one podcast we had was with Yana wellender who's building craftful and so she's like uh she's kind of like what you're doing she's marrying these two skills where she's a product manager and she's like has a really good sense of you know llms and prompting and all this kind of stuff and so she does she combines that to come up with the micro chains for product manager tests like analyzing user feedback prioritizing a road map like that kind of thinking and I think it sounds like what you're doing with that but with crms and sales and that kind of stuff yeah it sounds like a really nice marriage of these things yeah and uh yeah sorry I have one other idea that I forgot maybe we'll come so come coming back to this I I do also kind of want to talk about um so you know there used to be this thinking around like to have like a moat with your ml product you would have to like open AI is just gonna if all you have is prompts they're just gonna destroy you eventually yeah have these conversations what's your sentiment I I personally believe no because yeah I think this I think there's so much to structure like where you see the structure and I don't I don't know but you know obviously the end-to-end Deep learning people think otherwise yeah yeah so you know this is why we're not building a chat app you know it's uh it's been done it's been done really well um it's not where we saw our mode and it's also we we know where our skill sets are and it it was in uh building building products that solve kind of difficult uh uh problems for researchers and an analysts and extracting key insights and then the a huge part of that is ux and I think ux's role in um AI product development has I'm not going to say underplayed but it's not like the the part that gets the most media attention or the most hype around it but I think it's like incredibly important and if if there's to be in the world of like you know open Ai and all of these great providers of large language models if there's if their models or their modes you know the the modes for other companies out there should be things around um ux and then like just how they combine all of these little tasks together in a very user-friendly way um and you know we when before we even wrote a single line of code for this new product we really just thought about what's you know what's the user experience we wanted to to deliver and I'm not and that's not even to say we're nowhere near where we want to be but we're really thinking about it and trying to trying to get there is um kind of thoughtfully and fast as as possible um but what was a really big uh thing for us a big kind of aha moment was we had a realization about what the what this generate would be kind of from a ux point of view and I think for any data scientists out there are people who are kind of have worked in data science or analysts it could make sense from a data point of view but I was a big consumer of Jupiter notebooks Once Upon a Time just as a data scientist so I was I've done a lot of work in Jupiter notebooks over the years and people that work with data they understand implicitly how much of a change those added to the world of like data analysis and how big a deal that was so we kind of asked ourselves we said do why does something like this exist for like kind of language knowledge extraction where the data the primary data is actually a natural language and what we kind of thought about is no it doesn't um so that's actually a big inspiration for our ux is we are kind of we view ourselves as like an AI notebook for knowledge workers that's kind of like our house thinking around it and what does that mean well it means we think of we think of your application your in terms of cells so things are cells just like the way they are in notebooks and you can add a question cell or you can add a question table cell which is like the comparison stuff you've seen you can even add in text notes which can be marked down or whatever but Beyond just the UI those being like visual cells there's something else that's bigger there and that's reproducibility so when we talk about reproducibility what we mean is let's say you've figured out a really nice way to analyze annual reports you have this workflow kind of like an application almost you have an AI workflow a way of asking questions um and conducting analysis on um a bunch of annual reports well that's great annual reports come out annually and quarterly reports come out quarterly so this is actually a repeated task something that you'll want to do um on some sort of time frame and this is where the notebook ID I think really shines because using that we can kind of you know use the same structure of your notebook and reapply those questions to either new data or updated data and this is kind of the reproducibility aspect that we've been thinking about so you know I can share my notebook schema with you um and then you can copy that onto your own type of data as long as you know hoping that it's from the same sort of distribution um we're not there just yet but we have kind of the Scaffolding in place to to build out this notebook structure Rick we have like the notebook visuals and uh we're getting towards in the kind of medium term towards having this shareability and reproducibility in there and I think that's a game changer because it not only allows people to do things like you know a common analysis over um an annual report but you know it could allow people to create weekly digests from an AI you know based off of uh whether it's reports coming in for an executive from uh people that you know that are reporting into them or one other integration we added in at the very start was GitHub you know what if I'm a CTO and I want to know what my team has been working on every three days well I could conduct have this report that runs through scans my GitHub account runs it through this report and delivers it to your email it's that kind of reproducibility that we've been thinking about I'm building these kind of like AI notebooks or AI applications for um kind of a really large variety of end users and when we think about trying this all back to where we started that isn't really an llm problem that's a ux kind of design problem as well and there's a lot of other kind of engineering um problems that you need to solve in order to be able to deliver that so I think that's where we think our our motives and that's what kind of differentiates us you know firstly that was fantastic that was mind-blowing I I know I'm gonna make him know I'm cutting that out and putting just the last five minutes on Twitter and I'm not even just saying this because we're friends when I saw the tactic generate I had this similar kind of thought that like you have um you know tamed The Prompt into a UI so to say this is like a document comparison thing that makes sense and yeah I think um like in addition to Chad gbt I think probably a lot of our listeners know what uh perplexity AI is and uh perplexity AI they have like this kind of like cite your sources a GUI with the uh chai GBC so you know it's a little more like search engine llm fused together and you know we've yet we've built an open source verba which shows you you know like yeah the the the um the front end and the ux is so much opportunity and I mean just the last thing you said really was is really exciting to me because um like I think about like um you know with me say I have this hypothesis about out like currently my hypothesis is like oh I think gorilla llms are going to do such and such a thing and so I might imagine like you know I one thing that I do like one of my I've got this from Tim scarf he said this on the machine learning Street Talk is um like what's your information diet and so part of my information diet is I comb through the the tweets I've liked for the last week and I just kind of you know see what happened basically and so I can imagine yeah dragging and dropping all of that into um into tactic and then saying like a question of like would any of this change my hypothesis about the current thing because like you know when Falcon 180b you know arbitrary thing that came out this week is like maybe that changes my hypothesis about fine-tuning llms or yeah something like that yeah yeah that's what you kind of said there is exactly how we're thinking which is we know there are people out there that have kind of like their own personal workflows for how they like and a lot of it could be in your process data and then the questions you ask of that and what we're trying to do is just figure out a way to like weave all of that in together and give you just an application to do that so we're like a we're like an intelligent data pipe for workflows um yeah so I have a question for you this is something I've been thinking about like with the verba project is um is like does fine-tuning have any role like um you know so verba is a quick background is like you know it's like arbitrary vlogmens a generation app and we're dog fooding our own weevia you know you have to issues for the we V8 documentation that's how you do it and so I think about like you know what whether you would um you know thumbs up thumbs down the responses and then rohf and whether that still has a role in these kind of things or if we're just kind of like zero shot LMS go for it yeah like I think the thumbs up and thumbs down definitely has is important but like the I like when I think about this the problem with it right is even even though like you know reinforcement learning with human feedback has gotten it's we know how good it is you still need like a critical mass of data to get going and I think it's hard to say to people well you need to get like ten thousand ten thousand responses like thumbs up and thumbs down to this before you get going I think anyone that's developed an application where you're looking for like Thumbs Up In terms then responses no it's generally it's hard to get clicks and stuff like that even if you've got a really busy product a lot of people just don't leave that kind of feedback um but when it comes to fine-tuning in general and then versus something like rag the way I've been thinking about it I saw a really great tweet that like stuck has like stuck in my head ever since I've seen it and I think it was saying that you know fine-tuning is for style and retrieve rag is for facts and like I stick I think that's like that makes total sense to me and I even seen the work you guys did last week with Gorilla that I think that like still adheres to all of that because you know the style there is actually like a structural style of you know emulating graphql so style is important in that instance but if if Fox um and retrieval and just bringing back the right data is important I think retrieval suits more to that need you're going to get a lot more out of retrieval than fine dining because most people's data isn't too far out of distribution like your data has to be fairly significantly out of the original data distribution I think in order for fine-tuning to make a ton of sense um and I know there's a lot of there's a lot of people that do fine-tune these models on very particular data and it is of course it has its place but I think for a lot of you know Enterprise users and stuff like that the value add from uh from fine tuning mightn't be exactly what they think it will be especially if it's like trying to imbue like if there's a certain if there's like facts and information figures you want to be returned I would just use rag right you know that's that's it just seems so much cheaper so much faster to iterate on and to control than um fine-tuning yeah I think my I have a few a few things on this like um so our last podcast with farshad fireboxy and the Gen AI specialist at AWS he presented um instead of style he phrased out his skill versus knowledge and and he used a lawyer example where it's like you know me I could have the world's greatest like I could have the perfect uh laws that I need to help get you out of jail and you're still going to jail if it's me who that has to reason about the laws that help you out so it's like but I I do agree that like um you know I think with um I think as we think about like the future of this too I think probably there's going to be some like let's say gbt5 like what do we think that's going to look like we we're seeing these long context llms like we had ophira press on the podcast to explain how Alibi attention works and like there's even like a week later there's like yarn scaling it like moves that fast and and so so it's like um I think that you'll be be able to put so much context into it that it'll really be that that will really take over and just zero shot with great context but so I kind of but um so staying and yeah the style for so I guess I'll make you one more point on the gorilla thing with that thing is like I think there are some for me gorilla is about um like you don't need a massive language model to write graphql yeah it's like and and there's a lot of little tasks like that that's kind of how I see the gorilla thing yeah and I it's probably because you know graphql the great thing about it is it's a structured language so I imagine when when finding tuning lamb on that it like it probably really picks up and uh picks up and the the structure of it fairly fast because it's it's a it's a programming language so it's actually nice and has a limited syntax which is good yeah I'm so excited about like uh Destiny coder there's like a new code Foundation model that's it's oh man it's so interesting how the how you fine tune but you need like the foundation model checkpoint to fine-tune from and it's like well can someone give me a smaller Foundation model yeah and it's all really crazy I mean um yeah and like I also think the text to SQL models would probably be smaller models like you know this yeah but so I kind of want to talk a little more about fine tuning and so you know you I think we both agree that to have your llm you know reason across your documents provide these summaries and like aggregate the results from the single questions in the tactic sense that you probably don't need to fine tune it to reason about your specific thing it probably is going to just be such a capable reasoning engine that with some retrieve context and with the current thing it will get you there but there's still this idea of fine-tuning the search models maybe yeah like maybe you fine-tune ranking models or embedding models how do you currently think about that yeah Yeah well yeah I see what's great about search models and embedding models and rear anchors is they are like you know orders of magnitude easier to to fine tune and they're just like lighter cheaper models in general um and there is it's they're just so much smaller and I actually think retrieval models are such a fantastic example of how bigger isn't always better for in terms of you know in like large language models you know retrieve like retrieval models are just so much better than uh like very very large language models for you know picking at the top K candidates and I know llms can't really even do search but you know just what if you look at the the the top retrieval models um kind of in benchmarks out there at the moment you know open AIS uh Ada two is like kind of in the middle of the results and you have these open source models that are like you know probably under two gigabytes in size um like vastly outperforming them like I mean I think that's a really good sign showing that if you've got like specific very task specific things you know that's where there are so still there still exists exist cases where llms are not the king it might give it a year and let's I'll probably you know change my view on that but right now that's still the truth um so when it comes to retrieval models they're they're great they're really easy to to to fine tune so let's say you know we decide oh we've got a really good use case for for law or for Health Care well then you know to to train tactic for health or tactic for law that's a that's a lot easier for us to do and then to pass that into uh uh llm to kind of pick out the passing and the information it needs so picking up improving the retrieval is a much easier task and you know for the right for the right if the if the down if the other domain is you know significantly out of domain you know you can only fine-tune llama or something like that on on that domain there's always an option to do that and you know it there's there's probably like a strange correlation between the industries that would require you to self-host the model anyway and how to distribution their data is I'm talking about like healthcare and like people stuff a lot of the time these might be Industries where sharing you know the data is so sensitive it can't be sent over in llm so you might as well just fine-tune your model on it anyway because it's it's going to be self-hosted or I think that's what I think there is going to be anyway when I'm seeing what's happened with llama the last couple of months is it's going to be a lot of you're going to see a lot of people looking for expertise or companies out there that can help them fine-tune and deploy their own special models in-house because they're just there's just there's a bunch of Industries out there and they're just never gonna allow certain data to move over the net over their apis no matter how secure um uh the the API provider is or the service provider is they're just they can't you know I live in Europe you know there's just there's no ways can allow some of that data move over move over the web that easy yeah well I I want to parse out this um you know easy to up easy to train retrieval models I think firstly I'm talking to the wrong guy because I remember in our other podcast you had trained you use the pie torch big graph thing and I mean that is like pretty hard but I I think I think the um for me this is actually kind of the phase shift in training and betting models I mean first the first thing that happened with llms is it was looking like you could use the LMS to generate synthetic queries and that was like the oh now we can you now we have positive pairs you know and that was kind of exciting it but I think and especially for the long tail queries like you know queries that are sorry documents that are frequently queried on you can kind of even out the distribution more this way by having queries for those documents but I think even that for me you know contrastive learning I don't think that was going to I don't I don't know I you know like we see products for fine-tuning in the market but I think this end to end you train the llm the gradients from the LM go back to the encoder as well that makes training embeddings so easy yeah yeah so yeah I think that's really interesting um I I the whole world of fine-tuning to me I think is in flux um I don't know if you saw this week but you know there's a new kind of there's a new continuation of reinforcement learning for human feedback called the acronym so difficult to remember but reinforcement learning for AI feedback um so it's you know the exact same as human feedback but just replacing the human in the loop with a kind of an AI agent that's prompted to understand that task somewhat and to me maybe it's not my kind of unpopular opinion on oral HF is that I don't think it I think it's actually a it it's it's going to be something that shouldn't exist in five years because it actually highlights issues with our current training regiments for fine tuning and for training for training models in that the the latent data that the original model is learning from isn't good enough or the architecture of the model isn't good enough to train a model you know to be able to do these chat tasks in a in a really good way you know that so you actually need to do this fine-tuning step whereas my expectation would be that you know we get enough compute and enough we improve the architecture enough that in a couple of years we're kind of just back to where we were with the original regressive Auto regressive models which is you're just passing in the data it's and you're not giving it any you don't even necessarily need to do this reinforcement learning task it's just it it has enough capacity to learn I'm in a chat context here or here I'm in a instruction context or here I'm in an extra context that to me seems more pure than this layer at the end of doing fine tuning um not not that I think you know reinforcement learning hasn't been amazing it's been what's given us kind of the last year's worth of improvements but it feels like an in-between step hmm yeah I don't I don't really have a great thought on this my I just I guess for me it's like um uh the difference is always I guess I don't really understand the difference that well honestly like with reinforcement learning with human feedback it's like you like the answer so you could also just kind of language model that answer it's not necessarily that it has to be plus one minus one optimized with proximal policy optimization and uh you know have a reward model and all that kind of stuff I'm not sure I understand you know I I know that there is like if people out there listening are curious like Nathan Lambert has written a lot of great stuff about this at hug and face and I just I haven't read it yet I I don't know but um this um this kind of like llms versus synthetic data is so interesting I mean kind of coming back to tactic I mean I can imagine like um and maybe not the current generation of albums with the multimodal LMS that like use a UI or well I mean yeah maybe coming out of the UI and just let's say just with apis right like we could have LMS like a multi-agent kind of system this kind of yeah what do you think about this kind of direction of like I think there is a paper it's like uh it's like a large language models content and behavior language models something like this but but yeah it's like about um the llms like you know they simulate using because you mentioned like a gbt4 eval where the LM is prompted like with the instruction response pair did the response follow the instruction and people are that's that's actually like I think the most common way people evaluate the question answering systems yeah yeah so like I I do think we're probably going to see a world where it's just gonna be like it's going to be models calling calling models um I mean what you guys have done with Gorilla I think you could you could if you think about it you could probably just extend that outwards right which is um your your model gorilla is for kind of GRA has knowledge of certain graphql schemas well I I have my private model which I also have trained on my private graphql scheme or maybe it's the rest maybe it's SQL those models can now talk to each other in like natural language they actually don't need to know each other's schemas so my one can request data from yours via like natural language queries and vice versa and then they can convert those in the background to the accurate schemers return it so I think there's this I've vaguely thought about this where you have this world now where you can have models effectively um talking to each other that are fine-tuned on very specific schemas but they have no knowledge that the other one has like a specific schema behind it because the model would probably still come back you know in a natural language response but like it's it's actually creating a structured database whether it's SQL or graphql or whatever it is so that yeah that's kind of one once what I saw you did last week I was like oh yeah you could potentially have this world of just like agents talking to each other very just through natural language but just distilling it down yeah I'm really gonna like dream into the future with this one but I I've also been thinking a lot about crms and particularly like um you know like my dream with the gorilla project is kind of the Integrations angle where you would say uh you know uh build a llama index query engine from my notion workspace titled biochemistry store the data in weeviate embed the data with cohere re-rank it with cohere or like visualize over the rise like I want to see this like combination of all these things together and so I think like um you know with with like a CRM this has kind of been you know when when Bob was first like pitching like you know explaining his vision for generative feedback loops this kind of idea of like um personalization has always been like that I just I love that like we when we developed a blog post it was like Airbnb listings and it's like write an advertisement for Connor who travels with his dog Bowen or Bob who's a power lifter and he's like a special kind of gym and so it's like uh this kind of thing of like um you know why would uh deep set be interested in my gorilla blog posts like you know help me you know come up with something for me right and so that that's where I see like crms and you know like thinking about the other agents in your system with the future of like API design and yeah and I think the tricky part there right is the routine systems because now we need all these routers and it's like it's kind of funny that these concepts are returning that people haven't really had to think about for years you know like since the you know the initiation of the web so now you have this now you have rooters in the sense of for for large language models and you know sending things to I suppose in a way you kind of call them the right experts or whatever um and but you kind of still need this routing system on top um and I think that that's a problem I'm working on like today trying to figure out like trying to figure out when when is the right time to use a router um how like why should you use one and then if if they're talking to with these experts like the the ones you're using how do you represent what that expert which which expert can do what you know is it just like a is it a descriptor or does the can this router actually go out there and talk to these experts and say which of these ex which of you is the you know it can provide the best candidate answer to my question yeah yeah it's just you're in I had just sharing Tianjin from Berkeley the authors of girl I asked them the same exact question like are we going to need to have a hierarchy of gorillas like yeah I feel like just um I I guess it's like um well for what we've done so far with the graphql apis I can fit all of that into you know it's it's 46 apis but it's like uh you know there there are Atomic apis and then we get a lot of some compositionality like how you combine like you know Vector search with a wear filter limit the results see the object Vector so you know like you could fit all the atomic apis in the prompt with some explanation of how the compositionality works and if you give that to gbt4 obviously use the strongest thing you can to see if it works at all and then like that yeah yeah and then that could give you like the natural language command to then hand to the you know smaller more economical weviate gorilla so yeah that's how I kind of see that thing and I guess if I can ask one more question on the crms thing because I really like exploring this idea is like I feel like with business kind of like the most effective thing you can do is kind of like try to make a lot of people more success right like and it kind of like I feel like tree of thoughts this kind of like planning could have such an interesting intersection with these CRM kind of things where it's like um you know like I have these different projects that I could pursue right and it's like if for each of these ideas you know the these like CRM reasoners could like you know go in and say okay well deep set probably wouldn't get too much out of that streamlit might get something out of that and then like put it all together and then say hey Connor I've done the analysis I think you should do this project yeah I mean that that's like that's a we've kind of had a very equivalent thought about around crms but specifically with some of the users we have in our existing core product which is kind of sales and marketing people which is you know they feed us um a list of accounts from from their CRM and we help them pick which ones are the best ones for them to Target you know to to do their job the best and to have the highest um efficiency and success rate so if you think about a reasoning agent there what tactic does is we pull back in our core applications we pull back information and data we extract data about all these companies so reasonably you could hypothesize that using a CRM and then you know using uh you know if you specify out like a kind of a a prompter some kind of reasoning around what ideal customers look like you should be able to allow this thing you could feasibly have like a Chain of Thought going on looking at these accounts the knowledge you have about them and reasoning giving you like the giving like a you know you're a salesperson you're an account you you know account exec you're going to be calling people tomorrow you might come back in tomorrow morning nine o'clock and you check your CRM and you have like a list of today's Target accounts and then you have reasonings why and you have like some explanations in your CRM being like we want to I think you should talk to this person at this company because uh this change has just occurred they've just hired this you know this change has happened in the market that'll be really cool and I I don't I I don't think stuff like that is you know too far off to be honest you know we've explored parts of that so yeah I guess maybe the biggest part with that is um maybe it's I mean you know the whole uh connecting data to alleviate that's exploding like you know we um we just did a podcast with David garnets from Vector flow you know there's uh unstructured we did a podcast with and there are a few that we're talking about but this like how do you you know like how do I keep Charles's last week updated in my CRM right like yeah yeah it's really interesting yeah yeah it's such a cool topic I love thinking about kind of the future of crms because I I do feel like that would be the big thing is like if we could just better organize business better organize our effort better coordinate everyone sort of right like it it's kind of I mean yeah like I love thinking about the multi-agent perspective of LMS of like not necessarily like yes elements but like you know the the way that things work sort of like it needs to you need at the end of the day your thing your building needs to like appeal to a person otherwise yes yeah 100 like I think you can kind of tie that back to what we were talking about at the start with even with tactically generate in terms of workflows you know people you know like leaving the land of just talking in terms of Agents uh what llms are trying to do is or the value I think that you know people see in them and investors seeing them is that everyone has all these workers out there have these workflows and there's repetition Within These workflows and there's tasks that need to be done and these workflows can also be defined somewhat so using these models you know the the idea is make workers more efficient by automating the parts of this these workflows that can be automated and there are Parts in there and by actually doing that when we make when we automate away um these parts you make workers more productive by allowing them a lot more of the the deeper the deeper thoughts the more complex parts of their job and I think that's that's where we see um the power in llms is that you know we know that there's people out there that have processes that they work through and it's like okay how do we like best capture capture those and like you know just solve the the parts of that that aren't enjoyable or that are just real time suckers you know the things that really take up take up your time and I think any everyone in most Industries could like if they think about it can be like what what do I still do every week that's manual and there's always something so something out there that's like a manual research thing that people do and of course anyone can build their own um if you have the if you have the knowledge you can build your own you know really intelligent kind of automation around that so what we're trying to do is build those four people and you know a lot of that will actually end up as well being Integrations on in inwards and outwards Integrations you know like you know we take in data from GitHub from Salesforce and we export it to you know wherever so that kind of flow as well will be really important you know integrating with a lot of common workflows for people yeah that's amazing I just imagine how much everyone will be super charged by that because it's like it's like not only do you have your own assistant that kind of manages like you you have six emails today you have this me like how you might think about like a 1970s secretary now it like uh could even organize it could even like schedule your like you know I have you back to back with Charles and say I have someone else working on a similar project because like it wouldn't be too much of a context switch for you to then talk to someone else similar to Charles and or like you wake up and it's like you have this meeting and here's why you know like it can be something as simple as you know you've been away I was I was away on holidays last week so you know I come back and I I just want to know what's been going on in my slack you know and I know the fields out there that you know that they already do to that but that's one integration so how do you build a tool that can kind of build those Integrations for everything and repeat that and this is where you know and the questions you know uh a tech person or an engineering person might ask a slack might be very different to what someone in go to market go to market function would want to ask um and again you know extrapolate that to GitHub and what a CTO might want to know about you know what how their team has been getting on and what bugs have been occurring and you know imagine you could ask okay what bugs have been occurring and like what parts of the code are these occurring in and like that might help you realize oh and we need some better testing on like this part of our database or sorry this part of our code repo because bugs are like consistently occurring there and you you know you could always discover that via your own analysis but these are things you can actually automate a way as well we think yeah that is the killer that that's really that's really exciting I mean just yeah like testifying from with weavier and trying to keep up with everything that happens in the slack and then yeah and then also trying to tie that to the code base which is itself like an entire like city of complexity yeah oh yeah yeah I understand I understand the band I think anyone that's worked on any kind of project that's going in complexity knows you know I recently looked at the weba code base and I had looked I'd worked on a tiny bit you know maybe two years ago small contributions I was like oh wow it's completely different I I had thousands of commits to pull down when I change my job so yeah yeah but yeah that that um the that that would probably be one of the biggest applications of that generative feedback loop thing I think is think is uh summarizing the slack so I one more question I wanted to end with from our talk uh you know a year and a half ago we were talking about uh we talked pretty heavily about graph embeddings and knowledge graphs and I want to hear like where is your sentiment on that now I'm I'm still I'm still long on on graph embeddings I think they're like I think this back to what I was saying earlier and that there's like there's expensive ways to do things and llms are an expensive Hammer brilliant and that's great but I think uh in order to really connect data that's not just language and you know that are kind of topics and objects and uh I think that's where graphs graph embeddings are still going to or graph models are going to take off or like that they will be relevant what I saw in the last week which was kind of cool um is a lot more people working on generating graphs from llms and I we talked really briefly about this I think maybe two years ago I kind of discussed that but we're probably now in a place where that is way more feasible and that you say to a model here's a here's an article uh just write me every single here's the set of relationships that we can have um between objects and and here's the set of objects types that can exist or node types that can exist just send me send me in whatever graph format because there's like a million graph formats out there but just send me send me whatever I want in like you know head relation tail format all the relations you see in in this text and then you can slowly build up like a a graph database then of all of these things and then you could further train this to to model the latent space of these and that that would be a much cheaper way in my opinion than to build like a a Knowledge Graph understanding of you know what's going on in your data without having to llm absolutely everything and build my open AI bill so I still I I do I I do probably I would say graph stuff graph embeddings has probably not probably fallen out of the Limelight a little bit within the last year or two just because of how how easy um llms have made it to do a lot of the tasks people were looking looking to those for but I do think that um there's a lot of value in them and I I I've still used them for little projects over the last year or so and I just think it's quite amazing actually when you see them train how like those little latent spaces of graphs is just so cool to me still so yeah I still I still have a I have quite a bit of belief in them still yo I guess um for me the um like the connection of graphs and then causal inference has always been what keeps me interested in this topic more than anything else because I like earlier I mentioned that um you know I get my new week of Twitter and basically the question I'm asking in my own head is does any of this news change my world model of how things work and and then thus how how I'm planning to spend my time because of my belief and how things are and so I do think like if you extracted you know and it's like the comparison across documents thing if you extract the structure of the you know relation uh entity relation entities and then you know compare them with each other it might be a more efficient way of saying this document disagrees with this other document compared to just looping through with the llm being like does this paragraph occur this one actually really good point because there is you know a well-known well-known problem class in graphs is not just no classification but also like graph classification and graph comparison so if you're building up sub graphs um I think reasonably compare a generated graph versus a generated graph and you know have a similarity score off of that which is again cheaper than llming that straight out of the box you know yeah well I think there is so much that I mean I guess it's like like I guess one thing that I'm really interested in is like if uh some something happens that changes everything in your document before then then what do you do about that kind of and yeah I know the whole thing is pretty interesting I mean yeah graph embeddings I guess here would be my question about graph embeddings that I've struggled with is I really like this idea of like I have all my documents and I connect them with symbolic structure and maybe I propagate that to have better embedding somehow but then how do I put my query into the graph as well so how do you query the graph yeah so we I actually have done stuff on this in the past um and there's like I think there's like a couple of there's like a couple of ways in which is like you could if you're like embedding a graph into let's say I'm creating like a evade instance and the the vector embedding is like an actual graph well then what I could have is like the query the query could link to um some textual representation I have of like an object in that graph and then from there I could resolve that down to like an item within the graph so let's say let's say you know I search I want to discover films uh about Ben Affleck well then the query might be Ben Affleck I have a text object that I know resolves to the resolve that down to um the maybe it doesn't have to be one but resolve that down to like a couple of nodes so one of them might be Ben Affleck one might be the you know the Batman films and from there then you can try and return relevant results from from that graph back um but resolving natural language to that's one idea maybe I had for I have for how you could resolve natural language that back down um to graph embeddings but I know it is a tricky thing um um because it doesn't naturally translate right you know they're very very abstract Concepts like an item or a node embedding yeah I heard that same idea from uh Professor Laura Dietz from the University of New Hampshire was on the podcast and yeah she she explained that same kind of idea of uh you know you could like retrieve with the embeddings and then re-rank with the graph or vice versa and yeah it does sound like a pretty cool way of doing it yeah awesome Charlotte's been such an interesting podcast let me ask you one one more big question which is uh oh actually sorry before this I'm very curious because you're building you know an actual product with llms and I'm very curious um where your sentiment is on the Llama CPP ggml this kind of like um you know would you replace gbt4 with llama 2 with those kind of inference libraries what would it take for the Tipping Point to hit um I think it's probably more a matter of like when if it when we're gonna do this um and I think it also is kind of use case dependent but you know a big aspiration of ours that we're going to do is we're going to have an Enterprise offering of this where we'll we'll Host this model for you we'll get that set up and this I spoke about it briefly but in that world it's not going to be gpt4 it's not going to be whatever it's going to be those models are going to have to be you know on someone else's on someone some someone that we're hosting this as far as Cloud you know on their AWS instance it's going to have to be their model it's gonna their data can't leave their AWS uh VPN or a VPC I should say this is going to stay within there and in that world when we get to those because we want to help those kind of Enterprise customers out that have this kind of they want to use what tactic generate can do but the data can't leave and when we get to solving those problems that's where we know we're going to have to to use these types of models and you know we're we're very well aware of that and we're we're working on it looking at llama and we're saying we're kind of having we have our plan of action for when we need to execute that we're ready to go and kind of deploying those at that version of that of tactic generate to do that when we need it yeah that's super interesting to hear yeah I think like what Amazon is doing with that is really interesting I also we had a podcast with Rohit Agarwal from portkey and I think kind of this um like load balancing between the LM apis managing updating it and taking one down I think there's another software layer in between there and yeah that sounds super interesting so so yeah let me ask you kind of the big uh kind of concluding podcast question which is uh like what is sort of the thing that is on the frontier that excites you the most wow that is a big question um what's on the frontier that excites me the most okay I would say um I'm I'm a big I I read a lot I like a lot of creative things so I'm really excited to see how creative models can really become the point where not that it's like a novel novelty interesting I wanna I wanna see some I want to see stuff generated by models that's like you know you know effects affects you like the way a good book or a good film would affect you I I and I think you know people might laugh at that now or they might find it kind of funny but you know the very first four years ago or whenever gpt2 came out I fine-tuned a model on scripts film scripts I was able to generate film scripts and I thought that was amazing and now GPT 3.5 can do that with barely any specific fine tuning on that so the fact that that's like the change that occurs in like three four years I think you know probably in very less than three years three years being a high conservative estimate you're probably going to see some really cool art being um created by these models I don't know what the modality will be um but something will happen so that's like kind of a fun one of the fun cool things that I'm I'm waiting to see happen where people are very happy to consume media that's generated by these things um not maybe not all of it but I that's something I'm looking forward to and I think it's going to happen so yeah I agree completely it sounds so exciting I mean I I've always liked thinking about like I always talk about this as like compositional generalization like the avocado shaped armchair is like the concept of avocado composed with armchair and yeah I think I guess there's like that trying to think too hard about like what it means to be new art right and then there's like I I like the I like this other kind of you know people who are skeptical of AI art and stuff where they say you know there's quite a lot to the human connection to it like I like this Travis Scott song not just because it sounds good but it's also like he's putting his brand his reputation behind it and there's something like kind of like this podcast right like you and I are both like you know humans behind the content sort of yeah so like where where I kind of fall on that is like 100 degree you know I like to read especially you know if it's you can feel something personal in there or whatever it is but the compositional aspect I still would think will probably still exist in there right you know if you probably showed songwriters the equipment that's available nowadays for people to create music they would maybe say something similar which is like that's not creating music because they're not using real instruments or it's not you know that that wasn't that's not a real piano that's not a real keyboard it's not a real drum it's generated or it comes from a key like a computer so people are going to still have to like prompt these these stories in a certain way um or there's gonna have to be there will be some sort of thing in there that like will be some compositional element and I think I think humans will you're gonna have people that are better composers of these tools than others and I maybe maybe that's where we'll see um people kind of have their foot fingerprint um putting their stamp on on their own art with this um but yeah who knows yeah that's awesome Charles and Charles thank you so much for coming back on the weba podcast is such a fun chat I learned so much and I hope everyone listening checks out uh tactic generate it is you know I think we already kind of talked about it thoroughly but I'd say it's like the same way perplexity is you know bringing together search and LMS you're bringing together kind of like multiple personal documents and this interface it's super cool so I hope everyone checks it out and Charles thank you so much again thank you so much it means a lot cheers thank you ", "type": "Video", "name": "Charles Pierse on Tactic Generate - Weaviate Podcast #69!", "path": "", "link": "https://www.youtube.com/watch?v=L_nyz1xs9AU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}