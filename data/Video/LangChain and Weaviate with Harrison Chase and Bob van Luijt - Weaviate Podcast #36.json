{"text": "Hey everyone! Thank you so much for watching the 36th episode of the Weaviate podcast! This episode continues on the ... \nhey everyone I'm super excited aboutthis week podcast we have Lang chainfounder Harrison Chase and we've yet CEOand co-founder Bob Van light so guysthanks so much for joining the podcastthanks man looking forward to thisconversation thanks for having me guysreally excited to be here awesome wellI'm just so excited to dive into itHarrison could we start with the storyof like the origin story of Lang chainlike how you created this yeah I mean itstarted really uh kind ofinnocently and innocuously I was justchatting with the so you know everyone'sinto language models these dayseveryone's building applications and andso when I first started chatting withfolks and this is back in likeum September October people were stillinto it not to the extent they are todaybut there was a lot of people playingaround and messing around and buildingapplicationsum and I chatted with a bunch of them atmeetups I had some friendsum building stuff Sam Whitmore uh shoutout to her was building an awesomeapplication and so really got to likeknow them and chat with them about theiruse casesum and basically just saw like a fewcommon kind of like abstractions thingsthat were happening factored those output those in a python package very kindof like just engineer you know Factorstuff out put it in there and put it outthereum put it out to the world and and gotuh got a positive response and so kepton adding stuff in kept on refactoringas you know the the abstractions that Ithought I first saw were of course wrongand so those kind of like evolved overtimeum but yeah basically just started offby chatting with a bunch of folks andpulling out comments distractions into apython packagebrilliant maybe so we could start withkind of maybe the first abstraction thathelped me understand link chain was kindof the sequential chains like you knowyou have the output of the languagemodel is the input to the next call tothe language model could maybe startwith describing the sequential chainsyeah absolutely I think so the the ideaof chaining is basically breaking upcalls to language models and in multiplestepsum and not only call us the languagemodels but to other things actually andso I think actually most of the examplesthat I first added were like languagemodel and then other thing and thenlanguage model and basically chainingthe results of them together in a waywhere you can you you did some iterativestuff and so to make this concrete withan example one of one of the things thatI first added was based on a paper byoffer press self ask with search sobasically you'd ask a question and andthe examples in this paper were kind oflike multi-hop questions so it wasn'tjust like a simple answer and these arecases where language models are known tokind of like not perform Super wellum and so the self ask with searchParadigm is you first kind of like thinkabout what intermediate questions youneed to answer soI think like uh the the the example usedin the paper is like what is thehometown of the current U.S openchampion and so like if we're if we'rethinking about that intuitively likewhat would we do as humans first we'dthink about who who the current U.S openChampion isum and then would figure out where hishometown is and so basically the idea oftraining was was to break those downinto exactly those steps so the languagemodel should hopefully know that itfirst needs to think about who thecurrent U.S open Champion is figure thatout and then it needs to think aboutum where he's from and and figure thatout and uh you could do that with uh youcould do that with a single pass of alanguage model the the thing that's umthe thing that's interesting and thething that caught my attention wasbasically the idea of combining thelanguage model with Google searchbecause if you're asking about thecurrent US Open Champion the languagemodel who's trained on data up to 2021or something like that wouldn't know theinformation and so basically usinglanguage model to ask the intermediatequestion you then pass that question toa search API you get back a result andthen you basically keep on going fromthere and so the the idea of chainingthat really stuck out and this is alittle bit different than the sequentialchains that you brought up but I thinkit's uh I think it's more interesting tobe honestum so I think it's the idea of chaininglanguage models to determine to figureout what information they need to lookup getting that information from aseparate more more accurate morereliable more up-to-date source and thenplugging that back in and letting itcontinue on its merry wayoh yeah incredible and uh Bob and Irecorded our generate module podcast andBob you could hop in more on sort ofjust how you're seeing this kind of youknow language model calling the searchdatabase and you know from Google searchto webiate searchyeah it's so it's so funny that youbring it up because that's exactly whatI wanted to say because the um therewere like these two things sometimes youhave like these multiple things comingtogether right so one is exactly whenyou started with Lang Chan I was lookinginto like so what is he doing and it'slike oh I got it and then there was alsothat article that I was like when peoplesay like okay hey we can hook this up toGoogle search I was likeyou can also hook it up to a vectorsearch engine right and do this stuffwith your own data so that was why I wasso super you know I was super excitedabout uh you know about what you'reworking on um because I was like youknow this is like just a beautifulSynergy of all these things comingtogether where we really use naturallanguage to or create a change or havethe database for like you know largeamounts of um uh data and that's just Ihad the exact same I was looking at theexact same thing and when I saw hookingit up to Google search and I don'tremember Conor I think you shared thatfirst article with me but when I sawthat I was like yes that's what we cando and then everything came together andand then you started with Lang chain andwe were looking at what we could dothere it was just it was just super youknow super exciting so um I had theexact same thingand and to your point Bob like Iactually think it's I think it's moreinteresting to hook it up to yourweeviate database or your own internaldata because that's just more likeunique to you and that's more distinctto you like anyone can hook it up toGoogle Search rightum anyone can hook it up to WolframAlpha but like your your documents yourdata that are in your vector databaseyour reviate database connecting it withthat like that I think allows you tobuild like a differentiated and uniquekind of like chat bot or questionanswering or whatever kind of likeexperienceexactly and I think why it's interestingto do that with like new types of ofvector databases likeum we've hit or for that matter also uhWolfram right so it is that it has thisnatural language interface so and andwhen I recorded the the podcast with uhwith together with Conor so while we'rerecording we have not released themodule yet but when this podcast seesthe light of day it people will knowabout it right so the um is that we'removing towards aumhow should I say to to a way ofinteracting with the database not withlike precise queries and precise answerslike you need to have a keyword thatmatches in your database versus a resultthat you're getting from the databasethat must be stored in the database butwe can just you know we can just havefree associations with our database andwe can even generate different resultsbased on the tasks or the prompts thatwe're giving to our data and I thinkthat's just that that this is superexciting I'm just just talking about itand thinking about it just makes me likesuper exciting for the coming year it'sgonna be it's gonna be a cool yearyeah I think like this natural languagelayer on top of like whether it'swhether it's a vector database or astructured SQL database or amongodatabase any of that I think that'sreally like powerful and reallyinteresting because it allows likepeople who don't know SQL or don't knowhow to write graphql to interact withthese databases and soum yeah I'm really excited to see thiskind of like unlock a lot of you knownew people using using this stuff acrossa variety of these casesyeah that's something that I that Ithought was so exciting when I first sawlion chain is is how the language modelcan control the database like you justsaid with the writing the graphqlqueries out or writing the SQL querieswriting graph database queries uh so canwe talk about that kind of uhorchestration layer where you say tellthe language model hey you have like inweviate land you have this class youhave this class you have this class thisclass contains like weba blog posts thisdocumentation this is the code base andand so it like chooses which informationsource to Traverse maybe you can alsotalk about like SQL or like the Googlesearch API or just other apis like allsorts of external data sources and howthat's interface in line Jyeah I think um I'll maybe start withjust a SQL database example because Ithink that's maybe one that that mostpeople are familiar with but it's it'sthe the ideas are common across othertypes of databases whether structured orunstructured or vector or anything likethat um and I'll start with like asimple example but I think uh we'll seepretty quickly that it starts to getpretty complex okay so at the most likesimple exampleum the pipeline is basically taking anatural language query you then generaterelevant SQL and I'll come back to thatin a little bit but you generaterelevance equal you then execute thatSQL against the database you get backthe result and then you you pass that tothe language model if desired and kindof like return like a humaninterpretable answer and soum yeah like I think the example that wehave in the documentation is like youknow how many employeesum exist and so it like does like youknow uh it gets like the count of thenumber of rows in the employee table andthen returns something to the user likethere are nine employees or somethinglike thatumtouching on the first part likegenerating the relevant SQL query as youwere getting at there's a lot ofinformation that you actually need toput in to kind of uh do that correctlyso you need to you need to kind of likeput in information about all the tablesthat exist and then not only the tablesbut the columns as wellum and and if there are relationshipsbetween those columns you need to inputthose as well and so the prompt thatyou're constructing starts to get prettycomplicated already and soum you know a lot of the the value thatlane chain provides is ways to likeeasily construct these prompts and thenalso like just like see what's going onlike this is a complicated prompt I'malready describing it I already probablylost half the audience and so like I'mmaking it like really easy to see likewhat's going on and what it actuallylooks likeum okay so that's like the simple usecase but there are a lot of likecomplexities so what if there are justlike too many tables and too many rowsand or sorry too many columns in thosetables to put into the prompts becausethere are there are context kind of likewindow length what do you do thenum and so and so one another chain thatwe have in LinkedIn is basically a chainthat first select relevant tables andthen puts only those tables in theprompt and so kind of like a simple ideabut basically the idea of like filteringdownum then so that's around likeconstructing the query then after likeexecuting the query what if the query islike incorrect syntax what if it's kindof like references tables that don'texistum what do you do then so I thinkthere's there's a few things that umto be honest aren't in link chain yetthey might be by the time this getsreleased I think they're on our roadmapone is the concept of kind of likeoutput parsing or validators orguardrail so like validating that thingsare valid uh SQL syntax and stuff likethatum another idea is basically the idea ofkind of like if it tries and it failsjust like passing that back to thelanguage model and letting it learn fromits mistakes there's a really goodexample of this workingum from Riley Good Sideum with uh not with SQL but with like apython example where he asked it to do amath problem it tries to use like themath module but it's not imported and soif you allow it to kind of like correctits errors it will see like import errormath not recognized and then it willkind of like fix it the next time aroundand so I think like things like that forfor SQL for any type of databasequerying will be will be important aswellumyeah so I I think that's an overview ofkind of like what's in LinkedIncurrently and like stuff that we want toadd because yeah it gets a littlecomplex a little quicklyjust out of out of curiosity to build ontop of that price IDum uh because the focus now is mostlythat you have like um language rightLang chain how do you what do you thinkwhen it comes to like these uhmulti-model kind of models right so howwhat do you think will happen there andhow will link potentially evolve withthese kinds of uh models but or do youhave any thoughts on thatyeah yeah no that's a really goodquestion I think um okay so at at thesimple uh the simple answer is there'sbasically kind of like Integrations wecan already do and they're actuallyalready rprs for thisum to kind of like hook up kind of likemultimodal things on either end of thelanguage model so for example liketaking audio file transcribe it generategenerate some stuffum generate some textum that's you know done by kind of likeconverting it into the text domain soum yeah so in that's in that sense it'ssomewhat multimodal but it's not likefully multimodal another example of thiskind of like quasi thing is like hookingit up to an image API or something so sothere is a PR open to basically have achain that first like uh takes in uh youknow like because all the image promptsare like really convoluted like that'slike that's like Wizardry right there sotake in kind of like a simpler querygenerate a more convoluted prompt passit to dolly or something get back animageum so in that sense um I think there'salready there there will shortly be kindof like multimodal support in link chainmore and more involved than thathonestly I I don't knowum at the momentum I think I know there have been a lotof uh more kind of like uhfirst class multimodal models coming outand so I think we need to look a littlebit more carefully about how tointegrate thoseyeah so the the thinking is like youwould have an image captioning modelthat parses the image into text and thenit just easily flows into the textinterface of the judge Epsom most likeyeah that's that's kind of how we'reimagining things uh that would beeasiest for the current kind of likeconstruction of LinkedIn for sure and soI think that's what we'll do first yeahI think that's such an exciting emergingthing of the um you know like the themultimodal chat gbt style large Visionlanguage model I think that isdefinitely on the horizon I would if Ihad to take a guess I'd say that'swithin three months yeah I hope so I'mexcited to play around with it I thinkum I think character AI has done somelike multimodal stuff as well I thinkthey have some multimodal chat Botsum so yeah excited to see it morewidespread oh I just really say yeah Isaw it like deep mines Flamingo atnerups is is that alreadyyeah so I just it's like by matter oflike a thought experiment so the otherday I was thinking about the followingright sowhat I noticed and it's something we weare doing also with wifiate and maybethat's also happening for like whatyou're working on Harrison is thatum I was thinking we somehow we tried tocapture these things in like atraditional way of a software engineerright so we say okay how do we write thetechnology to you know and then we getstuff back and we get this complexchange in your case or in our case likehow will we represent the data I must ifwe just think about liketwo three years from now could it be thecase that we're just interact with likesoftware completely different because ofthese LMS and what we're doing today soto give you a very pragmatic examplethe first time I interacted with agenerative model so quite some time agoI needed to get used to the fact that Iwas not writing software so that I justcould use natural language to give it anassignment that felt so unnatural to meright so I'm just curious actually bothof you how you guys see this because I'mI just I have like a feeling that we'restill trying toshoehorn this into a traditional way ofwriting software but that maybe in likea year two years from now that's just acompletely different Paradigm in how wecreate technology and or how we interactwith the database or how we changethings together I'm I'm just curiouswhat you guys think about that if youjust you know kind of dream into thefuture what this might look like yeah II thinkumI mean it's a really good question rightlike that's like I think that you askfor all these thingsum is kind of like what people aretalking about I don't have any I don'thave any great answers I think like onething that umI mean kind of like in the vein of likeand this is a bit more on the likedeveloper side of things but on like thevein of like multimodal stuff like Ithink like you know right now a lot ofthe stuff that we're like when we'retalking about ingesting data right forlike PDFs like right now we'retransforming a PDF into like some textand then maybe like embedding that textor something like that or transformingyeah doing like a caption on image andembedding that caption or something likethat I think a lot of stuff will movetowards just being like talking to eachother in like embedding space basicallyum and translate in between thatum but yeah that that's kind of a littlebit separate than what you were asking Idon't yeah I don't um I mean okay sohere's what here's what I'll say aroundlike the ux of actual products I thinkthey'll start to be like look at copilotlike why does copilot like work as kindof like a productum it works because it's in a situationwhere you don't need 100 accuracyum there's a human in the loopumand uhyeah it's a bit it's it's kind of likeworking with you and so I think like youknow the the common thing for productshas been like co-pilot for X co-pilotfor x and I think like the importantpart is like it's people are stillgetting used to working with theselanguage models the language modelsstill aren't at like 99 accuracy or evenclose to that so you need kind of thishuman in the loop and this likesituations where it's okay to have loweraccuracy I think we'll start I think aslanguage models get better and we getmore familiar we'll start to go we'llstart to see more applications wherethere's less human in the loop andthey're more automatedum and they're in situations where youcan have like higher accuracy uh or orsorry yeah where where where yeah whereyou can get a higher accuracy where youneed higher accuracy and it starts tounlock thatum soyeah you know I don't have any greatinsights as to what the future will looklike but I think that is like one kindof like natural progression that thatwe'll seewe'll see yeah exactly because I I wasalso thinking about this and I I wastrying to think back of like the how wecould like the origins of it and Iremember that I had like this 50 momentswhen I was at a conference and peoplewere talking about the semantic web andthat I was like that some people in theaudience were like annoyed because wehumans couldn't agree on stuff right sohow we were structuring the data andthat this whole thing of these languagemodels not even large language but justlanguage models in general right backthen it was just Cloud pasta Etc thatpeople started to think about what if wedon't have to do that anymoreand I think if you now for example fastforward to today so for example let'ssay that uh Conor and and I that werelike we're working on a piece of coderight and I make a mistakes hey Connorit's not what what mistake didn't makeand Connor looks at it says oh youforgot like a summer column or somethingthat I could imagine that we're movingtowards the space where you have you'realmost running like pseudo code but atthe model says Oh no I got you I knowwhat you want to do I'll just execute itright I I see where you're going and Iwould not be surprised that that wouldjust get to a to a natural languagestate of of programming which of coursewill come with with certain rules andand and certainum uh ux elementsum I I was I I was listening to apodcast from from uh um the open uhwhat's the name the open source datapodcast from Sam ramji and he wasinterviewing bandorka and then Ben alsosaid like how will we get the rigor ofsoftware engineeringinto working with these language modelsand I find that it's super interestingbecause if we're if we and then we likeuh they had a Humanity we'll figure outhow to do that then it will becomeeasier for people to interact with thesemodels but also write technologysoftware right so you just describe whatyou want and the model helps you todeploy it to develop it I would not besurprised that we will see things basedon also what you're working on uh thatthat data will be like uh deploy acomplex uh infrastructure by justdescribing it in natural language andthen the model figures out oh then Ineed to spin up a pot here and I need todo this over there and those kind ofthings right or or design that you justhave visual design you just describe itand it was like okay gotcha and it justfigures that out so I I really hope thatit also lowers the barrier for even morepeople to just write so far and justcreate cool things and and I would notbe surprising like a year two years nowwe just we're slowly moving towardswell a natural language way ofdescribing what we want the machines todo and then they just in combinationwith this model they just figure it outand just do ityeah and I think there's been a lot oftalk around like you know promptengineering like it is promptengineering here to last like my take isit will kind of like converge to likewhat you're describing like just as youwould tell a human how to do somethingyou'll have to tell the language modelhow to do something and so this to yourpoint around this natural languageinterface for doing somethingum like yeah I think that's prettyrealistic that that we can get thereno yeah that kind of like um I I think Ireally like the example that Harrisonbrought earlier quickly I want to comeback to that about like with the SQLcode how you check if it's correct kindof and it makes you like I'm so excitedabout this idea of like the languagemodel would write code to runexperiments like run the experiments andthen analyze the experiments could maybekind of Step into the technical and likehow will it this look how will it checkthe correctness and then flow in thelength chain uh syntaxyeah and I mean I mean copilot had areally cool demo of this at one of theMicrosoft conferences where they askedit to write a problem and then it kindof like it it they ran it you could seethe output it realized that the outputit wasn't even that I don't think it raninto any like compile issues orsomething it ran successfully but theoutput was just like nonsensical and soit like logically reasoned that theremust be a mistake somewhere in like theprogramum so I I don't know how I actuallydon't know how kind of like co-pilot didthat but I would imagine the way that umI think like uhI think the best wayI think hard coding like oh check iferror check this I think that is uh isis doomed for failure because I thinkthat's just you're gonna run into toomany educations and so I think actuallythe the right way to go about this andthe way that people will go about thisin in the future is basically lettingthe basically telling the language modelthat it can take these actions it canwrite code it can run code it canobserve output of code or I guess in thecase of SQL you know it can write SQL itcan run SQL it can observe the output ofSQL it canum check SQL query or something likethat and then basically let it determinelike what actions it should take sofirst you should write some code then itshould run the code then it needs tolook at the output and and thendetermines okay do I need to like editthe code do I need to run it again do Ican I return it to the user and sobasically like yeah I think the controlflow will kind of like be determined bythe language model but then it just hasaccess to all these like tools oractions whatever you want to call themwhere it can do certain things but it'snot hard it's not hard it's like it'snot hard coded that like you do thisthen you do this then you do this I justthink that will not enable the types oflike umyeah the types of experiences that areneeded for these more kind of likecomplex workflowsyeah because I think what Bob was sayingearlier with the idea of you spin up apod and it knows how to monitor theproduction app and like I haven'tlearned to I haven't didn't know toomuch about this until I joined weave andgot under the curtain and saw otherthings that happen and it's like thatidea of you know the language modelkeeping the software running with allthe errors that come up that is justamazing I thinkyeah exactly and to build on top of thatso I'm just curious to see if it will goto a world where so as you're describingit Harrison I think that will of coursebe like the the short term not eventomorrow like right now like we wedescribe something what we see with goldfighter we describe a problem it outputsSQL and then it gets whatever it needsfrom the database right but I wouldn'tbe surprised if we're gonna skip thatmiddle Step at some point so let's takewe've hit as an example there's noreason why we've had couldn't have likea SQL interface we we don't have thatbut you could theoretically have thatthat if you just have like the situationwhere it's like okay we have like thisis how the embeddings are encoded ondisk or in memory and those kind ofthings and then the model just knowswhere to get it and um that we get justnew systems that we justinteract with them based on that it justknows where the information is and itjust figures that out by just telling itin the prompt right so it literallyprompt engineering like this is how thedatabase is structured this is how westore the vectors and and the data in inmemory or on disk do your thing rightand I I wouldn't be surprised if you seeI mean not tomorrow but like I would besurprised if very soon we will see thefirst maybe research or blog post andpeople experimenting with this so justto cut out the middleman basically wherethe middleman is theumum the the interface language like rightlike SQL or those kind of because theproblem is that these um theseinterfaces they force us to be extremelyhyper structured which is understandableand which is great for many use casesbut what if you can just skip that alltogether because the way that we're nowinterfacing with each other right I I'mnot I'm not formatting my questions ormy remarks in a certain way then I golike okay I hope that Conor can parsewhat I'm saying right now right I justuse language and then and then it justyou know and I I really hope that thatis where we where we can go based onthese these embedding based and languagemodel based approaches that's I meanit's a little bit further in the futurebut I I really hope that we can getthere and you know with all these toolsand what everybody's working onyeah so Harrison can I ask about some ofthe prompts that you like the most likemaybe like let's think step by step theidea of um you are the writer you arethe editor you are the reviewer rightlike like have any of these promptsreally stood out to you as being reallyinterestingyeah I I think the ones that are mostinteresting to me are the ones that umare good are basically good atinteracting with arbitrary external kindof liketoolsum and so what I mean by that is likeum so okay interacting with likeexternal tools and thinking about how tolike reason with tools there's a reallygood paper called react which is likesynthesizing reasoning and acting andbasically it combines kind of like someof theum Chain of Thought stuff which is whereyou kind of like ask the language modelto kind of like think slowly about whatit you basically tell it to thinkum which sounds silly um but you tell itto thinkum and then and then acting is like uhdetermining kind of like what action totake and what and and what action andwhat input to that kind of like actionor tool to beum and so combining them it it kind ofit you know I think the paper showedsome pretty nice gains and a bunch ofbenchmarks and stuff like thatum so that so that type of prompting isreally interesting to me because I thinkhaving the language model act as kind oflike a conductor that can interact withthings is is very powerful and so anytype of prompting that enables that Ireally like now taking like the zeroshot kind of like thing to that so theoriginal paper kind of like hard-coded abunch of few shot examples so they gaveit a bunch of videos I think like theoriginal in the original paper one ofthe examples was interacting with likethe Wikipedia client and so it could dolike a search it could do like a lookupI think those were the two actions itcould do it gave a bunch of examples ofuh doing those actions and then itlearned from those examplesum and so to the point earlier aboutlike prompt engineering kind of goingthe way of you just tell it what to dolike I think the way that it will be inthe future is you won't necessarily haveto give it those examples you can justtell it like this is what you can do andso the zero shot way of interacting withtools is exactly that there's noexamples you just kind of say Hey youhave access to this tool it's calledsearch it takes as input a string andwhat it does is it look and you shoulduse it for like current events and stufflike that and then you you do that withhowever many tools you have and it kindof just like learns to use them in azero shot wayum and and the the the react promptingis is really powerful for this becauseit lets like think about like you knowall the information it has like the toolname and the tool description and stufflike that and I find this really cooland I think like um yeah one it likeworks surprisingly well just out of theboxum and then the other like really funthing is that if it's not working it'skind of easy to tweak by just likechanging the description of the tool soone of the common questions I get askedis like how can I like you know it'susing this tool incorrectly or like howcan I get it to use this tool in thisspecific scenario and it sounds stupidbut the answer is you just tell it tolike you just tell the language modellike use this when you have a questionabout math use this when you have aquestion about music and and it'sgenerally pretty good at like observingthat and following those instructionsum and so that type of like zero shotreact prompting is that's that's by farthe most interesting stuff to me I thinkvery exciting very exciting I just Ijust want to highlight one more timethat when you said like you just tell ittoo that is just how far we got like inlike just think about two years agorightit's that is just that that one sentencethere you just tell it that was like howexciting that is I I love thatyep yeah all in in all the papersum you know a lot of the papers thatcame out in this were from like a I meanyeah even like a year ago when youneeded few shot examples and youcouldn't just tell it to and you had todo this like really elaborate promptengineering and now you just kind oflike tell it to and there's still likeagain like I don't think this I don'tthink this means that there's no needfor prompt engineering like you stillhave to like figure out how to like youstill have to construct The Prompt in acertain way and you still have to tellit like what scenarios it's good for andstuff like thatum but it's a lot easier too and it'sjust like it's more similar justchatting with a human and instructingthe humanyeah I think maybe playing the devil'sadvocate here I think kind of the youjust tell it too is maybe like I thinkthe whole thing about prompt engineeringis that there is a little bit of an artto telling it right like and so I'mreally curious about this intersectionbetween like you could sample manydecodings from the large language modelthat temperature thing being like thekey knob that you can slide maybefirstly just set the stage what do youthink about that temperature parameteron the large language modelsI think um if I'm so I think there's twodifferent like ways to use languagemodels I would say one is likeleveraging their like reasoning abilityum and their ability to like you knowyeah take ambiguity and and this anddecipher and decide what to do and thiscomes into a lot of the action stuff andthen the other is generating text rightgenerating Pros generating poems so forthe latter for like generating text yeahcrank the temperature up like get somelike funky responses go for it but forlike the part where you want to likereason about things I almost always setlike temperature to zero and justbecause you want the single kind of likeyou want the best most accurate responseyeah that's it's interesting that yousay that because the what we're alsoseeing with the database right so andand um Conor and I coincidentallyearlier today had a conversation aboutthat that what I really believe is likeyou have like the the reasoning aspectof the modeland then in our case also the databaseright so appreciate that you can sayokay we're gonna literally in frontengineering you tell it like we're gonnagive you information in this format andyou must base your answer on theinformation and we're giving it and ifyou can't tell us you can't and thentemperature all the way to zero you knowwhat I mean and and I and I find it veryinteresting because what that means isthat you're kind of cutting out and I'mrecording it the knowledgethat is in the model but you keep it tothe language understanding like as ifyou have like a human who justunderstands everything you're saying buthas no knowledge and has like an old setof you know encyclopedias and then yougo like okaywhat's the distance from Earth to theMoon and okay let I understand thequestion let me find that in the in theencyclopedia and uh I find that that Ifind that very intriguing and I'mcurious I have a question for you aboutthis Harrison soum they're like two camps right that wesee like one is like we're gonna keepfine-tuning the modeluntil it has all the knowledge right forwhatever use case we haveor we're gonna just keep that separationthat we say like these um we have themodel and we just feed it withum uh with data coming from a datasource I'm just I'm just curious whereum uh I mean I have strong opinions onthis but I'm very curious where you siton uh on this uh no this this this thisain't you know what your angle is whatyour take is on these these approachesyeah I mean I I think there's a honestlyI think there's like a place in time forbothum I don't think that one's kind of likestrictly better than the other I thinkthe one that's more interesting to me iskind of like the one that you combinewith external data I think um but likeyou know if we think about if we thinkabout that language model is kind oflike acting as a decision maker or arouter one of the things that it couldroute to is a larger language model thatis trained on everything and it couldcall that like when it needs toum but yeah I think like um I think theidea of well okay so yeah the idea offine-tuning on everything and alwaystrying to make sure the language modelis up to date I'm not very bullish onthat I do think there's a place for likegeneral purpose language models but as Isaid I'd rather use that as like a toolrather than trying to like have that bethe sole source of everythingum and and then yeah like combining datawith language models I think there'syeah there's I mean even today you cando that with prompt engineering there'ssome like really interesting papers onlike um kind of like ways to do it at amore kind of like ummore native to the model so where you'reactually attending over embeddings ofdocuments that you pull so like retrostyle approachesum I don't think there are any greatpublicly available models for that yetbut that that might be something thatcomes out in the next year or two thatwould be really interestingum and then yeah the the idea of havinglike umthe language model act as a router onething that I I like I would love to havelike a fine-tuned model that's justreally good at zero shot kind of likerouting and reasoningum and I'm actually chatting with a fewFolks by this so I don't know when thisis coming out so it's possible that whenthis comes out we'll we'll have somelike uh yeah we'll we'll have alreadyshared some stuff about that but like Ithink I think creating that like smallfine-tuned model really good at zeroshot reasoning would be really reallycoolum and so yeah that's kind of the that'sthe type of fine tuning that I'minterested in I'm not interested in kindof like the fine-tuning to make it kindof like up to date with every possibleinformation that's under the sun I'mmore interested in kind of like the finetuning to have it do routing to othersources of informationyeah I like that very much so I'm I Ihave a very similar uh point of view soI would not be surprised if we're gonnasee these kind of models that are justthat indeed are like good at likegeneral purpose things like an llm formedical terminology in LM for legalterminology in LM for engineering thosekind of things but that it is very goodat just processing basically theseOne-Shot approach right that youmentioned that it just it understandslike for like other terms of theunderstands it can help you reason whatkind of data that it needs to get fromin this case a database or any datasource that you can tell it's I'm it'sinteresting to say that because I have avery similar point of view yeahyeah I think I'm I I used to really likethis idea of like you would maybe havesome kind of classifier that classifiesthe model in the hugging face model Hubthat's the best for this task but uh soso what will this all these largelanguage models the lawyer thebiomedical language model how do you seelike how will that be organizedfirst of all I don't think anyone knowswhich makes this so excitingum I thinkum yeah I mean like I don't know rightnow the the private models are waybetter than the open source models likeum I think it's yeah like you know GPTgpt3 is way better than than the bestopen source models probably flon T5um anthropic when they come out withtheir model it'll probably be prettygoodum I think there you know it's like umI I it's possible that there it'spossible there will be a better opensource model release it's possible thatto your point around like having a modelspecifically for medical or specificallyfor law maybe you can get that byfine-tuning font T5 and it's and it'sless about kind of like you know maybefor like smaller more narrow things likethat actually definitely for small forsmaller narrow things you can probablyget just as good performance by finetuning font T5 or something like thatfirst like it kind of just depends onlike what small and narrow is right likeis law like small and narrow I wouldargue it's still kind of like big andand and and out there but it'sdefinitely smaller than like every pieceof knowledge on the Sun soum yeah I don't know I mean I guess mycurrent guess would be that they'll belike the the private models will be thebest general purpose ones the opensource models will be fine for smallsmaller tasks and I think probably overtime like thelikethe the open source models will startcatching up and at the same time theprivate models will keep on gettingbetter and better so I think they'llalways be this Gap it will just becomelike you know what's in this Gap is isthe real value in this Gap or is thereal value now doable with like smallerfine-tuned models and and I don't Idon't I don't know I don't know how fastthose will move up a lot a lot ofquestionsyeah actually now when you when you putit like that I'll take back what I saidbefore so just I hope you can cut thatout to comment I'm joking but the butthe um it just let one model it's justone model to uh to roll them all andthen maybe a few different providerswith different you know for theeducation I don't know but uhum yeah so this is what I meant likewhat I said it's like it's like thistraditional mindset right so you knowit's like you have different programminglanguages for different tasks but likewhy not why not one one model that doesit does make senseyeah I think the counter argument tothat though would be like right now theinference is kind of expensive likecompared to if I train like anextractive QA model on my documentationlike it you know I could even sparsifythe question answering model it maybe isonly like 80 million parameters and soit's just super fast that would be kindof my counter argument to like thesmaller fine-tuned models for certaintasks like in the search pipeline likethe re-rank all right like I see a lotof tweets that are like oh you can usethe large language model to re-rank andI'm like what a waste of the large butlike to re-rank it's like kind of a I Ithink the Paradigm and and there's agood quote from uh Stan from dust and soI'm going to shamelessly steal it herebut he has a great quote that's likeum no gpus before pmf which is basicallylike no gpus no fine-tuning modelsbefore pmf product Market fit before youknow what you're doing and I think likeum the power of large language models isthat they're so good at just likearbitrary tasks and you can get them todo like basically whatever and soexperimenting with like differentdifferent pipelines or different thingsthat you're doing is really it's it's somuch easier than before and so I thinkthe common thing will basically be likeyou know experiment with the best modelsthen when you actually get somethingthat's like working and you want toscale it up not even that's like whatlike when it's working and it's just foryou it's probably fine but when you wantto like scale it up then you need toworry about like fine-tuning models andso I think it's also kind of like aprogression as well like you know if Iif I was building an application I wouldnever start with a fine I would neverstart with fine-tuning no I'd start withthe the language model and then when Ior I'd start with uh the biggestlanguage model gpt3 or something likethatand then whenum yeah when when when I get to thepoint where I have enough confidencethat I need to scale it up then I'dstart thinking about that and I thinkthat'll be like a pretty common workflowand I'm I've already seen a few peoplein yeah I've already seen a few peoplelike doing that it's um it's not thatcrazy right soso I just want to say that's very that'svery interesting and especially withwhat you said with cmap right withproduct marks because it's like there'sthis Tipping Point of life with themodels being the general first modelsare good enough to solve the task rightso it just and we're just we're hittingthat Tipping Point I found itfascinating to what we saw the last fewweeks the discussions on Twitter andwhat have you and in newspapers I wasjust sitting on the sides eating popcornwhile I was watching it right of seeinglike core research but also like productpeople working in this space how theylook at this very differently right soit's like uh and I think I think um thatis for from me in my profession one ofthe breakthroughs of 10 GPT was not onlyusing the model to do it but also thepackaging like the it's it's so simpleif you think about it but it's so wellexecuted andum and that kind of ties into what youwere saying uh Harrison that it's it isit where to just we're just past theTipping Point that where you can buildamazing stuff like for example uh takingLang chain right and solve your problemor store your data and weed it andfactorize it just and just startsearching and doing whatever you want todo that just that is just that haschanged in the last year as opposed to ayear before and that is also why I saidearlier like I'll take back my what Isays like maybe it's just gonna be likeone model right or just a handful ofmodels that are just good enoughyeah awesome so I kind of want to Pivottopics and um you know and ask Harrisona question about sort of the virality ofLang chain and the open sourceengagement has been something that'sreally been impressive and so I justwant to ask kind of like like how likethe question like how did you do thishow did you start the fire likeobviously you're a really smart guy andthe idea sticks like crazy but yeah likewhat are your thoughts on that yeah Imean I think like umI think like uhhonestly I mean one it's just been likeso much fun and I think like that's thething with like all these things I thinkBob was saying like it's super easy tolike create these things like it's justso much fun and people have fun buildingthese things and I have fun buildingthese things and so it's just like I Idon't know there's umyeah like I I think there's just athere's there's a lot of like energy andaspect of fun and just like buildingthings and exploring and so I don'tthink like um yeah like I I think umyeah like like yeah I don't think I Ihaven't done anything like in particularit's just been like a lot of fun I thinklike yeah I mean like the you know thethe the two things that I try to focuson besides just having fun although theyare like very related are like buildlike actually useful thingsum and then like be nice as well like Ithink like and that gets back into likehaving fun right like I think like therereally is just like everyone's like thisis a great time to be hacking on likeideas and being exploring ideas rightthis is a phenomenal point in like uhyou know yeah like I'm not that old butlike this is by far the best point in mylifetime for like exploring these typesof ideas and so and I think a lot ofpeople realize that and I think a lot ofpeople are out there doing that and sojust like trying to build things thatare actually useful for them and thenlike you know likebe nice and having fun with people asthey're doing it like I think you know Iyeah no no that's that's all I reallygot soyeah that's incredible and I think justlike that yeah exactly like thecontagiousness of sharing um this promptsequence created this is yeah and the itis really truly amazing um so I'm kindof curious to see like the Lang chainHub uh so what are kind of thedirections that you're thinking oftaking Lane chinayeah I mean I think like the to yourpoint around basically like sharing thisprompt sequence sharing that's exactlywhat link chain Hub is is designed to doum I think we put something out reallyquickly in like a GitHub repo where it'sjust a collection of kind of like chainsand agents and prompts that that you caneasily load and prompts you can't reallyuse by themselves but like chains andagents you can just easily load and useby themselvesum and I think the despite it being aterrible ux as it like you know GitHubrepos are great don't get me wrong butthey're not meant for like sharing anddiscoverability and stuffum and soum like within a particular GitHub reposo despite that terrible ux like I thinkwe saw a lot of people really interestedin it and so I think that's somethingthat where you know and I think likelike why are people interested in thisbecause likethere there's just so many differentthings that you can do with them and andso like having them like and and againgoing back to like the just like hackingand building and playing around likethere's definitely that type of likeatmosphere and a big part of that islike sharing your work and and sothey're like not just Lane changes opensource but a lot of other really awesomeprojects built on top of it are opensource and so like the idea of likesharingum I think people really enjoy and likein in lynching Hub is really just aimedat making it um easy to share your yourchange your agents your prompts stufflike that yeah so maybe uh yeah like thethe open source thing is reallyfascinating like the um how has kind ofthe maintenance been of it as because Iunderstand how like how many are you thesole maintainer or how does that kind ofthing happen yeah so there's one otherperson working on it full time with methe maintenance costs have definitelygone up I'm not gonna lie I thinkthere's like yeah I think there's like110 GitHub issues and like 43 open PRSso gotta catch up on that a little bitfor sureum but on honestly like I think it'sbeen um but likebut but it's been like fun like it'sit's like all the things that people areadding are likeum you know like people are adding likedifferent uh different kinds of likeembedding modules different types of ofmodel providers like there's like that Ihadn't even heard about but like now I'mlike okay I gotta go check that out likedifferent types of likeum Vector stories different types ofchains different types of of tools tolike interact with and so I think likeum even though there's a lot of issues Imean and someone like opened up a PR forlike some of like the image stuff rightso it's likeum I don't know like even though there'sa bunch of stuffum and and there's a little bit of abacklog which I need to I need to fixright after thisum but uh yeah it hasn't been like toolaborious to kind of like keep up withor anything like that awesome wellfantastic Harrison I'll let you get backto it uh I thought this was such anincredible such an incredible podcast Imean yeah the the sequential change isthe first thing that just helped meinstantly get it so if listeners are outthere wondering checking my chain outfor the first time you know thesequential chain of how you chaintogether multiple language model callsone to the weeviate vector database andyeah I think it's just such afascinating library and seeing it emergeso Harrison thank you so much for yourtime and joining the weba podcast nothank you guys for having me and yeahjust uh I don't know if people listeningto this realize but like we V8 and youin particular Connor reached out superearly on in the link chain Journey likeI don't like it was it was uh yeah likeI uh yeah that was a while ago and it'sbeen awesome to kind of like work withyou guys and and kind of like I think weboth see the world in like similar waysand and there's a lot like I thinkVector stores and are like for a lot ofapplications are like a criticalenabling piece and so it's been awesometo to work with you guys and and chatabout stuff and so yeah thanks forthanks for having me on always alwayshappy to belike yeah thank you it's super excitingand you know we're you know here to helpeach other because it's just a whole newecosystem that's like it's like asupernova like you know thanks to theseLMS and like this whole new ecosystemand would just I I think we we need tohelp each other right to to reach ourgoals and this is just yeah this issuper exciting", "type": "Video", "name": "LangChain and Weaviate with Harrison Chase and Bob van Luijt - Weaviate Podcast #36", "path": "", "link": "https://www.youtube.com/watch?v=lhby7Ql7hbk", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}