{"text": "Arvind Neelakantan, Research Lead at Open AI, talks with Connor Shorten about their newly released embeddings API, his work ... \nhey everyone thank you so much forchecking out the wva podcast we have areally special episode today with arvinnila kontan a research scientist atopenai this is such an interestingtiming with this because openai has justlaunched their embeddings api which hasbeen integrated with we v8 in version0.10 so you can access the embeddingsapi and plug it right into wev8's vectorsearch database to enable all these coolapplications with these deep learningpowered representations of unstructureddata like text and code with these withthe latest models so first of all arvindthank you so much for coming on thispodcastthank you thanks for having me i'm superexcited to be hereand i'm so excited to get into all thesetopics uh i think your career in deeplearning science is so exciting and ilove uh you know reading thesepublications and kind of seeing yourline of thinking with these things so tokind of kick things off can you tell meabout what's new with the embeddings apisure umsowe've had the uh open ai apito be usedfor more than a year now uh we startedoff with uh general models for text uhmoved to code um so the new uh so we nowhave aa new uh api endpoint uh that canconvert uh text and code to to to avectoruh and uh wewe have models that are fairly generalpurpose so you can use these vectorrepresentations for many downstreamtasks uh like clustering classificationtext search code search and so onso i'm really curious about in yourresearch career what drew your interestinto these contrastive learning methodswas it these say recent computer visionpapers like simclear moco and say theeffectiveness of data augmentation toform these pairings what kind of firstgrabbed your interest into wanting toreally explore contrastive learningsure uh yeah i mean those had someimpact for surei think uhthe bigger one is uhwhen we put out the api uhum people were started to start to useit for search um so they would use umyou know uh concatenation of the queryin the document get the log prop fromthe language model uh and this was likea very high quality relevant score thatwas very general purposeumbut that clearly does not scale uh to tomany documents um so that was likeone of the big reasons why i startedthinking about this problem uh and alsolike if you follow like ifyou've been following like kind of theresearch communitywork on like search umkind of like the modern neural networkmodels uhdon't really work that well out ofdomain for text search if you have alarge label data set uh then theembedding methods work quite well umbut uh there were not really goodsolutions that are there are generalpurpose and work across a broad set ofbenchmarks uh and like keyword search uhwith bm25 was was like uh was like areally hard baseline uh to be um uh forlike unsupervised searchso what's thesay newest thing in the text embeddingsis it the contrastive learning lossfunction compared to maybe in the pastwhere you try to say label uh i know innatural language inference they try tolabel them asentailment or contradiction and thencore question pairs you had similaritylabeling so is that contrastive lossfunction is that the big thing that'spowering the new advancesyeah there are a few things umi think like one thing uh had to startwith is uhlikewithin like text embeddings umthere was liketwo uh research topicsone for learning embeddings forclassification tasks and sentencesimilarity tasks and then there was aseparate research topic around learningembeddings for such anduhit it felt like alittle bit likenot the most optimal route uh given thatyou know both areuh going after the goal of getting highquality text embeddings soso we kind of likewanted to take the shot of like can weget like anunsupervised model to produce embeddingsthat works well across ussoyeah i would say like the the reasonuhwhy our models i think are working wellis um you know mix of like large-scaleunsupervised training uh initializinginitializing with good generative modelsum and like uh and then also uhcontrastive loss with uh you knowsufficiently large batch size yeah thosethreei think things put togetherare are giving us pretty good uhembeddings yeah it's so interesting thatthe self-supervised learning frommassive internet scale data has enabledthis zero shot generalization that maybesupervised learning wasnever gonna going to achieve was thatwas that always obvious to you from theearly beginning of self-supervisedlearning or you may be hesitant on thatidea ah no i mean it was clearly i meanuhthe potential waswas clear uh that you know there's justlikeway moreunsupervised data uhandso the the potential is always therewhether it's gonna work out is you knowit's always a research question that youyou know gradually build up anduh see if things are going to work umi meanit was also like a problem that had tobe solved umif you look at like supervised modelsthey do work on a particular data setbut then they're very brittlewhen you test them out of domain uhthey're not robustyou know the adversarial attacks onunsupervised models uh you know is likesuper well studied uh you know both inlanguage and other uh application areasso yeah it kind of like uh felt likeyou know supervised unsupervisedlearning uh isis really important uh and had to bestudied yeahyeah so we've been learning about uh thedifferent use cases people are buildingwith the we va vector search engine theyhave such uh diverse data domains thatyeah that idea of that zero shotflexibility is such an interesting partsoare you uh with your latest thinkingabout the idea that you can have anoff-the-shelf model that covers all datadomains do you think you still maybeneed tocut it up a little bit like say this isthe biomedical bur this or like a burpbeing like the typical acronym whenyou're doing this thing where you putdata domain and thenbertto describe itso do you think you still kind of needlike computer science paper news burt orare we really about to hit this pointwhere you just have thisone uh thing for general representationsthat's definitely the goal uh i meanlike uh if you look at the paper uh kindof uhum you know we tookuh like like the the the central themein the paper was to take oneunsupervised embedding model andevaluate it on like uh i think weevaluate on like some 15 search datasetsuh seven classification data setsand then like uh six or seven moresentence similarity data sets and youknow we use the same embedding modeluh i think there's something to be saidaboutuh if a modelcan work well on alarge number of tasks uhi think it's it's uh indicating that itis uh robust uh which i think reallyreally matters in the real worldumso yeahwe do hope thatwe can haveyou knowmost of the heavy lifting at least mostof the heavy lifting done by a singlemodel maybe you need a little bit of uhfine tuning for your domain but not toomuch so one thing i really want to getinto as well is the um the largeembedding sizes and kind of the ideas ofhow how much embedding sizes you havebut quickly before getting into that andand we're going to later on in thepodcast talk about this idea ofprompting but i really want to get intothis idea of the impact of datapre-processing and i'veseen things like you know you have toavoid new lines and that kind of thingwhat's kind of the story behind the datapre-processing for testing thisembeddings api out yeah i i i it's inthe it's in the documentation uhit's basically we use slash in as adelimiter uhfor uh for like knowing whethersomething is a query or a document so itjust kind ofuh it was like you know in in thehindsight it's like it was like a badchoice as a delimiter uh but basicallythat's the reason why like if the textalso has slash in it can kind of mess upthe model uhuh yeahbut that's about it i don't thinkthere's otherpre-processing things you'd have to dothat's kind of a tricky step right withthe um with the delimiters on the linesand uh internet scale text scrapes doyou maybe like the idea of using thehtml tags i've seen that idea coming upand where you maybe useline break or paragraph break and kindof have the structured data in theunstructured datayeah yeah i mean our hope is we can likeget rid of uh the delimiters uh alltogether in the next one uhi i think if this was likeyou know getting the model to to uh toinitially get good results we kind ofumwanted to try out a lot of things andthis was one of the thing that thatstuck uhbut yeah we actually think we can getrid of the delimiters all together inthe next run and you know uheven the slash and pre-processingwouldn't be requiredso you prefer the idea of having a superlong sequence left to rightyeah that's really interesting and sothe structure of the breaking probablynot worth the timei mean yeah yeah it's basically you knowthe model can handle that yeahso on the topic of say the um 12 000dimensional vectors and i think that hassuch an interesting play and uh anddescribing say using pca to try to takedown the the size of it and then thingslike say you build up one of thesevector indexes like we like to talkabout the h and s w algorithm onweavgate and if you've got 12 000dimensions in each of the vectors itmakes it a little tougher uh we've alsolooked into say binary passage retrievalwhere you can have some kind ofoptimization where you learn how to havea one zero one zero representation howimportant do you think these highdimensional representations are to alsoachieving this off the shelf any datadomain zero shot flexibilityyeahsoso if you look at the results in thepaper umwe do uh report results for likeembedding dimensions from thousand to uhyou know the largest one twelve thousanduhyou can like cut it by half uh or morethan half i think even the 4kdimensional vector oneuhyou know it performs really well umsoyeah if you want the absolute bestperformance uhuh the twelve thousand one uhwould would uh would be the one to pickuh and it is definitely uhuh you knowvaluable uh for certain applicationsthat care about the the you know thelast uh few pointsfor for other ones you know uheven the uhthe four thousand dimensional or the twothousand dimensional one already haspretty good uh transfer transferperformance on search and classificationyeah i think that's such an interestingpart of it is the uh dimensionality andhow much that kind of makes it cost torun it and things like that can you tellme a little bit more about theevaluation of embeddings and yourgeneral thoughts on sayusing the embeddings to retrieve morecontext for the current input and thatkind of decomposition of retrieve thanread for downstream tasksyeah that's exciting yeah i'll come tothe second part yeah for the first partuhyeah so we evaluate on uhyou know as i mentioned likeclassificationtasks linear in in a linear probefashionandtext search and code search and alsosentence summary souh so we evaluate on like foursets of uhtasks um and like multiple data setswithin each categoryumyeah i think uh we decidedto give more importance touh text search and text classificationover tech similarity uh primarilybecause the for the former ones aremore clearly defined and have like afairlyagreed upondefinitioni think sentence similarity as a taskis still a little bit bigand not clear what theyou know the end use casesuh basically um you know if you take twosentences like we talk about this a lotin the paper if you take like twosentences like you know uh jack lovesjillmary loves chocolate uhare these two sentences similar i meanuh yeah kind of uh but are they reallymaybe not i mean it's so it's like it'suh it's quite weak umand souh yeah we we like the classificationand text search benchmarks i thinkthey're more uhclearly defined yeah i i know our webvausers agree that this uh we like to textsearch and think of that and i don'tknow if too many v8 users are fittinglinear probes on the embeddings andusing that for their downstreamsupervised learning test so i do want toget more into this retrieve than readdecomposition wherewhere the idea of you retrieve somecontext to say uses data augmentationfor your input and we love this idea welove say this particular thing ofsolving this problem of hallucinationwhere these generation models generatelike url links that don't go anywhereand all sorts ofthings like that so we love the ideathat you can retrieve factually correctinformation you have theinterpretability where you can see whatit's retrieved you can update what it'sretrieved and then we like the idea thatyou don't have to store theend to end the data in the model thatalso does the downstream task so can youtell me more about your thinking aboutthe retrieve than re kind ofdecomposition of tasyeah i think it's definitely an excitingdirection umyeah itto me it does make sense that uhyou don't want to storeuh all the knowledge in the weights ofthe neural net umand umuhso so it's likewe as humans also don't do that uh welook up information all the time uh touh that can help us guide to do uh whatwe want to doso yeah i think like factual generationuh and things like that umi feel likethe idea of like havingsome way to retrieve relevantinformation uh and then like our generalmodels are you know starting to getfairly robust in the sense that they canstartusing information in the context uh andleveraging it well while uh solving atask so it feels like uh this isstarting to get to work so i want totalk a little more about how that kindof changes the problem into thek-nearest neighbor regression and andsome of the evaluations in the paperabout uh not just zero shot but thatk-nearest neighbor where you go to yourtraining set you find the nearestneighbors and you use that to inform thecurrent predictionyeah yeah glad you asked that questionit's like uh one of my favorite uhexperiments uh in the paper uh so wetake this uh to give more context wegive take this sentiment classificationdata setfrom stanford um so the task is givengiven an input textyou want to say whether the sentiment ispositive or negativeso we evaluate on uhfour different settings uhone is zero shot uh so herewe basically embed the text uh get avector and then embed the labelspositive and negativeand then zero shot is just uh whicheverlabelsembedding is closest to the input taxesuh embeddingthis works actually fairly well uhit kind of like works better than likethe supervised uh neural nets that wereintroduced along with the original paperuhuh and then we also try out uh zero shotwith prompting uhso instead of just positive or negativewe just make a simple prompt saying thisis a positive piece of text this is anegative piece of text and then use thatembeddingwe get a tiny boost in performance bydoing thatand thenthe third one which is something youtalked about is k-nearest neighborsso we takethe embedding of theinput text and then look upk nearest examples in the training setand then the label is just basically themajority one ahthis actually works quite well uh it'svery close to linear classificationwhich i think is super interestingbasically it meansyou don't need anytask specific tuning of parameters togetat least a decent performanceand yeah i think this is like one of theuhone of the surprising findings at leastfor me from the paper yeah i thinkthat's an extremely interestingtestimony to the potential of thatretrieved and read decomposition thatyou can get the k-nearest neighbor iguess just parsing it again because ithink that's amazing that the linearprobe fine-tuning for the task isoutperformed by the k-nearest neighboror on on par similarly like competitiveyeah yeahyeah yeah with just uh k nearestneighbor i think that's so interestingas you're talking it kind of reminded meof say with clip the way that you have alabel representation by the textsequence of this is an image of a catthis is an image of a dogyeah that's true it's it's it's uh it'sexactly the same yeahi think in uh like meta learning paperstoo they have like prototypical networkswhere they also learn like an embeddingof ayeah that's agood point yeah yeah that's such aninteresting way to think about thatproblem to have embeddings for labelsthinking about those one-hot vectorsand that kind ofway i think that's why i really want totalk more about prompting i think it'ssuch an interesting kind of thing withuh with the open ai papers and sofirstly i wanted to talk about uhthere's a recent paper uh titled promptburt where they're uh saying thatbasically if instead of doinguh x where you have your sequence andthen mask and then you say index the clstoken to get the embedding if you havethe template the sentence x means maskthese like templates is the idea ofprompting this kind of thing like helpsthe representation in a in that paper ina massive way so i'm really curious ifuh if you've explored prompting fornot just the downstream tasks in thesense of say the few shot gpt3 idea butin the sense of producing embeddingsthrough the apiyeah so this is a good question umwe've not really studied uh prompting atrain time uhwe explored prompting at test time uh soyeah i discussed those results with uhsentiment classification where uh it didseem to help uhi also tried this for search umso the beer benchmark has data sets youknow acrossdomains you know as a data set but covetit has a data set about you knowfinancial stuff and things like that soi tried to do a prompt uh pro i try todo a prompt experiment wherei add something like you know apart fromthe query itselfuhi uh kind of have a prefix that saysuh this is a queryorasking for information about code thisis a query asking information aboutfinance stuff uhit didn't seem to help that much uh inmy initial experiments uhi mean but it was like definitely notsomething that uhwe studied very rigorously and i thinkuh there's something i think there'ssomething there that area yeah so areyou interested in uh in this idea ofprompt search where you're searching forthe optimal prompt again the idea of uhthis is a query about code would be oneexample of doing it or say hey i have aquestion about code would be likeanother discrete way of representingyour prompt and then another idea maybeis continuous prompt tuning where theyput the prompt into the embedding spaceoptimize it with gradients how do youthink maybe the search for promptsdiffers from the search for factualinformation which we're most commonlykind of studying when we're talkingaboutmost of the searchyeahi think this is one of the cool uhresearch directions uhthat's coming out uh yeah i want toanswer it with like uh you know with fewdifferent things uhuh first thing yeah as i mentioned likei think the factual generation stuffuhis really interesting to get additionalinformation in the prompt uh uh thegenerator models are you know robust andsensitive to context that it canleverage thatthe second one about retrievingthings from the training set uhit's uh it's actually one of the endpoints in open ai it's calledclassification uh that uh takes like thenearest neighbors from retaining set andputs it in promptthat does seem to work better uh thanlike you know randomly putting in someexamplesuhso yeah again uh yeah the whole idea oflike constructing these problems on thefly at test time are super important ithinkthey're starting to work quite well umyeah finally uh kind of likeyou knowdoing some kind oflike moreexpensive searchumfor prompts uh either at train or testtime umyou know i think that againuhi feel like has a lot of potential uh inthe sense thatthe unsupervised models are fairlygeneraland have a lot of informationandthe in some sensethe current kind of context you provideto themsteers the model only to a certainextent to the task or the input you careabout and i don't think it likeactually kind of extracts all the juiceout of the model and i think thesemethods for like searchinguh for prompt i think are superpromising to kind of you know get themodel to focus more on exactly the thingyou care about yeah and i've alwaysloved the idea of like ensembletechniques and i think maybe having abunch of different outputs that comefrom a few different prompt sourcescould also be another way of having likean ensemble at test timing and we lovethinking about say connecting severaldifferent retrievals together like as webuild these end-to-end search pipelineswe like to have say bm25 tf idf a coupledifferent experts depending on how youtrain them and you have all thesedifferent things and see i think likehaving a few different uh prompts couldbea really interesting way to have like anensembleis there likegenerally on thinking of say you have aseparate kind of embedding for query anddocument and that kind of line ofthinking do you think you should have aseparate kind of embedding for inputoutputkind of examples compared to documentsof like information compared to liketask informations do you like that kindof idea of separating or just oneembedding for every kind of thingyeah i meanit's definitely more convenient if youcan have one embedding for everythingit's hard to argue against that uhum uh yeah our our hope uh and i thinkour kind of like first crack uh atembeddings is that we can probably getlike one embedding that seems to workwell across tasks and across like usecases umyeah soyeah otherwise i feel like you know uhthe the the ultim the system you'reultimately building has too many movingparts you know errors propagate thingslike that uh and whereas now i thinkhaving like a single model uh that cando all these things uhfeels like the right way to do it yeahso transitioning a bit i i love how kindof like the clip model this is likemultimodal with text and code and ican't wait to talk more about deeplearning for code and that particularapplication of just generating code suchas codecs and that kind of thing butfirst kind of back to the text embeddingside do you think it gets saylike that kind of reasoning informationthat program execution from the codedata that transfers into the textdomains like maybe we have thisdecomposition of sayfactual retention and then likereasoning and reasoning is kind of apretty abstract thing but it seems likeone idea for that would be to look atsay mathematical expressions in theirevaluations and then just language modelthat or logic expressions language modelthat and similarly with like the codeoutputs just language model that do youthink that kind ofproperty of the reasoning of that kindof symbolic execution translates intothe text applicationsyeah that's a good question uhyeah i don't know whether it has to bethroughlikeuh you know output of executing uhsomething uhi feel like this the signal there isquite sparse uh you know you get veryfew bits of information uh from like youknow like if you execute a program andgive like you know i don't know onenumber back and if the model is learningfrom that i think it's like uh thei think models might overfit umbut yeah i think if you can instead likeactuallyuhhave some likereasoning logic or code that you're likecan additionally you know guide themodel towards reasoning i think thatthat is definitely super promisingawesome so coming into codex and how ithink these cpc embeddings and we talkedabout the retrieve then redecompositionhow these could probably take codex tothe next level with our search poweringuh so before that uh generally what areyour thoughts on deep learning for codeis itlike because to me it seems superexciting i love this topic of deeplearning for code yeah i think it'ssuper uh exciting and it's like uh youknow it's amazing that it's likestarting to work uhreally well like uh you know i use uhcopilot uhuh you know uh every day for programmingand it's like uhyou know it's like super useful uhyou know if uh i i notice a hugedifference when it's when i have it andwhen i don't it's just like uh very veryuseful as invery very usefulness auto complete uhdon't have to look up in other placesthat much uhso and like you know just the wholekind of like just just from auser perspective of like you know i canif i write the comments well uh i canusually get a good first draft uh whichi think is like you know uh takes a lotof uhuh frees up a lot of uh mental space forme to like think about other stuff soi think it's just like amazing that itstarted to work andyeah i think it's uhumyou know it's one of theit's prob probably the best applicationof uh deep learning models yeah i i doagree i personally agree with that ithink some people might want to getalpha fold two in there and have thatone alsoyeah but yeah i've seen so many amazingtestimonials of copilot and it's soincredible andi mean coming from co-pilot which issomething that already works and we'renot even in the clouds but to go intothe clouds do you think this idea thatyou could just kind of loosely sketchlike an idea for a deep learning paperand then it could write you pie torchcode that would create the paper maybeeven set up like a weights and biasescallback like all the kind of thingsthat you would needyeah i think i mean the current ones uhuh not sure uh you can do that i thinkit is like fairly uhuh more like uh specific uh you know youknow you can definitely do things likeyou know set up uh weight and biases anddo the thingbut i ii don't know whether you can dosomething like you knowmake the transformer uh attend to uhmillion tokens in a rough thousanduhyeah that kind of high level make thisattend over in quadratic like linearcomplexity to in the just a naturallanguage descriptionso coming down from kind of that bigvision of it that i think is socaptivating one of the most interestingtechnical details of codex to me is therepeated sampling and how you say havethe tree structure decoding things liketop k beam search where you go throughthe tree several times and you got thattrade-off between diversity quality kindof similar to sampling from anygenerative model like an image model oranything like that and then you havethis kind ofmaybe a deduplication step which ismaybe something that i want to bringwe've eat back into which i think andcoming back to this search thing becausehaving these search embeddings let youalso embed the tree traversals tomake sure you pass less noise andoverall make codecs more efficient haveyou thought about that kind of puttingcpc in thefiltering of the repeated sampling forsay codexyeah that's a good question uh i mean iuh i i i saw that the for exampleumuh the alpha code workumyou know they sample a lot of candidatesand then they do some kind of clusteringuhbut their clustering is based onuh input output behavior uh rather thanembeddings uhso that's like feels like one you knowplace where it can you can easilyapply something like uhembeddings there uh code medics there uhbut yeah in general uh i do think thatum you know uhusing these embeddings to guide thesearch processit feels very natural yeah yeah just thegeneral idea of uh the embeddings fortraversing the trees i think is generalapplicability and kind of coming back tothe the cloud idea as i said this ideathat if you're gonna gen if you're gonnawrite code that generates a deeplearning experiment it takes so muchtime to run it's not like code forceswhere you can or you can filter by inputoutput behavior because you can just runitright so you would need kind of thatsearch layer toyeah yeah for sureyou know and i also really like the ideaof say how this could help people withlike their specific python librariesthat they're building up and help peopleget kind of the adoption the questionanswering and that kind ofsupport so i'm curious what you thinkabout say the role ofcode language models code search toolsgeneration for say facilitating opensource projectsyeahumyeah soso i think like uhthe best results we get in the paper areon like code search very clearly uh youknow our model seems to bereally really good at code searchacross multiple languagesandin some sense i feel liketext search isyou knowis asuper well studied problem uhwe have really good benchmarks uh wehave lots and lots of methods and papersand you know software librariesuhfor for text search um and you knowthere are places whereyou feel like oh my god tech searchsucksbut in many places i think it does itdoes a decent jobuh whereas i feel like code search ithink has amuchfurther way to go uh and it's uh andlike i i almost feel like it's probablythe case that code searches likelags a lot behind text search and inapplicationsis becausekeyword search works really well fortext and you can like kind of build yourfirst application based on that uh whereit's not that easy to do that for codesearch and you really needsome way tocapture the semantics of text and codeso that you can do searchumuh yeah i i really think our models canlike startuhpowering uh the next generation of goodsearch tools yeah i definitely think soas well and um just a quick question howbig is the impact of like the compilerand input outputlike because the the text search and thething and the problem with is it's sohard to evaluate it right like becauseit we we say things like uh when we wereinterviewing charles pierce at keniusand they're building a scientific paperrecommendation system and that idea ofserendipitous discovery and fuzzyresearch where it's like here's asimilar paper did it help you like it'sharder to evaluate really compared withthe code where it's like it's correctlike it's not yeahyeah exactly i i yeah i think goodsearch is likesuperuh well-definedtaskand yeah i i think umthe the data set that's commonly used uhcode search net uhis quiteuhi think it's like uh the trainingservice is noisy uh it's uh script fromuhjust like open source code but i thinkthey have like aum at least a subset of test set that'slike more clearlyuh marked with like whether this is thecorrect code for the for the query and ithink uh it's it's a it's a nice way totest these models yeah and i think likehow we say with um unsupervised textlearning we can use back translationfrom english to french back to englishand i think one heuristic we've seenwith code is uh i think this paper istitled break it fix it where they uhcorrupt the code so it doesn't compileand they use that to kind of get thedata and similar kind of backtranslation way of generative modelsthat generate their own data in thatkind oflike data augmentation schemeinteresting i see so so you like traintraining a model to go from likea thing that like doesn't work to thinkthat worksand like using the compiler as a way toget that datayeah that's pretty cool yeahbecause i think debugging is is a hugeapplication of this so let's go i knowfrom like learning how to code that kindof you know hair pull your hair outthing where you can't figure out how toget past the error or whatever it mightbeyeah yeahso does that kind of use of the groundthe reward signal from the compiler theinput output pairs does that inspireyour interest in reinforcement learningand i don't even brought this up at allyet but generally what are you what'syour thought on reinforcing learning forthese applications i mean likeyou know like if you step back i feellike search is probablyan application that has benefited themost from uhhuman feedback uh starting from clickdata uh i i think like uh uh uh like thethe like all search engines uh benefitfrom that click data and yeah and ithink with code there is thisway of like verifyinguhverifying your code through input outputtests yeah i thinki think all that is like definitelysuper helpful so we've talked aboutquite a few topics and um so one thingis we we mentioned say i think the besttransition for this would be to bringback up that idea of reasoning and as wehave these deep sequential neuralnetworks they have several layers andthey maybe reason through theirrepresentations that idea of likeparsing and selecting the information soi'm trying to transition into this ideaof latent knowledge representations andsay exploring that in thesemodels and sayvector quantization is another reallyexciting topic so i'm curious what areyour what's your thinking arounduh just latent space exploration whetherit'slike a generative image model or one ofthese chat bot kind of neural assistantthingshuh like uh do you mean is it likespecifically like looking uh looking upa knowledge source or is it more likeyou'respending some searchcompute to info like activations oryeah the the latter one where you'retrying to search to find what's going onwith this network what's it thinking ifyou want to use that kind ofanthropomorphization of it and say it'sthinking butyeah yeah yeah i get it yeah i think uhyeahthis is kind of like related to like uhthe idea that like you knowespecially once they have theseunsupervised models that are very broadumthey they don't get likeuhit's like at a test timeuhusually i think they they don't they'renot given likeenough contextto focuson the tasks on on that particular inputuhand yeah i thinkmethods that can likeuh you know let the modeluhum you know uhdo a lot moreuhyou know do do a lot more uh thinking asyou sayumat this time it's definitely a promisingidea um yeahi feel like maybe things like say likeuh pondernet or like early exitingnetworks where you scaled the capacityto kind of simulate ityeah and also i would say like you knowuh we touched on this before the idea oflike sampling a lot of things and thenuh kind ofuh finally deciding which one to use uhi think all of this kind of falls underthis bucket of like you know uhlet's have the model uhdo a lot more things at test time andseeuh if you can figure out a way to likeget these models to perform even betteryeah so transitioning like a bit intosay how we can kind of understand it doyou see discrete bottlenecks in theintermediate representations of thenetwork as being a way that we canunderstand what how it might bereasoningah yeahso i feel likeinterpret interpretability with neoletshas always beenuh challenging uhin andi i thinki i don't know whether havingdiscrete activationswouldhelp with interpretability or not uhand yeahyou know if it's like going to belike you knowuh vqbie codesand like that are like also very highdimensional uh they're the skin butstill high dimensional i don't think yougain a lot of interpretability uhum so yeah so generally that kind of isit maybe just more so it's like acompression thing than it is that idea ithink so i i think uh i i think thosetechniques are useful because they helpus uh compressyou know very long inputsespecially in the perception domain toto like a you know you create abottleneckso also on this topic of bottleneckswith say like architecture bottlenecksdo you i think i know the commonpractice generally is to say apply themto have the transformer be isomorphic ithas the original input sequence lengthby say the embedding dimension and thenthe the tension layers they nevercompress that and to say like incomputer vision architecture as how saylike you net we would turn it into avector skip connection up samplingand a funnel transformer has applied asimilar kind of idea and then anotherone of the most popular embeddingembedding models out there uh siamesebur sentence bird they alsohave that um compression so what do youthink about that kind of style ofcompressionyeah i meanin general i feel likefor textfor you know context lens we usuallyhave uhuh i i think like uhyou know the opening api some of thelonger models and even that i think islike 2 000tokensand like a lot of the open source onesare like 500 tokens or even smallerat that stagewhen you're dealing with texti don't think you buy a lot bycompressing uhbecause likelike parallel attention uhfor that context lens seems to be fineuh but i mean the moment you move toanother modality umthat has you know higher kind of uh orlike lower signal to noise ratiouhum like perception tasksor if you want to do like text modelsthat are just like way way longercontexti think that's when again like this kindof uhbottlenecks in the architecture so let'sstart uh helping you out um you knowlike vision transformer kind of thefirst step is touhyou know do like a very rough umencoding of the image in in in a lowdimensional space and then you run thetransformer on top of that and thatseems to be working quite well so kindof wrapping up i know we talked about somany things from the embeddings apiretrieve then re-decompositioncontrastive losses and the search fornegatives and i mean all sorts of thingsfrom prompting etc with the as they'llbe the show notes for people watchingthe podcast but so kind of umto wrap it up and a question that i'mcurious about is um what is kind of likewhat motivates you like is it a is ityour curiosity of the algorithms do youhave a particular application in mindthat drives you yeah i think a bit ofboth uhand definitelyuh you know kind of look atum you know what are things that we cancurrently solve uh with the techniqueswe know you know what are thingsuhwe know work well you know that thingsthat don't work well so try to uh youknow understand uh the currentuhyou know current capabilities of ourmodels and trying to push that uh andalso definitely seeing the other sidetoo of like you knowwhat are what are things that can havea good real world uh impact so yeah it'sa bit of both so one more question likethat uh so what is kind of yourinformation diet how do you handle thislike massive velocity of new informationand deep learning oh yeah that's reallyharduh i think there's like so much so manypapers coming outumi don't know in some sense it's like uhyou know uh i i don't know i feel likeuh i i think jeff hinton has this likeuhadvice on like uh you know don't readtoo many papers uhuh it will stop you from being creativeuh i i i can see where he's coming fromuh i feel like um i try toyou know try tobasicallybucket things into some kind of highlevel categories and saying okayyou know these areyou know these are the sets of ideas wehave these are the sets of problems wehaveyou know and likethese are the capabilitiesthat our current models have and here'swhere we lackand kind of try to think from thereandkind of notthink too hard from a specific paperspoint of viewuh and yeah i mean of course then onceyou decide to work on something andyou're trying to improve something thenyou start diving deeper into that areatrying to understanda specific paper or a specific set ofpapers in a lot more detailuhbut yeah uh for for like high level kindof thinking about what to work on nextit's a lot moreabstract than a single paper yeah that'ssomething i've noticed and i imaginelike once you get to your level you havesuch an abstraction over the categoriesthat it really helps uh do thatfiltering whereaslike i think when you're starting outyou see like neural neural radiancefields and yeah you're like all over theplace with these different things and ithink the better you get the betterthose high level categories guide yourthe buckets as you yeah i think that'ssuch a well described way of handlingthat yeah i think you also get better atuh reading papers over time like youknow papers where you know you're likeokay i get the high level idea from theabstract you know sometimes you go intothe results and then you know when toactually go deeperuh i think you kind of like get betterat that over timeawesome so arvin thank you so much fordoing the vva podcast i hope ourlisteners uh you know excited about theopen ai embeddings api and using it inin the wpa search and powering all sortsof search applications so manyinteresting details to explore with withthese algorithms and and what they cando so thanks again so much for coming onthe podcast awesome thanks for having meit was fun chatting with[Music]you you", "type": "Video", "name": "Weaviate Podcast #7 \u2022 Arvind Neelakantan of OpenAI \u2022 Embeddings API in Weaviate", "path": "", "link": "https://www.youtube.com/watch?v=uFxfZ0vLsoU", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}