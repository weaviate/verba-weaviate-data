{"text": "Thank you so much for tuning into the first episode of our LlamaIndex and Weaviate series! This episode will show you how to ... \nhey everyone welcome to the firstepisode of the Loma index and weavateintegration in this video I'll be goingover an overview of what llama index isgo over the various data loaders thatthey have hosted on the Llama Hub thenI'll share how to load data andalleviate using llama index and then howto connect llama index to your alreadyexisting weave instance I also share afew ways to run review if you're notfamiliar so you can use sweepy embeddeduse WCS which allows you to have to runa 14-day free sandbox and then also howto run it on Docker so running itlocally so these are just a few optionsthat you can use to run revade and alsoget started with your application withusing we beat and llama index togetherand then also share this in the reviewrecipes I'll include a link in thedescription but this is really where Ijust share an end to end uh Notebook ona few features that we have in weviatebut then also with our integrationPartners as well all right so let's jumpinto the video This Is The Notebook thatI'll be sharing under the Wii V8 recipesrepository so make sure you follow alongand go under Integrations llama Indexepisode one and then you can followalong from there so this is the overviewthat I already went over so I want toDive Right into what Loma index is soLama index is a framework that enablesyou to connect other LMS and storageproviders together and when I seestorage providers I am referencingabbreviate the open source Vectordatabase so while llama index and vv8together make the ultimate retrievalaugmented generation stack is becausethe large language models don't haveaccess to your specific data but whenused Lama index and we meet togetheryou're essentiallysupplying the llm with the data that isstored in your database so this isallowing you to make queries that arespecific to your company like uh howlong do I have to give my company myresignation letter or that's maybe ahorrible example but you kind of you getthe gistum so one cool thing about llama indexis their llama Hub so it it's um it's ahub that has all of the various dataloaders whether this be slack PDFdocuments YouTube notion which I show inthis demo uh PowerPoints essentially allof these different data sources can befed into your vector database and thatis the first part that I show is how toload data into leviate using llama indexand then also the other way aroundum so with that being said let's getinto the demo so for those of you thatdon't have an existing VB instancerunning there are three options to getthis startedum so you can use we be embedded whichallows you to run it directly in yourapplication the only requirement is thatyour python client is up to date so justmake sure is that minimum 3.21 and thenrunning be embedded will work if notthere are a few other options if thatmaybe isn't the best uh way for you todo that the other option is using our BBcloud service so you can create anaccount and then from there create a BBinstance and what's really cool aboutthis is that it's a 14 day free sandboxwhich really allows you to get startedand like test the botters with Vectordatabasesum so that's one option so run itcompletely free and then also embeddedin Docker also free so whichever waywhichever method works for you bestum so once you create your bb instancein the console uh you'll pass in yoururl right here so I have my llama Indexepisode one uh working and then you passin your open AI key here and forsecurity and financial reasons I have ithidden and then also if you create yoursandbox and it has authorization you canalso pass it in right hereum but for this demo I don't have thatenabledlastly you can run review using DockerSo within this llama index folder I havea gamble file and if you could just grabthat run it and then it should beworking and running at localhost 8080.so those are like three options to runwheat feet if you don't already have arepeat instance runninganother requirement to get weave set upis to build out your schema and so whatI'm doing here in this cell is justbuilding my blog post class and then I'mpassing in my content property and whatthe content is is just a text that iswithin each blog post and I guess Ididn't make this clear before but I'musing the bb8 blogs as my data setum so yeah make sure you check that outas well adding data to webva using llamaindex is actually super easy using theirvarious data loaders so in this videoI'm covering three uh ways to load indata using the simple directory readerbut then also the web page reader andthen loading in documents from notionbut if you want to use maybe slack orPDFs or YouTube videos I'd recommendgoing to llama Hub because you can seelike the various ways to use those dataloaders okay so starting off withDecember directory reader what this isdoing is just reading files in your filesystemum so I have all of the rev8 blog postsin my data folder and I'm just going toload that in as easy as that the nextway to do this as well as using thissimple web page reader so it's a webscraper that turns HTML to text so justto show you to give you a feel of how todo thisum I just passed in the Wii Vape blogand then the Llama index and weave blogpost and it's an easy way to load indata from websitesthe other option is to use the notionpage reader so it loads documents infrom notion and why this is so cool isbecause you can actually convert notiondocuments into markdown and I'm not sureif that's like a new feature or maybeI've been under a rock but that's reallycool because now you don't have to gothrough the manual effort of convertingblog posts that are on Google or maybenotion as well and converting that intomarkdown so this is a really cool optionif you want to give that a try so at thenotion page reader is doing is usingyour integration token so if you're aworkspace owner or admin you can createan integration and then you'll just passin your secret key here next with thepage ID is so if you go to notion.so andthen navigate to the document that youwant to load in the URL will end withthis code mixed up numbers and lettersand then you just paste that into hereand then it's as easy as that to load indocuments from notion which is great nowthat we have our data we're going towant to chunk it up so we don't run intothe limited token length problem so Lamaindex has a simple node parser and whatthis is doing is just chunking up yourdata so our blog posts in this demo intonodesnext we're going to want to take thosenotes and upload it to eviate um so bydoing that we need to construct ourVector store so here we have our weaveclient and you're setting that equal toclient which is either a few are runningit with embedded with a WCS instance orlocallyyou're just going to want to connectthat rebate instance toum you're going to want to connect thatwe beat instance here to construct thevector store and then what the indexname is is just the class that wecreated so in our example we are usingblog post which we defined in our schemaand then we have text key which iscontent and that's the property that wedefined in the schema as wellnow we want to set up the storage forarm bettings that's what we're doing isjust passing in the vector store whichwe just defined here because we're usingthe weviate database next we just wantto set up the index so we're just takingthe nodes and then setting up thatstorage equal to what we had justdefined here and that's really the laststep that you need to get started withuploading data into alleviate usingllama index now that we have our data inour weave instance I want to build asimple query engine so I'm doing this bysetting by using the index that we justbuilt and passing in my query so I'masking what is the intersection betweena lumps and search and where I want thisto retrieve this information from isfrom my weebe database and to be alittle bit more specific I want it tofetch the blog post where I'm talkingabout a lumps and search and Conor and Ijust published that blog post maybe likea few weeks back so it's kind ofinteresting to see how it answers thisso it's saying that the intersectionbetween alarms and search is the abilityto use alums to improve searchcapabilities such as frag queryunderstanding index construction andlens and rewrackingEtc if you would like to actually readthe blog post I'd recommend checking itout but it's really cool how you canbuild such a simple uh Engine with llamaindex the other option is to query usingthe VBA consoleso up here I'm connecting to my weeviedinstance and then I'm just running asimple hybrid search and for those ofyou who aren't familiar with what hybridsearch is it's taking bm25 which iskeyword search and Vector search andcombining it together and it's doingthis waiting by this Alpha parameter soAlpha set to zero it's pure bm25 andAlpha set to one it is pure Vectorsearch so setting it to 0.75 or 75 isskewing more towards per Vector searchbut this is just something that you cantoy around with for your application uhbut for this I just set it to 0.75 allright so once it but it's going toreturn is a Content so just a text thatis within the blog post and again myquery is the intersection between a lensand search so I wanted to grab the blogposts that where we talk about this andit's doing exactly that hereum so it's passing in or it's uhoutputting the elements in search blogposts which is great another thing tonote is that you can pass in your openaikey and the header down here because weneed to vectorize our query and yeahthat's it that's one way to back youreye oh sorry that's one way to query inllama index and in mediate for those ofyou who already have your weave instancerunning and you just want to add llamaindex to it this is the way to do it soyou just want to use the web readerwhich you can actually see thedocumentation on this and the Llama Hubum or just follow along with thisnotebook but you want to connect to WCSor pass in your localhost 8080 if you'reusing Docker so you just sign in withyour username and password and then passin the URL to your rebate instance andthen documents what this is is just yourschema so I'm taking my blog post classand then passing in AI content propertynow that I have run that you can nowumquery or you can now upload and querythe existing class that you already haveall setum so I'm again passing in the URL sothat my we beat reader knows whichinstance to connect to and then I'mbuilding out my query so I want blogposts about that explain what reftubecis and I want it to search on thecontent property limiting it to two andonly outputting the contentall right so now that I have mydocuments I need to build out the indexand then I simply just run my uh queryengine so again I'm asking what isreftubecand it says crafty bike is a machinelearning algorithm that uses NLP togenerate Vector representation of textreferencesum that's a little debatable but it wasable to answer so that's one way toquery in a llama index but then againyou can also query in the console so ifI ask in the console what is rough toback using your text passing in my openAI key because we need to vectorize thatyou can see that it will output the blogpost that is about rough tebec and whyyou need it for your recommendationsystem so if you'd like to learn moreabout what ref tibec is I'd recommendchecking out our documentation thanks somuch for watching the first episode ofthe weeviate and llama index integrationstay tuned for future videos where I'llbe covering how you can build moreadvanced guides with using llama indexand movie together to really build thatultimate rag stack and then also ifyou'd like to follow along with thenotebook don't forget to head over tothe weeviate recipes repository whereyou can download this notebook andparticularly or also just learn moreabout various features and mediate againI cover end to end notebook Demos inthat repository and then also make sureyou like And subscribe and tune in forthe next video bye", "type": "Video", "name": "LlamaIndex and Weaviate - Episode 1: Data Loading", "path": "", "link": "https://www.youtube.com/watch?v=Bu9skgCrJY8", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}