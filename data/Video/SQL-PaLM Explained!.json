{"text": "This video dives into the new SQL-PaLM paper, exploring how well the PaLM LLM can be prompted to convert natural language ... \nhey everyone thank you so much forwatching weave it on YouTube today we'regoing to dive into SQL Palm improvedlarge language model adaptation for texttestql so before diving into it maybelet me give you three reasons why thispaper is worth your time exploring sofirstly this could really reduce thebarrier of Entry to using databases ifyou just have to write a naturallanguage question like you know what isthe average age of country music singersinstead of having to learn how to do theSQL syntax it makes more people able toaccess databases and by people we alsomean large language models in this wholetool use kind of thing so the secondthing I think this is a reallyinteresting paper is just understandingfurther the zero shot few shot learningabilities of these large language modelsthey compare their fuse shot promptedPalm large language model with say thesemodels that have been fine-tuned on thespider text SQL data set and they'refinding that basically they can promptthis model to just instantly outperformthe previous models trained withsupervised learning and that brings meto the third thing is I think especiallyif you're interested in deep learningresearch this spider data set we'rewhere they collect 7 000 queries across166 different database tables fortraining and then say like a thousandqueries on 22 databases for testing it'sa really interesting data set for howtext SQL is measured they also havethree variants of it spider synonymreplacement spider realistic and spiderdomain knowledge that kind of tests thisidea of you know how do we Benchmark howwell these models can write SQL queriesI think this is super interesting forwevia weavate also has an aggregate APIbuilt in as well so you can do thesekind of queries with weave as well I'vetested this kind of few shot prompt onwevia's aggregate syntax so we'll diveinto that and all sorts of fun detailsso thank you so much for tuning in and Ihope you enjoy this paper summary thisvideo will explain a super exciting newpaper on text to SQL translation SQLPalm improved large language modeladaptation for text to SQL reallyquickly before getting into the paper ifyou like paper summary videos like thisplease leave a like And subscribe to thechannel it really helps encourage us tomake more content like this so let'sdive into it with a two minute tldroverview so the high level task of textto SQL is to translate natural languagequestions into SQL structured querylanguage questions or syntax so we takea question like what are the names andrelease years for all the songs of theyoungest singer and then we translatethat into the SQL query based on ourattributes of the table select song namesong release year from the table singerand then order the results by age inascending order and limit the results toone for just this uh youngest singer sothis is the high level idea being ableto ask databases questions in just avery natural way and then under the hoodthe large language model is translatingthe natural questions into thestructured query language so one of thekey investigations of this paper iscomparing the performance of few shotprompting the Palm model Palm is one ofthe giant pre-trained large languagemodels one of the you know 500 billionparameter free trained models so we'regoing to be exploring how well you canjust few shop prompt this compared tothe performance with say fine tuningPalm on the spider data set andcomparing with you know the currentstate of the art all the existing modelsthat have been fine-tuned and deployedmiscellaneous training tricks andinference tricks to perform this task oftext SQL translation so quickly whatthat looks like is when you're doing fewshot promptingin the input you give it examples of adatabase schema and a natural languagequestion and then the corresponding SQLtranslation so you in this a diagramyou're just seeing two examples of thisin the input that's kind of one of thequestions a few shot prompting is youknow how many examples to give whetherthese examples should be tuned to bemore in line with the downstreaminference but then what you do is youthen have this novel inference schemathree plus question three and then itgenerates the new SQL so Infuse shotprompting it has these references of thetask to you know to reference and sortof learn from in the input window whichis you know one of the super interestingemergent abilities of large languagemodels compared to the more standardinference setup where you just have thenovel input and then you know yougenerate the output so a is exploringthe few shot prompting B is exploringfine tuning Palm on the data set thespider data set of text SQL translationsand then just seeing single inferencesingle output kind of setup so this is aquick additional look at what this wouldlook like when you're talking aboutgiving it the schema you're talkingabout compressing representations likethis into text to prompt the model sosay you bolded singer as the table andthen it has the keys singer ID namecountry song name and so on sointerestingly you say have like foreignKeys when you when you're looking atconcert and you need to join say concertID and Stadium singer in concert so youhave a lot of interesting ideas of howyou could kind of extend this and it'salso worth mentioning that this ismostly about kind of like a surfacelevel SQL interface not like theunderlying optimization of how the datais stored butyou know offering this kind of interfacein natural language so so this is theidea of taking these questions and thentranslating them into not into SQL basedon giving it the table in as a part ofthe input so another really interestingdetail this paper are the data sets thatthey use to evaluate this spider is acollection of about uh 7 000 tradingqueries I think a thousand testingqueries across 166 database schemas fortraining in something like 22 fortesting so they also have these variantsof the spider data set as the text toSQL research Community has iterated andlearned about this these things sospider's synonym is about manuallymodifying natural language questionswith synonym substitutions so instead ofhow many singers do we have and singersmight be like two kind of on the nosewith the database schema you say howmany vocalists do we have ideas likethis to try to like test the robustnessof how well the models perform when thenatural language question starts todeviate from you know something that'sclosely aligned with the database schemaso it was spider realistic that removesthe mentioning of column names socompared to the question how manyconcerts are there in year 2014 or 2015just more natural how many concerts arethere in 2014 or 2015 and then spiderdomain knowledge is where you're addingdomain knowledge so you know list allsong names by singers above the averageage and then hard to answer age-relatedquestion based on the you know if youonly have the uh the birthday column soso you need to like derive birthday fromthe table and then answer the questionby age and other examples like this soquickly before diving further into thedetails of the SQL Palm experiments Iwant to quickly remind you that you cando these symbolic aggregation queriesdirectly in weviate using the aggregateAPI so in weavate if you have a classlike maybe just to continue on this ifyou have say the singer class yousimilarly have these properties whereyou have you know Joe sham is a textproperty or say you have age which is ayou know an in property or Ismail is aBoolean property in weeviate's aggregatesyntax you can then access these kind ofsymbolic aggregations using this syntaxso say you want to see which of yoursingers appears the most in your dataset you would do name and then topoccurrences so you want to see theaverage age you could similarly do thisyou know age mean to access that or theBoolean total true total false this kindof thing and then if you want to do thiskind of joining as well you would do youknow say singer and then say singer andthen the relation is performed inconcert concert you would do you knowperformed in concert dot dot on concertand then now you're in the concert classand you can keep using all this kind ofsyntax so that's how you do this in wegate we're going to look at a few shotexamples showing that this exact kind ofthing works in weavate which is superinteresting so if you want to do thissymbolic joining queries aggregations ofyour metadata you can also do that inweeviate there's another super superexciting connection of This researchwith weeviate we're going to dive intothis more at the very end of the videoon some key takeaways but Lang chainllama index they've recently beenpromoting this self querying retrieverkind of idea which is really amazing andwhat it is is you take a query like whatis a golden doodle and you add filtersto make it filtered Vector search tostep back a bit weavate Vector databasesare about building these Vector indexstructures to allow approximate nearestneighbor search at absolutely massivescale in addition to just kind oftraversing the proximity graphs to findthe nearest neighbor's distance wise wealso can connect them that matchsymbolic filters so say you want tobuild one index and then have a symbolicproperty like the source of the index sosay it's you know text passages and thenyou have a filter on you know whetherit's comes from Wikipedia it comes fromarchive or comes from Reddit you can addthese filters onto the query and it willTraverse the vector index with thatfilter so it's really interesting theidea of enabling these you know queryrouters to either say which of theseclasses do you want to search through orwhat kind of filters do you want toapply on searching through the vectorindex so we'll talk about that at theend but this is another kind ofconnection to this idea of using theselarge language models or you know justgenerally the capabilities of languagemodels to help facilitate the queryinterfaces so coming back to the SQLPalm paper let's look at some examplesof natural language questions and theircorresponding SQL translations as wellas the database tables in reference sofirst of all imagine this question whatis the average minimum and maximum ageof all singers from France we have thisdatabase table with the tables Stadiumsinger concert singer in concert andthen we need this to produce this queryselect average age Min age max age fromsinger where country equals France sothe large language model needs to lookat the table look at the keys infer thiscountry property and then generate thisquery so already I think somethingthat's really interesting about this andyou know previewing the weeviate angle alittle bit is how right now what we'redoing with this SQL Palm paper is we'rejust giving it the names of theproperties without any kind ofdescription of what the properties areor say you know if it's a categoricalproperty which of the values it can takeon and maybe some kind of description ofthe categories as well or say it's likean integer the range that it can take onso a lot of interesting things forextending this further but right now itseems like just semantic Keys is workingfor this kind of translation but maybethat's a direction to take this furtherso here's another question show namecountry age for all singers ordered byage from the oldest to the youngest soagain we take the exact same data schemaas the the first example and wetranslate that this query intoselect name country age from singerorder by age in descending order soagain it needs to do an inference aboutthe age ranking and then produce thisorder by age descending order so this isa great example of taking the naturallanguage query inferring the intent thatthe user wants and then Translating thatinto this particularly order by agedescending order thing so next up wehave our first example of needing tojoin tables together so we have thequestion what are the names of Nationswhere both English and French areofficial languages we have this tablecountry and country has the foreign keycode which is How We join with countrylanguage country code so what we need todo is we have this um you know fromcountry as T1 join country language asT2 on t1. code equals t2.country codewhere and then it learns to parse outthe the English and French are thelanguages and then it needs to then getthe names from the top of it it alsoneeds to check this condition isofficial from the artificial languagesso we're already starting to see anexample of a query where you know doingthis query out might require someknowledge of SQL some experience ofdoing it especially to you know likequickly slash instantly translate thisnatural language query into this kind ofthing so this is a really exampleinteresting example of introducingjoining tables together in this pictureof generating text SQL queries the nextquery is what are the number of concertsthat occurred in the stadium with thelargest capacity so now we're doing anaggregation we're selecting the countfrom concert where Stadium ID equals andthen we have this nested query idea ideawhere we select Stadium ID from stadiumand then we order by the capacitybecause we want the largest capacity andthen we want to just limit it onebecause we just want the largestcapacity not like a list of the you knowtop five largest capacities so now we'reseeing this concept of an inner querysuper interesting concept again oftranslating this into the SQL next up wehave a super interesting query find thefirst name of students who have both catand dog pets and we have the databasetable student has pet and then pets sowhat we're going to do is we're going tofirst sub-sample from each of the tablesso first We join the student has petpets tables with the condition uh pettype equals cat pet type equals dog andthen we're going to do the intersectionof those two tables of students who havecats and students who have dogs to findthe first name of of the students whohave both cats and dogs or a cat and adog as a pet so this is the first case Ithink where we're starting to wade intothe Waters of query optimization theirSQL is built on this idea of relationalalgebra where basically you do these uhlike set pruning set operations thatwill filter the set so say you know youhad a thousand a thousand objects inyour database table and this one filterwould potentially reduce it down to like20 objects compared to whereas thisother one would reduce it to you know500 and then you're joining that withanother table so there's a questionabout the order of operations for howyou apply this kind of set filtering toreduce the cardinality of how manyobjects are in your databases hopefullythat was a decent overview I definitelyneed a brush up on my relational algebrabut to get the general sense of there'ssome optimization behind you know howyou apply filtering operations and thenthe order the order in which you applyfiltering and Joint operations the nextqueryso this is a pretty complex one what arethe IDS and names of all the countriesthat either have more than three cardmakers or produce Fiat model so in thiscase we have the union of these twoconditions on the database tables sowe're joining together uh you know thecountries with the car makers so we haveuh six different database tables in thisso another case of the this exampleparticularly is a great example whereyou know you would you would need tohave written some SQL to have quicklytranslated this into this selectt1.country ID from country so this Ithink is the perfect example of why weneed these models and how thisfacilitates this kind of naturallanguage question shown on the top downinto this SQL syntax so quickly beforemoving on from the SQL query examples Iwanted to run a little test of how wellthis would work with leviate's aggregatesyntax so the way that I structured ThePrompt is first I give it a descriptionof the API syntax so the aggregatefunction is structured as follows thengive it that same you know graphql allpossible things you could do with itblockas shown previously and then I give itthe new schema so I you know I like toplay with this webia podcast searchexample so I have podcast clip that hasproperty speaker content podcast numberand the duration of the podcast thenanother quick description of the taskyour task is to take a query andtranslate it to the appropriateaggregate syntax based on the syntaxprovided above and the data schema sothen a training example who is the mostfrequent speaker in the podcast Clipsyou know and then this would be the howyou do that you top occurrences valueoccurs and so now the test query of howlong was the longest podcast clip sorunning this live hopefully worksso yeah that's exactly correct and so wesee how it's able to do this translationand maybe that's not the most confusingquery as we saw some really confusingqueries but just to get a general senseof how this might look with weaviate andthe things we can do with this kind oflarge language model translating fromnatural language into structured querylanguages so let's get into the datasets that were used to evaluate Palm'sability to write SQL queries and alittle more background on this field ofresearch called text to SQL so to take aquote from the paper text SQL is along-standing challenge crucial toenhanced database accessibility withoutrequiring expertise of SQL so this angleis the you know the general humanaccessibility trying to help more humansuse SQL systems you know as easily aspossible get running as quickly aspossible and then the other angle textSQL enables the development ofconversational agents with Advanced dataanalytics abilities so there's a lot oftalk about you know tool use largelanguage model agents that use tools andthis is about helping them helping theagents make SQL queries these symbolicaggregations to acquire information likeas we mentioned like I don't know Ithink it was like how many concerts wereperformed in the largest stadium orthings like this to enable largelanguage model agents to acquire thatkind of information from structureddatabase tables so This research of textto SQL the flagship data set has beenspider spider is the imagenet of textSQL or the beer like the you know thethe big data set for this researchcategory spider contains 7 000 trainingsamples across 166 databases and 1034development samples across 20 databasesso having examples of a database schemaand then corresponding natural languageto query translations based on thatdatabase table so similar to sayimagenet C and you know the therobustness corruption tests aroundimagenet spider has these variantsspider synonym this describes manualreplacement of synonym substitutions innatural language questions so you knowsometimes the questions they theyexplicitly kind of match the key in theschema so you so they replace this tosee how robust these models are when thequestion isn't so on the nose andtalking about exactly the property inthe table spider realistic is aboutremoving any mentions of column names inthe queries so similar idea instead ofreplacing it with a synonym you justoutright destroy any uh mention of acolumn and then domain knowledge thisone I think is a little more nuancedthis is where you need to kind of derivea property from one of the attributes soit was I wasn't completely sure of thatso with that said let's dive into someexamples from the spider the originalSpider data set which are categorized aseasy medium hard and very hard socharacterizing each you know train inputoutput example is easy medium hard extrahard this is a pretty standard practicein deep learning for programminglanguages like say a lot of these datasets constructed on like code forces orleak code they also have this kind ofcategorization to it it'll be reallyinteresting to do this for imagenet andall that stuff as well but let's take alook at the you know the trainingexamples and how difficult they've beenlabeled as so an easy SQL question whatis the number of cars with more than 4cylinder cylinders just you know selectcount from Cars data where cylinder isgreater than four then a medium questionfor each Stadium how many concerts arethere and so I think this is graduatesfrom easy to medium because now you needto join the concert table with thestadium table based on these IDs andthen you need to you know select thecount of the concerts and you alsointroduce the group by syntax and youknow grouping the same IDs to you knowaggregate the concerts anyways so thenthe hard question I think then you'rejoining together three tables countrycontinents and car makers so you knowextending the joining you have thecondition having as well uh which issimilar well you have a condition on theaggregation so maybe that's part of whatmakes it hard versus easy and then extrahard I think you have this nested querynot in where you also have this kind ofjoin in the nested queries so a littlebit more maybe there's more to thedifficulty levels with respect toqueries that have that kind ofopportunity to optimize with therelational algebra I'm not like a superan expert on this I'm just familiar withrelational algebra but maybe that'ssomething that could also factor intothe categorization of the difficulty ofthe queries okay so now that we have asense of what the data set looks likeexamples of these questions that arebased on these schemas and then thecorresponding natural language testskill question the key detail that we'regoing to be exploring in this paper ishow well these this SQL this Palm modeltaken off the shelf and prompted with atask description and a few of theseexamples how well can that translatenatural language into SQL and how doesthat compare with fine-tuning a palmmodel on these input output pairs sofirstly let's dive a little deeper intothe few shock prompt in the appendix ofthe paper they have the exact promptsfor how they're going to compress tableswith the questions and do this few shotprompting so we're at the end of thepaper and we're looking at the exactprompt that was used to prompt the Palmmodel to translate natural questionsinto SQL so the first thing to note isthey're going to ablate two details aconcise prompt design compared to theverbose prompt design and this is kindof what I was mentioning earlier where averbose prompt design is where you youknow you give it the attribute and thenyou tell it the type of the attribute Ithink it could be interesting also tokind of say it's a category attribute toextend this with the differentcategories I think this would be sort ofessential for that self queryingretriever idea we mentioned at thebeginning but anyways I think that'sgetting distracted from this but sobasically verbose prompt is where youreally tell it about you know these areprimary Keys these are foreign keys andyou know you give it a lot ofinformation compared to concise wherethe syntax is a little more maybe let mezoom in to make it easier to see whereasthe zoom in is just giving it the valuesdirectly so basically what you're doingis you start off by telling it the taskthis is a task converting text into SQLstatement we will first give thedatabase schema and then ask a questionin text you're asked to generate SQLstatements so then here's an examplehere's an example so these are the fewshot examples so they're annotated ashere is an example convert text to SQLso then you have the schema valuesso in this case it looks like the tablesare separated with this um like Farmcolon uh yeah so this is City okay sothat's what that looks like uh then youhave the column names associated withtheschema oh so you do have the type so youjust have a little more verbose way tosay in the type so sorry if I get badinformation uh so then you have thequestion example so what are the themesof farm competition sorted by urineascending order and then you have thecorresponding translation so so you givea couple examples of these and then whenit comes to be test time you have here'sa test question to be answered converttext SQL you have the new schema the newexplanations of the types of the columnsthe primary Keys foreign keys and thenthe question how many singers do we haveand then generate the SQL in addition tothe comparison between concise andverbose prompting the authors are alsogoing to explore consistency filteringand execution filtering so to give aquick background before we'll dive intothe open AI playground and get anexample of what this kind of Randomnessin large language model decoding lookslike consistency filtering is mostlyused in question answering is where yousample diverse reasoning paths and thenthe ones that end up at the same answersorry answering they end up at the sameanswer that's going to be the finalquestion so if it's like mathematicalreasoning and then you're like breakingdown the steps of doing the math bydecoding different paths in the languagemodel output then you just aggregate thefinal answers it's the most consistentlike say 40 if we're adding numbers orsomething and then that would be theanswer that you give in the questionanswering execution filtering is uniqueto programming languages this is whereyou sample the diverse outputs but thenyou put the outputs through the codeexecutor and then similarly how manyended up with the same output so you canuse this for you know SQL python allthis kind of stuff you can take thedifferent code generated and thenexecute it and then whatever the mostpopular output is that's what will getsent as the answer okay so we're in theopen AI playground and we're going todive deeper into how consistencyfiltering works so the idea is thatwe're going to sample diverse candidatesfrom large language models as we decodethem with Randomness we have temperatureset to one and we're asking the languagemodel please write a one sentencesummary of kubernetes for afive-year-old please be as creative aspossible so the first time we ask itthis it says kubernetes kubernetes islike playing with Legos to build asuperhero City in the cloud okay so thatwould be you one potential generationthen we sample another generationkubernetes is like a magical box thathelps get your work done faster sothat's an example of how we can sample ayou know diverse outputs this is similarto the idea of like tree of thoughtswhere you you know go down all thesereasoning paths so maybe another examplewould be uh you know how many people arein America please show each intermediatestep as you you know determine thisanswerand then so this is kind of likesomething that maybe requires reasoningsoyou know it's sort of like ahallucination also to ask it to do thisbut okay so it came up withcalculated people so it's saying youknow 331 000 so this is like the finalanswer so then consistency filteringwould be we just keep sampling from itand then see if it keeps coming to thatsame 330 Million number I don't know ifthis is the best example of that but yousee how instead of doing the step two itjust did it after step one you do thiskind of thing but for writing pythoncode SQL code you sample a bunch ofdifferent Pathways and then the finalanswer because in question answeringconsistency filtering is just about isthis answer the same whereas with codeexecution filtering you take the greenthat it generated like you know write aPython program for bubble sort and ityou know write this python code and thenyou would put that into the pythonexecutor and then consistency of theoutputs so quickly before diving fullyinto the results the authors do find asignificant benefit by doing thisconsistency and execution filtering yousee you know no consistency down to 77then the execution filtering 79 comparedto you know up to 83 with the exactmatching or the execution accuracy ofthe SQL queries so I think this is asuper interesting idea for this was oneof my favorite ideas and say the Langchain chains is taking the output of thelanguage model putting it into the saythe python reple and then seeing theoutput and then chaining where thelanguage model then sees the output andsays okay is this the output the authorsactually are going to conclude that theydidn't find good results of putting theerror messages for queries that didn'tpass into the back into the prompt andsaying hey here's the error that you gotfor this but I think generally that kindof that I mean like that's how Ipersonally code as a human right is Isee the error and I iterate on the errorso I think there's probably something tocontinuing to mine these chains ofexecution filtering okay so let's diveinto the results now that we have anunderstanding of what the spider dataset is what it measures these text SQLtranslations given a schema as well aspart of the input and we have a sense offew shot prompting versus sayfine-tuning the model as well as saythis consistency filtering executionfiltering concise prompt verbose promptablation so firstly what we're seeing isthe comparison of these few shot SQLpalm versus the fine-tuned SQL Palm sothe first interesting detail is thatthey don't find much benefit byfine-tuning the model this is actuallyan absolutely enormous detail because itit simplifies using this like crazy likeif if you don't need to fine-tune themodels and you don't need to think aboutlike all this stuff around constructingthe data sets the batching the you knowthe the evaluation or the modelversioning all that kind of stuff thatwould come with if you really needed tofine tune these models to get it to dotasks like that so they do find goodperformance in the fuse shot I mean it'sprobably worthnoting that say we're doing the weeviatetrend we're writing weeviate aggregatequeries or you know you're trying tocustomize this to any arbitrary API itmight it might not have as much domainknowledge of that in the pre-trainingdata because surely palm and itspre-training Corpus has SQL examplesinformation about SQL in it so thatmight be slightly biasing the results aswell but super interestingly so we'reseeing 82.7 from the fuchsia modelcompared to 84.1 from the fine-tunedstate of the art another kind of Reasonthough the fine-tune state of the artmight be a little more interesting isbecause of this three billion parameterso it's gonna be a little cheaper to runthis is another one of the big Topics indeep learning is can we use maybe thesemodels to generate training data to thendo knowledge distillation and then havea much smaller model that costs us lessfor inference so you know is it reallyworth it if every time we run thesequeries it costs us like two cents totranslate it to the SQL especially whenthe large language models are doing themautonomously so it's an interestingdetail these three billion parametermodels that are you know pretty on parand we could probably use these modelsin a different way to distill them butnevertheless if you're a trans likeagain is using this example of theweeviate aggregate query translation Ithink that's the most interestingmotivating case of the few shot becauseyou know you're you're getting it tolearn this new API as fast as possiblewithout collecting train data oranything like that so here's anotherexample breaking down the performancefrom easy medium hard extra hard so youknow probably the biggest takeaway isthat you do see this like monotonicperformance decrease from easy to mediumhard extra hard so that's a prettyinteresting detail of this so especiallyif you're you know planning on if you'reinterested in designing systems likethis if you should probably have somekind of maybe a classifier that says howhard the question is stuff like this orjust generally logging the queries thatfail and overall trying to work to getthese models to perform better on thehard questions but just an interestingthing to seeso then we have the variants of spiderso again we have the synonym replacementuh the more realistic questions whereyou deleted any mention of the columnname and then the domain knowledge Iactually wasn't really able to figureout exactly what that is so uh socomparing with the chai gbt open AIdefault prompt this is another reallyinteresting detail I'm sorry I forgot toshow this in the video but open AI theyhave a recommended prompt for writingSQL queries so what they're showing isthey're uh they're more verbose problemswith the consistency filtering executionfilteringimprove the performance and then you seethe robustness across the uh thedifferent data sets you know it's stillthis three billion parameter model isdoing a pretty good job which isexciting because this would be cheaperto runso then we have the ablation of theconcise versus verbose prompting sointerestingly the concise promptsperform better which they perform aboutthe same but like the you know notreally giving it these long descriptionsof the properties I think it reallydepends on this and you know we're gonnaI think the verbose prompting is moreexciting going forward for the k for thecase of filtered Vector search with thatself querying retriever thing because wewant to you know filter it based onproperty so I think it needs to havesome sense of what the properties arelike what the potential values that youcould filter with so definitely aninteresting topic as well so here's somediscussion topics from the authors theysay that you know once they fine-tunedthe model so you know converting this tothis the sampling diversitysignificantly reduced so that kind ofconsistency filtering executionfiltering they had less diversity andthus that technique on top of theinference was less effective they alsofound that as mentioned earlier theself-correction giving it the errormessages when it doesn't work that thatdidn't work that well which I thoughtwas kind of interesting and then theyfind that you know that there are someproblems in evaluation data set theygive this comment that many of theerrors are actually correct according tohuman experts so here are some of mypersonal Reflections and takeaways afterreading the SQL Palm paper so first ofwhich I think coming up with some kindof Auto API for weviate aggregate Ithink this is low hanging fruit itdefinitely seems like something we canachieve with using the openai largelanguage models or the Palm that's justany of these large language model apisthat we already have in place for saythe Eva generate modules we couldsimilarly put this after the query totranslate it into these aggregatequeries which then the next question ishow exactly we want to design thispipeline so maybe it should First TakeYou know the auto API should be soopen-ended that you just have a queryand then the classifier or the languagemodel first says is this aggregationquery or a get query and then the thirdthing so so this is kind of just alittle layer on like is this anaggregate query or is this a vectorsearch query and but you can also applyVector search within here to you know tosay you want say you have tweets and youwant to say like like you know similarto this tweet you like exactly paste thetext for your new tweet and then youwant to aggregate I don't know say likethe likes or something from that I'vegiven a talk on this at odsc Londonthat's also on alleviate YouTube ifyou're interested in that kind of topicof the combination between Vector searchand then symbolic aggregations I thinkit's a pretty interesting topic butanyway getting a little distracted butso then what I want to talk about isfirst of all this query routing ideaso first of all imagine you have twodifferent classes in weeviate you haveall the podcast podcast transcriptionsand then you have like the Wii V8 codebase and you're asking a question likeyou know how is this particular thingimplemented first asking that questionthe language model of which class shouldyou search then this idea that I lovewhich is which filters to add so this isthe you know self querying retriever youask what is a golden doodle and imagineyour passages have this attribute aboutwhich animal they're talking about youcan then filter the search spacedramatically with that so say we havelike I don't know we have like a 5million scale passages about animals sothen asking it what is a Goldendoodle ifyou can do that filter where animalequals dog then you dramaticallysimplify the search space so it's apretty interesting thing thinking aboutthese categories I think it's moststraightforwardly manifested with youknow like price filters so say you youknow like take a picture from a shirtfrom like Louis Vuitton or one of thosedesigner Brands then you just drop thatinto Amazon you say you know imagesearch shirt like this for you know lessthan a hundred dollars and not having toknow how to parse out the wear filteringthe the large language model under thehood parts of that out for you the nextreally interesting topic I think isconnecting surge primitive so you knowwe have these you know we have all sortsof different features for search and weV8 so say you have like you know youobviously have the wear filters we justtalked about but you also have Vectorsearch bm25 Hybrid search or say youwant to re-rank the search results canwe kind of automatically construct asearch pipeline for doing this kind ofthing and then sixth thing is thisconcept of generative feedback loopswhere we take data from the database youknow send it to the large language modeland then save the result back to eviateI think in a lot of cases these you knowlike when you're doing these kind ofsymbolic aggregations you might want tosave the fact that you derived maybe asa natural language fact into some kindof Text corpus like I know generallylike when I'm using SQL like back when Idid that kind of thing I if I had aquery that was useful I would save thatquery for reference later so I wouldn'talways have to remember how to write itso maybe there's something to that insome kind of connection with generativefeedback loops but overall my takeawayis I think this kind of idea ofautomatically writing these kind ofaggregate queries exact same ideas thepaper I think that's also something thatwe could achieve in Wi-Fi and it's quiteexciting so thank you so much forwatching this paper summary of SQL Palmagain if you like content like thispaper summary content please leave alike And subscribe to the channel itreally helps encourage us to make morevideos like this please check out wevv8on weavate iO or the open source GitHubrepository weband please follow us on Twitter atwebiate IO thank you so much forwatching", "type": "Video", "name": "SQL-PaLM Explained!", "path": "", "link": "https://www.youtube.com/watch?v=g3ocV0a_G2c", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}