{"text": "Thank you so much for watching the 42nd episode of the Weaviate Podcast! Ethan Steininger is the founder of Mixpeek, ... \nhey everyone thank you so much forwatching another episode of the weviapodcast I'm super excited to welcomeEthan steininger uh Ethan is a prolificentrepreneur who's created a mixed Peakand Kali and he's really got ourattention to someone who's building coolthings with weeviate and generally inthe uh search and AI space master ofsoftware engineering so Ethan thank youso much for joining the podcastI definitely don't know about master butI appreciate the enthusiastic introawesome uh so maybe to then could youdive into your kind of background insoftware engineering and search maybeyeah maybe search is more the masteryeah I'm actually only recently uhimmersed in the search ecosystem but Iguess that doesn't act as too much of adetractor considering the industry haschanged so much in the last year aloneuh so my background is actually as asoftware engineer went to school forprogramming actually started a lot ofprojects a lot of startups most if notall of them have failed uh so I've gotmy own if you've ever seen the killed byGoogle website I've got my own graveyardof projects and GitHub repos Etc thatI've abandoned so no shortage of failedprojects but uh my foray in the searchwas actually at my most recent job whichwas at mongodb uh they made the decisionto actually embed leucine which is likethe core for those unfamiliar withlucian's the core open source librarythat powers elasticsearch solar and aton of other search engines out thereand mongodb decided to kind of embedthat open source Library within thedatabase and coupled it together andbecause that's such a novel concept atthe time they needed a special SWAT teamto help take that product to Market andso that's what I was summoned to dowhich was really just a matter ofdefining the the customer profilebuilding out technical collateraltalking to customers and being that kindof liaison to the product who's actuallyI won't mention his name but he's one ofthe formal advisors of of weevier uh andactually one of my old-time mentors whenI first got into searchbut that's kind of how I first got intouh the industry just being summoned tosupport the go to market of mongodbsearch productthat's so interesting yeah learningabout uh well I guess I'm kind ofcurious about this like leucine mongodbmaybe I'm very like I don't know if it'sthe most entertaining podcast topic butI am very curious like like what arethese Technologies kind of like umis it too because I know so little aboutthis kind of world I've like kind of Ijoined wevie coming from like the Deeplearning background of being veryinterested in just kind ofrepresentation learning optimizedvectors and then sort of and then sofrom there I came into likeelasticsearch Lucy and solar hearingabout these things so I would even maybetalking a little more about like what isthe underlying technology of andsolar and these kind of things yeah Ilove the fact that you take most thingsfrom a research angle like that the howdoes it work uh which is something thatI need to get better at but I'vehistorically tried to figure out likethe the positioning of the product andlike what kind of immediate businesspain is does it solve I was in I was asales engineer at mongodb uh but underthe hood it's really actually quitesimple I mean every database has achange stream API uh my sequelDynamo they all have some kind oflistener that you can open up up like acursor on the database so anytimethere's a change you get alerted of thatchange and so the Architects behind thatmongodb searcharchitecture they basically coupled thechain stream cursor API which listens inon changes and replicated all of thosechanges into a leucine inverted indexand so once you have those two datastructures together then they basicallycreated a a wrapper on top that exposesif it's called the aggregation pipelinein mongodb it's kind of like thequerying language they expose thisaggregationstage that allowed you to run a searchquery on the leucine inverted index andthen once you have the results of thatsearch query it would actually pipe itback into the mongodb database whichwould allow you to do uh kind of youhave the term hybrid search that'shybrid if you had like database queriesuh but I know you guys have hybrid as inlike TF IDF plus Vector search so uhit's a little bit of a differentpositioning where customers that reallyvalue the acid compliant properties of adatabase and want to combine that withthe uh with the full text searchfunctionalityyeah that's so interesting and I I thinkI was really curious uh you've writtenthis great article on the ml stack whereyou have the acid compliant thing andthen we get and I was like Olivier hasthe database stuff too I was like do younot agree like I'm curious like is theresomething to the acid support in um that's left out of weave yet yeahI wouldn't say there's anything left outbut I as someone that has sold toEnterprise customers for a long timecustomers are reluctant to change theirsystem of record right and so like whenpeople are already using a or evenan Oracle and they're using that astheir source of Truth their theirdatabase it's a lot easier to tack on anexisting search engine and have thatjust be coupled together via some kindof streaming technology rather than justreplacing it all together so I I'm surethat the the weeviate database API setand methods are are super robust to justthinking about it from customerstandpoint unless you're a startup andyou're just doing something new for thefirst time they typically have bigcustomers typically have a lot of uhLegacy code data stores in Old databaseEtc but it's a good questionyeah that's interesting and I I'm kindof coming back to something else yousaid earlier about the mongodb aggregateuh pipeline uh Sebastian would Alexaalso former uh and and now Olivierhe showed me like this kind of aggregatething in the uh like thinking about thevva pipe design and all these differentfilters that can be attached to ev8 Ithink it's so interesting like the yeahjust all these kind of things you can doto it so maybe pivoting topics um canyou tell me about kind of the foundingVision behind mixed Peak and and theproblem you're tackling yeah one of themost common problems that I hadexperienced so I I was traveling theworld talking to our most challengingcustomers when I was at and one ofthe themes that I had learned aboutpretty much every week if not every daywas really that of how do we search thecontents of files and most of the usecase was really PDF files just becausethese were mostly Enterprise customersEnterprise uh companies have a ton ofPDFs spreadsheets even like doc filesdocument files uh and so I was justbasically telling them all to hey likeyou got to create this framework andthis architecture and you're using Tikkaand you're extracting the Tikka contentsinto your search engine you're doingchunking and all these things and it gotto the point where it's like all rightthis is a big enough pain I've seen thisenough and the vector search uh projectswere becoming more and more popular uhand this was right around when Lucine Iforget which version it was but it'swhen they first introduced the vector kn uh capability into uh the the coreleucine branchand uh that really unlocked a lot ofsuper interesting opportunities and uhdecided to to quit and build thatout full time and then I'm very gratefulto have raised the seed round from someinvestors and that's given me a littlebit of a cushion to explore some ofthese really radically changing areas uhI've I've been talking to a lot ofstartup I live in New York and I've beentalking to a lot of startup Foundersaround the New York City area about likehow has your road map really changed inthe last three four months and everysingle one of them is like yeahdrastically we've pivoted sosignificantly to keep up with all thesechanges and like open ai's plug-inMarketplace was just announced yesterdayand you best believe at least thousandsof startups are going to be consideredmoot because they've just built wrapperson top of the Chach EBT API so we'redefinitely about to experience an appleto App Store like uh paradigm shift anduh I'm super impressed that we V8 I sawBob's post we V8 is on the the plug-inMarketplace you guys are well positionedto be that default Vector search enginethat wraps on top of Chach EBT right outof the box so uh but yeah that was kindof like the intro to why I started todevelop mix Peak and at its core it'sreally just a multimodal indexingembedding and search API so we take allthe messiness around the database the uhkeyword search the vector search thefile parsers the file extraction andfinally the search and we just exposedit as two API calls with re-rankingchunking analyticsEtc all baked inyeah amazing that I think there's a fewthings on that I think I'd like to comeback to the uh chat gbt plug-in becausethat's such an interesting topic butfirst I really want to just kind of pickyour brain more about the mixed Peak uhgoals and so so on this idea of and Ialso think maybe we could talk aboutKali as well this like really nice userinterface for getting like dropping PDFsin and then it's in the vector databasein the chat gbt thing like all this kindof ranking all that is like accessibleum so I I'm so curious about this kindof data ingestion like kind of I thinkthe PDF ingestion with like I I recentcalled it OCR on the podcast with Dennisyou from mem and he said no it's it's sopowerful that you can't call it OCR likethe way that gbt4 he said it's likehaving a human looking at your PDF butshortly these things will just make itsuper easy to get PDFs into you knowVector databases and stuff like that andyeah all that so I'm curious kind oflike how do you see this these uhInnovations and maybe like this llmenabled ETL for unstructured data kindof as well as this kind of chunking idealike what are some of the opportunitiesmaybe around chunkingyeah uh I think one of the mostimpressive use cases that I saw for gpt4uh by the way uh there was a paper thatwas just released by Microsoft researchI believe two days ago the 22nd today'sthe 24th all about hey we think thatchat gbt4 is demonstrating a spark of ofartificial general intelligence and inthat paper they used a couple of usecase examples one of which was like yousaid somebody provided a picture and itnot only described the picture but itextracted the contents from it obviouslywell beyond OCR it's like a human isinterpreting it uh and that again thathelps us kind of position what we thinkis the most valuable and at its core Imean this is my theory on like a lot ofstartups are having existential crisesright now uhand like chat gbt is rendering a lot ofthem Moot and so what I'm what I'mtelling anybody that's asking is likeyou need to get closer to the businessand you need to understand what theirpains are and build phenomenal userexperiences on top of that right and soif you think about who your user is forme I'm building an API so my userexperience is the developer experienceand if I can really nail that developerexperience and make it as sticky aspossible that's my mode that's mycompetitive modeand I advise the same thing for anybodyelse because like in the end of the dayand this is what I've always told peoplethat challenged when we were positioningmongodb's Atlas search in the end of theday any engineer can build anythingreally at its core I mean maybe it won'tbe as good it won't be as robust itwon't have high availabilities servicelevel uh slas uh but they could build itit's just a matter of like hey do theywant to and B is it as intuitive andclean as you could so definitely acouple of existential threats there butas long as you're getting close to thebusiness and understanding the pain thenyou're in a good spotyeah it's so interesting I really likekind of the story that's emerging in ourpodcast so far of like this kind of likecustomer success oriented sales engineerthing and how that leads you to thinkabout how the perspective that createswhen you're building this kind ofstartup in the space and yeah sointeresting maybe kind of staying onthis topic of moot existential crises wecould come back to the chat gbt uhretrieval plug-in um it's yeah it's sointeresting this kind of like uh themarketplace for chat gbt being likehosted on the UI because we saw so muchwe saw so much like building around theAPI like uh like Lang chain llama indexof the two things that I've been superinvested in learning is like these youknow building these kind of appendagesaround chat gbt rather than kind of theChad gbt UI like hosts the apps and yeahI'm just curious what your perspectivelike I think it's such a fun likeemerging topic is is like is this goingto be the App Store kind of or likebecause yeah or would it be like the APIlike just how do you see the that kindof spaceyeah I'd I'd wonder and obviouslyeverybody's just like conjecturing rightnow but there's really two Avenues Ithink it could take it's really eithergoing to be a zap here like experiencewhere you could just combine all thesethings together I can use chat EBT to bethe link betweenI don't know my Roku with my Alexa andmy thermostat right where catch EBT isthe link between them all where the kindof adhesive the glue is my humanlanguage do this than that whateverthat's one area and the other is reallyjust like a standard marketplace whereyou can procure services from within thechat gbt like interface I saw a coupleof examples where people were bookingflights from within Chach EBT so thatcould be that single point interface forall of the apps within the marketplaceit's probably more so going to be thesecond rather than the first because thefirst I mean there's really not muchmoat around just being a glue betweeneverything but the first is really likeif this is your default entry point forgetting anything done accessing theinternet your calendar your trips thenthat's it's remarkableyeah wow that is I mean umuh yeah it's like the the business modelthe mo is super fascinating like the umobviously they make like I think it'slike 20 a month is the cost for this UIright like to even access the app storebecause it's only can is it is that acorrect understanding firstly that it'sonly the paid version that has thisPlug-In or I'm not sure about that but Iam a very proud gpt4 subscriber so I'llfind out soon yeah I'm subscribing aswellit's funny I feel like uh no offense toanyone that works at Google but the lasttime I've Googled it I'm a I'm codingall day the last time I've used stackOverflow is like weeks ago it'sexclusively been chat EBT which isreally demonstrating a significantparadigm shiftyeah I've also been just why I also amso excited to check out uh copilot X Ihaven't yet uh like spun it up yet but Imean the the ability of it to write codeis amazing like my kind of story withthis is that you know we've yet it'swritten in golang and I don't reallyknow golang but I can like be with thehelp of Chad gbt it's just making thelearning curve like so much quicker likeI you know if I say hey I need you tosort this list like I have thisdictionary I have these keys I don'teven need to know about like the mapinterfa the map thing of golang it'llwrite it for me and then once I see itnow I can quickly adapt so that's Iremember there was this paper fromFacebook that came out like three yearsago is like translating betweenJavaScript and python I was like wowthat's so ambitious but yeah now it'slike I thinkyeah what I would love to talk moreabout get your perspective on how yousee how uh gbt4 helps your codingproductivity because for me that kind ofhelped me learn a new language has beenjust the biggest one yeah well before Ianswer that question I think that thereis a big opportunity around using thislarge language model and really others Imean we shouldn't only focus on chat gbtlike open AI is doing really well uh theopen source models are super exciting Iknow that uh llama Stanford's llama isis generating a lot of hype just becauseit's smaller it's more lightweight itcan run with on less CPUs and it's opensource so uh just well there's there'sother options out there uh but at itscore like what I've been doing is I meanchat EBT for any use case in the uhwe'll call it content creation so codecopy whatever it it really just servesas like providing a framework for mostthings it's never really producing afinal copy maybe for like a one-lineemail it will but for code I mean noone's just dropping it right into theircode and deploy into production like ifthat happens then we've got things Glorynow but I think we're a far ways fromthat uh let Famous Last Words obviouslyoh yeah so I think the like the Llamaalpaca thing one thing about that that'sso interesting to me is kind of like thelicensing of it like with llama it itdoesn't have a commercial license likeyou it's like I think it's like just forresearch purposes so like the L packetslike you can use it for your phone butyou can't like just use it and I thinkthat is another interesting thing likeopen AI they have this thing wherethey're saying um you can't use themodel to develop models that competewith openai so obviously like theknowledge distillation thing is like youcould just copy the outputs basicallyand take any model so yeah that wholething around like what you can use themodels for is so interestingyeah uh I wouldn't be surprised if thereis going to be need to be a likeprecedence uh shift around licensing forsome of these code bases these modelsbecause like I'm sure that there is someuhfinagling around the legal definition ofLicensing when you've really trained amodel on the entire closed Sourcedatabase of GitHub uh so I I wonder ifthere's going to need if anybody is apolicy maker out there that's aconversation that probably should be hadsooner rather than later because like isit is it really fair to have that uhline item in your legal statement whereyou've kind of done something differentI don't know uh but alpacas the wayalpaca was trained is really reallyfascinating I mean they really juststarted with this open source library orthis open source model called llamawhich I think was like seven billionparameters they started with that opensource model and then they basically sowhenever you uh whenever you fine-tune auh we'll call it like these cheap gbtmodels you provide prompt completionPairs and what Stanford did is theyactually used chat EBT to generateprompt completion chairs and they uhPairs and they actually created afeedback loop of uh positive versusnegative rejecting versus acceptingthese prompt completion Pairs and fedthat into llama and I guess that marginof new new pairs has got it to the levelof really competing with the GPT uhmaybe not four but maybe the three uhwhich is which is super valuable likeimagine the the example that I alwaysgive is really like imagine these largelanguage models at the edge right if wehave an llm on our phone or even likesome off-grid deviceit's able to of it's able to consume anykind of input and generate an outputagnostic of its connectivity to theinternet and using all the data thatit's connecting it's kind of training onthe fly at the edge in real time it'sit's really a lot faster so that couldbe like another convergence of the twoFields is like this Ai and iotum it's the really first time I'vethought about that I don't know whatmore use cases beyond what I just madeup are if anybody has any of them feelfree to share yeah the the iot thing isjust it's super interesting I I don'tknow if this is productive to mentionbut I like I I took a little grad classin graduate school class in like um inthe in the Internet of Things it wasabout like monitoring buildings and howyou like send a pulse in one part oflike construction like you know buildingand construction and networks andthey're like okay the building is okayright and thinking about like I don'tknow could language models in that be beproductive or something like theInternet of Things topic has always beeninteresting that I've known a little bitabout not too much but anyway sopivoting to the first thing you saidabout how alpaca was trained in thiskind of reinforcing learning from Humanfeedback thingum I think I'm thinking a lot about likeas impressive as Chad GBC is what if Ifind like what if I fine-tuned it andlabeled it on the prompt completionsthat I like like you said like I think alot about this like like I've had a lotof conversations with like JonathanFranco at mosaic ML and theirperspective on uh businesses wantingtheir own custom language models I'vealso talked to Nathan Lambert about uhhugging faces reinforcing learning fromHuman feedback and like surge Ai and allthese things like how this might emergebecause I think about like let's say Itrained a language model on like theweeviate slack like and then I startlabeling its Generations I feel likethat's just going to give me somethingbetter than Chachi BC yeah yeah and andthat's a really interesting point andthe exact direction that I'm taking withmix Peak which is around like domainspecific data sets right so I mean whatI'm finding and really everybody'sfinding is like exactly right I meanit's nice that chat gbt understands theinternet but maybe the reason why therevenue model isn't quite sound yet isbecause they're just hoping that Conorand Ethan pay 20 a month which theyhappily do but the real the real moneywill always be in the B2B market and notonly the B2B Market the Enterprisemarket and so there's a ton of companiesout there including me includingincluding mixed Peaks that are reallytrying to understand a company'sEnterprise uh let's say knowledge baseand training models maybe they'll callthem agents trading these agents aroundunderstanding that data and thenproviding some kind of chat gbt likeinterface on topuh there's so many sources ofinformation there's slack there's jirathere's uh email inboxes Wiki like thesecompanies have so many differentsegments of uh of knowledge and they'reall really like very well formatted LikeFor Better or Worse their q a like slacksomeone asks a question I'm sure in theweeviate slash Channel there's an answerand that's a very obviousprompt completion pair that can be sentto a gbt model so to answer yourquestion I think that there's reallygoing to be a strong push towards uhtowards customizing models but what I'malso really interested in is like wherewe V8 comes in is like you guys have asearch engine and the search engine willalways be the source of Truth and I wasactually on one of Bob's uh Twitterspaces I forget it was somebody fromcohere as well and I asked the questionhey like what do you guys think abouthow generative models and AI how doesthat contend with the search landscapeand a lot of I mean my initial thoughtwould be like it's replacing searchobviously because you can createinformation rather than retrieve butafter hearing Bob's great explanationand doing a bit of research there willalways be the need for kind of likereferencing the source of how it came tothis conclusionuh in perplexity AI has a great UI forthat I'm quite fond of theirs and I'mmodeling uh the interface that we'rebuilding on top of uh Kali around thatthat interface which is really likeand I'm not I propose this like opensource framework for kind of creatingthe verified truth of generative uhresponses and it it really involves thissearch engine you embed an entire Corpusof content then you you chunk it so thateach one has its own meaningfulimportance like modular meaningfulindependent importance and you embedeach one and so then you run alleviatequery across those entire embeddings youget the ones that are most important ormaybe the top K most important and thenyou feed that into a chat EBT and sothen Chachi BT has a little bit ofcontext and it understands that littlebit of information that can then be usedto either create a summary or an answeror something so that's how I'm seeing alot of people combine the search plusthe generative and I see that as being apretty standard frame framework forcreating these things and I just wrotean article that was like here are allthe steps that that need to happen to dothat because I've built this internallyfor we could talk about Kali which islike a really simple user experience forembedding search on your application butlike I've seen and built this frameworkenough where it probably makes sensewhere someone uh standardizes it so ifanyone's interested in collaborating onthat happy happy to talkyeah super cool and um oh yeah I lovethat topic I think kind ofone thing about that that I still thinkis so exciting was kind of like thefirst thing is like right now thegeneral how do you take the context andput it into the language model is likeyou just put it in the input like theinput is like you know please answer thequestion based on documents documentsyou know go for it whereas there is thescience is looking at these models likeuh deepmind had a model called retrothere's like these fusion and decoderlayers there's this uh memorizingTransformers where you would uh to keepthe embeddings keep the vectorembeddings and then you say you like putthat in layer 9 out of 12 of thelanguage model and so this has reallyinteresting scaling properties becauseuh you can you know the way that you cankind of like transpose the matrixmultiplication you could put like prettymassive uh documents into these modelsand attend over more context so I thinkthat's an incredibly exciting part ofthis is that I don't think we've seenyet the full power of these retrievalaugmented language models and what theycan do when they can take in re reallymassive context and then yeah as youmentioned I read your article as welland I've obviously I mentioned earlierI've been studying like Lang chain andllama index and all this kind ofthinking of like okay how exactly are wegoing to organize the um you know thesearch results to present it to thelanguage model is such an interestingtopic um yeah maybe we could talk a bitabout this idea that the Llama indexidea like there's one thing that Ireally like about this integration whereit's like you retrieve a hundred resultsfrom wevierand then you need to like extractstructure from those results beforehanding it to the language model and thelanguage model kind of use the languagemodel is what's used to extract thestructure as well so it's if it's likeyou want to turn the top 100 resultsinto a Knowledge Graph you're using thelanguage model to go like what kind oflike relational triples are in this andit parses it out and then you have thisnew thing that then goes into the inputto like another language modelso kind of like yeah I'm just curiousyour thoughts generally on like howexactly do you hand the search resultsto the language model and how muchopportunity is there maybe for moreinnovation in thatyeah uh it's a good question I haven'tactually explored the exact use casethat you just had I love the idea ofinstructing the creation of a KnowledgeGraph uh and actually that artificialgeneral intelligence paper by market byMicrosoft's research team actuallyshowcase likethey instructed Chach EBT to ask asequence of questions to understandsomething I don't I forget what it was Ithink it was like the interior of ahouse and it demonstrated the creationof a mental map of that house that wasaccurate like a visual diagram of howthat house is laid out from just askingquestions so uh I I'm constantly findingmyself not only a maze but like uh I'mfinding myself like asking like whyaren't I just using chat EBT to uh likeeven like an ETL an extract transferload kind of uhactivity they're they're very suitablefor that I think the challenge that Ihave with like even feeding I think yousaid like 100 or so items likeyou're gonna fast come up to the uh thetoken limit for Chad EBTand I'd be curious from your standpointis that a something that you see goingaway and B I mean this is the first I'veheard about like the layering of llmswhich really would solve a lot of thosetoken uh upper bound issues because ifyou can just likeI I don't know enough about to even likeexplain that but uh seems like thatwould address a lot of the the thechallenges with like feeding your entireCorpus in one point to the the Chachi BTAPI rightyeah I mean I'm just fascinating on thistopic this has been kind of the numberone thing in my mind lately is likethese like text to SQL is kind of thestarting idea where the language modelis like writing an SQL query to getinformation out of the database but Ithink we're thinking about like okay howdo we do this with weaviate how do weget the language model to use thesymbolic filters so it's like if I let'ssay I have the weviate code bases likethe thing that's too many tokens to justput it all in there at once so we needto like cleverly search through it andwe have these kind of symbolic filtersof like the um like the folder structureI think is a really good one for theseyou know big code repositories you knowyou have like modules is here like reposadapters these kind of things and it'slike how do you tell the language modelhow do you prior it like um a promptosorry prior how do you prompt it to sayum you know you have these categoriesthat you can filter your search throughso like do you only want to look throughlike you know this particular folder ofthe project structure I yeah that kindof thing of like umgetting the language models to use thedatabase interfaces so are you sayingthat the repository the the weeviatecode base repo is an ancillary to thequerying language and by understandingthe relationships between the foldersand directories they can they being theGPT whatever it can then understand howthese manifest into the queriesthat yeah that idea is the one that Ithink is um yeah yeahI think that I feel sick tooit's like the um because it's uh thisGeneral thing is on it on any code baseright yeah I think that that linkingthat that does imply that your softwarearchitecture is like really well mappedaround like the methods that you exposein the query language too like you saidthe modules theuh I don't know enough about you said itwas written in Rustyeah yeah exactly this because all thesecode bases have this kind of and that'slike the thing is like the structure islike um like we're talking with Dennisabout mem and these like you know likeworkspaces where you create a workspacelike I don't know like you have somechapter of your molecular biology classand you're like and then you keep likeyou create a page and then you addcontent and like there's like thisstructure as well and I think thisstructure is really well captured andlike weeviate has the symbolicproperties as well as the vector searchand then the filtered Vector search islike made crazy fast like this bitmapindex thing of like these intense likefiltered uh disk and is a paper thatjust came out another like exciting ideaof how you integrate those two thingsbut yeah it is just such an interestingtopic um so maybe there's something Ireally want to come back to with themixed Peak and the uh specific problemsthing is and then we touched on italready with this idea of how alpaca wasfine tune with like a different data setof reinforced learning from Humanfeedback but how are you thinking aboutfine tuning I always I ask everyoneabout this topic because I love it okayso I'm gonna caveat everything which isby saying that like I I have a team ofreally brilliant Engineers that I'mworking with and they're the ones thatare really creating like I'm kind ofcreating the uh the little bit of anabstraction layer on top of like thinkof it as you have core services and thenyou have like routers on top of thosecore Services uh the really impressiveteam of Engineers is building like thecore embedding inference and uhre-ranking and fine-tuning models but Ithink we actually talked about this atthe weeviate Meetup Connor which is likehow or maybe it was your colleague but Iwas I was asking like what are some ofthe like really suitable production usecases of learn to rank right and I knowlearn to rank isn't quite fine-tuning Ithink there's probably a little bit of aNuance but uh I think that likere-ranking results around the previoussequence of some kind of uhsignal that a user has and reordering itbased off of some kind of conversionmetric that's that's exciting but Ithink at its core again it goes back tounderstanding the end user so like forexample I'm exploring with this Kali usecase which is it's really like anembedded search bar on any website it'sjust like a JavaScript widget that youcan embed on your site that understandsall the files and the directory of thefiles and I think if if we're able tokind of track the activity of a useracross a number of pages uh we cancreate kind of analogies between heythis sequence of activities which user aconverted and converted is just a metricthat is specific to this company somaybe if it's an e-commerce company theybought a chair or if it's a weeviate uhcompany they deployed some kind ofinstance so everybody has their ownmetric that they use to define inconversion and so if we can build alearn to rank model that is actuallyreordering the results based off thepropensity to convert then I thinkthat's really attaching ourselves to thegoal of the businessuh but I realize that's a little bitdifferent than fine-tuninguh well yeah no I I think there is arelationship but uh yeah we'll come backto particularly like what kind of funthing but yeah learning to rank I lovethis topic uh yesterday I record apodcast with um Erica from leviate andRoman and Siva from meta Rank and so ohyeah great people right yeah and so thiskind of idea of uh you know using likean XG boost style model that takes inlike user features as you mentioned likethe um there's like the interactionevent obviously like I think people areaware of this kind of like you know youpeople they collect click data about youand like when you like exceptyeah so so this kind of layer it I meanI guess um I think I at this kind oflearning to rank thing I think I'm verycurious about like the generalization ofIt kind of like the like because you'reusing all these features and I I wonderif that's going to be as kind of robustas like the content only based crossencoders and then I one idea I think isextremely interesting is maybe takingthese tabular features and just kind oftranslating them to text and just makingit a text based input and then you knowthen you can access the transferlearning kind of part of it wherethat's what I think is kind of thefrontier of learning to rank per and Iyeah I was I think umlet me just make sure I understand thatsaid differently we have user a thatgoes and clicks a button on the firstpage and then Scrolls down to the secondpage and then clicks another button onthe third page that's three differentsteps that can be mapped to text uniquetext and then that sequence let's sayit's an array of strings gets sent to alarge language model or whatever andthen the embedding is generated storedin a search engine and then you can runlike sequential inferenceis that kind of maybe not yeah yeahthat's well you you yeah like thebecause you kind of confused me a bitlike in changing my understanding withhow you're describing like the scrolldown the interaction because I I supposeyou could collect a crazy amount oftabular features that might be too muchto translate into text but then I alsothink if you're collecting that manyfeatures you're going to overfit to somepattern in this feature Vector thatyou've done like you know scroll downfor three seconds waited for two secondshovered over this for five seconds rightlike I feel like if that kind of vectorthat kind of feature engineering isgoing to overfit but yeah no that'sexactly it is like um you translate itall into text and then like I thinkabout um if I had some kind of userdescription like usually cross encoderis like query document but like if itwas like query user description documentyou know I don't see why that wouldn'twork just as well and then also you useda large language model to do that kindof reasoning and then you distill itinto like the 20 million parameter crossencoder that runs crazy fast andand then the the topic then I think isum you know they'll need to be likesoftwarelayers to make that kind of thingaccessible right like um trainingranking model that's what I reallythought that meta ranked podcast wasgreat because I I really like whatthey're doing how they've built the likeml Ops just for ranking I think it's apretty cool Niche like uh yeah becauseyou have all the how do they do it ifyou were to summarize in likea paragraphwell as I can say like coming from thebeginning of it my interest withintegrating this to weviate was likeweevia has this module system where youaccess the retrieval from you know likevector search Hybrid search with thesymbolic filters and then you can pipethat into like a question answeringmodel and so we could also pipe thatinto these uh ranking models and so it'slike if if we can just make that API toThe Meta rank services so metal rankdoes the full set of like the you knowinference hosting the model like the youknow how you do the data ingestion howyou do the model versioning thevalidation that is like quite a packageof ml Ops things and yeahyeah I uh while I was actually atI was trying to do my best on educatingthe entire Solutions architect org whichwas like 400 people at the time aroundVector search and from interviewing allof the companies that were exploring itwhat you just described were the biggestpains around it which was like okay howdo we do model versioning where do wehost the models how do feedback loopswork uh what's like the best referencearchitecture for the ml Ops to to handleall of thisuh what I'm finding is like I'm forcedto store model versions as like a stringand some kind of other uh data store andthen create an index for all of thosedifferent model versions because as youknow if we just tune a model evenslightly it kind of renders all theembeddings Obsolete and that poses anentirely new challenge which is okay howdo you kind of refresh all of theexisting embeddings and I've seen somepeople have some pretty impresseddistributed compute uh workloads they'reusing spark to just run everything inlike this horizontally compute fashionsome people are using like serverlessgpus to do that uh but yeah I mean it'sit's a huge Challenge and this is whylike if if anybody's exploring startinga company in the AI space it's toolingis hot uh just because of like no oneknows how to productionize some of theseuh applications and like I'm sureweeviate is doing phenomenally for thatreason uh but like all these ml Ops andeven what we're working on which isthese API based companies to helpabstract a lot of these complexitiesthere's there's a lot of interest inthat uh both from the market and frominvestors souh you did ask a question earlier Connorwhich was likeis there going to be a winner take allfor these models I'm curious to hearwhat your opinion is because likeeveryone's it's so obvious right nowthat open AI is like absolutelydominating but like is is that reallythe future uh are we just gonna all besuccumb to the whims of Microsoftum okay well I think um it's a it's asuper interesting question II think uhumyeah I mean well it it's I could see itbeing kind of Monopoly like in the sensethat well this kind of like zero shotthing to me is very monopolistic likethis you know like the whisper modelthat it goes audio to text similar togbt4 this AG like I think AGI is prettylike I don't I don't think that you'llbe like oh I didn't like the answer fromgbt4 let me go ask coher or let me goask Bard right this kind of thing likewhere you go ask another one of the agislike I think it's more likely thatyou'll just tune your prompt kind of ifyou're unhappy with the answer but I dothink like I don't I don't know I'm notsure I'm not I haven't really thoughtabout this too much but Ium and it's such an interesting topic Iwish I had a more like a more thoughtthrough yeah all right sorry to put youon the spot I know you guys we've yethas a lot of partnership with thedifferent uh modeling companies and I'veI've used most of most of them cohere uhhugging face I've I've used like so manyof the llms out there uh but yeah I Ithink personally there's probablythere's going to need to be some kind oflike staggering of the offerings and wetalked about how like the companies thatare offering these like domain specificmodels and they're like supporting thetraining on companies knowledge basesthey're going to do really well but thenthere's this entire uh arm of companiesthat really need security uh I went to asecurity meet up yesterday uh a companyin my our lead investors portfolio andthey like what we talked about earlierthey've completely pivoted their roadmapto support how do we create what didthey what did he call it like zeroknowledge proofs around uh like whatyou're providing to the model andensuring that you can validate that themodel isactually I don't want to butcher it uhbut it's an area of academic rigor andlikethe lowest hanging fruit is really themodels that you can self-hostand if that's never a direction thatChachi BT goes in which could unlock acan of worms in Pandora's Box because Iknow there's a lot of filters thatthey're putting on topbut uh I think there's a lot of avenuesdifferent model companies can go afterit's like is security the most importantis domain specific the most important isGeneral usage the most important coherehas a phenomenal API API Set uh so somaybe it's just like the developerexperience so uh I think there's gonnabe there's gonna need to be likedifferent niches and maybe open AI doesbecome the App Store but then likecohere becomes the sales force rightlike there's no sales force on the AppStore maybe there is nobody uses it butlike there's still a behemoth becausethey attack the domain specificknowledge baseyeah and I like yeah we've had a lot ofPartners and friends and like anothercompany that you know that I'm superinterested in is what Mosaic ml is doingand I think as you mentioned the salesforce I think Mosaic ml is the like thatis a company that's just super impressedme with their Pro I love like the umlike I love this kind of business modelobviously it's like the Wi-Fi businessmodel so I like it a lot of like whereyou kind of Open Source the software butthen the like Enterprise hosting ismanaged and so you know Mosaic ml theythey have this composer Library they'resharing all this knowledge onregularization and you know they'rethey're hitting they're cutting the costof training bro I think they just saidthat they trained Bert for like 20 andit's like they're you know they startedout by saying I can get you GPT 3 at 450000 and now today it's 300 000 andthey're you know they're they're cuttingthis down and I yeah I think it's superinteresting that kind of idea of the youknow the language model for your customthing but then there's is so so yeah Ithink actually we could segue this intotwo things there's the language modelfor your custom thing and we talkedabout the kind of custom re-ranker andhow that learning to rank generally usesall these crazy specific like tabularfeatures about you and then there's theembeddings models like like what do youthink of and and you mentioned thatproblem of uh the re-vectorizationproblem that's a pretty big problem likeif you update the embeddings and youhave a billion embeddings you then needto recompute a billion embeddings withthe new model right I've seen someinteresting but like retrieve theoriginal corpuses as well which is likeits own mess of challenges and that'swhy these like hybrid search engines aregoing to become more and more importantuh which is like you need the originalcontent in order to do the re-embeddingbut sorry I cut you off oh no yeahthat's yeah it's great I mean the yeahlike vectorizing a billion yeah likeI've seen a cool idea which is like likethe Facebook DPR model like where youjust update the query embedding model Ithink that's a potential idea where uhthe zero shot embedding happens with thelike you know the open AI or cohereembeddings model social coheresmultilingual embeddings model is amazingand you you know that's your documentembeddings and then you update maybe thequery and then yeah another interestingthing from that uh cohero Twitter talkthat Bob said was that he thinks uh like80 of the cases the zero shot modelpaired with the like lexico bm25 and thehybrid setup that that's a pretty goodyou know that's a pretty strong bet okayyeah and I this is uh an interestingtopic that I've been curious about whichis like is tfidf and bm25 are they gonnabecome obsolete at some point like arewe always going to need to do likestring matches to some capacity or willVector searches kind of just dominate uhobviously you guys have an opinion therebecause you've baked it into yourroadmap uh but yeah so so you weresaying sorry so the bm25 combinationwith what has excelled uh this is like azero shot embedding model so you knowlike the open AI embeddings pairing thatwith bm25 for let's say looking throughAir Airline manuals like some you knowlike some uh application like that uhyeah and I I do think BM 25 it's prettyinteresting because there is definitelysearches likeI like this idea of having like intentand like prompting search as well thereare a couple papers like task awareretrieval with instructions and instructin the instructor models that are likeyou prompt kind of the embedding modelas well because the embedding model alsois like capturing a relationship so it'slike a one of the great academic datasets is beer and beer has this one dataset called arguana and in argue Annayou're retrieving counter arguments soyou you put in some argument and it'snot it doesn't say get me what agreeswith this get me what doesn't agree withthis and that little difference so likethe retrieval models obviously aren'tlike adapted to that it's it's veryinteresting because like it's like thatnegation thing where you say like I amhappy I am not happy and then you'relike oh why are these vectors similar toeach other and it's like well there aresemantically similar and that's therelationship that's captured sosee I might have gotten a rant there fora bit but I yeah yeah so because beerwas trained on and it looks like it'sb-e-i-r right yeahbecause beer was trained on like theinverse or the negation of some of thesecomments they have slightly betterunderstanding of the use cases wherelike I am not happy versus I am happywhich is interesting because like assomeone that's experimented with a lotof the like hugging face off-the-shelfmodels that's something that hashistorically been quite challenging tograsp because you could have an entiresentence just one word makes that entiresentence completely differentwhich is probably an area of academicrigor so task wear retrieval withinstructions okay bookmarking that yeahyeah it's so fascinating and I thinkkind of one more thing I have strongopinions about b or b e i r because I'vespent so much time working on addingthis to ligate but like so the beer islike this zero shot Benchmark it's likeum I think 17 in total but three arelike closed source so 14 are like openlyavailable and so you don't do anytraining is the idea of it is like howwell can a model trained on somethingelse generalized to this and I thinkthat that and that's like that and thisuh I think like Ms Marco is one of thedata sets but it also has a training setI don't think we have a good academicdata set for the like continual learningcase like that like it would be amazingif there was like an academic data setthat was like let's say the pi torchdocumentation and like how it evolvesover time I I think that kind of dataset is needed because it you know it'slike um like I love this example withweaviate where it's like in 1.16 weintroduce ref to VEC and it's like modelwould have no clue what ref to VEC isyou know like it's this kind of sequenceproblem I thinkand by sequence you mean kind ofcapturing the evolution of a corpus andand using the Deltas between thesestages to tune the modeluh I mean that's a that's a good pointof like how exactly do you want to dothis I mean I because I just think likethe um it's like the kind of like thetrain test set is like uh there'susually like this IID you know likeindependent identically distributedwhere you you know have all your dataand you're like randomly sampling thetraining set randomly sampling thetesting set compared to this likehistorical data splitting where it'slike you trained on 2012 to 2018 testedon 2019 2020 and I think that that'smore realistic in my view right rightand I think the use case for that areare really aligned with uh just thisconcept of a knowledge base where thecontent itself is evolving and you needto kind ofnot only train but test on like the theDeltas of those stages over timeuh if it's all right with you I'd liketo Pivot slightly into something thatmight be a little bit irrelevant to NLPwhich is some a little bit of a hot takethat I have uh as of late so I've beengoing to a lot of these like meetups uhin New York I'm pretty new to the cityuh including the Wii v81 and they oftenhave you put like name tags on and whatI've been really into doing is just likeputting some kind of like contentiousopinion on these name tags and I I thinkthat one of the most important things assomebody that's building and trying toexplore and leviates doing a phenomenaljob at this is building in public andreally showcasing not only like thefinal released version but all the stepsthat you got to get there and not onlydoes it help you build an audience onthe way but it really kind of showcasesthat you're a human and you're a littlebit vulnerable because you're kind ofmaybe nervous about the steps thatyou're exposing but it unlocks so manydifferent opportunities around gettingfeedback at every stage garnering like areally strong evangelist uh user baseand the the best example of this isreally open source right if everybodycan see every uh pull request everycommit every issue then it's reallyquite obvious how everything is goingand especially if you're just like asole entrepreneur engineer it's likeeverybody can see hey this is theprogress this guy has made on on thisproductI don't know uh I don't know if you haveany projects that you've doneindependent of we V8 in the past butlike is that something that you'veexplored and are are there any companiesthat are doing that really wellyeah oh I love this up again well I yeahbecause I think about it a bit I thinklike umoh it's very interesting it's like thisquestion about like the business modelof Open Source kind of in general andthen as like as I think open source isalso kind of like a Content strategy ina way like you you you're like Yeah bylike constantly doing these releases andthen explaining all the details of ityou curate an audience and a lot ofthese products like having a communitythat's like super valuable becauseespecially if they're making pullrequests and things like that like Iknow like with yeah yeah like I thinkLang chain is a great example ofsomething that's achieved this like youknow people especially with like theIntegrations Integrations being such amassive part of this like with othersoftware companies and it like so yeahlike if you're creating this content andthen um that's kind of what I like aboutdoing this podcast as well is it's likethe potential to you know have somebodywho doesn't necessarily work at weavingbut you can kind of like highlight whatthey're doing and it kind ofincentivizes everyone to work togetheryeah it's pretty fascinating but I Ithink some parts of the business I don'tknow I like I think closed Sourcebecause there has to be some kind ofAdvantage unless you're like aMarketplace business like somethingwhere the community is the mode well thecommunity is is often like a reallypowerful Competitive Edge uh I mean assomeone that worked in an open sourcea company for a long time I can I cansay that but I think the real moat isaround the abstractions and likemanaging an open source project is isreally going to be a challenge if youespecially if you want to have some kindof semblance of high availability and anSLA guaranteed to your customers and sotherein lies the importance of likehaving these servers all managed for youand there are some interesting companiesthat are like really abstracting theserver uhthe the like server architecture of I'msure Mosaic is doing that to some degreeuh there's one company I won't give thema name but uh they are purely just adecorator in Python that says hey RunThis and like uh run this as aserverless function uh there's a coupleof companies that are doing that that'swhy I didn't want to name anybody but Ithink that for me at how I'm trying tomake myself uh mix be competitive isreally just around hey let's do our bestto abstract a lot of the patterns thatwe're seeing across these companies andfor us it's like everybody is doingeverybody is probably storing theirfiles in some kind of content repo likean S3 they're all trying to extract thecontents they have very strong variantsof files we want to extract the contentsin a way that it's maintaining the uhthe the structure of the file so forexample paragraphs and pages and PDFsrows and a spreadsheet we want tomaintain that and then offer some kindof search interface that spans all ofthem and all of these are like all thesedifferent steps and if we were just toopen source the entire mix be code basedand we could probably people couldprobably do a lot of that but they won'tget the same experience as just like atwo API call kind of thing and hopefullyyou guys are doing are exploring that inthe same way with weva cloudyeah yeah that is really interesting Iget maybe um I if you could teach me alittle more about the serverlessthinking we had Eric bernardson on thepodcast to talk about well I'm thinkingof modal yeah and uh yeah I saw yourarticle with uh banana as well could youkind of explain to me what thesecompanies are doing okay justyeah I mean I I had an idea of like inin any industry the companies that kindof consolidate all the different stepstend to do really well uh and it is kindof compounded in the ml space which islike the more data you have the morevaluable you are the more like we saidthe domain specific models to everycustomer is is the future uh like whatMosaic is doing and so uh if you'rebaking in the ability to spin up andinference engine a model in anarchitecture that is both cheap and fastand you're able to do that in a reallysimple way and expose that to your usersthen it's it's a really powerful assetthat you have in making your competitivemode as as a company it's likethe analogy that everybody understandsis like everyone is coming from Googleeveryone's coming from Facebook theyhave expectations when they interactwith your software and that expectationis it's fast it's accurate and veryoften it's a lot more affordable uh soand that's really why serverless is sucha an interesting space but what's reallyfascinating and this is something thatafter talking to a bunch of Engineers atAWS gcp and Azure is like is that itdoesn't seem like any of them are reallyattaching attacking these serverless GPUspace I don't know why but like I'veseen articles I've written articlesaround hey if you want to do likeserverless gpus then you gotta create anelastic Cloud an ECS uh architecturethen attach uh whatever the GPU instanceis and kind of have scaling baked inwith maybe like kubernetes and anybodythat's used kubernetes knows that it'slike the biggest painand so like modal banana they're allabstracting the kind of deployment ofthese models via the serverless gpus andI like modals approach which is just adecorator in Python I haven't actuallyused banana but uh yeah Eric's great guyyeah that's amazing I I've always beenso interested in this I mean full likedisclaimer I'm like I spend most of mytime reading research papers and stufflike I'm just these are just like we'reon the time of edge not an expert onthis but like the the thinking of likethe kubernetes and the scaling differentresources for different kind of uh jobslike I was always kind of as a asstudying deep learning I was alwaysreally curious like how's weights andbiases like how are they valued at likea billion dollars right because it'slike a it looks to me like hyperparameter logging tuning logging and youknow I did like some like marketing workwith determined AI where they were alsodoing this like uh hyper parametercluster thing and so I was like startingto learn about this kind of clustermanagement thing and I kind of came tothis thinking that like the kind of likethe callbacks require differentresources than the training and so youknow having thisI kind of like with weeviate like whereyou uh have some resources for theweeviate and then you have differentresources for like say the queryembedding container like this theserequire different kinds of uh computersand like all that kind of thing and it'spretty I mean I I like I really don'tknow too much about kubernetes but likeor like what the particular pains arebut I that's how I understand the ideaslike yeah like serverless to me itsounds like if you want to just have aquery embedding model on you knowrunning you just you know writedecorator on a python function right andthat kind of thing is super cool um yesI don't know if I have too many ideas onthis but I think it's super interestingI mean Leo like what is the bigkubernetes is a pain problem I've heardthis so many times but I don't reallyknow I think it's it's around likethere's two there's two aspects to itone and I'm also not a kubernetes expertby any means I've just use it it's it'sprobably the fact that I'm not an expertwhich is like I'm creating a little bitof a bias in me complaining about howchallenging it is uh which is like akind of uh a weird situation but for meit's really like the creation of thekubernetes cluster in addition to themaintenance of it and I what what couldbe and this is my own theory is likewhen you have distributedinference engines the state is inconsistent across them and I'm sure Ericcouldmake some explanation on why uh it'slike serverless environments canovercome that challenge but like if youhave an app server and you'reDistributing the workload across threedifferent servers and you're routing thequery across one of those threedifferent servers how do you guaranteethat there is like a state between theservers like the perfect example thateverybody could probably understand isthis concept of context with the chatEBT so let's imagine we have threedifferent serverless functions or oneeven one serverless function and everytime a user is calling this decorator itis deploying this inference on let's sayserverless environment a and thenanother user is doing serverlessenvironment B how is context sharedbetween them because they don't there'sno State it's serverlessuh I I I'm probably just speaking out ofmy uh my key stir here because I don'tknow much about the space but that's anarea that has always been challengingfrom purely I'm an app a softwaredeveloper not a researcher but that'salways been an area of challenge withlike serverless functions and databasesis you need some kind of StateManagementyeah amazing I've been learning aboutlike replication consistency from we V8and and it sounds is he related to theguy that created the Lampert clockoh oh no he Nathan hasn't been on thepodcast yet just a friend of mine I'mtalking about uh and I don't know aboutthe clock thing butumyeah the Lampert clock is like thefoundation of like distributed systemsand like consistency oh God you gotchayeah I've just yeah so I definitelydidn't like study too much replicationin school but I'm now listening toeveryone like Eddie and Parker and redone and I think just you know being ableto fly on the wall in theseconversations but like the um yeah thatkind of thing of like if I have if Ineed four gpus to run my chat gbtinference I suspect that's like theAzure cloud has maybe been built aroundthis in tandem with open AI if I wasbecause yeah that sounds like a terribleproblem I think and I know the companieslike Ray that do this kind of likeuh distributed GPU management it's superinteresting I mean I'm more sointerested in this company called neuralmagic that's trying to compress themodels and you know either run them onCPUs or they recently got the huntthere's a research paper with one of thetwo researchers has the neuromagicaffiliation that's run it on a singleGPU the 175 billion parameters and Ilike quantization sparsity thesesparsity is like one of these thingsthat hasn't been realized as like thelottery ticket hypothesis is like youcould train the sparse networks fromscratch but now there's like a lot oflike okay how do we really realizesparsity but yeah I'm talking about itlike user too like I know I'm thinkingabout these things too often but I dothink this isyeah it really sounds like what you'resaying is the the future of a lot ofthese models is you realize just themreducing in size but not only size butthe ability to run on more so commodityHardware because not everybody has otherthan the Bitcoin miners out there andnot everybody has some like reallysignificant GPU uh setups even in thecloudyeah yeah that's what I I mean I thinkyou know they got the uh the alpacamodel people are like running that ontheir phones so I was like yeah I sawRaspberry Pi running it which obviouslyimplies there's no GPU involved at allI'm sure it's slow as hell but the factthat they got it running is just amagnificent accomplishmentyeah yeah and I yeah I mean thisI guess it's like the the theTransformers I think became so popularbecause of how it uses this big matrixmultiplication thing for gpus but maybenew architectures like there's obviouslylike this sparse uh mixture of expertskind of model and yeah like maybe newarchitectures that don't that aren't sothere's like this great paper from uhSarah hooker called the hardware Lotterythat's like talks about how much thehardware has influenced the architecturedecisions and deep learning and thesekind of things andyeah it's definitely not an expert inthis space do you think in is there likethe idea that the decision to build themodels around these really large matrixmultiplication and arithmetic is thatreally uh was that decided on because ofGPU popularity you thinkuh or I guess are there other optionswhen you do machine learning I've onlyknown about just like the linear algebraumwell I thinkumyeah it's likeI'm trying to think because I I'm tryingto think about how the difference in thecomputation with like the convolutionalkernel is compared to the like attentionMatrix multiplications and I do thinkthat the convolutional kernels areimplemented by just kind of likereplicating the kernel and then makingthat also a big Matrix so I'm not yeahI'm not exactly sure yeah aboutum exactly how the Transformer utilizesmore of the GPU than the convolutionalmodel does or or if that is really theargument but I think it's just generallythis thing of likeyou know big Matrix multiplicationsyeah as far as I understand it yeah no Imean no I'm definitely not an expert atall uh but it is interesting to see likethere's only a couple of Hardwarecompanies out there and they are I meanNvidia is basically open AI at thispoint in terms of their like marketcapitalization on the ml space so uhit'll be interesting to see who else isgonna take over in the in the GPUoffering space and maybe there's otheroptions that aren't gpus who knows Iwent to a I went to AWS re invent uhlast year and there was a talk onquantum computer and she like the lady Ithink it was uh Oxford research companyshe brings out this like physicalquantum computer and it's like the sizeof my desk and I maybe that will becapable of some of these uh calculationsat some point who knows yeah that soundslike a good topic for like a PhD studentlike yeahyeah one other point that I want toleave with before we go is like there'sa lot of fud and real fun fearuncertainty and doubt there's a lot offud and like I said before likeexistentialuh threats and kind of just feelingpeople feeling generally reallystruggling with the idea of like thesemodels taking over and while a lot of itmight be true uh should always encouragelikeremove yourself from the situation Imean uh I'll tell anybody that wants tolisten about this but I lived in acamper van for a year before moving tothe city like outfitted a a Ford TransitHigh roof with electricals running watersatellite bed everything and really justlike removed myself for a year and Iencourage everyone to not do that that'sobviously pretty extreme but likeoperate in Sprints and uh and coasts solike you could Sprint for a couple ofmonths but don't forget to coast andwhatever coasting is for you like do itfor uh uh like a like a fixed amount oftime continuously it's not enough to inmy mind just take like a weekend triphere or there and I realize noteverybody has the the benefit of thisbut it's really helpful especially whenyou're trying to figure out how to uhresurge whatever project that was justrendered obsolete by the plug-inMarketplacebut yeah and if everyone anyone wants tosee how to build a van it'svanlifecoder.com is a a Blog that Imaintain documenting the build outprocess and the travels and I'll betaking it again this summer hopefully toNorthern Canadathat's awesome yeah that's super awesomethat's great advice I think umyeah it's I I think everyone's felt alittle bit of existential like what isthis with the gbt4 I thinkyeah people who are so dismissive of itI'm like it's obviously scary liketaking over every single job I don'tthink replacement is the right word butlike assets is certainly the right wordanybody that's not using it is certainlygoing to fall behindyeahit is pretty intense I mean I think alot I think the like the societal issueis like will this just cause moreconcentration of power at the topbecause now you're like the top can likehas all has even more leverage with justthe information uh control yeah yeah Ithink productivity is probably the bestmetric to to look at I mean if someone'sable to produce more in less time thenthey clearly have an advantage hopefullythese models again it's probably stillin that like open source alpaca llamaspace once these models do become moreand more commoditized and democratizedthen it does even the playing field andactually create equal opportunity uh forall which is really one of the mostimportant things with creating like a areally robust Society is like ifeveryone has access to the same Baselineuh chat EBT model then I think therethere's that even playing field and sureeveryone's going to have theiradvantages in some capacity but weshould do our best as a society toensure that everyone is likedoing their best or everyone is exposedto the same like Baseline opportunityand there's a difference betweenopportunity and outcome uh there willalways be people working harder andthere will always be people that have alittle bit more of an advantage but ifeveryone has the same Baselineopportunity I think that's what weshould strive foryeah there's a lot of great topicsaround this I think um I've recentlylistened to Richard satcher was on thegradient podcast and he was talkingabout uh his work with the AI Economistpaper and this kind of like runningsimulations to inform policy decisionswhere the where the agents in thesimulation are reinforcement learningcontrolled like to you know make it alittle more realistic of a simulationand all these this kind of ideas uh yeahit's super interesting I mean I do likeFrancois Chalet had this interestingtweet where he was like uh saying thatuh oh I'm gonna but I'm gonna do thislike crazy but he's saying somethinglike uh thinking that gpt4 is like superintelligence is similar to thinking thatlike a 3D printer is just like arbitrarymanipulation of matter that you can justlike and I don't know like that kind ofthing of like how are we like it's scarybut is it that far is it like completecontrol of the universe so to say youknow like I don't know if it really isthat in that productive yet but it seemslike it's on the way to it yeah it'sdefinitely on the way and I think thatthis plug-in Marketplace some of the usecases that I saw on the website arereally like oh a phenomenal the paperthat I was mentioning by the Microsoftresearch team which again is reallybiased because open AI in Microsoft areobviously together uh but theyanalogized this ability for Chach EBT tofigure out problems on its own I Viaquestions Etc with the time in whichHomo sapiens discovered their ability touse toolsso like for example openai or chat gbtwas capable of kind of like calling athird party API when it wasn't able tofigure something out on its own it'sclearly demonstrating enough reasoningto use a tool to accomplish its goalwhich is again that same overlap whichisHomo sapiens discovering how to use aknife what fire is so we could be seeinglike the dawn of a a new species adigital species uh and maybe there willbe that like Evolution uh staging of ofthis new species who knowsyeah a lot of sci-fi uh articles aroundituh yeah I mean before we go I do want tostay on this little like I've beenthinking a ton about this idea of howwith language models they can have thislike role playing like one languagemodel is the writer the other is theeditor or say wevier right where we getis like a remote company where you knowfor the most part we interface viatexting each other and writing code andpull requests and like having calls withpeople outside the company and thingslike this it's like you could have theyou know the core team full of languagemodels that basically the difference islike what information the language modelis hooked into so like if you're on thecore team I don't know like if I'msampling someone I don't know but likeyou know people access differentinformation and I think what we'll seeis like entire like digital likecompanies that are just like languagemodels with different roles it's kind ofhow yeah I mean you're saying that theremight not even be a single employee at acompany it'll just be all these largelanguage models that have their ownpersonas and maybe they're trained ontheir specific skill sets you've got alarge language model that isspecifically marketing you've got onethat specifically sales engineering EtcI could see that I did see a tweet Idon't know who it was but he basicallyposed a challenge to Chachi BT to turn ahundred dollars into two hundred dollarsand he was like do whatever meanspossible and I think what they amountedto was some kind of like affiliatemarketing uh project which is like cooland all but like what are you gonna dowith that so it kind of uh it suggesteda domain name it wrote the website it uhreached out to a bunch of Affiliates andit kind of built the Analyticsuh structure so I guess each of thesethey need to be modular right you needto be asking these questions in a littlebit of a modular fashion and I thinkthis is also something that chat TBTstruggles with is like every ask issequential and that's really what chatEBT excels in which is like you ask aquestion it gives you an answer and youask it to tune that answer or replace itor whateverthat sequence is how we all think butwhat if it could uh kind of go way backinto some other state and this is againlike that statefulness if it could goback into another state and uh resumesome kind of context there and this isprobably where the layers of largelanguage models comes into play and eventhese are like the concepts of Agentsmaybe you have a version that's doing Xand A version that's doing Y whereVersion Y has access to the context ofuh I don't know some other agentuh this is interesting I don't know thisis the first time I'm thinking aboutthis but there's there's so manydifferent opportunities this is a goldrush certainly yeah it definitely is andI really liked your article about thecontent verification layers because I'vebeen thinking a lot also about like youcan sample many different decodingPathways it's like you're saying withthe stateful thing like you know it'sokay you know it's thinking and then itgets to this node and then you have likethis like I think temperature is nowlike just if I say temperature peoplewill understand that you can adjust thetemperature to get different more randommore deterministic outputs from thelanguage model but really the way itworks is there's like this probabilitytree that it's decoding through and youcould take many pathways through thattree to get several differentgenerations and yeah I mean yeah that islike because the thinking with thecontent verification layers is like yousample all these outputs and then youjust kind of like filter it that waylike obviously the most of the filters Ithink are right now like more like guardrails of like whoa don't say that likethat kind of thing whereas I feel likeif it's like writing code maybe aclassifier could classify if this wouldcompile or not or not even a classifiermaybe I don't like I don't I don't knowif that's a great example because likeobviously you could like compile it butlike this kind of thing of like samplinganyway so I do think I've gotten totallyoff topic uh Ethan thank you so much forjoining the weba podcast I mean wecovered so many topics that like reallychallenged my thinking and a lot ofthese different things and I hope Ididn't say anything too stupidbut yeah no I mean you could alwayscensor it after post-production but nothis is great Connor uh alwaysinterested in talking to people in thespace and uh if anybody wants to reachout I mean I'm happy to talk uh buildingout this this project this startup doingit in public there's mixpeak.com thenthere's kali.ai and I am uh Ethansteininger on anything I mean I'm prettygoogleable or I guess chat gbt maybe Ishould check ifperplexity.ai definitely does I'dencourage anyone to search their name inthere it's really cool yeahyeah it's super quiet the perplexitything I mean I think yeah just the wholelike kind of the new era of like you.comNeva these like just brand new ways ofthinking about search yeah yeah yeahthat's really cool cool", "type": "Video", "name": "Ethan Steininger on Mixpeek and the AI Landscape - Weaviate Podcast #42!", "path": "", "link": "https://www.youtube.com/watch?v=EDPk1umuge0", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}