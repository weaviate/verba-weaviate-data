{"text": "Hey everyone! Thank you so much for watching the 59th Weaviate podcast with Luca Beurer-Kellner! Luca is the lead author and ... \nhey everyone thank you so much for watching another episode of the wevia podcast I'm super excited to welcome Luca Bureau Kelner Luke is the lead author of lmql a super exciting new programming language for large language models and Tool use and I think kind of this space is just continually evolving of what these llm Frameworks are going to look like and I think lmql clearly adds something to this conversation so before going any further Luca thank you so much for joining the podcast yeah thank you Connor for having me um happy to talk about Alexa and also yeah the entire space a bit yeah awesome so maybe before we even get into the details of lmql could you describe kind of like your research path and your PhD student at eth and like what led you into uh working with large language models yeah so I'm in my PhD at dth currently I briefly I did my bachelor's in Berlin and also my Master's Master stand here in cerica dth and yeah I guess before I came into llms I really was in the field or I still am in the field of programming languages um really something that fascinated me for my entire studies so far Bruce Lee I also worked at the company building mostly tooling and a language in the JavaScript ecosystem and they are doing my masters I also got um took a few machine learning lectures started to look into this a bit and in general my PhD studies are basically are at this intersection of machine learning and programming languages and yeah like a year ago basically we started to look into llms because they seem to get more and more powerful and capable of doing many things and this was like even before church 50 came out so basically a different era if you look at it from today um and yeah so we started working on on llms and started to think about how can we program with this like is there some programming language perspective in here and that's how we started working on lmgl yeah that's so interesting I love how the lmql like just for me there's just the syntax of it how you have kind of like it's like an SQL where it's like select from where it has this kind of look and so I think it would kind of be I'm really interested in also touching on that you know pre-chat gbt how you were thinking about that before that but I'd like to just let's keep transitioning like your perspective on programming languages like what like what is it a large language model programming language yeah I mean that's a great question like obviously um from an academic setting it made sense to start to think about this in terms of programming systems because I mean previously machine learning models were mostly just models that were trained to do one task well you put something in you get something out but now with models that can take free text input also like diffusion models for instance just becomes more of an interactive um form of of programming or interacting with these models and when we set out to build something in the space we were mostly Modified by this perspective of programming language models like having machine learning models that offer this form of programmability of you can compose them you can make them do different things and really um to start to look at this from this this perspective so I've kind of had a similar perspective but coming from sort of The Ensemble learning perspective where you kind of like Ensemble model predictions and especially you know like these ideas like hugging gbt where you're routing inferences to like you have some kind of task and you break up the task into which of these models could perform each of the subtests it also kind of reminds me of this recent work on gorilla it's a large language model from Berkeley that's like fine-tuned to use particular tools so it sounds like you have that perspective of like composing machine learning inferences together to kind of say okay you're the lawyer or like you're the image generation model like like this kind of segmentation of model inferences the uh correct understanding yeah definitely I would say this is almost already the next step like this is the step of this is the Master model supermodel that composes different models like in Ensemble learning right and we essentially moving this responsibility of composing models to a human programmer um so so we say Okay youth you humans can also compose machine learning models in this way or like developer program I can do this um it's true that of course this entire program of how to compose these things the llm generated um I think this works with reasonable success so far and I think there's a lot of potential in there um but yeah with the project we're mostly focused on providing this to to Google program is not necessarily in fully synthesizing this this program that's that's being executed on a higher level yeah I think like the to me the challenge of Designing that how you synthesize the program and the challenge and say like Lang chain llama index or say semantic kernel Gina AI deep set is uh like the abstractions change kind of right and so I when I first saw lmql and the syntax of it I thought it was something that was kind of like fundamentally different from sort of wrapping abstractions in like python classes is there something to this kind of lmql that would help like how are you thinking about sort of your understanding of the abstractions evolving over time and how you would uh you know adapt with I hope that question wasn't too open-ended no I I totally see uh where you're going with this like I think there's lots of new Crown to cover and I think that's also the reason why lots of people have lots of different ideas on how to abstract these things the design philosophy that we are following so far is mostly not from this top-down perspective of how can we abstract things in the space it's really coming from how do language models work internally so we started with the perspective of the Auto request the flash language models are token by token predictors and there's these decoding algorithms like you can do arguments to calling you can sampling you can do beam search you can do even more advanced things um and to start from this perspective thinking about how can this core Loop of token by token by token prediction be optimized how can we control this more tightly on the one hand with constraining and on the other hand with um scripted execution like this way that lmql enables you to use do template based text generation yeah I think the template based thing is one of the instant things that jumped out to me about Lang chain when it was first released is like you know you're chaining together language model calls and you put it in the um you put the output in the input but um I understand what you said about ARG Max and the internals of large language models like I when I first saw lmql I saw that like you can switch ARG Max with beam search with say this there's another paper called flare I've made a paper summary video this on weevier where it's this thing where you would sample the next sentence and then look at the uncertainty of those tokens and if it's uncertain you would then retrieve again basically that there are all sorts of decoding things you can do and yeah that's pretty novel I don't think um you know the the like the other Frameworks I think because they treat the language model apis as sort of black boxes right so I don't know if like I don't even think open AI with their API gives you that option to um uh you know like have beam search or like maybe it's just cooked into kind of like the temperature right like but or like tuning those kind of things exactly like yeah I guess like um so how much opportunity is there to because don't you need to have like uncertainty calibration and all sorts of things like that in order to make that kind of thing work yeah yeah definitely you do um it's interesting like um actually depending on what API you use with open AI especially if you use the now deprecated completion apis you actually do get this information at least on a limit in a limited form they do some obfuscation log it's sometimes very I assume for for um to protect against um model distillation but you can actually get some of this out of there it's obviously it's a bit restricted but we put a lot of work in making it compatible and exactly for this reason because the black box is actually not that black after all especially with open models obviously you have full access you get all of this information and even with open AI models you get some of this information and you can in fact Implement beam search on top of these apis um now this completion apis are being deprecated but actually what what opener announced in the same blog post is that with the chat API they will also add login access in the future I assume again a limited form but I hope they're definitely up to it that we can maintain the support because in the end of my air models are what most people use these days yeah sorry it's like jogging my memory I was trying to think of something I'm just kind of it's so interesting but like I do remember that you can like highlight the tokens on the API and yeah obviously the open language models and yeah sorry so so yeah so that kind of idea of the decoding I think just um I guess the question I wanted to ask you and sorry that took me a while to form this is just um like it sounds like that alone would be quite a like that would be a product by itself is how to decode from a language model do you see that as like being a a big like the the amount of algorithms that you can write in that space like we see so much about inference acceleration whether you're trying to quantize the weights or you know compress the model with knowledge distillation or pruning but just that kind of like you know I don't know too much I know like greed greedy decoding beam search I think there's like some kind of contrastive sampling in there like how how much research is there in that just like how you decode from the language model yeah so this is lots a lot of research actually this is an entire um research field on its own especially kind of in machine translation they use very sophisticated Advanced versions of beam search they there's a Monte Carlo based kind of sampling methods that are coming out now I think the the core difference here is obviously decoding on top of language models especially if you have to work around open air restrictions for instance can be expensive and will also be slower even though they can lead to um better results and I think most at least at this stage of um like L&M hacking and practical LM development most people will just use arcmics decoding this is fast this is more or less cheap um but I definitely see lots of potential to apply this in the future of course what will what it will need is actually a library that sort of or lmgl maybe an ecosystem that actually implements all these decoders and makes them accessible to users that want to use them practically because oftentimes unfortunately you only find them in somewhat esoteric research and repository so this is not um directly usable for many or many practical developers so far I mean overall I see a lot of potential in applying most of this research to to the space that's that's um evolving now yeah I think especially with the if the open source language like just generally is the cost of inference gets cheaper and cheaper which seems to be you know every I feel like every week There's a new open source like I've grown tired of keeping up with it honestly it's so intensive just the news of it but it's like I think I see the two things like earlier I mentioned Flair Flair as you sample the next sentence and if there's a high uncertainty you would then do another search query to get better information maybe for that and that obviously with our interest in weviate and retrieval augmented generation has a huge application but you mentioned Monte Carlo tree search and there's this other really exciting uh paper called tree of thoughts where you know you sample these Pathways maybe you have some kind of thing that would like cut um cut nodes and then you know keep sampling and so on but um yeah so and that kind of thing reminds me of like the you know like the alphago that how it had that Monte Carlo tree serves that kind of look ahead search how do you see that kind of like look ahead search and language modeling yeah I think this is a really interesting Direction I also see again coming from programming languages there's really cool projects that we're going looking at and maybe hopefully will find time to eventually do um I think that's cool essentially if you think about these like three or fourths for instance it's a form of um yeah X search-based programming like you build these reasoning algorithms if you want to call it that that and they are essentially defined a third procedure in this tree where you expand thoughts or like hypothesis and and like forms of reasoning the llm produces and ultimately of of course this this is intuitively it makes a lot of sense that this will actually help um with overall accuracy and quality although again like I think prerequisite for this is that inference will become much cheaper much faster and also should run in parallel of course so you can actually explore many branches at the same time um also like ultimately I think the big advantage of these methods is you can run an llm and if it doesn't give you the output you expect you can run it again you can sample from an llm right but this is sort of a never-ending process like in the end each time could be the one time that it eventually works out but there's no guarantee so um ultimately what you actually want is the power of l m is this rate this this um ability to sample but also a form of combinatorial search through the space of possible answers so that you get some guarantee that eventually you will find some model some solution to the problem that you're looking for and um I think there's cool hybrid solutions that you get to build in the space and I see lots of potential area hmm yeah what you're saying is really inspiring just I think just generally this is like connecting like model based reinforcement learning where the agent has like a model of its environment so it can simulate you know action trajectories and I guess there's all sorts of like exploring exploiting that you could do even within traversing your own world model right like usually I think in reinforce and learning you think of explore exploit is like uh strategies you should take when interacting with your environment I think there's like um uh I don't remember the name of the paper but something where you know there's like intrinsic motivation where the the desire of the exploration is to strengthen the world model and then this language model is the way it can simulate you know different trajectories it's also fascinating but so yeah so I wanted to kind of definitely touch on that because I think when I first looked at lmql seeing the ARG Max I imagined people listening who are looking into lnql that might be one of the newer things to look into and then but let's kind of I want to talk also just about broadly how lmql connects L alums with tools and sort of like generally your perspective on you know that kind of tool use concept yeah definitely so this big priority or I mean in the end our whole philosophy is to say well can we sort of interweave just general programming language like and python in our case like lmgl is essentially a superset of python you can just write whatever you would write in Python with the ability to to ask or like query a language model along the way and during execution and this means you can actually go forth and back with a language model called Tools in between called external retrieval systems like your vector database polar information and this enables a very seamless and very close coupling of of llm prompting getting some results and possibly a structured form executing some core as an external tool and then going back to the model so so um from that perspective this is really core DNA for us like just the whole idea we want to essentially bring this from programmability and use of external tools to the prompting itself um looking a bit into the future we also have a couple of features that were assumedly merged and Upstream which will be enabling of much more easily so so essentially there will be a seamless way to just expose some functions to the model and it will be able to call them along the way without the need for you to specify a specific um protocol of how the model calls the function and how results are fed back so so definitely a direction we are also actively exploring yeah I'd love to just kind of like that way of how you expose functions to the language model to get a little more clarity on that because I see you know open AI funks I think they're calling it or you know or it's like the Json dictionary kind of syntax I see in lmql you it looks like you know it it's like a hybrid between Python and SQL and sort of how it looks and there's like you know death where you define like the calculator and stuff so so yeah I guess like um yeah like the design of how you're going to prompt the interface of functions towards to large language models and I think yeah I hope that's not to like not specific enough of a question I guess like um there's something interesting as well about uh there's another paper from Omar katab and others called demonstrate search predict where they would also couple examples of how to use two tools or tasks broadly where you add kind of examples into this sort of thinking as well so yeah hopefully that sets the stage of um yeah I mean that like a very good I'm starting with the function chords this is obviously a very interesting um thing that they enable now um we do intend to implement this although not really just wrapping their API we actually what our goal of lmql in general is to not be model specific so we intend to implement something very similar that essentially works like function calls a bit more seamless because we're already in Python so we can already you just pass the function you don't need to um bother with Json schemas and everything um but we actually want to make this not augmented specific so this will also just work the same way with open source models basically abstracting whatever you need to do on the back end to make this work um also like another detail that I'm not sure many people um know about is that actually the function calling of opmaya is not strictly robust in a sense that it may still hallucinate the format it does not strictly adhere to the to the schema all the time because ultimately it's based on fine tuning not actually on on Strictly forcing the model to fit to the to the schema and the schema so um yeah our standards are more in the space of being vendor agnostic um and actually providing these strong guarantees because we can do this with our constraint decoding engine can we assume that the constrained decoding engine I've seen like structured output parser from Lang chain and I'm you know familiar with this of myself where you try to have it like output a Json dictionary and then your the idea is you're going to parse the keys in the output from the language model and it's like so important that it um you know followed the rules sort of so is this just kind of like um you know like if it's doesn't output and the square angular bracket after search you reject it like what are the ideas behind constrained sampling yeah so I think this is one of the biggest issues with if you think about Ellen Amsterdam programmability perspective this is one of the biggest issues like in regular programs you write a function as you know whatever you call this function it will do what you wrote down like typically these are not um randomized in behavior um but with llms it doesn't quite work this way like all the examples you used during development could be fine but then um at in practice when some user uses this function indirectly because they use your product this may just fail for for arbitrary reasons like there's no it's really hard to get a grasp on why they failed sometimes um and this makes programming actually really hard right this means functions fail randomly and not just in a they produce the wrong output sense but they don't even produce output in the right format like this is sort of the interface robustness is not even given so so I think and this is one of the core challenges I still see with llm programming and also what we try to work on is make this interface 100 and even if the result doesn't end up being correct this you can deal with but if the format does is not correct you essentially get the equivalent of null Point exceptions in your language and this will typically crash your program unless you handle it somehow um very reflexively but this is also really difficult to work with yeah I love that you just named that interface robustness I hadn't heard that particular phrase and I think that just Nails it right on the head I'm familiar with robustness and deep learning as well like you know some of the stuff Dan Hendricks did with um like image classifiers where he would show that you know if you increase the brightness or make the image snowy all of a sudden that imagenet test set accuracy goes from like 95 to like 40 accuracy and you know obviously that kind of thing is manifested in language models as well and so prompting it to use a tool you know could create that kind of thing um yeah it's a really fascinating kind of thing is just forcing it to use the tools and I guess kind of one more thing before moving on topics I wanted to get your opinion on earlier I mentioned gorilla gorillas like llm fine-tuned to use particular tools like you know GitHub CLI to make pull requests and stuff and I've been thinking really heavily about you know with weaviate you know we V8 you can see weaviate as a tool I see kind of two schools of thought we're thinking about this you can either just think about retrieval augmented generation in a pretty blind way where you the vector search engine just gives you context blindly sort of and then you just put that into the input or you can think of it as a tool where you're deciding like which of the classes because it's you know like vector database like you have like different classes for your data you like which of these classes do I want to search through which of the properties do I want to access or you know maybe even formulating your queries this one's a little hand wavy but maybe the idea of um you have a particular query that you would say oh I want to wait bm25 higher than Vector search for this one or I want to re-rank it with a cross encoder so like generally kind of like the the tool of levia like using the API so I think heavily about whether we should train a language model that you know is like that glue between using Eva so so I guess the the question is like how do you see these kind of language models fine-tuned to a particular tool whether that's weviate or Wolfram Alpha or you know what have you I mean fundamental is I mean it's very clear that fine tuning will help the model to adhere to whatever you wanting it to do um coming back to rent a faith robust and fine tuning is just the same we'll just fail in the same way maybe at a lower rate but I guess the problem here is if you have more than one call and you have a low percentage of each call failing in some you will have actually a High um high probability of things failing like of course you want to um you want the language models to actually be finding to exactly what you needed to do on the other hand what I hear and whatever I think is the most one of the most um yeah fun aspects about elements and also like in terms of inner economical terms the fact that you don't have to train them is actually one of the biggest advantages and biggest strengths right reactional purpose multi multi-task listeners and you don't have to train them meaning you don't have to invest the effort and time to build data sets and in some situations this may not even be possible like it's sometimes really hard to construct these kind of data sets yeah I guess like is a solution to interface robustness just you take the output and then you say template it and say did you follow the instructions all right and then see if it revises output right isn't that kind of like the um they used to have an uh there was a name for that kind of prompting I think reflection spelled funny like with an X yeah I mean just one way to do it if you assume some independent error rate eventually you will get there and practice usually there's no guarantee and if something is wrong it's typically because there's some weak spot in the model and even if you make it revise its output it may still have somehow some weird internal state that makes it repeatedly make the wrong do the wrong thing right now concretely how we implement this and also the fundamental technique behind us that other Frameworks start to pick up on also is the idea of constraint decoding meaning you don't even allow the model in terms of interface robustness to produce something that would be illegal you force it to produce it it's a bit like like one very traditional way of doing this is just hooking up parser and say you can only produce tokens that are actually um allowed next according to my grammar and this makes the make sure that the model will only produce outputs that are consistent with your grammar and this means you can pass this robustly and there will never be a situation where you will end up with an output that you can't parse in the sense so essentially you force the model strictly to adhere to a certain for output format and there's no need to revise or even um depending on how you do it definitely even not even a um you don't even need to tell the model about this like you can just restrict it strictly restrict its output distribution to only fit in this format that you provide it's making me think of like um you know like automata Theory and all that kind of um like grammar regular expression that kind of because I'm just like kind of you know getting the story of Luca interest in programming languages and now it's taking it in this kind of Chomsky like um perspective so you think about it and can you help me kind of understand that perspective of like formal languages a little further and how that would Inspire this design yeah so actually the parallels to a parasu and also like trumpskin and language theory is is um very clear and and also in in terms of expressiveness you can very much um like anchor it there like if if you think about from a person's perspective it is it is essentially a dynamically constructed parser that's hooked up to your language model and that will make sure that the that or the language model can only use the follow set as you would name it in in parser terms um of tokens that will can actually follow at the current position it's a bit like when you write code in your IDE and you open code assist it will only allow you to insert identifiers and keywords that actually are legal at this position in a program hmm well yeah so that was an awesome tour I just gained a ton of understanding of what a what an llm programming language would mean especially in this context of um you know of uh interfacing it with functions and having it adhere to the syntax or having it adhere to that this kind of thing um so kind of skipping topics I I wanted to jump ahead to something that just blew my mind when I saw it which was the lmql playground I think this is such a cool visual demonstration of these you know complex language model calls can you tell me about the design of it yeah so we um essentially when we in the process of building um we started to also build a graphical or visual debugger interface which is actually fully available on the web so invite everyone to just go to its lmgl.ai playground you can actually run all of nmql in the browser in this graphic user interface which will allow you to gain a better understanding of what's actually happening also especially on the decoder level if you always wanted to see like a visual representation of how beam search works or what other tokens the model has considered at particular points and during generation like all the different rates that were not explored actually this is a really cool way to see this um also big shout out by the way to the Empire Diet team they're building a python webassembly version of python and this is the only reason that lmql actually can even run in the process so this is also a really awesome project um now the playground itself I would say it's that it out as a debugging tool and we still use it heavily in that sense because it enables us to really goes token by token step by step we do a lot of token by token computations masking validation um also all about decoding algorithms that are branching can be visualized as it is a craft view that actually allows you to see all the different sequences that are being decoded how they relate to each other what's the origin of of the coding in general so and this helps a lot and but then again yeah on from an educational perspective it's also really interesting to explore just from as a user I would say um you would learn a lot about internals um we also buy by the way provide actually we haven't this paper is not public yet but this will come out soon we Implement now Implement a high level library for implementing custom decoders so it's something like Trio thoughts for instance or more advanced beam search variants you could now Express very easily with a high level language in lmgl and or in the internet of nmql and you would get all of this tooling for free so you can write your own decoder see the graphical results in the in the inspector on the playground um and play around with this yeah I definitely want to come back to that but just kind of like for our listeners coming to lmqo for the playground for the first time could you explain like how it would visualize say Auto G Auto gbt is this problem where it's kind of like you know write a set of tasks and then start executing the tasks and then reflect on you know our is the execution of these tasks getting me closer to my goal and I think it's one of these things that we you know is so like it's such a compelling idea but then it's kind of hard to tame it in the real world and I think this is like having this kind of visualization can you just kind of maybe explain the TL like the high level explanation like this kind of example of this you know like recursive do you need to keep doing things sort of yeah so act that's I mean that's a great point I think um now the current state of energy or the NPR playground is we really focus on this single query query meaning an LGL query is usually a long prompt that keeps on extending you can have different parts for the elements called but ultimately you you're generating one text document in a sequential order until you come to an end when you have done or gotten all your results um things like Auto GPT or more like compositional Frameworks where you chain calls together um obviously actually have more than one such call and we definitely plan to add this um but for this we still we first have to realize all our plans in a compositional um space as well um but potentially what you want really is a regular debugger with function calls and stacks and the stack frame and have like recursive chords being in the context of their parent calls right you can jump into them go token by token go back out see the parent call like like this kind of tooling definitely um would be very useful um although I'm not really all for Reinventing the real you so maybe there's also a very smart integration that you could do with existing python-based debuggers adding the lower level of when you execute a prompt function you can actually also step token by token fascinating so it's so that kind of parallel of you know how you would do a stack Trace with you know any kind of like you know C plus plus code or so on compared to maybe like yeah we've seen like laying flow where we have like these dags that kind of you know show like um uh you know I call the calculator I got the result or like I wrote this python code I executed it and that kind of thing um yeah well it's pretty interesting I mean I don't think I have a great uh question just um yeah like I that hearing that parallel really opened up my understanding of it comparing it with the traditional stack tracing and debugging that already exists and yeah it makes perfect sense so that stuff would translate you know right into this kind of language model stuff so yeah I think um maybe um with the lmql playground I guess and kind of like also when you originally land on lmql uh you have these set of examples could you maybe describe like an example to listeners that you know you particularly like and helps kind of illustrate lmql yeah sure um so I think one of the the simplest and and One Step Beyond just asking Church 50 something prompting method is basically called Channel thought right this is so stand with me this will be new um essentially the idea is to not ask language model to directly provide a response but instead you you first ask the model to but you provide a question you ask the model to provide um a reasoning how it would come to a response so essentially you just ask the model to reason step by step and then eventually after that did this you ask now give me the answer meaning you um you help the model in sort of providing a small algorithm basically on how to arrive to add an answer instead of just directly producing it and this has been shown to to create success and that this works really well like this is much better than just directly producing the answer and the way you would do this for instance in lmgl is you just write you write down the question and your query code you write let's think step by step then you have a placeholder that you insert where all the model reasoning goes and then you ask a model in a the follow-up statement Now give me the answer um and this actually also enables you to have like free text reasoning the model will do some number arithmetic maybe whatever kind of reasoning is required and then eventually when you actually want to retrieve the answer you can then leverage for instance lmql constraints saying okay now I want an integer number that represents the the answer um coming back to interface robustness this means you have sort of a natural language based reasoning process but the output the return value of your run function actually will be an integer value that you can robustly handle the rest of your program code so I think this this um illnesses quite well like the sort of standard process of how lmgl typically works yeah that's a really great clarification of um you know the difference between when you want to enforce the structured output parsing compared to where you want to let it just have the open-ended reasoning and um maybe to read this to listeners to kind of also get you know for people just listening and not also looking at this uh you know if you go to lmql.ai where you click Chain of Thought and that's kind of the example that we're talking through right now so you have the ARG Max and then you have a question it was September 1st 2021 a week ago what is the date 10 days ago in mm slash DD slash yyy Quest like you know forcing that kind of uh structure already and then but then you give the answer choices where you have you know a b c d e f these are each like dates formatted like that then you have let's think step by step and then you have reasoning and then you say therefore among a through b the answer is result can you tell me a little more about like reasoning and result and just how lmql parses that so essentially you have to read it like a sequential program it's executed top to bottom left to right and top level strings that you see in the query are just um pass to the model as prompt and whenever you have in your top level string a placeholder variable in in square brackets this is when we actually invoke the language model to produce a response um and to prompt the language model will get for this particular call is whatever text has been consumed so far by a sequential execution of your program and the language model will come to naturally come to an end typically a language models Just Produce some end of sequence token with return some some text that represents the reasoning and in an nmgl in problem logic this means after executing the statement there is a variable defined in your program context it's called reasoning which will just be a string and you can access the string you can print the reasoning the llm used you can also just ignore it it will from now on the part of the follow-up prompts that you will send to the language model so here in this example you will continue you will prompt the model therefore the answer is and the model will actually see its previous output so in the next core when we produce the actual result and it will see us reasoning it will see the original question it will see the new prompt asking it to produce an answer and for result this final placeholder variable here and we have additionally defined constraints so we can actually now limit the language model to say well result should be one of a to F and we can enforce this strictly which can just limit the distribution of the model to be only across a through F and no other tokens are allowed which means we can we have guarantees about the format of this final output right um because in practice what will happen this works most of the time and then at some um odd generate case the model will just use some other letter maybe or something else entirely um and you can't parse this and by using constraints in lmgr you can actually guarantee this will be one of a through F and there's no other way that this weapon will terminate the return value will be one of those and this means you can just return this without value to your property logic you can also use it to index an array with limited options in this case and this through our work robustly without any need to do output parsing or somehow some some fussy logic to validate ourselves yeah I I love the way it like where result in you know a b c d how you have that syntax I think yeah it's really it's super cool I mean I I have played with a lot of problems where you're saying like if and that you know like you're prompting it with if else kind of logic where you say if and then some abstract natural language description of what to do with the thing and then then output like you know no change needed or whatever right and so this syntax to constrain it to certain valuables as you discussed and then or constrain it to be a type maybe even like make sure it's Boolean would achieve that same kind of but like I guess because it is free text but yeah like this kind of syntax is so elegant and so it brings me to my next question which is kind of a Harrier question is and you know you know like it's such a convincing thing I would love to get running with this like how does this integrate with the existing Frameworks like I know there's an integration with llama index like is this just kind of treated as like one of the structured output parsers how does lmql kind of like what is the early stage of this integrating in the current sort of like llm software tools yes I actually I'm quite happy about the current state of integrating like essentially we can integrate with all of them more or less and the reason for this is that most Frameworks are um compositional and they have this black box perspective and they do lots of training cards together or like even in some kind of tree structure and I'm index they do lots of interesting things but since they assume the language model itself is a black box and lmgl mostly operates in this black box we can always just fit in this black box State it's a black box to them they have no assumption about its inner workings and lmgl fills this black box leveraged some more some more advanced information from the llm and so in that sense we can for instance a link chain we can just operate as a chain component we can just it's just a lmql lmql queries are just python functions and and this fits very well with multiple positional framework so so there's lots of um yeah to be had from each other so on the one hand we can use dama index or next chain to retrieve use with all their retrieval Integrations to insert them into the prompt on the other hand lmql programs can be used as part of your agent where we have like Auto GPT variants using lmql all sorts of projects just employed as sort of the as a fundamental building block and what they're building compositionally with L M's yeah it's amazing I I guess like kind of the other thing is like you know I I love this kind of like the llms write the code and I think this um like I love this question of like I feel like the llm itself could be prompted to write lmql code like if you uh you know say uh you give it these I think nine examples of tell a joke packing list Chain of Thought and then you give it these examples then ask the LM to write new things do you think about interfacing lmq well that way yeah I mean it's it's um obviously in the current uh day and age this is number one thing people talk about also to us and obviously as PL people like we work on programming languages we design when a model and concise abstractions that's our at least a labor of love and that this hurts a bit like we build a nice programming language and then people don't want to use it they just want to llm to use it um which is actually an entirely different very interesting program can we build the programming languages that are work particularly well with llms um because this is fundamentally they use the lnfs are really good at using for instance python because it's popular on the internet but what if we decide the language that was by on by on first principles based on being an interface to LMS and not to humans this is a very interesting problem I think to work on like to see lots of potential there as far as it comes to lmql um we have some limited experience with this essentially for instance if you write Adam Q L and you're editor of choice and you have for instance GitHub co-pilot installed um GitHub copilot will after a few demonstrations of lmql effortlessly write lmql like it's so close to Python and semantics are mostly declarative that it's not really hard for for um the auto completion models to pick up on this um we haven't done more for our experience experiments with intenders um so there may be something there for us it's mostly about time currently like we have so many directors and projects to explore um incredibly busy these days so so hopefully at some point we can we get to work on this but yeah not not directly right now it's not a priority first yeah super cool yeah it's very interesting hearing the um the frustration of a designer of programming languages yeah so you mentioned the you know the time thing and they I'm very curious just kind of you know I've learned so much from talking with you in these 45 minutes you certainly seemed like you have a really you know exciting vision for the future of this what are some of these like um you know future projects directions that you're going with lqo so I mean on a high level I think the most fascinating thing to me being a PL and machine learning person is this this new generation of models that's programmable so suddenly like you can prompt them to do things you can compose them in new ways they're not just one task reasoners they're multitask listeners and for me this is incredibly interesting I think also um talking to people in in like bigger labs there is interest in building models that are programmable in the sense maybe even Beyond prompting like maybe we can find more formal languages train Foundation models on different kinds of data that are programmable and composable in the sense so so I think in general this field is is really amazing I think multi-modality definitely want to integrate this um not sure about the programming models there for instance programming with images is very different usually than visually and then with text like text is obviously the most the closest thing to to code as well so um yeah we'll definitely explore this this I think this is incredibly interesting in Array like also our industry paper the core Insight is prompting is programming like this enables a new form of of programming that will be fundamentally different from what we know so far because you don't have to specify every detail you have these new reasoning engines that you can use as building blocks you can make fussy things hard things that are things that were hard so far suddenly became much easier to do with l and m so so it's very interesting to explore it in this way carve it out on a much more concrete level we also have lots of things you want to do with lmgl of course um we're definitely thinking about compositional stuff like chaining stuff together mapreduce Style computations with llms and I've for now we're very minimalistic we try not to add too many abstractions the feedback from the community often is very harsh with regards to these um I think there should be well thought out it's hard to find the right attractions as long as things are moving that fast but we definitely have some ideas around like algorithmic use as well like llm-based sorting algorithms for instance or like just using llms as data transformation tools to go from one form to another in a much more machine learning based way and then like something that's more or less coming up more or less immediately is also types like we will add types to lmql we have intentional types for now but this will extend to um reg X matching but also structural types like data classes Json um yeah I think this will be really useful and correct practical to have also valid and programming in general yeah that's a I love that you know future perspective also immediately very grounded I you know I learned a lot about you like the structured output parsing and being I think one of the key constraints to enforce with a large language model uh programming I love this kind of moving data from one format to the other like CSV to Json that's just like a common thing that people want to use but um so I really wanted to earlier I brought this up quickly there's there's this other uh I wouldn't compare I wouldn't call it quite like um lmql but uh demonstrate search predict DSP basically the idea is um like one part of the idea that I understand well and I'm sure I'm already a much better description of it but like my understanding of it let me like Frame It That Way first is like you would retrieve some examples of a task so you have some input output of like I don't know how I like to respond to emails about we V8 something's particular like that and then it will um look at intermediate tool use kind of chains to to get to that output that you've demonstrated and you give it a few examples of it and so it will compile some kind of like intermediate reasoning chain sort of and it makes me think and then you you know because you mentioned the multitask learning kind of perspective and I guess I'm just I hope that I'm framing this right but like this thing about like gradient descent is it still needed to adapt to new tasks or do we just kind of like compile new chains of tool use and checking parts and adding structured parsing and in the middle I hope that question is clear yeah I mean coming from core machine learning models I'm not ready to give up on on gradient descent let's say am I before I worked also on differentiable programming languages and actually I think there's lots of really cool potential to explore there like there's this ongoing debate also about is prompting enough or will prompting actually eventually die and and fine-tuning ruler wise again um obviously for now the more resource uh conscious thing to do with protein because you don't have to spin up your own GPU machine some of these really large models are not even feasible to train for smaller companies but then like there's these much more very interesting Pathways to to fine-tune models now so I think actually um and we're thinking about this like completely um dismissing the the neural layer that actually is below below the text layer that we have now is I think it's it's not um we shouldn't do this like I think there's lots of um bottlenecking like the text layer is actually a bottleneck like especially if you chain multiple chords together um lots of information is lost in just putting the output text of one call into the next call like the model has very rich representations internally so I think actually composing models and also large pre-trend models on a neural level like actually passing hidden States latent representations along this could be really interesting in the future obviously for now it's also a resource issue like you need gpus you need to run this model small or less locally to do this um but yeah thinking longer into the future I think we may even go back to the neural layer not say on the text layer I think text layer is also something that was born out of the practicality and and for economical reasons so oh this is it's really really interesting I like I'm really fascinating in these architectures like retro Fusion indicator memorizing Transformers long llamas one that John trengrove at levia sent to me today just like the latest iteration of this where you you know you have the um attention over vectors retrieved by something like a vector I don't want to say Vector database because you know like a vector index like it's something to facilitate approximate nearest neighbor search at like absolutely enormous scale and then the difference is instead of just putting that in the input layer you put it in layer like eight out of 12 of the Transformer and it attends over those latent representations and you could imagine like there's this other paper called uh Transformers are Universal computation engines or something that shows that image embedding spaces can be processed by text embedding models and when you give it the latent space and the intermediate layer not the input so and then you're describing this composability thing so it's like this idea of having some kind of debugging for that kind of architecture as well that kind of like intermediate so so yeah like um how do you see those kind of architectures being realized though is it going to take someone you know just just trying to you know change out maybe one of the open models like MPT or falcon or say you know gbt3 is modified to have this kind of extension because you know like what's kind of the state of that like putting the latent representations in the middle of other models and combining models and then combining models that way it's really fascinating stuff yeah so I mean I think um if we look at open air what they do um currently they're very into this we have a text-based API you put text and you get text out and the chat apis are much more limited than the previous completion apis they're moving more towards this it's a match function it does sometimes that's what you want it to do um obviously that's actually moving away from this interface that we would need to implement more um neurally based systems and so I guess to do this right now the only way is to actually work with open models um I also can see if this actually works out like I'm sure many people work on these kind of issues also already if this in the end um as promising also to them I can imagine them opening this up maybe providing some kind of platform I mean at this point we don't know um I think for now we are even open it as GPU constrained at least this further now so actually exposing this kind of much deeper um interface would be difficult for now and probably also from a proprietary perspective not too smart like if you leak your hidden States model distillation becomes much easier of course so yeah I guess if you want to implement this today you will probably have to withhold two open models um and then for other things more proprietary apis it will be interesting to see a red interfaces go like our chip D4 will also at some point accept image input which will be a limited form of this or less red you can now also embed some image and this will be passed through to the text model to be processed by the text model yeah it's hard to tell at this point I think um resource constraints it's for everyone with those constraints are currently the bottleneck to do this yeah it's totally this is this conversation has totally opened my eyes to how this is I've heard these things that those these rumors on Twitter and so on that gbt4 is like a mixture of experts model and I think the architecture of mixture of experts is kind of like a composable model in one it kind of reminds me of just like you know like lottery ticket hypothesis showing that sparse networks can you know carry the burden and so it probably what happens is we have this like mix of sparse networks it's kind of like that um a thousand brains Theory uh it's been a long time since I reflected that but like that kind of idea that you you have this kind of composability within dense architectures as is but if you explicitly separate it hi so I mean it really makes me think about like whether Vector indexes would compose embeddings from multiple models as well it's not something I've ever thought about like having like open AI embeddings as well as clip and uh like you know the Ada two text embeddings with the clip embeddings like totally separate models but in the same kind of index and uh yeah there's just so many interesting ideas to that I think really so yeah uh so yeah it definitely got on the train of thinking towards the future it you know I think we're mostly thinking of composing model inferences purely through the text input text output kind of landscape do you think like I think we're we might be dreaming a little bit do you think that's how long do you think that'll still be the most common way of interfacing models with each other wow I mean at this point it's really hard to say things are moving so fast although yeah it's really hard to tell like at this point um bigger shops closing down more and more means also that any day someone with some new model this has something bigger and and the tire research fields are being disrupted by this more or less so it's hard to tell where this is going um I think from a programming perspective the text layer definitely is something very accessible like coming from PL having a model that takes natural language input and thus more or less what you tell it to do is the best programming language in the world right it's just natural language and there's this incredibly accessible to so many people that's also read so many people use chat GPT because they essentially they're essentially just overnight learn to code because they can just instruct your computer to do something and it doesn't and like having a lot of passion about coding I get them like obviously this is amazing to them having disability now and but so in that sense I think the text layer is really interesting as an input as an output of course you can also do images I've seen really cool projects about models outputting code that then renders as user interface this is also really cool like personally I've grown a bit tired of reading long wordy paragraphs of a language model output like the scenes this seems to take it like for my present test this takes too long I will tell you um effective in taking out up this config information um so yeah I think there's lots of um benefits to the text layer um especially for like everyone that's not super technical and wants just wants to use some some chatbot API or some chatbot interface to get some answers to their questions yeah I think I mean this whole perspective I think most of the llm Frameworks I don't like I guess it's like I still think of lmql this way even though I think of you as a scientist like like I think what we're talking like what we started talking about about discomposable models I still don't quite understand how that would work and Allen kill quite yet but I'm sure that you'll figure that out but it just like um like moving past text being the how the bottleneck for uh language model chains language model tools interacting with others even just with embedding so like maybe let me take a step back and tell this kind of like you know like we have this feature in weba called ref to VEC that we often use for recommendations so you know I'm Connor and I like these three basketball shoes and so then I have like this Vector that captures my taste in basketball shoes or like say my taste in movies right and then I have Lucas taste in movies and maybe we find some you know we average these vectors and then a generative model you know produces a movie that would be something that me and Luca would like yeah it's kind of like moving into tensors or vectors I mean how do llm Frameworks get there like it's such a it's such a eye-opening idea I think it's totally different Paradigm like I I think and and it makes sense like we're currently building things for the text layer and and this is really cool and fun if we I think this would be a different thing like there would be I guess different abstractions I mean I'm not even convinced that we landed on the right abstractions currently on the text layer there and also the models are still moving so so who knows where this will go like essentially we just have to try out most things and then see what works right and then going to this more um like I would say that what you propose this sort of averaging of vectors and then putting this into a model that this is definitely some form of composable or programmable model and at that point right you you really Define a program of what you want and then the model sort of executes steps that that you um Define your algorithm right so um yeah I mean I mean I think it's it's probably not a time yet that this actually works or this is actually um something people do or build I mean in research for sure but but like not optional on the level of llm and tooling um but once this actually becomes possible I think also lots of interesting new programming ideas will come up no new Frameworks new languages and yeah with the current lmgl um I think we would move a lot in the presence of such a such thing amazing Luca thank you so much I think you know just um you know firstly understanding lmql when I first saw I think just like you know when I first saw the lmql my first impression personally was it reminded me of levier design how we have kind of like a graphql API as well as these client libraries and you kind of can see the difference in in my opinion it's easier to design the graphql and I because I kind of feel like the syntax of lmql looks like that compared to a lot of these Frameworks like you know I don't want to name them but like that require all this buy-in you know this is a little more open-ended than that so I was always already super impressed with lmql the lmql playground is a visual thing I'd highly recommend people to see that because it's it's brilliant really it the way that it lets you visualize this complex prompt uh execution is really super novel and then those ideas around structured output parsing that kind of like wear clause in the lmql syntax and how that restricts the thing all amazing stuff and then start adding more thing but how lmql already integrates with llama index Lang chain you know is something you can kind of get running with and then it just kind of towards the end of our conversation this discussion of you know the text bottleneck that just really opened my eyes into how the space could evolve so you know Luca thank you so much for the podcast I think you're you know building a super incredible tool and you definitely have the Visionary aspect of seeing where this technology is headed uh before we wrap up could you give listeners like your media like how to follow along with you like are you primary publishing papers are you on Twitter they are definitely um you can I mean lmgl you just find at lmgl.ai we also have Twitter account um and I'm also on Twitter um our calendar maybe we can link it somewhere you can follow me there um and yeah also please if you want to try out lmql do so we have the Discord we always most of the time we're online and helping people also so please feel free to reach out there as well and and happy to help and discuss also like more broadly and then I'm programming and right this can go yeah and thank you so much for having me yeah well quickly let me ask I'm curious about your perspectives on this Discord uh Community how has your experience been building something like that for a new technology like this um it's it's um I actually really like interacting with people talk to them a lot um it's a bit overwhelming to be honest this is my first open source project at this scale it's a lot of support requests and all of us and the team already have full-time jobs so essentially it's another full-time job to do this um but at the same time the community feedback also has been quite quite amazing and and people start to contribute um and we are still like very much welcoming everyone who wants to to hack on lmgl um brainstorm and and also like happy to help out beginners talk about the issues with NFL maybe you didn't want to get something running with totally I'm happy to help with that yeah I think it'll be it'll be a really cool demonstration of um you know Community feedback plus this science this vision of it and yeah I'm super excited to follow along with it Luca thank you so much for joining the weba podcast this is truly one of my favorites I learned so much about the large language model space and how this can develop thank you so much for having me Conor ", "type": "Video", "name": "Luca Beurer-Kellner on LMQL - Weaviate Podcast #59!", "path": "", "link": "https://www.youtube.com/watch?v=cuWLPHDAQ5g", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}