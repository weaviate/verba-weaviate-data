{"text": "Hey everyone! Thank you so much for watching the 59th Weaviate podcast with Luca Beurer-Kellner! Luca is the lead author and ... \nhey everyone thank you so much forwatching another episode of the weviapodcast I'm super excited to welcomeLuca Bureau Kelner Luke is the leadauthor of lmql a super exciting newprogramming language for large languagemodels and Tool use and I think kind ofthis space is just continually evolvingof what these llm Frameworks are goingto look like and I think lmql clearlyadds something to this conversation sobefore going any further Luca thank youso much for joining the podcastyeah thank you Connor for having me umhappy to talk about Alexa and also yeahthe entire space a bit yeah awesome somaybe before we even get into thedetails of lmql could you describe kindof like your research path and your PhDstudent at eth and like what led youinto uh working with large languagemodelsyeah so I'm in my PhD at dth currently Ibriefly I did my bachelor's in Berlinand also my Master's Master stand herein cerica dthand yeah I guessbefore I came into llms I really was inthe field or I still am in the field ofprogramming languagesum really something that fascinated mefor my entire studies so far Bruce Lee Ialso worked at the company buildingmostly tooling and a language in theJavaScript ecosystem and they are doingmy masters I also got umtook a few machine learning lecturesstarted to look into this a bit and ingeneral my PhD studies are basicallyare at this intersection of machinelearning and programming languages andyeah like a year ago basically westarted to look into llms because theyseem to get more and more powerful andcapable of doing many things and thiswas like even before church 50 came outsobasically a different era if you look atit from todayum and yeah so we started working on onllms and started to think about how canwe program with this like is there someprogramming language perspective in hereand that's how we started working onlmglyeah that's so interesting I love howthe lmql like just for me there's justthe syntax of it how you have kind oflike it's like an SQL where it's likeselect from where it has this kind oflook and so I think it would kind of beI'm really interested in also touchingon that you know pre-chat gbt how youwere thinking about that before that butI'd like to just let's keeptransitioning like your perspective onprogramming languages like what likewhat is it a large language modelprogramming languageyeah I mean that's a great question likeobviously umfrom an academic setting it made senseto start to think about this in terms ofprogramming systems because I meanpreviously machine learning models weremostly just models that were trained todo one task well you put something inyou get something out but now withmodels that can take free text inputalso like diffusion models for instancejust becomes more of an interactiveum form of of programming or interactingwith these models and when we set out tobuild something in the space we weremostly Modified by this perspective ofprogramming language models like havingmachine learning models that offer thisform of programmability of you cancompose them you can make them dodifferent things and really um to startto look at this from this thisperspectiveso I've kind of had a similarperspective but coming from sort of TheEnsemble learning perspective where youkind of like Ensemble model predictionsand especially you know like these ideaslike hugging gbt where you're routinginferences to like you have some kind oftask and you break up the task intowhich of these models could perform eachof the subtests it also kind of remindsme of this recent work on gorilla it's alarge language model from Berkeleythat's like fine-tuned to use particulartools so it sounds like you have thatperspective of like composing machinelearning inferences together to kind ofsay okay you're the lawyer or likeyou're the image generation model likelike this kind of segmentation of modelinferences the uh correct understandingyeah definitely I would say this isalmost already the next step like thisis the step of this is the Master modelsupermodel that composes differentmodels like in Ensemble learning rightand we essentially moving thisresponsibility of composing models to ahuman programmerum so so we say Okay youth you humanscan also compose machine learning modelsin this way or like developer program Ican do thisumit's true that of course this entireprogram of how to compose these thingsthe llm generatedumI think this works with reasonablesuccess so far and I think there's a lotof potential in thereum but yeah with the project we'remostly focused onproviding this to to Google program isnot necessarily in fully synthesizingthis this program that's that's beingexecuted on a higher levelyeah I think like the to me thechallenge of Designing that how yousynthesize the program and the challengeand say like Lang chain llama index orsay semantic kernel Gina AI deep set isuh like the abstractions change kind ofright and so I when I first saw lmql andthe syntax of it I thought it wassomething that was kind of likefundamentally different from sort ofwrapping abstractions in like pythonclassesis there something to this kind of lmqlthat would help like how are youthinking about sort of yourunderstanding of the abstractionsevolving over time and how you would uhyou know adapt with I hope that questionwasn't too open-endedno I I totally see uh where you're goingwith this like I think there'slots of new Crown to cover and I thinkthat's also the reason why lots ofpeople have lots of different ideas onhow to abstract these thingsthe design philosophy that we arefollowing so far is mostlynot from this top-down perspective ofhow can we abstract things in the spaceit's really coming fromhow do language models work internallysowe started with the perspective ofthe Auto request the flash languagemodels are token by token predictors andthere's these decoding algorithms likeyou can do arguments to calling you cansampling you can do beam search you cando even more advanced thingsum and to start from this perspectivethinking about how can this core Loop oftoken by token by token prediction beoptimized how can we control this moretightly on the one hand withconstraining and on the other hand withum scripted execution likethis way that lmql enables you to use dotemplate based text generationyeah I think the template based thing isone of the instant things that jumpedout to me about Lang chain when it wasfirst released is like you know you'rechaining together language model callsand you put it in the um you put theoutput in the input but um I understandwhat you said about ARG Max and theinternals of large language modelslike I when I first saw lmql I saw thatlike you can switch ARG Max with beamsearch with say this there's anotherpaper called flare I've made a papersummary video this on weevier where it'sthis thing where you would sample thenext sentence and then look at theuncertainty of those tokens and if it'suncertain you would then retrieve againbasically that there are all sorts ofdecoding things you can do and yeahthat's pretty novel I don't think um youknow the the like the other Frameworks Ithink because they treat the languagemodel apis as sort of black boxes rightsoI don't know if like I don't even thinkopen AI with their API gives you thatoption to umuh you know like have beam search orlike maybe it's just cooked into kind oflike the temperature right like but orlike tuning those kind of thingsexactly like yeah I guess like umso how much opportunity is there tobecause don't you need to have likeuncertainty calibration and all sorts ofthings like that in order to make thatkind of thing workyeah yeah definitely you do um it'sinteresting likeum actually depending on what API youuse with open AI especially if you usethe now deprecated completion apis youactually do get this information atleast on a limit in a limited form theydo some obfuscation log it's sometimesvery I assume for for um to protectagainstum model distillation but you canactually get some of this out of thereit's obviously it's a bit restricted butwe put a lot of work in making itcompatible and exactly for this reasonbecause the black box is actually notthat black after all especially withopen models obviously you have fullaccess you get all of this informationand even with open AI models you getsome of this information and you can infact Implement beam search on top ofthese apisum now this completion apis are beingdeprecated but actually what what openerannounced in the same blog post is thatwith the chat API they will also addlogin access in the future I assumeagain a limited form but I hope they'redefinitely up to it that we can maintainthe support because in the end of my airmodels are what most people use thesedaysyeah sorry it's like jogging my memory Iwas trying to think of something I'mjust kind of it's so interesting butlike I do remember that you can likehighlight the tokens on the API and yeahobviously the open language models andyeah sorry so so yeah so that kind ofidea of the decoding I think just um Iguess the question I wanted to ask youand sorry that took me a while to formthis is just um like it sounds like thatalone would be quite a like that wouldbe a product by itself is how to decodefrom a language model do you see that aslike being a a big like the the amountof algorithms that you can write in thatspace like we see so much aboutinference acceleration whether you'retrying to quantize the weights or youknow compress the model with knowledgedistillation or pruning but just thatkind of like you know I don't know toomuch I know like greed greedy decodingbeam search I think there's like somekind of contrastive sampling in therelike how how much research is there inthat just like how you decode from thelanguage modelyeah so this is lots a lot of researchactually this is an entire um researchfield on its own especially kind of inmachine translation they use verysophisticated Advanced versions of beamsearch they there's a Monte Carlo basedkind of sampling methods that are comingout now I think the the core differencehere is obviously decoding on top oflanguage models especially if you haveto work around open air restrictions forinstance can be expensive and will alsobe slower even though they can lead toum better results and I think mostat least at this stage ofum like L&M hacking and practical LMdevelopment most people will just usearcmics decoding this is fast this ismore or less cheapum but I definitely see lots ofpotential to apply this in the future ofcourse what will what it will need isactually a library that sort of or lmglmaybe an ecosystem that actuallyimplements all these decoders and makesthem accessible to users that want touse them practically because oftentimesunfortunately you only find them insomewhat esoteric research andrepository so this is notum directly usable for many or manypractical developers so far I meanoverall I see a lot of potential inapplying most of this research to to thespace that's that's um evolving nowyeah I think especially with the if theopen source language like just generallyis the cost of inference gets cheaperand cheaper which seems to be you knowevery I feel like every week There's anew open source like I've grown tired ofkeeping up with it honestly it's sointensive just the news of it but it'slike I think I see the two things likeearlier I mentioned Flair Flair as yousample the next sentence and if there'sa high uncertainty you would then doanother search query to get betterinformation maybe for that and thatobviously with our interest in weviateand retrieval augmented generation has ahuge application but you mentioned MonteCarlo tree search and there's this otherreally exciting uh paper called tree ofthoughts where you know you sample thesePathways maybe you have some kind ofthing that would like cut um cut nodesand then you know keep sampling and soon but um yeah so and that kind of thingreminds me of like the you know like thealphago that how it had that Monte Carlotree serves that kind of look aheadsearch how do you see that kind of likelook ahead search and language modelingyeah I think this is a reallyinteresting Direction I also see againcoming from programming languagesthere's really cool projects that we'regoing looking at and maybe hopefullywill find time to eventually do um Ithink that's cool essentially if youthink about these like three or fourthsfor instance it's a form ofum yeah X search-based programming likeyou build these reasoning algorithms ifyou want to call it that that andthey are essentially defined a thirdprocedure in this tree where you expandthoughts or like hypothesis and and likeforms of reasoning the llm produces andultimately of of course this this isintuitively it makes a lot of sense thatthis will actually help um with overallaccuracy and quality although again likeI think prerequisite for this is thatinference will become much cheaper muchfaster and also should run in parallelof course so you can actually exploremany branches at the same timeum also like ultimately I think the bigadvantage of these methods isyou can run an llm and if it doesn'tgive you the output you expect you canrun it again you can sample from an llmright but this is sort of a never-endingprocess like in the end each time couldbe the one time that it eventually worksout but there's no guarantee so umultimately what you actually want is thepower of l m is this rate this this umability to sample but also a form ofcombinatorial search through the spaceof possible answers so that you get someguarantee that eventually you will findsome model some solution to the problemthat you're looking for and um I thinkthere's cool hybrid solutions that youget to build in the space and I see lotsof potential areahmmyeah what you're saying is reallyinspiring just I think just generallythis is like connecting like model basedreinforcement learning where the agenthas like a model of its environment soit can simulate you know actiontrajectories and I guess there's allsorts of like exploring exploiting thatyou could do even within traversing yourown world model right like usually Ithink in reinforce and learning youthink of explore exploit is like uhstrategies you should take wheninteracting with your environment Ithink there's like umuh I don't remember the name of thepaper but something where you knowthere's like intrinsic motivation wherethe the desire of the exploration is tostrengthen the world model and then thislanguage model is the way it cansimulate you know different trajectoriesit's also fascinating but so yeah so Iwanted to kind of definitely touch onthat because I think when I first lookedat lmql seeing the ARG Max I imaginedpeople listening who are looking intolnql that might be one of the newerthings to look into and then but let'skind of I want to talk also just aboutbroadly how lmql connects L alums withtools and sort of like generally yourperspective on you know that kind oftool use conceptyeah definitely so this big priority orI mean in the end our whole philosophyis to say well can we sort of interweavejust general programming language likeand python in our case like lmgl isessentially a superset of python you canjust write whatever you would write inPython with the ability to to ask orlike query a language model along theway and during execution and this meansyou can actually go forth and back witha language model called Tools in betweencalled external retrieval systems likeyour vector database polar informationand this enables a very seamless andvery close coupling of of llm promptinggetting some results and possibly astructured form executing some core asan external tool and then going back tothe model so soum from that perspective this is reallycore DNA for us like just the whole ideawe want to essentially bring this fromprogrammability and use of externaltools to the prompting itselfum looking a bit into the future we alsohave a couple offeatures that were assumedly merged andUpstream which will beenabling of much more easily so soessentially there will be a seamless wayto just expose some functions to themodel and it will be able to call themalong the way without the need for youto specify a specificum protocol of how the model calls thefunction and how results are fed back soso definitely a direction we are alsoactively exploringyeah I'd love to just kind of like thatway of how you expose functions to thelanguage model to get a little moreclarity on that because I see you knowopen AI funks I think they're calling itor you know or it's like the Jsondictionary kind of syntax I see in lmqlyou it looks like you know it it's likea hybrid between Python and SQL and sortof how it looks and there's like youknow death where you define like thecalculator and stuff so so yeah I guesslike umyeah like the design of how you're goingto prompt the interface of functionstowards to large language models and Ithinkyeah I hope that's not to like notspecific enough of a question I guesslike umthere's something interesting as wellabout uh there's another paper from Omarkatab and others called demonstratesearch predict where they would alsocouple examples of how to use two toolsor tasks broadly where you add kind ofexamples into this sort of thinking aswellso yeah hopefully that sets the stage ofum yeah I meanthat like a very good I'm starting withthe function chords this is obviously avery interesting um thing that theyenable nowumwe do intend to implement this althoughnot really just wrapping their API weactually what our goal of lmql ingeneral is to not be model specific sowe intend to implement something verysimilar that essentially works likefunction calls a bit more seamlessbecause we're already in Python so wecan already you just pass the functionyou don't need toum bother with Json schemas andeverythingum but we actually want to make this notaugmented specific so this will alsojust work the same way with open sourcemodels basically abstracting whateveryou need to do on the back end to makethis workum also like another detail that I'm notsure many peopleum know about is that actually thefunction calling of opmaya is notstrictly robust in a sense that it maystill hallucinate the format it does notstrictly adhere to the to the schema allthe time because ultimately it's basedon fine tuning not actually on onStrictly forcing the model to fit to theto the schema and the schema so um yeahour standards are more in the space ofbeing vendor agnosticum and actually providing these strongguarantees because we can do this withour constraint decoding enginecan we assume that the constraineddecoding engine I've seen likestructured output parser from Lang chainand I'm you know familiar with this ofmyself where you try to have it likeoutput a Json dictionary and then yourthe idea is you're going to parse thekeys in the output from the languagemodel and it's like so important that itum you know followed the rules sort ofso is this just kind of like umyou know like if it's doesn't output andthe square angular bracket after searchyou reject it like what are the ideasbehind constrained samplingyeah so I think this is one of thebiggest issues with if you think aboutEllen Amsterdam programmabilityperspective this is one of the biggestissues like in regular programs youwrite a function as you know whateveryou call this function it will do whatyou wrote down like typically these arenotum randomized in behaviorum but with llms it doesn't quite workthis way like all the examples you usedduring development could be fine butthen um at in practice when some useruses this function indirectly becausethey use your productthis may just fail for for arbitraryreasons like there's no it's really hardto get a grasp on why they failedsometimesum and this makes programming actuallyreally hard right this means functionsfail randomly and not just in a theyproduce the wrong output sense but theydon't even produce output in the rightformat like this is sort of theinterface robustness is not even givenso so I think and this is one of thecore challenges I still see with llmprogramming and also what we try to workon is make this interface 100 and evenif the result doesn't end up beingcorrect this you can deal with but ifthe format does is not correct youessentially getthe equivalent of null Point exceptionsin your language and this will typicallycrash your program unless you handle itsomehowum very reflexively but this is alsoreally difficult to work withyeah I love that you just named thatinterface robustness I hadn't heard thatparticular phrase and I think that justNails it right on the head I'm familiarwith robustness and deep learning aswell like you know some of the stuff DanHendricks did with um like imageclassifiers where he would show that youknow if you increase the brightness ormake the image snowy all of a suddenthat imagenet test set accuracy goesfrom like 95 to like 40 accuracy and youknow obviously that kind of thing ismanifested in language models as welland so prompting it to use a tool youknow could create that kind of thing umyeah it's a really fascinating kind ofthing is just forcing it to use thetools and I guess kind of one more thingbefore moving on topics I wanted to getyour opinion on earlier I mentionedgorilla gorillas like llm fine-tuned touse particular tools like you knowGitHub CLI to make pull requests andstuff and I've been thinking reallyheavily about you know with weaviate youknow we V8 you can see weaviate as atoolI see kind of two schools of thoughtwe're thinking about this you can eitherjust think about retrieval augmentedgeneration in a pretty blind way whereyou the vector search engine just givesyou context blindly sort of and then youjust put that into the input or you canthink of it as a tool where you'redeciding like which of the classesbecause it's you know like vectordatabase like you have like differentclasses for your data you like which ofthese classes do I want to searchthrough which of the properties do Iwant to access or you know maybe evenformulating your queries this one's alittle hand wavy but maybe the idea ofum you have a particular query that youwould say oh I want to wait bm25 higherthan Vector search for this one or Iwant to re-rank it with a cross encoderso like generally kind of like the thetool of levia like using the API so Ithink heavily about whether we shouldtrain a language model that you know islike that glue betweenusing Eva so so I guess the the questionis like how do you see these kind oflanguage models fine-tuned to aparticular tool whether that's weviateor Wolfram Alpha or you know what haveyouI mean fundamental isI mean it's very clear that fine tuningwill help the model to adhere towhatever youwanting it to doumcoming back to rent a faith robust andfine tuning is just the same we'll justfail in the same way maybe at a lowerrate but I guess the problem here is ifyou have more than one call and you havea low percentage of each call failing insome you will have actually a High umhigh probability of things failinglike of course you want to um you wantthe language models to actually befinding to exactly what youneeded to doon the other hand what I hear andwhatever I think is the most one of themost umyeah fun aspects about elements and alsolike in terms of inner economical termsthe fact that you don't have to trainthem is actually one of the biggestadvantages and biggest strengths rightreactional purpose multi multi-tasklisteners and you don't have to trainthem meaning you don't have to investthe effort and time to build data setsand in some situations this may not evenbe possible like it's sometimes reallyhard to construct these kind of datasetsyeah I guess like is a solution tointerface robustness just you take theoutput and then you saytemplate it and say did you follow theinstructions all right and then see ifit revises output right isn't that kindof like the umthey used to have an uh there was a namefor that kind of prompting I thinkreflection spelled funny like with an Xyeah I mean just one way to do itif you assume someindependent error rate eventually youwill get thereand practice usually there's noguarantee and if something is wrong it'stypically because there's someweak spot in the model and even if youmake it revise its output it may stillhave somehow some weird internal statethat makes it repeatedly make the wrongdo the wrong thing rightnow concretely how we implement this andalso the fundamental technique behind usthat other Frameworks start to pick upon also is the idea of constraintdecoding meaningyou don't even allow the model in termsof interface robustness to producesomething that would be illegal youforce it to produce it it's a bit likelike one very traditional way of doingthis is just hooking up parser and sayyou can only produce tokens that areactuallyum allowed next according to my grammarand this makes the make sure that themodel will only produce outputs that areconsistent with your grammar and thismeans you can pass this robustly andthere will never be a situation whereyou will end up with an output that youcan't parse in the sense so essentiallyyou force the model strictly to adhereto a certain for output format andthere's no need to revise or evenum depending on how you do it definitelyeven not even aum you don't even need to tell the modelabout this like you can just restrict itstrictly restrict its outputdistribution to only fit in this formatthat you provideit's making me think of likeum you know like automata Theory and allthat kind of um like grammar regularexpression that kind ofbecause I'm just like kind of you knowgetting the story of Luca interest inprogramming languages and now it'staking it in this kind of Chomsky likeum perspective so you think about it andcan you help me kind of understandthat perspective of like formallanguages a little further and how thatwould Inspire this designyeah so actually the parallels to aparasu and also like trumpskin andlanguage theory is isum very clear and and also in in termsof expressiveness you can very much umlike anchor it there like if if youthink about from a person's perspectiveit is it is essentially a dynamicallyconstructed parser that's hooked up toyour language model and that will makesure that the that or the language modelcan only use the follow set as you wouldname it in in parser termsum of tokens that will can actuallyfollow at the current position it's abit like when you write code in your IDEand you open code assist it will onlyallow you to insert identifiers andkeywords that actually are legal at thisposition in a programhmmwell yeah so that was an awesome tour Ijust gained a ton of understanding ofwhat a what an llm programming languagewould mean especially in this context ofum you know of uh interfacing it withfunctions and having it adhere to thesyntax or having it adhere to that thiskind of thing um so kind of skippingtopics I I wanted to jump ahead tosomething that just blew my mind when Isaw it which was the lmql playground Ithink this is such a cool visualdemonstration of these you know complexlanguage model callscan you tell me about the design of ityeah so we um essentially when we in theprocess of building um we started toalso build a graphical or visualdebugger interfacewhich is actually fully available on theweb so invite everyone to just go to itslmgl.ai playground you can actually runall of nmql in the browser in thisgraphic user interface which will allowyou to gain a better understanding ofwhat's actually happening alsoespecially on the decoder level if youalways wanted to see like a visualrepresentation of how beam search worksor what other tokens the model hasconsidered at particular points andduring generation like all the differentrates that were not explored actuallythis is a really cool way to see thisum also big shout out by the way to theEmpire Diet team they're building apython webassembly version of python andthis is the only reason that lmqlactually can even run in the process sothis is also a really awesome projectum now the playground itselfI would say it's that it out as adebugging tool and we still use itheavily in that sense because it enablesus to reallygoes token by token step by step we do alot of token by token computationsmasking validationum also all about decoding algorithmsthat are branching can be visualized asit is a craft view that actually allowsyou to see all the different sequencesthat are being decoded how they relateto each other what's the origin of ofthe coding in general so and this helpsa lot and but then again yeah on from aneducational perspective it's also reallyinteresting to explore just from as auser I would say um you would learn alot about internalsumwe also buy by the way provide actuallywe haven't this paper is not public yetbut this will come out soonwe Implement now Implement a high levellibrary for implementing custom decoderssoit's something like Trio thoughts forinstance or more advanced beam searchvariants you could now Express veryeasily with a high level language inlmgl and or in the internet of nmql andyou would get all of this tooling forfree so you can write your own decodersee the graphical results in the in theinspector on the playgroundum and play around with this yeahI definitely want to come back to thatbut just kind of like for our listenerscoming to lmqo for the playground forthe first time could you explain likehow it would visualize say Auto G Autogbt is this problem where it's kind oflike you know write a set of tasks andthen start executing the tasks and thenreflect on you know our is the executionof these tasks getting me closer to mygoal and I think it's one of thesethings that we you know is so like it'ssuch a compelling idea but then it'skind of hard to tame it in the realworld and I think this is like havingthis kind of visualization can you justkind of maybe explain the TL like thehigh level explanation like this kind ofexample of this you know like recursivedo you need to keep doing things sort ofyeah so act that's I mean that's a greatpoint I thinkum now the current state of energy orthe NPR playground is we really focus onthis single query query meaning an LGLquery is usually a long prompt thatkeeps on extending you can havedifferent parts for the elements calledbut ultimately you you're generating onetext document in a sequential orderuntil you come to an end when you havedone or gotten all your resultsumthings like Auto GPT or more likecompositional Frameworks where you chaincalls togetherum obviously actually have more than onesuch calland we definitely plan to add thisum but for this we still we first haveto realize all our plans in acompositionalum space as wellum but potentially what you want reallyisa regular debugger with function callsand stacks and the stack frame and havelike recursive chords being in thecontext of their parent calls right youcan jump into them go token by token goback out see the parent call like likethis kind of tooling definitelyum would be very usefulum although I'm not really all forReinventing the real you so maybethere's also a very smart integrationthat you could do withexisting python-based debuggers addingthe lower level of when you execute aprompt function you can actually alsostep token by tokenfascinating so it's so that kind ofparallel of you know how you would do astack Trace with you know any kind oflike you know C plus plus code or so oncompared to maybe like yeah we've seenlike laying flow where we have likethese dags that kind of you know showlike um uh you know I call thecalculator I got the result or like Iwrote this python code I executed it andthat kind of thing umyeah well it's pretty interesting I meanI don't think I have a great uh questionjust um yeah like I that hearing thatparallel really opened up myunderstanding of it comparing it withthe traditional stack tracing anddebugging that already exists and yeahit makes perfect sense so that stuffwould translate you know right into thiskind of language model stuff soyeah I think um maybeum with the lmql playground I guess andkind of like also when you originallyland on lmql uh you have these set ofexamples could you maybe describe likean example to listeners that you knowyou particularly like and helps kind ofillustrate lmqlyeah sure um so I think one of the thesimplest and andOne Step Beyond just asking Church 50something prompting method is basicallycalled Channel thought right this is sostand with me this will be new umessentially the idea is to not asklanguage model to directly provide aresponse but instead you you first askthe model to but you provide a questionyou ask the model to provide um areasoning how it would come to aresponse so essentially you just ask themodel to reason step by step and theneventually after that did this you asknow give me the answer meaning you umyou help the model in sort of providinga small algorithm basically on how toarrive to add an answer instead of justdirectly producing it and this has beenshown to to create success and that thisworks really well like this is muchbetter than just directly producing theanswer and the way you would do this forinstance in lmgl is you just write youwrite down the question and your querycode you write let's think step by stepthen you have a placeholder that youinsert where all the model reasoninggoes and then you ask a model in a thefollow-up statement Now give me theanswerum and this actually also enables you tohave like free text reasoning the modelwill do somenumber arithmetic maybe whatever kind ofreasoning is required and theneventually when you actually want toretrieve the answer you can thenleverage for instance lmql constraintssaying okay now I want an integer numberthat represents the the answerum coming back to interface robustnessthis means you have sort of a naturallanguage based reasoning process but theoutput the return value of your runfunction actually will be an integervalue that you can robustly handle therest of your program code so I thinkthis this um illnesses quite well likethe sort of standard process of how lmgltypically worksyeah that's a really great clarificationof um you know the difference betweenwhen you want to enforce the structuredoutput parsing compared to where youwant to let it just have the open-endedreasoning and um maybe to read this tolisteners to kind of also get you knowfor people just listening and not alsolooking at this uh you know if you go tolmql.ai where you click Chain of Thoughtand that's kind of the example thatwe're talking through right nowso you have the ARG Max and then youhave a question it was September 1st2021 a week ago what is the date 10 daysago in mm slash DD slash yyy Quest likeyou know forcing that kind of uhstructure already and then but then yougive the answer choices where you haveyou know a b c d e f these are each likedates formatted like that then you havelet's think step by step and then youhave reasoning and then you saytherefore among a through b the answeris result can you tell me a little moreaboutlike reasoning and result and just howlmql parses thatso essentially you have to read it likea sequential program it's executed topto bottom left to right and top levelstrings that you see in the query arejust um pass to the model as prompt andwhenever you have in your top levelstring a placeholder variable in insquare brackets this is when we actuallyinvoke the language model to produce aresponseum and to prompt the language model willget for this particular call is whatevertext has been consumed so far by asequential execution of your programand the language model will come tonaturally come to an end typically alanguage models Just Produce some end ofsequence token with return some sometext that represents the reasoning andin an nmgl in problem logic this meansafter executing the statement there is avariable defined in your program contextit's called reasoning which will just bea stringand you can access the string you canprint the reasoning the llm used you canalso just ignore it it will from now onthe part of the follow-up prompts thatyou will send to the language model sohere in this example you will continueyou will prompt the model therefore theanswer is and the model will actuallysee its previous output so in the nextcore when we produce the actual resultand it will see us reasoning it will seethe original question it will see thenew prompt asking it to produce ananswerand for result this final placeholdervariable here and we have additionallydefined constraints so we can actuallynow limit the language model to saywell result should be one of a to F andwe can enforce this strictly which canjust limit the distribution of the modelto be only across a through F and noother tokens are allowed which means wecan we have guarantees about the formatof this final output rightum because in practice what will happenthis works most of the time and then atsomeum odd generate case the model will justuse some other letter maybe or somethingelse entirelyum and you can't parse this and by usingconstraints in lmgr you can actuallyguarantee this will be one of a throughF and there's no other way that thisweapon will terminate the return valuewill be one of those and this means youcan just return this without value toyour property logic you can also use itto index an array with limited optionsin this case and this through our workrobustly without any need to do outputparsing or somehow some some fussy logicto validate ourselvesyeah I I love the way it like whereresult in you know a b c d how you havethat syntax I think yeah it's reallyit's super cool I mean I I have playedwith a lot of problems where you'resaying like if and that you know likeyou're prompting it with if else kind oflogic where you say if and then someabstract natural language description ofwhat to do with the thing and then thenoutput like you know no change needed orwhatever right and so this syntax toconstrain it to certain valuables as youdiscussed and then or constrain it to bea type maybe even like make sure it'sBoolean would achieve that same kind ofbut like I guess because it is free textbut yeah like this kind of syntax is soelegant and so it brings me to my nextquestion which is kind of a Harrierquestion is and you know you know likeit's such a convincing thing I wouldlove to get running with this like howdoes this integrate with the existingFrameworks like I know there's anintegration with llama index like isthis just kind of treated as like one ofthe structured output parsers how doeslmql kind of like what is the earlystage of this integrating in the currentsort of like llm software toolsyes I actually I'm quite happy about thecurrent state of integrating likeessentially we can integrate with all ofthem more or lessand the reason for this is that mostFrameworks are um compositional and theyhave this black box perspective and theydo lots of training cards together orlike even in some kind of tree structureand I'm index they do lots ofinteresting thingsbut since they assume the language modelitself is a black box and lmgl mostlyoperates in this black box we can alwaysjust fit in this black box State it's ablack box to them they have noassumption about its inner workings andlmgl fills this black box leveraged somemore some more advanced information fromthe llm and so in that sense we can forinstance a link chain we can justoperate as a chain component we can justit's just a lmql lmql queries are justpython functions and and this fits verywell with multiple positional frameworkso so there's lots of um yeah to be hadfrom each other so on the one hand wecan use dama index or next chain toretrieve use with all their retrievalIntegrations to insert them into theprompt on the other hand lmql programscan be used as part of your agent wherewe have like Auto GPT variants usinglmql all sorts of projects just employedas sort of the as a fundamental buildingblock and what they're buildingcompositionally with L M'syeah it's amazing I I guess like kind ofthe other thing is like you know I Ilove this kind of like the llms writethe code and I think this um like I lovethis question of like I feel like thellm itself could be prompted to writelmql code like if you uh you know say uhyou give it these I think nine examplesof tell a joke packing list Chain ofThought and then you give it theseexamples then ask the LM to write newthings do you think about interfacinglmq well that wayyeah I mean it's it's um obviously inthe current uhday and age this is number one thingpeople talk about also to us andobviously as PL people like we work onprogramming languages we design when amodel and concise abstractions that'sour at least a labor of love and thatthis hurts a bit likewe build a nice programming language andthen people don't want to use it theyjust want to llm to use itum which is actually an entirelydifferent very interesting program canwe build the programming languages thatare work particularly well with llmsum because this is fundamentally theyuse the lnfs are really good at usingfor instance python because it's popularon the internet but what if we decidethe language that was by on by on firstprinciples based on being an interfaceto LMS and not to humans this is a veryinteresting problem I think to work onlike to see lots of potential there asfar as it comes to lmqlum we have some limited experience withthis essentially for instance if youwrite Adam Q L and you're editor ofchoice and you have for instance GitHubco-pilot installedum GitHub copilot will after a fewdemonstrations of lmql effortlesslywrite lmql like it's so close to Pythonand semantics are mostly declarativethat it's not really hard for for umthe auto completion models to pick up onthisum we haven't done more for ourexperience experiments with intendersumso there may be something there for usit's mostly about time currently like wehave so many directors and projects toexploreum incredibly busy these days so sohopefully at some point we can we get towork on this but yeah not not directlyright now it's not a priority firstyeah super cool yeah it's veryinteresting hearing the um thefrustration of a designer of programminglanguagesyeah so you mentioned the you know thetime thing and they I'm very curiousjust kind of you know I've learned somuch from talking with you in these 45minutes you certainly seemed like youhave a really you know exciting visionfor the future of this what are some ofthese like um you know future projectsdirections that you're going with lqoso I mean on a high level I think themost fascinating thing to me being a PLand machine learning person is this thisnew generation of models that'sprogrammable so suddenly like you canprompt them to do things you can composethem in new ways they're not just onetask reasoners they're multitasklisteners and for me this is incrediblyinteresting I think also um talking topeople in in like bigger labsthere is interest in building modelsthat are programmable in the sense maybeeven Beyond prompting like maybe we canfind more formal languages trainFoundation models on different kinds ofdata that are programmable andcomposable in the sense so so I think ingeneral this field is is really amazingI think multi-modality definitely wantto integrate thisum not sure about the programming modelsthere for instance programming withimages is very different usually thanvisually and then with text like text isobviously the most the closest thing toto code as well so um yeah we'lldefinitely explore this this I thinkthis is incredibly interestingin Array like also our industry paperthe core Insight is prompting isprogramming like this enables a new formof of programming that will befundamentally different from what weknow so far becauseyou don't have to specify every detailyou have these new reasoning enginesthat you can use as building blocks youcan make fussy things hard things thatare things that were hard so farsuddenly became much easier to do with land m so so it's very interesting toexplore it in this waycarve it out on a much more concretelevel we also have lots of things youwant to do with lmgl of courseum we're definitely thinking aboutcompositional stuff like chaining stufftogether mapreduce Style computationswith llms and I've for now we're veryminimalistic we try not to add too manyabstractionsthe feedback from the community often isvery harsh with regards to theseum I think there should be well thoughtout it's hard to find the rightattractions as long as things are movingthat fast but we definitely have someideas around like algorithmic use aswell like llm-based sorting algorithmsfor instance or like just using llms asdata transformation tools to go from oneform to another in a much more machinelearning based wayand then like something that's more orless coming up more or less immediatelyis also types like we will add types tolmql we have intentional types for nowbut this will extend toum reg X matching but also structuraltypes likedata classes Jsonum yeah I think this will be reallyuseful and correct practical to havealso valid and programming in generalyeah that's a I love that you knowfuture perspective also immediately verygrounded I you know I learned a lotabout you like the structured outputparsing and being I think one of the keyconstraints to enforce with a largelanguage model uh programming I lovethis kind of moving data from one formatto the other like CSV to Json that'sjust like a common thing that peoplewant to use but umso I really wanted to earlier I broughtthis up quickly there's there's thisother uh I wouldn't compare I wouldn'tcall it quite like umlmql but uh demonstrate search predictDSP basically the idea is umlike one part of the idea that Iunderstand well and I'm sure I'm alreadya much better description of it but likemy understanding of it let me like FrameIt That Way first is like you wouldretrieve some examples of a task so youhave some input output of likeI don't know how I like to respond toemails about we V8 something'sparticular like that and then it willum look at intermediate tool use kind ofchains to to get to that output thatyou've demonstrated and you give it afew examples of it and so it willcompile some kind of like intermediatereasoning chain sort of and it makes methink and then you you know because youmentioned the multitask learning kind ofperspective and I guess I'm just I hopethat I'm framing this right but likethis thing about like gradient descentis it still needed to adapt to new tasksor do we just kind of like compile newchains of tool use and checking partsand adding structured parsing andin the middle I hope that question isclearyeahI mean coming from core machine learningmodelsI'm not ready to give up on on gradientdescent let's say am I before I workedalso on differentiable programminglanguages and actually I think there'slots of really cool potential to explorethere like there's this ongoing debatealso about is prompting enough or willprompting actually eventually die andand fine-tuning ruler wise againum obviously for now the more resourceuh conscious thing to do with proteinbecause you don't have to spin up yourown GPU machine some of these reallylarge models are not even feasible totrain for smaller companies but thenlike there's these much more veryinteresting Pathways to to fine-tunemodels nowso I think actually um and we'rethinking about this likecompletelyum dismissing the the neural layer thatactually is below below the text layerthat we have now is I think it's it'snot umwe shouldn't do this like I thinkthere's lots ofum bottlenecking like the text layer isactually a bottleneck like especially ifyou chain multiple chords togetherum lots of information is lost in justputting the output text of one call intothe next call like the model has veryrich representations internally so Ithink actually composing models and alsolarge pre-trend models on a neural levellike actually passing hidden Stateslatent representations along this couldbe really interesting in the futureobviously for now it's also a resourceissue like you need gpus you need to runthis model small or less locally to dothisum but yeah thinking longer into thefuture I thinkwe may even go back to the neural layernot say on the text layer I think textlayer is also something that was bornout of the practicality and and foreconomical reasonsso oh this is it's really reallyinteresting I like I'm reallyfascinating in these architectures likeretro Fusion indicator memorizingTransformers long llamas one that Johntrengrove at levia sent to me today justlike the latest iteration of this whereyou you know you have the um attentionover vectors retrieved by something likea vector I don't want to say Vectordatabase because you know like a vectorindex like it's something to facilitateapproximate nearest neighbor search atlike absolutely enormous scale and thenthe difference is instead of justputting that in the input layer you putit in layer like eight out of 12 of theTransformer and it attends over thoselatent representations and you couldimagine like there's this other papercalled uh Transformers are Universalcomputation engines or something thatshows that image embedding spaces can beprocessed by text embedding models andwhen you give it the latent space andthe intermediate layer not the input soand then you're describing thiscomposability thingso it's like this idea of having somekind of debugging for that kind ofarchitecture as well that kind of likeintermediate so so yeah like um how doyou see those kind of architecturesbeing realized though is it going totake someone you know just just tryingto you know change out maybe one of theopen models like MPT or falcon or sayyou know gbt3 is modified to have thiskind of extension because you know likewhat's kind of the state of that likeputting the latent representations inthe middle of other models and combiningmodels and then combining models thatway it's really fascinating stuffyeah so I mean I think umif we look at open air what they doum currently they're very into this wehave a text-based API you put text andyou get text out and the chat apis aremuch more limited than the previouscompletion apis they're moving moretowards this it's a match function itdoes sometimes that's what you want itto doum obviously that's actually moving awayfrom this interface that we would needto implement more um neurally basedsystems and so I guess to do this rightnow the only way is to actually workwith open modelsum I also can see if this actually worksout like I'm sure many people work onthese kind of issues also already ifthis in the endumas promising also to them I can imaginethem opening this up maybe providingsome kind of platformI mean at this point we don't knowum I think for now we areeven open it as GPU constrained at leastthis further now so actually exposingthis kind of much deeperuminterface would be difficult for nowand probably also from a proprietaryperspective not too smart like if youleak your hidden States modeldistillation becomes much easier ofcourse so yeah I guess if you want toimplement this today you will probablyhave to withhold two open modelsumand then for other things moreproprietary apis it will be interestingto see a red interfaces go like our chipD4 will also at some point accept imageinput which will be a limited form ofthis or less red you can now also embedsome image and this will be passedthrough to the text model to beprocessed by the text modelyeah it's hard to tell at this point Ithink um resource constraintsit's for everyone with those constraintsare currently the bottleneck to do thisyeah it's totally this is thisconversation has totally opened my eyesto how this is I've heard these thingsthat those these rumors on Twitter andso on that gbt4 is like a mixture ofexperts model and I think thearchitecture of mixture of experts iskind of like a composable model in oneit kind of reminds me of just like youknow like lottery ticket hypothesisshowing that sparse networks can youknow carry the burden and so it probablywhat happens is we have this like mix ofsparse networks it's kind of like thatum a thousand brains Theory uh it's beena long time since I reflected that butlike that kind of idea that you you havethis kind of composability within densearchitectures as is but if youexplicitly separate ithi so I mean it really makes me thinkabout like whether Vector indexes wouldcompose embeddings from multiple modelsas well it's not something I've everthought about like having like open AIembeddings as well as clip and uh likeyou know the Ada two text embeddingswith the clip embeddings like totallyseparate models but in the same kind ofindex anduh yeah there's just so many interestingideas to that I think really so yeah uhso yeah it definitely got on the trainof thinking towards the future it youknow I think we're mostly thinking ofcomposing model inferences purelythrough the text input text output kindof landscape do you think like I thinkwe're we might be dreaming a little bitdo you think that's how long do youthink that'll still be the most commonway of interfacing models with eachotherwow I mean at this point it's reallyhard to say things are moving so fastalthough yeahit's really hard to tell like at thispointum bigger shops closing down more andmore means also that any day someonewith some new model this has somethingbigger and and the tire research fieldsare being disrupted by this more or lessso it's hard to tell where this is goingum I think from a programmingperspective the text layer definitely issomething very accessible likecoming from PLhaving a model that takes naturallanguage input and thus more or lesswhat you tell it to do is the bestprogramming language in the world rightit's just natural languageand there's this incredibly accessibleto so many people that's also read somany people use chat GPT because theyessentiallythey're essentially just overnight learnto code because they can just instructyour computer to do something and itdoesn't and likehaving a lot of passion about coding Iget them like obviously this is amazingto them having disability now andbut so in that sense I think the textlayer is really interesting as an inputas an output of course you can also doimages I've seen really cool projectsaboutmodels outputting code that then rendersas user interface this is also reallycool like personally I've grown a bittired of reading long wordy paragraphsofa language model output like the scenesthis seems to take it like for mypresent test this takes too long I willtell youum effective in taking out up thisconfig informationumso yeah I think there's lots ofum benefits to the text layerum especially for likeeveryone that's not super technical andwants just wants to use some somechatbot API or some chatbot interface toget some answers to their questionsyeah I think I mean this wholeperspective I think most of thellm Frameworks I don't likeI guess it's like I still think of lmqlthis way even though I think of you as ascientist like like I think what we'retalking like what we started talkingabout about discomposable models I stilldon't quite understand how that wouldwork and Allen kill quite yet but I'msure that you'll figure that out but itjust like umlike moving past text being the how thebottleneck for uh language model chainslanguage model tools interacting withothers even just with embedding so likemaybe let me take a step back and tellthis kind of like you know like we havethis feature in weba called ref to VECthat we often use for recommendations soyou know I'm Connor and I like thesethree basketball shoes and so then Ihave like this Vector that captures mytaste in basketball shoes or like say mytaste in movies right and then I haveLucas taste in movies and maybe we findsome you know we average these vectorsand then a generative model you knowproduces a movie that would be somethingthat me and Luca would likeyeah it's kind of like moving intotensors or vectors I mean how do llmFrameworks get there like it's such ait's such a eye-opening ideaI think it's totally different Paradigmlike I I thinkand and it makes sense like we'recurrently building things for the textlayer and and this is really cool andfun if we I think this would be adifferent thing like there would be Iguess different abstractions I mean I'mnot even convinced that we landed on theright abstractions currently on the textlayer there and also the models arestill moving so so who knows where thiswill go like essentially we just have totry out most things and then see whatworks right and thengoing to this more umlike I would say that what you proposethis sort of averaging of vectors andthen putting this into a model that thisis definitely some form of composable orprogrammable model and at that pointright you you really Define a program ofwhat you want and then the model sort ofexecutes steps that that you um Defineyour algorithm right so umyeah I mean I meanI think it's it's probably not a timeyet that this actually works or this isactuallyum something people do or buildI mean in research for sure but but likenot optional on the level of llm andtoolingum but once this actually becomespossible I think also lots ofinteresting new programming ideas willcome up no new Frameworks new languagesand yeah with the current lmglum I think we would move a lot in thepresence of such a such thingamazing Luca thank you so much I thinkyou know just um you know firstlyunderstanding lmql when I first saw Ithink just like you know when I firstsaw the lmql my first impressionpersonally was it reminded me of levierdesign how we have kind of like agraphql API as well as these clientlibraries and you kind of can see thedifference in in my opinion it's easierto design the graphql and I because Ikind of feel like the syntax of lmqllooks like that compared to a lot ofthese Frameworks like you know I don'twant to name them but like that requireall this buy-in you know this is alittle more open-ended than that so Iwas always already super impressed withlmql the lmql playground is a visualthing I'd highly recommend people to seethat because it's it's brilliant reallyit the way that it lets you visualizethis complex prompt uh execution isreally super novel and then those ideasaround structured output parsing thatkind of like wear clause in the lmqlsyntax and how that restricts the thingall amazing stuff and then start addingmore thing but how lmql alreadyintegrates with llama index Lang chainyou know is something you can kind ofget running with and then it just kindof towards the end of our conversationthis discussion of you know the textbottleneck that just really opened myeyes into how the space could evolve soyou know Luca thank you so much for thepodcast I think you're you know buildinga super incredible tool and youdefinitely have the Visionary aspect ofseeing where this technology is headeduh before we wrap up could you givelisteners like your media like how tofollow along with you like are youprimary publishing papers are you onTwitterthey are definitely um you can I meanlmgl you just find at lmgl.aiwe also have Twitter accountum and I'm also on Twitter um ourcalendar maybe we can link it somewhereyou can follow me thereumand yeah also please if you want to tryout lmql do so we have the Discord wealways most of the time we're online andhelping people also so please feel freeto reach out there as well and and happyto help and discuss also like morebroadly and then I'm programming andright this can go yeah and thank you somuch for having me yeah well quickly letme ask I'm curious about yourperspectives on this Discord uhCommunity how has your experience beenbuilding something like that for a newtechnology like thisum it's it'sum I actually really like interactingwith people talk to them a lotum it's a bit overwhelming to be honestthis is my first open source project atthis scale it's a lot of supportrequests and all of us and the teamalready have full-time jobs soessentially it's another full-time jobto do this um but at the same time thecommunity feedback also has been quitequite amazing and and people start tocontributeum and we are still like very muchwelcoming everyone who wants to to hackon lmglum brainstorm andand also like happy to help outbeginners talk about the issues with NFLmaybe you didn't want to get somethingrunning with totally I'm happy to helpwith thatyeah I think it'll be it'll be a reallycool demonstration of um you knowCommunity feedback plus this sciencethis vision of it and yeah I'm superexcited to follow along with it Lucathank you so much for joining the webapodcast this is truly one of myfavorites I learned so much about thelarge language model space and how thiscan developthank you so much for having me Conor", "type": "Video", "name": "Luca Beurer-Kellner on LMQL - Weaviate Podcast #59!", "path": "", "link": "https://www.youtube.com/watch?v=cuWLPHDAQ5g", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}