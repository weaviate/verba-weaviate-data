{"text": " \n[Music] foreign [Music] air we have a whole crew with in here I've got Zen JP Conor and Erica and myself of course and this episode is going to be super exciting at least it is for us and hopefully you'll find it as exciting on your side and today it's all about the the latest that we V8 release but also will have something from Connor towards the end about like what's new in the AI just like we did last week and I think this is super exciting so what we would like to do first is maybe a quick introduction from everybody on uh on on this stream and I guess we can go in the order as we have it on the screen like so then you want to go first sounds good to me my name is Anne hessen I am a senior developer advocate here at semi Technologies I'm based out of a snowy and called Toronto Canada where getting into that snowy weather hopefully soon I enjoy it a lot of people don't enjoy it but it's a little bit about me I'm an engineer data scientist by training throwing it off to you JP oh this way thanks thanks Ed um yeah my name is JP I'm a technical curriculum developer at semi I've been here about a month now and it's been really really exciting obviously it's my first podcast or a live video session here so I'm really excited to be a part of this and yeah I'll be kind of shaping a lot of the sort of educational Journey for the audience who's come using uh weaviate for various bits and pieces of their work so I'm really excited to be on board for the uh for the journey awesome I'll go next hi everyone I'm Erica Cardenas I'm a developer advocate here at semi um I'm based out of Boston I'm nervous for my first winter but I'm also looking forward to it and I'm excited for this episode we're going to Showcase a few cool things and hey everyone I'm Connor also in Boston uh as they mentioned with the weather moved to Boston from Florida and we're having our first snowy cold season and missing Florida a little bit but a research scientist says semi and uh been working on figuring out deep learning and search and it's been so much fun perfect and I guess I'll go last uh so hi I'm Sebastian I am the head of Deborah here at the semi uh leading this amazing team in front of you um yeah and basically I'm all about like sharing everything that we are working on and uh hopefully you all enjoy that um so okay so what we're going to do today let me give you a quick overview of the overall flow and and the structure uh so the idea is and I already mentioned it a little bit but the idea is like um yesterday we had a release of vivid 116 and we thought that this is a great opportunity to pretty much share what uh we we worked on what went into that but also like as a bit of a background so as part of the whole uh release flow the team here that you see here each of us had like a different uh part of the the new features or changes that that we were involved with sharing uh so we we created this release blog post uh and and then we thought like hey like why not actually uh again go in with air and then talk about the segments that we're writing about and maybe like get into more of a conversation or maybe demo some of those features uh so that's a part number one and then the second part again like I mentioned earlier I will have Conor who will go over the cool things that like the cool papers that he was reading about uh in October so Connor I can't wait uh to learn more from you uh and yeah that's pretty much the general idea um okay so maybe uh instead of asking for volunteers I'll volunteer myself uh to open with the first segment so something that we did that was different around this release or at least since uh v115 uh we changed the approach in terms of how we are releasing patch releases so in the past we would be more like we always had patch releases like that starting new but in the past we used to kind of think like okay in order to release a patch release uh we would say like okay let's get this and this and this fix together and once that was ready then would kind of like cut that patch release and then then push it but then we realized that as much as this was very convenient for us to kind of do everything like well one touch goal or Etc um we realized that people had to wait or you had to wait basically for uh these fixes or future improvements to arrive right so uh we kind of changed the focus and the idea was to kind of like let's go and as soon as we have a fix let's publish it so that everybody in the community everybody that uses Vivid have it available uh and then incidentally enough uh today uh Erica you can probably talk about it a little bit um but Erica was work you were working on a demo right uh for for your later segment and what happened yes um I noticed it wasn't working I couldn't perform the queries that um is written in the documentation I was kind of going a little crazy I'm like maybe it's an error on my side but we found a small fix and first of all Aaron Dirk was able to help and he submitted then he submitted the first patch release of B16 so that's awesome yeah two so there you go like there was like a quick bug that we we discovered we should have discovered maybe a little bit earlier but that that happens sometimes uh so there was like a specific Edge case that was actually used in Erica's demo um but this was the really cool thing right like we talked to Derek in on the engineering side and was able to like Implement uh the fix and we already are like yesterday we published a 160.0 today we published 16.1 so that everyone can actually have a nice and working version of widget which is absolutely great um so yeah that's basically it from my side in terms of uh my update but I think uh since we already mentioned it uh from from Erica about Erica then I think we can move to the next and maybe one thing I should have done probably by the way like I'm I'm such a rude person it's like thank you all for watching and taking time uh because uh thanks Conor for uh finding it out uh because I think it's really important that you take your take take the time to to join us on this stream uh and if you do have any questions uh FYI while uh you we are running this uh this is a live show uh so feel free to ask any questions and and we'll try to answer them as we go as well um all right so I'm going to pass it on to Erica so Erica what do you have for us all right I have I will be covering the two new filter uh operators um that are part of the B16 release would you mind sharing my screen and I've created a demo out for you guys uh the first one is the um is null so you'll be able to see um where the properties are missing or it was set to null um and then also you're able to filter by array length um so I will share a visual of this just because it's always better to demo things out and then this is also how you find bugs um so a little bit like a backstory how I created this demo and kind of why I'm talking about food allergies is because we are all going to Italy soon and Jesse a wonderful head of people asked does anyone have allergies I think maybe like five times and I don't have any allergies but I understand the importance of it right um so Bill Nancy and Samantha are like a few people on the top they do not work at semi I guess I should have used our names our real name Sebastian thinks I can I see like dead people like I can just I have imagined friends um is Bill not in the company and Nancy huh I guess they're just in my imagination um so yeah here we have a few people and their specific allergies so um for a few people they have one but then if we scroll down we have Noah and Emma um so as you can see for Noah he is missing the property completely um but then for Emma it is set to null um but this it will important to deviate the exact same so I just want to make a note if you are importing a data set that is ginormous and you just don't have the time to go through data cleaning um this is a nice feature where you don't have to make like um you don't have to make sure that the property is sectional it could just be completely missing which is very nice and then if we scroll down we have George and Victoria who are the ones who we need to pay uh give extra caution right because they have more than one allergy and we can see this in the console in a few minutes of how to take the right length um and kind of see the people who have more than one hour energy um all right so this is a little bit about the data set and what we're going to be getting into in this demo um quickly I will go over to the did that you still see my screen okay uh we can steal your vs code yes let me just get that okay are you Ken see it are you good okay sorry about that all right so here we have our scheme on everything is standard um except with uh V16 if you want to index by the no state or also by the property length you have to go into the inverted index uh config and set these two um parameters to true the default is false um but maybe if you anticipate your data set having no values or that you want to filter by the property length then just set it to true it doesn't hurt you right um so that's a little bit of the schema and how you have to configure that next I will go over to the um just click on it um uploading the data set um or uploading the data to eviate this is also standard but I will just scroll down and highlight the key difference that you'll need in order to perform these filters um so you have to tell viviate that if there are no properties that is okay not to break don't regurgitate like an error message um so yeah just having the lg.get you're going to grab the allergy but if there's none that is completely fine and then also here in the properties where we've defined it in our schema in the last file hey Erica I uh I have a question um because early on when you were showing the data um that we had like two different kind of examples I think where yeah Noah like Noah doesn't have allergy but Emma does but it's set to know uh will how how how how will we we respond to that what what's going to happen to that when he Imports it into a database well good question the short answer is that it will import the same but in a little more detail on movie Imports the objects and it skips the note values um but then for the index it will set the missing slational properties to null it's kind of like back and forth um so kind of does it the same but do you wanna basically doesn't matter whether we just skip the property or set it to null right exactly which is nice you know yeah it's a good feature to happen because I don't know if you have a large data set and you can't really go through it all it's convenient nice nice okay so let's jump into the console does that sound good yeah let's do it serious to see what kind of thing yeah all right so since I started off with the Israel property let me start off with that um so here we're gonna get the food allergies which is our class um and here I describe the name um just so we can see that our data has been properly uploaded um let's do the fun part of grabbing the wear filter of the isnal perfect where so and this is not a bit like this all right and now we're going to take the path of allergy right because that's just where I have me missing properties um and then we have the Valley Brewing um so this you're going to set it to true and then we can also see that if you want to set it to and then we obviously have our new operator of the isnal and they shouldn't worry all right it's a Moment of Truth everyone hold your breath um so here we have we're taking the allergy um property and setting it to if the property is missing um yeah it's just going to return the names where it is missing and then the alternative is to set it to false to find the people who do have the allergy located okay cool that's uh by the way I'm impressed how you can write your graphql under pressure or live and everything so uh that's that's pretty impressive but that's really cool um so I guess um at least my take away from it is that like we could use it to like maybe find people that do or don't have allergies but maybe we could also use it to like clean up our data right like say if we're missing like email fields and then you could kind of go like hey let's uh let's make sure everybody in my in our database has emails so we could like very quickly just find like hey um I said null is fine to the database but maybe not for the cleanliness of my database right course and in Jesse's case this would be useful just to confirm that everyone won't have a food allergy or need an EpiPen in Italy right so differently well usually if you do have an allergy like you would be cautious and be prepared for the all possible cases right of course and then um for the people that might have a little bit of a bit of um and we need to find um yeah just people who have more than one allergy it's a little more severe um we're going to take you can measure these lengths hey uh could we also show the actual allergy property because I think you just showing name for now oh yeah of course let me go back it's included down here right because if the valuable line is set to false then you'll be able to see um if it has the peanut allergy along with Samantha and then um for people that have more than one it is also listed and then yeah good so let me guess you'll be now you'll be able to look for those that have more than one how did you know I don't know all right and then I can all right so we want to find people who have um more than one it's like the operator could be greater than now we have Victoria and George who need a little more cautious like a care to make sure that they don't eat these specific things but it's extremely easy and that's the whole point of it right is to show I guess yeah that's actually pretty cool um how quickly we can just find that and it's nice um yeah this is super awesome I have a question so if we go back to the um to the vs code how do I enable this functionality do I just have to when I set my architecture I have to let it know that I want this enabled of course yeah um so this the default is to um for it to be false um but if you anticipate that there will be no values or you want to index it for the property length you want to set it to true you can see you do that in the beginning because if not you'll run into errors okay awesome I had another thing I was thinking earlier in our meeting we were talking about using K nearest neighbor classification webiate and I was thinking watching there is no value maybe we could use the search with the unstructured data to fill in the missing values because I think a lot of times we use like fill in the media and you can use this nearest neighbor thing that's fill in the missing values it's really cool yeah that's super awesome you can do like 10 years neighbors imputation with this right look for null values and then look for the yeah that's it that's actually you'll hear more about that in the in the next movie podcast exactly let's do that you already signed up for it right yeah your name all over it you know I agree it's good for data pre-processing if you just want to go straight into using weavate rather than using pandas or python it's nice to have this option is there a way we could actually mix those uh queries like uh mixing length and is null I don't know we could maybe look for like hey show me the results where there are some allergies but there's less than something I don't know I think we meet way too often because you can read my mind um so this is for for people that have what did even work why maybe you're missing a closing bracket again at the end at least three indentation seems there we go hey thank you and now that's how everybody knows that this is a live demo and not a fake yeah so just people who have lost into allergies and then also their properties and such and all um so this there is a way to combine to teach operators and that is my demo thank you so much hey uh and then documentation where in the docs can we find it do you have a link to us for us let me track this over um so if you go to graphql references filters um if you scroll up here is documentation on filtering my property length and then also the it's not filter and then um there is a disclaimer that you do need to set your schema to handle this um and this is where you will find that information perfect thank you awesome excellent so uh uh this was great um so maybe how about we go next with Zen uh because then you are covering a couple of features in the release blog post but uh I'm pretty sure everyone will want to hear first about the note status API what's all that about like uh why do we need it yeah so this is a really interesting feature um it's a convenient feature really uh is what it is it allows you to once you've got your cluster spun up you want to get an idea of how it's going you want to diagnose if there's problems this is a you can submit a get request to this uh API endpoint and it tells you exactly how your data is stored on your clusters and whether there's a problem with your clusters or not and if there is a problem it'll tell you um where the where the problem is um rather than me talk about it let me show you a demo what I'll do is I'll I'll spin up a bunch of uh alleva cluster with multiple nodes and then we'll try to see if we can break something all right so let's do so there's there's a bunch of terminals that you're seeing here I'll let you know exactly this is the most important terminal here on the right I'm going to create uh nodes in these two terminals on the left so what I'm going to do is I'm going to set up alleviate and I'm going to start it up in this cluster so let me kick that off okay so now there is can I allow that okay so now in my local host under port 8080 I've got uh I've got one node for vv8 up and running and then I'm going to kick off another node here from the second terminal and this is going to occupy Port 8081 kick that off allow that and okay so many notes yeah we're good to go and this is only two nodes so now what I want to do is let me make sure I'm in the right repository I am okay let me clear that now what I want to do is I want to run a run this import file that is going to basically send uh objects to these nodes and so I upload data to these and you can see that the nodes are responding they're they're gobbling up that data okay so we're good to go here now what we can do is um if we want to know if if these nodes are perfectly fine if they're communicating well together you can go ahead and call this new API and this is the main feature that that we're showing off right we can uh we can send a get request to our um to our Local Host localhost here port 8080 that's where the uh the head node is V1 and the endpoint is nodes I'm going to take that and so this is what the response looks like it's a bit hard to see so what I'm going to do is I'm going to pipe that to my um my Json prettifier and so now we can see that well first of all you see that this the nodes get the get the request over here and you can see exactly the configuration that your nodes are in it tells you how many nodes you have so you have one node and then you have the second node over here you can also see how the data is stored in your nodes what the object count is for for each one of the classes that you've got here and the classes here are pretty generic so it's um I'm not going to go into how how the schema looks or anything like that but the main idea the main idea here is the status of the node right so you can tell that node one is healthy and node 2 is also healthy right so there's three values that this status flag can take healthy is what you want to see but now I want to show you what uh what else will happen right so let's say we simulate a crash in the second node here so I just crash this node and for everyone at home don't try to do it at home it can be dangerous only let it let it to prose like Zen to do it yeah simulating a data loss event over here okay so now we're shutting down this server and you can see that the first node uh realized that it it failed it sent the paint to node two it failed it's marking it as failed so node one knows that the second node failed but do you know that the second node failed right well now the answer is that you can know you can call this API same endpoint and now you get another response which is different from the response that we just got and now it tells you that you have node one and you can see here that the status is unhealthy because you no longer have no two and if you look into it further you can see that because your classes uh were you had object counts that were being shared and stored on node 2 and node one all of the object counts on node two are no longer there and so you've uh pretty much if this if this node loss was permanent You've Lost That data and now you can tell uh tell whether the whether your cluster is in a healthy or an unhealthy state there is also a intermediate step here where let's say you call this API in the moment that the second node is going down you'll get you'll get a status update that says unavailable and so that is a transitionary state between healthy and unhealthy but I like to think of this feature as the as the cluster doctor right you're you're basically taking your stethoscope and you're assessing whether or not your clusters are in good health but okay but is it like when it goes down completely isn't it unavailable actually yeah so that's interesting so the technology that we're using behind this um once the node is completely down uh it doesn't actually send any response right so we can't tell what the object count on that node was so here you only get node one and the state of node one is unhealthy not because Node 1 crashed but because the cluster had Node 1 and node two and now node 2 crashes right so the status here is uh the status of your overall cluster oh right that makes a lot of sense okay that's pretty cool hey what was the the command and I'm gonna change the subject slightly but what was the command that you use for predefying your Json oh this is just a JQ so this is the um so I'm piping the output into uh into this uh Json for the fire because I always use Json PP so that's kind of interesting okay and to see nice that that's pretty cool I wonder like we'll be probably cool to see next as well is like being able to subscribe to any of those events uh I'm pretty sure Etienne has some ideas around it or someone yeah I think it's pretty interesting there's so right now this is just a more of a passive monitoring um so the doctor can see what's going on they can't do anything about it or they can't fix it at this point um the engineering team has some pretty interesting ideas on on next steps for this to make this an active API where you can actually modify the state of your cluster through uh through a similar API so soon soon about that in an episode of uh We've eaten here that's pretty cool and and also I guess that'll be cool if there was a way to I don't know back up data from multiple nodes let's say I don't know oh stay tuned yeah we're getting to that yeah stay tuned for another 15 minutes and what happens if you want to rerun this simple you're being error uh no so you can run this API as many times as you want right how how about if you um fix node two um so that node one would be healthy yeah yeah so if we fix that node two here so if I rerun it see oh it doesn't run it's telling me that the the port is not available it should be available or it's permanently lost we can't run it against it and kids this is why you shouldn't be trying that at home you shouldn't be crashing your notes voluntarily it's for science guys it's for science awesome love it love it all right thanks uh thanks and this was a really cool overview so for anyone that's using clustered uh distribution for weviate uh definitely you should know about uh this new endpoint the V1 notes um all right then next person that we have is Conor so Connor you've been working on this this is actually pretty uh personal release because not only you were covering it in the blog post but you you were working on the centroid uh module yourself right for quite a few months and we spent some time working on a demo and everything um tell us what's all what's this all about yeah and thanks to everyone who's been helping me you know in the creation of this learn how new features are developed in weba and the research of product flow has been so interesting um so ref to VEC it's named as such because it's reference to Vector we have cross references between classes and I think this is a this relational structure that we V8 adds in addition to Vector search as you vectorize unstructured data you have a structured symbolic properties that you can use to filter the hnsw search and you know we have our inverted indexes of the categories there's all sorts of things we can do with the properties and I think expanding into what we can do with the relations is an incredibly interesting direction for wev8 so I'm going to start off by showing this example of ref divex application and recommendation and then from there kind of expand on the future of how we can do this and then I think that also transitions well into the topic of using ref to VEC to represent long documents that are longer than the say 512 token input length to sentence Transformers or uh and or complex objects that say it's a you know a real estate listing it's got images of the houses it's got graph structure data about the neighborhood it's got the symbolic metadata it's got text descriptions so how can we have references in our data and then combine these vectors to represent massive things so let's start with recommendation so what we're seeing now we're probably all used to using weba to you know search through our catalog we say you know search green shorts and then bang There are the green shorts and we're used to doing this kind of thing so we usually would have it as a products is our classes product and then it's a have text description and so all the text descriptions of these items are vectorized the queries vectorize and then boom approximate nearest neighbor here's your product that matches your query so now what we're doing is we're introducing a user class so user class liked item item so what we're seeing with this image grid is an example of having say a home fee or if you want to have yeah like a home feed kind of feature into your apps that you can build with weviate now so if you have a Blog you could personalize some kind of recommended articles with this kind of interface by using the centroid from the user so now let's start using it so I'm the user I you know I'm here I'm looking for a backpack I'm not looking for any of these clothing so so as you have the first backpack you see how you're now doing a nearest image search where this backpack is the query and say you're particularly looking for the strapless the strap backpack compared to like this duffel backpack so you click another strap and then it starts to you know it will average these two vectors to be the vector that you're searching through these with and so that represents the user preference of backpack so we could you know have our home feed is loaded by showing backpacks because that's the only item that our user is interested in on our uh say e-commerce website it's another fun example of this I think is looking through the watches is just an example of something that's has like a particular difference so you see with the watches how you you could have like a digital LED screen or you could have the you know the classic kind of clock style so as we you know as we do this we see we have the digital screen if we click two of them it prior it can visually tell to prioritize see how these are ranked ahead of these ones similarly if we you know click this style unclick that style and you know add that one then it shows us this one also with the same style so it's showing that semantic visual features at the pre-trained resnet and the alleviate image to VEC module can capture I think is a really fun example so it's kind of transitioning a bit so right now it's called ref to Vex centroid we're averaging out these two vectors to form the vector to represent the user another interesting idea that we're exploring is rough Divac centroids where we say have watches backpacks and we have these two clusters in our Vector space so we would have a centroid for each of the Clusters and so looking into whether we want to say use k-means or hdb scan clustering for this kind of thing and a new Eva podcast is coming out is with Martin grudendorst who developed Bert topic and he explained so many interesting insights about the difference between k-means and hdb scan clustering and how they preserve the semantics in the centroid so we're looking into that kind of hdb scan implementation and golang and delivering multiple centroids so you could have a blend between watches and then a blend between backpacks or whatever it is that you're recommending for the user so then let's talk about this idea of how we're aggregating vectors across the edges and this transitions into just one of the most interesting topics in deep learning which is graph neural networks so graph neural networks message passing networks you you only send messages in each layer of the deep neural network to the neighbors so you collect the neighbors then you have several layers of doing this with non-linear activation differentiable weight Matrix until you do something like predict clicks at the end so to contrast it with the graph neural networks one thing we could do is have like an XG boost machine learning algorithm where you would search for these watches and then you would have a classifier that's trained on clicks to re-rank it based on the xgboost classifier of whether you click this but another thing we could do is propagate these embeddings out with graph neural networks that do that node classification task and I think that's really interesting so then concluding you know again we have this idea of if you'll look at the wevia Wikipedia demo we have a breakdown of Wikipedia articles are too long to put into Burr it's longer than 512 tokens you can't just have a in for inspector for the entire Wikipedia article it was broken down into passage in article article and that's a you know that's a graph relation with the passages so the question is how do we aggregate these vectors into single searchable vectors or say we have the centroid idea so the central idea would give us multiple vectors for the article to search through so if we have the LeBron James Wikipedia article we'd have centroid to say describe his career with the Lakers Cavaliers the you know Akron Ohio these would be different centroid clusters but maybe with the graph neural networks we could compress that into a single Vector so I think there are just so many interesting ideas we can do adding this relational structure into our Vector search and these kind of cool ideas I think starting out with the recommendation developing home feeds with we V8 is I think one of the most interesting ways to get started using ref to VEC this is this is cool because I was immediately thinking like uh this this could be like a really interesting way to like provide recommendation if someone let's say you're doing research on a topic and then you're scouring like a huge database of papers and then if you saw like one paper on that on one topic and then something else and then immediately could go like oh you look at to this uh two of those papers let's say uh I don't know graph connections Etc you're like hey here's another few and then based on what you selected like continuously could provide you like more and more refined recommendations so that you can kind of keep going and keep looking for uh different articles and if at one point you pivot into certain area like the centroid the average can keep moving right yeah I love that you said that when we first wanted to explore this I was using there's this Twitter account called AK uh it would be like 4201 and he tweets new archive papers every night like six every night it's crazy and so you know I I interacted this a lot and so we extracted all the people who like tweets from AK and then we put all the AK and then we rank them based on doing this restavec and I was able to see the difference and say my recommendations compared to I did the user dissimilarity because I can use myself as a query I can also find my most least similar neighbors and so you know it was someone who likes these audio papers like it's not that I have anything against audios just that I've never looked into it and I just thought it was so cool to see it capture that in kind of a real world example like exactly if you described nice nice yeah because like you mean like also like one of the things that I was thinking about is just like uh when I watch uh stuff on like Netflix or HBO Etc right like they always give you like those recommendations based on like what you've been watching uh recently so that that sounds like something also that could work um but like how far can we go back in in with with those uh searches like is there like a recommendation like go for up to five or can we go with a hundred what what's the story around that I'm kind of curious yeah that's another really interesting idea we're looking into is in the uh in the module configuration having an interaction window so say it only uses the last three interactions in the website to form the center as right now it's the averaging in a single centroid so yeah we could have that interaction window and I think maybe another phrase I left out is just session based recommendation online recommendation how we how you could you know open up say tick tock and you don't have an account and you just start interacting and boom already you're getting recommendations you don't need to have this train this machine learning model on click prediction you can just boom start running with recommendations nice nice another I think this is pretty interesting that this seems like a game changer for both content-based and collaborative based recommender systems right um is is this more efficient than what what is currently used in those fields or because if um from what I know of the field right now they're they're essentially trying to capture the meaning behind the content that's consumed right if I buy one type of watch then they'll recommend similar types of watches maybe they'll recommend the same company's watches but what you're doing here is you're you're learning that you're learning what's similar about those watches and then recommending it okay so it's it goes one level deeper right oh yeah that's that's a good point because I always hate when like I search for something like oh yeah I don't know a new tripod for my camera and then like every art everywhere else it kind of goes like you've been looking for this I was like yeah I know there's no not much help but if you gave me a recommendations like oh that's a cool tripod I didn't know what existed but yes I am looking for a cool driver huh it really solves the cold start problem like along with new users if they're most similar to some users patterns before and even for this example when you clicked on the silver watch that's a little more fancy the backpack with the straps changed to this nice duffel bag right so you can kind of like put a whole outfit together with just like kind of searching around for what you want so it's kind of cool yeah yeah that's kind of cool that the duffel bag goes well with the silver watch it matches yeah that's super interesting because now that you can break down a product into its individual components on a vector there's nothing that's stopping you from comparing a fancy watch to a fancy backpack whereas before you were just like maybe you're comparing like the relative price of that watch versus the relative price of the backpack um and I never thought about it that way that's super interesting actually yeah I guess the cool thing is that it's like there's so many ideas that even we didn't think about and so I'm really curious how everyone else starts using it and like what kind of use cases we're going to learn about as a call to action everyone if you're watching it you should definitely try Centro it like you know uh try to come by use case that we didn't think about and then surprise us and surprise Conor most of all he's so proud of his baby cool nice nice um is that all Connor that covers the centroids oh yeah I'd say uh we're also gonna have a blog post published soon and uh yeah we're you know work at interaction window the ux for the collaborative filtering as Zayn mentioned quickly where you add the rating thing and and yeah just rolling along with this I think recommendation is gonna be such a cool use case for weviate as well as because it is kind of certain personal search yeah perfect perfect thanks a lot for uh this demo um all right so I guess we have a couple of other session uh features that we've added to deviate and on my agenda I have JP to go next uh so JP what are you going to tell us about sounds good sounds good thanks Sebastian um could you put my slides up if you don't mind I don't mind at all where are you here so yeah I'll be talking about it's going to be a little bit of a change of pace so with 116 and we've added Azure support to the way we do authentication with oidc um let's talk a little bit about RDC though because like I was writing the blog about it and I was like reading and I was like oh this is really cool and I was thinking about what kind of like is the catchphrase or like the you know fine line I want to go with and I was like well let's talk about how much we all hate passwords because I don't know about you guys but I use a password manager I'm trying to you know maintain security practices and whatnot but it is pretty unwieldy and more and more AGP sorry to interrupt as like how is that even a question like if you're not doing that if you're not using a password manager what's wrong with you some people don't you'd be surprised you know working in it or in you know Tech it's it's a bit different but yeah I promise I'm a nice person uh but yeah like if you don't like I think it's a good idea to use one um but yeah like it is a problem until we have password managers that was such a huge headache people are like oh I've got a system what is it it's my dog's name plus like four different numbers and it's like no that's not a big box change my passwords now so it wasn't meant to be a sub tweet kind of but um you know um so we'll talk a little bit about oidc so it's really cool so more and more we're seeing like these uh single signos right whether it's with through Google through Microsoft or whatever and it really tackles this one problem of like how do we secure our resources and maintain usability and I was really you know excited to see that with um at alleviate or at semif included IDC features so it can do authentication um easily whilst maintaining security right so that's kind of what my next slide is it's really a combination of the two things that give you those features it's authentication that tells the end client or the app who you are and you can trust who people say who it is and based on that you can do your authorization you know whichever way you want to so some people obviously do both in the same uh you know using the same tools I suppose so authentication with oatc and maybe your authorization would go off um but with weaviate we use oidc for authentication so we can trust that people are who they say they are not just you know a text box typed into a field so they can I can pretend to be I don't know Elon Musk or whoever um and based on that we can use we can use that identity to enable differentiated authorization and for people who's not really familiar with how IDC works this is kind of the workflow I've skipped a couple of steps but basically the point is that you know in the same way that a lot of people would have seen you go to log in somewhere whether it's uh again Microsoft or whatever and then you sign on and you get a token back and of course through the magic of public uh private care security you'll know that your token is secure and we passed that token to eviate and weavate it's like oh yeah you are you know this person Connor at semi dot whatever um or you know or you're not right because your token is uh doesn't have the right signature on it and you can send them the right response so the change with 116 is that we've added Azure support so even though oidc is an open protocol people do implement it slightly differently so that means it's not like a one-size-fits-all solution um likely we're using the module system which means that we can keep on adding these functionalities as we go and one of the benefits of course with Azure is that a lot of people would already have some sort of a you know employee directory or some sort of directory of users in Microsoft um Azure active directory so we can leverage that or they can leverage that with webiate so if you already have a database of users you can use that and get people to sign on through there get their identity tokens and go and do your do your thing in weba um so as an example of what that allows you to do is to have a one database we can give tiered access to different people right so instead of having like oh here's like one instance of we V8 which is for like Public Access you know here's like one instance of Eva for like actually private use whatever what we can do is to control who gets access to why so you might say well actually everybody regardless of who you are whether you're authenticated even if you're an economist Anonymous user you can read some part of your database right so maybe your demo data as a lot of data providers you know tend to do for marketing reasons or just you know uh just getting your getting your name out there but then with these tokens you can give one group of users read access to the whole database as long as they're authenticated and you can have another list and this is where the authorization based on your authentication comes in so you can say well actually these guys are in the admin list so they can actually read and write whether it's you know deleting um certain certain entities or entries and adding new objects right so you can do all of that and really um having these IDC tokens means we can decouple the security requirements because you know that's kind of not what we do right and people can trust that these things are happening securely you don't have to remember yet another bloody password um and it's all kind of done securely and safely while kind of not compromising on the accessibility side of things so yeah I kind of learned a lot reading about it uh writing about it was really cool and yeah it's it's good that I think you know all these um of this authentication and authorization needs are moving to these kind of open uh transparent and secure standards that are evolving as well as you know easy to use so yeah that's really cool Hey so uh because you you talked about oidc but like I also know about all like what's what's the difference like what's How do they yeah that's a good question so they're both by the same um standard open ID standard oidc is built on auth on top of that so the main difference is that there are two different types of tokens right so you can get the uh what's called an authorization token I'm gonna have to make sure I don't mess this up oh that's action token which is typically used for providing access to certain assets right based on things um but IDC is built on top of that so they provide but it all uh authentication sorry authorization tokens doesn't tell the um doesn't tell you anything about who it is it just says Whoever has this token can use these resources whereas open oidc um ads on top of that and adds what's called ID tokens right and the ID token will basically have secure encrypted information about assigned as you say information about who you are right so it'll say this person whoever is using this token is this person and we can kind of using uh we use encryption to prove that that is true right so that's that's the difference I see and how are the tokens validated yeah um so it's like the um asymmetrical but basically like it's all the magic of a spectacle encryption right so there's it's a public um private key encryption the same way that if you log on to GitHub using your keys you have your private keys and GitHub has your public key so they can see that your information is encrypted and they can decrypt even though they can't encrypt it themselves right um because they can tell that it has been encrypted by you and this is the signature kind of works the other way where it the signature is signed by uh the let's say Microsoft in this case by Azure because they've got their private case and if you have their public key you can verify that it has been encrypted by them and has not been tampered with so um yeah I don't want to pretend to go too much into the maps but it's it's all one-way functions with very large prime numbers um and all that so I did take one course in cyber security so it sounds familiar thank you but yeah just as a huge nerd I remember reading this book called crypto back in the day it's like way off topic but um it's all about like the development of RSA um uh standards and like who did it and all these like interesting stuff but like export restrictions and they ended up like exporting all this stuff by printing out new books because that was like one way to get them get around the export restrictions at the time it's like really interesting stuff so if you're interested in that check it out I think this tiered access thing is super cool so I've worked in uh in the data related healthcare industry in the past and any regulated industry um for example in in healthcare you have HIPAA compliance only certain Healthcare professionals are allowed to see specific patient data um not only do they not they're not supposed to have access to it but this component of oidc that you mentioned you need to know who accesses something because if if somebody um inadvertently or incorrectly access the wrong information all of that needs to leave a paper trail right so um but the question is the question I have is what happens if the uh the provider servers go down in that case let's say the service won't happen yeah that's a good question obviously if the wavier loads are down you can't access data but one of the cool things about token based systems is that once you have that token um you don't really really you don't really need to access the token issue or servers all that often right so you need to issue it every so and when you want to first get the token or when you need to reissue the token because it is time limited along the time right for security but other than that and also a time when you want to pick up the public key for verifying the signatures um so other than those small Windows of time you're kind of Fairly robust to that which is which is really cool that's cool nice nice I was kind of thinking it's like because can you invalidate that token like say like hey I gave this token away before but now I don't want to accept it anymore yeah so um with auth I think there's a few different ways of doing that so a common situation is like you might issue a token you know an authorization oauth token especially to an employee and then what happens if you you know terminate employment or you know if they leave whatever right so you can either um yeah there's ways of doing it so a common ways like you get a token that expires fairly quickly like in an hour or you know whatever number of hours and then but you get a renewal key or a renewal um key so you can use that to keep getting your token and the new renewal key so again turn off the tab at the server end to say that this renewal key will no longer work because they no longer work for us so that's one way to do it um but again it also means you know you only need to access that server like once every you know frequency of every time it expires so again okay if you can achieve both things yeah cool cool nice so I I guess yeah again I think this is a pretty use uh useful feature I think one one example where we internally at semi are using it um like the tiered access uh to um uh to to deviate it's actually how we build some of our public facing demos uh so for example like everybody probably know about this Wikipedia demo uh so if you try to access that uh AP uh that date that instance a vb8 without authentication you can actually run queries but but you can't make any read or write you know commands which is really cool because on one side we we have the control of what data goes there you know like some some people put like uh maybe they'll put some bad objects or something and we can avoid that we can make sure that the demo always is in a good shape but then at the same time anyone that wants to test it out and and see like what sort of queries you can run on Wikipedia um uh it they can access it so I think that's also like one of the good approaches to do that yeah so yeah nice all right so uh conscious of time uh next uh we have uh well leaving the best for last uh so we have Zen uh Zen you like in the in the last one I released blog post you were also covering an update to the backup functionality uh in in viviate so uh what's different what's new uh because yeah this is this is one of the main Flagship updates um it was uh super awesome to learn about this and talk to all the engineers and the whole process of how the the inner guts were revamped to provide this new functionality quickly stated basically what it allows you to do is um before you could back up your data as long as it was stored on one node right if all of your objects are stored on one node that could be backed up okay um even if you had your objects or your classes multi-sharded and what that means is instead of storing one table you take call your rows of your table and now you create let's say you have a a table of four rows you can create two shards of it where now that data exists that's two tables but now both of two rows so you can multi-sharg your data and as long as you are doing that physically on one computer you could still back it up right that was 1.15 the new added functionality is that you can take these multi-shards that you can distribute them across hundreds of different computers and you can still back it up as if it all existed in one computer and that's a super cool feature because there's we can get into the many advantages of sharding if we want but one of the things that I want to show you if you could share my screen here kind of just hidden into the first demo was this idea of multi-shorting what I did in that first demo was I spun up uh two nodes and then I pushed data to those nodes right and here I didn't specify how the data was supposed to be stored whether one class was supposed to be stored only on exclusively node one and then another class was exclusively stored on the second node so this is a bit more um of the functionality of the node API feature but the data that you get back from that feature you can actually tell that the data is multi-sharded so if you look at your category class you can see that nine of the objects that I pushed are stored on node one and the other 10 uh for the yeah so if you look at the category class here or the other 10 are stored on node two so this is what it means to have multiple shards for the same class right same column category column but you have 10 rows that are stored in node two and nine rows that are stored in uh in node one and this is what a multi-shard multi-node uh cluster looks like with 1.16 you can now back this system up entirely you could just call the backup functionality on this uh on this cluster and it would be able to preserve all of your data so in in the event loss that we had where node two went down you could back it up and retrieve all the data immediately the additional the one other one last thing that I'll add is that on the user interface side nothing has changed right so you could still call the exact same uh apis to back up the data it's just that now you have the ability to backup multi-node multi-charted data nice so can I then if I have a backup created with version 115 can I restore it into 116 instance as well exactly exactly it's it's perfectly backwards compatible so that could be a cool way to migrate to a newer version of V8 yeah for sure didn't think about it before that's actually a fresh one is it correctly understanding that like you know as we have like billion scale tests that you could have this multi-node backup and then you could just restore it to instantly have like a billion scale Vector data set just like just restore it and then you're running with it yeah exactly if you have well if you have the compute and the hardware to be able to support it then you could definitely back it up right and that's the whole the scalability uh component of this thing you could have hundreds of computers where your data data is distributed across those hundreds of computers and if let's say 20 of them go down you have a backup for the entire thing and you could restore those right as long as you restore the physical Hardware then you're good to go that was going to be a good question like what happens if a few of the computers go down um like what happens with the notes that were on there yeah so the the nodes that are present will still be able to you'll still be able to back those up but until those uh so you'll have a previous backup uh that you had when the nodes were up okay so if the hardware if you restore the hardware you can you can recreate those 20 nodes but you could also actually create a backup of the 80 computers that are that are still remaining really cool I think it's just amazing like the you know like how long it would take you to say vectorize like a billion passages you've scraped from the internet now you no longer would have to wait for the import times you could just restart it and then you're running with it nice yeah I'm I'm connected yeah because like since you explained like my mind is going like all possible scenarios because Connor you mentioned the billion data scale and everything but like what if you had a setup where let's say you were perfectly fine like you got 200 million objects your environment was set up just right but then you realize that like your data is growing really fast and then suddenly like maybe you need more notes or maybe you need different servers so I guess this could be pretty cool because we could create a backup spin up more instances or more powerful instances and then kind of restore and then now you could grow from let's say 200 million to like the next level that you anticipate for right yeah exactly the the great thing about distributed um Distributing your data across multiple computers is that it's super scalable right not only are the query scalable because you now per computer you have less data you're not storing all of your data on one computer your Aquarius don't need to filter through um as many data points to before I can come up with an answer but um if tomorrow you get much more data you can always expand go from 100 computers to 200 computers and you have well literally infinite scalability right nice that's cool all right um so you showed us the demo before with like two notes uh I'm gonna be trying like 20 now let's see what happens but I promise I won't kill any of them I won't harm them on purpose yeah that's my job yeah that's your job yeah I'll call you over for that all right uh thanks and for uh for this update this is actually super exciting isn't it cool that like you talk about backups and many people would find it like uh not so exciting and boring and then Zen comes in and there's like this whole conversation coming up it's like you know then you have a special talent you make even backups sound exciting so that's pretty cool um all right uh so this is basically this concludes the part of um the waviate features and updates uh so uh like like I mentioned at the beginning of the stream uh we are already on vivid116.1 so I definitely recommend you all to upgrade to it like especially if you want to take advantage of all the cool features uh that the team here just uh described uh it's definitely worth it we are super excited really proud about it uh but if you have other ideas other suggestions on what should go into evade or if you have any feedback or if you just want to share some love you know in terms of because there's been a lot of work that's uh that went into it uh we're more than happy uh you know join us on slack or drop us a message event here uh we monitor the the messages on YouTube and we can see them as they come in so that's great and I want to uh basically finish with a corner segment where he will cover like what's new in in AI in October and and I know like Conor you read like uh so many papers every month in research for cool things that could go into alleviate uh so uh what do you have for us yeah cool well let me tell you about some of the things that I thought were called uh this month and um so First the full screen is good let's sharing it yes we can see we'll be there to Connor sure so uh so with the ref the back thing I might have been a little hand wavy with the graph neural network thing so in this slide I promise you we'll understand what a graph and all that work is uh and starting with this new paper from Amazon science recommending related products using graph neural networks and directed graphs the core thing with the directed graphs is that there's an asymmetry and recommendation you buy an iPhone you need airpods you need a phone case but usually when you buy a phone case you don't also need airpods so they have two separate kinds of relations in the graph so in wva say we have a phone case uh phone is one kind of cloth or it's all product we still have different named relations within the class so you could have you know co-purchase relationship co-viewed with cross reference relationship and we V8 and so they have this graph where you have co-viewed which are these bi-directional lines and you have co-purchase which are directional lines so the way so and really what I want to do with this is explain to the graph and all that work is so the core idea of the graph neural network is it has a message passage a message passing uh prior so uh so when you have and the core idea with this new idea from Amazon science is that you have two embeddings for each node so a has a source embedding and a Target embedding and you know sources like from Network science or you know it flows from the source a to c and 2B but a doesn't flow 2D it's a Target to D so the idea is you have two separate embeddings for each of these things so let's get the math and I promise you understand what a graph enrollment work is after this so graph neural networks similar to deep neural networks it has you know L layers so let's just 8 12 whatever model layers so you initialize it with some features for each node so usually say you have a text description of the product bang vectorize it with mini LM now you have a 384 dimensional Vector at layer 0 of the network that represents say this iPhone case so now what we're doing is we have two Edge graphs this subscript CP and subscript CV so what we do is we're going to do the message passing by averaging out the vectors that this Source node is connected to so again with this example of a is connected its source it goes to C and B so at each layer of the graph neural network we average the vector of C with the vector of B and then we multiply it by that layer's weight Matrix so you know say it's 384 the average will be 1 by 384 times 384 by whatever hidden Dimension we want to do with that layer so let's say it's 512 and then you end up with a 512 dimensional Vector you can like blow up and shrink the uh the kind of latent bottleneck that way however you want to do it so in the end you end up with you know any this these weight this is all differentiable with the weight Matrix so you learn this weight Matrix and in the end what you're doing is you're producing embeddings for for the notes and the embeddings for the nodes are how you then do recommendations so you want to recommend a target from The Source you query with the source node and you learn that node embedding through the several layers of these graph neural networks and you do that with this loss function where you know the co-purchase things you try to make these similar to you know the iPhone Source going to the iPhone case the Target and make that dissimilar from from a randomly sampled one so let's say there is also like a a set of dumbbells also as a sample Target that was also on this like Amazon product graph so then you also have you know making Source representations similar to each other in the co-view relations if you know the subscript and so that's how it works so uh quickly before moving on because I think this is the most important like technical concept does everyone feel good about what a graph neural network is are you stacking the um so you mentioned that the uh you have multiple nodes and then you're you're learning the weight are they stacked on top of each other is that how the layers work exactly so layer zero you have the initial sentence Transformer Vector for c and b and then so a will be the average of those two boom then you multiply by the way Matrix and you did that also for C with its E and F Neighbors from source and then now we're on layer one and so on so just keep doing that okay I see cool so awesome I hope you all thought that was interesting and thanks for thanks guys and uh so some other things I thought were really cool and related to rest event was uh Pinterest posted this blog about how they use that refx centroids kind of idea for their uh home feed and their recommended pins example so they start off by you know you say you have uh 80 of the time you're on Pinterest you're looking at interior kitchen designs 15 let's say birthday cards and five percent pictures of dogs previously what they had is then when they're doing the home feed they just sample 80 15 5 with the recommendations so now they've added this uh Bandit style feedback loop where what you click on so you know you say you start clicking on the dogs it'll it'll increase the sampling rate from that rather than just the static sum of actions because say you know you used to be on Pinterest and you looked at like the 2000 images of interior kitchens and then now your recommendation is so biased by your past Behavior so this feedback loop would be one way to update it in addition to this kind of interaction window idea so next I want to talk about re-ranking and I thought this paper was a super cool idea so to start off re-ranking is about we retrieve some documents and vector vector index returns us a ranked list by Vector indexes but then we'll hit it by like a pairwise classifier to get even better rankings for the results and so what the core Insight is the performance of a re-ranking pipeline is limited by the recall of the candidate pool however this is because documents that were not found by the initial ranking function have no chance of being re-ranked and I think this one so the idea is you retrieve say 100 documents re-rank and then you have the top 10 and I use the top 10 as query to get say another 10 and then blow it back up to 100. so I think this is a little counterintuitive at first you might think like okay the newest neighbors to the query aren't they the nearest neighbors to each other but they're actually not because of this High dimensional space so you know the nearest neighbors the query document one two three four five the nearest neighbors to document one might be like document seven document 13 and then documents not even in the list like 81 or you know whatever so you expand the list and then you have more candidates to re-rank and it's a really neat heuristic that improves the results on a lot of these techniques like the M25 Dr query Colbert and splade cool so the next idea is another re-ranking strategy that I thought was really interesting and different from kind of just the binary classification query document uh put it to a binary relevance label this is the idea of using language models to score the likelihood of the input question conditioned on a retrieved passage so you train your language model by concatenating your data set of document and query and you know language models just predict the Mast out token but the way that a language model predicts the mask down token is by assigning a probability to each of the next words so say the sequence we estimate log P of Q given Z sub I using a pre-trained mask it puts a 85 on language and then it has this massive distribution of probabilities on all sorts of other words so what you're doing is you're going to multiply out the probabilities of the query as you say have the document and then you go mask massive s and you're putting in the probability of the uh of the passages that you've retrieved and you can use this to re-rank the passages based on the probabilities of their likelihood coming out of the language model so I thought that was another cool idea and the show how that this improves over the contributor the DPR model compared to this idea with the re-ranking the Retriever with the language model so another kind of cool idea like this this idea of you know maybe taking the passages input and then outputting the query and inverting the process is this paper decoding a neural retrievers latent space for query suggestion we learned a query decoder that given a latent representation generates the corresponding query so you have some kind of gold paragraph like this Illinois election 2018 the general election will be held whatever so you then hit it with a sentence Transformer and now you have the vector and now you decode from the vector the query that would match with that paragraph so it's not an obvious thing that say in bm25 search you have pseudo-relevance feedback where you know how much weight you could put on the keywords to have matched the paragraph but it's not so easy to invert the space in the neural space where you have to generate it into a natural language query like this so I'm not sure uh yet what this is useful for they have ideas like you Traverse the latent space from the original query and try to have like an ensembling of nearby queries that are similar to this latent space but generally I think it could just be an idea that helps you get a sense of what's going on with your models as you upload documents and it says queries that would match with it maybe it gives you some insight into how to query it maybe maybe we could use this for uh generating queries for Jeopardy right so if you have an answer it's like hey uh find me the question that will go well with that yeah so you could have like a vector search engine Jeopardy you know like you could have few instances of widget maybe Zen can set them up on distributed nodes and then each of them can ask the right question yeah exactly we're making the language models play Jeopardy and answer what was the question rather than hey what could go wrong right okay cool so what the next topic I want to get into is an update with Gina ai's fine tuner so there's very interesting space in model training software we have like Keras tensorflow pie torch for training our models and it requires a bit of knowing how to get the data loader how to get the optimization Loop Define the model architecture code and Gina ai's fine tuner has created this way of pipelining the document array which is where you put your uh query document labeled examples particularly for multimodal image text captions and accessing a lot of these features use the train clip like uh the wiseft robustness turret there's a lot of things that are built into the fine tuner and so here's some results that they uh present in their share with their in their blog post about the updates with this Flickr AK 8000 3200 000 and bang massive improvement from the AK and retrieval so uh you know you're you have a text caption you're searching for an image and if you have some some kind of really particular data set I think this kind of domain adaptation achieved through fine tuning model training software that makes this easy I think it's incredibly exciting so and then we see more modest improvements on Flickr 30k and Ms Coco so you know this is building on the clip Baseline which is a pretty General model but I think this is super exciting for domain adaptation in general so now we have a Conor if you jump to the next one we actually have an interesting question from the Tien I it sounds like there's some plus ones also on building the idea of Jeopardy with AI based engine so hey you you maybe you spoke too soon that you didn't know how to use it we might even have just uh came up with you know what to do yeah I got something I have to do cool cool um awesome okay so uh give it a roller now so now we're kind of pivoting into more things that aren't as particular to search but in this General space of large language models so Google is back at it with another amazing language model uh they've already trained 540 billion parameter this Palm model three times the parameter count of gbt3 and now what they're doing is they're training this model with instruction fine-tune tasks and I mean you plus 9.4 on average massive multitask just unreal ability for a large language model so let's kind of start about like what is instruction so this kind of is it's like this Chain of Thought thing uh well actually let me start the story with T5 so before the T5 Transformer people would use totally different architectures for different natural language processing tasks like natural language inference good question answering text specification they would all you know have a different way of compressing it into a classification layer then T5 said hey how about we just language model this let's just as the prefix a question answering then give it the input and then mask and then the mask will be the answer or the mask would be yes or no for binary classification and so on So You unify all language tasks into language modeling and now they have all sorts of ways of of mapping tasks into the description of the task so you know obviously with gpt3 in context few shot learning you give it input output examples with some description of the task as well now they and so instruction fine tuning is kind of similar they also have that with like give the rationale before answering so not only answer it but explain yourself and then Chain of Thought fine tuning which is like this is how you would explain yourself so if it's something like you know I have 23 apples I gave you 20. you say Okay 23 minus 20. I have three stuff like this so what they did is they have this just incredible diversity of tasks that they fine tune this one model with and it's obviously a massive model so the next Super interesting thing in let in large language models is large language models can self-improve and this is the same idea as this Chain of Thought thing so again with Chain of Thought the question is Stefan goes to a room with his family they order an appetizer that costs ten dollars and four entrees that are twenty dollars each if they tip twenty percent of the total what is the total amount of money that they spend so what you do with Chain of Thought is you break up that question you say okay the appetizer costs ten dollars the entrees cost ten dollars each so four times twenty and so on so the way that language models work again and then this comes back to the the Jeopardy thing and say using this to do re-ranking is as it's doing this output it has a probability for each of these words so you know the is like say 75 appetizers like 60 of The Next Step cost is like 90 and so you can do different decoding paths through large language language models in general so say greedy to coding is you just take the maximum probability of each step you can have beam search all these kind of things for decoding pathways through the output so this idea of self-improving means at the end the model might it takes different paths to get there you see how like 90 times 1.2 compared to 90 plus 18 but in the end they have the same answer so this consistency is used to filter the output and then use this as additional training data for the language model so output 1 and output 3 are then concatenated to this question and then the language model does some additional training by language modeling that and other incredible idea for further improving the performance of these language models okay so then just another thing that I find this research in like iterative writing to be extremely interesting so I quickly want to present this idea as well where instead of again just having a language model say greedily decode a story you have this iterative plan draft rewrite and edit and I think it's really interesting how you you know they break this down into plan it generates a setting giving a premise it generates characters they have this kind of Knowledge Graph extraction for factual consistency within the story you know start writing the story and then you have the rewrite where you have this coherence and relevance ranking so this is kind of a part where this whole ranking search pipeline thing comes in to filtering the potential decodings of the language model ensuring factual consistency and overall I just think it's an incredibly interesting idea for generating long stories of language models so then let's talk about the other way of doing language modeling this is the so these these three ideas are like these you know massive language models you put like 100 billion parameters you just compress all the data into the parameters and language model compared to retrieval augmented language modeling where you retrieve you have the query uh you have the input you use that as a query to retrieve some information and then you condition your generation on that retrieved information so in the last movie error episode we talked about Facebook ai's Atlas model and particularly what they're doing is they're saying can those can those retrieval augmented language models also achieve few shot learning where you give it a few examples and it learns a task because that's one of the core cells of these large language models uh now we're exploring can they do common sense reasoning so the problem with common sense reasoning is it's a different kind of retrieval task so the question is only after learning you can gain knowledge true like these little Common Sense things and the question was really like can the retrieval generate relevant things or what the next thing is using this kind of retrieval augmented strategy for multimodal information I think this is also extremely interesting so you have questions like what shape is the pediment used by Capitol Hill in DC and so you need to kind of retrieve this image and then you look at it and you go triangular shape pediment the way they do this is they use the uh the embeddings of images and the embeddings of text they put that into the same document index and then you know fusion and decoder style retrieve and read generate answers train it with uh with like these vqa data sets okay then finally the last thing is the massive text embedding Benchmark and it's about having Universal text embeddings applicable to a wide variety of tasks we love using it for retrieval we think about this a lot you know you say fact verification you have a claim can you retrieve the evidence for this claim we can also use embeddings for say uh summarization where you have this similarity score of the embeddings between the long document and the potential summaries you could have a pair of uh of sequences that you compare the embeddings to to do some kind of classification with and all sorts of things like bitex minings they say you use embeddings for translation by you say something in English embed it in English nearest neighbor in the French index that's going to be the translation so is a collection of a ton of different tasks ton of different data sets a ton of different languages as well so really interesting way of seeing all the things we can do with embedding based models and then you know it puts a scale for comparing GTR with mpnet with our mini LM with uh all that Specter not our like we developed it at we did but this is just a common sentence Transformer lightweight use it a lot uh Specter for a lot of these things on the same scale uh so thank you so much for listening to this uh please let us know anything you thought was interesting and I hope you check out webe to learn more about the weekday Adventist search engine excellent thank you for this uh huge overview Connor uh that was really good and basically just for everyone in the audience to know uh how what how important this segment was uh to Conor he literally has a taxi uh about to arrive in half an hour so uh uh you know like he was still in this he's still in this and like yeah I can still make it on plane and fly over um to to Italy because like a bunch of us like pretty much everyone in the company most of the people in the company going to meet in Italy soon uh so yeah thanks Connor for taking the time um I I know you're going to share some of the materials as well right um oh sorry uh yes yeah uh Twitter thread that has the links to each of the papers if that's what you're looking for and yeah I think we'll continue thinking about how we want to share this if we want to write something or something but hopefully the just the links is enough now what's your Twitter handle Connor C short and 30 I'll I'll put it in the YouTube chat let's do that so yes if any of you wants to actually get the you know the list of everything that Connor covered uh yeah you should definitely follow him on Twitter and uh without a say you should follow each of us as well uh but I would definitely say like yeah follow semi Twitter handle and wavy8 as well so I think that's pretty much it from us this is all we had to cover for today uh thank you all for listening uh thank you for uh my co-host uh you all did an amazing job um any final words anyone thanks for listening everybody thank you thank you thanks a lot so let's do a collective wave waving what I'm going to do thank you bye I'll see you next time [Laughter] bye everyone ", "type": "Video", "name": "weaviate_air__episode_2", "path": "", "link": "https://www.youtube.com/watch?v=lTwB2blPwRs", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}