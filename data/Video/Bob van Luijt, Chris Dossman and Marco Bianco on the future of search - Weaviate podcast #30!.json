{"text": "Thank you so much for watching the 30th episode of the Weaviate podcast! ChatGPT has landed, leaving a massive impact on the ... \nforeign [Music] 's chat gbt is an incredible breakthrough in artificial intelligence chat gbt has inspired many people to wonder about the future of search engines the latest weba podcast features people at The Cutting Edge of large language models and search technology together today we host semi-technology CEO Bob Van light and facts co-founders Chris dossman and Marco Bianco uh so thank you so much for joining the weba podcast thanks for having us yeah thank you it's like we maybe kicked this off uh Marco and Chris could you tell us about uh what you're building sure well facts was uh born from a bad experience I had living in Southern California where me and my uh wife and two young children at the time had to evacuate because of wildfires um and when trying to figure out uh what alerts to sign up for what uh Twitter accounts to follow or Facebook pages to follow and uh it was all completely disjointed very difficult to find that information took me about two full days to feel like I really had you know coverage and understood uh what was going on and um so it was born out of need from that and realizing man if it if it took me uh if it was this difficult for me most people are getting best incomplete information and it works bad or no information so originally our goal was to just crowdsource validate uh these essential facts uh links phone numbers uh things that people need in day-to-day life uh as and for you know emergency situations like this uh that then uh expanded using uh AI we wanted to take these and and uh output them in different formats so we could deliver these to people where they are in different platforms different uh types of output and we built a system that is able to use Vector search and large language models to take these crowdsourced validated facts and uh and not hallucinate and then use them to Output in in real answers uh from there it became even even more powerful than that and I'll let Chris speak to to Marianne and some of the the exciting search capabilities we've built with it yeah so I guess we started by um really figuring out a way to add these verified facts uh and have them show up in the output instead of having uh hallucinated facts like Marco was saying uh and then we're we went one step further and we're like okay well if we if we add this these facts and we don't have the context needed to correctly answer the information then why don't we just go out and find that context on the internet um and so that's you know when Marianne was really born it was a a large language model connected to the internet uh that that understood when it didn't have enough information to correctly answer uh the question um and it just it it just keeps on snowballing from from there so now oh now we can do now we can answer not only local essential information but information about all sorts of uh items and not only can we answer questions but we can actually write content um with all of these verified info facts uh in it so it's been really exciting a couple of well like this point six months and it's imagine it's going to get even more exciting as we continue down this path there's definitely a need for it I mean Marco talked about his uh Wildlife story and just a story on my end my wife's Chinese we're trying to go through the process of getting her to get the green card in America and it's just it's so obtuse um so disjointed all the information what you need what documents who you got to send it to when the timeline we were forced to hire a lawyer and it's it's just it seems insane because it really should just be like a sort of checklist uh kind of process um but we ended up needing help because it's so complex and so hard to deal with imagine Mary Marianne next uh next release Marianne might be able to help with that yeah yeah super cool I think the the topic of solving hallucination language models with Vector databases is such an exciting direction for weviate and combining with gbt advances um so can we kind of describe like how particularly are we thinking about integrating the vector search in the language model is it this kind of like self-ass Chain of Thought prompting where the language model is kind of probed to say our follow-up questions needed yes and then it will search the database or is it just kind of the idea of you take the query or previous generations and use that to search and then just kind of append it or general thoughts around how do you make the language model attend to the facts and not just ignore it and generate something regardless of the facts in the input is this maybe with prompting does this require additional training uh so kind of the thoughts on how exactly yeah I'm gonna say all of the above and you know in no particular order just sort of start start working towards adapting your your system to include all of these different uh items and it just they all add the combinatorial makes the output better uh yeah multi-shot prompting you know having examples uh within the prompt space itself was I think our first like iteration uh and then going from um multi-shot prompting to Dynamic prompting where we're we're not it's just not static examples they're actually examples that fit that particular task best uh and that's again that's being pulled from uh the vector database uh of like known good examples and we keep on adding to those over time so the capabilities improve and that's just special prompting now of course you you were saying about chain of uh prompt chaining and recursive prompting and you start to to get systems that are strange uh in how they you know they act very human-like you give a hard question on on Marianne and it might take 28 seconds to find the answer why is that well it's because it figured that it didn't quite have enough information needed to go back and search some more um so it's it's a obviously we don't want to we don't want to like tell you exactly how we make the sausage and the seasonings that go into it but uh it is a it is a hodgepodge of many different uh things coming together um fine-tuning is is funnily enough one of the last things I think we're we're we're focusing on right now um because we find the the output from the prompting is so good that we'll be able to bootstrap uh enough uh examples good good examples in order to fine tune later on uh so maybe maybe a later step well I mean even the context the con yeah the context retrieval model we've been fine-tuning to to match questions and passages from text much much more effectively than um what you can do when you don't fine tune so that's I guess that's one one area we've really pushed uh on that uh method but there's always more coming out right and I think that might be where a lot of the um improvements are coming from for chat GPT GPT uh like I'm not sure if it's just the model the that was innovated on I think they also started to uh include some of these Advanced prompting techniques uh recursive chain of prompt Chain of Thought prompting and I'm sure um a persistent knowledge base uh that because you it does respond to and maybe I'm going a little bit off topic but it does it does seem to respond to previous conversation that you had so there's definitely a potentially like a look up uh vector-based lookup for for previous context uh when it's it's generating the new answer from it I like I like how the model is very very Dutch so I asked it something and then I asked like the same question in a different way and responded like as I told you before and then it just said no but but just just to quickly build on top of what you're saying so what I what I find very interesting also from from from our perspective because for this of course was very interesting right is that the the collaboration basically that we have is that um you know companies and people like yourself Building Products on top of something like leviate right so whether it's part of the the stack of the uh of the um of the uh the the the secret Souls I I guess right the um the um what I find interesting is the difference in the model between um language understanding and having information or producing information and knowledge and what I mean with that is the following it's like you have like these these statistics right where it says like that like I don't know like 98 or something of data is you know is behind closed doors and the rest is is out in the public so you could look at these models that are being trained aside from the perspective like are they able to parse the question the the natural language question and if we can get them good enough to know where they need to find the information in this case from the factor database then I think that's more powerful than adding the knowledge itself to the model because the problem is that if you keep adding the knowledge to the model then you need to keep fine-tuning them all keep updating it but let's say that um let's say that the model does not know just for the sake of argument what what deviate is right um or no actually an even better example is something where time plays a role so um well I saw here in the back I have like I've hit the Angelo record right so let's say that tomorrow all of a sudden he would release a new record and I would ask the model what's the latest the Angelo record right then it would give me the wrong answer because the training data of course you know had like that latest that latest record I think what's very interesting is that and that's also what we now see with a gbt chat or chat gbt I always forget what way around it is but the thank you is that the um is that sometimes it also responds like I have no connection to the internet and that is something that I find super interesting because what you then can do is that if you can ask a question like okay what's in this very specific example was the Angelus latest record and it can parse that query and then basically ask the vector database like hey wait a second tell me something about you know the representations for like the Angelo records and those kind of things and it gets back a top 10 result and then it parses the results and Returns the answer then that means you can keep updating the database and getting these ends back and what I find very interesting for for companies like you like yourself is like going back to that number uh a a a a 98 of of data is is um you know behind closed doors so in the example that you gave about the green card maybe that's a beautiful business for you know for you to sell to law firms where you can say hey if you have specific data internally that could answer these kind of questions automatically then you're you're cutting out the middleman to answer these kind of questions incentive structure yeah exactly um we even hope to do that with uh with government agencies you helped offload um a lot of the work from County clerks for example hundreds of emails and phone calls for even the smallest of counties uh that could be answered using this and also help expose data exactly the 98 behind closed doors is a good is a good topic because there is especially with essential local information in government and municipalities there is so much behind closed doors uh we hope to to point this at those data sources and really expose it but it is interesting I mean it is such a limitation of models that the Corpus you know chat GPT I believe is up to 2021 July 2021 so anything temporal that happened since then uh just uh doesn't exist um it's an opportunity for us yeah they for some reason they won't connect it to the internet but we're happy to options right so you have like you have like connecting to the internet but you also have the opportunity to uh enrich it with very specific yeah Bill and knowledge base and and what is what is super exciting and we see that in action also because of the things that for example what you guys are building is the that that we're that we're starting to move towards this uh um this this natural language interaction with these databases or these these data and the reason I find it so interesting was that one of the early ideas or like the things that sparked also the idea for for um uh for for viviate was that the um I was very into this into the semantic web right and the problem was that we needed humans to agree on you know nouns and those kind of words you know in advance to describe things and that simply didn't work right so you get like these noun lists and these keyword lists and those kind of things and then these um being able to having a uh um a conversation like we're having now in a certain context that I think these these these Vector searchings were like a well actually the models first of course and then out of that game um the the idea to store the information but that you could actually start to interact with these systems and then now what you're describing is like a a third step so but if you can really interpret what somebody is asking or even keep context and what people are asking and then send it back to the database so the option it just keeps keeps it just keeps growing yeah just to build off a little bit what you're saying Bob um there is definitely a capability overhang when it comes to large language models what we currently have is way more capable than what we are able to to tease out of it now but and I think that's because like you said we keep on falling back to what's worked in the past which is more data during training and maybe that's not it maybe actually these large language models are capable enough that if we put them into designed systems we can get them to do things that they would never be able to do otherwise like when it comes to Marianne being able to answer the give you the right answer faster uh right or or you know when we think about helping County offices deal with all this uh all these questions pointing them in the right direction well none of that's using fancy you know state-of-the-art large it's not using uh 500 billion uh parameter models it's it's DaVinci 2 but used in uh in in maybe a correct way right it often reminds me of the introduction of electricity uh in London uh for the factories it actually took 10 years before uh efficiency numbers profitability went up because when people first started using electricity they were just using it in the way that they used to use Steam and actually all of the benefit comes from now you can reposition the Machinery because you don't have to deal with steam pipes uh delivering power you just have these these cables so uh we're in a similar situation I think with large language models and it's part of the reason why I think it's coming way faster than we can imagine because really what's holding us back is just the eyes the spark the spark of imagination to to put algorithm down that's uh able to handle situations as they come and then when it maybe understands what it it knows what it doesn't know and then search for that uh to try to fill in the gaps yeah I know I like I like this very much and I I think so um I think a lot of what a lot of people liked about the model was like the answers that it was producing sometimes like funny or sometimes it was like uh you know the correct answer sometimes wrong answers but um what actually was exciting to me when I saw it was that it was parsing the question so it was like and and the moment I saw this parsing my question I didn't care anymore this would give me the right answer or not because then because I was thinking I was thinking about that 98 right so I started thinking like if it can parse that question than with um on the infrastructure level the um the the database but like on a on an application Level which you guys are building is like there's so much opportunity now in in literally every every industry so it's funny it's sometimes when I talk to people and then sometimes when I'm like at a party or something right so people um who might not necessarily listen to effective search related podcasts so so and they think so what do you do and then explain what they do it's like I'm in Search and sometimes people go like we need search and you're like what do you mean we need search everybody and I am more and more starting to understand like people are people are unaware that if they for example type something in in um in such a chat window there is a search happening in that knowledge base it's everything a search so if you really can take that next step in in [Music] um storing the information in a way that it can be processed but also parsing the information to the models that's super powerful super powerful yeah and then that's where you know Vector search is is so great to understand the meaning of that search and match that with the text that we're pulling from various places and just joining joining those meetings I mean it would not be possible without Vector search yeah no I I agree and I it's the it's the um that's sometimes when I when I talk to people is that I say like so one upside that we have with uh with machine learning is that in these kind of situations I always like to call that the uh um uh um a little bit tongue-in-cheek I like to call like the magic of machine learning because when people see they're like oh that's amazing it's like you know that you do like a card trick so it's like it's like it's it's you know in the in the you know in under the hood it's just software doing stuff but just when people see it and observe it it's like engage that it gives this part to it it feels like magic yeah exactly and exactly and I think that is what gets also so so many people excited so that they're like hey but now you know if I can really start to interact with the systems and when I say interact I don't even mean uh uh chat based interact but natural language a language based form of interacting I think that is so because we we keep on because it's the status quo right but we keep underestimating how incredibly difficult it is to turn a search like a question that an end user has into a query if we don't exactly know what they're looking for that is that is extremely hard so these models helping um uh um in in in translating the the the natural language questions uh to structured questions that we can you know query databases and get these results back yeah that's super powerful super powerful giving a semantic understanding of those questions of of that question regardless of how the user has maybe typed it or uh being able to ask follow-up questions when when it's unclear about the and and that's surprisingly not that difficult to do with these uh current systems as long as you're you're halfway decent at prompting uh you can build these follow-up systems and train them over the course of a couple thousand examples to perform really really well at least to cover 90 uh 95 of uh questions that you might get um exactly and I find it very interesting because nowadays you sometimes see these um uh these interviews on like these YouTube channels like with like language philosophers and those kind of things and there's also kind of like often you know interest of mine and um and then these these these uh philosophers always you know they make sure that everybody understand that the machine does not have semantic understanding of what something means but from my perspective I look at this very different because I understand I I get you know where they're coming from but the point is just being able to parse the question right and and put that into context and then know from what you know where in this case in Vector space where the context is stored as you can retrieve that information what we you know in the industry I guess call semantic search that is what makes it so exciting I I really think that even even developers right so even developers might sometimes not be aware how extremely hard it is to parse a question and to know where to find the answer even if you have the answer so it's a very human thing right like that matching a question to information or at least where to even look for that information it's very human it's very very difficult and uh without Vector search we're what back to keyword based searching and that just doesn't it just doesn't work it's just not nearly as capable I wanted to have been quickly on this idea of this conversation around not understanding meaning and there's this great paper that went out it was called climbing towards nlu on meaning and understanding and language models and the the picture is painted like this there's two people stranded on desert islands and they communicate with an underwater cord and an octopus is intercepting the chord and it learns how to mimic the language such that it could cut it and then talk to the other person you know and you don't know it's octopus of the person and so that's kind of been like the example of the same the language models are just mimicking the text they don't act in it but I think now what we're seeing with chat gbt in building on instruct gbt and reinforcing learning from Human feedback is that it is embodiment because the language model is being given some kind of instruction like uh write this in Shakespearean Style and then it's predicting the tokens but then it gets that kind of feedback signal so I think I think it is now embodied and I think that kind of idea that it doesn't have meaning or understanding I think that we're actually moving past that and I think this reinforcing learning from Human feedback idea can like it I think is being underappreciated like you still see people reacting to chat gbt like it's just predicting the next token well it's not it's also you know has humans labeling how well it's following the instructions and I think that's just a significant difference you know I I I I just to add a little bit I I maybe I don't see it as a difference at all actually then maybe that is just intelligence it's it's picking the next right word right how how much of really great podcasting is just knowing what to say when right predicting the most effective like maybe we we have that ability internally as humans but we're just now getting to the point where we we figure out how to do it with computers uh and I'd like to think that there is a the same type of intelligence that we have for natural language processing they are gaining like at least uh the ability um and you know it's it's truly I think intelligent what's missing is the persistence aspect of it like the problem is none of these systems persistently exist over days weeks months years and so have no ability to to uh form like long-term memories and and I think that's when we would start to be wonder whether or not they truly are intelligent when they have that persistence so they're sort of like at call right now and only exist for a short time before they're you know scrubbed and then like refresh somewhere else again I think that goes back to the databases website would come in uh because the vector databases is that persistent yeah Vector search is that persistence and what is intelligence but being able to do the next right thing based on your associations that you've learned yeah uh and what is you know the association it enables those associations it really is powering those intelligent systems yeah and I I quickly I I quickly want to go um uh back to what Connor said because what I find what I what I find interesting is like I strongly believe that we make these systems for humans right so we make it for each other to help each other right that is that is that is what that's why we build these systems so if somebody says well you know the thing is just doing is predicting you know the right token or if somebody says oh you know in effective database you're just doing like a distance calculation from one to another sure but that's now I mean we now have like the uh the the the the the the soccer championship happening right so it's actually that's the same thing that if somebody scores a beautiful goal that you say oh there was just a signal sent from the brain you know to his feet and you know they had to kick the ball yeah that's true but that's I kind of uh that defeats the point of for what it's doing right it's creating and sending value in the case of soccer I guess like entertainment value and and in the um in in in the in the case of vector database it's like it's a information retrieval value right so the two use cases for example that you guys mentioned in the beginning so for me those kind of arguments like oh yeah it's just you know predicting the next token I'd app that I just I it goes in here and goes out there because I was like you know who cares it's starting to add value to uh to people's lives and we just know that it's gone it's a matter of time before people we will hear the stories that people say like oh thanks to these systems I could you know I was able to do X thanks to these systems I was able to do why that is it's already happening but that's just gonna be more exactly it's already happening yeah I think it's um and again what chat GPT I think has done is brought it to people's attention more quickly I think what we've you know people in the industry have maybe seen this coming uh for several months and experience but now it's bringing it to the masses and people are just realizing and I think quickly or going or already using it to help them in in day-to-day tasks and it is adding value from the the programmer to the uh the student um it has so but really excited to see now with more companies doing what we're doing is integrating it as part of a bigger system yeah and what I find interesting and that is just a uh um and I saw somebody tweeted this but I I forgot who I I forgot who sent out this tweet but the thing is like we're spending so much time right so we're making these bought gas to talk about it we have or we have the academic research we have the blogs we have like and everybody's doing that stuff throwing it into the outside world and then it just takes an input uh uh you know an input box on a website where people can just type it in and I found that fascinating goes for for you guys as well I remember that you had the first tweet uh I think there was also tweeters like you know people cannot try it out and yet like the the link and you can could ask a few questions and I was like super exciting to see and people were actually trying it out and and and and testing it so I was like oh this is It's just sometimes it's so interesting so sometimes something is like in the air and people go like you know we're going to get it but nah not completely and then it's just an input box and it doesn't matter if it's you guys doing it or or opening eye doing it just the people you can type something in and that they just get a response back and I was and I thought I was like I had to laugh about it because we're spending so much time making content and explaining to people this is what's happening on the hoot and those kind of things and then it just took an input box for people to fill something like oh now I get it [Laughter] yes yes yes yeah yeah that's actually I like that so it's like it's it would be the same as like um like if you see like you know an a magician who would start off by you know telling how uh how he or she's gonna make an elephant disappear right you just you don't care you just want to see in Heavenly basically yeah interesting so so I'm curious I'm curious to hear what what kind of what you guys think that you might see happening because what's very interesting for for somebody like like myself right it's like the um in our case we're like an infrastructure database provider that helps you know in this stack um and and these types of applications that your building is like amazing because that brings it really into the hands of of of um you know like literally everybody right so just to the the the non-so fair folks if you will and I'm just I'm just curious where you think so if you just dream a little bit about like what you think that will be happening in the in the near future what if you have to guess what what do you think that they will see in in the coming year I mean if you want to go first sure right we've we've pondered this a lot um and it's things are moving so quickly uh much faster than I think anyone even expected and it's only going to continue to uh grow more exponentially um I don't I don't think people are used to natural language uh questions asking and getting natural language answers yet uh because it just that's not how people necessarily necessarily search on Google and to be honest Alexa in Siri which are people's uh you know General interaction with that is not very good uh at those answers uh you know they're kind of glorified clock timers and and weather uh and they can tell you the weather but as far as you know actually answering like we're seeing Marianne or Chet GPT they're not there so I don't think people have gotten used to this format yet uh and once they realize that they they can um this is how we normally talk this is how we normally ask things so I think we'll go back to to speaking like this where I think eventually it will go uh possibly an always-on type of digital assistant uh that's listening to your conversation uh and inserting itself an adding value where when it thinks you might need to know something when you might have a question uh somewhat like the old Sci-Fi movies where you wake up and you're speaking to the room because I don't think the input box is going to be is the most efficient interface anymore and I think the capabilities of this and are just so great that now we're now we can go there now we can enable systems like this eventually you know from my end I I have thought a lot about this and I think uh chat GPT um was really a watershed moment like I keep on thinking back to the movie Interstellar when they are on the plan the water planet uh and then they see uh what looks like mountains in the background and like oh mountains that's so crazy and then they look behind themselves and they just see like a towering wave coming for them I very much feel like we're at that point um and the easiest way for me to try to conceptualize it is I I agree with Marco there's persistence in these agents um that are going to be a thing uh and so what does the world look like when there's a trillion people in it and 99 of them are Flesh and Bones and the rest of them are like digital intelligent agents going around what's that world look like I have no idea you know it's just it's it's it's it's it's I think it's coming very very shortly like in the next two to four to five years we're gonna have agents that are persistent uh that can travel and decide what to work on and do and I just I don't I I guess I should get used to saying please and thank you to to my digital assistants because they might I don't want to piss them off when they become sentient yeah no but that that's that's super that's super interesting and I I think so of course um what we sometimes keep forgetting is that language is just that's just a form right so we can we you can tokenize like kinda everything right so think about like games or um uh or or like I don't know lab Assistance or something right where you can choose also um uh store or predict you know certain types of behaviors and those kind of things so I think that's that's gonna be that that's gonna be coming as well and which is not per se driven through um uh true language so I find that just it's just you know or degenerative for those kind of things so I find that that is very exciting as well it's uh um I'm also what I also find interesting because I what I really like you guys took like like also a little bit like the Long View although that in in in our world of course the Longview is like soon but I think also if you look at like tomorrow for example just to be pregnant is it um I'm also very curious to see how um how one people will integrate this into existing businesses so I'm thinking for example about like um ticket systems or those kind of things so when I have like the airline I want to ask a question like why where's my luggage you know those kind of things that they that you can figure it out in in an NLP fashion but even what I'm more interested in is like new businesses that we will see so people can build new things on these systems like like completely new products new services um uh on top of thesis and I'm looking very much forward to um uh uh to to see what's happening there right so I saw for example um uh recently I saw there was a there wasn't based on the generative model where you had certain voices of uh famous actors and there's like a startup and that they say well rather than actually hiring the actor all right she just give us the text and when we have the the actor you know um uh um you know say the lines but the cool thing is that that's a new business opportunity also for these creatives like these actors right because yes they now don't have to do like the like the one recording but they can do like hundreds or thousands recordings simultaneously why while you know they can see they can skill that so I also think so for example I think also for the creative industry so this is going to be great because of course you know some people are a little bit scared Etc but that's fine but I actually think it's going to help people in um being more creative and make more um uh do it faster so that you can just have a higher output of quality so all these kind of businesses from from from a generative like like like language integrating it with the database you get the right information out but also for basically any creative process that we're doing as humans and I regardless if you're creative as like as like a doctor or like a visual artist I I think we're going to see a lot of new businesses pop up based on these kind of models we're kind of that chain of like the understanding of what somebody means plus the information retrieval plus the information storage it's kind of it what I like was like also the analogy of the wave right because all of a sudden the puzzle seems to be completed from the beginning to the end right and then all of a sudden all those ideas start streaming and people start to build new things and that's something they're super excited about just you know it you you talked about creativity uh and I actually work with another company that is using this to turn natural language questions about data into data visualizations and python code that collects the data from your specific uh data Escape so it's it it it's coming and it's it's so it's so fast uh to build too if you know if you have the experience with these large language models you can spin something up pretty quick that covers 80 it's only a perfect MVP tool yeah it just launched these things but I I also agree I think it's going to affect every business in every industry I think uh it's not just so many new businesses that will be coming so many new businesses that or current businesses that are almost obsolete as well and new businesses to replace them uh if they don't adapt and start uh utilizing some of these tools but uh I think you're right Bob the the puzzle Has Come Together between Vector search these foundational models uh really the the elements are there to build these systems and it's a very exciting time to be a part of it that feels really transformational yeah yeah I I agree I agree and that is that's great and I think one thing to build on top of also something that Connor said about that research there's there's this other research paper I need to I need to look it up because it's like I I don't know about heart but it's it's actually a pretty old paper where they where they make an argument um so they have like this this thought experiment where they're saying okay you have two people right one person is just um you know completely healthy but somebody else is like you know it's maybe like starting to forget certain things right and you both test them with walking from the same you know point to um in a city to for example Museum the first person just you tell them okay Straight Ahead left left right Etc and then you're at the Museum but the other person who keeps forgetting you give them a um a note and the note just says okay you're on your way to the museum go you know left left right left right then you're at the Museum and what the what the um that paper is arguing so the question that's being asked in the paper is like would it be fair to say that this note or this notebook is an extension of the brain because the um can we can we can we make that claim and then the paper argues yes you can make that claim so for example if you want to remember somebody's phone number back in the day right you wrote it down there's kind of an extension of your brain outside and you just you know you read it and then you have that information and then that experiment or sorry that that thought experiment is redone based on search online so can we make the argument that search online uh extends the extents of the brain and then they come to the same conclusion we're saying yes we think that you can make that argument because if you just you know don't know in what year the Eiffel Tower is built you know you just in today you you Google it or nowadays I guess you would ask exactly and um and and get the um and get the answer and I think so what we're doing is like we're we're creating these systems to extend like this Collective brain not only with public information but also information that you know that might be behind closed or just imagine that you have such an integration with your with your bank right so you might ask a question about like you know where about certain you know clothes or something that you like and then it interacts it automatically interface with your bank and it's just like okay you know you could go to the store but bear in mind you know you don't you don't you don't have enough money in your bank account those kind of things that it intelligently starts to make those connections that is what it's enabling and I and and that goes back to what I said earlier about the semantic web that it I think it was generally speaking underestimated in the industry how big of a problem it was that we as humans needed to make these connections inside the databases and that we now not have to do that anymore creates this whole stream all the way to the previous argument that was my story that was 10 like okay so now we can start to extend that Collective brain because it starts to make those connections automatically and I strongly believe that so it's like a uh um and and yes a factor search plays a role in that the models play a role in that but also what you're building with Marianne Ryan so that you say okay so this is an example of such an application that people can use on a day-to-day basis so it's just the the explosion of creativity coming out of this is super exciting to me yeah I think I think we don't even realize how smart we can be also and kind of on this user interface is one thing I kind of want to bring up this multimodal idea and I saw this one demo from anthropic or Adept I always mix up the companies and I'm sorry fans but what it is is it's like recording your screen so you say to gbt like I'm trying to import one million data objects to weviate and then it'll watch my screen it'll watch me like get going my terminal download the docker composer to watch me interacting with the web and then it would like suggest things on the side so it's it's kind of like a different interface compared to where you talk about the data visualization and you imagine like okay I got this matplotlib error so now I need to copy and paste everything give it to the chat window compared to something that's like always watching you doing your task exactly I think that always on type proactive assistant uh to maybe deliver the results versus waiting for you to ask for it yeah you've got to think from uh computational uh efficient energy energy efficient standpoint what what is better the specific tool that runs on very very low cost hardware and software versus uh an adapt like tool that you know you have to push 1080p video to a system embed it what's going to win out in that situation well I think the for people who can afford it uh the always-on everything assistant is going to be the thing to do but you might need the best hardware on the planet to run it right you might need to have the knowledge and capabilities of launching a server with a couple gpus in order to get it going and at that point maybe maybe it does make more sense to go to that specialized tool that just turns my my Pro I understand I need a data science thing I'll go to the data science tool and then uh work with that in order to reduce the cost I mean it's it's going to be a very interesting landscape of I don't think I think the the I think the obvious or the first thing to think about is like there's going to be like one winner take all but I think because of the the hardware constraints on on these systems there's gonna be plenty of room for the more specialized low-cost Tool uh in in that new landscape so don't know and we were just talking about this yesterday about what's going to win is like does facts have a chance you know kids are going to survive when you know GTP 4 and chat GTP 4 come out I think probably at least for the the next five years yeah for sure uh there's gonna be that uh especially if we partner with like organizations that are going to exist despite the introduction of AI uh like governments or Community local communities like integrating directly with them and helping them like transition and and start using these tools in a way helpful for them yep and solves their their everyday problems um not everyone's a coder right so no no exactly but I think so they're like I if I may I would like to unpack two things about what you're saying because that something that I find very interesting is the um so so two things so the first thing is like the um so so my my work is right so I'm like in in in software business right that that's what I do and that's that's how I make for since forever a living and the um and and I'm always very interested in these um these laws right that start to appear like hey you have like uh you know conways all those kind of things so they're they're things we're learning about what software is doing and and one of these these laws is that um and it does not per se from digital business but it's like it's something we especially see in digital business is like that um uh the solution that that brings the the less the the least amount of friction is something that people um are willing to to use and and even if so if they get enough value from it they're fine you know to just you know um look away with certain you know situations like for example with like now with with all the the chat applications or these always on situations where you might like you know maybe um uh um you know I don't know whether the information is going where that information is being stored but it gives me so much value that I'm willing that I'm willing to do that I think a um not not to divert Too Much from the from the from the subject matter but just to make my point is the I always found it very interesting with like everything that's happening also like in cryptocurrency right so because that's also that's like outside of my realm of expertise but it happens also in business and what I find fascinating that the claim was like okay you're gonna have a private key but these things are hard to use so now you get like digital Banks right that store that information and I think the same thing is like with um what you guys are building with Marianne or if that's like um the these these screen capturing tools Etc that so much value is being created for people the people like I want this right I need this in my life because it's helping me so that is the first thing right so that I think that we now we we're past that point where so much value is being created that people like okay give it to me right I want this I want to I want to be able to use this because the ux is just great and the second thing that I find uh very interesting is that I think like these winner take all uh uh businesses that just that just not a lot of them right so and especially also in your domain and what you're doing what you just said right so because yes so we now keep referencing for example the models that openai has but let's not forget a lot of these similar open source models that are being produced right we should not forget that so if you're like a government agency and that for for a good reason it's like we would love to have such a service but you know unfortunately we you know we can't use a third-party service or something like that then there are like solutions for that as well so it's like a there's and and it's fine because you know there's so much value being created by so many people for so many people that I think uh uh that we will not see um uh last companies I think we should we will see more let me see look at so I recently saw a list of companies that just now have generative Services right so that you said okay write me a LinkedIn post for um you know something I want to sell and uh and I was just surprised about the amount of companies that not our only found it to solve this but they're actually also finding niches and being profitable and successful in these niches it's just we're just scratching the surface I really believe that yeah I agree I think the niche focusing on the niches is uh there's so much detail in minutia in when you get into any industry uh there's always going to be opportunity to really better solve that specific problem um and now and people have the tools to do so now yeah yeah you know it makes you think also maybe maybe actually that that winner take all business is just the the one that can turn a natural language prompt into like pointing to the right Niche service that can best solve that that specific prompt um I mean it's very interesting just I want to touch base a little bit what you said earlier because I think it resonates with what we've experienced is that we've started with GTP and da Vinci uh and the new instruct uh GTP but then what we find is uh actually we once we get enough uh usage on our product then we have all the data we need to train our own open source fine tune our own open source models and just hop off of uh the GPT uh ecosystem at least until the next best thing comes along and we we figure out how to do that really well and rebuild our examples and then fine-tune our our own system so it's you know there is definitely ways for people to to grow and get value from using a third party like uh cohere or open and I want to give some some love to the other people the other companies in the room as well uh can't wait till adapt uh Adept releases uh if anyone here is uh working on adapt uh please hit us up and let us get some access to the API we'd love to to um use it to help make people's lives easier uh in terms of actually doing the actions like hey can you apply for a green card for me and my wife all right depth to take it away and that's what's coming next uh is actually you know now we're helping people find the right answer faster yeah um next up we will also be using we V8 to help suggest services and programs and resources that might apply to people as we understand more about that person one of the big problems um in this country and I'm sure everywhere is under utilization of these programs and services people might qualify for certain things or might uh there's one of the things I discovered uh building this business so far is how much free tutoring there is for children all across country in real time we can go online and find free tutors to help you with Calculus right now someone's sitting there open and willing um and so you know I had no idea and uh that's just a basic example but you know helping people with heating bills helping people qualify for free Broadband uh so suggesting those programs and then next up is helping people actually complete those actions uh take advantage of them uh which is I I like the example that buyer interests use when we got a demo abbreviate and he was like I'm hungry and then we were able to serve food banks in the local area and that's what we want to get to we want to be like hey bring us your needs your problems that you're having and we'll help you get connected to not what the Nationwide that but the your local essential uh ecosystem what exists where you are at because that's the probably the best place for you to get the help that you need uh get the support um and that's what we're really trying to build you know I think you said it earlier it started with the wildfire and like getting the most useful and local information but I mean there's just so much that people don't realize that's out there in terms of resources and things you could accomplish and the the the issues that people just don't know what they don't know and the problem is creation yeah curation there's so much out there it's hard to find what you're looking for it's a needle in a haystack sometime and that again yeah who who knows the very specific local name of the program that's going to help you you just have a problem you've got to describe that problem and get you know hopefully get surface the right uh information or program for your for your specific problem that situation yeah and that's very interesting and I now when you're when you're giving these examples I'm also thinking like these um we're now very much talking about like how we use these models at query time because all these examples you give like they're like at query time do something um uh what I think is is going to be very interesting to see if these models can help in structuring the information when we when we create the information right so that could be and I'm I'm now just from the top of my head right so an idea might be like if you store information about um well the the examples food banks on a website that the model says well if you structure like this it's easier to process or it's easier to get access to so they were not only solving the problem unlike in on a query on query perspective but also on and from from an input perspective right or maybe even then it can even help with generating that kind of uh pure kind of content I think we're already using it yeah you're speaking to the choir yeah we're we're we're already using it we're using AI to help us one of the problems again is there's so much information out there there's so many links and phone numbers which is right which is correct which is relevant which is which is essential uh so we have in part of our pipeline we're uh We've trained a model to help us determine if something is essential or not so it's already helping us uh you know filter down and uh structure the data better on that that's that's a little bit farther away from the query side but even even go farther away uh we take the these verified facts and we produce content with them we produce local news summaries we produce uh facts you know question answer pairs that are in human language and they're easy to search using your current channels like Google uh We've even talked about starting to publish these things on Twitter accounts like a local a local essential new uh news information you can follow and and find all of these interesting if we surface all sorts of stuff I mean anything you can think of there's usually someone in your community that's helping that's that's there to that's their job that's that's what they do and they help and they it's just so hard to find uh so we have been doing it we just published another 40 000 facts uh on on facts yesterday and we'll be there's no reason why we couldn't do that uh you know a hundred thousand times every every week for the next next couple weeks it's just that powerful and I have a question so I so now this is very intriguing right so in in the beginning of this conversation you talked about like the the the the the secret Souls right so so um so if is there something in the souls that you can just share with us where you go like well if we look at the code base oh there's this there's one thing this one one ingredient in the whole sauce like without giving the sauce how you mix but like this one ingredient in there we go like we're so proud of that we're so proud of that wow I think there's a is there one I mean you can you can speak to that I think what I'm proud of is the the human verification aspect and the fact that we've gotten you know at this point over 12 000 people contributing to uh to sourcing and validating uh these facts so really the the human I don't want to forget about humans in this process too because AI is better with humans uh humans plus AI makes it makes all the output better uh and that really is that that virtuous Loop right that that flywheel um but as far as our secret you know aside from the I think so I think that's that's a big part of uh our product and then that's a that's a really interesting question I like I think we need more prompt space for sure I need more prompt space I need uh way more prompt space because more con I was finally it's interesting and then just the side part here but I find that words in prompt space almost act like pointers so if you use more words in the Target area that you're trying to answer for you get better results don't quite understand what the dynamic or like what might be causing that with the dynamic how to explain it or even if there's a word to describe that phenomena but I think it's important like more prompt space more examples more context uh exactly isn't the word context it's called yeah it's it's context you're absolutely right it is context the more context I can fit within that prompt the better the answer is oh is going to be always more examples of like good quality exactly you know that that really is I think where I could get where personally with the current uh algorithm how it's set up get the most bang for my buck but I do see um like algorithmic Innovation being super important like I can't we quite quite like it's hard to get the model to to understand what it doesn't understand like if we could if if I could get that the system to display that quality I think we would be at a point where I could just let it run consistently and see see what happens like I there's just a lot to do I I really these intelligent it's we have a new paradigm it's not a Von Neumann machine it's something else they uh and we don't know how we don't quite know what how to put these things together in order to build like the CPU of the large language model error you know like but I think it's there I think it's there for the picking like it hasn't really been discovered Deep Mind for all it's amazingness hasn't hasn't quite cracked that code yet but you just said something that really triggered me it's like I was like that's like because we were just talking about like you know all these business ideas then that then startup ideas ever come from this I just the the word that just popped into my mind when you were describing everything about context was like fingerprinting so let's say that you just let's say that you have like um the the the always on system right so that keeps giving context to the model of like who I am can be in natural language can be in how I my screen recording and I say okay now we have like a fingerprint of you know who Bob is so now I might go to uh um to use Marianne in my government situation I can't give it access to public web but I don't mind feeling it my fingerprint so that it's like boom it has my contacts like oh okay oh so this is this guy right so and it knows what you need yes it's almost there's there's like an embedding exchange like if it was easier for everyone to to share the user embeddings generated in that specific context or give access to that uh context for the user to then bring to other services probably something that probably a really really interesting business right there or just imagine that you that you subscribe to like to Netflix right and then rather than say like what movies do you like say okay just upload your you know your embeddings fingerprint yeah you're embedding yeah at my Google search history yeah done now I understand that's what I like yeah what I find interesting about the about the about the embeddings is that it's it's so um if if I go into a bar and have a conversation with somebody I've never seen right then you have a conversation and a little bit of context is going back and forth to figure out like okay is do I have a connection with this person right is it interesting to have a conversation about you know whatever um I don't have to show this person my Google search history for this person to go like oh this is an interesting person to talk to like oh no I'm not gonna just approach this person you know um so and that is I think what these what these these these fingerprints could do is the um uh is that you basically can say okay wait a second uh it's a way without like giving all that information about myself right just more like I have a a representation of me basically in in in Vector space if you will yeah yeah I mean it's just it's it's a dating app for those embedding is what you're describing even you know uh it's very interesting it's good too because it's actually privacy preserving it's right it's the only information you're transmitting is your relationship with that with that user base in in that service you're not you're not actually showing them your Google searches uh search uh files just how similar your eyes to uh one user or the other uh which I think is another really great thing because it's a lot in terms of mental barrier I know I don't feel bad about sharing I would feel bad about sharing uh my Google search my entire Google search history to to everyone but just the embedding this this you know 256 long long character string boom easy yeah and I think that might actually be like a nice uh even like a nice uh uh uh like a conclusion of this of this conversation right where we say like okay these um we we it's like over that Tipping Point on multiple levels where people where it's like good enough to give people the right value and the way that the information is stored and the way that we current information is so radically different from how we're doing that you know in like five years ago and before that the amount of opportunities for people to build new projects make new models build new startups build new businesses help people right doing new stuff is this this is going to be tremendous it's like it's a uh it's it's it's super exciting it's really cool it's really cool it's uh really good that we're we're part of it actually I'm I'd like I'm really glad it's kind of scary at the same time with how everything is happening but been really really happy that we're actually here and and I think the the problem that we're trying to attack is a really good one too and one that would often be ignored I mean you see how popular stable diffusion is um but not quite uh how popular trying to solve the local every day yeah exactly um no it's uh and it's been great working with you guys thank you for the support as well we've uh we couldn't have done built this with without webe um it's and to Echo what Chris said it really is an exciting time the it's amazing what's coming out every every day it seems like uh every other week um and uh it's great to be a part of it it's great to to use it to solve real world problems uh for real people uh we just excited to see what comes next excited to be in the space and and uh and just be a part you know a transformational time in history I believe it's fantastic to see what you guys have been and it's it's just it's fantastic it's just awesome and I remember that I tried it out I was like on our on our slack Channel that I was like oh this is awesome thank you thank you very much yeah well well Bob will look we look forward to setting Mary up uh Marianne up for uh we V8 to answer some developer questions I know I know the slack can get kind of crowded with all the questions that you guys get uh maybe we can just hook up to your documentation and the the issue tickets uh on GitHub and sort of automate 90 of your work that that would be nice if you can automate my work so and that's the great that would be great so thank you so much guys thank you thank you for having us on ", "type": "Video", "name": "Bob van Luijt, Chris Dossman and Marco Bianco on the future of search - Weaviate podcast #30!", "path": "", "link": "https://www.youtube.com/watch?v=s9aVAgk-6Ww", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}