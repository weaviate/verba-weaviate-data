{"text": "Hi Everyone! In this video, I cover the architecture design of Verba 0.3.0. Verba is an open-source RAG application that allows you ... \nhi everyone welcome to this video where I'm going to cover how you can build out your brag pipeline from scratch rather than using various Frameworks I'm going to show you how to the architecture design in each step of the process so we'll start off with how you import your data chunk your data vectorize understand your data and what kind of questions that you can ask and then we jump to the fun part where you can generate text from your specific documents let's get into it verba has access to all of the we documentation blog posts and YouTube videos users can ask questions that are specific to weate in our various features in this video I'm going to show you how you can build this from scratch by starting off with the reader manager the way that my colleague Edward has built out beautiful verba is by assigning an assignment to each manager so we'll start off with the reader manager and what that's doing is it's taking the path of the file path that you may have it's also taking taking in PDFs as an option for you to load in your custom data and start chatting with it in like a quick rag application verba 0.3 is going to allow you to upload data directly on the UI so in this example I'm dragging in a document called llama index blog post and I'm uploading it onto the front end um what this is doing is it's going to import this PDF file and then it's going to go through the process of chunking it now I'll jump over to the chunker manager what this is doing is ensuring that verba is retrieving the right context and not going over the token limit um so depending on the model that you're using because we are modularized right now we're um using open AI but we'll eventually allow you to use the sentence Transformers uh model so depending on the model it has different uh token limits uh so what the chunking is doing is the first one being the word chunker what the word trunker is doing is after each word it's chunking it so the' is one word then next jumping over to the sentence trunker once a sentence ends it that is trunk one jumping over to trunk two will be be the beginning of the next sentence next is the PDF reader and I have a video on the PDF and markdown reader and what this is doing is where there is a beginning of a uh topic uh so like in a research paper you have abstract and introduction abstract is one trunk in introduction is the second trunk and so forth uh moving on to the markdown reader what that is doing is taking the heading so it could be heading two and just assigning it to trunk it based off of the markdown heading now that we have our trunks we want to be able to embed our data so like I said in the first version we only relied on open AI but we're now adding more models for you to transform your data into embeddings um so we'll have the sentence Transformer and the cohere MultiLing go model what is really cool about that is that you can import maybe documents that are in Spanish and then chat with it in English and it's still able to retrieve the documents that have um the query that still have the documents that are similar to The query that you are looking for now that we have our data uploaded it is trunked and we have factorized it now the part that verba is doing is retrieving the context that is important or relevant to your query so the retriever manager is assigned the task to make sure that the query is that is relevant in blog post one is retrieved and it's not uh retrieving uh documents from document 10 per se um this is the way to just ensure that your query is getting answered correctly now that we have the retrieved information we can generate text from it so in Wei we have our generative module where in step one we are retrieving the blog posts or YouTube videos that are the most relevant and and then we jump over to the generation text of it so maybe you have a query that you want to generate text from so you take given this blog post I want you to write a Facebook ad about it or maybe a poem that is what the generation manager is doing and as you can see we have different models that are enabled with this um so you can use open AI you can use cohere or palm and this is that like modularized ecosystem that we discussed and that we want people to have so verba is open source and rather than just using the we documentation you can load in your own data I hope you enjoyed this video and I'll catch you in the next update for verba bye ", "type": "Video", "name": "RAG App from Scratch: Verba 0.3.0", "path": "", "link": "https://www.youtube.com/watch?v=wbR0l4OKzzI", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}