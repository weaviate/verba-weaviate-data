{"text": "Thank you so much for tuning into the first episode of our LlamaIndex and Weaviate series! This episode will show you how to ... \nhey everyone welcome to the first episode of the Loma index and weavate integration in this video I'll be going over an overview of what llama index is go over the various data loaders that they have hosted on the Llama Hub then I'll share how to load data and alleviate using llama index and then how to connect llama index to your already existing weave instance I also share a few ways to run review if you're not familiar so you can use sweepy embedded use WCS which allows you to have to run a 14-day free sandbox and then also how to run it on Docker so running it locally so these are just a few options that you can use to run revade and also get started with your application with using we beat and llama index together and then also share this in the review recipes I'll include a link in the description but this is really where I just share an end to end uh Notebook on a few features that we have in weviate but then also with our integration Partners as well all right so let's jump into the video This Is The Notebook that I'll be sharing under the Wii V8 recipes repository so make sure you follow along and go under Integrations llama Index episode one and then you can follow along from there so this is the overview that I already went over so I want to Dive Right into what Loma index is so Lama index is a framework that enables you to connect other LMS and storage providers together and when I see storage providers I am referencing abbreviate the open source Vector database so while llama index and vv8 together make the ultimate retrieval augmented generation stack is because the large language models don't have access to your specific data but when used Lama index and we meet together you're essentially supplying the llm with the data that is stored in your database so this is allowing you to make queries that are specific to your company like uh how long do I have to give my company my resignation letter or that's maybe a horrible example but you kind of you get the gist um so one cool thing about llama index is their llama Hub so it it's um it's a hub that has all of the various data loaders whether this be slack PDF documents YouTube notion which I show in this demo uh PowerPoints essentially all of these different data sources can be fed into your vector database and that is the first part that I show is how to load data into leviate using llama index and then also the other way around um so with that being said let's get into the demo so for those of you that don't have an existing VB instance running there are three options to get this started um so you can use we be embedded which allows you to run it directly in your application the only requirement is that your python client is up to date so just make sure is that minimum 3.21 and then running be embedded will work if not there are a few other options if that maybe isn't the best uh way for you to do that the other option is using our BB cloud service so you can create an account and then from there create a BB instance and what's really cool about this is that it's a 14 day free sandbox which really allows you to get started and like test the botters with Vector databases um so that's one option so run it completely free and then also embedded in Docker also free so whichever way whichever method works for you best um so once you create your bb instance in the console uh you'll pass in your url right here so I have my llama Index episode one uh working and then you pass in your open AI key here and for security and financial reasons I have it hidden and then also if you create your sandbox and it has authorization you can also pass it in right here um but for this demo I don't have that enabled lastly you can run review using Docker So within this llama index folder I have a gamble file and if you could just grab that run it and then it should be working and running at localhost 8080. so those are like three options to run wheat feet if you don't already have a repeat instance running another requirement to get weave set up is to build out your schema and so what I'm doing here in this cell is just building my blog post class and then I'm passing in my content property and what the content is is just a text that is within each blog post and I guess I didn't make this clear before but I'm using the bb8 blogs as my data set um so yeah make sure you check that out as well adding data to webva using llama index is actually super easy using their various data loaders so in this video I'm covering three uh ways to load in data using the simple directory reader but then also the web page reader and then loading in documents from notion but if you want to use maybe slack or PDFs or YouTube videos I'd recommend going to llama Hub because you can see like the various ways to use those data loaders okay so starting off with December directory reader what this is doing is just reading files in your file system um so I have all of the rev8 blog posts in my data folder and I'm just going to load that in as easy as that the next way to do this as well as using this simple web page reader so it's a web scraper that turns HTML to text so just to show you to give you a feel of how to do this um I just passed in the Wii Vape blog and then the Llama index and weave blog post and it's an easy way to load in data from websites the other option is to use the notion page reader so it loads documents in from notion and why this is so cool is because you can actually convert notion documents into markdown and I'm not sure if that's like a new feature or maybe I've been under a rock but that's really cool because now you don't have to go through the manual effort of converting blog posts that are on Google or maybe notion as well and converting that into markdown so this is a really cool option if you want to give that a try so at the notion page reader is doing is using your integration token so if you're a workspace owner or admin you can create an integration and then you'll just pass in your secret key here next with the page ID is so if you go to notion.so and then navigate to the document that you want to load in the URL will end with this code mixed up numbers and letters and then you just paste that into here and then it's as easy as that to load in documents from notion which is great now that we have our data we're going to want to chunk it up so we don't run into the limited token length problem so Lama index has a simple node parser and what this is doing is just chunking up your data so our blog posts in this demo into nodes next we're going to want to take those notes and upload it to eviate um so by doing that we need to construct our Vector store so here we have our weave client and you're setting that equal to client which is either a few are running it with embedded with a WCS instance or locally you're just going to want to connect that rebate instance to um you're going to want to connect that we beat instance here to construct the vector store and then what the index name is is just the class that we created so in our example we are using blog post which we defined in our schema and then we have text key which is content and that's the property that we defined in the schema as well now we want to set up the storage for arm bettings that's what we're doing is just passing in the vector store which we just defined here because we're using the weviate database next we just want to set up the index so we're just taking the nodes and then setting up that storage equal to what we had just defined here and that's really the last step that you need to get started with uploading data into alleviate using llama index now that we have our data in our weave instance I want to build a simple query engine so I'm doing this by setting by using the index that we just built and passing in my query so I'm asking what is the intersection between a lumps and search and where I want this to retrieve this information from is from my weebe database and to be a little bit more specific I want it to fetch the blog post where I'm talking about a lumps and search and Conor and I just published that blog post maybe like a few weeks back so it's kind of interesting to see how it answers this so it's saying that the intersection between alarms and search is the ability to use alums to improve search capabilities such as frag query understanding index construction and lens and rewracking Etc if you would like to actually read the blog post I'd recommend checking it out but it's really cool how you can build such a simple uh Engine with llama index the other option is to query using the VBA console so up here I'm connecting to my weevied instance and then I'm just running a simple hybrid search and for those of you who aren't familiar with what hybrid search is it's taking bm25 which is keyword search and Vector search and combining it together and it's doing this waiting by this Alpha parameter so Alpha set to zero it's pure bm25 and Alpha set to one it is pure Vector search so setting it to 0.75 or 75 is skewing more towards per Vector search but this is just something that you can toy around with for your application uh but for this I just set it to 0.75 all right so once it but it's going to return is a Content so just a text that is within the blog post and again my query is the intersection between a lens and search so I wanted to grab the blog posts that where we talk about this and it's doing exactly that here um so it's passing in or it's uh outputting the elements in search blog posts which is great another thing to note is that you can pass in your openai key and the header down here because we need to vectorize our query and yeah that's it that's one way to back your eye oh sorry that's one way to query in llama index and in mediate for those of you who already have your weave instance running and you just want to add llama index to it this is the way to do it so you just want to use the web reader which you can actually see the documentation on this and the Llama Hub um or just follow along with this notebook but you want to connect to WCS or pass in your localhost 8080 if you're using Docker so you just sign in with your username and password and then pass in the URL to your rebate instance and then documents what this is is just your schema so I'm taking my blog post class and then passing in AI content property now that I have run that you can now um query or you can now upload and query the existing class that you already have all set um so I'm again passing in the URL so that my we beat reader knows which instance to connect to and then I'm building out my query so I want blog posts about that explain what reftubec is and I want it to search on the content property limiting it to two and only outputting the content all right so now that I have my documents I need to build out the index and then I simply just run my uh query engine so again I'm asking what is reftubec and it says crafty bike is a machine learning algorithm that uses NLP to generate Vector representation of text references um that's a little debatable but it was able to answer so that's one way to query in a llama index but then again you can also query in the console so if I ask in the console what is rough to back using your text passing in my open AI key because we need to vectorize that you can see that it will output the blog post that is about rough tebec and why you need it for your recommendation system so if you'd like to learn more about what ref tibec is I'd recommend checking out our documentation thanks so much for watching the first episode of the weeviate and llama index integration stay tuned for future videos where I'll be covering how you can build more advanced guides with using llama index and movie together to really build that ultimate rag stack and then also if you'd like to follow along with the notebook don't forget to head over to the weeviate recipes repository where you can download this notebook and particularly or also just learn more about various features and mediate again I cover end to end notebook Demos in that repository and then also make sure you like And subscribe and tune in for the next video bye ", "type": "Video", "name": "llamaindex_and_weaviate__episode_1_data_loading", "path": "", "link": "https://www.youtube.com/watch?v=Bu9skgCrJY8", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}