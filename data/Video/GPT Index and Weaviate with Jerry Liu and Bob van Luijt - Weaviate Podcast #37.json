{"text": "Hey everyone! Thank you so much for watching the 37th episode of the Weaviate podcast! This episode discusses some of the ... \nhey everyone thank you so much forchecking out another episode of the wevapodcast I'm super super excited aboutthis one we have Jerry Liu the creatorof gbt index and we've yet CEO andco-founder Bob Van light so firstlythank you both so much for joining theweba podcastthanks Connor it's great to trygreat to be back on you know our ownpodcastawesome so uh Jerry could we dive intothe origin story of gbt index what ledyou to create this incredible tool yeahfor sure so you know uh these days qptindex is a primary tool to build aninterface between your large languagemodel and your external data and thisseems to be a problem that's resonatedwith a lot of people in the communityand when I first started playing aroundwith llms about a few months agoum I was actually trying to build abasic sales bot so basically you knowum to address some of uh customerconversations uh from notion Salesforcegong Etc and I wanted to use thegenerative capability of lens on top ofthis data to actually build a to-dosynthesizer for me for for the nextmeeting so basically do some sort ofmeeting preparationand of course whenever you try usingthis amazing technology on your own datayou start the first thing you run intois the token limitation and the cost pertoken right so one of the things thatum you basically have to figure out isokay well you know DaVinci right now is4 000 words how can I actually stuff allthis information into the prompt so thatit has the context to actuallysynthesize the information that I wantnow four thousand words is actually adecent amount for you know a cache butof course it's not enough to feed inyour entire database of information andthat leads to uh you know figuring outhow to build interfaces for stuff likechunking for stuff like being able to dobetter retrieval so that you canactually craft The Prompt in a way thatactually solves your taskum and so I started this off as you knowa design project uh built this thingcalled a tree index which basicallyhierarchically built a tree over yourexternal data that you could then usegbt to look up afterwards however Ithink since then it's grown from adesign project into an everyday toolthat people are actually using on top oftheir llm projects so I think that partis is uh super cool to see and I'm veryexcited to watch it develop more I wouldlove to I love to learn more about theexecuted tree that you're building soit's like you just went over it veryquickly but just I remember that we hadour first goal and I should talk usthrough it and it was like superexciting so can you talk a little bitmore about what you're actually doingthere like at the core of GPT indexdefinitely I mean again I think I justwant to emphasize that that started offas a design project and you know it'sit's one of those things where I kind ofjust um made it up into something that Ithought was pretty cool uh I think youknow these days practically speakingthere is a bit of limitationspractically in terms of actually using atree on top of large corpses of datahoweverum the uh the the Paradigm that Ibasically started with was okay so youhave this big Corpus of text now what ifyou basically just hierarchically builta tree over this text so what happens islet's say you take every 10 pieces oftext or 10 paragraphs and then you builda summary over every 10 paragraphs thenyou build the next uh set of parentnodes on top of this then you build anext set of summaries over these uhsummaries that you just built and thenyou kind of build the tree all the wayuntil you have a set of root notes rightand to me this is one way of uh almostlike information compression such thatyou basically build some sort of datastructure that you can then use with gbtafterwards and so you know when gbtwants to look up a piece of informationit can start from the top and then godown this tree to actually find theinformation that it wantsum and you know if you uh The Way WeBuilt This was quite naive and simple itwas just you know aggregating every 10Trunks and building this likehierarchical tree over it you couldimagine this generalizing to graphstructures which are actually a GPTindex supports through kind of moresophisticated means now and basicallybuilding a Knowledge Graph over yourdata and using this knowledge graph andleveraging this knowledge graph toactually feed into LGBT so uh the waythe tree index started was again justbuilding hierarchy over a set of text uhand then when you actually want to sendin a prompt or query you can start fromthe top and then of the tree and then godown until you actually find the piecesof information that you want these daysyou know I think the thing that worksthe best actually probably isn't thetrivia next though you know it was acool thought experiment and we do useparts of that and you see parts of thatlive on through other pieces of the toolthese days the most basic thing thatpeople start with is uh you uh take inthe Corpus of documents uh split it upuh you know embed each trunk and thenthrow it in a vector store right so likeweeviate or you know another Vectorstore and then during uh query time youjust retrieve uh top kum uh you know documents or chunks byembedding similarityand put it into the prompt and so thisis a bill has a bit less structure thanfor instance something like the treeindex or a Knowledge Graph it actuallyworks surprisingly well for probably Iwould say like 40 50 of use cases rightfor of like basic queriesum but I think this uh idea of the treeindex which then generalized into thisidea of like defining a composabilityand knowledge graph of your data is nowuh quite uh uh has the potential to toallow you to Define more complexstructures of your data as opposed tojust kind of random you knowum like just fetching different chunksof the room batting lookup yeah so somaybe I I'm still kind of wrapping myhead around the knowledge graphicextension as well as this whole kind oftop level index thing so let's say Ihave podcast Clips is like the examplethat I've been using to think throughthese things so if I I aggregate sayfive at a time to form a summary andthen from there I'm going to summarizethose to like summarize the next thingso when I'm searching through this indexin my first searching so I say I'mtrying to find just a conversationsegment do I first search through allthe summaries then I search throughthese intermediate summaries like canyou kind of take me through like how thesearch works through the top level indexyeah soum there's a few points here uh that I Ido want to addressum taking a step back just really quickyou know the the gbt index is alwaysevolving as a tool and going back to thehigh level Vision it really is aboutbuilding this interface and thinkingabout what exactly is a best interfaceand the set of tools that we can giveusers to you know build some structureover their data to solve their tasks andso so a lot of the tools that you seewith LGBT index today are manifestationsof that so stuff like you know we offerIntegrations with Vector stores we offerthe ability to Define graphs on top ofyour data it's possible as these modelsevolve and you know as considerationscome in for instance stuff like latencyand cost these structures will alsoinvolve so to take what I'm saying rightnow with like a slight grain of salt inthat I think we're sold very muchoptimizing towards okay what exactly isthis like best structure of data thataccounts for again latency costs andperformance and that solves a broadrange of different use cases from youknow customers and Enterprises so withthat said you know one of the thingsthat we we thought about in thebeginning was toum uh and and this is something thatwe've heard from users of GPA indexesyou know uh uh it it'sum it's hard to kind of feed like highlevel context into uh into for instancelike a text trunk for uh as an exampleso when you take in a document and ifyou just naively you know split it up uhand and now within each tax dunk youkind of lose some information about whatthe entire document is about so goingback to an example of say like a bookyou know if a book is divided intodifferent chaptersum or actually maybe a better example islike a research paper uh research paperis divided into different sections likeintro related work methodology and thenwithin each section you know you'regoing to have subsections describingdifferent components of each section nowif you split this entire text up intodifferent trucks and let's say you justhave like section 2B and some randomslice of that you're gonna not reallyhave information about how this relatesto the rest of the paper so one painpoint that this idea of defining a graphover your data can solve is that you cankind of like hierarchically build uh oryou you kind of have this like hierarchyof context both like very fine graincontext and then also kind of likehigher up context with the summary andso one thing one use case that GP indexwith these graphs allow you to do islet's say you do say build an index forevery subsection of your of your paperand then then you build an index forevery section like so you set a summaryfor every you know intro uh like relatedwork methodology and then now when youactually query this you know kind ofparent top level index it can bothretrieve specific sectionsum of text that are relevant to yourquery but also refine it with withhigher level contacts and this happensbecause you're able to define a sort ofgraph over your dataanother use case of this isum you know again what is the finalgraph of your data me and at leastinterview BC Index right now itbasically just means you can Define likeindices on top of other indices and soanother use case that this could uhthis could solve is let's say you definea sub index for every data source solet's say you have a collection of uhcall transcripts in gong and then youhave a collection of notes in notionright and let's say maybe you have someconversations in slack now when you wanttoum like uh uh ask a question let's sayyou explicitly want to want tosynthesize and answer across all threedata sources now what you can do is youask this question and you define a subindex for each one of these data sourcesand then you define this like higherlevel index at the top level and nowwhen you ask a question we just routethis question to all three of these datasources and then we combine them withthis top level index for instance usinguh one thing that GPT index offers islike a list index data structure whichis synthesize and answer across everysingle uh node in its structure so sobasically this allows you to justcombine information from all thesedifferent sources into one response soit's it's quite an interesting thing youknow like Ium I I uh I think people are stillexperimenting with different use casesof uh such a structure this idea of aKnowledge Graph but the idea of justlike being able to Define some sort oflike hierarchies uh over your data hasproven to uh sometimes yield betterresults depending on your use casevery interesting I I have a questionabout like a term that you that you keepmentioning you keep using the termKnowledge Graph and I find itinteresting because it has that has kindof a it's of course already also kind ofan older term if you will was also verymuch related to the to the semantic weband I think that if we talk aboutknowledge graphs todayum uh or like the traditional way oftalking about a Knowledge Graph wasmostly also related to just you knowjust having notes in your graph and thenand then just having just you know fixedrelations between them maybe like usingSparkle or those kind of thingsone thing that I find interesting andand in in uh in in wifi8 we also supportlike simple route structures right soyou can just make cross-references andsometimes I also use the termKnowledge Graph to talk about this rightthat is like it seems that there's likea change happening where these the notesin the uh in the graph are not just on a2d plane right so just like a graph andthen relates to another one but then weactually placing these notes into thehyperspace that these models give usthrough these embeds right so thequestion I think I havea little bit speculative but could it bethe case that the um sorry that um forexample GPT index or in combination withlike a effect store like with it couldbe like a new Revival of the of theknowledge graph like the knowledge graph2.0 or would I be too ambitious uh if Iwould say those kind of things cursewhat you think about thatconceptually that absolutely could bethe case I think there are a fewpractical uh limitations and challengesthat we would have to solve to make thisworkum but there are already components thatyou can kind of see within GBC index andyou could totally integrate with theback end store like uh we did so umthere'sum the part that GBC index supportsright now is given you know auser-defined graph uh let's say theyconstruct it within GP index tools uh wecan then you knowum uh kind of perform operations overthis graph right we can then route likeperform have a query and Route itthrough the knowledge graph to get tothe right information that it needs toanswer this this queryum there's also this separate componentof Knowledge Graph construction rightwhich like uh right now uh you you uhusers uh have to build a little bitmanuallyum on on top of their data at least withNGP index and you know I think it's alsoa very interesting question to think heylike you know what uh are ways tobasicallyum infer a Knowledge Graph right fromunstructured data uh and and you knowlike maybe we can generalize Beyond thisidea of like a Knowledge Graph just uhgoing back to the mission statement ofGPT index is like what is the beststructure over your data that we caninferum you know most of the world right nowor at least in terms of data and fraudlives on structured data right and thennow of course there's a lot of uh stufftaking off around like unstructured uhdata paired with Vector stores and thenthere's this idea of knowledge graphsand so figuring out you know how toextract for instance like entities fromthis data either in a structure formatand a graph format or as like rawinstructor text I think these are allvery interesting questions think aboutand you could totally use gbt to uh touh you know at least in the ideal stateto automate a lot of this ingression andtransformation and so I think that isabsolutely something that you knowespecially as these models improve likegbt index would want uh want to be atthe Forefront ofuh so I think so I think like therethere are really theseum two components and and uh right nowone thing that gbt index does is itallows people to uh Define uh you knowgraphs uh on their own on top of theirdata and be able to you know routequeries through through these structuresbut I think you know the the line ofwork that we're very excited aboutimproving is how can you infer differenttypes of structures one thing that gbtindex does offer right now is we canallow you to pass in your unstructureddata and we can actuallyum infer structured data points fromthat and put it in for instance like aSQL databaseum one line of work that we do want todo is do a bit more in terms of thinkingabout how to best address and storeunstructured data in different formatsuh outside of just like naive texttrunking for instance right and so oneuh feature that users have asked for isoh how can I inject like Global metadatainto each structure text trunk topreserve some sort of global contextI have a quick question about it becauseI find it so intriguing so so so so soso Conor and I we we did a little bit ofresearch also with the with the we werelooking at like creating feedback loopsalso with umum with the database right so that youhave a query that goes into ev8 and thenwhat we currently do with the generativeParts actually goes into ev8 and thenyou get like your candidates and thenyou bump that through like or pipe thesub pump through a generative uhum model and then you can do you cangive it a prompt right you can give thetask and what we were playing aroundwith was that we were saying likeum you know can we also ask the modelfor example like to just do anotherquery in vv8 and as part of the promptwe basically said like we want you topopulate this Json object right withthis key and this action andto my surprise I was just yeah maybe Idon't know I was just flabbergasted thatit actually did that but it it yeah youremember that we worked on a counterthat it presented the results as a Jsonobject and they were like but that'samazing because then we can really havelike more functional uh do morefunctional things with with the model sothe reason I'm bringing this up is Iwould love to learn you said somethingso interesting about like uh how you'relooking at having the llm help increating the structure would it besomething similar as that I justmentioned or is it something completelydifferentoh 100 I mean I think that would uh I Ium it's actually a pretty interesting uhway to to try to uh get llamson for uhdifferent types of data um the use caseat gbt index does right now is itinfrastructure data from unstructureddata um I have seen uh uh people playaround with different tools I'm sureyou've seen this too where you know youjust ask your PT that hey just likestore context within the prompt itselfand then just give me back like anotherJson object also in the promptum and so you just see in the prompt youjust feed in like your entire like Jsonobject and then and then it'll give giveyou back a new Json object for instanceum I think uh yeah I think I think theseare something things are we'reexperimenting with I think there'sprobably like a few limitations to forinstance just like storing context andstate within the prompt entirely justbecause again due to like token sizelimitations but if you can somehow againmaintain some sort of structure and thenhave gbt index be able to both read thestructure and be able to know how toupdate this structure uh you know andthis structure is maybe stored outsideof the prompt itself uh in some formatthat but then you can feed parts of itinto the pump then that that part isvery interesting to um to think aboutbecause I think um yeah like imagine youmaintain this Json structure but thenyou were able to feed parts of this intogbt index so uh still a beta token sizelimitation but it provides uh gbt enoughcontext to help update and insert newelements into this overall structure Ithink that's going to be reallyinterestingum there's also stuff around forinstance like Knowledge Graph inferencewhich you know like imagineum you know given this content you canextract like entities from this contentand then you can then in forrelationships between the entities andnow you know I likeum there's this cool project called likegraph3pt where I think uh it was thisyou know front-end visualization andthey had this like a nice front end butuh what they did was they basically youknow took in this user query and then uhbasically directly asked gbt to inferthe structure uh directly within theprompt so like it kind of like given theoutput it should infer all therelationships within the data that youyou feed it I think that's alsosomething I've kind of been interestedin for GTA index but maybe extendingthat to also storing the structureOutside The Prompt itself and then youknow given some unstructured data likestart building up some knowledge graphover your entities within the structurethat you can then you know query overwith with gbt index uh so you know lotsof very interesting things around notjust like the query side of things usingolives but also actually how toconstruct these types of structuresusing hpvd as wellyeah well when I when I think ofKnowledge Graph I also think of thislike um you know like Conor lives inBoston you know works at weviate likethat kind of structure where it's youthe the data structure is to collapsethe entities into the single thing it'smade me think about like um so if I havelike coming back to the podcast clipexample I might extract the entities andthen use that to go get the facts andthen add that to the promptthat kind of thinking is is it yeah iswhat it is inspired me but I kind of ifI could come back to something else youwere saying about the integration ofdifferent data sources like slack uh thecallsthese kind of things and it makes methink that like so in weviate usuallythe thinking is we would divide these upinto different classes and so then justthe atomic units each of them lives intheir own Vector index like based on thethis is the slack Vector Index right soso are you taking all the atomic unitsof all the different data sources andputting them all in one kind of vectorindex and then you build up thehierarchy from that kit like how doesthe kind of chunking of atomic units inindex construction happenuh yeah that's a good question I thinkyou know it makes sense to me for allthese different data sources to bestored in different uh structures uh souh for instance if there are differentweeviate tables or just like differentyou know indicesum I think what we would do is we'dprobably want to maintain that structureso we don't want to like you knowcollapse all the data into one table uhon on our end but what we'd probablywant to do is let's say you have usecases where you do want to for instancelike synthesize a response across allthree different data sources or you wantto route a query to the best set of datasources that can answer your question wewant to you know treat for instancethese data sources and we V8 as threedifferent sub-indices and then allow youto build some index structure on top toactually solve your use case whetherit's summarization or uh routing forquestion answeringso then that routing that's um that'sthe the llm tool use where you tell ithey you have you know slightconversations blog posts rightoh kind of yeah so so there's differentways you can you can think about thisone is you can directly do this withinGPS index itself it's actually part ofthe graph so just imagine like a parentuh node that'sum you know at the top of the graph andthen each trial node is like yourdifferent data source so you have likethree trial nodes one slack one is anocean one is you know uh gong orSalesforce and then you can have aparent node at the top that acts as arouter so then you can actually you knowgiven a query like pick and choose whichof these uh trial nodes is most relevantto your queryum you can also actually integrate thiswith kind of multi-step agent behaviorsand you know for instance like Lanetrain has an agent abstraction where youcan actually act in some sort ofmulti-step Manner and can choose betweendifferent toolsum then you know you can also have thesedifferent uh sub indices B tools thatthis agent can choose from so part of itis just dependent on which abstractionlayer you want to build atum if you do want to kind of wrap thisinto entire thing around a GPT indexlike data structure you could to solveyour use caseyeah so yes I think the whole the agentthing is a whole conversation likebecause I don't want to get too off ofjust kind of understanding the subindices and all that but maybe if wecould come into just the tool used theexternal apis and all of how that'sintegrated with GPD index yeah so sorryjust like clarified do you mean like theline training tools or do you mean yes Ithink kind of I've been so I'm so sorryfor the slower so I'm still trying tolike process the understanding of the umthe sub indices and all that but so Ithink in addition to the sub indiceswhich is like a data structure there'salso like the tool used am I correct inthinking that these are two separatethings like the the llm tool use andthen sort of using GPT to create theseindices or those like you see those asseparate yeah so um I can try to helpclarify it uh that's a little bit moreat a high level um I know uh the way Idescribed it was probably a little bitcomplicatedum but basically in in my mindumimagine GBC index like a data structurelike quote unquote you know we we havethat termum just imagine that as a interface toyour data and so the like imagine thatentire thing as a black box right so youyou've given some question and at theend of the day you want to define astructure so that you get back theresponse that you want right that'sthat's kind of everything within thatbox is that data structure that we uhallow you to uh allow you to create soum if we just operate purely within thethe tooling of gbt indexum going back to that example of havingfor instance like sub indices what Imean is let's say you define like aseparate index data structure for youknow all your notion uh notes and thenalso your slack conversationsall right now what you can do is you canactually Define say like a top level uhdata structure over these um uh you knowsub indices or individual data sourcesuh and this top level data structure cantake on different formsum it could act you know as it could belike a list index which is like asummarizer basically it can you knowum uh it'll route the query to eachindividual data source but then combineall the responses into one response itcan act as a router where it actuallypicks like a subset of these uh subindices to actually dive into and thenin the end it'll synthesize a responsefrom the sub indices but basically justimagine say you know you have someparent node as a graph and it can routeit to some you know data structures assub indices if you will and so if youchoose to you could wrap this entiregraph including the parent node and thetrial nodes into one Gypsy index datastructure that you can then you know sayquery for uh summarization or as a queryfor question answering and then we'llroute the queries underneath the hoodright based on your graph to actuallysynthesize the response that you wanthopefully that that makes a little bitof sense but the idea is that you cankind of allow users to Define some graphquote-unquote structure of your data toum kind of you know Define uhhierarchies to solve the tasks that youwant and at the end of the day it's justallowing you to be able to query oversome data and then you're able to getback the response that you would wantum the Integrations with other tools forinstance like Line train is a separatecomponent of this so for instance likeum one thing that you a lot of users aretrying to do is let's say you define anindex structure over your data let's sayyou know you definejust a simple Vector store base indexover your notion notes or your slackconversations and but let's say you'rebuilding a chat bot right and you wantto use like Link train to do that so youcan build a light train tripod whichwill maintain your conversation historyand this agent will also try to look upor try to use different types of toolsuh in its repertoire to actually performdifferent actions or perform lookups soyou can actually add these indices astools withinum you know kind of like the set oftools that Adrian can use so that uhwith this subtraction every time theagent is trying to reason about a stepthey can choose a tool that will help itperform you know uh uh that that's likethe best tool suited to to perform theaction that's requested of it and thiscool tool could be a gbt index uh datastructure right and again going back tothe fundamental interface what you cansee indexes you can pass in that queryright some request and you'll get backsome something out of it and the thistool could uh like this GPT index datastructure could be arbitrarilycomplicated it could be very simple likejust a vector store index or it could bean entire graph structure underneath butan agent can choose to you knowum basically use this as a tool to getback the response as it needs at a highlevel you can basically think of this asyou know um one thing that like theagents do really well is that they cando multi-step reasoningum but you can treat GPT index as onestep right of this multi-step reasoningto achieve uh retrieve the informationthat you would wantinteresting I I so while you weretalking about this I I have a quickfollow-up question related to thatbecausetheum it for me making like these thesethree structures that that makes a lotof sense to me it's also I find it superintriguing in in how you how you uh umuh how you you know walk down the treebasically to find the answers I I havetwo questions about that so one is likelet's say that I have like a largedocument because actually this issomething I don't know let's say I don'tknow like really large like 100 Pagessomething right or like 100 paragraphsthat's maybe easier how what what doesthe how much insurance is it doing onthe model to find the the answer and howmuch time would it take just to producean answer so how often are we talking tothe model how often is GP index able toknow where it needs to Traverse towhat's what's what are we talking abouthere yeah so um no it's a good questionand I think uh again uh this probablywarrants like a broader discussion aboutsome of the trade-offs you make whendefining these graph structuresespecially with the current state of uhGPTum imagine every node of uh whatevergraph that you define right if it's atree structure let's say you know youhave two levels like a para node andtrial nodeevery node is going to require some llmcall maybe two right to to gbt nowum you know there is uh some sort oflike practical like cost and latencytrade-off that you're gonna have tothink about when you actually Definethese complicated graphs over your databecause I think conceptual it's veryinteresting it makes a lot of sense butevery call to gbt is going to takearound like you know two to threeseconds if you just give it like uh youknow three thousand four thousand tokensright and it's going to incur a marginalcost as well so there are just somepractical constraints in making thisgraph overly complicated because themore nodes that you add and the morenodes that attribute index has toTraverse the more alaline calls thereare going to be and then you know thethe kind of longer and have to wait foryour responseum so I I think you know for a lot oftree structures uh practically speakingwhat uh has worked well or just aslightly more shallow structures so avector store a base lookup actuallymakes a decent amount of senseum because actually it for an embeddingbased query you don't really need tocall the L one at all right you just doa DOT product and then the only callsyou need to make are to the embeddingmodel during construction and then maybea call to the language model finally ifyou want to like synthesize and answerright from the set of nodes that youretrieved through embedding lookup soembedding lookups can can be a prettypractical like uh cheaper alternative tothatum but I think yeah generally speakingyou know hopefully as these models getbetter and the costs and latency doescome down this notion of repeatedlyquerying or recursively querying the llmfor more information has already provento be pretty useful in a lot of caseslike if you think about just like youknow Chain of Thought prompting reactquote traversing through knowledgegraphs it's evaluation it's all veryinteresting but that stuff will be morepossible once we solve some of thePractical constraintsyeah and I'm actually this is sointeresting because this goes back tothe thing we we just discussed um uhabout that we're looking at how can weuse basically the llm to just also feeddata back into into V8 and what I likeso much about Jeep index is that thatyou support like these graph connectionsso it something that I'm superinterested in in like also furtherfiguring out is that rather than justhaving this combination of GPT index andthen view it as a vector store thatstoring these connections as well uh sobasically that if you if you if you dothe query like for the first time youknow it needs to go to the model needsto figure it out but it can not onlystore for example the embeddings butalso theum the graph connections that it'smaking that is something that I'm I'msuper excited about because I would notbe surprised that this year we're gonnasee this trend of yeah for the the termthat I'm now using is just creating afeedback loop back into the databaseusing using tools like for example GPTindex and I find that super interestingI'm I'm I would not be surprised if wesee some prototypes in the in the nearfuture exactly doing that becausethen you could even say like heyum uh um you know Jeep DNS I want you tofigure something out for me I'll be backtomorrow you know and I'll just itstarts to Traverse it starts through thelookups it starts to add stuff to thedatabase and then the next day you seeall these graph connections andrelations in the database and now youcan fast and quickly Traverse over it II find this very intriguing it's it'ssuper interesting super interestingI find it very interesting too I mean Ithinkum if once these part of this is a betthat these models will get better orfaster and cheaper and then you canstart using it to really automate someof your uh more of your kind of likedata ingestion and transformationpipelines and reduces the human workloadon really thinking about okay what isthe best structure of your over yourdata right because a lot of dataengineering once this does get better tosome degree quality well uh uh I can'tkind of hopefully try uh be solvedsomewhat by by being able to um uh infera lot of these relationships uhautomatically uh right as opposed tomanual definitionI thinkum yeah I'm I'm very excited to seewhere this goesum I think they're they're uh uh likejust a kind of like with a grain of saltthere are some practical considerationsjust because you know um it is I thinkimportant to Define some uh performancebar right over like what is theacceptable level of quality that you'relooking for like for instance if you'redata and dress pipeline using GPT isactually you know making mistakes like10 of the time like that might be toohigh right and and then the question isthinking about how can you think aboutsome interface where you know maybe it'snot automating all of it there's stillsome like human feedback in the loop butit's automating like a good chunk of itright and and and then it can actuallyhelp Empower and speed up like usersworkflows and actually building out someof these pipelines so uh a similaranalogy to this is you know why forinstance something like copilot ornotion AI are popular because they allowfor mistakes uh made uh by the modelright and so you do want to probably putthis as some interface where you canstill allow the model to make somemistakes because you know the model isgreat but it's not perfect it makes alot of mistakes uh and and soum how can you make sure that the errorsdon't propagate and that you can kind ofcorrect errors right now I think that'sa gonna be an interesting interface tothink about and probably something I'mthinking about for for GPC index as welland the hope is as these models getbetter you're going to have to do alittle bit less of that yeah I have onemore follow-up question about thatbecause it's so interesting so if we ifwe switch gears a little bit from youworking on GPT index more as likely youknow the the the the the project youalso need to design it right so you'redesigning like the the interface howpeople interact with itum what so what kind of things are youtaking considerations for those who wantto use stupid index really to to buildlike production social right so are youare you taking it into considerationright now or like no no I'm just parkingthat that's just you know first thingsfirst and then do that later or I wouldlove to learn how you how are youthinking about thatum I thinkI think um uhI'm somewhat parking that and the reasonis because I haven't dove into the uhfull brainstorming about how to reallysolve like uh how to automate like dataingestion and transformation I imagineonce I really start thinking about thatthen the notion of you know how toevaluate performance and how do I uhcorrect errors those types of thingswould become more important I find thatfor the basic use case that a lot ofpeople are using right now for GT indexbecause the construction of the index isstill kind of manually determined by theuser uh a lot of the end use cases arefor instance for like summarization andsearch and for a lot of the current usecases uh it's actually okay to make someerrors right like you know your peopleuse like recommendation models ml modelsand search all the time and you know uhpart of the appeal right now is you canactually just do search and build thattype of tool a lot faster with somethinglike ubt very interesting very cool andfor those listening to this podcast whoare responsible for building and servingthese models you all know what to do youknow we need some we need some speedyeah I had one question I want to jumpin on the correcting the errors um soone thing that I've been thinking aboutis like with the cost like you you mightinstead of using DaVinci 3 you might uselike Ada or something to have likebecause it's cheaper and then you cansample like 100 outputs and then re-rankthem with these ranking models uh so sowhat do you think about that kind ofidea where you use a lower capacity gbtbut then you generate a ton of outputsand then filter re-rank the outputsyeah I mean I think there uh there's alot of approaches to dealing with thatright now um I haven't uh been able toexplore this fully but I think that umat a high level the idea of say buildingsome optimization layer that can have areliable estimate of performance uh uhbut also give you you know like uhpredict the the cost and uh thatsatisfies your compute Budget Buildingthe optimization layer is absolutelysomething I want to start working on andso whether or not that includes forinstance using like cheaper models andstacking it with like uh better modelsright uh or whether that's a notion ofjust like how do I try the best to likeevaluate latency and how do I speed thatup right with respect to for instancelike async operations orum or other techniques those are all inconsideration for this idea ofoptimization because I think right nowthere's like a lot of there's like agrab bag of different techniques thatpeople can use to try to uh like bothmake things a little bit cheaper andalso a little bit fasterum ideally what I'd want to do isprovide an interface and make that asaccessible as possible and also adopt alot as these models get better becauseuh you know that is some of thesetechniques might become out of date asthese models get better like uh a classI mean one of the examples is is theopen AI embedding like before like openair release like tax and betting data uhright like zero zero two uh like it wasjust infusible to actually use open AIembeddings like I I ran up a 20 Billgoing through like uh like two or threedocuments uh and then all of a suddenwith these embeddings are like 99.98cheaper it's just a lot more feasible touse this to index a lot of documents soI think um we do want to make this uhprovide some general tooling to to helppeople decide between cost and latencyand we also want to adapt this tool toFuture advanceshow much are you are you connected to togbt models right because it's in thename right it's a DVD index but uh youknow you you know a lot is happeningthere so is that just uh it are you areyou like you know married to gbt modelsor are you just open to also exploreother thingsyou know Bob that's actually a greatquestion because you know I'm going touse this opportunity to say that we areactually going to undergo a name changeuh probably you know within the next fewweeks it'll be gradual you know we'llsupport some sort of backwardscompatibility with this package of GPTindexum that everyone's familiar withum but uh yeah so we are very muchum uh trying to trying to I mean thetool itself is already General but we'retrying to also position it as moreGeneralum uh already like you know GPT Indexright now supports different lensbesides just open AI models itself rightyou can plug inum basically any sort of llm fromplugging face cohero 21 other modelproviders and you can also plug indifferent types of them adding models aswell we do want to be a general toolinglayer on top of like different uh llmsright as opposed to being tied to aspecific service also you know changingthe name and and more General will helpus avoid some trademark issues so uhvery excited to start uh kind of keepingyou posted on some updates for this soso are you are you going to keep uswaiting or can you already share whatthe name will beyou know I um I weI will give you a hint in that wereleased a llama Hub about two days agoor yesterday and we like llama as aprefix and I think that's what I'll saythere okay okay that's that's finethat's fine that's that's we can workwith that thanks for sharing yeah that'sgreat because llm it's too like you knowthere's no vowels in the middle of it noexactly yeah I I love the name I thinkthat'd be a great thing if we could talka little more about llama Hub uh so Ihad a quick look at it it's like a hubfor external data sources tell me moreabout it yeah exactly soum maybe to frame this a little bitbetter you know part of GBC Index rightnow is the way you can Define complexrelationships over your data but reallythe higher level mission is again toDefine this best interface of your dataright and one thing that we've beennoticing especially as people have beenstarting to use GPC index is thatit has this entireum pipeline has a potential to kind ofalter the data analytics landscape likeif you think about just the amount ofwork it takes to address data right andthe data engineering pipelines in placeto address transform you know store dataand then you know transfer transformthose into insights that you get to theend user there's like multiple companiesand you know billions of dollars withineach of these components right sowithin like five lines of code withinGPT Index right now right you canbasically build a Search bot you canaddress your PDFs right convert it intosome text and the beauty about gbt isthat you don't have to make that textsuper structured you just need toprovide some information about it andthen the worries that you have are moreabout like text trunking and how toactually provide this information andthen you store it you know in someformat whether you know it's uhalleviate uh or or some more structureddatabase and then you just ask gbt tofor to answer questions right and thenGPT can handleknow translation to SQL or just directlyusing the the raw question to answeranswerum your query so there's just a lot ofkind of interesting things happeningaround this idea that I thinkum if once llms do take off this entirepipeline will be able to change uh andand actually become kind of like a lotsimpler and and just uh more automatedand one of the key components at thebeginning of this is this idea of dataingression right and soum I think one thing that's been reallycool a really cool component of GT indexso far is we've seen users submit a lotof community built data loaders uh fromPDFs so for instance uh HTML documentsto PowerPointsum to web pages and apis with prettymuch a lot of the popular Integrationslike Notions slack Discord uh we have aGitHub integration coming soon as welland it it's really the thing is it'sactually not super hard for users to addthese Integrations because you know whatthey have to be worried about is justnot like doing all the ETL into astructured database they just call orconnect to this API and they provide theinformation as raw text maybe with someannotations on top right and then thequestion is just okay now how can youfeed this into something like 3pt indexbut can which can address this raw textand do Tech splitting and and you knowstore it into an index data structuresorry yeah so if you look at the um ifyou look at the at the uh the the sulfurstick right so where you have the useron top and then core infrastructure onat the bottom right so and so you havethe whole stack and then for example soso we've hit is a bit lower because it'slike a database and then GP Linux alittle bit above that closer to the tothe userdo you think that GPT index would evolvealso more like up the stack so because Iwas very intrigued what you said aboutlike also all these these data loadersthat people are introducingum that is interesting because thatwould allow you to have like this wholeyou know uhum you know Marketplace basically ofdata loadersum or are you more interested in movingdown the stack how do you see thatdevelopuh it's a good question II don't really see myself or Jupiternext movingum down the stack anymore right uh atleast at the current moment because youknow like we V8 knows you guys know howto create like scalable like highperformance like databases right and anduh part of gbt indexes appeal isactually just being able to integratewith uh for instance you guys toactually uh help users build an appright for uh uh on top of their dataum I could see us expanding bothhorizontally and and maybe a little bituh kind of up the stack as well I thinkdata ingression is one of those piecesthatum very much is that fits within thisphilosophy because you know we we buildthis Marketplace um or this communityit's not really a Marketplace but like aCommunity Driven Hub of uh people tryingto submit and then you know justsubmittingum different types of parsers andloaders for different different types ofapplications we can try to have them useGPT index with this data loader or youknow you can actually use this with Lanetrain as well and what it actually doesa few things one is you know we providethe central platform for them to thenaddress this data then you know whatwhatever the storage and kind of likeum uh of this data is it could you knowvery well be weeviate and thenum the other component of this is thatby kind ofum creating this community of dataloaders we can help almost like educateusers on the value of outlands becausebecause now you know you can actuallyhave people thinking hey like it's notlike I only need to just feed in my textnotes right it actually turns out likewith Technologies like not even just agbt or llms like by combining stuff likewhisper or like image captioning modelsor any sort of you know uh models thatbasically convert unstructured data intotext we can actually build thisend-to-end application starting fromthis very unstructured data intosomething that you can actuallytranslate into insights so I think thatthat is uh very much something that ispart of our vision and I think the firstpart of that is super important as wellyeah well I I think um well I thinkthat's a good coverage of the topic soif there's anything else you guys wantto add I I mean you shouldn't offer thatbecause I can keep talking for two morehours about this so it's like this isjust too exciting stuff man too excitingyeah well maybe I I want to throw thisin quickly before we wrap it up is umlike how about the extension from textimages and multimodal I just love thistopic because I think we're yeah so wesaw the diffusion models and I think alot of us predict that you know we'reheaded towards this boom and and uhimage uh image audio video 3D images allthat yeah 100 I mean I thinkum I'm still kind of trying tobrainstorm use cases let's say for textto image like what that would look likeand you know this is just me spitballingoff the top of my head is it like oh youwant to be able to reference like acorporates of existing data that's alsoimages that you could generate a newimage is that that you want to be ableto reference a corpus of textdescription so you can generate a newimage I'm definitely open to thepossibilityum at least in terms of including somecomponents of that I will say though interms of like storage or orconverting from like say images andaudio to text that's actually part ofthis idea of llama Hub and actuallysomething that we we want to push forimagine if you can just you know take insome different types of uh data rightthat are not inherently taxed on theirown but you can convert them into a textformat that makes it pretty easy tosearch and look up without doing toomuch data engineering on your side Ithink that could be a pretty valuableapplicationyeah it's incredible do you see likemaybe even like brain computerinterfaces like that kind of data beingtranslated and GPT index going throughyour brain scans yeah no I mean I thinkyou know a lot of the heavy lifting isdone by these models that are are doingthese conversions and and we're veryexcited to keep tabs on the advanceslike for instance we integrate like openair whisper we open it uh integrate likethe donut model which does like uh kindof OCR uh we're very excited to try toinclude this and now the question is howcan we uh you know wrap this in a layerthatum makes it both easy for people tobuild apps on top of it and then two uhmake this uh scalable and perform itright because you know some of thesemodels do have GPU and performanceinstruments yeah and one more as I'mlike doing this list what about roboticslike uh have you seen the the say can uhlike kind of how much these advances intext processing are impacting therobotics generalization as wellyeah that's interesting I mean I kind ofum came from a world of self-drivingresearch beforeum uh my current role uh and this is afew years ago and I think so far youknow I think it's beenum somewhat decoupled like I think youyou'd store for instance like image andand lidar data as uh you know uhembeddings on its own you don't reallythink about like converting it to textuh so I think you know for practicalreasons there's probably ways to justlike store different types of data intheir own formatsum but if you know we start to see thesemodels become just again faster cheaperand better like I could see text being abit more Universal of the interface forstorage and then and then you know thenif you're filled a bunch of applicationson officeyeah incredible well Jerry and Bob thankyou so much for coming on the webapodcast and for having this discussion Isaw Bob recently shared a meme whereit's uh Patrick from SpongeBob his headis exploding and that'sthat's how I felt this whole time and Ithink this is just such an informationheavy uh podcast I think this sub indextool use this routing thing is just oneof the most exciting emergingTechnologies and we're so grateful tohave you on the podcast so thank you somuchyeah fantastic thank youamazing thanks a lot and thanks Connor", "type": "Video", "name": "GPT Index and Weaviate with Jerry Liu and Bob van Luijt - Weaviate Podcast #37", "path": "", "link": "https://www.youtube.com/watch?v=jbQ2UbnU7vQ", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}