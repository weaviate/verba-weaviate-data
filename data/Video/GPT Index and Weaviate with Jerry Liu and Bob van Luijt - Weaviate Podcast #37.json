{"text": "Hey everyone! Thank you so much for watching the 37th episode of the Weaviate podcast! This episode discusses some of the ... \nhey everyone thank you so much for checking out another episode of the weva podcast I'm super super excited about this one we have Jerry Liu the creator of gbt index and we've yet CEO and co-founder Bob Van light so firstly thank you both so much for joining the weba podcast thanks Connor it's great to try great to be back on you know our own podcast awesome so uh Jerry could we dive into the origin story of gbt index what led you to create this incredible tool yeah for sure so you know uh these days qpt index is a primary tool to build an interface between your large language model and your external data and this seems to be a problem that's resonated with a lot of people in the community and when I first started playing around with llms about a few months ago um I was actually trying to build a basic sales bot so basically you know um to address some of uh customer conversations uh from notion Salesforce gong Etc and I wanted to use the generative capability of lens on top of this data to actually build a to-do synthesizer for me for for the next meeting so basically do some sort of meeting preparation and of course whenever you try using this amazing technology on your own data you start the first thing you run into is the token limitation and the cost per token right so one of the things that um you basically have to figure out is okay well you know DaVinci right now is 4 000 words how can I actually stuff all this information into the prompt so that it has the context to actually synthesize the information that I want now four thousand words is actually a decent amount for you know a cache but of course it's not enough to feed in your entire database of information and that leads to uh you know figuring out how to build interfaces for stuff like chunking for stuff like being able to do better retrieval so that you can actually craft The Prompt in a way that actually solves your task um and so I started this off as you know a design project uh built this thing called a tree index which basically hierarchically built a tree over your external data that you could then use gbt to look up afterwards however I think since then it's grown from a design project into an everyday tool that people are actually using on top of their llm projects so I think that part is is uh super cool to see and I'm very excited to watch it develop more I would love to I love to learn more about the executed tree that you're building so it's like you just went over it very quickly but just I remember that we had our first goal and I should talk us through it and it was like super exciting so can you talk a little bit more about what you're actually doing there like at the core of GPT index definitely I mean again I think I just want to emphasize that that started off as a design project and you know it's it's one of those things where I kind of just um made it up into something that I thought was pretty cool uh I think you know these days practically speaking there is a bit of limitations practically in terms of actually using a tree on top of large corpses of data however um the uh the the Paradigm that I basically started with was okay so you have this big Corpus of text now what if you basically just hierarchically built a tree over this text so what happens is let's say you take every 10 pieces of text or 10 paragraphs and then you build a summary over every 10 paragraphs then you build the next uh set of parent nodes on top of this then you build a next set of summaries over these uh summaries that you just built and then you kind of build the tree all the way until you have a set of root notes right and to me this is one way of uh almost like information compression such that you basically build some sort of data structure that you can then use with gbt afterwards and so you know when gbt wants to look up a piece of information it can start from the top and then go down this tree to actually find the information that it wants um and you know if you uh The Way We Built This was quite naive and simple it was just you know aggregating every 10 Trunks and building this like hierarchical tree over it you could imagine this generalizing to graph structures which are actually a GPT index supports through kind of more sophisticated means now and basically building a Knowledge Graph over your data and using this knowledge graph and leveraging this knowledge graph to actually feed into LGBT so uh the way the tree index started was again just building hierarchy over a set of text uh and then when you actually want to send in a prompt or query you can start from the top and then of the tree and then go down until you actually find the pieces of information that you want these days you know I think the thing that works the best actually probably isn't the trivia next though you know it was a cool thought experiment and we do use parts of that and you see parts of that live on through other pieces of the tool these days the most basic thing that people start with is uh you uh take in the Corpus of documents uh split it up uh you know embed each trunk and then throw it in a vector store right so like weeviate or you know another Vector store and then during uh query time you just retrieve uh top k um uh you know documents or chunks by embedding similarity and put it into the prompt and so this is a bill has a bit less structure than for instance something like the tree index or a Knowledge Graph it actually works surprisingly well for probably I would say like 40 50 of use cases right for of like basic queries um but I think this uh idea of the tree index which then generalized into this idea of like defining a composability and knowledge graph of your data is now uh quite uh uh has the potential to to allow you to Define more complex structures of your data as opposed to just kind of random you know um like just fetching different chunks of the room batting lookup yeah so so maybe I I'm still kind of wrapping my head around the knowledge graphic extension as well as this whole kind of top level index thing so let's say I have podcast Clips is like the example that I've been using to think through these things so if I I aggregate say five at a time to form a summary and then from there I'm going to summarize those to like summarize the next thing so when I'm searching through this index in my first searching so I say I'm trying to find just a conversation segment do I first search through all the summaries then I search through these intermediate summaries like can you kind of take me through like how the search works through the top level index yeah so um there's a few points here uh that I I do want to address um taking a step back just really quick you know the the gbt index is always evolving as a tool and going back to the high level Vision it really is about building this interface and thinking about what exactly is a best interface and the set of tools that we can give users to you know build some structure over their data to solve their tasks and so so a lot of the tools that you see with LGBT index today are manifestations of that so stuff like you know we offer Integrations with Vector stores we offer the ability to Define graphs on top of your data it's possible as these models evolve and you know as considerations come in for instance stuff like latency and cost these structures will also involve so to take what I'm saying right now with like a slight grain of salt in that I think we're sold very much optimizing towards okay what exactly is this like best structure of data that accounts for again latency costs and performance and that solves a broad range of different use cases from you know customers and Enterprises so with that said you know one of the things that we we thought about in the beginning was to um uh and and this is something that we've heard from users of GPA indexes you know uh uh it it's um it's hard to kind of feed like high level context into uh into for instance like a text trunk for uh as an example so when you take in a document and if you just naively you know split it up uh and and now within each tax dunk you kind of lose some information about what the entire document is about so going back to an example of say like a book you know if a book is divided into different chapters um or actually maybe a better example is like a research paper uh research paper is divided into different sections like intro related work methodology and then within each section you know you're going to have subsections describing different components of each section now if you split this entire text up into different trucks and let's say you just have like section 2B and some random slice of that you're gonna not really have information about how this relates to the rest of the paper so one pain point that this idea of defining a graph over your data can solve is that you can kind of like hierarchically build uh or you you kind of have this like hierarchy of context both like very fine grain context and then also kind of like higher up context with the summary and so one thing one use case that GP index with these graphs allow you to do is let's say you do say build an index for every subsection of your of your paper and then then you build an index for every section like so you set a summary for every you know intro uh like related work methodology and then now when you actually query this you know kind of parent top level index it can both retrieve specific sections um of text that are relevant to your query but also refine it with with higher level contacts and this happens because you're able to define a sort of graph over your data another use case of this is um you know again what is the final graph of your data me and at least interview BC Index right now it basically just means you can Define like indices on top of other indices and so another use case that this could uh this could solve is let's say you define a sub index for every data source so let's say you have a collection of uh call transcripts in gong and then you have a collection of notes in notion right and let's say maybe you have some conversations in slack now when you want to um like uh uh ask a question let's say you explicitly want to want to synthesize and answer across all three data sources now what you can do is you ask this question and you define a sub index for each one of these data sources and then you define this like higher level index at the top level and now when you ask a question we just route this question to all three of these data sources and then we combine them with this top level index for instance using uh one thing that GPT index offers is like a list index data structure which is synthesize and answer across every single uh node in its structure so so basically this allows you to just combine information from all these different sources into one response so it's it's quite an interesting thing you know like I um I I uh I think people are still experimenting with different use cases of uh such a structure this idea of a Knowledge Graph but the idea of just like being able to Define some sort of like hierarchies uh over your data has proven to uh sometimes yield better results depending on your use case very interesting I I have a question about like a term that you that you keep mentioning you keep using the term Knowledge Graph and I find it interesting because it has that has kind of a it's of course already also kind of an older term if you will was also very much related to the to the semantic web and I think that if we talk about knowledge graphs today um uh or like the traditional way of talking about a Knowledge Graph was mostly also related to just you know just having notes in your graph and then and then just having just you know fixed relations between them maybe like using Sparkle or those kind of things one thing that I find interesting and and in in uh in in wifi8 we also support like simple route structures right so you can just make cross-references and sometimes I also use the term Knowledge Graph to talk about this right that is like it seems that there's like a change happening where these the notes in the uh in the graph are not just on a 2d plane right so just like a graph and then relates to another one but then we actually placing these notes into the hyperspace that these models give us through these embeds right so the question I think I have a little bit speculative but could it be the case that the um sorry that um for example GPT index or in combination with like a effect store like with it could be like a new Revival of the of the knowledge graph like the knowledge graph 2.0 or would I be too ambitious uh if I would say those kind of things curse what you think about that conceptually that absolutely could be the case I think there are a few practical uh limitations and challenges that we would have to solve to make this work um but there are already components that you can kind of see within GBC index and you could totally integrate with the back end store like uh we did so um there's um the part that GBC index supports right now is given you know a user-defined graph uh let's say they construct it within GP index tools uh we can then you know um uh kind of perform operations over this graph right we can then route like perform have a query and Route it through the knowledge graph to get to the right information that it needs to answer this this query um there's also this separate component of Knowledge Graph construction right which like uh right now uh you you uh users uh have to build a little bit manually um on on top of their data at least with NGP index and you know I think it's also a very interesting question to think hey like you know what uh are ways to basically um infer a Knowledge Graph right from unstructured data uh and and you know like maybe we can generalize Beyond this idea of like a Knowledge Graph just uh going back to the mission statement of GPT index is like what is the best structure over your data that we can infer um you know most of the world right now or at least in terms of data and fraud lives on structured data right and then now of course there's a lot of uh stuff taking off around like unstructured uh data paired with Vector stores and then there's this idea of knowledge graphs and so figuring out you know how to extract for instance like entities from this data either in a structure format and a graph format or as like raw instructor text I think these are all very interesting questions think about and you could totally use gbt to uh to uh you know at least in the ideal state to automate a lot of this ingression and transformation and so I think that is absolutely something that you know especially as these models improve like gbt index would want uh want to be at the Forefront of uh so I think so I think like there there are really these um two components and and uh right now one thing that gbt index does is it allows people to uh Define uh you know graphs uh on their own on top of their data and be able to you know route queries through through these structures but I think you know the the line of work that we're very excited about improving is how can you infer different types of structures one thing that gbt index does offer right now is we can allow you to pass in your unstructured data and we can actually um infer structured data points from that and put it in for instance like a SQL database um one line of work that we do want to do is do a bit more in terms of thinking about how to best address and store unstructured data in different formats uh outside of just like naive text trunking for instance right and so one uh feature that users have asked for is oh how can I inject like Global metadata into each structure text trunk to preserve some sort of global context I have a quick question about it because I find it so intriguing so so so so so so Conor and I we we did a little bit of research also with the with the we were looking at like creating feedback loops also with um um with the database right so that you have a query that goes into ev8 and then what we currently do with the generative Parts actually goes into ev8 and then you get like your candidates and then you bump that through like or pipe the sub pump through a generative uh um model and then you can do you can give it a prompt right you can give the task and what we were playing around with was that we were saying like um you know can we also ask the model for example like to just do another query in vv8 and as part of the prompt we basically said like we want you to populate this Json object right with this key and this action and to my surprise I was just yeah maybe I don't know I was just flabbergasted that it actually did that but it it yeah you remember that we worked on a counter that it presented the results as a Json object and they were like but that's amazing because then we can really have like more functional uh do more functional things with with the model so the reason I'm bringing this up is I would love to learn you said something so interesting about like uh how you're looking at having the llm help in creating the structure would it be something similar as that I just mentioned or is it something completely different oh 100 I mean I think that would uh I I um it's actually a pretty interesting uh way to to try to uh get llamson for uh different types of data um the use case at gbt index does right now is it infrastructure data from unstructured data um I have seen uh uh people play around with different tools I'm sure you've seen this too where you know you just ask your PT that hey just like store context within the prompt itself and then just give me back like another Json object also in the prompt um and so you just see in the prompt you just feed in like your entire like Json object and then and then it'll give give you back a new Json object for instance um I think uh yeah I think I think these are something things are we're experimenting with I think there's probably like a few limitations to for instance just like storing context and state within the prompt entirely just because again due to like token size limitations but if you can somehow again maintain some sort of structure and then have gbt index be able to both read the structure and be able to know how to update this structure uh you know and this structure is maybe stored outside of the prompt itself uh in some format that but then you can feed parts of it into the pump then that that part is very interesting to um to think about because I think um yeah like imagine you maintain this Json structure but then you were able to feed parts of this into gbt index so uh still a beta token size limitation but it provides uh gbt enough context to help update and insert new elements into this overall structure I think that's going to be really interesting um there's also stuff around for instance like Knowledge Graph inference which you know like imagine um you know given this content you can extract like entities from this content and then you can then in for relationships between the entities and now you know I like um there's this cool project called like graph3pt where I think uh it was this you know front-end visualization and they had this like a nice front end but uh what they did was they basically you know took in this user query and then uh basically directly asked gbt to infer the structure uh directly within the prompt so like it kind of like given the output it should infer all the relationships within the data that you you feed it I think that's also something I've kind of been interested in for GTA index but maybe extending that to also storing the structure Outside The Prompt itself and then you know given some unstructured data like start building up some knowledge graph over your entities within the structure that you can then you know query over with with gbt index uh so you know lots of very interesting things around not just like the query side of things using olives but also actually how to construct these types of structures using hpvd as well yeah well when I when I think of Knowledge Graph I also think of this like um you know like Conor lives in Boston you know works at weviate like that kind of structure where it's you the the data structure is to collapse the entities into the single thing it's made me think about like um so if I have like coming back to the podcast clip example I might extract the entities and then use that to go get the facts and then add that to the prompt that kind of thinking is is it yeah is what it is inspired me but I kind of if I could come back to something else you were saying about the integration of different data sources like slack uh the calls these kind of things and it makes me think that like so in weviate usually the thinking is we would divide these up into different classes and so then just the atomic units each of them lives in their own Vector index like based on the this is the slack Vector Index right so so are you taking all the atomic units of all the different data sources and putting them all in one kind of vector index and then you build up the hierarchy from that kit like how does the kind of chunking of atomic units in index construction happen uh yeah that's a good question I think you know it makes sense to me for all these different data sources to be stored in different uh structures uh so uh for instance if there are different weeviate tables or just like different you know indices um I think what we would do is we'd probably want to maintain that structure so we don't want to like you know collapse all the data into one table uh on on our end but what we'd probably want to do is let's say you have use cases where you do want to for instance like synthesize a response across all three different data sources or you want to route a query to the best set of data sources that can answer your question we want to you know treat for instance these data sources and we V8 as three different sub-indices and then allow you to build some index structure on top to actually solve your use case whether it's summarization or uh routing for question answering so then that routing that's um that's the the llm tool use where you tell it hey you have you know slight conversations blog posts right oh kind of yeah so so there's different ways you can you can think about this one is you can directly do this within GPS index itself it's actually part of the graph so just imagine like a parent uh node that's um you know at the top of the graph and then each trial node is like your different data source so you have like three trial nodes one slack one is an ocean one is you know uh gong or Salesforce and then you can have a parent node at the top that acts as a router so then you can actually you know given a query like pick and choose which of these uh trial nodes is most relevant to your query um you can also actually integrate this with kind of multi-step agent behaviors and you know for instance like Lane train has an agent abstraction where you can actually act in some sort of multi-step Manner and can choose between different tools um then you know you can also have these different uh sub indices B tools that this agent can choose from so part of it is just dependent on which abstraction layer you want to build at um if you do want to kind of wrap this into entire thing around a GPT index like data structure you could to solve your use case yeah so yes I think the whole the agent thing is a whole conversation like because I don't want to get too off of just kind of understanding the sub indices and all that but maybe if we could come into just the tool used the external apis and all of how that's integrated with GPD index yeah so sorry just like clarified do you mean like the line training tools or do you mean yes I think kind of I've been so I'm so sorry for the slower so I'm still trying to like process the understanding of the um the sub indices and all that but so I think in addition to the sub indices which is like a data structure there's also like the tool used am I correct in thinking that these are two separate things like the the llm tool use and then sort of using GPT to create these indices or those like you see those as separate yeah so um I can try to help clarify it uh that's a little bit more at a high level um I know uh the way I described it was probably a little bit complicated um but basically in in my mind um imagine GBC index like a data structure like quote unquote you know we we have that term um just imagine that as a interface to your data and so the like imagine that entire thing as a black box right so you you've given some question and at the end of the day you want to define a structure so that you get back the response that you want right that's that's kind of everything within that box is that data structure that we uh allow you to uh allow you to create so um if we just operate purely within the the tooling of gbt index um going back to that example of having for instance like sub indices what I mean is let's say you define like a separate index data structure for you know all your notion uh notes and then also your slack conversations all right now what you can do is you can actually Define say like a top level uh data structure over these um uh you know sub indices or individual data sources uh and this top level data structure can take on different forms um it could act you know as it could be like a list index which is like a summarizer basically it can you know um uh it'll route the query to each individual data source but then combine all the responses into one response it can act as a router where it actually picks like a subset of these uh sub indices to actually dive into and then in the end it'll synthesize a response from the sub indices but basically just imagine say you know you have some parent node as a graph and it can route it to some you know data structures as sub indices if you will and so if you choose to you could wrap this entire graph including the parent node and the trial nodes into one Gypsy index data structure that you can then you know say query for uh summarization or as a query for question answering and then we'll route the queries underneath the hood right based on your graph to actually synthesize the response that you want hopefully that that makes a little bit of sense but the idea is that you can kind of allow users to Define some graph quote-unquote structure of your data to um kind of you know Define uh hierarchies to solve the tasks that you want and at the end of the day it's just allowing you to be able to query over some data and then you're able to get back the response that you would want um the Integrations with other tools for instance like Line train is a separate component of this so for instance like um one thing that you a lot of users are trying to do is let's say you define an index structure over your data let's say you know you define just a simple Vector store base index over your notion notes or your slack conversations and but let's say you're building a chat bot right and you want to use like Link train to do that so you can build a light train tripod which will maintain your conversation history and this agent will also try to look up or try to use different types of tools uh in its repertoire to actually perform different actions or perform lookups so you can actually add these indices as tools within um you know kind of like the set of tools that Adrian can use so that uh with this subtraction every time the agent is trying to reason about a step they can choose a tool that will help it perform you know uh uh that that's like the best tool suited to to perform the action that's requested of it and this cool tool could be a gbt index uh data structure right and again going back to the fundamental interface what you can see indexes you can pass in that query right some request and you'll get back some something out of it and the this tool could uh like this GPT index data structure could be arbitrarily complicated it could be very simple like just a vector store index or it could be an entire graph structure underneath but an agent can choose to you know um basically use this as a tool to get back the response as it needs at a high level you can basically think of this as you know um one thing that like the agents do really well is that they can do multi-step reasoning um but you can treat GPT index as one step right of this multi-step reasoning to achieve uh retrieve the information that you would want interesting I I so while you were talking about this I I have a quick follow-up question related to that because the um it for me making like these these three structures that that makes a lot of sense to me it's also I find it super intriguing in in how you how you uh um uh how you you know walk down the tree basically to find the answers I I have two questions about that so one is like let's say that I have like a large document because actually this is something I don't know let's say I don't know like really large like 100 Pages something right or like 100 paragraphs that's maybe easier how what what does the how much insurance is it doing on the model to find the the answer and how much time would it take just to produce an answer so how often are we talking to the model how often is GP index able to know where it needs to Traverse to what's what's what are we talking about here yeah so um no it's a good question and I think uh again uh this probably warrants like a broader discussion about some of the trade-offs you make when defining these graph structures especially with the current state of uh GPT um imagine every node of uh whatever graph that you define right if it's a tree structure let's say you know you have two levels like a para node and trial node every node is going to require some llm call maybe two right to to gbt now um you know there is uh some sort of like practical like cost and latency trade-off that you're gonna have to think about when you actually Define these complicated graphs over your data because I think conceptual it's very interesting it makes a lot of sense but every call to gbt is going to take around like you know two to three seconds if you just give it like uh you know three thousand four thousand tokens right and it's going to incur a marginal cost as well so there are just some practical constraints in making this graph overly complicated because the more nodes that you add and the more nodes that attribute index has to Traverse the more alaline calls there are going to be and then you know the the kind of longer and have to wait for your response um so I I think you know for a lot of tree structures uh practically speaking what uh has worked well or just a slightly more shallow structures so a vector store a base lookup actually makes a decent amount of sense um because actually it for an embedding based query you don't really need to call the L one at all right you just do a DOT product and then the only calls you need to make are to the embedding model during construction and then maybe a call to the language model finally if you want to like synthesize and answer right from the set of nodes that you retrieved through embedding lookup so embedding lookups can can be a pretty practical like uh cheaper alternative to that um but I think yeah generally speaking you know hopefully as these models get better and the costs and latency does come down this notion of repeatedly querying or recursively querying the llm for more information has already proven to be pretty useful in a lot of cases like if you think about just like you know Chain of Thought prompting react quote traversing through knowledge graphs it's evaluation it's all very interesting but that stuff will be more possible once we solve some of the Practical constraints yeah and I'm actually this is so interesting because this goes back to the thing we we just discussed um uh about that we're looking at how can we use basically the llm to just also feed data back into into V8 and what I like so much about Jeep index is that that you support like these graph connections so it something that I'm super interested in in like also further figuring out is that rather than just having this combination of GPT index and then view it as a vector store that storing these connections as well uh so basically that if you if you if you do the query like for the first time you know it needs to go to the model needs to figure it out but it can not only store for example the embeddings but also the um the graph connections that it's making that is something that I'm I'm super excited about because I would not be surprised that this year we're gonna see this trend of yeah for the the term that I'm now using is just creating a feedback loop back into the database using using tools like for example GPT index and I find that super interesting I'm I'm I would not be surprised if we see some prototypes in the in the near future exactly doing that because then you could even say like hey um uh um you know Jeep DNS I want you to figure something out for me I'll be back tomorrow you know and I'll just it starts to Traverse it starts through the lookups it starts to add stuff to the database and then the next day you see all these graph connections and relations in the database and now you can fast and quickly Traverse over it I I find this very intriguing it's it's super interesting super interesting I find it very interesting too I mean I think um if once these part of this is a bet that these models will get better or faster and cheaper and then you can start using it to really automate some of your uh more of your kind of like data ingestion and transformation pipelines and reduces the human workload on really thinking about okay what is the best structure of your over your data right because a lot of data engineering once this does get better to some degree quality well uh uh I can't kind of hopefully try uh be solved somewhat by by being able to um uh infer a lot of these relationships uh automatically uh right as opposed to manual definition I think um yeah I'm I'm very excited to see where this goes um I think they're they're uh uh like just a kind of like with a grain of salt there are some practical considerations just because you know um it is I think important to Define some uh performance bar right over like what is the acceptable level of quality that you're looking for like for instance if you're data and dress pipeline using GPT is actually you know making mistakes like 10 of the time like that might be too high right and and then the question is thinking about how can you think about some interface where you know maybe it's not automating all of it there's still some like human feedback in the loop but it's automating like a good chunk of it right and and and then it can actually help Empower and speed up like users workflows and actually building out some of these pipelines so uh a similar analogy to this is you know why for instance something like copilot or notion AI are popular because they allow for mistakes uh made uh by the model right and so you do want to probably put this as some interface where you can still allow the model to make some mistakes because you know the model is great but it's not perfect it makes a lot of mistakes uh and and so um how can you make sure that the errors don't propagate and that you can kind of correct errors right now I think that's a gonna be an interesting interface to think about and probably something I'm thinking about for for GPC index as well and the hope is as these models get better you're going to have to do a little bit less of that yeah I have one more follow-up question about that because it's so interesting so if we if we switch gears a little bit from you working on GPT index more as likely you know the the the the the project you also need to design it right so you're designing like the the interface how people interact with it um what so what kind of things are you taking considerations for those who want to use stupid index really to to build like production social right so are you are you taking it into consideration right now or like no no I'm just parking that that's just you know first things first and then do that later or I would love to learn how you how are you thinking about that um I think I think um uh I'm somewhat parking that and the reason is because I haven't dove into the uh full brainstorming about how to really solve like uh how to automate like data ingestion and transformation I imagine once I really start thinking about that then the notion of you know how to evaluate performance and how do I uh correct errors those types of things would become more important I find that for the basic use case that a lot of people are using right now for GT index because the construction of the index is still kind of manually determined by the user uh a lot of the end use cases are for instance for like summarization and search and for a lot of the current use cases uh it's actually okay to make some errors right like you know your people use like recommendation models ml models and search all the time and you know uh part of the appeal right now is you can actually just do search and build that type of tool a lot faster with something like ubt very interesting very cool and for those listening to this podcast who are responsible for building and serving these models you all know what to do you know we need some we need some speed yeah I had one question I want to jump in on the correcting the errors um so one thing that I've been thinking about is like with the cost like you you might instead of using DaVinci 3 you might use like Ada or something to have like because it's cheaper and then you can sample like 100 outputs and then re-rank them with these ranking models uh so so what do you think about that kind of idea where you use a lower capacity gbt but then you generate a ton of outputs and then filter re-rank the outputs yeah I mean I think there uh there's a lot of approaches to dealing with that right now um I haven't uh been able to explore this fully but I think that um at a high level the idea of say building some optimization layer that can have a reliable estimate of performance uh uh but also give you you know like uh predict the the cost and uh that satisfies your compute Budget Building the optimization layer is absolutely something I want to start working on and so whether or not that includes for instance using like cheaper models and stacking it with like uh better models right uh or whether that's a notion of just like how do I try the best to like evaluate latency and how do I speed that up right with respect to for instance like async operations or um or other techniques those are all in consideration for this idea of optimization because I think right now there's like a lot of there's like a grab bag of different techniques that people can use to try to uh like both make things a little bit cheaper and also a little bit faster um ideally what I'd want to do is provide an interface and make that as accessible as possible and also adopt a lot as these models get better because uh you know that is some of these techniques might become out of date as these models get better like uh a class I mean one of the examples is is the open AI embedding like before like open air release like tax and betting data uh right like zero zero two uh like it was just infusible to actually use open AI embeddings like I I ran up a 20 Bill going through like uh like two or three documents uh and then all of a sudden with these embeddings are like 99.98 cheaper it's just a lot more feasible to use this to index a lot of documents so I think um we do want to make this uh provide some general tooling to to help people decide between cost and latency and we also want to adapt this tool to Future advances how much are you are you connected to to gbt models right because it's in the name right it's a DVD index but uh you know you you know a lot is happening there so is that just uh it are you are you like you know married to gbt models or are you just open to also explore other things you know Bob that's actually a great question because you know I'm going to use this opportunity to say that we are actually going to undergo a name change uh probably you know within the next few weeks it'll be gradual you know we'll support some sort of backwards compatibility with this package of GPT index um that everyone's familiar with um but uh yeah so we are very much um uh trying to trying to I mean the tool itself is already General but we're trying to also position it as more General um uh already like you know GPT Index right now supports different lens besides just open AI models itself right you can plug in um basically any sort of llm from plugging face cohero 21 other model providers and you can also plug in different types of them adding models as well we do want to be a general tooling layer on top of like different uh llms right as opposed to being tied to a specific service also you know changing the name and and more General will help us avoid some trademark issues so uh very excited to start uh kind of keeping you posted on some updates for this so so are you are you going to keep us waiting or can you already share what the name will be you know I um I we I will give you a hint in that we released a llama Hub about two days ago or yesterday and we like llama as a prefix and I think that's what I'll say there okay okay that's that's fine that's fine that's that's we can work with that thanks for sharing yeah that's great because llm it's too like you know there's no vowels in the middle of it no exactly yeah I I love the name I think that'd be a great thing if we could talk a little more about llama Hub uh so I had a quick look at it it's like a hub for external data sources tell me more about it yeah exactly so um maybe to frame this a little bit better you know part of GBC Index right now is the way you can Define complex relationships over your data but really the higher level mission is again to Define this best interface of your data right and one thing that we've been noticing especially as people have been starting to use GPC index is that it has this entire um pipeline has a potential to kind of alter the data analytics landscape like if you think about just the amount of work it takes to address data right and the data engineering pipelines in place to address transform you know store data and then you know transfer transform those into insights that you get to the end user there's like multiple companies and you know billions of dollars within each of these components right so within like five lines of code within GPT Index right now right you can basically build a Search bot you can address your PDFs right convert it into some text and the beauty about gbt is that you don't have to make that text super structured you just need to provide some information about it and then the worries that you have are more about like text trunking and how to actually provide this information and then you store it you know in some format whether you know it's uh alleviate uh or or some more structured database and then you just ask gbt to for to answer questions right and then GPT can handle know translation to SQL or just directly using the the raw question to answer answer um your query so there's just a lot of kind of interesting things happening around this idea that I think um if once llms do take off this entire pipeline will be able to change uh and and actually become kind of like a lot simpler and and just uh more automated and one of the key components at the beginning of this is this idea of data ingression right and so um I think one thing that's been really cool a really cool component of GT index so far is we've seen users submit a lot of community built data loaders uh from PDFs so for instance uh HTML documents to PowerPoints um to web pages and apis with pretty much a lot of the popular Integrations like Notions slack Discord uh we have a GitHub integration coming soon as well and it it's really the thing is it's actually not super hard for users to add these Integrations because you know what they have to be worried about is just not like doing all the ETL into a structured database they just call or connect to this API and they provide the information as raw text maybe with some annotations on top right and then the question is just okay now how can you feed this into something like 3pt index but can which can address this raw text and do Tech splitting and and you know store it into an index data structure sorry yeah so if you look at the um if you look at the at the uh the the sulfur stick right so where you have the user on top and then core infrastructure on at the bottom right so and so you have the whole stack and then for example so so we've hit is a bit lower because it's like a database and then GP Linux a little bit above that closer to the to the user do you think that GPT index would evolve also more like up the stack so because I was very intrigued what you said about like also all these these data loaders that people are introducing um that is interesting because that would allow you to have like this whole you know uh um you know Marketplace basically of data loaders um or are you more interested in moving down the stack how do you see that develop uh it's a good question I I don't really see myself or Jupiter next moving um down the stack anymore right uh at least at the current moment because you know like we V8 knows you guys know how to create like scalable like high performance like databases right and and uh part of gbt indexes appeal is actually just being able to integrate with uh for instance you guys to actually uh help users build an app right for uh uh on top of their data um I could see us expanding both horizontally and and maybe a little bit uh kind of up the stack as well I think data ingression is one of those pieces that um very much is that fits within this philosophy because you know we we build this Marketplace um or this community it's not really a Marketplace but like a Community Driven Hub of uh people trying to submit and then you know just submitting um different types of parsers and loaders for different different types of applications we can try to have them use GPT index with this data loader or you know you can actually use this with Lane train as well and what it actually does a few things one is you know we provide the central platform for them to then address this data then you know what whatever the storage and kind of like um uh of this data is it could you know very well be weeviate and then um the other component of this is that by kind of um creating this community of data loaders we can help almost like educate users on the value of outlands because because now you know you can actually have people thinking hey like it's not like I only need to just feed in my text notes right it actually turns out like with Technologies like not even just a gbt or llms like by combining stuff like whisper or like image captioning models or any sort of you know uh models that basically convert unstructured data into text we can actually build this end-to-end application starting from this very unstructured data into something that you can actually translate into insights so I think that that is uh very much something that is part of our vision and I think the first part of that is super important as well yeah well I I think um well I think that's a good coverage of the topic so if there's anything else you guys want to add I I mean you shouldn't offer that because I can keep talking for two more hours about this so it's like this is just too exciting stuff man too exciting yeah well maybe I I want to throw this in quickly before we wrap it up is um like how about the extension from text images and multimodal I just love this topic because I think we're yeah so we saw the diffusion models and I think a lot of us predict that you know we're headed towards this boom and and uh image uh image audio video 3D images all that yeah 100 I mean I think um I'm still kind of trying to brainstorm use cases let's say for text to image like what that would look like and you know this is just me spitballing off the top of my head is it like oh you want to be able to reference like a corporates of existing data that's also images that you could generate a new image is that that you want to be able to reference a corpus of text description so you can generate a new image I'm definitely open to the possibility um at least in terms of including some components of that I will say though in terms of like storage or or converting from like say images and audio to text that's actually part of this idea of llama Hub and actually something that we we want to push for imagine if you can just you know take in some different types of uh data right that are not inherently taxed on their own but you can convert them into a text format that makes it pretty easy to search and look up without doing too much data engineering on your side I think that could be a pretty valuable application yeah it's incredible do you see like maybe even like brain computer interfaces like that kind of data being translated and GPT index going through your brain scans yeah no I mean I think you know a lot of the heavy lifting is done by these models that are are doing these conversions and and we're very excited to keep tabs on the advances like for instance we integrate like open air whisper we open it uh integrate like the donut model which does like uh kind of OCR uh we're very excited to try to include this and now the question is how can we uh you know wrap this in a layer that um makes it both easy for people to build apps on top of it and then two uh make this uh scalable and perform it right because you know some of these models do have GPU and performance instruments yeah and one more as I'm like doing this list what about robotics like uh have you seen the the say can uh like kind of how much these advances in text processing are impacting the robotics generalization as well yeah that's interesting I mean I kind of um came from a world of self-driving research before um uh my current role uh and this is a few years ago and I think so far you know I think it's been um somewhat decoupled like I think you you'd store for instance like image and and lidar data as uh you know uh embeddings on its own you don't really think about like converting it to text uh so I think you know for practical reasons there's probably ways to just like store different types of data in their own formats um but if you know we start to see these models become just again faster cheaper and better like I could see text being a bit more Universal of the interface for storage and then and then you know then if you're filled a bunch of applications on office yeah incredible well Jerry and Bob thank you so much for coming on the weba podcast and for having this discussion I saw Bob recently shared a meme where it's uh Patrick from SpongeBob his head is exploding and that's that's how I felt this whole time and I think this is just such an information heavy uh podcast I think this sub index tool use this routing thing is just one of the most exciting emerging Technologies and we're so grateful to have you on the podcast so thank you so much yeah fantastic thank you amazing thanks a lot and thanks Connor ", "type": "Video", "name": "GPT Index and Weaviate with Jerry Liu and Bob van Luijt - Weaviate Podcast #37", "path": "", "link": "https://www.youtube.com/watch?v=jbQ2UbnU7vQ", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}