{"text": "You can now use Weaviate as the document store for DocumentArray in Jina AI. We had the pleasure to talk with their CEO Han ... \nhey everyone thank you so much for checking out the 11th episode of the we va podcast today i'm joined with han xiao the ceo of gina ai gina ai is such an exciting end-to-end search pipeline software and so i'm really excited to be talking to han and learning more about this so to kick things off han thank you so much for coming on the podcast and could you tell us a bit about what gene is about hey connor thanks for having me and really glad to talk to you and also to the vivian community and uh yes sir my name is han i'm the founder and ceo of gina ai and so gina ai is a very new company we founded in february in 2020 during pandemic and over the last year we have been building the new research our pipelines the food stack solution uh including uh the framework itself but also including the data structure the fine tuning uh and also the uh kind of marketplace online right so that's that's right now so right now we have 45 people of the world our headquarter is based is in berlin and right now i'm sitting in my burning office enjoying the ringing day here and uh you know complaining about the weather and you know making pull requests right so that's that's kind of my daily work yeah i love learning about gina seeing uh the gina hub thing i thought was really cool the fine tuner the doc array the document executor flow and i'm really excited to get into all these things but quickly could you take me into what inspired your interest to work on uh say vector search and deep learning for search and these kind of applications yes yes for sure uh so actually my let's say my experience with new research uh back in the days we call it a neural information retrieval starting from 2017 so when i worked at talento a german company which is a pretty big online fashion retailer it's like a mini amazon uh but not so many it's already one of the top 30 companies in germany uh you know but back in the days it was not so big right so i was working there uh and working on the especially at work for the recommendation team working inside the recommendation team and later i worked i built up the searched uh you know the search system uh uh behind talento right and then uh when we work at when we build this search system in thailand because it's a more fashion related you know you will see a lot of pictures patterns some addresses uh on shirts and so on you see people looking for you know a very detailed patterns uh on their on their dresses right so let's say t-shirt with uh with some slo with some slogan always certain logo i was a superman on it but back in the days you know we have uh we have uh for each article back in the database we put some text you know manually put some tasks to describe okay so what is this tag what is this article is about is the tag could be uh like a visual based or it could be like uh i say this this uh this shirt is made of cartoon it's made of a silk or whatever this kind of things right uh it can be also like a price tag a brand tag sometimes the tasks can only uh can also contains typo so i i remember very clearly that uh when i brought the article to catalog of the articles i see there are intentionally a lot of typos inside the tag i asked the people why are they doing that and then the answer is because people search for those typos and then they want to heat the tables to the articles they want to connect the typos to articles so that's that was in the days where you know deep learning was not so evolved in the search system and people tried to associate the article with the tags that is misspelled right and and then but the misspelling is one thing misspelling among all the newer search problems is probably one of the smallest things that uh you know that we want to solve the most important as back in the day the most interesting things is about how do you search the uh the pattern like the the superman on the t-shirt on the long-sleeve t-shirt uh a short sleeve t-shirt you know connects these things to the article by using image as a proxy right so that's that's kind of the key problem and then as you can imagine it is uh it's kind of cross modality cross model right so from text to image search but back in thailand it was uh more beyond that the more interesting question is talent although it is a german company is trying to provide service for 18 countries in europe i remember very clearly because we want to support 18 different languages right uh in in across europe and then imagine that you build one text image model and you have to rebuild another model using query query to article this data set and let's say we have a very small country that we operate in very small countries let's say in poland right so there are not so many german fans in poland and then the people you know people don't use hilando there and uh uh so how do we want to build such model uh from from poland their language uh to the article because we don't have this training date right so one way so we're facing very serious uh like this is this kind of code start problem because we lack of training data if we want to if we ever want to build a training model from scratch so back in the day is my goal right my so i later work in thailand research and we try to solve this two problem in one shot right the two problem one is from text to image the second is from multilingual text to image right so try to solve this two problem in one shot and then at the end we come up with a new research pipeline uh let's say back in the days we call it the deep learning retrieval pipeline uh which basically is a very end-to-end solution and try to solve try to combine these two problems in one big deep learning framework of course it's very competition demanding back in the days because there was no birth model and everything has to be used between the rstm and uh people were not very smart enough of confidence enough of using this kind of uh you know attention since back in the day there was no thing as attention on everything rstm either rn or lcm and then especially you want to add multiple layers on top of rcm and then you want to build this rstm cnn it's like a frankenstein you you put the rstmcn together it was terrible model but right in the days you know this kind of terrible model is mainstream right in the market so that was the first start and we i published article about talking about this the frankenstein model uh i think in 2018 uh in january basically summarizing my work back in thailand and that that is the time where i left as helena after three and a half years we worked with this frankenstein model i left orlando and working at a chinese company called tencent it's very big one of the biggest chinese internet company and mostly popular in east asia so back in tencent we have a social app uh called wechat as you can imagine it's like whatsapp but this is like a a mini operating system that inside your phone right because it can you can do a lot of things you can do payment uh you can have a party you can you can try you can buy stock uh inside wechat you can do a lot of you can also play games of course and uh uh so inside reach head we have a lot of we have also our our own kind of like a facebook timeline so it's a mini social uh social social network it is a closed social network it's not like everybody can view so you can only view other people's timeline if you are the friends of the other people right and uh because it is a closed source it's not closer to because it is closed ecosystem then the content that you that you publish there whether it is an image videos audios the content you publish there stays inside this ecosystem so that means you cannot really google it from outside right because google can google uh this uh crawling boat they can not really touch this close a closed system and then we have a very strong need of searching those content how to how to get those content out how to make this content searchable and this contents including the text the audios like the auto snippet where you'll se you you use it you send in the whatsapp right and also the videos uh images and so on right and also stickers emojis so now the requirement back in tencent was how can we build an infrastructure that can search all the kind of data types that we have right uh so tencent actually has this system which is built on top of elasticsearch right so and they they actually they forked a very early version of elasticsearch uh and they they added a lot of plugins on top of that uh i remember back in tension we have seven layers of plugins so the plugins has its own plugins so we have in total seven layers of plugin it is understandable because tencent is super big company and over years you gather like a seven layers on on top of the elastic search and then so basically every plugin focus on very niche particular search use cases and then you know when i joined tencent i look at this another frankenstein you know leaving from one of frankenstein and joining another function and look at this architecture and then i did what every engineer you know would like to do is to first uh distract these things right so first to destroy the scenes and build another new one right so uh and then i bring my knowledge license learner from talento and then try to try to use a completely deep learning mindset and need to restructure to refactor the uh the architecture and then in 2019 we proposed a framework called generic neural elastic search genus which is you can imagine it's like a father of gina today and the idea is really to very radically using containerization microservices idea and wrap every step in the in the search pipeline to to separate every step every step in the search pipeline each one as a own microservice and then connect and then use a container to wrap this microservice and finally connect the dot dots to orchestrate them together right so that's kind of the you know a big shift from back in the days the elastic one is a big monolith program by contention and now we're shifting to a very radical micro service uh architecture right and uh so that was a generic neural elastic search so you can still find this uh github repository online but it's not really maintained the sunset archived already uh but then when i work at tencent i you know i in like working for this project for about one year and then this project gets cancelled for the reason that they want to focus on video search right because back in the days there was a some very intense competition between tencent and tick tock uh basically it's a the company behind uh uh sorry the tick tock is a product and the company behind tick tock is called buy downs right back downs and there was a serious very intensive competition between tencent and buy downs and then you know as a result so the company decided to spend a lot of human resources in the video intelligence right they try to analyze videos do some smart video recommendations all these kind of things so instead of uh doing what genus uh original vision is about the original vision of gina of genus is about building a universal search engine for every kind of data right so whether it's text video sound audio 3d models and so on right so that's that's kind of like a uh disappoint me uh disappoint me a little bit and therefore like uh after seeing through all the how the decisions you know landscape all this open source my my my interest in open source all these kind of things and i decided to leave tens and i started to start this company right in 2020 uh january so that's kind of the back story uh of gina and why i'm working in the new research today well thank you so much that was such a compelling back story and i love that frankenstein analogy i think that really resonated with me is this idea of how we have all these different components of these search pipelines and the seven layers of plug-ins and the background on on your journey i really thought that was such a compelling backstory so thank you so much for that so to kind of transition a little bit and to try to unpack this frankenstein uh could you explain to people what uh what make up these search pipelines what are the key components of them yeah so i i think the uh a lot of people when they first talk about neural search it seems that okay so it's not so it's not so difficult it's just like you you compute cosine distance and that's it right to be honest it is true right but providing that you have a good representation right then you compute cosine distance right if you don't have good representations and you know computing whatever distance is minimized right uh and then so and then there's a bunch of people from machine learning just think that okay so especially right after birth right right in the age of transfer learning that everybody knows that okay representation is a key right so everything can be represented by a vector right so whether it's a vector uh image to vector text vector whatever birth this kind of things right this this concept what actually this concept was not there right back in 2000 or something like that so the only thing that was popular back in the days was word to back which compared to today's this vector model is completely different scene right a globe this kind of thing and right now global is only used for initialization it's like usa and you have final products it's just used as a neutralization right so it's a it's a huge paradigm shift right but back in the days there were two two big things about enabling a good neural search is one is you need to have a good representation so that requires a very strong machine learning model right and then the second step is uh you need to have a good distance a faster retrieval somehow you can compute the distance similarity vector vector by vector vector by matrix and matrix by matrix this kind of similarity computation has to be fast and then uh so basically it's competition and storage right competition and storage uh so maps to today we have the machine learning power and then the database right so this is kind of the big two biggest concept you know that can power that kind of like the two pillars of your search right uh but uh if you zoom in into the pipeline you found that okay so there when you of course these two pillars itself has a lot of lot of you know details demo in the details there are a lot of lot of details to to be implemented right for example in the metric uh in the in the database part you know how do you store those things efficiently right uh how do you uh how do you can you use something else rather than euclidean distance for example okay you know float 60 64 or flow 32 is just too space consuming can i just convert everything into integer or binary and then still compute somehow this distance right or why does the distance must be cosine or euclidean or harming distance can it be some distance that's learned by some models right so there are a lot of things that you can do with with just the database part with just the vector retrieval and then on the on the machine learning part of course like a different modality how to convert image to vector text to vector audio to vector and most importantly how can you connect the image and text right combine the multi modality how can you cross the modality to get a vector representation but apart from that as i said devil in details right so there is a preprocessing steps and a post-processing uh in the neural search pipeline uh for example in the pre-processing step so let's say you have a big picture and this picture big picture contains a lot of very very complicated concepts so there are a lot of objects in that picture right and then i have a search query i have a i want to search for a very simple object which is like a just a single apple this my image my image query my query image is just an apple but then all the image that you have in the database it's very super common it's like a mcdonald's menu right it contains a burger it contains a french fries it contains uh cola all these kind of things every every picture is a mcdonald's menu but then your query image is just apple so you can immediately see that even though you use the same model uh uh for representation the the the vector representation the semantic behind this vector representation is not really uh symmetric right so this brings us to the question like it's so so this brilliant bring makes me think that you know you cannot really expect one single model without any pre-processing just storing some data it will give you some good embedding right so therefore uh a very important step back in tencent is about pre-processing like for example how can we cut how can we segment the image into different chunks a different granularity right in order to get embedding a kind of a hierarchical embedding right on the very uh you know on the very top layer you have the overall bird view of how you know kind of a birdview embedding and then you can segment it all the way to the bottom you get a very fine-grained granularity this kind of embedding to describe each object right so in the end one document whether it is an image or text or a chapter of of book will end up with not only one embedding but a lot of embeddings right a group of embedded then how do you match your query which could be also a group of emails to another group of embeddings right so this is not simple cosine similarity and then you can imagine that when we put the problem into this setup the database is just a two it's a very atomic operations to enable such retrieval but that is not enough pre-processing is important to get the graph to get the correct granularity uh to get the group so get the correct group of embeddings and but also the post-processing is also important you have to aggregate the group of embedding scores the scores from different groups from different hierarchies you know to into the final result right so this is a this is just one simple example you know when it comes to the image search and then you can imagine in the video search where you you have a video input video of like 45 minutes uh and then your search query your query video is just like one or two seconds or it could be like just a short video like what you see what you agreed on uh tick tock so that then you need a preprocessing step such as segmenting by shots right and then combining the frames into shots and shortening the frames all these kind of heuristics in order to get a good search quality you cannot expect that i threw a two or three seconds video into the embedding model and then 45 minutes video into into the same embedding model and the result uh embedding would be somehow comparable right so that's that's that's why you know in gina we focus on the full stack on the end to end experience our final search quality not really on the computation part not really on the database part but on the fine on the full stack uh you know experience of your search all right so another great uh great cluster of information i learned a lot from that and i really like um just coming back to the beginning of what you said with uh with the computation the storage and in we've eight we've explored things like the h sw vector index for having the centroids to speed up the search and we've explored binary passage retrieval for having the binary representations of vectors so the two things that we've seen a lot with the vva side on the vector database storage and so i i thought that pre-processing thing was so interesting that added a lot a lot to my knowledge and so is this talking about using say object detection models or semantic segmentation models to to separate the objects and then you have embedded so say you classify uh this is the basketball in the image and do you then have an embedding for that basketball window and then can you tell me a little bit more about then how these embeddings are you mentioned it's hierarchically aggregated give me a little more detail about how you assemble these embeddings yeah so i i think see i think you're definitely right so this is a the rough idea is about you know decoupling con you know divide and conquer right divide and conquer and finally you assemble all the scores together but when it comes to applications how do you ensemble them like you usually want to put some weight you you don't want to just sum up everything together you want to somehow put waste on the on the bottom layer and then bubble this up to the top link right but bubbles is up to the to the to the original document which is a the thing that you want to search for right uh so uh so the installing strategy is actually highly correlated with your and application right so let's say if i'm doing to document search i just want to look for reference right i just want to uh copy paste a paragraph abstract into my search engine i want to look for the you know what what are the other academic papers you know have the same idea right i want to search for this then you can see the query the granularity of the query it's probably one or two sentences but then the search result is a full document right so they are on different granularity so the assembling procedure will probably go you know all the way to the top to get to the full the full information of the food document right in order to before it returns to user another thing is you still have the same thing you still input one or two sentences but it's about describing a problem so let's say in the long document qa right you ask a question about this long document and then it returns some answers right and then in this case the answer the return results it's just a one or two sentences or sometimes it's just just a token right one or two tokens right then you see the granularity is somehow you know it's even smaller than your input granularity so the the final pre the pre-processing procedure the pre-processing step and the incentive step highly depends on how do you want to what is your application is about but in the middle there are probably some reusable building blocks that you can use it regardless of the application and that's actually inspired us to do gina hub right for example for the two examples i talked about giving abstract searching for academic papers and asking a question about academic papers highlighting the result these two applications share the same natural language embedding model they can share the same language language embedding model even though their final usage appearing would be would be completely different a user interaction would be also become a completely different one could be just the traditional search box and the other could be just a qa chatbot right and uh so in this case you know as i said it's highly depends on your final application but but that also means you know although it depends on application but as a framework as something like we are we call ourselves a framework company or infrastructure company as a framework we want to get ready for that we want to make sure that user once user has this need has this idea of you know breaking down into different granularity and then combining this up once they have this idea they can implement such ideas under gina right so that's that's kind of if you zoom in to dock array and go to docker array website documentation website you can see that the docu document which is uh like a primitive data type in in gina in dark array are like in gina ecosystem it's actually nested and hierarchic it's recursive right so the document can sub document and subdocument can contains its own sub document not only on the vertical direction it is recursive but it's also on the horizontal direction so that means a document kind of has its own nearest neighbors a soft document that can have all can also has its own nearest neighbors so you can imagine this is becomes a tree right so it's kind of a recursive in both horizontal and also vertical directions so this gives a very powerful representation uh for user to represent a complicated object and allowing them to you know traverse over this very complicated document uh bubbling up the scores assembling the scores very easy so that's kind of the idea of dockery and we actually found this kind of pattern a long time before but we just previously it was just part of gina and now we pull it out as a separate project and then you know serve it as a common cornerstone for all of our products uh in our ecosystem so this doc ray is it kind of similar to how you have like a json schema that can embed you you could put like you know another dictionary within the kind of python dictionary data structure json that kind of yes that kind of structure and can you tell me more about uh gina hub how do people contribute to it what's kind of the organization of it yeah so gina hub gina hubba is a very interesting story uh has a very interesting story so to be frank uh we failed uh two times before the scenes that you see today right so i'm i'm going to be very frankly right i mean marketplace like it's very obvious like every uh you know not every not apple do not apple to marketplace google also do a marketplace right they have app store you have google play which is like app store marketplace it seems so obvious that a lot of software company also like to do marketplace right uh you know some of the very popular open-source company also has a marketplace running and i believe you right now if you talk about if you go to any uh ecosystem like whether it is about your search or database uh you know security they will all have their own marketplace so we also observe that i will see that okay so everybody has marketplace it must be very easy to do that it must be very obvious to do that right and then we start with the first marketplace which comes which is completely powered by github right because because you can abuse github by you know by putting by storing all your kind of algorithm inside one repository so then you have a kind of very poor man version of the uh of the hub this is exactly what we did for the first project right i kind of have a collection of repository in github repository in one single github repo right but later we found out this doesn't scale because you know you know everything does stick together is like you have a very small room and there are 20 people in that you know there a lot of things a lot of conflict management development management issues uh so this doesn't scale skills out right so this actually slows us down uh when we try to update some something uh update some uh you know some dependency all these kind of things and then the second version is uh we look at all the so that was the first uh failure right back in i think this was back in the uh uh 2020 2020 in winter right we realized that okay so this doesn't work right so uh you know we kind of put or we kind of uh you know uh suspend this project you know project like forever right and in 2021 we restart this project because you know everybody do marketplace we still want to do marketplace you know we are one of the cool guys and we still want to do marketplace and we think about okay so uh we failed because of the you know everybody has to go to github github repository and there's no very interaction user engagement on that so let's first let's focus on ui right so let's first build a very nice graphic user interface to attract people there and with car design bootstrap you know this kind of uh card things and and then this version of cars also fails right so it fails because there is no infrastructure that supports this marketplace right so basically the infrastructure is not up to date it's still like a very repulsory base and then you basically build a static website which somehow you have some nice card and then link back to the github repository right this also doesn't work and then i started to as this failure was the second failure that happens in uh summer 2021 i think in may 2010 something like that and as i start to think about this most seriously right i started to think about okay so what does it what has a cornerstone what are the pillars that makes a good marketplace and uh i summarize as a three points right uh uh so it is just my personal opinions uh probably some people don't agree on this so the first point is you need a good infrastructure all right so think about app store right so you download an app from the app store from apple app store right it seems that you have the same download speed whether you're locating in us or whether you are in china or you're in germany you have you basically have the same download speed and every time the app is updated you get notified every time your ios is updated then the apps that requires to be updated updated outdated automatically the apps that are not necessarily yet to be updated stay on the same version so this is an infrastructure it is something that belongs to this marketplace without this infrastructure app store won't work right you won't receive push notification you won't receive push update you won't you know you won't get a lot of version conflict you know after the operating system operating updates and you get your your apps cannot use anymore so the reason the fact that you don't observe this from day to day is that apple implements a very good infrastructure behind their app store right so why do we care about this we have the same problem we have a gina which is like the ios like the operating system and the executor which is like the reusable building block it's like the app on the app store so there are version control issues there are updates issuers who updates first and who gets updated what is the cost what is the consequence and you know and all the push things right so you want to pull you want to use executor inside gina and then pull this and then pull and then you want to encourage community to push it and then whether the developer has certificate authentication all these kind of so this is infrastructure problem right which support which becomes the first successful factor of a marketplace and then the second is the content right so let's say we build a very good infrastructure right but nobody literally nobody uh you know contributes on that then this is also bad i think you know right now one of the most successful open source arp company in the world has very successful and active marketplace it's because a lot of contributors a lot of people in this and contribute very good uh content to that to give you a better example let's don't talk about competitors right so let's let's just use xbox right some people like xbox some people like sony ps4 or ps5 but what matters let's say comparing side by side their graphic cards their cpu gpo this kind of thing you know controller you can talk about this right you can compare side by side but that's the nursing right so that's very nerdy uh what really matters is in this platform do you have their favorite games here right do you have your favorite games there uh nintendo 3ds right so there is a there is a there is a lot of like a very very uh you know it's very bad hardware right and but then you have a very good uh zelda right on this on this console right so that's why uh you know people play that right and uh let's say if you have a infrastructure that's of course not enough you you have a marketplace you need to have a good content you need to have sexy content that lure people in right and so people it is exclusive to this platform right so let's say we have a new bird model and this is first available in this marketplace right then this is a this this generates an impact that you know attracts people to your marketplace so the content is the second successful factor uh but also like a content is not really it's it's really it's i mean it's very easy to summarize like this but when you try to implement that it actually involves engineering effort debris effort uh research effort business developing effort a lot of things right and then the third thing is social a lot of people missing the social parts the social pillars of the marketplace uh this uh so think about this uh so i remember in the old days we have google chat or msn messenger right i mean they are not really like uh uh kind of like a really easy to use right especially msn messenger a live messenger microsoft live my center it's not really easy to use but you still use that because your friends using that right uh so this is a social factor of the marketplace if we can make sure that your friends your colleagues right your friends in the data science community also use the same platform right then this is what makes the marketplace more active so these are the three factors that i eventually summarize you know before we start the third version of gina hub and this is the kind of the the gina hub that you see today on the surface you see okay there's a our cage interface there and there is uh some some kind of uh contents there but underneath we have a very very powerful infrastructure so what you see right now is just a virtualization layer so you see a bunch of docker images there it looks like very static but right now with gina 3 release so this each uh docker image there suddenly becomes a darker container that is already running it is we call it sandbox so you can directly query it as a macro service you can without even downloading without even pulling for your local right so this basically suggests that besides virtualization part which we are already have a good computation layer under the hub right and then we have we have uh if you if you read our documentations uh very carefully uh very very closely you'll find that there is a docker rate push and pull and this is actually the storage part of the hub system so overall if you ask me what is what is my vision what is hub about i would say hub is about three pillars right now the you know not easy um now the the social you know infrastructure these things but the three pillars of uh virtualization computation and storage so those are the three pillars three layers of the hub system and that we have and this well actually becomes the uh let's say this is the highlight of the county in this year so we will spend a lot of energy a lot of human resources in the hub and the hub will become the middleware of the camp all right so it was support gina it was support fine tuner darquery and all the product all the ecosystem that we have wow that's incredible i think that's such a this is a great master class on the marketplace and and the hub and all these things can you take me through how these say modular components and i i love that micro service so you can query it and it can be independent and you can test it that way i think that's so exciting could you take me through uh i think it's uh document executor flow can you take me through how you how these things all plug together yes yes definitely so i think the uh the documentary executor and flow this three concept has been zero uh let's say uh since we first since we write the first line of the code right so we have we have we actually have a lot of concepts right so we have we have a lot of concept like a driver executor p pod a runtime uh zenflow so we have like a we we used to have a family picture right and there is a wait wait we actually plot we actually uh asked uh uh a a uh you know a illustrator uh kind of like an illustrator and help us to draw some cartoon figure for each kind of uh canton picture for each kind of figure for each component that we have but then later we murder everybody that we kind of refactor all the things that we kill everybody and then the only three leftovers are executors document a document executor and flow right so that's the three concept that we eventually realized that okay in order to let user to know about your search to use your search these are the only three concepts that users need to know nothing more right before that we have the idea that okay so you know we are so awesome on engineering so we are so awesome so so uh so smooth and refactoring build all these abstractions since let's tell the user about it but the user don't don't buy it it's just like you sell them a burger you only tell you'll only talk about the meat you know this is a vacuum meet or whatever this very premium value you don't talk about cheese or pickles in the burger right so i i never see there is a burger company saying that okay we use the best pickle because it's meaningless right so people only care about the meat right or the best of bong or whatever there's said no one give a damn about this right so that's that means that when you when you try to build a product right you only tell the users the necessary part in order to satisfy them and then the necessary part in the gina ecosystem what we say that is in your search ecosystem is document which describes the objects the real world objects you want to search or you want to index it could be a pdf it could be an image video audio mp3 mp4 those kind of and then the executor executor is basically like an algorithm uh especially uh you know the algorithm unit of how you want to process this document uh the executor could be indexing could be bird could be storing or it could be pre-processing scoring all that kind of stuff and finally the flow the flow is kind of connecting all the executors and puts them together so the reason of using executor is uh it's actually uh making the original very local uh orientated algorithm network ready or cloud ready as a cloud ready so basically uh by using executor you cannot wrap your algorithm with a network layer so that it becomes a kind of micro service that are ready for the flow to be connect with to orchestrate right and then the flow is a final composer of everything right so you can imagine i'm a flow i'm a composer i'm an orchestrator so all the executors are sitting there and i just connect the doors and then to accomplish certain tasks right so that's kind of the three concepts that we eventually found you know uh that are really necessary for the end users so when people push a micro service to gina hub is it wrapped in one of those like they're either uploading an executor algorithm or an overall orchestration is it one of those three things they're pushing to the marketplace yes so right now you can so if you use document array push pull so you basically you trigger the storage layer you actually store your document array on in the hub and if you push a executor into the hub you basically uh it will actually build your executor into a docker image into a docker container and make it a service ready right on the on the on the hub right so this is a this is your experience on the whether you can deploy an end-to-end thing like a flow right now or multiple executor or subfloor right a subfloor subfloor is also very interesting right so let's say it's not a single exerter can do these things but you know let's say 2x heater can concat together you want to make it a subflow and you make it reusable in some other tasks this is also very interesting concept but at this moment the hub is not supporting subfloor or the flow level deployment or push-pull things right it only supports executor and document level push-pull yeah but as you can see this is a very natural step that we will work on uh in the next couple of months so say to come back to our earlier uh example of where you're parsing an image for to get out the different clothings with say an object detection model would you wrap that into a pre-processing executor and then you'd push that to the gina hub and that would be the contribution yeah exactly exactly that's the point yeah exactly very cool that's super cool so so coming a little out of the end to end and a little back to the embeddings themselves i want to ask you about the fine tuner library and the things that are in it like the lost functions hard negative mining and uh and the general concept of say off-the-shelf embeddings versus these fine-tuned embeddings yeah yeah exactly so so this is a this is a scene that uh uh this is another missing piece uh you know when we uh but we actually to be honest we didn't uh we didn't come up with this idea when we built a company let's say back in 2020 in february we don't have this idea we didn't have this idea but while we are developing or making synergy building some prototype with our clients we found ourselves always stuck in the position where after deployment after this thing is done there is no way to improve it further right we have seen him we have been seeing a lot of ways like you know hyper parameter optimizing you know uh using some heuristics uh this kind of thing but in the end what really matters is about the embedding the representation whether it is good enough for the ranking problem right because it's not like a classification it's not for general representation it's for very specific ranking right can you can you sort a before b right so that's the that's that's the that's the idea right so we we always stuck there right we always say that okay so at this point probably you only need to rely you you can only hope that google or open ai gives you a better model right uh so at some day last summer i i said that's enough right so we need to do something we need to do something about this this uh these embedding things about this naughty embedding right and then since october uh uh since august we have this idea and then we spent two months to develop the first prototype and then we published we released as a open source package in october uh fine tuner in october so if you count the date by date so we are only one month late than google so google released such fine-tuning metric learning tools back in 2021 in september and we released that in 2021 in october right so that's that's uh that's that's basically show us how we you know we look ahead in terms of this marketplace so why i think this is necessary why do i think this is important because i believe the tools such as tensorflow or pi torch is not designed for fine tuning so you know that in the transfer learning to give you some background transfer learning you know first uh training from scratch and then second you'll you'll fine-tune something right so this is a this is usually a two-step procedure and then tensorflow and paid torch or whatever this other deep learning package they are very good at building a model from scratch where you need to write a architecture a network architecture from scratch this is a completely different in the fine tuning usually you don't do such writing like a writing phone writing a big network architecture in the fine tuning procedure usually you just mask out some layers uh usually you just add some layers mask or some layers leveraging the existing pre-trained weights and then do some progressive learning right so this design pattern this usage pattern is also different quite different from you know from zero to one things right so you can imagine you break down the whole procedure from zero to one and then from one to n right and then this needs a two different kind of two kits or two twos right so uh so that's why i believe uh you know i i'm pretty sure that a lot of people using tensorflow or pytorch for fine tuning but i don't believe this is the right tools for finding i believe we need a different tools which is very good at masking out or selecting which can be fine-tuned in the network architecture can be very smoothly integrate human feedback in the fine-tuning procedure because this is super supervision and and also of course bring the best quality right out of that so based on this consideration so if you look at the initial uh you know concept of fine tuners that we have it actually composed of three components uh the trainer of course is uh you know training all these things and the tailor uh tailor is uh you know you can mask out some of the layers or you decide to you know add some layers on top of that usually are linear layers as back as a as as a as the end or you can freeze certain layers right and finally uh the labeler right so a labeler is allowing people users to uh interactively label the wrong data and in the next iteration it triggers some active learning you know selects the next hard examples and then uh tells the user to label uh you know to improve the training efficiency right so the tailor trainer and labeler right so that's the three original concept uh uh components in the fine tune and uh i still believe that this is this is very true that you know in this age a lot of you are seeing more and more company focus instead of focusing on training from scratch right there's still companies like focus on training from scratch but then i'm expecting that more and more company from this year you know they will start to developing tools developing surveys for fine tuning right because training from scratch is not really doable by a lot of companies whether it is you know time wise or money wise you don't you have to spend a lot of talents resources money uh gpu right electricity you know build on training something from scratch but the fine tuner is different right you you don't want to spend a lot of effort you want to optimize the time to market right and then the the training from scratch part is not part of the time to market the fine tuning who can ever provide the best fine tuning uh who can win the time to market part super interesting and i really want to ask also about your view on prompting versus fine tuning next but then just to quickly unpack these things a little bit i really liked your description of the taylor part i think that's so interesting say the lottery ticket hypothesis how we know that there's this sparse sub network within the dense architecture that can retain the full performance but there isn't really a good masking interface as you say to implement that masking and pie torch or tensorflow bit of a headache you got yourself in yeah exact things we've and things we've seen with say the adapter and compactor layers a recent paper vision and language adapter they're able to fine tune they only need four four point four percent of the original clip parameters to fine tune it because what they're doing is they have these intermediate layers that they fine-tune they don't fine-tune the whole network architecture so as han's describing this tailor part is such an interesting part and so i think we'll come back to the labeler part i wanted to ask you a little more about that but to kind of stay on this topic of tuning generally um what are your thoughts on say prompting large models compared to fine-tuning them yeah i i i know this uh so i know the problem to you this kind of thing is very uh becomes very uh let's say a lot of attention uh in the especially in these years i think it's super i think it's super useful like i i we i remember there was a recent paper about the mask auto encoder which is kind of like a prompting and then in the region part i think this idea is very uh it's very related to fine tuning but then people people really now even talk about you know in the fine tuning can we even skip the labeling part can we just rely on self learning can we self learning can we just leverage the redundancy of the data itself and then use it for fine-tuning including problem here is one part mask auto encoder is another technology but also like augmentation i think this is these things are very very related and we actually have we actually plan to have all of them in the fine tuning framework yeah i see that as a part of the search like because the way you can ensemble all the outputs with the different prompt in the like test time data augmentation and that kind of thing so so coming back into the components of the fine tuner could you tell me about the labeler a little more you mentioned the active learning where you say bubble up the most uncertain predictions to save for labeling but is this with respect to similarity labeling with respect to like say triplet losses where you're saying these are similar this is a hard negative or something like that and and if so when you're labeling base and similarity do you kind of have like uh like a a similarity graph where if two things are similar well it's like it's also similar to that other thing you labeled it right so how do you kind of organize annotation of contrast of learning models yeah exactly so so there there are two questions so one is uh like what to label right so whether you select the most confident one and tell the model is very confident they say okay so i'm pretty sure that this is the correct prediction and then you give it a bump you say that no this is not correct are you you're telling the model to return the most unconfident one right so the model is yeah i'm not so sure please help me human rights so either either way this could work right so i i remember you know my phd was actually about adversarial learning it's about selecting the example that can ruin the whole thing right so this is like the very very deconstructive part right so uh but but i so there i i learned a lot of models a lot of measured about how to select uh the examples uh you know there there are a lot of a lot of measured a lot of lot of like a family of measures so some are based on the uh you know by space based on the uh i remember when i work on that it's mostly about labeling for svm so there is like a margin based approach and then as people select the the data points that are very close to the margin are very far away from the margin in order to do that right so there is also related somehow related to the uh random procedure a random process like a gaussian process so for each data point you have kind of like a confidence interval and then you kind of use this confidence interval as a kind of the metric to ask a human to labor right so this is one thing i think there is no very deterministic conclusion on this right a very very uh very very certain conclusion on this uh so that's why in the in this framework we try to provide the mainstream one right so those are all this mainstream one and then the second problem is actually more interesting right uh i believe you see the spacey have a nice very nice labeling tools uh which called i forgot their name is a guy i think it's a parody or something like that and uh it has very nice ui i i really like it i actually learned it a lot from when i do the fine tuner labelers interface but then it is different like in spaces uh space is an nrp company by the way so it's a focus on text processing all this kind of thing in spaces labeler they try to label the name entity so it's mostly like uh you know you highlight some part of the text and then you label with some entities but in ranking it is different right so how many results you want to give to the user how how do you want to represent the relationship between you know it's a kind of older relationship very you want to represent it very nicely to the labeler and uh asking them to label it you know very efficiently because usually when i design the label interface this involves two parts so one is for the developer for the machine learning expert you know usually who's sitting behind the labeler who will try to guide the algorithm to pause it pose a question to the labeler so those people you have to make sure that the graphic user interface makes sense for them makes sense from the machine learning perspective you know you are asking the right question and then you you your user interface is not misleading the labeler to give you the wrong answer right so this is one part right and then the second part is probably more dark than your thought is that you have to make your interface very efficient for labeler you you don't want to you don't want to introduce a lot of video concepts you know a lot of uh you know a lot of uh very visual visual studios to distract them you don't want to introduce very complete concept that labeler cannot really understand what you know how to choice or let's say for you for example uh you know i i i previously saw there is a user interface asking the labeler to drag and drop you know to drag a scroll bar to select uh to to raise how related which is you know it's like a i would never go for like uh in the middle right so i will just go either on the on the negative or the positive side so so i mean this is about the fact that when you want to deploy this when you want to have this labeler system and practice usually your users of the labeler is completely different from the so they might be professional labelers so think about this so when you put this on amazon mechanical terp right or crowdsourcing platform so those labelers made professional in terms of labeling but they are not professional in understanding uh you know why they are doing that right so this this is a this is a difficulty part this is a challenging part you know compared to classification uh compared to you know the name entity recognition uh so the question of ranking right and how to represent the ranking in a very nice intuitive ui and the worker can efficiently label that this is a still the question and this is i would say this is still an open question i have to i checked a lot of uh you know open source labeling system like label me uh there is another labeling tools which is very popular on github i checked them but most of them they just they don't optimize directly for search they optimize for classification they provide for classifications on the mainstream use case it's still about image annotation or image segmentation name entity recognition i believe there will still need more attention more resources to put into this uh search labeling tools yeah right that's so interesting and yeah i think that's that is definitely an interest different kind of labeling compared to the programmatic labeling of image classification or named entity compared up to just similarity annotation and then re-ranking it seems like a hell of a task to annotate uh re-ranking orders so uh i was kind of coming out of the fine tuner bit and um i know that i think today as we're recording this uh there's the announcement of gina three can you tell me a bit about what's new and then kind of what's on the horizon for gina and what things on your horizon are exciting you the most yeah so i i think gina is really what excites me most is about a support uh on the cloud and and then we really want to you know carry the promise that we are the cloud native neural search framework right so we're actually from the day one gina is designed in a very complicated micro service way which a lot of framework won't do that in the first place as let's say for example numpy won't do that pandas data frames they won't do that but gina from day one it is introduced a lot of concept about about micro service and now we we start to converge into a point where say that okay so now the design pattern has been zero for a long time and now you can really use gina as kind of the micro service framework for uh in production right so this is a this is more like a symbol and then the the other thing what makes me very excited is about uh gina compared to one year ago or two years ago it has many friends already like whether it is internal friends like dr ray feinhunder uh and uh you know the hub so it has all about the external friends so it already formulized uh formalized ecosystem right so the real power is not it's not really about the genome itself right we try to maximize the productivity of gina user with all the ecosystem so right now if you go to the readme right you read your you go through the readme and you already found out that okay so there are a lot of things that it seems like it's not really implemented inside gina but it's actually gina calling other service to do that right that some of the surveys are internally some of the surveys are externally and we are also building a synergy with viviet so we haven't announced yet but for the careful readers who you know go to our website go to a doc array website you can already see that that there is a storage background called viviet you know listed under the document store which enables people to use stock array but meanwhile enjoy the vector the faster vector retrieval capability that uh offered by vivian right so this is the thing that i'm talking about so gina is not only it's not a solo fighter anymore it's kind of like it's become the glue of the neural search echo system and this is actually what makes me very very excited super cool yeah the integration with we've we love the you know the storage the vector and then plugging it into this end to end gina i think it's such a perfect match of the glue and all these things fitting together so well so i kind of have a meta question i'm curious if what drives you're thinking you're so knowledgeable i've learned so much from this chat and i'm really like impressed by how how much range of all these topics you've been able to cover and i'm i'm curious like um how as you develop these things do you have a particular application in mind that you pursue is like in your mind that like something that you'd like to see come to life as like a builder of developer tools in this kind of framework yeah yeah definitely i i would say from from the beginning we focus on cross modality and multi-modality search and we're still pushing in that direction so our focus is always on cross-modality and multi-modality uh solutions right so let's say we in the end we want to make sure that you know every every time developers want to realize some cross-model and multi-modal capability in their application they come to gina right uh so that's our long-term vision and that's always my always our vision right but in terms of the very uh you know practical solutions uh real real-world applications i would say right now it's still about text and images right it's still about texting me images videos you know we have some video partners but you know to be honest it's it's a little bit difficult because uh it's actually not about database it's actually about computation and pre-processing the vector that the video sales is much more like say space demanding you know and also in terms of network uh you know it actually puts a lot of pressure on the micro service structure right and uh uh so when it comes about text and images i would say in terms of text i would say uh what what what interesting ask is the question answering this is something that i mean if you talk about your research on text right so the first thing that usually the investor will ask you is isn't this already done by elastic right so you are doing a search and then you are doing search on text either this is already done by elastic or blue scene or whatever right uh but then if you think about elastic or lucy they are able to do the token based matching but they are not able to do the more deep semantic this kind of relation exploring things right and then the one very typical very good application in the text is a question answering especially the reading comprehension this kind of thing this is something that still in the text domain right because everybody loves text because the text is like a 70 of the all the data that we have right and then but this is something that previously if you use elastic you use leucine this kind of symbolic search tools you're not able to do that it's very very hard to do that you can just mimic some very simple intelligence but you can easily beat up those intelligence right so nowadays with all these machine learning deep learning models so qa is what definitely one of the interests when it comes to text in your search and then when it comes to image neural search i think the the old things everything is about the quality i mean neural image search uh when you have whether you use neural or non-neural right so you can use phase to to do that uh it's you if it's not a big topic it's not a new topic people realize people implement that long times ago using different kind of heuristic hashing measures lisa shows this kind of thing but now the thing is about the quality it's the quality of this you know not only the the quality of the search or the ranking result but the quality the ability of adjusting complicated images let's say hd images let's say 3d images right achieve all these kind of things right and uh can we are we able to are we able to come up with a solution over that over a perfect solution on this problem so this is also and then there are also a lot of um you know to give you an example there was a very interesting idea about uh you know uh inside the company is about using a newer search to serve to to to solve the front-end uh cicd problem so what is this financial department so usually when you write uh uh css or html right so you kind of render the page web page on top of that but sometimes you know you want to compare this web page to the previous web page to make sure that you are not uh introducing something very weird layouts that somehow mess up all everything right uh and so this is one thing that of course you can you can use direct in uh you know complete exact image mesh to compare pixel by pixel uh but then in another case you want to have kind of very general feeling about whether this layout makes sense or not you know this kind of thing compared to the previous layout that you have i'll compare to the reasonable layout in a collection so this is a very interesting neural search problem and then the search media is an image but it's a screenshot it's probably a screenshot on multiple devices right on iphone on kind of like uh you know on the on the on macbook pro you you have re or you know this kind of very high resolution uh screen or on windows where you don't have high resolution screen uh but this kind of that do they all behave the same or do they look like similar even though they're you know they're kind of not in the same shape uh so this is a this is something uh that can be used or can be solved by a neural search right so this is what i mean by image and by image search we focus on quality and innovation part yeah i love that idea of the text or the css to the user interface and that kind of using deep learning models on user interfaces i think it's so exciting and this general scope of like no code and deep learning to help with code is something that i think is so interesting and so kind of going out into some ideas that might be possible and something that i'm really curious about is uh as you mentioned earlier say scientific literature mining applications where you might highlight a you're writing a paper and you highlight your section you're like has anyone had this idea before you know you send that to like the archive or whatever yes can can text and the figures or the images that describe algorithms and scientific papers do you think we're getting close to being able to unify those two things and and really have say maybe an uh image captioning model tr that can caption a figure from a deep learning paper or maybe a visual question answering can like could you explain to me where in this image x is described or something like that yeah definitely i i know there is a direction called visual qa which basically you can ask image on questions right so you can ask how many apples are in these images or what is a what is a general trend of this curve does it go on does it go down you know this kind of thing uh so i i think it would be super powerful uh application if we can combine this kind of multi modality scenes with qa into one solution right and uh i think by that time you know we want to make sure gina is ready for that right that's that's why you know gina is focused on cross modality multimodality try to spread over you know on different domains on different applications the only reason is that you know we see the field of neural search is so wide right and there are so many places so many modalities and potentials in this in this uh in this field right and we want to get ready we want to make sure that we are ready as a developer tools we are ready and before people realizing that realizing there there is a need for that right and when they when they when they realize that and they they can come to gina and they use gina to build something very quickly to solve their problem right like the problems that you were talking about whether it's a text qa video qa table qa all these kind of things yeah yeah i love this i can imagine how recently reading facebook's cm3 model where they're they're modeling html text and then they take the images and they put them into vq vae discrete codes i can imagine how you would have a vq vae pre-processing layer as an executor on gina hub and then you could grab that plug it into your pipeline and then you've got the discrete codes to make your multimodal thing more interesting and and yeah i think it's so interesting i'm really like really impressed with the gina hub and thinking about how these modular components again i really love the microservices that you can query each individual component i think overall it's so interesting so uh thank you so much for coming on the podcast han i think we covered so many topics and i think it's maybe a lot for one person to digest all these things but i'll be having a chapter companion and things like that to try to parse it but uh maybe kind of just wrapping up is there anything else that you think um maybe we left out in the coverage uh yeah i think it's good i think everything is covered yeah i mean i can keep talking like a forever that's my job that guy's the ceo but i think that's that's good yeah actually if i can't ask you one more question just um as the ceo what's been your experience building such a company like this uh i think it's uh they're i think there are a lot of to experience i would say it's it's completely i i always say that there are three types of person will work in the open source domain one is you work as a hobbyist right so it's a it's not open source is just your hobby so you have a daily job uh working some companies and then afterwards you you work in open source after work your working opens up and then the second type of person is people who get very lucky in microsoft and google but then not only in that in this company but also working tensorflow team right working for pytorch right so this is also very very happy job right so both of them both of them are kind of very happy because uh they don't have to worry about putting the bread on the table right so that's that's the happy part right but then what so there's third type of person it's just like a uh me and bob so who i believe believing open source so much that we are willing to create a business and we are willing we are so confident that saying that okay so this is not an ideology i ideal ideology right so this is not about you know having world peace uh not about something like that it's about creating an economy right we are confident about this kind of make money and so on right and then we work on the open source we create this open source software as a company right so what people call the commercial open source company and uh uh so then everything changed right so what previously become well previously what's happening now is yeah it's uh it's occasion right okay it's happening and uh and then everything that we work every move that we have in the community on social media it becomes very strategical right so it's not so let's say some people say that it's not so pure right because then you're kind of back with money you kind of like you know you want to adoption those kind of things it's not so pure anymore but hey after all you know we sacrifice our time right so we use our time and effort and build up this community and offer this technology for free i mean this is a spirit of open source we we work with upstream we work with downstream we help people you know we help the community to solve their problem in order to you know not only just of course to promote our product but also to improve the technology of neural search right whether it is bob or it is me you know we share the same goal we want to push this economy to the new high and then everybody gets you know gets happy about this if we make this cake bigger then everybody's portion is also bigger right of course we have to be very competitive [Music] you know you know then we get you know equally bigger portion of the cake right so that's that's all that's a happy happy ending for everybody right so i i think in general i would say it's completely different than when i work at tencent i used to be a open source contributor where i used to work at tencent i was uh you know i was a open source program office i work in open source program office i work as a kind of like a technical manager there to moderate the strategy of things in open source how how they want to open source the software especially in ai how to how they want to open the ai software in the linux foundation in the apache foundation and now sitting as a ceo i see let's say i'm seeing more realistic part of the open source it's not only about collaboration synergy now from my understanding especially sitting as a ceo as a company as an open source company open source means more about uh open competition right open competition it means that okay so whatever vivian implement or whatever let's say let's look at always talk about let's use another uh imaginary accounting right so uh so we we all the source code are open to each other right so let's say today we release gina screen and we have a very cool new features then you can always adopt that you can always copy copy paste the code you know it is actually unlicensed online apache you can always copy the copy paste the code and then have these functionalities in your code base as well right so there's no problem at all right but uh so then it makes us to think about you know usually in the software company source code is your secret sauce it's what makes this company successful if the source code is not your secret sauce anymore then what is your secret sauce right you must have something special right to make this company sustainable right uh you know warm heart you know this kind of enthusiasm uh this don't take long right those don't sustain you need something sustainable right to make sure that the company stays long right especially as open source software i believe every open source software uh company uh face the same challenge to keep retrospect to keep asking themselves what is my advantage what is my mode of the company right in the end you have to make money and uh so you do all these community things since can we translate this community contribution into kind of resources that we leverage to improve the adoption right so those are the questions that usually i believe every ceo of the open source company well from time to time asking themselves wow well thank you so much han i learned so much from the podcast i'm so excited for our web community to to see this and i think there's so much to learn from it so thank you so much again yeah sure [Music] ", "type": "Video", "name": "weaviate_podcast_11_ceo_han_xiao_from_jina_ai", "path": "", "link": "https://www.youtube.com/watch?v=HIGAQAE_xaI", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}