{"text": "Hey everyone, thank you so much for watching the 49th episode of the Weaviate Podcast!! This podcast features Professor Laura ... \nhey everyone I'm super excited towelcome Professor Laura Dietz from theUniversity of New Hampshire to the weviapodcast Professor Dietz is one of theworld's leading scientists in searchtechnology and information retrieval andfirstly thank you so much for joiningthe podcastthank you for having meawesome so I'm so excited to dive intothis topic of uh to open things up withneurosymbolic uh search and kind of I'vealways been trying to wrestle myunderstanding of neurosymbolic how youcombine neural Technologies like deeplearning with symbolic systems like saymaybe knowledge graphs and treealgorithms and all these things so uhcan you maybe open us up with maybe kindof just how you define neurosembolic AIbroadly and then maybe we could diveinto the searchsure I thinkI mean most people think that it's verydifficult to combine these thingsbecause one sounds like hard facts andthe other one is called like softprobabilistic thingwhere in reality a lot of like thesymbolic stuff also has like a softpublicistic notion like I did my PhD inprobabilistic models and you know youyou kind of like still have sort of likeyou have access to both of those thingsum I think for me what's maybe moreimportant isum words I don't like Words particularlyin particular I always say I don't havea lot of passion for these little wordsum this is why I'm not an NLP Professorlike uh the prepositions and theconjunctions and all these little thingssomebody needs to care about it andthat's not me but what I care aboutyourself like big picture things andthat's like what ultimately brought meto information retrieval which is sortof like a field I entered during mysecond postdocum it's like big picture thing hey hereI have something I want to know and thething over here could or could not berelevant how can I bring these bigpicture things together rather than havelike little sentence by sentence withBarbara tasks so that's like that's notlike the thing that like I always likedand it took me a long time to realizethat I was like doing something likeinformation retrieval already when Ithought I was a machine learningscientist soso um uh you asked me about symbols solike one I mean and symbols is kind oflike it's a very generic term like itcan mean whatever you think is a goodsymbol for what you're trying to doum like here more concrete example of asymbol with let's say maybe uh what whatpeople call an entity link that's sortof like you have text and in the textyou have a mention of a thing that weall agree is a thing in the real worldlet's say uh oysters okaywe can agree that oysters are a thingokay so now there are different thingsto say about oysters okay but like ifyou have a text where uh that talksabout oysters a lot and you havesomebody wants to know about oysters butif you can spot that this text mentionsoysters and you can identify thatoysters are like relevant for what youwant to know then this oyster is notjust a word but it's sort of like aparticular kind of thingum and in particular maybe oyster thething is different from our oyster shellyeah so like it's more than just theword but if you identify that oyster isa thing in the text now that kind oflike helps you sort of like cope withall the kind of like Witnesses innatural language or like synonyms forlisteningum needs for disambiguation differentways of phrasing the same things usingcompletely different words you sort oflike I call it sort of like a landmarkin text that can like latch onto and itkind of gets me half of the way towardslike what I want to do to like helpusers find what they're looking for sothat's kind of like maybe like a veryconcrete thing of like why I'minterested in symbolsnowso I keep going yeah you know I'm aprofessor so you give you like a onehour 20 minute monologue if you don'tstop meum so you ask about like neurosymbolicright so some of us talking about likesymbols right like then um I think a lotof like current work in newer methods iskind of like about like words anddealing with sort of like vectors basedembeddings kind of thing you know andlike similarity in the vector spacethat's supposed to like capture somekind of meaning and we can just put thesymbols in there as well you know if wecan do like a word is sort of like ahard thing right if you think of a wordas a symbol we know how to representwords in a neural network space so thesymbols are just likeadditional words right so we can like dothe same thing that we've done to wordsand we can again represent them a latentspace so that's like no problem noproblem on that side but it's a naturalfit it's just like maybe the way that wethink about words is a little bit morelike fluid uh and the way that we thinkabout symbols is a little bit more rigidumso I guess my question is I've alwayshad a hard time understanding this kindof like entity parsing out I get like somaybe just take a step back like withthe oyster example I I always have kindof thought that like kind of the vectorscapture the semantics of the oysters somaybe like clams or mussels I likesimilar Foods kind of so it depends onthe context or I don't know too muchabout oysters but maybe if you're likefishing them so so maybe could you helpme understand like how the entityparsinguh like how how it plays with searchkind ofwell I mean there's like um towardsworking with aunties they are kind oflike two parts but one is you have textand the text is just words um toidentify which of these words actuallyrefer to likeuh oysters and like particular oysterversus oyster shellumthen I think once you know that it'slike you can like take entities asadditional words and you can likeinclude them in you know your relevancemodel to identify what's is it on topicis it off topic umum they're kind of like some otheradvantages where you know often they'relike Tethered to like a knowledge graphor some databases or some other externalknowledge um and even even just like ifyou have like small spelling variationsif you just ever look at words you havesort of like a question about thisinvigorationum maybe oyster isn't like that butlet's say you have David Smith in thetext and you have another text also talkabout David Smith right we don't knoware these the same David Smith is solikeum somebody that we don't even like knowabout like this is all like we'reentities this invigoration is like veryvery critical especially with likepeople names and uh place namesespecially since the Americans decidedthat like every European Town also needsto be placed in the US so now that'skind of like you know that's like it canbe can be very hairy problems rightum but even like other things like umtime right so when I say time and Idon't give any further context like youknow or we probably talk about the thingon the clock but like time I like youknow their Pink Floyd song called timeit drove me nuts like was like very verymad at Pink Floyd for a whileum so can we think of stuff like beinglike it's undisputably like when I sayone word that's the thing but like ifyou look at text and if you look at itin detail it's not necessarily clearthat the thing that mentions the rightname is actually the right thing soso when you actually go through themechanics of like entities invigorationsaying is this time thing on the clockis it time the work of artnow you can like add this to yourdocument representation and the nexttime I want to know about like time thePink Floyd songI can sort of like directly go to mysearch index and grab out these piecesof text we've already put in some workin well I know that this is the here inthis context we we refer to the PinkFloyd song so that's sort of like whereyou can really like add additionalknowledgeum something that people like oftenthink like I think or like maybe like 15years ago people thought uh Hey namedentity recognition which is notdisinfiguration it's just like here'sthe text oh that looks like a place thatlooks like a person and they were tryingto like make gain some leverage out ofinformation retrieval and it didn't workand the reason why it didn't work iskind of like obvious in hindsightum but just while you know in searchyou're really focusing on the wordsuh the words already there the reasonlike like the way that you identify thatthese are people names is becausethey're particular words things like ityou can look up like in gazetteer orsomething so you're not really addinganything to the knowledge there's veryfew very few general terms just likehave people names in it and if there'soften like an organization or maybe aplace or something so just like therecognition part like or like mentiondetection is also calledum it's like not that useful for searchhowever once you have like these entitylinks they're sort of like you know youdisambiguate dimension in the text andsay is this personit's this thing well it's like it's timethe song versus like time the generalconcept now that happens to be likereally useful in information retrievaland and I think my my second side of themost cited work is actually about likeshowing that this works in informationretrieval together with like JeffreyDalton and like James Allen from humansum and I think it was really like wellwe kind of like it was off like a tightrace you know the the market was ripefor doing this kind of work where we hadgood entity linking technology we hadsome benchmarks that kind of like wouldalso like to you would do better on ifyou would identify these entitiesum and that's what we did so like theone thing you just like toss it in andit makes everything better so I meanthat's like uh that's that's always agreat thing if you have a great modelsomething it really works you just add asecret ingredient and everything goes upand that was like one of them right soand I think again that's also somethingwe sense in hindsight because if you'reinterested in time in the Pink Floydcontext it's not the most frequentmention of time in the context you canuh immediately discard all the mentionsfor time as the clock and like focus inon the text that kind of like reallytalks about the word time in the rightcontextso if I have a query like um when wastime published uh something like thatand so I'm kind of I'm still trying totry to wrap my head around kind of thesystem architecture and how the systemworks so would you maybe first do avector search with the embedding of thatphrase uh uh when was time published Iremember what I had startedand then and then would you say like relike filter the outputs because you thenrun the entity parser over the candidateoutputs to say okay these thesementioned time the uh Pink Floyd songyeah so I thinklike this is not the machine learning mespeaking um I think usually the bestmodel is one that kind of does all thesethings at the same time we call thoselike joint inference modelum and like what neural networks do withend-to-end training and end-to-endinference it's like like the same idearightum I think if you would like write asystem that goes into productionuh number one talk to somebody elsenumber two do you have like two routesin which you can like go you can eitherfirst look at all of your collection onein entity link on all of those thenindex some information of the entitiesalong with wordsand these are now not I mean that's kindof like logical identifiers you knowpeople use you know Wikipedia titles orWiki data IDs or like whatever matchesin like your entityum like entities in the world that youcare aboutnow you can like take like any typicalretrieval model that of your choice andjust so extend it with like entitiesokay that's sort of like the search partuh the really hard part like to actuallyidentify what is relevant for what theuser wants to knowright like I mean if uh if a user wantsto know hey what is like healthy versusunhealthy Seafood I haven't mentionedoyster in that like information need butlike maybe talking about oysters whetherit's good for you maybe there might besome health risk associated thenum yeah it was like making that linksaying this is like what the user saidthe user did not know that they wantedto know about oysters I mean that's okaythose information needs exist but weusually consider themselves like thereally hard part is are like those wherethe stuff that's like really relevantthat really kind of like shows the rightkind of information and like reallybetter information than you would getotherwiseum I just like based on stuff that islike not that obvious I love like themachine learning inference embeddingtechniques are like about how can Ibring the words that I used in the querysort of like similar to the words thatactually in the real relevant documentsif we would know what that is of like a2020 hindsight kind of thing and wetrain on that and again like thisgesture here is something that I uh likeexercise a lot in my class so it's likewe have these things they're like theylook like very separateand whatever we do with like Machinerytechniques we try to bring the rightthings togetherand we push the wrong things apart rightand I think this is like also whereum like latent space embeddings thatlike neural networks give us it's likesuch a great fit because you can likereason Beyond just like lexicon matchingbut just like how the world prior tolike neural networks kind of like reallywereum and really like try to have somesemantic meaning of this is similar thanthat right and that's like somethingthat you also like said earlier aboutwell there's an information need thereare all these different things like Iwant to know that oyster here is similarto other things that uh they may find atthe beach or like that I find in the seaor I find in the water or something butlike the real and I mean that's alsolike you know the like an often sideduh advantage of doing the symbolic thingespecially when you have knowledgegraphs at the backgrounds that you havelike the taxonomy so you know an oysteris a this and that and that you have thewhole taxonomy that you can leverage uhif you have Wikipedia things you havethese categories that try to be likeoverlapping sets it's a little bit moremessy than like a nice static treeum which can help in some casesumthe big problem that we're usuallyfighting with isum it's only like helpful in like someof the cases just because the taxonomyisn't always the right thing that theright kind of group of thingsum let's sayum sea creatures you know we have likethe nice taxonomy of like oh uh oystersare part of like fall in with musclesand they are like this and that and theydon't quiz me on the biology but likesometimes I just want to say uh thingsthat like live in the water and theyoften isn't like a nice type for it orthere isn't a nice category for it andthat's like when step when stuff getslike hard and unfortunatelyI want to say that um yeah I sent abunch of students down the wrong RabbitHole trying exactly that and they'relike I don't know stuff isn't reallyworking so well and then we looked verycarefully I was like yeah Works in somecases but like often uh there isn't likean easy solution like just walking upthe taxonomy tree that's like wherewe're doing like love like an infantlike on the spot and so on likeidentifying what is the right set ofentitiesyeah this I think there's so much tounpack I I remember uh Bob and light atweavier when he was telling kind of thefounding story of weavier it started asa semantic uh web technology and um hetells a story that he was at aconference and they and people couldn'tagree on what was a lake or what was a cand this kind of like trying to formontologies people can't agree on whatwhat the vocabulary for things but uhyou you mentioned kind of the embeddingoptimization you know push thingssimilar push other things apart and soI'm really trying to understand kind ofthe role of knowledge graphs with thecurrent Vector search technology ismaybe the strategy to link the datasymbolically based on you know maybeshared entity mentions or however youlink the knowledge graph and then fromthere you you do like Knowledge Graphembeddings could that be maybe thefuture of embeddings or at least I seesorry to be going on a little bit but Isee kind of two two things of this whereit could be either like you know you youyou take a zero shot embedding modellike the pre-trained open AI cohere nicelike long list of pre-trained modelprovidersand then you kind of uh you know form anontology about your particular data andthen you have some kind of likeKnowledge Graph embedding orchestrationthing that that is like maybe the newstate of the art for how you get thebest embeddings is that maybe how you'rethinking about it orquite honestly it's uh an open researchquestion I'd like I think one of thereasons why we are giving the tutorialseries on like neurosymbolicrepresentations for informationretrieval is because we want to also getmore people to think about thisum typically the people that we talk tofall into two campsone says you don't need knowledge graphswe just have like neural methods andthey just like figure everything outthat's one way I mean and then and I'mnot like you know I'm not saying sorryyou're wrong right like I wouldn't say Ithink it's like it's a possiblehypothesis like you don't like need anyof the symbolic stuff anymore if youhave the right neural networkum I think on the other side you wouldhave people would sayumyou know we have all that knowledgesitting around here for free why notutilize it why not like work on tryingto make it work right then you have likethe other Camp saying oh yeah well wetried a bunch of these things and itdoesn't really help and I was like wellwhat kind of things exactly did you tryyou know think about it like you knowthe the technology like advances like ifyou use um a call that's like aprescription strength neural networksuper optimized by like you know Decadesof work that open AI put into somethingand then you um have a few really likePoor Man's entity features they're notgonna cut it right it's like Davidversus Goliath right no what you do needis like prescription strength entitylinking and entity ranking methods toactually kind of like make a dent hereright so this is like where we'recurrently in this parallel track phasewhere one says oh you know we tried itall and like doesn't really work it'slike not worth our time they have otherpeople like me who said no no if youever want to kind of like go out of ourlocal research option them if you wantto escape that we do need to pushfurther and like as long as we haven'tas long as the last researcher hasn'tgiven up hope we're gonna like plow inthe direction and we kind of like pullresources and we like see whether maybethere's a way here to like make makesome Headwayum but in 2023 we don't exactly knowright and I thinkum I think the other thing to us like beaware of thatthere are so many different fields thatlike work with knowledge graphsand they all work ultimately withdifferent problems and different problemsets like if you have your less couragelike talking about like knowledge craftsyou think about it like in oneparticular way which is often like youknow Knowledge Graph completion findingthese linksbut like this is not really the essencewhat you need in information retrievalinformation retrieval you need adifferent kind of set of Technology bothof those are working on knowledge graphsbut the purpose in the I call it likethe texture of the prediction problem islike very very differentum to give you an example an informationretrieval we always work in the settingthat during training time we don't knowsearch requests that we will see in thefuturethis is where a lot about likeinformation retrieval and like themachine learning methods that's beingused is all about similarity learningand particular the lexical similaritylearning because like uh today we'regoing to talk about oysters and tomorrowwe're gonna be talking about like greensea turtlesyou might have never seen a word like aquery that talks about anything as greenor C or Turtle during training timeyou cannot focus just on the wordsinstead you need to figure out like whatare the things like like if I if Ichange my information need if I changemy search query which other words willthat bring closer to this one so youcannot do something like a like Alexaclassifier like a classified that looksat word features and TF IDF featuresthis is not how it works you first needto like have some means of likesimilarity I mean I'm always saying webriefly glance at the words in the queryand the words and the document and thenfrom very instantly go into likesomething that is a similarityand that Trend goes like back as long asTF IDF and Boolean search right it'slike we quickly look at what's in thereand instantly return it like in thissimilarity metric and that's like stillthe case like today with the neuralnetwork methods that we use informationretrieval like I think dense passageretrieval or like by by encoder my mindI can't even think of it as the samething but you briefly look at the queryyou embedded you briefly look at thedocument you embedded and now thisproximity Is ultimately like metriclearning as it's as it's core now thereare different kinds of metric learningas uh there's like some big toolkit thatlike claims to do everything of metriclearning where students tried it itdidn't really work for IR casesum and when I look at the model I'm likeyeah okay I understand why this model isa good metric learning for this oneclass of problemshere we have another class of problemsit's not very surprising if it's likeyou know you kind of like still I meanthe devil is in the details and you likeneed to look at exactly what is yourmodel leveraging what is your what isyour unfair Advantage if you're amachine learning model to kind of likedo bet better in your task now youchange the task completely and you willfind that different things work betterand you find that maybe you kind ofactually really need a different modelhereyeah I really want to um get it I wantto come back to the entity linking andhow that happens but I really want tounderstand entity ranking a bit more andhow that uh Worksum maybe if we could unpack two kind ofCutting Edge ideas in the representationlearning space uh the first idea I'dlike to talk to you about is Colbert soColbert is like uh in addition to havingthe the vector that represents the wholepassage you also would do the you keepthe token representation you keep thevectors for each of the tokens and thenyou have this late interaction so I soso I'm thinking as I think about entityranking I think I have a query or I havea query like what was Barack Obama'sLegacy right and so I have Barack Obamaas I have this uh maybe a single entityvector or I have these kind of twovectors from the tokens like like I Ijust like like what does entity rankinghow does it look like uh as an algorithmsureumlike in genuine that's like neuralversus not neural dad likes of likethree branches of of entity informationpeople are utilizingone is like what you said you take thecurry you're entitling the curry now youknow oh here we have this person name weknow that person it's in bikini dataunder qid something somethinguh that's like one wayum another way is tosort of like retrieve stuff oh noactually like uh um retrieve stuff lookwhich entities are in there and like tryto identify what's in the knowledgegraph and like use the knowledge like Imean okay um hold on I kind of likemixing everything one is likeanti-linking the query the second one istake the queryhave your knowledge graph indexingKnowledge Graph knowledge it's like verytextural you just like shove that inyour search index you take the query youretrieve from that search indexum one way of doing that one is takeWikipedia toss it in a search indexretrieve a page every page you retrieverefers to an entitynow you get like entities this way theseentities might not just be the Obamasthese entities might be uh White Houseor somethingum the Third Way which um spoiler alertis actually the best way in ourexperience is you take your searchrequestsfirst you retrieve passagestext passages form a corpus of yourchoice you can also do that withWikipedia that actually works betterthan just trying to directly retrievePages interestingly you can also do itwith the open web and so on so forthpassagesnow you look which entities are linkedin these passagesokay and you can do some kind ofanalysis and this is like where thedifferent methods like this deviateum so you look at these passages in therankingyou identify what like the frequentmentioned entities which are NT says soclose to the query words and so on soforth you do a bunch of analysis andthat's another way of like finding outwhich entities are relevant and theseentities are often actually reallysurprisinglyum much more robust or stable thananything else likewhy does it work so well okay likenumber one anti-linking the query you dothe same thing that we did with uh nameentity recognition originally rightyou're not really adding additionalwords sometimes you add some more namescan sometimes help but most of the timethe person name needs to be sufficientlyalready disambiguate in the words foryou to actually be able to entity linkit and there are a whole bunch of peoplethat work just on entity Link in thequery which just requires a fewdifferent twists right or at leastdifferently trained models for it thiswayum so with anti-ling the query I don'tthink you add a ton of new informationit's a smidge and it depends but likeit's not where the real cake is a futurefrom the knowledge graphso now it depends how good yourknowledge graph is now the problem isum like if your knowledge graph iscoming from Wikipedia and if you look atthe first two paragraphs on theWikipedia page before they start withthe section and so on it's very veryshort brief description of this entitythis will mentioned the most importantfacts that people typically want to knowabout this entityuh let's take South Americado you know any South America factsuh maybe largest rainforest in the worldin Brazil let's start with maybe it's umit's not a country but it's like acontinent right and it has differentcountries uh yeah rainfall is probablyanother good one um so interestinglyum I don't know it's been a while backbut remember the the zika outbreak andlike I think it was like 2015 it waslike big in the news right interestinglyand it happened where South Americanow uh guess what is not mentioned onthe Wikipedia page of South America atleast last time I checkedEzekiel breaks and why is that hmmmaybe somebody like is like removingfacts from like certain pages I don'tknowum maybe they're just like moreinteresting things to say about SouthAmerica than the zika outbreak okay soif you however go to like the Wikipediapage that describes zika fever and thezika outbreak well they've mentionedlike South America South America SouthAmerica various kinds of likeum South American countries right it'slike oh no it's you know it's here andwe have like this many people kind oflike affected by here and there right sothis is ultimately like why the thirdpart of your first retrievebecause yeah if you want to know aboutthe zika fever right you can't startretrieving and you're getting a bunch ofpasses that talk about like the aboutzika the zika feverum about like different like medicaldetails or biomedical functioning orPathways and so on right and about likethe outbreak and like how tragic it wasand how it affected like so manydifferent lives especially of pregnantpeople you know so umif you retrieve those first and thoseare pretty easy to retrieve now if youlook which entities are in there you seelike South America is definitely likedominating so in this example about likeoh tell me about the zika fever or likewhere did the whether we have thickerfever outbreaksum you will not find but like you willnot find South America by entity linkingthe query because it's not mentionedyou will not find it by retrieving fromthe knowledge base because the knowledgebase finds all kinds of other things uhbut probably not South America if you goand like you retrieve from the fromeither Wikipedia or the open web lookwhat you need to say in there there youhave it South America right and and thisis just like in and this is a story thatwe've seen like time and time again inum in like our research where withdifferent kind of benchmarks and so onso forth like this is really wherethere's like bottom up you firstretrieve some Snippets that like seem tobe about the query Curry firstthen analyze whatever you get back toidentify which entities are veryrelevant and this is umyeah various of my students kind of likefine again and again that that's like agood that's a good way of doing itumyeah that that's super interesting andthat that's a really clear example of umof when you would do that kind ofKnowledge Graph retrieval my questionwith this has always been uh I've I'venever really understand understood howthese query languages for knowledgegraphs work but I think I think maybewith the like kind of the text to SQL islike kind of what I see as a relatedbranch of research where uh the largelanguage model can take a naturallanguage question and then turn it intolike an SQL query and so I imagine we'llstart to see the same kind of thing butwith you know maybe Cipher or these kindof Knowledge Graph rdf languages and sodo you do you think that's that maybethe like the large language models willknow how to take uh the query of wherewas the zika virus originated and thenturn it into the the graph query andthenyou know take advantage of theTechnologies betteryeah that will be that would be greatumso far we find that this like only worksin like very constrained environmentsright and this is like wherethe the search domain that you're tryingto support really matters a lot herelike if it's uh if it's something wherewhich is very very well represented by aknowledge graphyeah you do it I mean there's like allthis question answering over linked datait's a thing and they can like do reallywell on questions that's of like fitwell with the schemathe big problem is what do you do whenthe schema doesn't matchright so and um and I think this is likeme being in a as a more General IRresearcher working with like General IRbenchmarks we find that very often itlike doesn't match I rememberum like a couple of years back we didsome study in trying tosee um I would think we were trying touse in um open IE relation extractionsystem now that system was was designedto like extract relations about likepeople and organizations and places butnot so much about butterflies andflowers and like um water pollutionthings like that right so we try to makesome use of that technology on a verygeneral like IR Benchmark I think it waswas probably something like clue web ortrack web or somethingum and like me my student we looked atthe search queries and I think one waslike fall activities for children we'relike you can give up the schema will notbe able to answer those kind of likequestions right so we focus then on thefew queries it was probably like 40 ofthem where we had actually any hope onitum but it was still like like an upperbattle right like I think um like if youasked theum akbc crowd like automatic knowledgebased construction even they you knowthey went from triples like subjectspredicate objects like entity entity howthey connectedto uh hear a bunch of vectors by thenthey've been doing that one for a longtime right no no kind of like the thingslike you can then turn these vectorsinto triples if that's like what youprefer and like they're actuallyapplication for that but you can alsojust like directly work with thesevectors and they have like absorbed thatknowledge sitting in the vectors youmaybe don't need triples explicitlyanymoreum yeahI mean I think like nowadays what wehave and I think one thing um that mycolleague Hannah based she's a professorat University of Freiburgum and she's working a lot in the interlike like comic combining text notedtext bases and like knowledge based morestructural knowledge basesum one thing that she found out was likeyou know the GPTEtc models right like that and you thinklike you know you kind of ask it hey canyou take that natural question and runit as a sparkle queries like KnowledgeGraphshe said like crunchy what she finds isit generates perfect vaco which you knowit's like a very complicated querylanguage like very few humans canactuallycan actually like writegood Sparkle by hand like I give up onthat it's like not my it's like not myforte but they can write perfect Sparkleit like once it's syntactly correctbut then often you get an empty resultsetand then she did again and like newSparkle Curry again empty this outsidethen you tell the model hey your resultsis empty how do I need to change it toto find something and we know that thereare elements that existand again it generates something andagain the results it's empty and like Idon't I don't want to cite this as likea oh this is so bad technology weshouldn't even give it a try it's quitethe opposite I think I think it's likethese are great times to be alive rightit's like it's it's like uh it was likenearly Unthinkable maybe a year ago thenuh you can have you can give a questionand it will generate some sparkle thatkind of like looks believable isactually correct syntactically correctbut that's like a huge accomplishmentthat like you know blows everybody outof the water rightum but it's like also there's like youknow open questions right and and I meanit was like not be able to overcome thesituation where the schema justcompletely does not match what you wantand this is like wherewe currently in my research group wekind of like focus more on this like uhunstructured we have the text we knowhow Knowledge Graph extraction wouldwork in theory so we can like includethis information just to read the textfor us and pull out the important piecesand then we get an entity ranking thisway so it's sort of like um there's alot about like finding out like howresearch and other areas work which mostpeople don't like to do because it'spainfulum but like we'rethe the kind of like the unstructuredapproach that we focus on is mostly it'snot because we didn't want to work withknowledge graphs but because likewhenever we tried it didn't work on likeAya benchmarks very well and that'scertainly also like maybe the fault attrying to do uh say general purposeKnowledge Graph where um and maybe it'salso like at four make my preference umabout like search queries my favoritesearch queries um is maybe also at faulthere because I'm sorry I don't careabout peopleI don't care about people careers Idon't want to know anything about anycelebrities like I there may be like twoactors in the world that can actuallyrecognizeum and I just like it's just like notreally proud of my interest like myinterest is in like Popular Scienceenvironmental topics social topics andfor those we don't really have love likegreat knowledge crafts with us like workthereum so that's like one of the reasons whywe find it's not working that doesn'tmean it's not working statically it justmeans it's like it doesn't work for thislike very open domainsoft topics that are just like we knoware not very well represented byknowledge craft so but kind of likebecause I like those queries and I thinkthese careers like deserve to beanswered wellum and whenever I use a search engine Ifind myself just being highly frustratedin not finding the stuff that I want toknow especially when I want to learnabout something new like there's sort oflike a teachable moment that's likereally wasted so this is like why wework on these likeopenvague complex information needs thatalso like happen to be not well coveredby knowledge graphs but if you findyourself working on some likewell-covered areas like um people inbiographies or like um about companiesand like maybe like financialinformation and so on or in thebiomedical domain where you know ncbihas a very very expensive like knowledgebase very little very spots on the textbut very high on the structure much morethan like Ricky dataumum then that's like like the way to goso it's that's something it depends onthe domain what works and what doesn'tyeah it's so interesting um all theseknowledge graphs that I think likewikidata has been curated by humans withthe relations and stuff and there's alot I want to parse out but first I wantto get your opinion on another KnowledgeGraph that's really captured myattention which is uh it's from a groupat Harvard biomedical informatics calleduh Prime kg so Prime kg is like 130 000nodes which are like drugs proteinsdiseases and then they have roughly fivemillion edges between each others likedrug drug interaction drug proteininteractionum yeah but well yeah maybe quickly uhwhat do you think about that kind ofKnowledge Graph and the applications ofitum I don't knowwe like commentum you said like a hundred thousandentitiesthat doesn't like me like a whole lotquite honestly right I thinkum if you look at ncbi there's like it'slike such a big deal so it's really likea engineering challenge like work withit right like umso again like um yeah but I think youknow if you really like work in uhpharmacology they really like need toknow about like the interactions I meanit's a very again a very like narrowdomainbut maybe this is really like what youwant to know and I think that's alsosomething forum bigger isn't always better especiallywhen it comes to knowledge graphs likeum like what I said my initial examplewas like time the Pink Floyd song versustime the thing on the clockum if you if you know that you're notinterested in works of artandthen it's not a question anymore rightlike you the disambiguation problem justlike goes away because there's now onlylike one meaning of timeum so I think like by if you if you cansort of like identify that oh yes a nicecrap but he's just like the the subjectsection it's actually even like relevantfor what my users are needing and if youwant to if you want works a lot youwould go to a different kind of likesoftware right so this is like thesituation that you find yourself in herewhere you have knowledgecraft very veryspecific targeting one particular taskthat's importantmotion also kind of like in some wayslike simplifies things and I'm alwayslike a fan of like you don't need tomake your life hard unnecessarily soummaybe pivoting topics a little bit butI'm I've always I think one of thebiggest Trends in search with these newsearch engines like perplexity andyou.com and of course like vva we buildthis under the hood is like this kind oflike filtered Vector search where youmight pick a particular source of datato search through so say you want tosearch through Wikipedia Reddit Twitteror you know PubMed particularly and soto me that's one kind of structurethere's it's not necessarily uh linkedin a graph it's just kind of like youadd uh you know symbolic attributes ofof the source to the unstructured datawhat do you think about that kind of ADsymbolic data to unstructured data tothen kind of filter the search withoh yeah I mean I think like addingmetadata uh I think it should go withoutsaying like I think a lot of like workson umI think initial works on trustworthinessbefore we landed in that like veryheated political thing right like peoplesaid here A bunch of like news sourcesthat we generally trust hear a bunch oflike you know scientific schools that wegenerally trustum you usually put a lot of trust onWikipedia so if somebody like asked usfor anything we prefer those sources andlike only if you can't find anythinghere then we might get into the weeds umI think maybe in today's climate maybeyou want to kind of like uh firstidentify what's your user which side arethey leaning towards and then like showthem the sources that they might usuallyuh prefer to see to like avoid a bunchof heart attacks right that's likeanother example of kind of like being umfocused and selecting like by The SourceumI know that some people were like tryingto like predict when which source islike the most appropriatehmmum I think from what I've seen it's notmy core area but like from what I'veseen like the best thing is toum essentially like use your user modelor like you use Case Model like are wecurrently asking about health or are wecurrently asking about like oysters thenum like you step onto like to select theresource and then maybe like do somelike meta search and like merging a fewsources that are kind of likeappropriate rightum that would be kind of like um if Iwould have to do that in practice that'suh how we'll be doing itum I think as a research problemI would probably stick with thatI'm not thanking my research time on itand not my students time eitheryeah awesome That's so exciting and yesI think that was a really reallycomprehensive tour of the ofneurosymbolic searches understandingentity ranking well oh sorry there wasone more thing I wanted to pick yourbrain about which is entity linking andI think because I think with the largelanguage models we can now prompt it totake like two passages and then outputlike how they're related is that is thata breakthrough in energy linking what'skind of been the story of thisyeahI haven't done any empirical work withlike the latest models right like Ithink you can ask like the otherregressive language models to likeannotate your the text that theygenerate with like entity links and theyclaim they do that I don't know aboutthe accuracyum I thinkum for a long time the anti-linkingcommunity really like focused on likelinking every single entity in textwe're from an IR resource standpoint I'mlike you should ideally link thoseConcepts that really matter in thecontextum here's an example uh there's aWikipedia page about the word thethwhatever the link every single mentionof the yeah like you might have sometext that actually talks about the as animportant concept and now you do want tolink itright so uh I call this like a queryspecific or context specific entitylinking and I think that's kind of likeimportant rightum like another thing that I think isreally important is like to go on a subentity levellike uh oyster like we have actuallysome research areaum a multiple things to say aboutoysters you know you can oyster it's ananimal some people forget that it's ananimal it's an animal not vegetarianfood some peopleum say well there are sort of like somehint that it kind of like actually canlike filter the water and can help withsome of like cleanup of polluted watersourcesum but then it's also like a thing thatyou can eat right there is a differentconcept contests so can we identify thatin a text where we know all oystersmentioned here and we have an entitylink to the right oyster or maybe evenlike David Smith you know it's likesomething we have that anti-linkingfirst can we identify what's the contextwhich aspect of an entity is actuallymentioned in that contextuh it turns out you canin terms of if you do that you actuallykind of like have another kind of likeyou know another another hammer in yourhand that is saying you have the bighammer that's like entity andanti-league you have the small Hammerthat like it's like no here's this islike oyster the food that's beingmentioned here and here we have oysteras you know a creature that has ahabitat and a home and the family toreturn toum uh so then because that now tells youthat at least two pieces of textalthough they mention the same entitytalk actually about different thingsabout this entityum and that's something where we've kindof like we've shown like some initialpromise but then there's also like morework that needs to be done in this arealike how can we identify how can weleverage this like fine-grained entitylinking right but of course you know thethe knowledge graph embedding can helpus with all of this rightumand and I think you know like theanother thing you ask about like howgood are they at entity linking we knowthat like earlier models like bird areactually not very good at it I'm alwayssaying likeum like I remember in 2019 peoplethought oh Bert can do everythingthe train predominantly on Wikipediatherefore it should be able to do allthese entities and I think over the pastlike two three years we found out likeno this is actually not true it'sactually like birth is not very good atrepresenting entities like because it'salso like and if you think about howit's trained with a closed taskum you simply random word the chancethat you get a you know common word likea preposition or conjunctionum it's just like very highum it's much higher than sampling what Icall an information bearing word likeyou know you can think like rare wordsthat like tfidf would likeum also there's like fine-tuned withcertain kind of like other tasks thatare often very like lexico or like T5which is like trained on you know glueand super glue which are all like NLPtasks very lexical you need to reallyunderstand the words to like do well onthose tasks whereum something I've been trying to do witha couple of collaborators is to maybeeven train a new even like anold-fashioned birth modelfrom an academic budget just like undo afew changes and see whether you actuallyend up with a model that actually worksmuch better and also like an IR ingeneral certainly a model that's betterat representing like entitiesum and like part of this is like on inthe tokenizer your brother has adifferent token as into preserving butthen there's still like a bunch of likeotherI don't want to call them mistakes I'mjust saying stuff that choices that weremade when trading the model that reallymeans that they are very good for NLPtasks and not so good for these like bigIR tasks where you need character to beclose to you know health concernsyeah so uh the The Epiphany before Ithink this will make a really greattransition to the next uh one of yourpapers I really want to talk about butkind of the Epiphany I had when I waslistening to your explanation was I'vebeen thinking a lot about these crossencoders that take the query and eachcandidate document as input and they cankind of Reason across entity uhsimilarities and intend a little bit butso so kind of the Epiphany I'm having isit's about can we do some kind ofoffline computes because the crossencoder this is really slow to do thiswith you know and that's the problemwith that but if we can do some kind ofoffline computation of entity linking Ilove this knowledge graph embedding thisidea where maybe we can sync the linksacross the graph I think there is a lotof research to be done I don't like havea really concrete sense of how thatwould work but and then I think alsokind of likeadding entity mentions and kind ofpopulating symbolic filters because youcan symbolically filter really fast andall that so okay awesome so the next thepaper I'm so excited to dive into istitled perspectives on large languagemodels for relevance judgment and um soquickly I'm going toI'm going to I'm gonna uh in the shownotes or in the podcast quickly I'mgoing to edit and show this pictureof the collaboration perspective so thepicture okay so I'm I'm so excited todive into this I'm so interested in thisidea of using large language models touh you know generate queries fordocuments or label the relevance ofqueries and documents um can you pleasetell me about like how you think aboutall this okayI think first of allfirst of all it was a rejected paperthat will just like tossed out anarchive and tweeted about it and it'sprobably like now my most sighted andlike I'm like okayopinion piece like how about my otherwork okay wellum yeah I thinkmost people and I think there was likesome confusion initially where peopleare like looked at like we did someexperiments on um can you use like GPTlike completely replace human judgmentsand if you just do an ex empiricalexperiment yeah like Coral is actuallyreally well you knowum not always especially there are a lotof like uh entries where and that'smaybe actually very interesting pocketwhere um the user said a human judgesaid it's not relevant but like a largelanguage would say it is relevantand I think those documents are eitherextremelybad or they're going to be extremelyinteresting because they might pick upon things that like the human assessormight not be able to like identify justbecause they didn't knowum like here's my favorite example is Iasked a bunch of these models like howisum how is diabetes connected connectedin the relevant way to child traffickingand that's some that's actually aquestion that we asked like someassessors in like um a track track thatwe ran like a while back and most humanswould say uh probably not relevant sohere's what the large language modelscame up with they say oh no it issomewhat relevantum because I'm actually I'm guessing itI'll let you I'll let you take a guessuh maybe it would bea you'd have to take extra careyou see it's a negative I see okay sohere is what the larger English modelslike said and I don't know whether it'strue or not right but like I think it'slike interesting to considerum that is you knowchildren who suffer from diabetes relyon their medicationif you're trafficking children you needthem to do your biddingvery easy way to do that you will holdthe medication that like they depend onI mean this took a Doctrine very quicklyyou know butit's like an example of like oh my God Ididn't see this coming yeah againGoosebumps with this you kind of likewith something like that like and I'mkind of and I think it requires likemore study and research to kind of likeidentify well what is this pocket wherea large language model maybe like see aconnection but the human judge withoutlike any further knowledge and withlimited brain capacityum it's kind of like not seeing itI think maybe I was like this is likenot the most important fact to mentionabout like childhood traffickingalthough I think maybe it is you knowpeople should be warnedum but like it's certainly likesomething that's kind of like if I wantto give more information about let's saychild trafficking it's something thatlike deserves to be mentionedum and I mean a lot of the stuff thatI'm really excited about is like notjust to give like a short answer but togive like a longer answer right and thisis like where I think those facts wouldgo inum to come back to the original questionabout the using GPT for relevancejudgmentum I thinkthe the real title should have beenum why why you shouldn't use GPT forviolent judgments although it looks likeyou couldbecause there's like a lot of problemswith it like even even though it lookslike oh yeah it like lines up reallywell with like humansum there are a lot of problems with thatum like often we like to use judgmentsas being sort of like an independentarbiter and as as unbiased as we can beum so that when we develop a new methodit's not already prone to prefer onemethod with the other like here's anexample like we all so excited aboutlike GPT different GPT models are fromdifferent brands and so onum if you choose to use one to dorelevant judgments and then that's theone that like somebody is like using intheir methodvery likely their method might just lookbetter than another method that'ssimilar but use a different largelanguage models so you get like a realkind of bias that very likely onelanguage one just like it's have apropensity to like some model some workbetter than othersum just based on well this is like thesame thing you know it's umso that's kind of like one problem withthat umthere are other problems that could beum okay but why do you bother using likethese last language models to createrelevant judgments if they are so goodat identifying what's relevant why don'tyou just like use those as a as a as aranker they lose youam I backI'm back sorry about that hey I was justlike so exciting like just on the highpoint I get cut off oh no yeahnever forget my train of thought umokay why should you not use it well umyeah I mean like there's one thing aboutlike you know having uh propensities tolike one model then there's like anotherone method versus the other so youprobably wouldn't be quite as likeindependent now the problem of likehuman judges are also like not thatindependent there's like all kinds oflike other biases like when it comes tolike humansum another problem is well rather thanusing large language modes to createjudgments and then use a not so greatsearch model to like to train it or I'dlike to assess it why not just use GPTas a ranking model if it like haslearned everything okay that's like onethought um and maybe if you're whilewe're still staying with like the AIdriven modelsum although I hope we assume comingwe're moving away from that but as longas you're staying with that it's not soeasy to use as a rankerum maybe you can use like to generate afifth query and then run that against asearch engineum other people say well you still mightwant to do it because maybe that's tooslow so you can like train a fastermodel to do thatum so there's kind of like various kindof problems with thatumin the paper we go in like the spectrumof like we call it like a human machinecollaboration like it starts with likeyou just use a humanuh which like nobody in their right mindwould use they usually use a human withlike some very rudimentary support likehighlighting certain keyboards and so onand like you know Finding like stuffabout the same topic we try to group itso that the user can just say oh yeahthat's relevant oh yeah that's the sameit's also relevant so transitive closurekind of problems rightum like on the far end you haveum fire the human just use a largelanguage model and it just talked aboutall kind of problems in that but I thinkwhat's really interesting is like theSpectrum in between and that was whatthe paper really was intended to beabout even though most people justzeroed in like on this like far and thatit was just meant to be like atheoretical like let's see how well thatcould even work rightlike the spectrum between is like onewhereyou give the human like more and moremore supportum or you are used to human like toDefine what is relevant and you let theheavy lift even be done by some moreautomated method but like it's the humanwho defines this is relevant this is notrelevant okayum and then you can go further into likethe machine side where yet maybe havelike the machines like generate somerationales like maybe you can ask heyum explain to me why this is relevantexplain to me why this is not relevanttwo explanations now the human can readboth of them can say oh yeah I find thismore convincing right so being the humanas an arbiterum you talked about biases a lot like ofcourse that like introduces a bias rightlike I'll show you like what I saidearlier with the diabetes and childtrafficking once you see thatinformation you cannot unsee itand sometimes there's like interestinginformation which is not necessarily themost relevant information so this islike you really need like a specialtraining for for your human assessors ifyou want to do that kind of approach Iwould sayumyeah what elseum I think somethingthat could be very interesting is likeuseummaybe less for evaluation but actuallyas a method is to like use some of theauto generate like Auto regressive lightlanguage models to actually generatelike some pieces of text or likegenerate some hypothesis like what Ijust said for the human like this iswhere this is not relevant maybe you'reactually as part of like a searchtechnology you get a query you get abunch of things maybe entities and youcan ask for each of those hey is thisrelevant this is not relevant give tellme why you take those rationales youfurther kind of like throw them intolike an in-memory index kind of likeindex it on the Flyyou can solve like uh use some model togenerate some hypothesis of like whatcould be interesting facts while at thesame time then using search technologyto either verify oh is this reallyrelevant or uh if that's like a weirdclaim whether they come from they comefrom like some site that I likefundamentally disagree withuh or the user found that we disagreewith I should say then um maybe you wantto kind of like dismiss thisum and I think that could be a much moreinteresting constructive way to likereally work with like other regressivelanguage models umum and with respect to evaluation Ithinkum I hope that we will see like morework in the like middle Spectrum likehumans with like more automaticassistancesome more automated ones with like morehuman assistance like somewhere like inbetween I think the Spectrum often hasbeen like traditionally very likeunderexplored um like one thing that wetriedumif you were surprised it worked it waslike really an out there and outlandishidea was to instead of like havingqueries a collection and then askinghumans like is this relevant versus notwhich I'm not sure if you've ever triedthat it's a very annoying task to answerI can do it for three minutes then runout of patients I'm like veryinconsistent with myself sometimes I'mlike oh yeah this one's good that soundsno it's not really not wearing oh likethat sounds familiar I think maybe it isrelevant I don't know no I have to goback and do all the judgments myselfagain so it's like um quadratic grew upin assessments rightum like instead what we said heyespecially as a teacher hey just writean exam like here's a querywhat are the what are the importantfacts that I need to mentionfor in in stuff that's like relevant onthat topic it's a something aboutdaven's Voyage like you know in the inthe book that he wrote and some of thebig discoveries that he that he donelike about like genetics and so on rightit's um like you can say here this islike tell me about this and as a human Iwould say well you're for that kind ofparticular information you need I won'thave like this fact this fact this factthis factif I can write a multi-choice questionfor each of those factsuh and like then assume that multiplechoice question answering is a solvedproblemwhich I think hopefully most peoplewould agree then um you can just writeexam questions as a human to Definewhat's relevantI can train a question answering systemand then we can like ask differentsystem hey retrieve relevant documentsand we can check all of those documentsfor how many of these facts can aquestion answering system answerthe more of these facts the questions insystem gets right the more I believethat you are a good search systemso it's just like a very different wayof thinking about it um the paper thatwe wrote about I think it got rejectedtwice because people are like this isjust insane I was like yeah but look itworks like I don't believe your resultsokay like scientific methods yeah butlike um but like imagine this you cansort of like nowum use a human to Define what's relevantyou can use some other automatic systemto like do the heavy lifting while stilllike the human is still like in the boatand especially if you are if you'reworried about like biasing the Human byshowing them information you can justsay no the human first needs to come upwith the task like do your own researchlike come up with like tasks are reallyimportantum and now you kind of like have less ofa bias if that's like what you'reworried about by showing theminformation if you're worried about thatthe human might be missing things andespecially interesting facts that likeno human will probably think of in thefirst place you can then say okay nowread through all the different searchresults and then maybe think three moremaybe add a few more questions to it andbecause we have in the automaticquestion answering system or some otherkind of like machine learning methodthrough the heavy lifting you canactually run it again and again andagain and again and it will not likechange its mind on like this as wellwhat this is like not relevant um I meanof course your new question answeringsystem that answered the questions notfrom World Knowledge you're not allowedto memorize things you have to read itout of the text so this is like whereyou know lots of like theum reading comprehension work kind oflike now could really be like veryuseful here like as an evaluation methodyo um well that has so much informationabout it I'm firstly surprised to hearthat it has been rejected because Ithink this is such an impactful paperespecially from the perspective ofvector databases and search relevancystuff generally like this whole conceptwe've seen works like in pairs andpromptegator where you just generatequeries for the documents so then youknow like users of leviate can justupload their documents and then havequeries and now they have something tokind of ablate the models with so if youwant to sayyou know does the openai model workbetter than the cohere model you as youmentioned like annotating the relevancejudgments yourself is like maddening sohappening having the models to do it andthen you've identified this kind ofspectrum of how you would collaboratewith the uh large language models forannotating these I think that's probablya pretty promising startup category iscreating the musicthese kind of things I haven't leftgiving my ideas away for free like I'mnot I'm not in the market of startups Ithinktoo but like um yeah and I think this ismaybe it's kind of like veryyou know we're all kind of like verytechnical like technology oriented andmaybe this is like sort of like whyeverybody like gravitated to the rightside of the extremeum I'm more like in the in the middleand I think like the the paper is I meanlike it's not just my paper like it'slike um 12 really like well-known peoplelike in the field like thought and wedisagree with one another in ourdiscussions and like if you look at theend of it they're like sort of likethree opinions initially we thoughtthere would be either you you yes youthink we should use more llms like infor evaluation or you should not thinkand if you look at it as actually morepeople came out on the side like nolet's not do this right now and likesome of those might be maybe uh notright now but some people even thoughtmaybe neverum because of various kinds of likeissues that like come along with that soit's really like a paper like like andwants to caution people and not justlike saying this is what it isum and I think this is also like whereyou know identifying like should we useor should we should we not use it Ithink also for the research Communitywould be like very important to kind oflikehave a discussion and get some clarityon like what do we as a community thinkshould be done but it should be not doneum because you know we try to writepapers and like the thing I'm reallyworried about is where as a as a paperauthor you try to do everything rightand now if you end up using automaticjudgments or like some other halfautomated judgmentsyou get rejected because like somebodysays no we should never use thatand now if you don't do that then peoplewill reject your work because they saywell you haven't done that everybodyshould be doing this right and I thinkthis is sort of like I call it like areviewer standoff and I think that'skind of likenot healthy it's just like of like maybewhere you know the people I'm sometimestalk about the toxicity and researchCommunity that's why it's like one thingbut I also think like by uh talkingabout it and having a discussion andmaybe having a consensus maybe also likehaving a consensus forming discussionlet's put it this wayum it's really like important to do thislike right now you know the same thingthat you know currently have all thekind of teachers being like uh like uhlike ripping their hair out over or howdo we keep our students from likeillegally using uh language models fortheir homework when we actually want tolike test what they're doing right thisis like a big debate and like don't feellike nowhere we should be like comingoutand I think this is like another debatethat we need to be having uh we arecurrently like not havingum and I think it's uh it's somethingwherewe need to kind of like develop likesome way way as a community like whatcan we agree on or maybe we can at leastagree on that like work that does eitherof those is still okaylike best practices and I think part ofthis is like probably in in five yearsfrom now we will be like uh smarter inboth of those areas the educational partand the and the evaluation partum but like right now it's a little bitumwild westbut it's like uh dancing around tryingto figure out where they where theystand now in 2023 I said it's a greattime to be aliveyeah well you've given me such a newperspective of thinking about this Iwould I started out so bullish on thisidea that large language models shouldjudge relevancy because I just see thisproblem where like from maybe more ofthe industry Stan uh perspective wherepeople come to aviate with like aknowledge base you know your slack orwhatever it is you just have documentsreally you don't really have queries sothis notion of just generating queriesto me I was just so certain that thatwas going to be productive hold on can Ican I interrupt right here so he's likegenerating queries right and you know inthe yaya Community various people havelike tried to do that one as well likehere's a corpus let's generate queriesum I think that the idea of like what Isaid with that the human write an examand let the exam like automatically thengreat things but the human is still incontrol of whatsoever what's notrelevantum I mean they're sort of like similarwork done in summarization because likein summarization you also have like asimilar problem where you want to knowis this a good summary this is a badsummary right like and people actuallyhave also like worked on trying toautomaticallyderive questions from like a goldsummary that's like you know their theirrelevant track is just a gold summaryokayum the problem that I see with that andalso like they see some of the metricsthat kind of like combine these thingsis it's from a text it's very easy togenerate questions or queries which arenot that interesting all right I meanespecially if you use like a methods ofyou take something you know this text islike relevant or it's the right summarythenum you kind of use triples and frompurple like uh um you can say likeBarack Obama married to Michelle Obamayou can now like turn that one aroundinto like a question or query like uhwho's married to Barack Obama and theanswer is Michelle Obama okaybut if this text is about like somethingvery differentand it's relevant not because these twoguys are like married to one another butabout something very critical that'slike in there now the question will likenot really get at the core of what'srelevant like this is whereum in my work we were like flippingaround they said no you don't start witha text and you generate a query or aquestion from it but you start withsomething somebody wants to knowand now you do something that is I callit like a Humane a Humane use of humanassessors like these exam questions andthen from there you can automate theprocess like I call this Humane becausein some ways it's a lot more natural fora human to like say what's relevant inthis case then in the other case like ifum I don't know if I may but like nexttime you had a customer that comes toyou with like their slack chats and saywe want to retrieve over this oneyou can maybe sayum maybe like what are like uh what arecritical priorities of like why you needthis search for right but like thingslike give me a few examples of what youwant to know now give me in how can wecome up with like a test of what is likewhat are the things that you actuallywant to know uh versus like some stuffthat gives you keyword matches rightlike and I think you can like very it'svery easy to convince users that whatthey say they want it's not what theywant by just throwing them a littleprototype you say oh you want thekeyword matching here keyword matches doyou think that's relevant that's why nono no either say the first time you findyes okay so we need to like work on thisto make all the stuff that you said noto go away and all the stuff so you saidyes to like come up okay and now we cankind of like look at well why is thisthing relevantand from there you can now do somethingelse you can preserve what is relevantand why this is relevant like maybe morelike a rationaleum homeless rationale you can now takewhat we what the what your customerssaid they wanted to knowwhat was value and address is notrelevant and why is this relevant youcan now give that one to like a largelanguage model and from that one you canlet the large language model to say wellif this is relevant then this this andthis is also relevant because it'srelevant in the same senseso it's a lot faster than having a humansay yes no yes no I mean it's also likeevery mind I mean if you have to readthe same kind of facts over and over andover again it's just like one of the mycurrent problem was like search engineis like I'm asking for something getlike 10 documents that are pretty muchlike identical in the informationcontent so why do you show me at leastlike other documents to show medifferent documents rightum and that's like also like where byrelevant judgments also mind I meanbecause it's just like the repetitionimagine you have to watch the sameadvertising spot again and again andagain and again maybe you haven't madethat experience before okay so it's likeyou just like become to like hate thatinformation you're like please get meout of that hello please show me anyother advertisement from the 70s so atleast I see something elseum and I think this is like wheretrying to make the relevant assessmenttask less mind-numbing by using likeartificial intelligence in this likevery very particular way while stillhaving the human being the driver's seatand saying this is this is not relevantum I think that's really like where thefuture is and I think the future isn'tthat far away like uh it's not like anecessary I mean there could be alsolike more I think I wish more academicswould be working on that but I thinklike even from industry it's not thatyou need somebody to like reinvent likeand invent a new wheel for you right Imean this is just like it's just like asimple idea it's like a conceptum that you can run with and as I said Igive my ideas away for freeuh amazing I mean yeah I I I I love thenew ones that like justlike I love the perspective just to takeanother nugget out of the paper justlike where you have the relevance notrelevant and you have two and then youhave like a higher level thing thatjudges it like I originally think wasthinking of things like the Lang chainwhere you have like the chains ofprompts and so it kind of generatessomething and then reflects on what itgenerated with the but yeah justeverything you're saying there's so muchNuance to doing the relevance labelingmaybe quickly if I could pick like I wasI was thinking about like well yeah likewhen you generate a query maybeclustering these queries and embeddinglike does this document also answer thisqueryI think that's actually something maybelike just like a criticism I have andlike most IR benchmarks is that like wehave one query here one Curry here onecrew there we'd like have them likesample we usually try to sample fromlike you know the whole space likeanything anybody would want to know andvery rarely do we see like two queriesabout like similar related topics rightum but and I wish we had like more ofthose because I think if you are ifyou're real at search engine company andyou're like have like query logs youprobably see that uh there's like thingsthat people like want to know about andit's gonna be like pretty much like thesame the same the same and sometimesthey're like different like nuanceswhereas in good like different differentdirectionsum like we and we wrote a paper aboutlike a crew specific subtopics wherewith the idea of like actually trainingyourself to like identify differentTopics in search results not like withclustering team IDF clustering or liketopic models which where we actuallyhave some results that it does reallylike not work it doesn't correlate withwhat's really relevant to us it's notbut like we actually trained to pick outreally these like very detailed finenuanced topics and like one of myfavorite examples is to like just toconvince people that it's not justgeneral topics it's not just like here'sa set of document cluster them but it'sabout uses of documents that we retrievebut this is the information need thatthe user really want to know about theyactually can change the clustering islike one about you know you have liketwo queries about like covid-19 one issort of like about something where youwant to know like uh what was sort oflike big problems for like peoplepersonal problems let's say maybe likethe loneliness or maybe like being uhlike uncertain about the future you knowlike two big thingsum but another one would be about likecovid-19 sort of like measures and likeum like treatments right so you can haveimagine you would have like prettysimilar documents that are relevantabout both queriesbut the subtopics that make themrelevant they're actually very differentand that that's kind of like why I callit fine-grained and it's like topicsbecause you know it's like a a um youneed to identify what what the logicalsubtopics once you have the subtopics Imean that also like falls together withwhat we just talked about with relevantjudgments right like probably once youhave these subtopics if you put onedocument that says this is relevant thenyou actually want to like look at theother documents right away and say ohthese are actually also all relevant ormaybe not if they're not relevant that'sa sign that maybe the subtopic detectionkind of like wasn't quite correct andyou need to give you like more trainingdata into that right but again it's sortof like another way of like integratinghuman ancestors of like what's relevantor like what's topical and like whichtopics are relevant versus Whichdocuments are relevantum and with like some elements of likemachine learning which like so far itwas likeum it was kind of like as it would belike a taboo like you're not allowed touse machine learning in in relevantjudgments and I think it's like as yousaid like for for companies it's likeit's just like not reallyum financially feasible but also foracademics I don't think it's necessarilythe right idea because it's it gets likevery very expensive to do judgments forand then you have like a few queries andyou really don't have enough judgmentsto like train one of the heavy-dutyneural networks anymore right like youneed a lot more training data and thereneeds to be a compromise that we need toexplore and I think that's kind ofsomething that will help like bothindustry and academics to like moveforward but again we need to alsoovercome the taboo and like the academicworldhmmyeah just amazing uh so yeah that wassuch an incredible tour of theseConcepts I feel so much so mucheducation from uh both the neurosymbolicunderstanding the knowledge graphs aswell as this concept of the largelanguage model relevance judgments andjust wow there's so much depth to thatand this conversation just really openedup my understanding of it and theacademic thing wow it's all just sointeresting so uh Professor Laura Dietzthank you so much for joining thepodcast so knowledgeable you have such alike an entertaining and energetic wayof telling these stories and it's reallyawesome and so uh maybe before we uhwrap it up is there anything you'd liketo maybe um tell people to look intoI thinkyeah maybe one thing I think like at themomentsomething that like I don't want toquite say annoy me but like give me alittle of a pause is like how we talkabout technology and in particulartalking about it in like alife or death situation like you findlike people will say like oh the AIoverlords are coming and then we havethe other side says oh these are juststochastic parrots um like that'ssomething we're afraid of and I thinkit's very difficult like I usually findmyself in the middle of all of this I'mlike you knowum I don't think it's just stochasticparrots but I also like don't think thatthe air overloads already are here Imean like it's not I mean I understandthat a lot of people were likeblindsided by the by the development butlike it's face it you know I mean likeopen air has been working on GPT modelsfor like the last decade and I think ifthey really really deserve somethingthen it's like kudos for just stickingwith it like every academic willprobably have given up a long time agoand you know they were like ridiculedfor like a bunch of like models like andthen I remember the last time with gpd3it was like in the New York Times andeverybody's like freaked out and thenpeople looked at it more more carefullyit's like no you know this is actuallylike not that great good yet I mean it'ssomething to it but it's also like a akind of like an element ofuh saying you know this is like amazingand not just like trying to pick itapart as in yeah this is like oh looklook here's like the all these differentChronicles it gets like wrong I'm likewell how well is your method drawing onthis right like this summarizationmethod like oh you're a co-generationmethod like how good is it and are youeven like close to that one and like Ihave to say for me probably not rightbut it's also like you know there's alsolike clearly like things that we likestill need to learnum but then there's like so muchopportunity that this technology likegives us without kind of like going intothisum fear-mongering oh this is like allsuper terrible and like oh I have tolike leave the company now it's like notfurther not further this kind of likeevil that they're about to like breedright thereumum and I think that's kind of like oneproblem I think on the flip side wherepeople are not afraid enough about thissort of like user tracking I'd like Ithink um the number of times I had likeconversations with my friends onFacebook on not filling in these likesocial engineering posts and then nexttime they just do it again that's what Ithink where the real danger is and Ithink it's not gonna change unless weall kind of like do it a little bitdifferentlyyeah I mean I guess uhuh on the on the social engineeringthing I guess kind of the concept of itjust being very convincing so I guesslike there was a lot about therecommendations and how that would putpeople in kind of like a politicaluh what do you call it like uh whenyou're TR like a rabbit hole where yeahwhere you're just seeing what you wantto see and then there's just Echoes andyou never hear anotheryeah yeah sorry but yeah and I I thinkum I'm curious what you think about likethe kind of in the in the what hasinspired so much of the AI uh overlordsare coming hype uh what do you thinkabout kind of like the auto gbtv theability of it to kind of decompose tasksand then use memory and I think it'ssort of uh a pretty in it's a prettycrazy jump it seems to me at least thatlike now it can come up with an actionplan and like execute this action planand it's like connected to the Internetwith with the chat gbt Marketplace orlike the Lang chain tooling now I canwrite emails I can write so on theinternet it might as well be a person itseemssure but I mean it's like again like ifyou look at if you look at GPT threefrom like you know like two years agowhen was itI mean it had like you know this um thisthing of like being able to likegenerate text so I was like I forgotlike her name she kind of like co-wroteuh was it a book or somethinguh about her grief with gpt3 my gpd3would just like put out like rationalesmore or less and she would like thenedit it and so on and I think this isum you kind of and it's we're stilldoing the same thing it's just like wellthe quality got betterbut this is also like you know we figurethings out and I mean sure you know likeif you look at uh I'm not sure whetheryou remember the first iPhone you know Iwas like oh boy copy and paste right soI mean and look at the iPhones we havetoday or like other smartphones I wantto name any Brands but like um it's likeof course you know you kind of likeslowly figure things out if you look atChain of Thought prompting for exampleright like I mean it's it's not that youhave it's not a new mathematical modelit's just like a different way of usingit and we know that from uh gpt2 whichis you know like very old right we knowthat that actually was working reallywell in this like few shot settingright which counts like now I meanthat's like what Chain of Thoughtprompting like falls into and like weknew that well maybe gpd2 like out ofthe box with like direct answer itwasn't the best but really like at thetime people said you know what actuallythis is actually not bad technology ifyou use it as a future prompting and Ithink the instruction based method isjust sort of like a logical follow-up ofit like oh let's maybe prompt it withsome shots and not just like clear thesession and throw it away but like maybelike preserve this right like I thinkit's sort of like a over time it's likeuh it's not that um there was like thisone big thing that just that suddenlyappeared overnight no it's like it'slike steady amount of work over a decadeby by a bunch of people and then therewere like some people had some new ideaslike oh look I found this thing or likeme saying oh here was the thing wedidn't think will work oh my God itactually worked actually pretty well andlike what does this open up and the nextperson like learns from it and say ohnow we add this one here and this onehereumI think this is like where uh umwhenever we give our touring Awards wealways like pretend that there's likethis one or few people who kind of likedid it all by themselves but like inprice it's like never the case rightum and I think this is also like whythis development wasum like kind of like observable rightlike I think maybe if people likestopped looking after they played aroundplayed around with like gpd3 once ortwice and then said like yeah okay likethis is like neat but like it's not yetready uh you just like don't keep an eyeon the development and then you getsurprisedbutum I wouldn't say that this is likesomething where overnight our machinesbecame intelligent I think over the lastdecade Bit by Bit by Bit of machines allmachines became more intelligent andmore helpful to uswell I have one more on I have to giveyou a take on this with the for the sakeof ref perspective for those listeningthe last podcast we did or I don't knowwhat the order but the podcast with Bobon generative feedback loops the entiretranscript is 13 000 tokens I imaginethis podcast of Professor Dietz isprobably about 20 000 tokens am Italking too fastso the whole transcript of everythingwe've said in this hour and a half isprobably 20 000-ish tokens so these newmodels like gbt4 with 32 000 tokeninputs or the Mosaic ml MPT that do 65000 token inputs I mean what what can weexpect with thatI think you know and that's like a veryold machine learning Mantra like themore training data the betterum short ofuh well the training day should becorrelating with the task that youwanted to be good for right like umgarbage in garbage out of course alsoholds hereumI think part of this I mean I don't knowI I don't I don't talk to I mean I don'tknow the details about any of thecommercial available models but like myhunch is that they probably now haveconsumed the whole internet and and somemoreum and like this is where we are rightnow and there are still problems so Ithink next thing we need to do is to bea little bit smarter in spending ourtraining data wiselyum then I hear things like uh severaltrillionparameters and like the machine learningis likeuh do you have the training data toserve up on thesedegrees of freedom right like andum and like the third part of me thinksis like you know like all the like allthe regressive language models I thinkyou know it blows my mind how well thatworks Idid if you had asked me like a decadeago whether this is like the right wayof doing everything I would probably sayno probably not okay so kudos to themum but I also think that it's probablythe right architecture like if you lookat the architecture underneath it andhow it learns it's the rightarchitecture for anything that's alllike generativebut not everything in the world isgenerative I think at the moment peoplepretend that it isum and like maybe you can turn a lot ofthings into generative but likethere are other problems that are notnecessary about like all the regressingwords word by wordum like as I said initially withretrieval metric learning right likebring the things that close togetherthat are that are relevant bring themfar apart if they're like not relevantbring things close together when they'reabout the same subtopics bring them farapart further apart when they are likeabout different sub topics right you canwrite build up a spaceum this is not necessarily how otherregressive language models work rightthe question now that I have and that'shonestly a research question iscan we do with fewer parameters byhaving maybe a let's say medium smartlanguage model not one that likememorizes all the facts but maybe onethat maybe can like Leverage searchengines more effectively and if you seethis with you know retrieves augmentedgeneration and so on rightumbut like can we maybe also do that withknowledge graphs and so on and we seethat like with the the tool Integrationsthat we now have like in open ai'sproduct tool rightcan we maybedo away with some of the latentparameters that are currently being usedin kind of likejust like teaching like using languageas a means of like expressing thingsexpressing search requestsinterpreting what the user wanted toknow interpreting what we see andbringing that one together rather thanjustlike sort of like a like a student inclass like I know the answer I know theanswer but like can we maybeum trained like a machine the way thatmaybe we humans would like uh or sayinghumans would do that I mean the humansthat memorize phone books I'm not one ofthem so I need I need to look up thethings again and again and again againbecause it will not stick in my brain sois there something is that maybe like adifferent it's a very different approachum and like given that it took uh openAI like a decade plus like get to thatparticular to really fine tune all thearchitecture here I don't know maybewe'll take anotherfive six years like to rock oncompletely alternative approaches andthen we will have to seeum which one actually ends up getting usfurther tomaximum usefulness let's call it thisway right so it's sort of like they'relike other architectures that kind oflike might maybe be worth whileexploring but then uh again we end upwith the researcher standoff wherepeople say unless you compare to thisthing which is like overly tuned andlike forced and Polished we don't wantto hear about you we don't want to hearabout your ideas I was like well this islike this way we're just gonna be likestuck in our little research Optimum andall computer science professors willform this point forward be condemned toonly ever do prompt engineering which Ithink would be probably better be donein the humanities department but likeokay but like I think this is like wherethe news is still out on like whetherthat is the only architecture that youever need or whether they're like otherarchitectures that might be betterbetter as in like requiring like lessthree less fewer degrees of freedom uhrequiring like less training data usingthe training day like more effectivelyand doing something that are kind oflike they're just like the architectureis better matched like other tasksbecause I think not everything is likeother regressive generationbut it could also be wrong you don'tknow uh we should meet again in like adecade and then I can say when I waswrongyeah that sounds great uh yeah amazingso Professor Deeds thank you so much foryour time this is such an awesomepodcast and thank you everyone forlistening thank you Connor", "type": "Video", "name": "Neurosymbolic AI in Search with Professor Laura Dietz - Weaviate Podcast #49!", "path": "", "link": "https://www.youtube.com/watch?v=2s_GGMZ_Zgs", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}