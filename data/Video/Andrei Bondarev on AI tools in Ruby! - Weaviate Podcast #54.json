{"text": "Hey everyone, thank you so much for watching the 54th Weaviate Podcast with Andrei Bondarev!! Andrei has contributed an ... \nhey everyone thank you so much forwatching another episode of the weviapodcast I'm super excited to welcomeAndre bondarev Andre is uh works atsource Labs a consulting firm and he'srecently built a ruby client for wegateand Lang chain so I think this will besuch an interesting podcast diving intoyou know the the nuances of uh AIsoftware Consulting with these new wavesand deep learning tools like you knowLang chain leviate and obviously likethe llm apis and all these things soAndre thank you so much for joining thepodcastthank you hey super excited to chat withyou today awesome so could we kickthings off with uh Source labs and sortof what you're seeing in the kind of uhConsulting space with the new uh AItoolssure uh swearum sorry we're on a small softwaredevelopment firm uh it's called Sourceslots uh so we build custom applicationsTechnology Solutions for uh small mediumbut also large Enterprises so we workwith both uhuh venture-backed startups uh we workedwith Y combinator uh companies TechStars uh accelerated companies but alsowith uh all the way through Fortune 500companieswow that's interesting um I haven'theard too much about like um this iskind of like a like a like a stat I'veheard of like Staffing contracts wherepeople need to build some like say youneed to build a weba database so youwould you know a start up like a ycombinator startup would hire thesefirms to like quickly build the newtechnology can you maybe walk me throughmore about like what the business ofthat looks likesure so we don't uhwe we do some staff augmentation wherecompanies just want to pour more fuelbasically on the fire and kind ofaccelerate the development of theirtechnology oruh the execution over technology roadmapbut we also love to do Greenfieldprojects and and kind of come in andassess what the problem is what are theoutcome what are kind of businessobjectives you're trying to reach andand how to how to get how to get youthereum and we've been uh this year we'vebeen especially hyper focusing on AI uhML and llms of course yeah I'm superexcited to dive more in into the AI thenew kind of Stack that's the emergingbut quickly could you tell me likeum like maybe for you know entrepreneurslistening to this podcast like how didyou get into this kind of spaceyeah so actually uh we just finishedexecuting on a large uh project for aclient uh I'm not going to disclose whothe client is but it's a uh it's awell-known public companyum and they have a set of toolsum that they builtum that provides the data analyticslayer on top of public policy bothNational and globalum all around the worldum so public policy like laws rulesregulations Etcum and we just concluded in a massiveproject where we rebuilt our whole kindof application and a large part of itwas rebuilding their search engine uhand so we built that inum uh in the last six surgeum and we did both the the front end theback end work the setting up the datapipelineconfiguring the indexesuh the apis ETC andum as soon as we finished it uh latelast yearum I kind of uh came to a conclusionthat you know what we had built isessentially kind of outdated nowum and this was uh hap you know andas as the vector search database haskind of started uhbeing uh very popular in the marketum you know I figured thatumbuilding a purely a keyword searchuh is uh as a as a core feature of yourproduct is no longer very attractive Imean uh when you're building a searchexperience now uh you need to make surethat when a user interacting with yoursystem your large data setsum that the system also understands theintent the the meaning and what you callthe the semantic search uh and this kindof led me down the path touh explore the the current capabilitiesthe current systems the vector searchdatabases uh and I I discovered weeviateand prototyped a couple kind of petprojects with weavateuh so I love hearing that backgroundI've learned so much from like uh thepeople at open source connections andthat that whole Community around and uhByron vorbeck has recently done a talkon from keyword to Vector at Berlinbuzzwords and this kind of evolution ofthe uh the way I understand it is thatelasticsearch was quite a massive thingand you know a lot a lot of Consultingdeveloped around helping peopleImplement that and add key research andnow this this kind of the shift toVector search and yeah I've done allthat so interesting I love the TheMention Of You know the semantic Surgeand fuzzy meaning intent understandingall that kind of uh like abstract stuffbut yeah so quickly I think kind ofstaying on this topic um with yourtransition into Vector search what waskind of like your Eureka moment likewhat got you over thereum again uh some of the some of yourproducts I've I've prototypedum it it seemed likeum you know I didn't when I'm searchingthrough a large data set as I mentionedum I no longer have to search for exactkeywords uh exact keywords that arefound in in those data sets right I canI can search for synonyms and similar uhsemantic Concepts right similar Conceptsthat are uh Concepts that are similar inmeaningum and get to information that that Ineeduh and I've really enjoyed I've reallyenjoyed we V8 uh so I've looked at acouple different solutions I reallyenjoyed we need like I love the modulesystemum so I kind of I I like how it's uhit's an end-to-end solutionumand there's a lot less uh there's a lotless Plumbing that you have to do asopposed to as opposed to some of thesome of the other Solutions andum and uhmy my uh tool of choice although I'veplayed with a lot of different languagesthroughout throughout the yearsthroughout my career my tool of choiceuh has has always been Ruby uh I lovethe language I love the ecosystem andandum kind of my my journey into the vectorsearch and the open source work uhuh was kicked off by by me just writinguh a uh we V8 uh API client in Rubyuh that's super cool really quicklybefore I obviously we're gonna dive intoRuby and that's so interested in theclient um so it sounds like you knowyou're exploring these new tools and Ilove to mention the module systembecause I think it'll tie so nicely withthis as well as I want to thenunderstand uh how you like came intoLang chain and sort of your earlythoughts on using thatyeah so obviouslyum it's not a I I think the space is soum is so young rightum and people are prototyping and and uhpeople are doing a lot of prototypingand exploring different approachesum it's not exactly a plug and play justyet right so some of the things you needto think about when you're indexing yourdata into a vector databases like thecontext window for example right and howdo you determine the perfect uh contextsize how do you split up your data rightA lot of times you can't just split onuh a certainuh characteruh uh limit threshold uh because you youkind of lose the the semantic boundariesright so for exampleuh you know a lot of times like whenyou're searching for an answer uh ananswer might be a combination of thedifferent different chunks uh differentchunks of data so so there's thatproblem it's very chunkingum and uh also there's a lot of kind ofunderlying configuration uh that needsto be set up when you're configuring thethe vector search databases like the theuh the what what kind of embeddingsyou're using uh what kind of uh whatkind of formulas you're using whetherit's cosine or dot product to kind ofcalculate the uh the similaritiesyeah I think uh something like um wellfirstly I think I'm curious about thetext chunking things and the solutionsto that offered in Lang chain sort of Iknow about like the recursive charactersplitter that particularly I think it'syou know likedelimiters that are cooked in like ifyou're splitting up python code or stufflike that or markdown where it looks forthese particular symbols and and thenjust has the 512 tokens but uh is theremore and you know it for maybe a littlemore context in the wevia podcast we'vehad Brian Raymond from unstructuredwho's presented this idea of you knowusing these like visual document parsingmodels to maybe extract the structure oflike you know this this chunk of text isan image caption these kind of thingslike like what are kind of theInnovations in text chunking that arethat you're seeingyeah soyou can actually so one approach I'veseen uh and you know I think I thinkfolks are coming up with new approachesuh weekly uh one approach I've seen iswhere you would actually feed some datato an llmand and app and prompt it to suggest thechunks based on based on uh the meaningthat that body of text representsumalso uh you know one approach that we'reexploring within uh the project that uhwe're we're going to talk about shortlyuh link chain RB is is actuallysplitting up on uh on a custom functionso for example passing passing a Lambdapassing up function and then writingyour logic uh that would split the textumwhen it's being parsed right so oneexample I'll give you is for example uhif you're importing a legal documentright and it has several differentProvisions uh you know intellectualproperty non-compete in terms of serviceuhEtcso for example you can uh uh youprobably want to split that document bythose specific sections and it's not youcan't configure a set character chunk uhbut you could say that uh as the text isbeing parsed right if you encounter thisstring which is uh an enumerated headingof that contract section then slice itright uh so that's another approachyeah I think we we get lucky with likeweb pages where you'd have like that youknow like angular brackets slash UL orat the end of a list and then you knowright don't split this list into twoseparate chunks for embeddings but yeahas you mentioned just kind of detectinglike that kind of shift from free textlike if it's um yeah like laws and itstarts like the new the title of a newlaw and so you know and the chunk evenif it was only 100 tokens then it's justnot just like a 500 token window and soyeah that's super interesting and Ithink one more topic on Lang chain Ithink actually it makes sense to kind ofcover this before coming into the Rubythe Ruby ecosystem particularly is sowith Lang chain you mentioned um youknow the configuration of the embeddingmodels the configuration of the vectordatabases uh so so all right myunderstanding is you're seeing the valueof a framework like Lang chain as itlets you you know rotate out those kindof things is it it's like theI don't know what a good word for thatis but it's the orchestration behindOkay cohere has a new embedding model soswitched out with open AIS or you knowalleviate you know want to tweaksomething here so you can easily tell memore about how you see thatyeah so I I think there's always uhthere's a lot of benefit about uhuh about using an opinionated frameworkright and actually again we're going toget to uh the Ruby World shortly uh alarge uh part of Ruby development is uhRuby on Rails right so building uh webapplications uh apisuh in a extremely opinionated frameworkright and that's and and that's andthat's uh that's why and how it uh ittook off and became so popular becauseyou didn't have to think about all theselow-level decisions rightum the whole approach was that hey we'veyou know we think these this is the bestway to build 95 of the uh webapplications you know it covers 95uh of use cases it fits 95 of the usecasesuh and and this is the opinionatedframework that uh I think would workreally well soum so they so I'm drawing a parallel tobuilding llm uh based applications isthat I think uh developers uh can alsobenefit from this opinionated approachyeah I think that's the um in ourpodcast on llm agents um uh Colin Harmanwas describing this idea with likesymante Colonel and how it's a littlebit more like decided on you know theseare the these are the abstractions andand rather like whereas contrastively uhllm framework like Lang chain is alittle more open-ended where it's alittle more open source Community Drivenless of um you know a rigidconsolidation of you know these are thetools to use it's more the discoveringyeah I think that that whole thing is areally interesting uh just thinkingabout like what is a software frameworkgenerally as like kind of a marketcategory what kind of thing does itstrive to do I found that learning aboutthat is all really interesting I'm supercool so I think it would be great todive into Ruby and I'll try my best tokeep I know a little bitum yeah so as as I've mentioned uh Rubyhas been uh a tool of choiceumof mine for a very long time I've trieduh lots of different languages uh andkept coming back to Rubyuma lot of people talk about developerhappinessum uh and I will also mention that uhIt's always important to use the righttool for for the job and and I foundthat uh the problems that I that I wassolving that uh Ruby was was was uhgreat at solving those problemsand soumRuby's still very popularum there's still a lot of companies allaround the world using Ruby uh they'rebuilding they're supporting maintainingexisting products or starting andbuilding brand new applications in withRuby uh obviously Arabian rails is uhhuge within within the Ruby communitysoumIthought that as as a ruby Community weought to have uh a solution for buildingllm based applications uh becauseum as as thisumAI wave uh has been kind of rolling inum I think product managers are comingto their engineering teams now and areasking hey we're aware of thesecapabilities we'd like to add some ofthese capabilities to our existingproductsum here's a business case for ithow can we accomplish this right andthen as engineering leadership teamleads Architects uhuhthey have to decide whether you uh addpython right as kind of the most popularlanguage within that space in the mixum and if you do that you need to you'respinning up additional containersadditional compute uh separate Servicesright you have to figure out whether youwant to support additional complexityadditional overheadand also whether you have capabilitieson staff to do thatum or uh if it's a ruby shopum whether you'd like to uh use asolution that your engineers would befamiliar with rightum and I think there's also and this isthis is a uh uh a larger conversation Ithink there's alsoum kind of uhuh people are reflecting on and on allof these complicated uh microservicesarchitectures nowum uh this this path that uh we as uhthe software development Community haveuh gone downuh people are looking at all thatcomplexity and and are you know thinkingtwice now before uh before doing thatum so I I see a lot of people kind ofconsolidatinguh their architectures into into amonolith uh into a model of uhapplication architecture because it'sslotum uh a lot of times it's a lot easierto manageso taking it apart a bit because I don'tunderstand this too well so amicroservice architecture is where youlike containerize every function andturn it into like an API and then it andthen the system interacts with it thatway and then that way if something's inPython it's you know it's just acontainer with an API so it'slike whatever compared to where a modelis where the whole thing is in Ruby soyou put it in and it's all oneapplication right right right right uhanother way to to think about it is uhthe microservices architecture is whendifferent parts of your applicationum arestrung together uhuh by Network boundary basically haveNetwork boundaries right so from onecomponent of your application to talk toanother component of your application uhthere needs to be a network call rightuh and you know it needs to be a requestfor example Over The Wireum whereas a monolith application iswhere different a monolith architectureis where different parts of yourapplication different components of itare are hosted within a single uh withwithin a single kind of memory unitso then you know where with my deeplearning hat on I'm thinking about likemodel inference serving and so are youable to I know like theyso I I know a little bit about likebindings where you could you know likeyou can have the inference in C plusplus and it can have python bindings toit can you so can you do that kind ofthing to run inference of a deeplearning model within Ruby so that theinference lives in the same applicationumso any any of those libraries wherepython wraps uh underlying uh Cfunctionsuhyou can theoretically rewrite those samelibraries in Rubyum and and call into those same Clibrariesumyou know does it does it make sense todo that uh you'd have to think reallycarefully about that yeah it's sointeresting I mean I guess I'm justthinking about like umI guess like some some things withweeviate it's like I think about if wecould have like a model inferencedirectly in the database compared todoing networking requests like if wewould want to just like to throw out anexample like if we wanted to do thiskind of like re-indexing idea where youhave a model and now you fine tune itand you have a new model and you want toupdate the vector space like if we coulddo that inference directly and we getthat's what kind of motivates me askingthis question about like when you wouldbuild in model Arc model inference intosome kind of software architecturecompared to uh you know like APIrequests across the wire and uh I guessit's like where my head's at with thatkind of thinking but uh pivoting topicsa bit I'm really curious aboutlike clients in general like you know aruby client on top of a database how doyou think about like database clientsum well uh so for example in in uh if wetake if we take we V8 rightum so you guys currently have a uh anarrest endpoint and HTTP arrest endpointum and aum for schema managementum also indexingum and largely the capabilities forquerying the database are uh there's agraphql layer in front of itum and I don't personally find graphqlto be super convenient uh in in terms ofconstructing queriesum I think Json just just feels a lotmore intuitive but alsoum more in line with kind of the datastructuresum that are native to differentprogramming languagessoyou know actually and that's that that'sexactly the reason whyum I uh initially wrote the the Wii V8uh Ruby API client is to abstract awaysome of those complexities likecommunicating with a graphql clientumso so because like I know with pythonit's like you get back the request thenyou parse it where you're like you knowdata get so like they're they're you youinstead of have having to unpack the theJson that comes back from the graphqlyou already kind of parse it out andthen and and then you just create like asyntactically nicer kind of interface tothe database is that generally the idearight right correct so I think the othertopic uh is you know I understand verylittle about this Eddie and explained itto me and I just kind of nodded along inthe podcast like this difference betweenuh like graphql rest API grpc apis likelike what is really the difference I Ijust kind of for me I just think aboutit as like what the input output lookslike yeah so it's it it's basicallydifferent uh communication protocolsuh so grpc there's a couple differentFrameworks uhI'm personally most familiar with ApacheThriftumandum it's it'sumit's quite flexibleum you can configure uh you canconfigure uhyour transport layeruh to send data in lots of differentformats uh binary uhJson uh Etcum I find I've found that it's a littlebit challenging to debug actuallyumand it's also there's there's alsoum an overhead in in maintaining itbecause basically the way it works is isum uh kind of the the API server the APIhost declares an interfaceum and then you compile that interfaceintoum uh client libraries and so you needto make sure that all of the clientsthat communicate with thatumwithout server have the latest versionof those client libraries so there's alittle bit over overhead in terms ofmaking sure that all those client clientlibraries are syncedumbut there's also there's also benefitsto using a uh jrpcumto string Services togetherum you know I think I thinkum uh the obviously the the most commonway of stringing Services together isstillum is still uh HTTP uh Json apisum and I find that to be uh most uh mostconvenient to kind of program againstmaybe just like a quick thing out of Iknow extremely little it is there moreopportunity to kind of innovate on thatwith respect to likebecause I've heard about like streamingTechnologies I also don't really knowtoo much about what is under the hoodbut from the perspective of you knowlike vector database your your trying tosend your data to this embeddingsinference API as fast as possible andget the vectors back or you know sayyou're sending prompts and you'regetting the response back from the largelanguage models is there like a lot ofopportunity to kind of interface on howyou do that networkingum in terms of streaming data fromVector search databasesI I suppose just I'm broadly askingabout the technology the whole like thewhole entire networking technologycategory and if this particular like youknow how how we're currently thinkingabout you know how apis provide the Deeplearning embedding and then languagemodel inference Services if that isalready as optimized as it can be or ifthere's room for yeahyeah it's a good questionum I knowum theum large language models a lot of themumuh I know open open AI does this uh youcan you can stream completions right youcan stream chat completion and so it'ssending you it's sending you tokens asit's producing themumuh within our open source uh projectwe've added uh We've added uh supportfor uh a couple uh a bunch of other uhLMSuh so for example we support Google Palmuh I haven't I haven't seen assumingcapabilities within Google pawn yet uhalthough it should definitely add thatso I thinkum so I think VL alums themselves areum pretty optimizedum obviously when you're uh when you'readding a lot of datauh when you're adding a lot of data to avector search database uh I thinkthere's an opportunity to stream streamthat data yeah um as as uh as is beingindexedumbut I'm notum I'm I'm not sure what what's some ofthe other kind of uh opportunities areyeah it's it's really interesting Ithink that whole category of modelinference just the whole all thesoftware behind it whether you're youknow doing the Onyx optimizations of themodel or like you know theTriton servers neuromagic is interestingor say you step into like thedistributed computation you know areawhere you have like Ray and Spark and Ithink there's so much to that kind oftopic um yeah so so kind of coming outof this topic a bit I I think it wouldbe really interesting to just kind oftalk about to transition back into justthe meta around the evolving softwarespace can you talk about like yourexperience in software and how that'schanged with the latest you knowbreakthroughs in large language modelsand Vector databasesumyeah soum oneum really big use case uh that also I'vereferred to earlier is obviously uhsearch experiences right soum building the keyword searches uh nolongerumadequateumso I think we ought toumoffer uh in a lot more uh kind ofextensiveelaborate uh search experiences right sosemantic searchumchat Botsum are uh obviously becoming extremelypopularum so there's a lot of there's a lot ofthings and workflows that could be inbusiness processes that could beautomated there with softwareum and and also uhuh umyeah doing uh q a over your data sets uhso for example in in our uh link chainuh RB project uh we haveum uh We've we've built an agent thatdoes a Texas SQL search soum you know previously uh previouslythere that there's a whole set of tweetthere's a whole set of tools that uhdata analysts uh used right to make kindof interfacing with underlying databasesmuch easier and I thinkum and I think these llm basedcapabilities make it uh even more soconvenient to do thatyeah I love that you brought up the textSQL thing it's so interesting to me likeum you know just seeing the trend inlike you know like social likeentrepreneurs on social media like Iremember you know there'd be a lot oflike here's how I started my socialmedia agency you know I was like I make20K a month at 17 with my social mediaagency and it'll be you know and it'slike oh I help businesses like run theirTwitter Instagram and that kind of thingand recently I've been seeing on youknow on YouTube with this kind of thingit's like oh I'm 19 years old I make100K a monthly with my um with my AIautomation agency and this kind of likechat bot andis like the skills that you need tobuild these kind of systems are arebecoming so different like or you knowit's like no code is finally like reallya super serious thing do you think likeum and I think there's even kind of thisis a topic that I think about like allthe time is this kind of like zero shotuh AI where you don't need to train itat all and so the you know you just kindof plug it in and you know you can be 19years old and set this up uh like do youthink like that kind of thing of liketraining the models compared to justsort of plugging in the zero shot LMzero shot embedding models setting it upthat way what what's your current stanceon thatso first of all I would I would uh I amalways a little bit of I I'm always alittle bit of uh skeptical of uh YouTubeinfluencersbut claim to claim to make uh uh 100K amonth sobut I you know uh back to your questionI I think you have to uh you have topush off ofumyour uh product requirements uh in inbusiness use casesum so there's a lot of times where ageneric they call them foundfoundational models right there's a lotof there's a lot of times where afoundational model is either is eitheran Overkillumand really you could just get away withuh a simpler model doing basicclassification tasksumso there's a lot of times wherefoundational model is either an Overkilluh or it's not best suited toum to uh to accomplish the things you'dlike to accomplishumsoyou know the answer is uh it it reallydependsyeah I mean um again referencing theunstructured podcast with Brian Raymondhe discussed um building a foundationmodel for visual document informationextraction and I it was such aninteresting idea I hadn't consideredthis idea of like a task specificFoundation models but it may like I'dalways kind of thought of this ideawhere you have this algorithm calledknowledge distillation whereas like youuse the large model to label data tothen train the smaller model you know isoptimized on that data and the key ideais instead of humans labeling data whereyou have like a one hot Vector labeldistribution that you optimize towardsyou have this like soft distributionover the class label so you know it'slike 0.97 0.001 it like produces thisdistribution that lets you distill themodel but so like that's kind of thetechnical algorithm behind likecompressing the models and then you knowbut just I guess we're seeing this takeoff where it's like regardless of howthat model is produced like what I'msaying is maybe it's you know gbt4distilled into the a visual documentcompared to where you just train thatvisual document thing from scratch andthen you serve it like do you think thatcould also be an emerging startupcategory is like Foundation model foryou know I don't know I can't I guess ifI like creative but like some particularthing like maybe it's like like visualquestion answering has its own uh youknow its own Foundation model it's notgbt4 and then it's smaller or somethinglike that yeah yeah no absolutelyabsolutely and there's there's a lot ofuh there's a lot of companies that aretrying to do exactly thatum and offer uh task uhofferumapisum that arethat are specific for specific tasksright so whether it's summarizationwhether it's editing whether it'sparaphrasingum whether it's chatumand uh yeah I think I think there's uh Ithink there's a lot of opportunity thereyeah I just remember this as I passedthe mic back I I was in Berkeley twoweekends ago and I saw these researchersworking on this language model calledgorilla and so gorilla is like a largelanguage model optimized for Tool useand like so I think especially as thecreator of Lang chain Ruby I think thiswould be a great topic is like how doyou see tool use like just this wholetopic of llng using tools and howopen-ended that seems to be yeah so whenwe when we talk about toolsum we're also talking about agents rightum andI I believe that the current consensusis thatum the the current agentsumfor kind of General problem solvingum are not very powerful rightum so there's emerging techniquesumbut uh the current conceptualization ofagents and and the current techniquesand the way they currently workum uh they're not super usefulum so so obviously there'sum there's a Chain of Thought there's uhuh so for example in LinkedIn RB we havea react agentumum there was another research that uhcame out there's another research paperthat came out recently uh called uh treeof thought uh which is uh which is kindof an evolution on top of the chain offog techniqueumand uh an agent uh coupled with uh withtools uh is basically uh exactly whatkind of open AI offers with with itspluginsum but I'm not I'm not sure uh I'm notsure that theuh I I'm not sure about the agents areuh super useful just yetso we got a lot of that I want to unpackI want to start with the well okay sowe're definitely coming back to open AIthe plugins and now we have this newfunctions API and that's so interestingthen the you know hot today I meant Imeant the functions yeah oh I think boththose things are I think that's justthat whole thing and seeing how openaithemselves are clearly like exploring itas well it's like a whole I think thisis one of the you know evolving thingsbut uh so I quickly want to come back tothat reference of building it in Ruby sowhen I think of tools I think of likeyou know it uses like a calculator or ituses a code executor so like and then wetalked about monolithic architectureversus microservice architecture I thinkof these tools as like a micro servicearchitecture correct like where you knowthe email API that you know calendarthese are all like API so so would youcook these tools to access into Ruby solike the calendar the implementation ofa calculator is it stuff like that isthat I don't I don't know if I have thegreat example right now but maybe you doyeah yeahwell so so so one example that's uhmentioned in the length chain are uhlength chain RBS uh readme is uh thisuhuh example of uh prompting uh promptingan llm a prompt using the react agent uhto calculate the distance between NewYork City and DCuh uh in inuh in the number of full-length soccerfields rightand souh and so the way uh and so you'reasking uh an llm to break down the stepsand generate uh generate uh a set ofactions right so reasoning and actum uh generate a set of actions uh andaction inputs um that it would uh itwould need uh in order to arrive uh tothe answer right and soit might say that the first action uhthat it needs to do is calculate thedistance betweenum New York City and DC in in milesright and so if you expose it a tool tobe able to do that rightum it will uh it will try to use thattool right and so you obviously have toexecute that tool in in the codedirectly right so it would calluh you would call the Google Maps APIand ask it for to go to send it back uhthe distance between uh DC and and NewYork City right you would then take thatobservation that resultand send it back to the llm and ask itfor the next step right and so it wouldsay well now I need to know what thewhat uh what the length of a uhfull-size soccer field is right so youwouldcall some sort of service uh that couldgive you an answer to that question uhyou will then take that result packageit as a as an observation send it backto vllm right so now it has two piecesof data right and now it just basicallyneeds to you know take the overalldistance and divide it by uh by thelength of a soccer field to calculatethe total number of of fields neededright to cover a distanceum so that's so that's an example oftool usageyeah I think what you're saying isinspiring something I've been thinkingabout as well with um with go Lang[Music]so we Face written and going and umgolang is really good at like uh youknow handling concurrency control with aton of these parallel API requests andlike one thing that's built intoalleviate weave has the generativesearch modules with which what they dois you know they take say you search aquery and then you have you know let'ssay 20 search results and you want tosend each one in parallel to the openaiAPI it's really good at like you knowsynchronizing all those requests andthen and I think I haven't I don't havea super concrete example yeah but as youmentioned the kind of like self-askprompting and question decomposition Isuspect that there is something to likewhen to lock these like uh asynchronouskind of API requests and you lock theshared resource so that you don'toverride it and so I do think that kindof orchestration there is a lot to thatand I think using languages like goingand I don't know what Ruby has with thatkind of maybe you could talk more aboutruby and how it handles concurrency andthat kind of thing or I don't know toomuchyeah I mean short short answer is a lotof these uh high-level languages uhdon't handle concurrency all that wellum you know python Ruby it's kind of asimilar story sointeresting umyeah yeah I mean I'm definitely not aprogramming language I only know likegolang because of the situation in whichbut yeah uh yeah so that whole kind ofthing um yeah so maybe we could talk alittle more about the orchestrationbehind particularly you mentioned thechain of thoughts tree of thoughts itsounds like you definitely need to havea lot of um you know like templating inplace to kind of guide the apis to dothat kind of thing especially I meanwell Chain of Thought to me is justwhere you tell it to like break yourplan down and or or the self-assprompting that you just mentioned whereyou need to take a question and then saydo you need to decompose this into twoquestions and so on like how do youbuild the build a template around thatto constrain it to follow this kind ofbehavioryeah so we have uh we have outputparsersumspecifically specifically for before touh uh to ask for a specific uh ask thelln for a specific type of uh outputright so if you want to get uh Json backyou can supply your Json schema and sayHey I want you to fill out this Jsonumumuh and uh we have uh prompt managementum so you can create your own templatesuh you can fill out the templates youcan create new templates from scratchyou can save them uh so we're currentlysupport yaml uh and Json uh formatsum and we also uh we also uh look at uhwe constantly have our eyes on theemerging research to make sure that ourprompts our templates are using the bestpossible techniques right and there'sand that's that's that's that's what theyou know that's kind of the gist of uhprompt engineering is being able toconstruct these uh concise yet detailedclear instructions for llms to give youthe output that you're looking for rightyeah I love that topic I think um likethe discovery of prompts that work wellis pretty interesting I mean I thinklike people obviously kind of Snicker atthat a bit the idea that it's likeengineering to be doing that kind oftweaking but I think I kind of respectcalling it engineering when you'retalking about like umyou know like the the way that themodels switch and the new the you knowlike gbt4 might react differently to theprompt and gbt3 does or you know cloudor you know MPT 30 billion so that maybethere's some kind of compatibility tothe prompts and the models or yes whatdo you think about yeah and is itengineering yeah yeah so I think I thinkum that's that's that's a it's that's agreat question and I think the fact thatwe call it engineeringum actually points to our yearningfor prompting to be a much more precisedisciplinerightum I mean current prompting is kind of ahack rightumbecause it's it'sI mean humans have a hard timecommunicating with each other right inin coming to a consensus of problemsolving andum right and it's and uh when you'rewhen you're interfacing with a system inin natural language uh it's it'sdifficult to get it to do exactly uhwhat you wanted to do rightum and so and soand so I think when we call itengineering it's because we wanted to beuh much more preciseum and which which is why there's agrowing concern and kind ofumarea that people are exploring to toevaluate the effectiveness of differentprompts right so being able to assigndifferent scores uh to input output setsrightum also referring back to the uh thewhole uh you know tree of thought uhresearchso uh you get a model to produce uhdifferent intermediary steps and foreach step you ask it to producedifferent samples and then you have torate those different samples like howHow likely is this sample to get you tothe best possible answer rightum and so there's there's evaluationthere's kind of prompt evaluation uhinput output evaluation taking uhtaking place at at a different uhuh uh at all the different uh layers ofthe stackum and I'm not sure I'm not sure anyonehad uh had solved this uh just yetum butum yeah I think that's that that's whythat's why we're referring to it as asengineeringumyeah I love that like with my um like myexperience with doing a PhD in machinelearning where you're you knowcollecting all these metrics about theexperiments and I think there still is alot to that like um you know how you dothe input output evaluation deeplearning has like a long history andlike these benchmarks like imagenetclassification or like Ms Marcoinformation retrieval where you or likeSquad question answering because I thinkquestion answering is a good one thatpeople are thinking about when you likethink about these kind of things we havelike just collecting examples and thenyou know looking through where it failsand seeing is there maybe you likevisualize the embedding space of allyour inputs and use and you color itlike green and red where it's failingand then you look in this distributionparticularly it fails can we dosomething about that and that kind ofgeneralization testing thing withrespect to all you're doing is tweakingthe prompts instead of like thinkingabout some whole another algorithm oftraining like I think mostly it's beenlike you know the generalization testingis done to compare two models trainedwith like massively different effortsright compared to this earth like justtwo different prompts and and cannothave a profound difference in the testSuite right right right uh and this isthis is also a an area of concern in inuhum in application testing right soum you're testing input and output andespecially if you're if you're not usinga uh 0.0 temperature setting right whichwhich means that uh you're you're goingto get different results rightum and how do you account for all ofthose different test cases in theapplicationum so we're uhand this is one area that we'recurrently thinking through uh as aswe're building out link chain RVawesome super cool Andre I think this isa really great coverage of these topicsI think kind of a wrapping up questionit's I'm really curious about sort ofmaybe the Breakthrough in the nextbreakthrough in AI deep learning thatyou know would excite you the most itsounds maybe like you're an agents guyand you want to see the something withagents or maybe just the llm inferencecosts going down what kind of thingsexcite youoh that's uh that's a good questionum I think I I would love to seethe open source models catch up to uhopen open AI rightumit seems like it seems like gpt4 uh anduh open AI uh they're the leaders uh inthe space right nowum and obviously there's uh there's anemerging uh field of Open Source modelsrightum some of them are getting really goodum it's also becomingmuch much cheaper and uh kind of costeffective to run those models locallyso I would love to I would love to seeopen source catch up to some of thecommercial offerings so that we can wecan use much more powerful uh llms andrun them locallyyeah or on on the on the cloud hmmyeah that topic is I mean it's supertimely with as we're recording thispodcast Mosaic ml has just been acquiredfor 1.3 billion dollars from data bricksand you know super lucky to have hadJonathan Frankel on this we be a podcasttwice of you know not that thecollaboration has to end now or anythingbut you know we've just you know beenworking with the Mosaic ml peoplethey're super talented and and it makesme think a lot about this open sourcething because I was so excited with theMPT 30 billion becauseI was also kind of like thinking likethis group of people I you know I thinkthey they're super talented I think theycan do it they'll create the open sourceversion of you know gbt and or drive thecost of it down all sorts of interestingthings um do you think like with like ifwith them going to databricks what doyou think kind of the predictions ofwhat they would continue to doyeah to be honest I Ias as you know things are moving sorapidly and there's so many people inthe space right nowum doing very interesting things I Ihave not had the opportunity to playaround with uh mosaic if you see that ohokay yeah I mean I I don't mean to say Iguess like MPC I mean there's definitelylike a bias towards what the latestthing is and that changes every singleweek like one week exactly yeah exactlyyeah I mean I do think uh databricks hadpublished I think their model was calleddolly or something so I do think it'squite realistic that you know they justteam up and they keep pushing the opensource and that would be and that thatcombination would be the horse I wouldbet on but I think there's also like uhthere's like stability AI has oneum I don't I know just like kind of likevicunaI think that one comes out of Burke Idon't know too much about about thewhole replicate replicate has areplicated offering as well uh wesupport that within blank chain RB andactuallyum to kind of bring it back to linkchain RBum what we're striving to do with linkchain are B is provide a set a set ofabstractionsthat software Engineers can canunderstand[Music]umand have the flexibility to swap out thedifferent llms right whether whetherit's a SAS offering and you'reintegrating with an API whether you'rerunning uh whether you're running a uhvicuna model locally uh we want to makesure that you can easily swap those outum becauseas as you've pointed out uh as we allknow the space is moving really rapidlyumwhat this what this base is going tolook like and who are the leading modelsright like in you know uh in a couplemonths in three six nine months from nowon is going to be completely differentrightum but we want to make sure that ifyou're integrating LinkedIn or be withinyour stack and uh you decide to switchto a uh more cost effective model orjust some more powerful model down theroad you can easily do thatyeah I think that puts Lang chain andllama index these kind of tools that arereally interesting Market position ishow they let you rotate out the um youknow the models as well as the tools andyou might want to think of a modelinference as a tool like again we talkedabout you have a foundation model for asuper specific thing and so you you knowwhether you use gbt4 to come up with theplan and then it routes it to othermodel inferences you think of that as atool I think that you know that kind ofidea but and then there's also kind oflike the data you know like the databasethings like I hear people discuss likehow Lang chain lets you you know ablatethe different Vector databases and thatmakes total sense obviously like if youwant to say you know you want to useweeviate you want to try the wholeVector database Market I think it's alsoreally interesting for you mentionedtext to SQL and you know we V8 does havean aggregate API so it's not like youcan't do that thing in weba but yeahtheir particular kind of join operationsand relational database stuff I canimagine you'd want another kind ofdative tool as well say like maybe thegraph database stuff has something tooffer so yeah that whole positioning ofit to uh wrap around these differentServices I think that's superinterestingright right and actually and actually uhone uh maybe a question that I wouldeven post to toyour uh the rest of the weeviate folksis is thatum I like howum I like how this how you guysstructure your schemasand and you can create schemas thatpretty much resemble a traditionaldatabase right you have those differentdata types that can that can mirror yourdatabaseum and I've wondered whether you canactually use it alleviate as your asyour primary databaseand whetherthis was in whether that was thedirection that uh aviatus is headingdownyou know I'd say there are the kind oflike the efficient data structures foreach of the properties like invertedindexing on categorical Properties orsay like building up trees to searchthrough you know numeric valuesum the thing about this that I think isthe most interesting is the connectionbetweenum how you would join tables in arelational database compared to how wethink about joining classes in weviatebecause each class in weeviate has itsown Vector index and so it's like youknow I think like with a lot ofrelational database design you'd havelike customer you'd separate like thecustomer and the purchases and then likethe brand like your you know the supplychain you separated out into all thesetablesand so and then you kind of like joinalong andI don't know I don't know if you want tosend embeddings like back through agraph like that that's that like if ifthat kind of thing just because I thinkthere are a lot of like under the hoodoptimizations behind how the relationalalgebra of like when you're joining thetape you have like conditions forjoining the table so there's like anoptimal order to how you join the tablesbecause like this one create this onereduces the cardinality to like fivethousand versus like 50 000 right so Ithink those kind of optimizations uh canbe made in Wii VA but it's not somethingthat I personally am super knowledgeableabout but to me the thing that I thinkabout more is this idea of likeparticularly in like the recommendationcase there's examples of like graphneural networks where you like flowembeddings through relations like thatlike you know user liked product producthas Brand these kind of things and soyou can like slow embeddings through agraph and I think I think that's wherelike knowledge graphs are gonna mergewith Vector databases in some kind ofinteresting way but yeah that wholetopic of understanding joining tables orclasses that that's something that Idon't have a great answer for but Ithink it's a super interesting topic gotit yeah I mean what I'm curious aboutlike you probably have more experiencein databases than I do honestly likewhat do you think about kind of like umyeah like what are the components of anSQL database system that Vectordatabases should you know make sure toadd to make it a make it a One-Stop shopfor your dataum that's that's yeah that's a very goodquestionumI thinkumI so I obviously uh Vector search isum such a large massive uh growing spacethattraditional data traditional databasevendors are looking to add thosecapabilities right so there's athere's PG Vector uh postgres extensionright uh we're aware of some of theother database vendors and adding thosecapabilities yeah to their productsumandumyou know there's there's there's kind ofpros and cons thereum the same way that there's pros andcons toumuh having a monolithum application architecture or amicroservicesuh Centricapplication architectureyeah because it is isn't there there issomething to when you compute there'slike indexes that you compute with umSQL where you're gonna join like 20tables together like you've got like apayroll software right and so you sothere would be like a memory overhead tobuilding up those kind of indexes rightsomething like that yeah and so thequestion then is umyeah I don't know I think it wouldprobably be a case-by-case thing I I dolike just the general thinking of likeif you're asking a question like youknow what is the average age of uhcustomers who bought an Xbox gamecontroller in March questions like thatthat like I think you would always wantto use an SQL system I can't imaginelike a semantic search llm thing beingthe best answer to that particular kindof so right right so that's why when Ilove that Texas SQL topic and then Ilike to say you know leave it has anaggregate API I don't know if maybe wecould build a SQL API I just don't knowwhat even that would entail but yeahright right but it would interestsorry yeah yeah I mean if you're umyou know if you're trying to get the ifif you have a list of products andyou're you're merely just trying to getthe uh the cheapest product or the mostexpensive product than than yeah and asa traditional SQL query will get youjust just fine right but if you'researching the product descriptionuh in your certain searching for a uh uhif you're searching product descriptionum and you're searching for a productthat lets you accomplish certain thingsand then yeah semantic I think asemantic search would be more suitableI mean I I did like just when Mosaic wasacquired by databricks I did a littlemore homework on like what is databreaks and what stuff like and theybring they bring themselves as likestructured unstructured semi-structureddata Lake and and so I generally thinkthis idea that like unstructured andstructured you know data schemas havemore to learn from each other I thinksemi-structured is where you like Ithink like snorkel AI is one of thepioneers of this idea of likeprogrammatic labeling where you likepredict missing structure from yourunstructured data andyeah just I think there's a lot I thinkthat's a super how do you unify thesethings I think that's one of the areasof innovation in these new kinds ofdatabasesyeah right rightum yeah and this this this problem uhthis dilemma has been has been aroundsoftware development foruh for decades yeah yeah it was supercool Andre thank you so much for joiningthe podcast it's such a fun discussion Ithink the you know the Ruby Kleinhearing about the motivation behind itthis whole of space and Lang chain tooluse also interesting thank you so muchthank you thank you it was a pleasurethanks so much", "type": "Video", "name": "Andrei Bondarev on AI tools in Ruby! - Weaviate Podcast #54", "path": "", "link": "https://www.youtube.com/watch?v=BnHFE5Y5Vvc", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}