{"text": "Hey everyone, thank you so much for watching the 51st episode of the Weaviate Podcast with Greg Kamradt and Colin Harmon! \nhey everyone thank you so much forwatching the wevia podcast I'm supersuper excited about this podcast we haveGreg kamrat and Colin Harman these twoare both uh prolific entrepreneurs inthe space of llm Agents uh Greg has madeall sorts of amazing content about Langchain and different examples of uh promsays AI early signal series and uh Colinhas given this really impressive lectureon hallucinations and how that ismanifested in agents and how to fix itat the haystack conference so I thoughtit would be so exciting to bring thesetwo together and just hash outeverything with our currentunderstanding of Agents laying chainllama index and just how this wholeSpace is evolving uh so firstly guysthank you so much for joining thepodcastabsolutely thanks for having ushappy to be hereawesome so could we do a round of introsuh Greg can you tell us about like howyou came to be working in this spaceyeah absolutely so my background isactually on the B2B products side of thehouse so I used to run a growth teamover at Salesforce for sales and servicecloud and then I was the firstoperations hire at digits which is aseries C fintech company and I have ahistory of teaching people how to dodata analysis and build data productsbut this year my focus has been teachingpeople how to use AI tools to build AIproducts and it's just a fascinatingspace right now because not only is theapplications evolving but even the toolsare evolving themselves and so it'sreally a turbulent time which is fun tobe inyeah amazing I think um I can't speak toenough of how much your videos havehelped me understand Lang chain and it'svery cool hearing the Salesforcebackground because that that uh write100 sales emails with the Y combinatorvideo you did I can't wait to dive intothat because I think that's such aninteresting topic with how this like youknow personalized retrieval augmentedgeneration can impact that kind of thingum so before we dive into it any furtherColin could you also kind of tell thestory of like how you can be working inthis spaceyeah absolutely so a few years ago I wasworking as a machine learning engineerand umhad some exposure to natural languageprocessing and kind of decided to go allin on that and that was it turns out apretty good time to make that decisionum and then you know my in my currentrole I'm the head of Technology at Nashwhich builds uh Enterprise search andautomation applications for heavyIndustries so upon starting there alsogot really into the informationretrieval side of things andum as both of you know both of thoseConcepts have kind of exploded in thepast year two years so it's been a greattime to be in that area and and you knowfollowing content likeum Connors and Greg's has been superhelpful and um it's very important so uhyeah that's how I ended up here and andnow just trying to you know find thefuture of how do you put these thingsinto products and and understand itproperly yeah fascinating I think maybealso to kick things off if we could do around of just like how are we eachthinking aboutlike Lang chain llama index Chad gbtMarketplace just generally the space oflike large language models using toolsthis General concept of agency like likehow how would you define it to someoneum yeah I'll get i'll get started withthat but really I think my my opinion onit is a littleummaybe a little more old school basicallyum I I've been asking myself thisquestion okay we're talking about AI alot right and a year ago what did an AIteam do and what what did you need toprovide value with AI and the answer tothat was basically you needed asignificant amount of talent you neededa significant amount of data and youneeded in many cases a lot of computeresources as well right so that's whatAI wasum however not with language models ifyou want to be AI you want to dolanguage models you don't need any ofthose things right thanks to people likeyou guys anyone can figure out how touse these and you don't need compute todo it you can use it like a softwaretool so I'm thinking of language modelsnow as a type of software just anotherBlock in the software stack this is notAI it doesn't require special talentdoesn't require special data rightbecause the data comes with the toolum so broadly I think of of Agents as atype ofapplication that uses language modelsright and I think I think you'restarting to see some hints of that fromentities like Microsoft talking aboutthings in that way as well this is justthe new normal and it's going to be partof you know every not every system but alarge large proportion of systems outthere so um agents in particular if Iwere to make that more specific I'd sayagents are aspects of those applicationsthat choose and usevarious subsystems so I'll leave it atthat and we can iterate on it a bityeah and then just to join in on there I100 agree I think that we're seeing apattern here where you see an earlyiteration of a tool that's just clearlygoing to be what the future is going tolook like now the the other side of thatcoin is that the reliability piece andso you're seeing things like the babyAGI and the auto GPTis it a question that they're going tobe that's going to be the model for thefuture without a doubt it won't be theexact same thing but that sort offramework is going to be prevalent forsure we aren't quite there yet becausewe're solving a whole bunch of otherproblems that come with it butum I am all in on agents I'm a Believercount me in for ityeah I think those are both great uh youknow great overviews from just theconcept of just large language modelsbeing just like a compute primitive thiskind of like person in the computer thatyou can just put in any intermediatelayer of some you know transformation ofdata across an API or doing differentkinds of skills that you can compressinto natural language um so I you knowin preparing for this podcast I took alook at blank chains documentation tosee like what's the newest you knowpresentation of the ideas and soHarrison the latest abstraction isthinking that large language models canbe based around you know data awarelarge language models and then agent uha gen agent center there's some kind oflike agent agentic I've never seen thatword before like agent icy but so I saythese two things as likeyou know you connect to the data like ina vector database and that's where youknow our interests around this reallycomes and then also connecting with theapis so I guess kind of I want to startoff by diving into the data aware llmsand sort of what you guys are seeingwith you know I know Colin has done alot of work on hallucinations and youknow Greg has tons of videos oningesting particular kind of data intosomething like a vector database so thatyou can then retrieve the context andfacilitate the generation so how youguys currently think about this kind oflike making large language modelscustomized to your data through the useof like you know connecting it todatabasesyeah I'll jump in quickly on that one myview on it is it's a very romantic ideato think that a language model can doanything that you want it to right andit communicates and the story tells verywell that you can throw whatever commandat it whatever data at it and it's justgoing to magically return things back toyou but I think what we're seeing hereis that language models are really goodat some sort of tasks they're notwonderful at all tasks and that's okaybecause we don't want to over overloadthe system with too many um too manydifferent types of requests and anexample of that is where you see peoplesay hey language model please think outloud first and then answer my questionas opposed to just hey go answer myquestion for that so when it comes toadding data to the context of yourlanguage model I see too many folks tryto throw the kitchen sink and just throwevery single thing that they can onthere where I think in reality you canget a really long way with betterprompting and more signal to noise ratiowithin the context that you're passingin the first place which just speaks tothe programmatic ability to do reallyawesome retrieval in the first place asopposed to giving everything to thelanguage modelyeah and I think a lot of it is aboutjust how many places in kind of a searchpipeline you can inject a large languagemodel so from data ingestion using thelarge language model to kind of extractand format the data for the schema sayyou have like this High H lowercase ycapital D capital E is like this idea ofwhere you you take a query and you havethe large language model generate apotential document and you search withthat document or say using the largelanguage model to cut the search resultssay type 10 results passive languagemodel language what else has only givethese two to the next step in the chainor say the large language model re-ranksit it's like there's so many places toput the large language model in thiskind of retrieval Pipeline and getbetter search results but I think agreat topic Colin would be talking aboutthis hallucination problem how likewhere are we at with hallucination andfixing it with the kind of retrievalyeahum I thought Greg brought up a greatpoint right asking the language model todo the wrong task and that I would sayis is one of the big problems here I wasjust talking to a client today aboutabout you know how you can do better onmath problems when you use you know truethought chain of threat promptingsystemsum but why would you want tosolve a math problem probabilisticallybecause you know these models have acertain error rate on these mathproblems when we know how to solve mathproblems right we we've figured that outthat came with when computers wereinvented right so um there's there's abig question of don't solve the wrongproblem or don't solve a problem withthe wrong toolpick the right tool for the problem andum and then getting back to okay likehow do you use these language models andapplications really step one for 95 ofapplications is going to be connect thisto your proprietary data or whateverdata you're trying to attend yourapplication over so retrievalnecessarily is the most important partof any of these Real World Languagemodel applications just becauseum look at any software applicationright those are based on data as wellsoftware applications use databases theyuse searchum so the same thing needs to happenwith uh with language models because ifyou don't do that that's not a trulyuseful product it's like a demo right oryou can do it in chat GPT so for mostpeople building building businesses youneed to build something better than whatyou can do in chat GPT and the easiestand most straightforward way to do thatis connect to the important data andthat yeah that can be that could be avector index a Keyword Index like bm25it could also be managed index like Bingsearch API or it could beum it could be a structured databasewhich I know Connor you're you're intothe the querying using language modelsthing and we've been doing that for awhile now too and every single one ofthose can be optimized using languagemodels throughout the process so so yeahyou have this concept of okay retrieveand then generate but generate can alsobleed into that retrieve step and itdoesn't have to be a one directionalprocess right you can go back and forthso there's a lot of ways to improve itbut it's most basic you need to retrieveif you want to deliver business valueyeah I I love that not a one directionalthing I mean as you mentioned like yeahI love that um like I think now llamaindex and Langston are both calling itThe self querying retriever where youask it you know like uh What uh uh likehow long do golden doodles live onaverage as a dark question think aboutthe mortality of gold noodles but likeand then you you would give it like theyou know symbolic schema that you likeyou know Vector databases like weaviatein addition to storing your unstructuredtext chunks you also usually have somesymbolic data around the text chunks andwe integrate that kind of stuff into thevector index so you have filtered searchbut so you so you know you give it theproperties in the prompt and it mightsay you know where animal equals dog andthen you know you have the symbolicfilter so there's like that notion to itwhere you can just use more of thelevers to the search engine it kind ofis like with web GPT you have thesesearch actions like you know do you wantto scroll to the next page of the Bingsearch results and and this kind ofthing and you know but so there's likethat there's like using the llm tocontrol all the levers of the vectordatabase but I also really love thisconcept of um you know like an interfaceand this is kind of how I see clientFrameworks even like stepping like intothe software hat of like you knowdatabase client Frameworks like I seesomething like Lang chain llama indexesorchestrating like Eva and like sayneo4j and then like an SQL system andlike using the uniquebenefits of combining your data in eachof these ways another kind ofreally interesting area of retrievalfrom different kinds of informationsources but I think it would be a greattransition into this kind of tool usenow because we've already kind oftransitioned from retrieval and we'renow kind of making it more like a toollikeyou know I'm really curious about likehow you guys are seeing things like youknow zapier I know Greg has opinions onzapier and like using the calendar apisand like how to how does the tool usekind of come into this pictureyeah quicker than that one I think justhow I'm confident in that agent Paradigmwill obviously be what's happening inthe Future tools are the the other sideof the coin that come with it I meanthat's how you get them to interact withour lives I just saw this quote withinthe human Loop blog post that said uhSam Altman suggested that a lot ofpeople thought they wanted apps to beinside of chat gbt so they thought theywanted plugins in chat GPT but inreality what they really wanted was chatGPT in their appsso it's not chat gbt as the centralpoint we're going to interact with allyour tools it's rather because reallywhat's the incentive for the third partyapplications to support that heavilyright they what they want is they wantthe users in their app and they want thechat gbt like abilities within their ownapp in the first place so as we thinkabout tools I think it's going to be areally interesting dynamic betweenwhat's best for the user and what's bestfor the business because unfortunate notunfortunately but the way that marketdynamics usually work is what's best forthe business is what's going to come outin the very first place now open sourcesoftware will of course help out theuser and go from there butum I think this is a dynamic we stilldon't know how it's going to play outquite yetit's so fascinating you brought that uplike we did podcast fans stay tuned foruh a deep dive on Chad gbt marketplacewith Yana wellender who's buildingcraftful so craftful with a K is um youknow it's like a product manager insideof chat gbt sort of so what the productis is it's like prompts that productmanagers use like for analyzing customerfeedback or like you know suggestionsfor what you do so it's kind of likeskill based prompting like I thinksummarization has been one of the biglikes the most successful skill toprompt it with like create and refinemapreduce like how you summarize with askill and so so on this chat gbtMarketplace thing oh man I think this isso interesting and especially like youknow Greg's such a prolific contentcreator I think this applies to you sointerestingly is like and yeah likeeveryone really but like imagine liketaking all your expertise on how to useLang chain and like kind of setting uplike instead of like a course you wouldcreate now you create like a set ofprompts and it's like a product on thechat gbt Marketplace and coming back tothat market dynamics thing and like thebusiness around it it's likeit's like yes I want the users in my appbut the exposure of the App Store mightbe so much like you know kind of it'spretty fascinating I don't know what doyou think about that kind ofoh I mean you you've kind of it's suchan interesting topic to me thedifference between Chad gbt Marketplaceversus just the API but I think themarketplace offers a lot of marketingyeah I'd say another part of it reallylike maybe what goes under that that SamAltman quote is that the llm is afeature now of a different product rightand a lot of people are still thinkingof it as a product but now it's just afeature right it's just software so youhave a lot of people working on projectsthat are okay like there's some tool Iuse some software tool I use well I'mgoing to make a startup to do that withan llm well that's just going to be afeature in the incumbent in one to twomonths guaranteed unless you're talkingabout a really really slowumincumbent so these llms it's just goingto be a feature it's going to make itsway into everything it's because it'ssoftware now right you don't need tohire an AI team there's no barrier toentryum and I think there will still bebenefit from having you know possibly aapp in the in the Chachi PT Marketplacebutum truly most of the the really valuableproducts are things that aren't going tojust work in the chat GPT Marketplacebecause how many apps can you truly makehow manyum how much value can you truly providewith like a one-to-one okay you knowquery or you knowum chat chat entry and thencomputation like that is very limitedand there's more benefit coming fromintegrating that into a differentplatform or a different applicationyou know and building on what Colin justsaid there another statement I believeto be true is that there will be someCentral repository for all the memoryabout Greg or about any personal personso Greg Greg's style my writing style mypreferences all that will be heldsomewhere I it my hypothesis is it willnot be application specific so forexample Salesforce will have a languagemodel that it's going to know how Iinteract with Salesforce all rightthat's great so we'll Zoom so we'llprobably Chrome right but what's thelanguage model and where's my centralrepository for all my preferences acrossall of those apps or whatever it may beso the reason I bring this up isit's still unclear to me if a chat GPTlike tool will be that Centralrepository that knows everything aboutme or if a Google's just going to try togo in there because if you think aboutmost my activity it's all through thebrowser right and if you're Google andyou did this for me you'd capture 95 ofwhat I have going onumit's still unclear how that's going toplay out but I think it's going to be amixture of both where applications willhave their llm but also there's going tobe a Greg llm that's going to bepersonalized to me that everybody elsewill have as wellso you think that'll be cross businessesthat won't be proprietary to a singlecompanyI I well so I think that like obviouslySalesforce will have their own and gongwill have their own and zoom will havetheir own and all thatbut then in order to automate my ownwork I'm going to want something morelocal to me so I think that becauseum we won't live in an llm constrainedworld like there's going to be like aninfinite amount as many as many languagemodels as you wantumso I think that there will be one thatis personalized to me that I own that'sa little closer to meum and interacting with other llms fromother toolsit's really I mean it's inspiring me tothink about like kind of like theprivate GPT and that whole topic I knowof you know both of you with this kindof like Enterprise B2B experience onthese things likeyeah like you know I know just from likehanging out with friends outside of theweeviate circle that a lot of them sayyou know I can't use chat gbt for workbecause I can't just like you know putmy documents into chat gbt because ofthe security yeah I'm curious like howhow you see the emerging Trends in thislikelike are more like you know companiesgonna go to open Ai and say like heyopen AI we need you to set this upinside of our cloud like the modelinference server inside our cloud isthat something that maybeyou know open AI or cohere you knowanthropic these big model providerswould look to or would this maybe be theopen source language models or willpeople start you know training their ownlanguage models with maybe you knowMosaic and ML and tools like thatyeah sure yeah there's a lot there's alot there um so yeah you're absolutelyright a lot of Enterprises are notcomfortable with sending data to open AIum there's some ways that open AI isgetting around that and when I say openAI that that'll include you knowGoogle's offering Palm whatever any ofthese language model providers so oftenthe way they mitigate that firstobjection is by saying okay well nowwe're in your cloud provider platformright we're in AWS we're in gcp we're inAzure so you can use that and then youdon't have to go outside of azure andthen the next level is data retention soI think with most most of these systemsyou can opt out of data retention nowthat's a huge deal for infosec anotherstep that I'm not sure exactly where weare on this is dedicated instances rightso you can get that I'm you willprobably be able to get dedicatedinstances of some of these super highperforming language models pretty soonand then it probably ends there for themanaged models right and then you stepinto open source world and in opensource world you have those previousoptions but you also have private Cloudyou have on-prem and you will even haveEdge and Edge is also going to beinteresting because we're probably we'reprobably close to a point where yourum yourWindows PC or AppleMacBook may end up having a llm builtinto it right and we saw the Palm modelsthey had one that you could fit onsmartphones right so at some point thecompute may come with your device andthat changes things a lot right becausethen it doesn't leave your device that'snot it doesn't leave your Cloud itdoesn't leave your device you can doanything you want with that probablythere's still a little friction justgetting these infosec organizations tocatch up with all these Concepts andunderstand okay what is safe what isn'tsafe are these things stateful how do weknow it for sure but um I was justlooking at a company the other daycalled ask Sage and they're doingthey're providing open AI for governmententities including you know militaryright so the fact that that is gainingtractionum using those those open AI instancesand content retention turned off is apretty good sign that enterprises andorganizations are starting to understandand realize that they need this andthey're willing to take some risks or atleast understand those risks better inorder to do itnice the um I agree with Colin that theability like these models let merephrase um Sam Walton has another quotethat I really enjoy which is the cost ofintelligence will go to zero right andthe cost to serve that intelligence willalso go to zero now TBD on the timelinefor that but that's the direction it'llgo so I agree with Colin fully that theability to have compute uh Intelligenceon our Edge devices will 100 be therenow we'll we'll the the market adoptthat that's a little bit of a differentquestion for me and the example I wantto give isum take for example iMessage versussignal signal uh uh uh touts thatthey're end and encrypted right well arewe all using signal today not really westill we still use iMessage and I knowthat there's encryption and everythingaround there but I think the point is Ithink that where this will go isI think just the way that we trustGoogle and all these big on all theseother big info companies to handle ourdata our Gmail our drives and all that Ithink that'll be the same level ofcomfortability that we get to withlanguage models we're just um we kind ofjumped into a cold pool and we're stillfeeling the shock of the water right nowbut I have a feeling that we're going towarm up right to it and once Google oronce this becomes the norm in agoogle-like company starts to serve thisfor us we're all gonna we're all gonnabe okay with ityeah that that whole thing you know allthat introduced so many new ideas to meI'd never actually considered llm on thedevices like right into the chip likethe new M1 chip also comes with a applegbt in it and that'sthat's a really cool idea all thesethings and then think about the marketadoption like I think either we couldtake this this topic further and talkmaybe about like the kind of medical usecases and the evolution of that or Ithink we could talk about sort ofpivoting topics entirely and maybe stepback into our conversation broadly onagent use and before we dove into thisum Greg you had brought up the Chain ofThought Auto gbt so let me actually askyou guys both quickly do you think weshould yeah why don't we it was just asthe interview host I'll hijack the topicand what let's talk aboutlet's talk about Chain of Thoughtprompting and auto gbt how do you guyscurrently see thatum I'll give just a very quick opinionon this like I said at the beginning ofthe interviewnot only are the applications and usecases evolving we still don't know likewhat's the right way to run these thingsin our business which is superinteresting but the tools themselves arestill evolving so what is the bestframework for an agent to Think Throughyou know we're still figuring that outand the the way that we do figure thisout is through market adoption and wesee what handles most of the use casesand we let the market help us figure outwhat to do here now the fact that we'recoming out with new Frameworks everysingle week and we haven't yet settledon one I see that as a beautiful waythat Innovation happens and you can'tspeed this process up anymore let thedust settle let's see what kind ofthings come through here and we need totrust that Lang chain and llama indexand grip tape and fixie and all thesefolks will be the ones who will takeadvantage of these new Frameworks andprovide them for the end users like usyeah grip tape that's it I haven't heardof that one before but I like that namebehind it like uh guardrail is anotherone that I know with like the preventinghallucinations like having layers at theend of that yeah it's also interesting Imean I guess my thing about the auto gbtkind of craze in that is just this ideaof like you know coming up with a planand then sort of executing the planasynchronously is sort of like theComputing Paradigm that I think isreallyreally mind-blowing with this kind ofidea is like if I say you know I need toI need to come up with I don't know likea way to optimize my code at the lowestlevel and it's like research about armprocessors research about simdinstructions it's like it can likeparalyze all this research and likecoordinate it how do you think aboutthat kind of component of Auto gbt islike letting all these language modelthread it's like a new kind of likemulti-threaded programming is how I seeityeahum so I think there's some challenges toadoption with the rogpt Paradigm and uhit's something that works really wellfor an ad hoc Quarry right it's fun it'svery cooland it demo as wellit demos so well right but it lacks thethings that make it valuable to a aserious Enterprise an organization andthat could be anyone right that could beyou doing your job that could be anorganization buying it for their fortheir people that could be a universitygiving it to their researchers right andwhat it lacks isum repeatability for one thing and thenkind of this auditability observabilitythat we don't quite have greatFrameworks for yet but I'm sure that'scoming but to flesh out therepeatability portion a little morelet's imagine you have some knowledgeworkers in an organization rightum you could say all right look Auto GPTcan do everything that they do butthat's probably not going to work verywell because at some point you're goingto need to compare that with a similartask that a different knowledge workerhas doneum so what I think is going to happen inthese organizations are people are goingto look at these knowledge workerpieces of work work objects that theyproduce and what you want to do is groupthem into basically workflows is a termI've been using I've heard a lot ofother people use it as well so let's saylet's just take a concrete exampleyou're a data scientist and you're doingtopic modeling okayshould be familiar to our audience butthat's something that you want toroughly follow the same pattern everysingle timebecause you're going to share that withother people right and they're going totry to replicate it and if they try toreplicate it and their Auto GPT does ita different way you're going to getdifferent answers and what are you goingto do so I think what's going to happenis umpeople will gradually approach all theseproblems of various fields and kind ofsegment them into workflows and you'llhave some very frequent ones and you'llhave some you'll have a long tail rightso you have some tasks people do a lottopic modeling you'll have other tasksthat people do infrequently liketraining a new llm right and so you'regoing to take those high frequencyworkflows and you're going to try toautomate them and that might not betotally deterministic right there theremight be some some routing decisionsmade within thereum so that could be thought of as maybea sub-agent but then you're going tohave some supervisory agent that ischoosing that workflow or choosing heythis doesn't fit with anything I'm youknow really trained how to do so I'mgoing to go the long tail route and justgo full auto GPTum however that's again not as likely toto be as useful number one because it'sharder to trust and number two becausehopefully if you did this right thoseare less frequent tasks so if you canuse your language models and your toolsand your retrieval to automate thesehigh frequency workflows I think that'show we're going to see a lot of a lot ofautomation adopted in terms of theselike knowledge worker tasks that peoplewould expect Auto GPT to to addressColin question for you on that oneum for these for these Advancedworkflows there's kind of three piecesthere's the language model as thereasoning enginethere's the task and the prompt that yougive it and then there's the memory inthe context that it receives right I cansee one argument that says once you getto a high enough reasoning level likehigh enough intelligence level for alanguage modelthen you could fine-tune that workflowjust through the prompt and through thecontext that you're feeding it so forexample the data topic modeling well doyou need to have a specialized reasoningreasoning engine for that data topicmodeling or do you just need one ofsufficient level pass it the best promptyou can pass it the instructions on howto do topic modeling in the first placeand then let it run wildthat could end up being sufficient yeahit's very possible but even then youknow you have kind ofadded some deterministic informationsome you've given it a structure so thatstructure I think over time willprobably evolve toward what youdescribedum yeahit well I think you know earlier when Ibrought up uh what Yana is building withcraftful and the child GBC Marketplaceis very similar to this idea of like youknow I compress like Martin grutendorsThe Bert topic expert in you know topicmodel the expert into like a set ofprompts on how to run topic modelinganalysis is like the craftful ideas youtake these prompts on how you generallydo like user interviews manage userfeedback and and yeah so it's sofascinating I think I think of this askind of like a skill prompt and I gotthat kind of like skill prompt fromlooking at Microsoft semantic kernel andthat's like the abstraction that camearound like um you know like a promptfor how to do question decompositionlike our follow-up questions needed thisis kind of a topic around skill promptsit's really related to everything onagents is what is the evolution of fewshot examples do we still need to give afew examples of how to use agents orwith you know because Chad gbt like ityou know it seems like a lot of timelike I think react was a paper that waslike zero shot tool use so it's like youdon't need togive it examples or train out how to usea tool so what do you think fuse shotprompting give it a few examples ofusing a tool is that still neededyeah I think it's it's definitely stillneeded and you look at howhow people build plugins right now likeI like you men I like that you mentionedsemantic kernelum I think that's acould end up being a good standard goingforward because look how they built thatthey look at how everyone was buildingplug-ins and then they standardized itand generalized it right and that's notsomething you really get from the opensource Community which is kind of justpurely expanding it doesn't have a goodcontract stage yet whereas Microsoftwith that framework has done theirexpand and contract alreadyumbut in terms of if you want to give asystem new capabilities with a new toolumit's most likely that you want to dothat with fuse shotum you sure you could just describe itbut why would you do away with giving itadditional information I think there isa place that fails though which is let'ssay you have multiple tools and the toolcould couldn't include a retrievalsystem uh you know Atomic tool or also aworkflow let's say let's say theseinteract with each other or they'redependent on each other each other insome way then the kind of oh I'm addinga plug-in so here's my few shots andhere's my you know interface that kindof breaks because you need few shotsthat cross between the different toolsplugins workflows whatever and um thatmay be a time where you'll need toeither develop a lot more few shots butyou can also see how that would like thepermutations of that would would get outof control pretty quickly or possiblyeven train a specialized model to dothat sort of planning that it needs todo in order to figure out how to usethis this environment of tools ratherthan just thinking about it is you knowI can do one or two thingsumyeah I was gonna say I'm with Colin ofcourse nobody knows but my hypothesis isthat a few shot examples will still bearound because even if you craft themost perfect prompt I don't think you'regoing to account for every singlesituation and giving like a picturespeaks a thousand words well so does afew examples as welllike the story of a lot of machinelearning is you know examples and thenjust the research has been how do welearn from as little data as possibleand now we've seen that um calling yousaid something though I I hadn't heardthat abstraction before open source isabout the expanding whereas like acentralized entity is the contraction Ithink that you know like it makes a lotof sense and I think that is reallyinteresting and then something I thinkis really fascinating as well is I thinkGreg is one of the world's experts onkeeping up with this expanding of whatpeople are doing with prompts Greg has aseries called early AI signals and youcan see the you know notion templatereally nice organization of these thingsand I think this would be a perfecttransition Greg if you could talk aboutlike this expanding and how you'rekeeping up with itsure absolutely soum I have a small side project calledearly signals and it started as anexperiment really because there used tobe the saying that every spreadsheettemplate was a future startup and if youlooked at the Craigslist home page everylink on there was a future startup it'slike home rental Airbnb car rental Toroet cetera and I was uh just on justsocial media in general Twitter YoutubeHacker News all that stuff and I noticedthat people were using chat gbt for waysthat it was not intended to be used theydidn't really know you know how it wasgoing to be used so people saying oh Iuse chat GPT for therapyhmm interesting I use GPT to write mycover letters to help me with my resumeand all this and I thought to myself manis chat GPT really the optimal productexperience to execute against thoseworkflows likely not so this could be anopportunity to productionalize that thatworkflow now the hard part about thisand the piece I need to emphasize is youdo not have a defensible business if youjust productionalize a prompt so it's astarting point I I believe and there'sthe hint of it and somebody needs to goout and go build more defensibilityaround it but early signals I have acollection of those ideas andum it's about weekly I try to go throughand say say my favorite five but thengive folks the access to I think we'reup to like 70 to or 80 differentworkflows and the important part foreach one of these is that I need to showwhere a user has said that they do thisthing so I don't want it to besomebody's idea I wanted to be a usersays I do this right now and so youalready have a little bit of user for uhadoption for right thereyeah I think it's so useful it's such acool you know it's so interesting justgoing through it I think like from likethe AI girlfriend to like the uhyeah just like um the whole collectionof all these things that people do withit and I mean yeah I I I'm just like I'mI'm still kind of like my mind isblowing through my head thinking aboutthis kind of Open Source expansion kindof idea because I do think like Langchin like when it first came out the waythat it was like open source and thiskind of collecting the prompts and it'svery similar to what you're doing withthe early AI signals is just like maybeif I connected to like hugging face inthe model Hub the open source like howthey've managed to seize open source andit's like because they have you knowit's like what are we gonna do with thisnew tool and it's so creativeand it's just pretty interesting uhquick quick I think another Sam almondquote that I really enjoy and I keep onquoting them here butumthe reason the reason he States why theyrelease slow is because the collectiveintelligence of the human population isunpredictable it's unpredictable theyhave no idea what what humans are goingto do so it's like all right here's chatgbt what do people do here's pluginswhat do people do here's API you knowEtc et ceteraum I think that open source expansionopen source moves quick like you'retalking about Indie hackers all over theworld that are putting out reallyinnovative ideas one of the Primeexamples of this is baby AGI the founderof that was not a technical by tradeperson per se he's a VC so how cool isit that somebody who isn't necessarilytechnical is building this tool that allpeople around the world can takeadvantage of and I think that I thinkthat speaks to the open source types ofworld on there nowum proprietary and closed will all willcatch up to it but they're driven lessby let's provideum selfless Innovation out into theworld and they're more commerciallydriven but it's all it all it allfollowsI think it depends on that this stagewe're in also right because we're stillvery early and talking about somethinglike agents no one even agrees on theabstractions rightlike I I was looking at uh fixie whichis a pretty cool company andum they have a you know open sourcepackage available for agents as well andthey calleverything agents so like a plug-in forthem is an agent right so we can't evenagree on the abstractions andeventually we probably willand at that point we need to contracttheumwe need to focus right and that's notsomething we're getting a lot of at thisstage from tools like Lane chain for thethe general agent stuff and from llamaindex your other example for theingestion stuff right I think both ofthese started out very successfulbecause they gaverandom people quick cookbooks on how toput things togetherright that was the value they providedit was simple abstractions a collectionof wrappers that was basically it like Ithink a lot of people ended up startingusing Lang chain just because it wasmarginally you know four lines of codeeasier to do that and instantiateweeviate than it was to instantiatedeviate from the like the weeviatedocumentation which isn't the fault ofwebe that's just how software worksright so they made a wrapper that shrunkitum and same with the openai endpoint sothat was valuable to people for a whileand I think a lot of people are stillprimarily deriving value from it forthat reason however as it as it balloonsas it gets bigger and bigger you'regoing to start to lose the cookbook ofthe system because there's too manyoptions and I think you'll see thathappen to llama index really quickly iseverybody builds a different documentparser right and so all of a sudden I goto this I go to this GitHub and I wantto find a document parser and instead ofhaving three options where thedifferences are clearly articulated Inow have 2500 right because that's whatyou're going to have look at huggingface it even happens on hugging face howmany models are on hugging facethousands how many of them are usefulvery very few we don't trust huggingface to tell us which hogging facemodels are useful even we often get thatfrom somewhere elseso um yeah these these open sourceexpanding Frameworks will need to becarefulum and be sure to do some Contracting atsome point or else theseFrameworks that are much moreopinionated like semantic kernel aregonna eat their lunch because they weredeveloped kind of with the same processoriginally right these these Microsoftpeople just built a bunch of plugins butthen they took that learning and in anorganized way turned it into a trueframeworkthat people could agree on and was aswidely valuableyeah that is that is just gold insightsI I feel like I take took away so muchfrom that I mean um like we think a lotabout the weevier cookbook and how wewant to design this thing and yeah it'slike you know Tech search with this dataset text search with that slightlydifferent data set where you'd usedifferent properties is that the bestway to design a cookbook or do you justend up with like 2 000 examples and it'slike that just confuses youcompared to like one text one image onemultimodal and just keeping it to thepoint it's pretty fascinating um I guessI kind of like in this topic of OpenSource I thought maybe there is a linkto jump to this next topic which ismulti-agent systems like where we haveit's kind of like it kind of is similarto Auto gbt to me but like you know sayyou have like multiple agents that likelive in some kind of simulation I mean Ihad uh you Shang Wu on the podcast who'sbuilt chat Arena and what chattering isabout is like you know we Greg ColinConnor we each are like retrievalaugmented chat Bots that talk to eachother and maybe a third language modelis judging like who's saying the bestpoints and stuff like these kind of likechat games but like how do you thinkabout that kind of like multi-agent uhllm systemsI um quick comment on that one if youwere to ask whydo we do this multi-agent thing in thefirst place and it's really uhdeficiency in the current models rightnow not to be able to handle that typeof computation or that type ofprediction or whatever it may be rightand so I I think that is the use casegoing to be there in the future whereyou want to interact with an arena ofpeople sure we're seeing the marketalready want that right now is theanswer multi-agent well it's a prettyconvenient way to constrain One agent tolike think about a certain thing andconstrain its memory and all thatum is that the only way you canconstruct that type of application noand so is that the framework that Ithink is going to be the one thatpersists uh still TBD I'm not going tomake a hypothesis not yetyeah I think you're totally on base Greguma lot of yeah the reason you do that isto make up for their shortcomings and ifyou had a smarter model why would youneed to have two of them talking to eachother if it can justyou know understand okay well I've gotthis stuff in my context and I should dosomething a little differently becausethat's all the other one does it's justlike they're just swapping contexts in ain a different sort of way I think theplace where we might see more of thatbeing necessary is yeah further towardthe edge more open source where you youmaybe have the smaller uh specializedmodels like for example that that one wekind of talked about where it's trainedto use a certain group of toolstogether but um as you get smartermodels it shouldn't be as importantI mean I think it's just absolutelyfascinating I I think it's very relatedto just like real companies kind of likelike if I think about how likeyou know if I'm if I'm playing thisthese roles in this multi-agent systemthe first person is like looking at theTwitter feed you know doing the early AIsignals curation and then sees thisthing and says I think this could fit inweeviate just like someone who's justpicking things I think could go inwebiate then you pass that to like theproduct manager role playing LM who youknow has this particular retrieval andmaybe also fine-tuning to use those kindof tools to say okay here's the proposalthen the engineer you know who's morefamiliar with the code base and theinternals of the database and stuff likeokay and then uses the chains of likethe you know code execution tool used tolike prototype and develop a prototypeand then you know you have like somekind of maybe internal pull requestreview that happens with role-playing oflike different engineer llms and thenyou have like the marketing and like youknow without explaining like all theroles of the engineering company like doyou think you don't think do you thinkthat thing would be superseded by justone large language model that sees thenew thing on Twitter have her ingestdata however it comes up with ideas andjust end to end just I don't need thiskind of role playing it's just liketotally unnecessaryuh I think my previous statement wasjust assuming they're all built in fromthe same language model and the samemodel that comes in from there now whenyou start to speak around specializedtasksI think in in that caseit's still TBD but a lot of popularopinion is around that you're gonna havespecialized models that come around andthen with that if that precipitatesspecialized agents then you'll have amulti-agent world to complete thosetasksyeah I mean it's like well they're kindof like two emerging topics in largelanguage models I think which is thefirst of which is fine-tuning isbecoming cheaper we see like the Q Laurathe quantize low rank adaptation that'smaking it look like you can you know Ithink they say they fine-tuned a 65billion parameter or large languagemodel on a 48 gigabyte GPU and so it'slikeit's like that kind of thing is going toget a lot easier like way easier thanit's ever been right how do you thinkabout that kind of Trends in fine tuninguh yeah I mean they're definitely makingprogress I think there's still someunknowns there was a paper that came outrecently talking about how the nonthe non-managed models it turns outdon't generalize nearly as well as asthings like GPT 3.5 so I'm sure we canlink that I don't recall the title of itat the momentum but if you if you look at that whatis it saying it's saying these opensource models aren't as good as wethought they were and they don'tgeneralize as well to unseen tasks thatactually makes a case for morefine-tuning right if your business hascertain tasks you expect you need to dothere's more need for you to fine-tunethose models again stepping aside fromthe the super powerful model is thegpt4s of the world if you're goingtoward these smaller models then yeahfine tuning will probably be moreimportant and it does seem to be gettingway cheaper and that goes hand in handwith the hosting costs or the inferencecosts as well right they're kind oftightly correlated so with that thatquora paper that was really cool I'mexcited about that um yeah you can runinference and training for now it's it'saccessible to you know you need a littlea couple talented people to do itprobably but um that's kind of your onlyobstacleyeah I think that's exactly correct Imean you need to you need to then havelike the you know all the ml Ops skillsto take advantage of that kind of thingbut then if it saves you money saves youthat much money compared to like allthese repeated inferences of the supersmart thing so then the second big TrendI'm very curious about are these likereally long input lengths likeanthropics is 100k input lengths how doyou think that'll change agentsI don't know do you know how they dothat either you guys know how they didthat did they just pay the price oror did they have some trick I feel likepeople are still trying to figure thatoutwell I think with mosaics uh MPT theytalked they you know talked about Alibiattention and how you can do this kindof like sparse attention where yeah Imean I don't know the exact mechanics ofit and I'm sure they optimize it likeall the way down to the Cuda cores andlike you know have a lot of engineeringthat goes into that butyeah one one quick thought about itum and then I'd love to hear what youthink Greg but with the longer attentionI thinktraining probably becomes a lot moredifficult and expensive too so beyondthe compute which ordinarily with withattention skills quadratically rightum that's a problem but then also if youwant to generate fine-tuning examplesthat umthey replicate some long context tasksthat you want to do in the wild you needto generate some examples of that rightand so if you're having people right80000 wordexamples then you're going to spend alot of money doing that you probablyneed pretty smart people generatingthose examples but then the other sideof things is with longer context lengthsome applications look different rightyou don't have to do as much retrievalthere's a there's a certain window thatopens up of data that where you can justput that in the in the context in thepromptand it's not clear how much furtherwe'll be able to gobut that definitely does change okay howoften do you need to do retrievalum to yeah you can put some in thepromptyou know I think maybe I'm wearing theadversarial hat being in a vectordatabase company but we're alreadyseeing papers like large language modelsare distracted by relevant contextcalling in your Haystack presentationyou talked about n greater than onesearch result in the prompt you know itbecomes trickier so yeah I'm I thinkthat it's the the pro of retrieval islike you could still pack a hundredthousand with all sorts of informationsources as you search across classeswith different queries and stuff just topack this prompt as densely as possibleyeah and then generally I thinkit'd be hard to train those models Iagree with thatyeah and for me I think that longcontext weight length it demos reallywellit does well on Twitter and I think thereason why people are excited about itbecause it's storytells really well tooit's like oh now pass a book into thiswhole thing however the minute thebenchmarks start to go down I becomeless interested and so reallyis kind of a dramatic statement I don'tcare I don't care as much about contextlength at all I want improved reasoningcheaper and then longer contact well noimproved reasoning cheaper lower latencyand then uh longer contacts contactslengths for that because like Khan saidwhich I agree withit's a bit of a it's a controversialstatement but a longer context lengthallows you to be lazier on retrieval andit almost makes up for your inability tonot do retrieval as well as you shouldbe doing in the first place potentiallyI know it's a bit it's a bit of anoverstatement but I think that I am finewith managing a shorter context lengthand needing to beef up my deterministicretrieval to start thenum then somebody's saying oh now you cando a million tokensit forces you to build a better systemdoesn't ityeah fascinating uh Greg and Colin Ithought this was such a great tour ofall these topics of llm Agents I mean Ilearned so much on these podcast uhthose podcasts um wrapping it up uh Gregand Colin could you each maybe uh givelisteners like where to find you keep upwith your content hopefully they're youknow that's why I read the podcast andwant to just dive into all the onlinecontent you have umyeah absolutely so two places on YouTubeI run underneath the channel called Dataindependent you can find me over therewith a bunch of uh Lang chain contentearly signals and all that good stuffand then most of my communicationhappens on Twitter so I'm just at Gregcameradhey everyone apologies the recordingcrashed right as we were doing theoutros you can find Colin on his blog atcolinharman.substack.com and you canalso find calling on LinkedIn at ColinHarmon one more quick bonus on the outroyou can check out Colin's new talk atHaystack us 2023 stop hallucinations andhalf truths and generative search nowuploaded to the open source connectionsYouTube channel as a bonus you can seethe ordis Chrome plugin from Alexagordick this new AI summarization toolfor YouTube another really cool thing uhand then also in the spirit of it here'sGreg's Channel data Independence so manyincredible videos on lighting chaintutorials uh new things about AI theearly signal series all sorts of coolstuff so thank you so much for watchingthe podcast and please be sure to checkout Greg and uh Collins videos as wellas well as all sorts of other contentthanks again", "type": "Video", "name": "Greg Kamradt and Colin Harmon on LLM Agents - Weaviate Podcast #51!", "path": "", "link": "https://www.youtube.com/watch?v=iB4ki6gdAdc", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}