{"text": "Vector databases and large language models (or LLMs) enable fast prototyping of systems that were incredibly difficult to build in ... \nhi it's Adam from we8 and welcome to another episode in the series build with we8 in today's digital age recommendation systems have become an essential component of many online applications and services from product recommendations to content suggestions these systems help users discover new things and make informed decisions every day in this video we're going to build a simple recommendation system using weate a purpose-built open source Vector data database let's try it out together Point your browser over to book rex. we. and type in something that you want to learn about the books that are surfaced will contain semantically relevant suggestions based on your query these semantic relationships are found through approximate nearest neighbor search on Vector embeddings Associated between your query and the book details like the author the title and the description this way we're not just judging a book by its cover to build this project we're going to create an instance of a we we8 cluster using the we8 cloud console we'll create embeddings for about 7,000 books from a Kagel data set connect to a large language model hosted on open Ai and then I'll walk through the nextjs application doing semantic search over the data set to surface those semantically related books to you as always here at we8 we love open source and so we've made this example available to you on GitHub and repet we're excited to see what you build yourself with this sample and just a heads up some of the code in this video may be out of date by the time you watch it so keep an eye on the git repo for the latest changes if this sounds like an interesting project to you let's go build it right now the first thing we'll do is register on we8 cloud services or WCS it's super easy and will only take you a minute or two to get to WCS Point your browser to console. we v8. cloud and if you need pause the video to sign up for an account once you're logged in to weate console we'll create a new cluster for this example we can use the free cluster tier give your cluster a memorable name make sure enable authentication is set to yes and then when you're done reviewing the details go ahead and click create give this a bit of time and let WCS deploy your cluster then we'll take note of the cluster URL and the API key for your we8 instance when ready click details on our newly created cluster this will create an expanded view of the cluster go ahead and copy the cluster URL and save it in a text file or notes file so that you can reference it later and now for the API key back in WCS click API keys and then copy the admin key save it in that same text file for reference later and we're done with setting up our we8 cluster we'll also need an API key from open AI so that we can use their model to generate our embeddings to do c IC search note that since we're using an open AI model each time you make a call to create an embedding or to query the vector database there will be a small charge on your API key if you already have an API key from openai you can use that in this project too if you don't have an API key yet go ahead and register for an account on open.com once you're logged in select API then go to your avatar at the top right of the screen select view API Keys create a new Secret key and then give it a name of your choice and finally go ahead and create it copy the key and put it into your notes file for reference later and this should be everything let's go ahead and make sure that we actually have the source code now if you're watching this in repet you'll likely have already cloned the template and you're ready to go if you're watching this on YouTube or you want to build this locally you can find the link to the git repository in the description below clone the repository by downloading the zip from GitHub or cloning it in your shell environment when you have the files locally go ahead and open up the project in your editor of choice before we get into creating our embeddings let's go and set up our environment we need to put the cluster URL and the API Keys into our environment variables if you're building this locally you can use your editor of choice to put them in anv file you can copy the env. sample into a newv file use the variable names as reference in the file and change the placeholders with your values if you're building this in repet you can pull up the secrets tool on the bottom left of the screen and insert your environment variables there instead just make sure to use the same names as those referenced in the env. sample awesome so our environment is set up let's get going with populating the vector database with the book's data set and their Vector representations as mentioned earlier we'll be using a data set from Kegel it contains contains about 7,000 books with details like the ISBN number the description a link to the book cover and more if you're interested in reading more about the data set in Kagel you can find the link in the description below there's a folder called Data pipeline in our repository that has two scripts and the kagle data set this data is stored in a file called 7k- books dk. CSV feel free to pause the video and take a look through it one of the scripts populate py is respond responsible for creating vectors and storing those vectors in we8 let's look at populate py in Greater detail first we create a we V8 client object that receives the we V8 cluster URL the we V8 API key and the open AI API key in case the script was run before we delete any pre-existing schema called book just to you know keep the database fresh you probably don't want to do this in production but for this sample we do it to make sure our data is consistent between runs then we create a schema for our books the schema contains configuration details for how we want to vectorize the data as you can see we are using the textto V openai vectorizer and in the module configuration we're using Ada O2 as the foundation model to generate our embeddings finally we'll iterate through each row in our CSV data set to create vectors for each book and we use weh batch creation API to create the vector embeddings and to store the embeddings and related data objects in the we8 cluster okay so now that you know how this works let's run it to do that we of course need to install some dependencies set up a python virtual environment for these dependencies and then run pip install R requirements.txt in our terminal to install the official we8 python client along with several other dependencies needed for these scripts to run if you're repet I think these should automatically be installed into the repple then run python data pipeline populate py when it finishes you'll have data in your we8 cluster and we can begin doing some fun and interesting searches over it with the data in the vector database let's run a simple semantic search over our embeddings in we8 and get a better understanding of how the data is sent back to us as a result of the query there's a script called search. py in the data pipeline directory it demonstrates a semantic search query again to interact with we8 we create a we8 client object then we create an object called near text that lists several Concepts that we want to do our search against in the vector database now the search is not going to look for exact matches but rather semantically related Concepts to those in our list the query is executed against the weed client as shown on screen and the results are then printed to screen feel free to change some of the concepts in your text and run the script several times just to get an understanding of what the responses look like running the script should be as easy as running populate py in your shell run python data pipeline search. py looking through the results you should see a large object sent back with a list of books deeply nested in the response as you can see these book results should be semantically similar to those in the near text Concepts from the query all right now that we know how we can interact with we8 to find semantically similar items I'm going to show you how the nextjs application uses this to surface those recommendations to the web interface I used create next app in order to create the nextjs project and I configured Tailwind CSS from the get-go for styling I've kept the application as simple as possible by limiting the complexity of the interface there's an input field to receive the prompt from the user a grid view to show recommended books and then a modal overlay to act as a single Book View where we can read the description and see other book details the jsx for the application contains a form element which contains a submission button and an input element with various attributes the input field is most interesting because it's What receives the user's input we store that in a value attribute as query this query variable is a state managed in our component up at the top of this index file when text changes in the input field the set query function is triggered and the query state is updated this is just regular react stuff if this is new to you check out a course in react or nextjs to get a better understanding of how it works there's also some beautiful class tags that style the input field through the power of Tailwind CSS The Forum element has onsubmit that triggers a function called get recommendations when the submission button is clicked let's go take a look at get recommendations the first thing is some lightweight validation that ensures the user has actually typed something into the input field then we can trigger a fetch call against API reccommendations once we get a response we extract the book data from the payload if you look deeply enough at the results from search. py we know we can get the list of recommended books from recommendations. dat. getbook we then store it in a state variable and with this we have the book recommendations data in the next xjs client application let's take a look at how we set up the API endpoint on our nextjs app that queries weate on our data set in the pages folder there should be a directory called API and within it is a recommendations. TS file that will be triggered when an HTTP request is sent to /i/ reccommendations the recommendations. TS endpoint will extract the query from the request body and then pass it into the we client as a near text object and query the book vectors in much the same way that search. py did the result is then sent back to the client which we've already set up to be stored in the state variable of the nextjs application the recommendation grid appears with a list of books that come from the semantic search result from our near text query we have these stored in a recommended books variable after a query is made in the J SX of index we map through recommended books and this Returns the relevant divs that represent the recommendations grid the grid is styled in a flex wrap div so that they expand into the parent container and wrap around when a row is filled as we map through those recommendations we render book details to the screen such as the book thumbnail the book title and a button to learn more about the book when the button is tapped we render modal on screen there's some logic that will we select the book and put it into a state variable so that the modal knows how to display it and we also set an additional State variable to force the modal to come on a screen let's briefly look at the modal mechanics when the learn more button is clicked the open modal function is triggered and receives the book details so that we know which one was selected and we set that book in the selected book State variable we'll also have a state to manage the viewability of the modal we'll call modal is open when this state is set true the modal is rendered to the screen this modal contains the thumbnail of the book the author details genre average rating published year and description and these are all rendered from the selected book State since we also have the international standard book number or ISBN for this book we can make a naive query against Amazon to show that book on an Amazon search result when clicked this is just for fun lastly will also include a close modal button that will close the modal from view okay that's all there really is to using we V8 to create a simple recommendation system in a nextjs application with the simple logic seen from this video we prototyped a simple yet capable recommendation system using we8 Vector database thanks for watching this video we hope you found it informative happy building with we8 and if you have any questions please share with us on our community slack or the we8 forums the details are in the description below see you next [Music] time ", "type": "Video", "name": "how_to_build_a_recommendation_system_with_ai_and_semantic_search", "path": "", "link": "https://www.youtube.com/watch?v=SF1ZlRjVsxw", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}