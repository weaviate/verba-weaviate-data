{"text": "Weaviate is used as a database for Jina AI's Neural Search Framework. In this podcast Maximilian Werk, Engineering Director at ... \n[Music]everyone thank you so much for checkingout the we va podcast today i'm herewith maximilian work engineeringdirector at gina ai we're going to talkabout all sorts of things related togina ai's full stack neural searchsolution it's such an interestingsoftware we've been publishing blogposts and tutorials of how to integratewev8 with gina ai and they're just somany interesting components of this soi'm super excited to get right into itso i think a great way to tip off uh ourpodcast would be to talk about uh theecosystem of gina ai uh how you tackleneural search problems and the generalphilosophy behind it hey conor thanksfor having me uh here and give me thechance to talk about jina and how wetackle neural search so as han alreadymentioned last time we have severalcomponents inside gina soi think the first thing that you willcome and touch is the dog array whichsomehow is our tool for massaging dataand loading your data into a format thatgina understands and then all parts ofthe ecosystem can handle you can thinkof it a little bit like numpy arraywhere you put your data and then you cando all the crazy stuff either with numpyor scipy and it's somewhat the same herewe have the data format and the reasonwhy we didn't talk numpy in the firstplace is because in search you haveunstructured data and different datatypes andwe needed some structure to know okaywhere is what umandalso optimize it for network transportso umyeahthis is the doc array the first partthen i already talked about networktransport so we have our ginawe called internal gina core which isthe main package that you also findusuallyand there we care about all the nastystuff that you don't want to care aboutso network communicationdeploying docker images somewhere whereyour nice code is insidemaking sure that when you don't want todeploy docker images but run locallythat you also can just run locallywithout always having the wholeseveral docker images spin upso yeah this is what core takes about soall the infrastructure also coordinateshow todeploy to kubernetes and things that youjust want toas especially as an ml engineer youdon't want to care aboutumthen we have the gina huband i already talked about the executeor briefly mentioned some of theexecutors and the executors some otherworkingtools that we haveand um so whenever you have your customcode you put it into an executorandtheseandwe want people also to share theexecutors so for example we have a clipexecutor we can use a clip either forimage or text as an encoder and we wantthis to be sharable because we believein this social aspect that people canuse other people's code gene itself isopen source so we like the idea that youcan share it by the gina hub but youdon't have to so if you have yourprivatecustom executor for your application orpotentially even business knowledge isinside you don't want to share it so youcan also upload it to our hub withoutmaking it public and just having yoursomehow under your own supervisionand in the long run this hopefullycurrently we are developing alsomore features for this hub which makesthem really acommunicationplatform where people can communicateand also use more services of that wewill offer hopefully pretty soonyeahyeah the gina hub was so interestingi've been loving learning more about itand it reminds me of say like github buti love how it's also like hostedmicroservices and you can query thesemicroservices on the gina hub but if wecould kind of step into the executor andand just to increase my understanding ofand hopefully people listening isunderstanding of how executorsput operations on document arrays andhow flows kind of orchestrate theconnection between executors and so thefirst question i want to ask is aboutthe kind of functions you're applying onyour doc on your document array in theexecutor so are most of these functionsalready contained in the document arrayobject so similar to numpy array arraysuh document arrays they have built-infunctions so uh you know if you'resayingdocumentary.embed or documentary.findor you know the neural informationretrieval metrics is it mostly aboutorchestrating the calls to documentarray and putting them into an executorobject and then wrapping that up sendingit to the network layeryeah i would say so when you develop itlocally then you just have to exactlythis call to the document array andperps and you also load your model andthen you call the modelandthe executors are exactly about okayputting these steps into something thatis really runnable somewhere where youwant to put it in either cloud or onyour server or wherever you want to putit umandyeah you don't need to care about thiswrapping yourself too much especiallyall this network communication this isthen taken away from youumand the document array itself yousomewhere you ask okay what functions dowe have there so we have a lot of um ipersonally use a lot this helperfunctions so when i want to embed imagesthey first need to have a certain formatand so on and i alwaysforget about how to do this and thenthere's just a functional case scale methis is the right thing do the rightthings here and then usually it justworks underneath whichi'm personally super happy because inever can remember how these functionsare called in any other packages andwhich package how i do it andso we have a lot of hyper functionsespecially for image pre-processing butalsoquick data some more understandingfunctionsthem you might not put into an executorbut all this data massaging for exampleas a preprocessor you can put in frontof your model in order to have the rightformat when user just send your query asan image you need to transform it in thecorrect format and for example this youcan put an executor but whatever you doon on your doc array you can somehow putin thereand um we try to do it like the executoritself hasnot much or our our executor that wegive you that you then use subclass fromhasno let's say business logic so there'sno smartness whatever you want to dowith an executor you need to do yourselfbut somehow it really focuses on keepingaway the pain whereas when you want todo things there then you do it on thedrug array this is exactly what youdescribed before there you do youroperations on the dockeryyeah i love the pre-processing uh partof the gina hub i think it's sointeresting the way that you take say abig image and then you either probablythe most naive solution is to put asliding window across it and then puteach of those chunks into its own tensorin its own as you have that nested andhierarchical structure and peoplelistening i love this nested structureof the gina doc array that lets you godefine matches as well as definesegments of these objects so say you'researching through a scientific paper youcan segment it into abstractintroduction related works and you caneasily have this kind of hierarchicalembeddings and that's one of the most myfavorite parts about gina and the thingsthat i've been learning from talking tohan and going through the documentationis i love this hierarchical embeddingthen we just release a new feature letme just hook in there so besideshierarchical embedding we also use thisinternally to have this multi-modaldocument which allows you to store textand image somehow at the same time in adocument which was not easily doablebeforehand but someone then natively useboth of them which is really let's sayyou have a pdf that you want to searchon then you might want to sometimes scanthe search on the image space andsubtitle text page or this space areboth together and so umor if you just think about anye-commerce application so usually whendo you go to a shop you always havedescription of your product and the textand potentially you want to search onboth and this is where we use also thishierarchical structure in a way thatyoucan have both or multiplemodalities at the same time in onedocument but you don't feel it it'shidden and you somehow you just use itas it would be one so that's pretty coolnew feature we just released in a weekago or soyeah that's just so fascinating thatadding the images and text search tosearching through documents whether it'spapers legal documents i don't know howmany pictures are in legal documents butthis kind of thingand and maybe like tables alsothat kind of thing for papers especiallybut um one thing i'm curious about ishow well do these kind of pre-processingexecutors when they're uh you knowwrapped up in that kind of executorlogic how old are these generalized tothe hub souh maybe to give a couple examples ifyou have say an object detection modelthat's pre-trained and it's a part ofthe executor and the object detectionmodel parses the images chunks them saywe found a basketball we found shoes andit designs the uh the overall documentobject that way or maybe you have a pdfparser andthat generalizes toyou know it can chunk up any text andseparate the images is that kind of thevision for how these pre-processingfunctions hosted on gina hub generalizedto all sorts of applications yes i thinkyeah this is a very good point so ithinkthis is what we want we want somehow tosolve all the kind of application but ithink it'snaive to think we have this onesegmenter that segments text and imagesand then boom we're done and everybodycan just segment the pdfssoumwhat i see personally that this usuallysomeone have this generalized chunkerthat does then all the magic is kind ofhard but you rather havecertainuse cases like okay for pdfs i haveperhaps one chunker that does this butthis is just pdf we will have a hardtime to do this at the same time for pdfthen for i don't know what else could itbe the office document where you do thatso andmy vision is that for different usecases um you have different executorsthat can bespecialized and then you need this thesocial sharing becauseum developing one of these executors maytake you several days and to really makeit back free it takes you potentiallyweeks let's be honest that's the caseright whenever you want to make asoftware really good it takes you quitesome time andnot everybody has the resourcesand i believe in new research the theproblem currently is that in order tosolve one research application you cando everything yourselfbut you will it will take a considerableamount of time to make a product out ofitandwhen you look at traditional searchthere you have some more ecosystem whichis has grown over years overone and a half decades or so in order togive you all the features that you needand the features are well approved and alot of people worked on them and theytested them and know okay they work in anew researchor any emerging technologyyou need this a lot of parts try themout a lot of the executors in the couplejust fail and nobody will use them againthat's just i mean life right but someof them will be good and they willsomehow stay and i think the hub is somekind of also place where this umnew ideas happen and sometimes somethingis really good a little bit like an opensource repositoryright and sometimes they are good thenyou have another one which is a littlebit better in usability and all of asudden it raises much higher and i thinkin the hub people have similarbehavior and umso i believe there won't be generalizedexecutors to just do everything butrather a specialized ones and then whenyou have your use case um people wrote atutorial somewhere else and then youknow okay i can use this one becausesomeone else reallyexplained me how i can use this and theni can use this in a good wayi don't have to write it myself so iperhaps need still half a day tounderstand really what happens but notfour weeks to make a production ready sothis is then already you save threeweeks four days and some hours andi think this is the way how uhnew research must grow that you build alot of components and this is also whatwe do in general in general um that wetry out okay let's solve a new problemand then see where do we fail andusually we always wear somewhere butit's not thatso it gets better but still we failedsomewhere and then we see oh this iswhat something that we need to solve orwe see oh lookwe failed in implementing our ownindexer uhnot completely failed but not made thatperfect with all the replication and thenasty stuff that comes when you dodatabases and oh but we wait is therelet's use them let's somehow see wherewe can partner up and um somehow whenit's a really hard problem umi think it doesn't make sense to try tosolve everything yourself but find yourpartners andum yeah this is how we do it and ibelieve this is how new search can onlygrowyeah and i'm really excited to get moreinto partners and understand more of theintegrations uh really quickly i justwant to stay a little more on thisgeneral end-to-end framework and andyeah you mentioned uh there's there allthese different components and they'revery flexible modular and and you canrotate them in and out for yourapplication case and so i've beenthinking about generally this kind oftheme of say fine-tuning adaptation withthese uh parametric models and you knowwhether you have an embedding api that'sbeen trained on internet text and nowyou want to fine-tune it on biomedicalpapers or you want to fine-tune it one-commerce products and it was trainedon you know just internet image textpairs do you think maybe in thepre-processing layer the segmenter couldbe should be a parametric function sosome are doing natural languageprocessing how they train say namedentity recognition models and they tryto like label this is the most salientor let's say like um in computer visionyou famously have things like grad camwhere they highlight like this is thehead of the elephant this is the mostsalient part of the image do you thinkwe should maybe fine-tune these kind ofsegmenters as well for particularapplicationsto be honesti don't know so i haven't worked with anapplication where we had this somehow uhsegmenting part but i think yes just atsome at some point you willrun exactly this problem i'm not surehow good so what i understand when youhave the segmenting for example inself-driving cars this works alreadypretty good on images that you see okaythis is this especially uh when you haveuh self-driving toughcars have a quite kind of narrow domainso you need to identify people and othercars and static objects so it's a kindof um already predefined domain andthere it's solved already but yes you'reright it might be that for for other usecases we exactly also need to um traintheseparts in our pipeline and then um not uhcurrently we we have never i have neverthought about fine tuning this butabsolutely right um this makes senseand i'm really excited to get into thegeneral topic of the gina ai fine tunerand i think it's such an important partof this ecosystem but uh one morequestion i wanted to ask you about uhgina hub and the executors is um so iactually have two the first of which isum so with with the executor logic ifi'm if i want to implement my own customkind of processing on a document arraywherewould i be it would i be able to justhave to have like a for loop where i'mlooping through it how does it sayvectorize it and parallelize it is thata kind of a native thing to define someoperation on a document and then wrap itinto an executoruh yes so i the the executor itself hasthe function i think it's called applyyeah so we actually have the new applyfunction which we also implemented someweeks ago which allows you tohave a document array and just say okaydo with this with every document herethe following and then the supplyfunctiondoes the job for you and also as far asi understand it cares about paralyzingit out fanning it out and making itreally fastand um yeah so that'spossible out of the boxyeah i'm really excited to hear thatwith my cut i've seen so many caseswhere i've switched like a for loop to anumpy vectorization and the differencecould be like 40 minutes to 10 secondswhenthat kind of changed so so it's reallyinteresting for me to hear about thatapply function and add that to myunderstanding so one other question ihave about the general philosophy ofgina hub is are are the executorfunctions are they private if icontribute a gina hub and is this viewedas say my product i'm like a company andi'm i'm pushing this gina hub executoris this my product and my code isprivate or is it open sharing of thecode of the executor that's pushed onginahubhowever you want so uh you can decideand if it's openly passed pushed we onlydo this wire you push your code togithub and tell us here's the githubrepository usuallyandsoi think you can also just push the codebut we encourage highly to alsoshow this is the repository because thiswill also build trust with people rightseeing being able to go to the codeunderneath and check okay is this doingsomething weird on my machines or is itactually doing what i expected to do umwhile not too many people might want todo this i think it's generally a goodidea to have thisbecause some people go in there and willfind malicious stuff and this is alwaysa problem right when you have a hubsomeone can put you something underneathso we encourage to uminclude thecode in a as a gita because therepository whenever an executor ispublic but you can also just push it andget the private executor and then use itprivately and but use the sameinfrastructure so you push your codestill but you get docker images also indifferent genera versions which might benot so obvious feature butwhen we have a new gina versionandif you want to use the same executor youjust can say oh you use a new ginaversion you get another docker imagewith a new later gina version um whichisseems like um yeah okay perhaps thatmakes sense or not but we had bigproblems with this version control ofdifferent versions was of the wholeecosystem different parts of theecosystem and then also people havingtheir individual executors this this canbe quite a painandso do wewant to take away also this pain fromyou and why the hub looksif you look at it it's like yeah okay idownload some code and package it thedocker image which which is therethere's a docker file sowhat is the magic here but there isquite some some things then in themoment you put things into productionyou would feel the pain and we take itawayyeah it's fascinating i imagine yeah iremember han talking about theinfrastructure layer and having thingslike push notifications for when youneed to update one of your uh executorsin the gina hub and overall kind of theflow of versioning and that under thehood stuff that makes a marketplace kindof uh business come to life and and yeahas as you're talking about say thesecurity concerns i was thinking abouthow easy it would be to say add anotherlayer where you have a uh maybe somekind of cyber security model that takeseven like a text representation of thecode and tries to classify if there areproblems maybe something like that butbut like the modularity of it is prettyextensible to add that kind of virusscanning layer onto the infrastructureof gina hub so yeah i don't see that asbeing something that would umbe too problematicjust kind of taking people's functionsand just adding it to your databasepotentially right could benot goodso yeah so so kind of the next questionand i think it comes also this is aboutthe network layer that wraps this and ithink the design of the at requests uhtagging and then you have the paths ithink it's pretty straightforward howyou do that i you just kind of specifythe past and then it has that kind ofsequential flow where i think when itexits it'll it'll just call the nextpath is that correct do they share likeafile system so to say or is it all aboutpassing data from one executor orone wrapped executor to the next oneyes it's all they don't share any filesystem so the idea is the executors canin principle live on completelydifferent machines data even differentdata centers so it's possible that youhavewhen you experiment for example you haveyour local executors which does the easystuff but then you want toencode10 000 images with a clip image encoderand you don't have a good gpu on yourlaptop then you might have an issue butyou can still use uh external executorsoum the whole um ad request logic that wehave in our executors is purely forunderstanding uh when you glue themexecutes together in your flowdefinition umwhen you call which endpoint which otherand which endpoint should be called atthe executor so the easiest example hereis theindexer so sometimes you write data andsometimes you search andusually when you already call the api atthe very beginning of the flow of thegateway you know okay i call the umi want to index later or i want tosearch it but you rarely want to do bothor never and so there i already specifyi want to index now and then allexecutors in the flow know okay i needto do whatever i need to do doingindexingand it might be that you have forexample umyou could talked about index segmentersbefore and the segment i might also havetwo different uhsegmenting functions one for indexingthen you get pdfs so you need to do thepdf magic and get images and text out ofit and the other one might be segmentingjust for user input which might be justpure images and you want to search foronly people in these images find them inpdf's random example and then thesegmenter would get the faces or thewhatever you need to identify people ihonestly have never worked with imagerecognition or a people recognition butas an example somehow when you want thisthen the segment i must do somethingelse but it might be that you canactually use the same segmenter becauseboth is image segmentation so you justhave the logic a little bit differentfor these two functions and then you cando this for all your executors you candefine okay in this pathway you do thisand then the other pathway you do theother thing and then theyyou don't need tobuildtwo executors to do this but just oneexecuted that does both and this oneexecutor also lives on one machinewhich for the segmenter is neglectablesegment that doesn't care but theindexer when you index something and itsaves it locally and the machine and thestate and you want to search can't beanother executor because it should be onthe same machine because executors areum two instances of executors are alwaysshare no state with each otherso and as such they uh when you have thesearch in the index they must happen inthe same executor and you can't just sayi have two of themsouh and i'm sorry if i'm understandingthis incorrectly but so if you call anindexer you would have to put the otherexecutor on the same machine as theindexer rather than say uh like writingthe indexer to a database or like somekind of layer like that and thenmultiple executors access thatmemory is thatuhso yeah when you have the indexerseither it saves the state locally thensomehow you need the index and thesearch function on the samelocal storage because saves it locallyor they have a shared spaceor they have some database underneathwhich they call where the index theindexer is more or less just api layerthen multiple of them can share the samedatabaseand is this kind of the generalphilosophy behind like microservicearchitecture i think like functionalprogramming is that the correct kind ofgeneral uh design pattern of thisyes yes so so having umso let me talk a little bit about thehistory how we came there it might beconfusing but i think it's uhinteresting to to see this example howthings develop so this whole thing iscalled the flow because um originally wehad something like a like a circularnetwork so you send your traffic to oneexecutor and then the next one the nextone to the next one and at some point itcame back to the gateway and thenreturned the answerthis was our initial idea andthere you somehowahwhatever i want to saywhat was your question againthere was something very mentionedthe micro service architecture the uhright right okaywhen you have this flow this is notreally a micro service uh it's kind ofmicro service but it was connected by azero mq so umnot really what you see as okay ifmicroservices apis butyeah yeah not really what how youtraditionally see a microservice perhapsand but we found okay this is kind ofnice because youhave as few network hops as possiblebut at some point we figured out okaynetwork hops might bethat might be preliminary optimizationand we rather want to have one centraland then somehow ask the executors oneafter the other like like a star somehowand then every executor is like amicroservice because you just ask aquestion and you get a response you askthe next one and get a response andexactly then you have them encapsulatedas microservices which youcall one after the otherso is that um i think they call that themaster slave architecture where there'sthe um the center node and it sends upthe um the requests andyeah but master slave is somewhere whenyou have databases and they somehow allshare a common state more let's sayshare some some knowledge and then yousomehow have one that has the knowledgebut here's more like uhumcentral somehow noteit's not another master it's just acentral note there it has differentservices so the first service is asegment segmenter okay get me segmentedor a second service is um index or getme indexing back search services okaylock some information wherever you wantget this back and then the last serviceis perhaps another indexer because youwant to index thesomething else and so it's more like acentral gateway it's also why it'scalled gateway that's our gateway whichgets the traffic and then distributes itwhere it should goand so once it orchestrates thedistribution it flows sequentiallyaround the executorsbut always back to the gateway somehowit comes always backbut without uh writing data to thecenter nodeso it sends itsdata that it's returned to the nextexecutor node and the like if this isthe center and then we get a circlearound itno no it always sends back so what youdescribed just was how it was beforebut this has several disadvantages ifyou have this uh how it was before thenum and somewhere never happensyouneed to either propagate this arrowthrough all the consecutive executors oryou directly need to return the arrow tothe gateway andthere are a lot of when you have thisthe circle flow a lot of features thatyou have in modern micro architecturemicroservices or microservicearchitecture that you can't use andwhich are just not possiblescaling itself gets complicated becauseyou need in front of every singleexecutor you need somehow another minigateway in order to scale orespecially since we say that they can beanyhow anywhere in the world let's so ifone executor sends the next one but theone is local at my machine and the otherone is somewhere in the world then itmight be scaled with five replicas theni locally need to understand where arethese five logo replicas or i need agateway in front of these five replicasand the whole network attention getsmuch more complicated when we don't havethe central uh instance we somehow knoweverything about the architecture thatwe have here and then can umcommunicate thisand at some point the central instanceis the gateway i thinkto be honest i'm not even sure if we canalready replicate it on if we can itbut it's pretty uh soon planned that wealso canscale this one because um when you havejust one entry node and you canreplicate everything else for failurebut not the entry note you have the sameproblem again and so all this should bescalable and then all of theseentry notes have somehow have anunderstanding of the whole architecturesuper cool and so gina has these sixgreat examples right after you gothrough the intermediate boot camp whereyou uh go through the course of executorand flow and uh these tutorials forpeople listening uh in the text domainyou have fuzzy string matching questionanswering chat bot and open domainquestion answering on long documents andimages you have image to image searchsearch images from text and search smallimages inside large images do you thinkwe could walk through say the opendomain question answering on longdocuments to get a sense of the end toend gina system so maybe we start offwith ourcollection of documents we apply oursegmenter to each documentthen we apply the embedding algorithmthen we apply the h sw index and then wekind ofmaybe we have a re-ranking layer andthen we have our question answeringlayer could you help me understand howhow that then comes into the flow andthe executor pattern sure let me walkyou through this uh to the open the mainquestion answering uh guide that we havefirst perhaps a small disclaimer i'm notsure if this is a perfect way to solvethis problem but it should stillshow you how you cansolve tackle such a problem and how touse the gina components so don't expectit to be the perfect answer to the uh orthe latest state-of-the-art answer tohow to do open the main questionanswering but ratheryeah understand the components of ginaso if youlook at thediagrams that you see where you have thegateway then the question generator textencoder and simple indexeryou this is our flow that we have inorder to index our documents soas i said before when you build yoursearch engine you always have usuallyhave this two steps first you need toget your data that you want to searchinside into theindexer and then afterwards you want tosearch it and umhere in this case we built two flowswhich dothesteps individuallyandso we want to answer questions on a bigdocument so someone let me explain shortwhat we want to do so someonegiveshas a big long document or perhaps evenmultiple long documentsandafterwards you come with a question andwant to directly jump in this longdocument to the right sentence and getthe answerand for thishow one way to do this is that you takethis long document and break it downinto paragraphs or sentencesand then youfor each of these sentences youformulate a questionin order towhich would be answered by the sentenceand there are models in order to doexactly this somehow toformulate questions for a given answerand in the later when you search and youhave a question you actually just lookat all the questions that you generatedwhere is my uhsomehowwhere's the newest question to myquestion and then just return the answerumi think this is the progress uh or theway we do it hereand umlet me double check if this is reallytrue yes okay it's exactly the rightthing because we had so many uhapproaches how to solve this problem iwasn't sure if we reallydo this approach in this exampleokay and soso the first thing that we do iswe build our query flow and you see thegateway and this is um what why it's atthe beginning and at the end becauseyour user will interact with the gatewayat the beginning once when you send thequery and at the end the gateway willanswer so the for you it feels like thequery is going around what i explainedbefore actually the query goes from thegateway to the questions generator thenback to the gateway then to text decoderthen back to the gateway then to symbolindexer and then back to the gateway butfor you it doesn't matter so from from aconceptual thing is just okay it goesfrom one executed to the next oneand so the flow is the the complete uhuh graphic that you seefrom left to right then a singleexecutor is one of theseteal boxes so for example the questiongeneratoris theis one executor and in this questiongenerator is themodel that takes a sentenceandpredicts a query aquery thatwould be answered by a sentenceand the question generator itself alsoum chunks down the document as far as iremember so it also cares abouthaving when you have long documentmaking it to shorter documents so thistakes care of both these thingsand the next executor is the textencoderthisthen takes the questions that come inand encodes them intoa vector spaceso this isthe first model the question transformersomehow is just for transforming orgenerating queries and the second modelis now for generating us the vectorsthat we need for vector searchand then we use a simple indexa to storethe vectors inside the database and thesimple index are somehow local databasewhich you can easily use which doesn'tgo anywhere in the cloud you don't needit just needs afile path and it just saves there sourcedata and you can retrieve it later onso it's very convenient for localexperimentsand so so do you have any questions hereuh directly connor about whatwhat is whatyeah this this this looks great and it'svery clear to me how it flows like iguess like and i'm sorry that i'mgetting hung up on this i bet maybelisteners also have already kind ofunderstood this and i'm just a littlebehind but so the the gateway is theabstraction of the networking object sois that correct the gateway is the thingthat'suh just kind of contains the informationabout the sequential order of how to runthings and where they're hostedyou know what as a user you don't careabout the gateway you never see itas a user you just see the flow and youstart something and then you have an apiand you call the api and you don't carethat there's a gateway but yes you'rethe gateway is somewhat the centralpiece that i talked about before thatsomehow where you can send your requestto and then this takes care that all theexecutors are called in the right orderand when they're scaled also that thetraffic is distributed evenly betweendifferent replicas of one executor andtakes care about a lot of these uhthingsand so um so are these executors so theflowor points to where they're hosted withtheir api endpoints and do you hostthese executors on different cloudservices so saymy pre-processing is hosted on my localmachine but then mydocument embedder where i'm runningqueries through a sentence transformerthat lives on gpu ec2 or something likethat and then we come back to saysome kind of host for the queries is isit likeis so so you post the executors each ondifferent machinesyes however you wish yes you can hostthem all the same machine you can hearhosts in a different machine you canhost them all in one kubernetes clusteryou can even not host them at all and wehave the sandbox feature that i thinkyou mentioned earlier where you just sayi want to use this executor from ginaplease just use it and then the momentyou send traffic to us we spin it up ifit's not already spun up and then youcan just send queries and after 50minutes or soor i'm not sure sometime it gets down ifyou don't use it but as long as you useit you can just use and use it andcurrently it's for free so you don'teven have to host the executor itself soumyeah but in principle that's exactlyright you can put them wherever you wantyeah we have a similar service with thewe va cloud service that helps you dolike a free sandbox of these cloudservices and i agree i think it's soimportant for say integrating up with uhlike google collab and getting a quicksense of the networking layer and how todo that kind of thing so that was superinteresting and i love this tourlet me directly go in here so if you forexample you have the simple indexerwhere i said okay this stores everythingwherever the simple index lifts but youcan also use um um somehow abbreviateconnector vivian api and this isn't justan executor which whenever it gets thenthe would not index locally but wouldexactly use this vivid cloud service andthen send to this uv cloud service andit's stored there and when you search itwould somehow uh be also like a proxyfor the vv8 database and then you cansomehow when the query comes the queryalso goes to deviate and the result isreturned back and then you somehow youuse gina as an orchestration layeraround vv8 and but use the the power ofthe database itself umin the viva cloud for exampleyeah that's so exciting for wii veda ilove that you just with the networklayer you just have the dot slash pathand then the the vva cloud service givesyou your end point and then you justplug it right back into the gina flowi love that part of it and and switchingfrom the simple indexer to the vividindexers just use the other thing withokay you need credentials to alsoconnect the database obviously theexecutor needs to connect but that's itsomehow so for uh when you developlocally you can just try locally withoutuh caring about ubv cloud and then inthe moment you want to change you justchange and when the indexer has the sameinterface it justworks yeahit's amazing it's so exciting and umso so i thought that was a really greattour of the executor and flow and i alsojust for people listening i highlyrecommend the intermediate boot camplike that's just the latest thing that iwas at with trying to get my ownunderstanding and it was super usefulthe documentation is excellent for thesekinds of things so uh the next thing iwant to talk about is the gina ai finetuner i really want to get intokind of maybe you could introduce it andthen i could kind ofget the particular things that i'mcurious aboutokay so i said earlier we had thisproblem that at some point we umhow we do it we try out to use ginaand we see where we fail and then weimprove thereand originally we thought okay theactual problem in solving neural searchis not that themodel getting a good model but theproblem is the old infrastructure and ithink this is true but solving newresearch has a lot of open problems andwe figured there are people that areable to fine-tune their modelbuta lot of people that have a business orproblem or want to create a startup oralso already have a search um they don'thave the resources to do all the sametime to spend researching a newecosystem and having a machine learningteam to build their orcompute their own model andwe tried severalour customers somewhat to to sell themgina or some more explainer you pleaseuse them and not even sell just let themuse it and we figured so much so oftenactually they are not able to get thequality under control themselves sobecause building up this knowledge takestime takes resources so they can't justdo it and it worksum even for big companies it's nottrivial to do so um and so we thoughtokaythat's obviously the next constructionside where we need to go i need to dosomething and so we uh invented the finetuner or created this fine tuner and umthe idea was um initially to be uhsomewhat agnostic to the systems usepytorch or tender flow and or pedalpedal and then you somehow have yourproblem you bring your data and then youget a better modelso you also bring your model and you geta better modeland i think the open source fine tuneris pretty cool and it's usableumyou haven't seen too much progress inthe past two months perhaps becauseum also doing developing it we alsofound okay it's nice it's a nice toolbut also in order to use it you can needquite some knowledge how to use itbecause you need to understand how toconfigure it it gives you all the toolsthat you need but you still need tounderstand how to use it and it speedsup your progress but still not enough toallow people that are really umjust have their business problem theycan already use it so you still needquite some machine learning knowledge touse it well and somehow uh use it umin the right way which a lot of peoplehave so for them it's also i think areally cool toolor also a time saver tool but um wefigured okay actuallywe need to develop it further but we arenot sure what is the exact rightdirection and so we first said okaylet's first develop in-house a littlebit more uh continue developing it alittle bit more to one or two specificneeds that we have and not keep it ageneral purpose tool it was in the opensource version and try to solve reallyone or two very specific problems withit and thenwe're not yet sure what will be the nextstep perhaps you open source it againperhaps not ummight happen that we open source it thenwhen we go further but we didn't want tohave this development in the openbecause if we would have said forexample oh okay we throw awaytwo of the three frameworks just one andsomeone would be unhappy and we need toargue and we need to make sure that umwemeet the requirements we add a newfeature and with gina we have added alot of features in the past then at somepoint we discovered oh we need to throwit away because it's actually not goodand it stops our path further down theroad so umhere we said okay let's inner source itlet's uh for a moment uh keep it awayfrom the community to not disturbourselves and then let's see where we goit might be that we we definitely offerservices around itand potentially we open source it againat some point in timeperhaps even soon so this is not yetdecided butyeah but the reason is not that wesomehow want to inner source it forkeeping our knowledge but forhave some calmness in developing itfurther and really figuring out what weneed thereumyes and wei guess in the next two or three monthsyou will see some quite exciting newsaround the fine dinnerwhich then again makes it really reallyeasy to use it and yeahthat's super exciting and umso yeah it sounds like such a there areso many parts with the fine tuning thingi mean i think the tailor layer isextremely exciting the uh you know thethe idea of masking out parameters sothat you're only fine-tuning say fivemillion parameters of a billionparameter model and then that way itreduces the cost of doing so and irecently spoke with jonathan frankelfrom mosaic ml and composer and howthey're implementing all sorts of thingswith this kind of model augmentation todo that kind of efficient fine tuningand so then one other part of the puzzlethat i see is say the data labeling andso i'm kind of curious like and then andthen there's also for people to get afull picture of this fine-tuninguh ecosystem there's also the the hardnegative mining there's particular lossfunctions like triplet losses or maybeyou have some kind of contrast oflearning objective that are differentfrom like cross entropy y minus y hatthat kind of thing so so there are a fewdifferent things with it and one thing ireally wanted to talk to you more aboutand get your thoughts onis the data labeling thing how and hanhad mentioned that um say with um amazonmechanical turk people are get prettygood at labeling data but you still needto have a a good interface to to show toshow them how to label the data to youknow what what is this about really haveyou thought about the data labeling kindof software space and how that ties intothis particular problem of similaritylabelingyes so if you follow the progress in thefine tuner you have there was a labelerat some point and we took it out againand you might wonder why and the simpleanswer is it was not the quality was notgood enough for us that we want to keepit so we didn't felt likegood enough to keep it there andit was not yet the tool that weenvisioned and sothere are other labelers out there thatare alsomore or less specific tofine-tuning search problems butnone of them really convinces me so andso i still see the problem there sothere is an open field so if you if youif someone in the community knows a goodlabeler where they think okay this nailsearch labeling please put it in thecomments of the show because i want toknow where i want to have the samesynergy as this v8 because it would begreat toget this off our shoulders butstill butit's still not a good there is no goodtool uh at least i have not found a goodtool and um so this is definitely neededsoif this there is no good tool in threeto six months yes i guess we will takethis challenge again and we'll try tobuild a really good tool because um thisis neededyeah i'm gonna i'm gonnarecommendperhaps let me explain why it is so hardfor search because in solando actuallyso i worked before celando similar ashan and there we had a labeling toolin-house and this was actually great butcertainly not open source in this caseand so because for search labelingumin the end you want to have when youhave a query and you have let's say 10000 documents in your catalog you wantto say which of these 10 000 documentsare goodumsowhat you need you need to see for onequery a lot of answers perhaps not all10 000 but at least the top 100 fromwhatever is your search metric and thenstart labeling them but over time youwhen you have uh it might be that youmissed some down the road somewhat thatsomebody labeled some documents in thelong tail that's also totally finebut um when yougothen and search and change your yoursearch engine then it might be that somein the long tailturn up to be in the top resultsand then you actually need to label themagain so i think labeling is for one atool that you need but also to figureout the right process to do the labelingin a waythat you canget to measure the right things becauseif you miss something in the long tailand another algorithm picks them up andputs them at the top righteously but younever label them you will never notmeasure it and actually you might see ohthis algorithm does not perform so goodbecause some things that you labeledinitially but might be not as good itjust went a little bit down and solabeling in search is an extensive taskbut also it is a task that way you needto understand how you do this umprogressively and yeahone more thing there and once you labelsomehow when you have this long tail andonce you start labeling again somethings a long tail and then you evaluateagainyou also must evaluate your firstalgorithm again against the same dataset so this is again a moreoperational problem than a labelingproblem itself soyou label your data set over time itgets better so your data set is also notsomething that you're just aestheticwhich people from that come out of thescience world they have the data setaesthetic you won't touch it againsomeone has done this data set that'sperfect but no i think when you have alive problem a real problem that youwant to solve um you will have had nothave the chance to label it thoroughlybut you need to iteratively label toreally measure your algorithms and thisis um yeah as i said more operationalproblem than afront-end tool problemcould you um what the long tail thingcould you help me understand that doesthat refer to maybe you've asked a verybizarre question and it's long tail inthe distribution space of the queriesthat it sees or is it say long tail inthat um you ask a question and most ofsay it's you ask a question wherethere's new information and most of thereturned documents are that oldinformation and then you know maybe onresult like 73 it's found that newinformation and that's maybe the longtail or you help me just understand yeahokay we had before the um quest open themain question answering and so imagineyou have now 10 documents which you wantto search and in total they have each athousand sentences so you have athousand sentences that could be theright answerand now i have a question whatever it isthink about it any questions do you havea good question that we can play aroundum i like thinking about like who wonthe nba championship because it requiresupdating the information and then itrequires also that reasoning aboutunderstanding the year so you say whowon the nba championship in 2022particularly i love it i love it okaylet's say who won the nba the last nbachampionship that might be the questionactuallybecause of the crisis context so and youlabel the first time and then with anand you can't go to uhtens ofsentences so you need to somehow labeljust some sentences so what you usuallydo there is you have some search systemit just gives you answers and you gothrough the top 50 answers and you labelthem and now you have this question andyou may see oh uh in this year this isthis uh okay this is kind of relevantperhaps a perfect relevancy so youusually do not relevant kind of relevantsuper relevant or even more fine-grainedsome more labels and yeah they might sayyeah okay this is kind of relevant butnot the perfect relevance and then youlabel this and umyeah you do this but you don't get theperfect so the last in the top 50 thelast year was not in thereand um so now you might tune youralgorithm and then it's a and the rightanswer is somewhere atposition 280. and now we tune youralgorithm but out of a sudden the rightanswer is at position nineand now you need to go there and fightand somehow see again okay the rightanswer is actually bubbled up andsomehow now i need to say okay nine isgood so nine is much better than 280.or per that also heavily depends on yoursearch problem soif google puts the right answer on placenineyou might not be happyif your e-commerce search platformputs the right answer on the rightproduct on place nine which is reallythe right fit that might be totally finebecause you anyhow c9 product at thisthing and you can immediate the imageprocess much faster so um how much ofthis you have to re-evaluate from theseanswers to in order to also give creditto the new model that actually answeredthis question much better it very muchalso depends on your search system so inan e-commerce search plus you mightalwaysre-label all answers under place 9 or 18or 15 or whatever it is for yourplatform but for google you might say ohno only the top three are relevant so ionly need to re-label the top threebecause when my new search engine putsit at place four it's still badand umyeah so but this is also againoperational so you need to understand umthis is your your system and and this ismy problem and um how do i do therelabeling and so i think this for thislabeling we need to better understandhow to umfirst solve some very specific problemsand then generalize it to provide a toolthat actually different people can useand um soso i see kind of two layers of which youcould do this fine tuning you could tryto say you have some massive modeltrained with contrastive learning on amassive data set and that produces yourinitial embeddings you can maybe try tofine-tune that to adapt it to your datadomainor you could have say a re-ranking layerafter that in which you have a fewoptions like you could have a pairwiseencoder that takes two inputs at a timeand ranks them like that or you couldhave maybe a mapping from the embeddingvectors into a new embedding vectorspace or maybe you could stack themand predict the rank order with thesoftmax labelingyeah andnow i ask you another question so how doi evaluate now the first modelso i can evaluate both models togetherbecause i want to my final result isgood or bad but now i just want to trainmy first model and develop fine-tuneboth models separately but i want tofind you the first modelumwhen does it get betterit gets better when the second model canreally digest it souh it's not even clear if you want tolabel just be after the first model orto get better training data how to do itsomehow how to make it better becauseit's not clear if if some uh relevantquestions bubble up the second modelwill perform better or worse off itmight be that itbubbles the right one up but also somereally disturbing answerswhich disturbs the second model bubblesit also up and then the second modelperforms all of a sudden worse even sawthe first model and average performedbetter and sothen the evaluation again sure you wantto evaluate the whole systembut uh so if you just want to evaluateyou can create your valuation data setand that's finebut if you want to trainfor the second system again you knowwhat is your results what you want totrain for but i have no clue how to orit's not trivial and obvious how todefine the trainingparadigm for the first question but comeback to your question yes fine-tuningthe second model at some point is alsoreally important because it's re-rankingespecially insearch questions where the first answermust be right is super importantthis is an absolutely fascinating pointyou bring up and i'm a huge fan of likemichael bronstein and their work ongraph neural networks and geometric deeplearning and this idea that if you ifyou have a graph neural networkarchitecture prior and your re-rankerit'll be invariant to the rank orderthat your first embedding model hasproduced and that way you don't havethese propagating errors where uh yourre-ranker might be used to this certainlike because it has the prior of lookingat it as these this stack of vectorembeddings and so i think um at thisholds only true if your first modelprovides you the same set of 500 answersthe answer the all of the first 500 isirrelevant but if you're out of a suddenfrom the 500 250 go out of the set and250 new come in then the graph neuralnetwork model will still give youdifferent resultsoram i mistaken hereuhi think it would be i think it would beit would treat it as a set right so itwould umso if um so if you if you fine tune yourembedding modeland you get a different 250 i think thethe general idea of the graph neuralnetwork would be to make it lessfake less biased towards the initialranked listso as the embedding model changes itdoesn't propagate the errors into there-rank or as heavily as if it has thisprior ofthe initial rank order and sort ofprobablybiasing itself to predicting it that waybut i guess there are things like intransformers how they have that umposition encoding like where yougive it the signal of left to right intext sequences you could probably addthat kind of prior and maybe so maybe ifyou cook in that kind of embedding inthe input layer then you would stillhave that problem maybe something likethat it's just kind of something i'mthinking about as you're telling meabout this problem butto be honest i i have not looked intographics too much so i i uh i have ahard time answering or giving betterinsights thereso i'm sorry for thisi think like the key thing is like thethe bias in like a convolution is likethe answer is locally structured sort ofand then you bubble up the localstructure and i think the transformersof the graph neural networks are morelikeglobalkind of prior but yeah it's afascinating thing and definitely i thinkgraph neural networks are on that likecutting edge of thing where i'm like doi want to use this is it mature enoughwhere iam going to have a good understanding ofhow it fails but all that kind of stuffso it's a super interesting topic umfine tuning labeling all the differentparts of fine tuning and search systemsor fine-tuning your embedding model yourre-ranking or maybe the downstreamquestion answering functionality uh canyou tell me a little more aboutparticular experiences at zalondo andi'd love to hear about the story of howyou and han met and came to be workingtogether at gina as wellyeah so and i worked sometime in thelandlord then i was asked oh do you wantto join the search team and was a newteam founded somewhat they shouldrestructure the search build it from anold monolith to microservicearchitecture which sounds greatuntil you do it um andyeah then i joined the search team andactually the first day i came there hanwasn't there so i took a place and justsat in his place because none other wasfree and but some days later he hesomehowuh yeah i then left my hand spot and wesaid someone none and me said all in arow which is kind of funny so they arenow the ceo and cto of gina andyeah life happened and now i'm also hereand um there weumhan had this vision of this new researchalready and in the beginning ii was pretty skeptical because umi have before worked in the pricingdepartment and i have seen bring machinelearning liveneeds a lot ofknowledgeof the problemso uhgetting the model right okay yes themodel must be good otherwise it willfail definitely but it's not the umperhaps not the hardest part becausegetting the model right once you haveformulated your problem you can do itsomehow this is uhthere are people that are smart enoughthat can solve this problem but umunderstandinghow to actually solve searchturned out or generally how to solve abusiness problem in my opinion is oftenthe harder part because there might berequirements which you don't seesothere's always a cto with their mostloved question and this should be rightanswered if you fail your model can beperfect if it fails this one questionthe cto will hate your model so and thenyou need to somehow build around perhapsaround your model uhkind of a safety net which helps you tofilter out the bad results orkeep good results that you developedover time which is completely unrelatedto machine learning so it's just anengineering task that you build aroundyour model and um so but after some timehand and convinced me okay this might besomewhat doing this noodle search withvectors with embeddings might be areally cool thing to doand going away from the traditionalsearch pipelines umandbut then two other guys implemented italso put into production and i came tothis team only later so i can only inretrospect say what they did and theproblem is ham left salandoand someone else took it overandit's always when someone completelyleaves before having a proper handoverwhich took some time and someone elsereally onboarded the code there's alwaysthe code is always dropped and then theother person also left so what they didin the search team is they said okaylet's try it again and let's do it supersimple we don't do any multi-layer wejust do a one-hot encoding of all ourproducts of all our queriesand that worked pretty wellto a certaindegree andwas in the end a very simple approach tothe problem um just having this one hotencoding with which cylinder has amassive amount of data so we could justuse a massive amount of data train itand that was goodoh it wasyeah well it was i would say it was kindof good um it also was used inproduction and we could see okay weactually improveon different kpisgive me a second togather my thoughtsyeahwhat i figured out there um is that uhhow we then put into production was inthe end there was no model in productionthere wasno no fancy there was a lookup tablethat was pre-generatedwhich uh somehow um back in the days wasthe easiest way to integrate it in therunning system and then to build sometrust that actually we could providevalueand then only after week andwhich is when when you think about howgina doesn't research is always fullsystem for pipeline but back then therewas nothing like gina that was just wehad to build everything ourselves andthen the easiest way it was just okaybuild the lookup tableand provide answers for certainquestions where we said okay we forthese 300 000 queries we havepre-generated results which we can lookup and give the users and um then againuh it was interesting to see okay how dowe do training there so we trainedpurely on click data and now fashion isa really umseasonal thingso and in fashion you have every seasonnew items and the season switches and soon which data do you trainand we wanted to you could train on allthe data in the pastthat was too much and then you also havethe really old data in there which iskind of imay not give you too much insightbecause my maybe trends that don't existanymore so um it's hard then you can'tdo just for last four weeks because whenyou just train in the last four weeksyou have the problem that um when youhave a season switch you don't have theold season your trading data so youcan't answer any new questions about thenew seasonso we came to okay a good thing is justtake one yearand you have a full season cycle somehowinside your training datawhich uh yeah and then but then thetraining data was quite big and it cameto me ops problems which was not reallymachine learning but rather okay how cani put the data there and and umdoseveral training runs andsave my dataum andagainrather operational than just the thepuremachine learning magic was not not somagic butgetting it running and getting theengineering behind it done was often thethe real challengethat's super interesting and umso i think so it was a couple things anduh so one thing i wanted to maybe unpackis umis maybe is it this idea of sort of likea test time calibration layer thatyou're describing earlier like uh likean ensembling and then you kind of havemultiple ways of maybe when you have atest query you map it to a few differenttrain queries so so like if you have afrequently asked question template thethe problem is about taking a new queryand trying to find the most similarquery that you already have is that kindof theone of the architectures you'redescribingthis was yeah this was exactly this longuhlong document question answering exactlythat exactly you do this lookup table ina prepared questionsthat's super cool and hearing all thatsort all these uh different componentsof it is so interesting and i'm curiouslike currently do you have like anapplication that guides most of yourdevelopment oris it about mostly just like kind ofbeing a master of a bunch of things andgoing in and out and seeing how itchanges the overalllike holistic view of it yes we actuallyhave some clients that somehow guidesour development and some more i comealways new challenges that helps us someuh understand where should we goum so that's very helpful because theydon't have our uhour own goodwill somehow obviouslythey have their requirements and they'renot just okay i can keep a blind eye onthisfloor so that that's obviously prettygood but um internally we have when yougo to our documentation page you have toa bot at the bottom it's like a chatbotwhich uh where can ican put a question and then you getdirectly jump in the documentation tothe right placeand umthis is something that we need to knowor that we use in order to test our owndeployment ourownumalso uhnlp skills somehow uh develop thisfurther and umthis might become a product at somepoint in time but for now it's mostly toin order to test ourselves so actuallypeople just said we need to understandhow how we do things and so this is onething we have um one more um imagerelated uh project which we may announcepretty soon but i don't want to talkabout this ohtoo concrete but there we did a lot ofresearch and how can we actually do ittext to image and image image searchwith better quality and there we heavilyuse the fine tuner and that okay this ishow weconfigure this tool correctly in orderto get realor quality that that really impresses usthat we like and that is better than thepure clipthe default clip modelumyeah and as i said we have some someother also with other modalities fromfrom customerswhere i can't really talk about it i'msorryis um in the multi-modal space and ilove how gina has this kind of thingwhere you can add the text and images isvery uh natively integrated how you inthe document object you have dot textand dot tensor to put the imagedo you think about other kinds ofmultimodal fusions and generally is thisone of the core motivationsso what works surprisingly well is 3dmodels so when you have 3d models of anykind which you have i mean everycomputer game is full of 3d models everyfilm that you watch is a movie that youwatch is full of computer of 3d andmodels andin the moment you have some richor at least a little bit of metadata tothemor to some of them must even be for allbut for some of themthis is pretty easy to train because itis very restructured you have whichmodels can pick up wellsoi would say 3d models is actuallysomethingwhere i don't see yet that people comeup with a ton of problems but i believein the moment people come up withproblems we can actually solve thispretty well with your research sowe have seen some and they're reallypromisingandsoif there are people in the audience thathave a 3d model a search in mind wherethey say oh i have here thisapplicationthen please use your research or tryyour new research because there you willhave a lot of success really in shorttimeyeah i guess forvideo you have the problem that videosare so richthat we need to refine ourunderstanding of neural search socurrently it's oftenone query vector to one result vectorbut if you have a video and you justhave one vector for your video thatobviously doesn't work because even the10 second video they might be driving acar in the background there might be adog barking there might be someoneshouting there might be some someoverlay so there's so much informationin the video that you can't just saythis is the one thing that this thisvideo is aboutso there um i think that the research isalso developing this direction that youhave these um multi embeddings for onedocument where you somehow say okay thisis my my video and now i get 10embeddings out of it and then he'sembedding someone focus on differentparts of the video or somehow and thisthey're i'm not sure how they named butthere are new models where you alsodon't say okay please this embeddingfocus on audio this on text but theyautomatically give you somehow themultiple embeddings andtherei believe the research is not yet farenough that this will go intobroad production might be that googleuses it okay fair enough butin the broad production but it's also isee some development there and i foundthis this multi-embeddingidea very fascinating because itis naturally the next step if you alsoif you have a sentence potentially thesentence is about two different thingsand sometimes when you search this onething is really important and withsomething research the other thing isreally important and perhaps it's a badidea to have just one embedding forthese two topics but rather you need atechnique to have two embeddings butthen also to combine them in the rightway and um these techniques uhdeveloping this umi seeuh quite some potential in the futureyeah even for for just so sorry forinterrupting no even for just somehow uhfashion search because i come fromsalando i mean if you if you search fortake my shirt you can say okay it's afloral shirt so the embeddings can canfocus on so many different uh partsunder the arms okay it's a little bit uhlooser under the arms or it's as v-neckor whatever it has so it has so manythings that you canlook at detail at and when you searchfor it that you might care about thatone embeddingumi i'm curious if we see there at somedevelopment it comes back to yoursegmenting so uhyeah very segmenting this is just like asegment right you have your uh just adifferent perception you have your onyour document and you have differentsegments inside this document that youthen want in code or yeahyeah that's fascinating maybe like agenerative model that can add somecontext to the query and and have a fewdifferent ways so you can have that kindof like ensemble of different ways offorming and embedding of a query i alsoreally thought that was superinteresting what you're saying about 3dobjects because it has that like depthinformation that's so important aboutour visual world whereas uh videos theyyeah and they're very noisy with all thethings that could be in the backgroundthe audio and and they but they're still2d slices even though they have thatkind of motion and time prior that thethat the the 3d images don't capture butuh could give me a couple examples of 3dis it like you know like point cloudsfrom lidar scans is that maybe like mrisi think are naturally 3d and in gamesthese are kind of mostly the things thatyou're looking at or something yesyes it's really uh i think um sowe haven't looked yet at laser scans buti think there is really promisingbecause um i mean you need also somepre-processing you have laser scan youmight have uh i don't know severalmillion points but then you need tosegment them again also the search queryso there out of the sudden we have laserscan i want to identify okay which iswhich object here and but your catalogmight actually be just uh whatever otherobjects let's say a house have acatalogue of shelves of desk ofdifferent chairs and now i have my d3scan and i want to have a 3d model withexactly the right pieces then wechange somehow the paradigm between whatis query or somehow the size ofinformation in a query and in the resultso whereas an e-commerce or wherever youhave a lot of information about theproduct but the query has three wordsout of a sudden you just have this oneshare but your query is huge and youneed to first segment down your queryand then answer like multiple ofqueries inside one query so umtherei believe uh the identifying of theobject itself once you segmented your3d scan correctly it's kind of easykind of easy but the segmenting itselfmight beperhaps also easy i don't knowbut yeahto these guys is one thing then thesecond thing isthat we see is exactly 3d or models ingames in whatever movies where you havejust a database of 3d models and thereit's also when you want to then buildyour game and you have a character youwant a similar character because it's abrowser of the other character theyshould look similar so then get anothercharacter which looks similar or sixlike this i think there it's umyeah it's uh it's just amazing the umthe i see it kind of as we va and ginaai and addition to kind of looking atthe search application where it's kindof building like the data structurelayer as well for these multimodalobjects and you think about say visionbased robotics where what they're tryingto do now is they're trying to hathey're trying to bring like the successof transfer learning to robotics wherethey want to have the success of gpt-3kind of adapt to any domain they want tosee that happen in robotics and whatmaximilian is describing this havingthese say lidar scans that create these3d point clouds of the scenes and then imean you'd also need a video of thatright it'll befour dimensional even right you'd havethe uh the time axis of the frames asyou do these scans but the richness ofthat data and putting it into datastructures like the gina ai doc arrayand how it makes it so clear how tostructure multimodal data where you haveyouryou know you could have the 3d data thevideo of 4d data with the video with thepoint clouds as well and you can alsohave text descriptions of what therobot's doing maybe you have meta tagslikeyou know this video is collected insideof a lab in berkeley and the lightingwas thiswhatever meta symbolic tags you want toput on but this is like the datastructure for putting unstructured kindof multimodal data together and then yougot the we've a database puttingtogether these indexes for efficientsearch throughabsolutely massive collections ofvectors as we see things like billionscale similarity searches and all thisis just so exciting soi really enjoyed all this uh talkingabout all these topics maximilian it'ssuper exciting this field ofneural search and i think just so muchexciting technology is being builtso thank you so much for uh for being onthe podcast if there's uh maybe anythingyou want toconclude with that i might have missedonno i think you you nailed pretty much sothe purpose of this uh understanding howto really get the quality up and uh issome exciting topic for the future fromtheoperational and from theuh tuning itself perspectiveyeah yeah definitely and i really thinkso much for having me here it was reallya pleasure somehow talking about uh ginaandmy view on new research itself so yeahthanks a lot for having meand thank you so much and i really hopeyou'll be interested in coming back onthe podcast to share further how yourunderstanding is developing with allthese things and just super excitingthanks againawesome[Music]you", "type": "Video", "name": "Maximilian Werk on Jina AI&#39;s Neural Search Framework - Weaviate podcast #15", "path": "", "link": "https://www.youtube.com/watch?v=o6MD0tWl0SM", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}