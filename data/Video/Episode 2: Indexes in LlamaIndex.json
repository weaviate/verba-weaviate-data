{"text": "Thank you so much for watching the second episode of the LlamaIndex and Weaviate series! We cover the three indexes (Vector ... \nhi everyone welcome to the second episode of The Llama index and we V8 integration in this video I'll be going over the various indexes that are in llama index and I'll draw it out so you can see the architecture design and then I'll share a demo of how to use the vector store index and the list index thank you for watching and let's jump into the video I just want to make it clear that there are other indexes that are offered in llama index so I'd recommend checking out the documentation but for the point of this video I just wanted to keep it quick and to the point which has three indexes that I used in My Demo so with the vector store index it is is it takes each node or chunk of text and stores it in a vector database along with its embedding but the list index does is it takes the nodes and just stores it in a sequential chain so each chunk once it ends the other one begins and it's kind of like that sequential order and then what the tree index is is it has a root node and then a parent node and then each parent node has a child node and this is obviously really good for summarization task um but yeah keep in mind that there are other indexes I'm not covering at all in this video but I hope this helps and I think it would be even better to see it um and like I can draw it out I'm going to start with the vector store index so what this is doing is just taking each node or a chunk of text and storing it along with its embedding and adding it to or importing it into the vector database so here I have my three nodes and then the embedding I'm not a very good drawer so let's just say the N is a node and then let's say that this pink outline is a vector database because that definitely makes a lot of sense kind of right okay so given that given the nodes and the embeddings are stored in the vector database what it looks like when you are making a query is you take your query embedding which I guess let's again denote that as a cue because that makes the most sense you're going to embed that and pass that into the vector database and why would you want to pass it into the vector database it is because it needs to retrieve the top K documents that are most relevant for your query so what this is again is the query embedding okay so once that is passed in and let's say the first two nodes in this example are the most relevant this will then be sent to the response synthesizer query is also sent here so what this response synthesizer is doing is it's figuring out a way to combine the top K retrieved documents into one single output and there are quite a few ways to configure this setting so you can have a tree summarization compact The Prompt or just use the default setting there are a few different options and I can cover that in another video but at a high level that is what this response of this is doing moving on to the list index what this is doing is taking each node and storing it in a sequential chain so so just spare some time there um so here you have node one two and three and it's as easy as that so what happens when you make a query is it is passing it to all of the documents or nodes if you aren't specifying a specific filter so essentially if you don't make any um kind of like if you don't specify the filter for your query then it's going to take all of the nodes and then it just passes that onto the response synthesizer which I'll just write as RS um and this is good for short documents and in the demo I use this to kind of store the very short meeting notes that I have as like an example but yeah that's what a list index is doing moving on to the tree index what this is doing is building a hierarchical index from the nodes from the set of nodes so here we have the root node and then that is divided into two parent nodes then each parent node is going to have a child node just copy and paste this four times there with me okay so now we have each parent node has its child node so C1 and C2 summarizes the parent node one and then obviously C3 and not they aren't two c threes there is C four summarizes a parent too and then that again goes up into the root node and my this is obviously important or a good architecture design or index for summarization is because each node is carrying um some information that is unique to child 1 and child two then eventually that goes up into parent one and then the root index is summarized um and now I'll show what it looks like or how this is done when you are making a query so now when querying a tree index what this is doing is passing the query to the root node and then it like Works its way down to the leaf nodes or the child node for example so there is a way to specify the number of nodes and this is done with the child Branch Factor parameter um so if I set the child Branch parameter to one it's going to take this node given the one parent node but let's say I have I set this to two then it's going to take it's going to use both parent nodes and then C2 and C3 for example so then once the child nodes or once you've defined the child Branch Factor again the query is sent to the root node and then the two child nodes are then sent to the response synthesizer now I'm jumping over into the demo in episode 1 I covered how to load data into leviate using llama index and vice versa so in this video I'll kind of like Breeze by that so if you aren't up to speed or aren't familiar with this process I recommend checking out episode one and then jumping back to this video so the first step is to connect to your weebead instance and you simply do that by connecting or passing in the URL to your repeat instance um and then after you have connected to your instance you're going to want to create your schema the point of My Demo is to convince a client why they need a new feature in weeviate that we just released in 120. so for context when I make the query I'm using the blog post and the podcast as like an information Source if I'm like why does the client need multi-tenancy or why can't like how can reftubec benefit their application these are kind of the sources that the language model needs because it needs to refer to the blog post and the podcast to have that context and understanding of what I'm talking about all right so first in order to do that we have to create this schema um so here I have my blog post class and then the content property and that is just the text that is within each blog post and then separately I have the podcast schema so I didn't encounter it post a release podcast every single time there is a new release so what I'm doing is taking uh bb8 120 or 1 117 18 19 and 20 as context to give to the language model and I'm not taking all the podcasts if you are interested in taking that data set I recommend a podcast search that um was done by Connor now that we we've defined our schema we're going to want to load in the data all right so first I'm going to start with the blogs so I'm using the simple directory reader and in the first video I go over the various data loaders that are on the Llama Hub um so in here I have all the blogs in a data folder so I'm simply just reading every markdown file and then for the podcast so like I said I'm just sticking to the release podcast and I'm using the YouTube transcript reader and then loading that in by passing in the URL to the podcast once I've defined the schema and uploaded the data I want to build out the index so the first one that I'll be covering is the blogs index um so like I mentioned earlier I am using the vector store index for the blog posts along with the podcasts um so in the first video I go over how to construct your vector store and then store the blogs so I won't really go into too much detail but um I've just created the blogs index and now separately I want to Define my podcast index okay and now the one unique thing I guess that you can say that I'm doing is I'm now going to use a list index for my meeting notes so I actually asked chat GPT to create a fictional meeting notes based off of like a few uh requirements so I'm saying that the client has a photo sharing app and um they're in need of multi-tenancy so here I'm just going to load in the meeting notes using the simple directory reader then I'm going to want to create nodes again which is just the chunk of text and then I'm going to want to specify that the list index will be using those nodes the next step is to create a summary of each index so the first one I have my blog posts um so you're saying that it contains all of the blogs that are on review i o and then the podcast that it covers the new releases and then also the meeting notes with my client named Connor and then I'll just want to set the index summaries to the summaries that I just defined now we've gone into the part of creating a composable graph so what this is is it allows you to build an index on top of your index so here I have my three indexes again so I'm using the vector store index for the blogs and podcasts and then a list index for the notes but all in all I'm going to take five nodes from the blogs five from podcasts and five from notes and I'll have 15 nodes that will then create a list index which I'm passing in here and then I'm just passing in the summaries for the indexes that I had already created next I want to construct my query engine and then now I'm on the fun part so my question is what is multi-tenancy and why is it an important feature for Connor's application and in the meantime as this run I'll just show you what the meeting notes look like um so here I have that Connor is creating a photo sharing app and he has a few users and he is nervous about having shared data or data leaked to different users okay so here we have the response so it's explaining what multi-tenancy is and then it's saying it's an important feature for Connor's application because it allows them to scale to millions of tenants while still providing each tenant with their own isolated environment and this is a perfectly explaining what multi-tenancy is and why it's in it and why it's important and then if I want to print out the sources I can see that it's taken um it's actually taken information from various uh documents and then also it's considered the meeting notes as well which is why it knows who Conor is and what his application uh covers thanks so much for watching the second episode of The Llama index and we be integration in this video I went over the different indexes in llama index and I shared a demo notebook if you would like to get your hands on the notebook I've shared it under the webiate recipes and it's linked in the description I hope you enjoyed stay tuned for the next video and take care bye ", "type": "Video", "name": "Episode 2: Indexes in LlamaIndex", "path": "", "link": "https://www.youtube.com/watch?v=6pLgOJrFL38", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}