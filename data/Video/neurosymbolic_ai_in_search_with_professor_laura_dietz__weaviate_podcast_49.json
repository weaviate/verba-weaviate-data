{"text": "Hey everyone, thank you so much for watching the 49th episode of the Weaviate Podcast!! This podcast features Professor Laura ... \nhey everyone I'm super excited to welcome Professor Laura Dietz from the University of New Hampshire to the wevia podcast Professor Dietz is one of the world's leading scientists in search technology and information retrieval and firstly thank you so much for joining the podcast thank you for having me awesome so I'm so excited to dive into this topic of uh to open things up with neurosymbolic uh search and kind of I've always been trying to wrestle my understanding of neurosymbolic how you combine neural Technologies like deep learning with symbolic systems like say maybe knowledge graphs and tree algorithms and all these things so uh can you maybe open us up with maybe kind of just how you define neurosembolic AI broadly and then maybe we could dive into the search sure I think I mean most people think that it's very difficult to combine these things because one sounds like hard facts and the other one is called like soft probabilistic thing where in reality a lot of like the symbolic stuff also has like a soft publicistic notion like I did my PhD in probabilistic models and you know you you kind of like still have sort of like you have access to both of those things um I think for me what's maybe more important is um words I don't like Words particularly in particular I always say I don't have a lot of passion for these little words um this is why I'm not an NLP Professor like uh the prepositions and the conjunctions and all these little things somebody needs to care about it and that's not me but what I care about yourself like big picture things and that's like what ultimately brought me to information retrieval which is sort of like a field I entered during my second postdoc um it's like big picture thing hey here I have something I want to know and the thing over here could or could not be relevant how can I bring these big picture things together rather than have like little sentence by sentence with Barbara tasks so that's like that's not like the thing that like I always liked and it took me a long time to realize that I was like doing something like information retrieval already when I thought I was a machine learning scientist so so um uh you asked me about symbols so like one I mean and symbols is kind of like it's a very generic term like it can mean whatever you think is a good symbol for what you're trying to do um like here more concrete example of a symbol with let's say maybe uh what what people call an entity link that's sort of like you have text and in the text you have a mention of a thing that we all agree is a thing in the real world let's say uh oysters okay we can agree that oysters are a thing okay so now there are different things to say about oysters okay but like if you have a text where uh that talks about oysters a lot and you have somebody wants to know about oysters but if you can spot that this text mentions oysters and you can identify that oysters are like relevant for what you want to know then this oyster is not just a word but it's sort of like a particular kind of thing um and in particular maybe oyster the thing is different from our oyster shell yeah so like it's more than just the word but if you identify that oyster is a thing in the text now that kind of like helps you sort of like cope with all the kind of like Witnesses in natural language or like synonyms for listening um needs for disambiguation different ways of phrasing the same things using completely different words you sort of like I call it sort of like a landmark in text that can like latch onto and it kind of gets me half of the way towards like what I want to do to like help users find what they're looking for so that's kind of like maybe like a very concrete thing of like why I'm interested in symbols now so I keep going yeah you know I'm a professor so you give you like a one hour 20 minute monologue if you don't stop me um so you ask about like neurosymbolic right so some of us talking about like symbols right like then um I think a lot of like current work in newer methods is kind of like about like words and dealing with sort of like vectors based embeddings kind of thing you know and like similarity in the vector space that's supposed to like capture some kind of meaning and we can just put the symbols in there as well you know if we can do like a word is sort of like a hard thing right if you think of a word as a symbol we know how to represent words in a neural network space so the symbols are just like additional words right so we can like do the same thing that we've done to words and we can again represent them a latent space so that's like no problem no problem on that side but it's a natural fit it's just like maybe the way that we think about words is a little bit more like fluid uh and the way that we think about symbols is a little bit more rigid um so I guess my question is I've always had a hard time understanding this kind of like entity parsing out I get like so maybe just take a step back like with the oyster example I I always have kind of thought that like kind of the vectors capture the semantics of the oysters so maybe like clams or mussels I like similar Foods kind of so it depends on the context or I don't know too much about oysters but maybe if you're like fishing them so so maybe could you help me understand like how the entity parsing uh like how how it plays with search kind of well I mean there's like um towards working with aunties they are kind of like two parts but one is you have text and the text is just words um to identify which of these words actually refer to like uh oysters and like particular oyster versus oyster shell um then I think once you know that it's like you can like take entities as additional words and you can like include them in you know your relevance model to identify what's is it on topic is it off topic um um they're kind of like some other advantages where you know often they're like Tethered to like a knowledge graph or some databases or some other external knowledge um and even even just like if you have like small spelling variations if you just ever look at words you have sort of like a question about this invigoration um maybe oyster isn't like that but let's say you have David Smith in the text and you have another text also talk about David Smith right we don't know are these the same David Smith is so like um somebody that we don't even like know about like this is all like we're entities this invigoration is like very very critical especially with like people names and uh place names especially since the Americans decided that like every European Town also needs to be placed in the US so now that's kind of like you know that's like it can be can be very hairy problems right um but even like other things like um time right so when I say time and I don't give any further context like you know or we probably talk about the thing on the clock but like time I like you know their Pink Floyd song called time it drove me nuts like was like very very mad at Pink Floyd for a while um so can we think of stuff like being like it's undisputably like when I say one word that's the thing but like if you look at text and if you look at it in detail it's not necessarily clear that the thing that mentions the right name is actually the right thing so so when you actually go through the mechanics of like entities invigoration saying is this time thing on the clock is it time the work of art now you can like add this to your document representation and the next time I want to know about like time the Pink Floyd song I can sort of like directly go to my search index and grab out these pieces of text we've already put in some work in well I know that this is the here in this context we we refer to the Pink Floyd song so that's sort of like where you can really like add additional knowledge um something that people like often think like I think or like maybe like 15 years ago people thought uh Hey named entity recognition which is not disinfiguration it's just like here's the text oh that looks like a place that looks like a person and they were trying to like make gain some leverage out of information retrieval and it didn't work and the reason why it didn't work is kind of like obvious in hindsight um but just while you know in search you're really focusing on the words uh the words already there the reason like like the way that you identify that these are people names is because they're particular words things like it you can look up like in gazetteer or something so you're not really adding anything to the knowledge there's very few very few general terms just like have people names in it and if there's often like an organization or maybe a place or something so just like the recognition part like or like mention detection is also called um it's like not that useful for search however once you have like these entity links they're sort of like you know you disambiguate dimension in the text and say is this person it's this thing well it's like it's time the song versus like time the general concept now that happens to be like really useful in information retrieval and and I think my my second side of the most cited work is actually about like showing that this works in information retrieval together with like Jeffrey Dalton and like James Allen from humans um and I think it was really like well we kind of like it was off like a tight race you know the the market was ripe for doing this kind of work where we had good entity linking technology we had some benchmarks that kind of like would also like to you would do better on if you would identify these entities um and that's what we did so like the one thing you just like toss it in and it makes everything better so I mean that's like uh that's that's always a great thing if you have a great model something it really works you just add a secret ingredient and everything goes up and that was like one of them right so and I think again that's also something we sense in hindsight because if you're interested in time in the Pink Floyd context it's not the most frequent mention of time in the context you can uh immediately discard all the mentions for time as the clock and like focus in on the text that kind of like really talks about the word time in the right context so if I have a query like um when was time published uh something like that and so I'm kind of I'm still trying to try to wrap my head around kind of the system architecture and how the system works so would you maybe first do a vector search with the embedding of that phrase uh uh when was time published I remember what I had started and then and then would you say like re like filter the outputs because you then run the entity parser over the candidate outputs to say okay these these mentioned time the uh Pink Floyd song yeah so I think like this is not the machine learning me speaking um I think usually the best model is one that kind of does all these things at the same time we call those like joint inference model um and like what neural networks do with end-to-end training and end-to-end inference it's like like the same idea right um I think if you would like write a system that goes into production uh number one talk to somebody else number two do you have like two routes in which you can like go you can either first look at all of your collection one in entity link on all of those then index some information of the entities along with words and these are now not I mean that's kind of like logical identifiers you know people use you know Wikipedia titles or Wiki data IDs or like whatever matches in like your entity um like entities in the world that you care about now you can like take like any typical retrieval model that of your choice and just so extend it with like entities okay that's sort of like the search part uh the really hard part like to actually identify what is relevant for what the user wants to know right like I mean if uh if a user wants to know hey what is like healthy versus unhealthy Seafood I haven't mentioned oyster in that like information need but like maybe talking about oysters whether it's good for you maybe there might be some health risk associated then um yeah it was like making that link saying this is like what the user said the user did not know that they wanted to know about oysters I mean that's okay those information needs exist but we usually consider themselves like the really hard part is are like those where the stuff that's like really relevant that really kind of like shows the right kind of information and like really better information than you would get otherwise um I just like based on stuff that is like not that obvious I love like the machine learning inference embedding techniques are like about how can I bring the words that I used in the query sort of like similar to the words that actually in the real relevant documents if we would know what that is of like a 2020 hindsight kind of thing and we train on that and again like this gesture here is something that I uh like exercise a lot in my class so it's like we have these things they're like they look like very separate and whatever we do with like Machinery techniques we try to bring the right things together and we push the wrong things apart right and I think this is like also where um like latent space embeddings that like neural networks give us it's like such a great fit because you can like reason Beyond just like lexicon matching but just like how the world prior to like neural networks kind of like really were um and really like try to have some semantic meaning of this is similar than that right and that's like something that you also like said earlier about well there's an information need there are all these different things like I want to know that oyster here is similar to other things that uh they may find at the beach or like that I find in the sea or I find in the water or something but like the real and I mean that's also like you know the like an often sided uh advantage of doing the symbolic thing especially when you have knowledge graphs at the backgrounds that you have like the taxonomy so you know an oyster is a this and that and that you have the whole taxonomy that you can leverage uh if you have Wikipedia things you have these categories that try to be like overlapping sets it's a little bit more messy than like a nice static tree um which can help in some cases um the big problem that we're usually fighting with is um it's only like helpful in like some of the cases just because the taxonomy isn't always the right thing that the right kind of group of things um let's say um sea creatures you know we have like the nice taxonomy of like oh uh oysters are part of like fall in with muscles and they are like this and that and they don't quiz me on the biology but like sometimes I just want to say uh things that like live in the water and they often isn't like a nice type for it or there isn't a nice category for it and that's like when step when stuff gets like hard and unfortunately I want to say that um yeah I sent a bunch of students down the wrong Rabbit Hole trying exactly that and they're like I don't know stuff isn't really working so well and then we looked very carefully I was like yeah Works in some cases but like often uh there isn't like an easy solution like just walking up the taxonomy tree that's like where we're doing like love like an infant like on the spot and so on like identifying what is the right set of entities yeah this I think there's so much to unpack I I remember uh Bob and light at weavier when he was telling kind of the founding story of weavier it started as a semantic uh web technology and um he tells a story that he was at a conference and they and people couldn't agree on what was a lake or what was a c and this kind of like trying to form ontologies people can't agree on what what the vocabulary for things but uh you you mentioned kind of the embedding optimization you know push things similar push other things apart and so I'm really trying to understand kind of the role of knowledge graphs with the current Vector search technology is maybe the strategy to link the data symbolically based on you know maybe shared entity mentions or however you link the knowledge graph and then from there you you do like Knowledge Graph embeddings could that be maybe the future of embeddings or at least I see sorry to be going on a little bit but I see kind of two two things of this where it could be either like you know you you you take a zero shot embedding model like the pre-trained open AI cohere nice like long list of pre-trained model providers and then you kind of uh you know form an ontology about your particular data and then you have some kind of like Knowledge Graph embedding orchestration thing that that is like maybe the new state of the art for how you get the best embeddings is that maybe how you're thinking about it or quite honestly it's uh an open research question I'd like I think one of the reasons why we are giving the tutorial series on like neurosymbolic representations for information retrieval is because we want to also get more people to think about this um typically the people that we talk to fall into two camps one says you don't need knowledge graphs we just have like neural methods and they just like figure everything out that's one way I mean and then and I'm not like you know I'm not saying sorry you're wrong right like I wouldn't say I think it's like it's a possible hypothesis like you don't like need any of the symbolic stuff anymore if you have the right neural network um I think on the other side you would have people would say um you know we have all that knowledge sitting around here for free why not utilize it why not like work on trying to make it work right then you have like the other Camp saying oh yeah well we tried a bunch of these things and it doesn't really help and I was like well what kind of things exactly did you try you know think about it like you know the the technology like advances like if you use um a call that's like a prescription strength neural network super optimized by like you know Decades of work that open AI put into something and then you um have a few really like Poor Man's entity features they're not gonna cut it right it's like David versus Goliath right no what you do need is like prescription strength entity linking and entity ranking methods to actually kind of like make a dent here right so this is like where we're currently in this parallel track phase where one says oh you know we tried it all and like doesn't really work it's like not worth our time they have other people like me who said no no if you ever want to kind of like go out of our local research option them if you want to escape that we do need to push further and like as long as we haven't as long as the last researcher hasn't given up hope we're gonna like plow in the direction and we kind of like pull resources and we like see whether maybe there's a way here to like make make some Headway um but in 2023 we don't exactly know right and I think um I think the other thing to us like be aware of that there are so many different fields that like work with knowledge graphs and they all work ultimately with different problems and different problem sets like if you have your less courage like talking about like knowledge crafts you think about it like in one particular way which is often like you know Knowledge Graph completion finding these links but like this is not really the essence what you need in information retrieval information retrieval you need a different kind of set of Technology both of those are working on knowledge graphs but the purpose in the I call it like the texture of the prediction problem is like very very different um to give you an example an information retrieval we always work in the setting that during training time we don't know search requests that we will see in the future this is where a lot about like information retrieval and like the machine learning methods that's being used is all about similarity learning and particular the lexical similarity learning because like uh today we're going to talk about oysters and tomorrow we're gonna be talking about like green sea turtles you might have never seen a word like a query that talks about anything as green or C or Turtle during training time you cannot focus just on the words instead you need to figure out like what are the things like like if I if I change my information need if I change my search query which other words will that bring closer to this one so you cannot do something like a like Alexa classifier like a classified that looks at word features and TF IDF features this is not how it works you first need to like have some means of like similarity I mean I'm always saying we briefly glance at the words in the query and the words and the document and then from very instantly go into like something that is a similarity and that Trend goes like back as long as TF IDF and Boolean search right it's like we quickly look at what's in there and instantly return it like in this similarity metric and that's like still the case like today with the neural network methods that we use information retrieval like I think dense passage retrieval or like by by encoder my mind I can't even think of it as the same thing but you briefly look at the query you embedded you briefly look at the document you embedded and now this proximity Is ultimately like metric learning as it's as it's core now there are different kinds of metric learning as uh there's like some big toolkit that like claims to do everything of metric learning where students tried it it didn't really work for IR cases um and when I look at the model I'm like yeah okay I understand why this model is a good metric learning for this one class of problems here we have another class of problems it's not very surprising if it's like you know you kind of like still I mean the devil is in the details and you like need to look at exactly what is your model leveraging what is your what is your unfair Advantage if you're a machine learning model to kind of like do bet better in your task now you change the task completely and you will find that different things work better and you find that maybe you kind of actually really need a different model here yeah I really want to um get it I want to come back to the entity linking and how that happens but I really want to understand entity ranking a bit more and how that uh Works um maybe if we could unpack two kind of Cutting Edge ideas in the representation learning space uh the first idea I'd like to talk to you about is Colbert so Colbert is like uh in addition to having the the vector that represents the whole passage you also would do the you keep the token representation you keep the vectors for each of the tokens and then you have this late interaction so I so so I'm thinking as I think about entity ranking I think I have a query or I have a query like what was Barack Obama's Legacy right and so I have Barack Obama as I have this uh maybe a single entity vector or I have these kind of two vectors from the tokens like like I I just like like what does entity ranking how does it look like uh as an algorithm sure um like in genuine that's like neural versus not neural dad likes of like three branches of of entity information people are utilizing one is like what you said you take the curry you're entitling the curry now you know oh here we have this person name we know that person it's in bikini data under qid something something uh that's like one way um another way is to sort of like retrieve stuff oh no actually like uh um retrieve stuff look which entities are in there and like try to identify what's in the knowledge graph and like use the knowledge like I mean okay um hold on I kind of like mixing everything one is like anti-linking the query the second one is take the query have your knowledge graph indexing Knowledge Graph knowledge it's like very textural you just like shove that in your search index you take the query you retrieve from that search index um one way of doing that one is take Wikipedia toss it in a search index retrieve a page every page you retrieve refers to an entity now you get like entities this way these entities might not just be the Obamas these entities might be uh White House or something um the Third Way which um spoiler alert is actually the best way in our experience is you take your search requests first you retrieve passages text passages form a corpus of your choice you can also do that with Wikipedia that actually works better than just trying to directly retrieve Pages interestingly you can also do it with the open web and so on so forth passages now you look which entities are linked in these passages okay and you can do some kind of analysis and this is like where the different methods like this deviate um so you look at these passages in the ranking you identify what like the frequent mentioned entities which are NT says so close to the query words and so on so forth you do a bunch of analysis and that's another way of like finding out which entities are relevant and these entities are often actually really surprisingly um much more robust or stable than anything else like why does it work so well okay like number one anti-linking the query you do the same thing that we did with uh name entity recognition originally right you're not really adding additional words sometimes you add some more names can sometimes help but most of the time the person name needs to be sufficiently already disambiguate in the words for you to actually be able to entity link it and there are a whole bunch of people that work just on entity Link in the query which just requires a few different twists right or at least differently trained models for it this way um so with anti-ling the query I don't think you add a ton of new information it's a smidge and it depends but like it's not where the real cake is a future from the knowledge graph so now it depends how good your knowledge graph is now the problem is um like if your knowledge graph is coming from Wikipedia and if you look at the first two paragraphs on the Wikipedia page before they start with the section and so on it's very very short brief description of this entity this will mentioned the most important facts that people typically want to know about this entity uh let's take South America do you know any South America facts uh maybe largest rainforest in the world in Brazil let's start with maybe it's um it's not a country but it's like a continent right and it has different countries uh yeah rainfall is probably another good one um so interestingly um I don't know it's been a while back but remember the the zika outbreak and like I think it was like 2015 it was like big in the news right interestingly and it happened where South America now uh guess what is not mentioned on the Wikipedia page of South America at least last time I checked Ezekiel breaks and why is that hmm maybe somebody like is like removing facts from like certain pages I don't know um maybe they're just like more interesting things to say about South America than the zika outbreak okay so if you however go to like the Wikipedia page that describes zika fever and the zika outbreak well they've mentioned like South America South America South America various kinds of like um South American countries right it's like oh no it's you know it's here and we have like this many people kind of like affected by here and there right so this is ultimately like why the third part of your first retrieve because yeah if you want to know about the zika fever right you can't start retrieving and you're getting a bunch of passes that talk about like the about zika the zika fever um about like different like medical details or biomedical functioning or Pathways and so on right and about like the outbreak and like how tragic it was and how it affected like so many different lives especially of pregnant people you know so um if you retrieve those first and those are pretty easy to retrieve now if you look which entities are in there you see like South America is definitely like dominating so in this example about like oh tell me about the zika fever or like where did the whether we have thicker fever outbreaks um you will not find but like you will not find South America by entity linking the query because it's not mentioned you will not find it by retrieving from the knowledge base because the knowledge base finds all kinds of other things uh but probably not South America if you go and like you retrieve from the from either Wikipedia or the open web look what you need to say in there there you have it South America right and and this is just like in and this is a story that we've seen like time and time again in um in like our research where with different kind of benchmarks and so on so forth like this is really where there's like bottom up you first retrieve some Snippets that like seem to be about the query Curry first then analyze whatever you get back to identify which entities are very relevant and this is um yeah various of my students kind of like fine again and again that that's like a good that's a good way of doing it um yeah that that's super interesting and that that's a really clear example of um of when you would do that kind of Knowledge Graph retrieval my question with this has always been uh I've I've never really understand understood how these query languages for knowledge graphs work but I think I think maybe with the like kind of the text to SQL is like kind of what I see as a related branch of research where uh the large language model can take a natural language question and then turn it into like an SQL query and so I imagine we'll start to see the same kind of thing but with you know maybe Cipher or these kind of Knowledge Graph rdf languages and so do you do you think that's that maybe the like the large language models will know how to take uh the query of where was the zika virus originated and then turn it into the the graph query and then you know take advantage of the Technologies better yeah that will be that would be great um so far we find that this like only works in like very constrained environments right and this is like where the the search domain that you're trying to support really matters a lot here like if it's uh if it's something where which is very very well represented by a knowledge graph yeah you do it I mean there's like all this question answering over linked data it's a thing and they can like do really well on questions that's of like fit well with the schema the big problem is what do you do when the schema doesn't match right so and um and I think this is like me being in a as a more General IR researcher working with like General IR benchmarks we find that very often it like doesn't match I remember um like a couple of years back we did some study in trying to see um I would think we were trying to use in um open IE relation extraction system now that system was was designed to like extract relations about like people and organizations and places but not so much about butterflies and flowers and like um water pollution things like that right so we try to make some use of that technology on a very general like IR Benchmark I think it was was probably something like clue web or track web or something um and like me my student we looked at the search queries and I think one was like fall activities for children we're like you can give up the schema will not be able to answer those kind of like questions right so we focus then on the few queries it was probably like 40 of them where we had actually any hope on it um but it was still like like an upper battle right like I think um like if you asked the um akbc crowd like automatic knowledge based construction even they you know they went from triples like subjects predicate objects like entity entity how they connected to uh hear a bunch of vectors by then they've been doing that one for a long time right no no kind of like the things like you can then turn these vectors into triples if that's like what you prefer and like they're actually application for that but you can also just like directly work with these vectors and they have like absorbed that knowledge sitting in the vectors you maybe don't need triples explicitly anymore um yeah I mean I think like nowadays what we have and I think one thing um that my colleague Hannah based she's a professor at University of Freiburg um and she's working a lot in the inter like like comic combining text noted text bases and like knowledge based more structural knowledge bases um one thing that she found out was like you know the GPT Etc models right like that and you think like you know you kind of ask it hey can you take that natural question and run it as a sparkle queries like Knowledge Graph she said like crunchy what she finds is it generates perfect vaco which you know it's like a very complicated query language like very few humans can actually can actually like write good Sparkle by hand like I give up on that it's like not my it's like not my forte but they can write perfect Sparkle it like once it's syntactly correct but then often you get an empty result set and then she did again and like new Sparkle Curry again empty this outside then you tell the model hey your results is empty how do I need to change it to to find something and we know that there are elements that exist and again it generates something and again the results it's empty and like I don't I don't want to cite this as like a oh this is so bad technology we shouldn't even give it a try it's quite the opposite I think I think it's like these are great times to be alive right it's like it's it's like uh it was like nearly Unthinkable maybe a year ago then uh you can have you can give a question and it will generate some sparkle that kind of like looks believable is actually correct syntactically correct but that's like a huge accomplishment that like you know blows everybody out of the water right um but it's like also there's like you know open questions right and and I mean it was like not be able to overcome the situation where the schema just completely does not match what you want and this is like where we currently in my research group we kind of like focus more on this like uh unstructured we have the text we know how Knowledge Graph extraction would work in theory so we can like include this information just to read the text for us and pull out the important pieces and then we get an entity ranking this way so it's sort of like um there's a lot about like finding out like how research and other areas work which most people don't like to do because it's painful um but like we're the the kind of like the unstructured approach that we focus on is mostly it's not because we didn't want to work with knowledge graphs but because like whenever we tried it didn't work on like Aya benchmarks very well and that's certainly also like maybe the fault at trying to do uh say general purpose Knowledge Graph where um and maybe it's also like at four make my preference um about like search queries my favorite search queries um is maybe also at fault here because I'm sorry I don't care about people I don't care about people careers I don't want to know anything about any celebrities like I there may be like two actors in the world that can actually recognize um and I just like it's just like not really proud of my interest like my interest is in like Popular Science environmental topics social topics and for those we don't really have love like great knowledge crafts with us like work there um so that's like one of the reasons why we find it's not working that doesn't mean it's not working statically it just means it's like it doesn't work for this like very open domain soft topics that are just like we know are not very well represented by knowledge craft so but kind of like because I like those queries and I think these careers like deserve to be answered well um and whenever I use a search engine I find myself just being highly frustrated in not finding the stuff that I want to know especially when I want to learn about something new like there's sort of like a teachable moment that's like really wasted so this is like why we work on these like open vague complex information needs that also like happen to be not well covered by knowledge graphs but if you find yourself working on some like well-covered areas like um people in biographies or like um about companies and like maybe like financial information and so on or in the biomedical domain where you know ncbi has a very very expensive like knowledge base very little very spots on the text but very high on the structure much more than like Ricky data um um then that's like like the way to go so it's that's something it depends on the domain what works and what doesn't yeah it's so interesting um all these knowledge graphs that I think like wikidata has been curated by humans with the relations and stuff and there's a lot I want to parse out but first I want to get your opinion on another Knowledge Graph that's really captured my attention which is uh it's from a group at Harvard biomedical informatics called uh Prime kg so Prime kg is like 130 000 nodes which are like drugs proteins diseases and then they have roughly five million edges between each others like drug drug interaction drug protein interaction um yeah but well yeah maybe quickly uh what do you think about that kind of Knowledge Graph and the applications of it um I don't know we like comment um you said like a hundred thousand entities that doesn't like me like a whole lot quite honestly right I think um if you look at ncbi there's like it's like such a big deal so it's really like a engineering challenge like work with it right like um so again like um yeah but I think you know if you really like work in uh pharmacology they really like need to know about like the interactions I mean it's a very again a very like narrow domain but maybe this is really like what you want to know and I think that's also something for um bigger isn't always better especially when it comes to knowledge graphs like um like what I said my initial example was like time the Pink Floyd song versus time the thing on the clock um if you if you know that you're not interested in works of art and then it's not a question anymore right like you the disambiguation problem just like goes away because there's now only like one meaning of time um so I think like by if you if you can sort of like identify that oh yes a nice crap but he's just like the the subject section it's actually even like relevant for what my users are needing and if you want to if you want works a lot you would go to a different kind of like software right so this is like the situation that you find yourself in here where you have knowledgecraft very very specific targeting one particular task that's important motion also kind of like in some ways like simplifies things and I'm always like a fan of like you don't need to make your life hard unnecessarily so um maybe pivoting topics a little bit but I'm I've always I think one of the biggest Trends in search with these new search engines like perplexity and you.com and of course like vva we build this under the hood is like this kind of like filtered Vector search where you might pick a particular source of data to search through so say you want to search through Wikipedia Reddit Twitter or you know PubMed particularly and so to me that's one kind of structure there's it's not necessarily uh linked in a graph it's just kind of like you add uh you know symbolic attributes of of the source to the unstructured data what do you think about that kind of AD symbolic data to unstructured data to then kind of filter the search with oh yeah I mean I think like adding metadata uh I think it should go without saying like I think a lot of like works on um I think initial works on trustworthiness before we landed in that like very heated political thing right like people said here A bunch of like news sources that we generally trust hear a bunch of like you know scientific schools that we generally trust um you usually put a lot of trust on Wikipedia so if somebody like asked us for anything we prefer those sources and like only if you can't find anything here then we might get into the weeds um I think maybe in today's climate maybe you want to kind of like uh first identify what's your user which side are they leaning towards and then like show them the sources that they might usually uh prefer to see to like avoid a bunch of heart attacks right that's like another example of kind of like being um focused and selecting like by The Source um I know that some people were like trying to like predict when which source is like the most appropriate hmm um I think from what I've seen it's not my core area but like from what I've seen like the best thing is to um essentially like use your user model or like you use Case Model like are we currently asking about health or are we currently asking about like oysters then um like you step onto like to select the resource and then maybe like do some like meta search and like merging a few sources that are kind of like appropriate right um that would be kind of like um if I would have to do that in practice that's uh how we'll be doing it um I think as a research problem I would probably stick with that I'm not thanking my research time on it and not my students time either yeah awesome That's so exciting and yes I think that was a really really comprehensive tour of the of neurosymbolic searches understanding entity ranking well oh sorry there was one more thing I wanted to pick your brain about which is entity linking and I think because I think with the large language models we can now prompt it to take like two passages and then output like how they're related is that is that a breakthrough in energy linking what's kind of been the story of this yeah I haven't done any empirical work with like the latest models right like I think you can ask like the other regressive language models to like annotate your the text that they generate with like entity links and they claim they do that I don't know about the accuracy um I think um for a long time the anti-linking community really like focused on like linking every single entity in text we're from an IR resource standpoint I'm like you should ideally link those Concepts that really matter in the context um here's an example uh there's a Wikipedia page about the word the th whatever the link every single mention of the yeah like you might have some text that actually talks about the as an important concept and now you do want to link it right so uh I call this like a query specific or context specific entity linking and I think that's kind of like important right um like another thing that I think is really important is like to go on a sub entity level like uh oyster like we have actually some research area um a multiple things to say about oysters you know you can oyster it's an animal some people forget that it's an animal it's an animal not vegetarian food some people um say well there are sort of like some hint that it kind of like actually can like filter the water and can help with some of like cleanup of polluted water sources um but then it's also like a thing that you can eat right there is a different concept contests so can we identify that in a text where we know all oysters mentioned here and we have an entity link to the right oyster or maybe even like David Smith you know it's like something we have that anti-linking first can we identify what's the context which aspect of an entity is actually mentioned in that context uh it turns out you can in terms of if you do that you actually kind of like have another kind of like you know another another hammer in your hand that is saying you have the big hammer that's like entity and anti-league you have the small Hammer that like it's like no here's this is like oyster the food that's being mentioned here and here we have oyster as you know a creature that has a habitat and a home and the family to return to um uh so then because that now tells you that at least two pieces of text although they mention the same entity talk actually about different things about this entity um and that's something where we've kind of like we've shown like some initial promise but then there's also like more work that needs to be done in this area like how can we identify how can we leverage this like fine-grained entity linking right but of course you know the the knowledge graph embedding can help us with all of this right um and and I think you know like the another thing you ask about like how good are they at entity linking we know that like earlier models like bird are actually not very good at it I'm always saying like um like I remember in 2019 people thought oh Bert can do everything the train predominantly on Wikipedia therefore it should be able to do all these entities and I think over the past like two three years we found out like no this is actually not true it's actually like birth is not very good at representing entities like because it's also like and if you think about how it's trained with a closed task um you simply random word the chance that you get a you know common word like a preposition or conjunction um it's just like very high um it's much higher than sampling what I call an information bearing word like you know you can think like rare words that like tfidf would like um also there's like fine-tuned with certain kind of like other tasks that are often very like lexico or like T5 which is like trained on you know glue and super glue which are all like NLP tasks very lexical you need to really understand the words to like do well on those tasks where um something I've been trying to do with a couple of collaborators is to maybe even train a new even like an old-fashioned birth model from an academic budget just like undo a few changes and see whether you actually end up with a model that actually works much better and also like an IR in general certainly a model that's better at representing like entities um and like part of this is like on in the tokenizer your brother has a different token as into preserving but then there's still like a bunch of like other I don't want to call them mistakes I'm just saying stuff that choices that were made when trading the model that really means that they are very good for NLP tasks and not so good for these like big IR tasks where you need character to be close to you know health concerns yeah so uh the The Epiphany before I think this will make a really great transition to the next uh one of your papers I really want to talk about but kind of the Epiphany I had when I was listening to your explanation was I've been thinking a lot about these cross encoders that take the query and each candidate document as input and they can kind of Reason across entity uh similarities and intend a little bit but so so kind of the Epiphany I'm having is it's about can we do some kind of offline computes because the cross encoder this is really slow to do this with you know and that's the problem with that but if we can do some kind of offline computation of entity linking I love this knowledge graph embedding this idea where maybe we can sync the links across the graph I think there is a lot of research to be done I don't like have a really concrete sense of how that would work but and then I think also kind of like adding entity mentions and kind of populating symbolic filters because you can symbolically filter really fast and all that so okay awesome so the next the paper I'm so excited to dive into is titled perspectives on large language models for relevance judgment and um so quickly I'm going to I'm going to I'm gonna uh in the show notes or in the podcast quickly I'm going to edit and show this picture of the collaboration perspective so the picture okay so I'm I'm so excited to dive into this I'm so interested in this idea of using large language models to uh you know generate queries for documents or label the relevance of queries and documents um can you please tell me about like how you think about all this okay I think first of all first of all it was a rejected paper that will just like tossed out an archive and tweeted about it and it's probably like now my most sighted and like I'm like okay opinion piece like how about my other work okay well um yeah I think most people and I think there was like some confusion initially where people are like looked at like we did some experiments on um can you use like GPT like completely replace human judgments and if you just do an ex empirical experiment yeah like Coral is actually really well you know um not always especially there are a lot of like uh entries where and that's maybe actually very interesting pocket where um the user said a human judge said it's not relevant but like a large language would say it is relevant and I think those documents are either extremely bad or they're going to be extremely interesting because they might pick up on things that like the human assessor might not be able to like identify just because they didn't know um like here's my favorite example is I asked a bunch of these models like how is um how is diabetes connected connected in the relevant way to child trafficking and that's some that's actually a question that we asked like some assessors in like um a track track that we ran like a while back and most humans would say uh probably not relevant so here's what the large language models came up with they say oh no it is somewhat relevant um because I'm actually I'm guessing it I'll let you I'll let you take a guess uh maybe it would be a you'd have to take extra care you see it's a negative I see okay so here is what the larger English models like said and I don't know whether it's true or not right but like I think it's like interesting to consider um that is you know children who suffer from diabetes rely on their medication if you're trafficking children you need them to do your bidding very easy way to do that you will hold the medication that like they depend on I mean this took a Doctrine very quickly you know but it's like an example of like oh my God I didn't see this coming yeah again Goosebumps with this you kind of like with something like that like and I'm kind of and I think it requires like more study and research to kind of like identify well what is this pocket where a large language model maybe like see a connection but the human judge without like any further knowledge and with limited brain capacity um it's kind of like not seeing it I think maybe I was like this is like not the most important fact to mention about like childhood trafficking although I think maybe it is you know people should be warned um but like it's certainly like something that's kind of like if I want to give more information about let's say child trafficking it's something that like deserves to be mentioned um and I mean a lot of the stuff that I'm really excited about is like not just to give like a short answer but to give like a longer answer right and this is like where I think those facts would go in um to come back to the original question about the using GPT for relevance judgment um I think the the real title should have been um why why you shouldn't use GPT for violent judgments although it looks like you could because there's like a lot of problems with it like even even though it looks like oh yeah it like lines up really well with like humans um there are a lot of problems with that um like often we like to use judgments as being sort of like an independent arbiter and as as unbiased as we can be um so that when we develop a new method it's not already prone to prefer one method with the other like here's an example like we all so excited about like GPT different GPT models are from different brands and so on um if you choose to use one to do relevant judgments and then that's the one that like somebody is like using in their method very likely their method might just look better than another method that's similar but use a different large language models so you get like a real kind of bias that very likely one language one just like it's have a propensity to like some model some work better than others um just based on well this is like the same thing you know it's um so that's kind of like one problem with that um there are other problems that could be um okay but why do you bother using like these last language models to create relevant judgments if they are so good at identifying what's relevant why don't you just like use those as a as a as a ranker they lose you am I back I'm back sorry about that hey I was just like so exciting like just on the high point I get cut off oh no yeah never forget my train of thought um okay why should you not use it well um yeah I mean like there's one thing about like you know having uh propensities to like one model then there's like another one method versus the other so you probably wouldn't be quite as like independent now the problem of like human judges are also like not that independent there's like all kinds of like other biases like when it comes to like humans um another problem is well rather than using large language modes to create judgments and then use a not so great search model to like to train it or I'd like to assess it why not just use GPT as a ranking model if it like has learned everything okay that's like one thought um and maybe if you're while we're still staying with like the AI driven models um although I hope we assume coming we're moving away from that but as long as you're staying with that it's not so easy to use as a ranker um maybe you can use like to generate a fifth query and then run that against a search engine um other people say well you still might want to do it because maybe that's too slow so you can like train a faster model to do that um so there's kind of like various kind of problems with that um in the paper we go in like the spectrum of like we call it like a human machine collaboration like it starts with like you just use a human uh which like nobody in their right mind would use they usually use a human with like some very rudimentary support like highlighting certain keyboards and so on and like you know Finding like stuff about the same topic we try to group it so that the user can just say oh yeah that's relevant oh yeah that's the same it's also relevant so transitive closure kind of problems right um like on the far end you have um fire the human just use a large language model and it just talked about all kind of problems in that but I think what's really interesting is like the Spectrum in between and that was what the paper really was intended to be about even though most people just zeroed in like on this like far and that it was just meant to be like a theoretical like let's see how well that could even work right like the spectrum between is like one where you give the human like more and more more support um or you are used to human like to Define what is relevant and you let the heavy lift even be done by some more automated method but like it's the human who defines this is relevant this is not relevant okay um and then you can go further into like the machine side where yet maybe have like the machines like generate some rationales like maybe you can ask hey um explain to me why this is relevant explain to me why this is not relevant two explanations now the human can read both of them can say oh yeah I find this more convincing right so being the human as an arbiter um you talked about biases a lot like of course that like introduces a bias right like I'll show you like what I said earlier with the diabetes and child trafficking once you see that information you cannot unsee it and sometimes there's like interesting information which is not necessarily the most relevant information so this is like you really need like a special training for for your human assessors if you want to do that kind of approach I would say um yeah what else um I think something that could be very interesting is like use um maybe less for evaluation but actually as a method is to like use some of the auto generate like Auto regressive light language models to actually generate like some pieces of text or like generate some hypothesis like what I just said for the human like this is where this is not relevant maybe you're actually as part of like a search technology you get a query you get a bunch of things maybe entities and you can ask for each of those hey is this relevant this is not relevant give tell me why you take those rationales you further kind of like throw them into like an in-memory index kind of like index it on the Fly you can solve like uh use some model to generate some hypothesis of like what could be interesting facts while at the same time then using search technology to either verify oh is this really relevant or uh if that's like a weird claim whether they come from they come from like some site that I like fundamentally disagree with uh or the user found that we disagree with I should say then um maybe you want to kind of like dismiss this um and I think that could be a much more interesting constructive way to like really work with like other regressive language models um um and with respect to evaluation I think um I hope that we will see like more work in the like middle Spectrum like humans with like more automatic assistance some more automated ones with like more human assistance like somewhere like in between I think the Spectrum often has been like traditionally very like underexplored um like one thing that we tried um if you were surprised it worked it was like really an out there and outlandish idea was to instead of like having queries a collection and then asking humans like is this relevant versus not which I'm not sure if you've ever tried that it's a very annoying task to answer I can do it for three minutes then run out of patients I'm like very inconsistent with myself sometimes I'm like oh yeah this one's good that sounds no it's not really not wearing oh like that sounds familiar I think maybe it is relevant I don't know no I have to go back and do all the judgments myself again so it's like um quadratic grew up in assessments right um like instead what we said hey especially as a teacher hey just write an exam like here's a query what are the what are the important facts that I need to mention for in in stuff that's like relevant on that topic it's a something about daven's Voyage like you know in the in the book that he wrote and some of the big discoveries that he that he done like about like genetics and so on right it's um like you can say here this is like tell me about this and as a human I would say well you're for that kind of particular information you need I won't have like this fact this fact this fact this fact if I can write a multi-choice question for each of those facts uh and like then assume that multiple choice question answering is a solved problem which I think hopefully most people would agree then um you can just write exam questions as a human to Define what's relevant I can train a question answering system and then we can like ask different system hey retrieve relevant documents and we can check all of those documents for how many of these facts can a question answering system answer the more of these facts the questions in system gets right the more I believe that you are a good search system so it's just like a very different way of thinking about it um the paper that we wrote about I think it got rejected twice because people are like this is just insane I was like yeah but look it works like I don't believe your results okay like scientific methods yeah but like um but like imagine this you can sort of like now um use a human to Define what's relevant you can use some other automatic system to like do the heavy lifting while still like the human is still like in the boat and especially if you are if you're worried about like biasing the Human by showing them information you can just say no the human first needs to come up with the task like do your own research like come up with like tasks are really important um and now you kind of like have less of a bias if that's like what you're worried about by showing them information if you're worried about that the human might be missing things and especially interesting facts that like no human will probably think of in the first place you can then say okay now read through all the different search results and then maybe think three more maybe add a few more questions to it and because we have in the automatic question answering system or some other kind of like machine learning method through the heavy lifting you can actually run it again and again and again and again and it will not like change its mind on like this as well what this is like not relevant um I mean of course your new question answering system that answered the questions not from World Knowledge you're not allowed to memorize things you have to read it out of the text so this is like where you know lots of like the um reading comprehension work kind of like now could really be like very useful here like as an evaluation method yo um well that has so much information about it I'm firstly surprised to hear that it has been rejected because I think this is such an impactful paper especially from the perspective of vector databases and search relevancy stuff generally like this whole concept we've seen works like in pairs and promptegator where you just generate queries for the documents so then you know like users of leviate can just upload their documents and then have queries and now they have something to kind of ablate the models with so if you want to say you know does the openai model work better than the cohere model you as you mentioned like annotating the relevance judgments yourself is like maddening so happening having the models to do it and then you've identified this kind of spectrum of how you would collaborate with the uh large language models for annotating these I think that's probably a pretty promising startup category is creating the music these kind of things I haven't left giving my ideas away for free like I'm not I'm not in the market of startups I think too but like um yeah and I think this is maybe it's kind of like very you know we're all kind of like very technical like technology oriented and maybe this is like sort of like why everybody like gravitated to the right side of the extreme um I'm more like in the in the middle and I think like the the paper is I mean like it's not just my paper like it's like um 12 really like well-known people like in the field like thought and we disagree with one another in our discussions and like if you look at the end of it they're like sort of like three opinions initially we thought there would be either you you yes you think we should use more llms like in for evaluation or you should not think and if you look at it as actually more people came out on the side like no let's not do this right now and like some of those might be maybe uh not right now but some people even thought maybe never um because of various kinds of like issues that like come along with that so it's really like a paper like like and wants to caution people and not just like saying this is what it is um and I think this is also like where you know identifying like should we use or should we should we not use it I think also for the research Community would be like very important to kind of like have a discussion and get some clarity on like what do we as a community think should be done but it should be not done um because you know we try to write papers and like the thing I'm really worried about is where as a as a paper author you try to do everything right and now if you end up using automatic judgments or like some other half automated judgments you get rejected because like somebody says no we should never use that and now if you don't do that then people will reject your work because they say well you haven't done that everybody should be doing this right and I think this is sort of like I call it like a reviewer standoff and I think that's kind of like not healthy it's just like of like maybe where you know the people I'm sometimes talk about the toxicity and research Community that's why it's like one thing but I also think like by uh talking about it and having a discussion and maybe having a consensus maybe also like having a consensus forming discussion let's put it this way um it's really like important to do this like right now you know the same thing that you know currently have all the kind of teachers being like uh like uh like ripping their hair out over or how do we keep our students from like illegally using uh language models for their homework when we actually want to like test what they're doing right this is like a big debate and like don't feel like nowhere we should be like coming out and I think this is like another debate that we need to be having uh we are currently like not having um and I think it's uh it's something where we need to kind of like develop like some way way as a community like what can we agree on or maybe we can at least agree on that like work that does either of those is still okay like best practices and I think part of this is like probably in in five years from now we will be like uh smarter in both of those areas the educational part and the and the evaluation part um but like right now it's a little bit um wild west but it's like uh dancing around trying to figure out where they where they stand now in 2023 I said it's a great time to be alive yeah well you've given me such a new perspective of thinking about this I would I started out so bullish on this idea that large language models should judge relevancy because I just see this problem where like from maybe more of the industry Stan uh perspective where people come to aviate with like a knowledge base you know your slack or whatever it is you just have documents really you don't really have queries so this notion of just generating queries to me I was just so certain that that was going to be productive hold on can I can I interrupt right here so he's like generating queries right and you know in the yaya Community various people have like tried to do that one as well like here's a corpus let's generate queries um I think that the idea of like what I said with that the human write an exam and let the exam like automatically then great things but the human is still in control of whatsoever what's not relevant um I mean they're sort of like similar work done in summarization because like in summarization you also have like a similar problem where you want to know is this a good summary this is a bad summary right like and people actually have also like worked on trying to automatically derive questions from like a gold summary that's like you know their their relevant track is just a gold summary okay um the problem that I see with that and also like they see some of the metrics that kind of like combine these things is it's from a text it's very easy to generate questions or queries which are not that interesting all right I mean especially if you use like a methods of you take something you know this text is like relevant or it's the right summary then um you kind of use triples and from purple like uh um you can say like Barack Obama married to Michelle Obama you can now like turn that one around into like a question or query like uh who's married to Barack Obama and the answer is Michelle Obama okay but if this text is about like something very different and it's relevant not because these two guys are like married to one another but about something very critical that's like in there now the question will like not really get at the core of what's relevant like this is where um in my work we were like flipping around they said no you don't start with a text and you generate a query or a question from it but you start with something somebody wants to know and now you do something that is I call it like a Humane a Humane use of human assessors like these exam questions and then from there you can automate the process like I call this Humane because in some ways it's a lot more natural for a human to like say what's relevant in this case then in the other case like if um I don't know if I may but like next time you had a customer that comes to you with like their slack chats and say we want to retrieve over this one you can maybe say um maybe like what are like uh what are critical priorities of like why you need this search for right but like things like give me a few examples of what you want to know now give me in how can we come up with like a test of what is like what are the things that you actually want to know uh versus like some stuff that gives you keyword matches right like and I think you can like very it's very easy to convince users that what they say they want it's not what they want by just throwing them a little prototype you say oh you want the keyword matching here keyword matches do you think that's relevant that's why no no no either say the first time you find yes okay so we need to like work on this to make all the stuff that you said no to go away and all the stuff so you said yes to like come up okay and now we can kind of like look at well why is this thing relevant and from there you can now do something else you can preserve what is relevant and why this is relevant like maybe more like a rationale um homeless rationale you can now take what we what the what your customers said they wanted to know what was value and address is not relevant and why is this relevant you can now give that one to like a large language model and from that one you can let the large language model to say well if this is relevant then this this and this is also relevant because it's relevant in the same sense so it's a lot faster than having a human say yes no yes no I mean it's also like every mind I mean if you have to read the same kind of facts over and over and over again it's just like one of the my current problem was like search engine is like I'm asking for something get like 10 documents that are pretty much like identical in the information content so why do you show me at least like other documents to show me different documents right um and that's like also like where by relevant judgments also mind I mean because it's just like the repetition imagine you have to watch the same advertising spot again and again and again and again maybe you haven't made that experience before okay so it's like you just like become to like hate that information you're like please get me out of that hello please show me any other advertisement from the 70s so at least I see something else um and I think this is like where trying to make the relevant assessment task less mind-numbing by using like artificial intelligence in this like very very particular way while still having the human being the driver's seat and saying this is this is not relevant um I think that's really like where the future is and I think the future isn't that far away like uh it's not like a necessary I mean there could be also like more I think I wish more academics would be working on that but I think like even from industry it's not that you need somebody to like reinvent like and invent a new wheel for you right I mean this is just like it's just like a simple idea it's like a concept um that you can run with and as I said I give my ideas away for free uh amazing I mean yeah I I I I love the new ones that like just like I love the perspective just to take another nugget out of the paper just like where you have the relevance not relevant and you have two and then you have like a higher level thing that judges it like I originally think was thinking of things like the Lang chain where you have like the chains of prompts and so it kind of generates something and then reflects on what it generated with the but yeah just everything you're saying there's so much Nuance to doing the relevance labeling maybe quickly if I could pick like I was I was thinking about like well yeah like when you generate a query maybe clustering these queries and embedding like does this document also answer this query I think that's actually something maybe like just like a criticism I have and like most IR benchmarks is that like we have one query here one Curry here one crew there we'd like have them like sample we usually try to sample from like you know the whole space like anything anybody would want to know and very rarely do we see like two queries about like similar related topics right um but and I wish we had like more of those because I think if you are if you're real at search engine company and you're like have like query logs you probably see that uh there's like things that people like want to know about and it's gonna be like pretty much like the same the same the same and sometimes they're like different like nuances whereas in good like different different directions um like we and we wrote a paper about like a crew specific subtopics where with the idea of like actually training yourself to like identify different Topics in search results not like with clustering team IDF clustering or like topic models which where we actually have some results that it does really like not work it doesn't correlate with what's really relevant to us it's not but like we actually trained to pick out really these like very detailed fine nuanced topics and like one of my favorite examples is to like just to convince people that it's not just general topics it's not just like here's a set of document cluster them but it's about uses of documents that we retrieve but this is the information need that the user really want to know about they actually can change the clustering is like one about you know you have like two queries about like covid-19 one is sort of like about something where you want to know like uh what was sort of like big problems for like people personal problems let's say maybe like the loneliness or maybe like being uh like uncertain about the future you know like two big things um but another one would be about like covid-19 sort of like measures and like um like treatments right so you can have imagine you would have like pretty similar documents that are relevant about both queries but the subtopics that make them relevant they're actually very different and that that's kind of like why I call it fine-grained and it's like topics because you know it's like a a um you need to identify what what the logical subtopics once you have the subtopics I mean that also like falls together with what we just talked about with relevant judgments right like probably once you have these subtopics if you put one document that says this is relevant then you actually want to like look at the other documents right away and say oh these are actually also all relevant or maybe not if they're not relevant that's a sign that maybe the subtopic detection kind of like wasn't quite correct and you need to give you like more training data into that right but again it's sort of like another way of like integrating human ancestors of like what's relevant or like what's topical and like which topics are relevant versus Which documents are relevant um and with like some elements of like machine learning which like so far it was like um it was kind of like as it would be like a taboo like you're not allowed to use machine learning in in relevant judgments and I think it's like as you said like for for companies it's like it's just like not really um financially feasible but also for academics I don't think it's necessarily the right idea because it's it gets like very very expensive to do judgments for and then you have like a few queries and you really don't have enough judgments to like train one of the heavy-duty neural networks anymore right like you need a lot more training data and there needs to be a compromise that we need to explore and I think that's kind of something that will help like both industry and academics to like move forward but again we need to also overcome the taboo and like the academic world hmm yeah just amazing uh so yeah that was such an incredible tour of these Concepts I feel so much so much education from uh both the neurosymbolic understanding the knowledge graphs as well as this concept of the large language model relevance judgments and just wow there's so much depth to that and this conversation just really opened up my understanding of it and the academic thing wow it's all just so interesting so uh Professor Laura Dietz thank you so much for joining the podcast so knowledgeable you have such a like an entertaining and energetic way of telling these stories and it's really awesome and so uh maybe before we uh wrap it up is there anything you'd like to maybe um tell people to look into I think yeah maybe one thing I think like at the moment something that like I don't want to quite say annoy me but like give me a little of a pause is like how we talk about technology and in particular talking about it in like a life or death situation like you find like people will say like oh the AI overlords are coming and then we have the other side says oh these are just stochastic parrots um like that's something we're afraid of and I think it's very difficult like I usually find myself in the middle of all of this I'm like you know um I don't think it's just stochastic parrots but I also like don't think that the air overloads already are here I mean like it's not I mean I understand that a lot of people were like blindsided by the by the development but like it's face it you know I mean like open air has been working on GPT models for like the last decade and I think if they really really deserve something then it's like kudos for just sticking with it like every academic will probably have given up a long time ago and you know they were like ridiculed for like a bunch of like models like and then I remember the last time with gpd3 it was like in the New York Times and everybody's like freaked out and then people looked at it more more carefully it's like no you know this is actually like not that great good yet I mean it's something to it but it's also like a a kind of like an element of uh saying you know this is like amazing and not just like trying to pick it apart as in yeah this is like oh look look here's like the all these different Chronicles it gets like wrong I'm like well how well is your method drawing on this right like this summarization method like oh you're a co-generation method like how good is it and are you even like close to that one and like I have to say for me probably not right but it's also like you know there's also like clearly like things that we like still need to learn um but then there's like so much opportunity that this technology like gives us without kind of like going into this um fear-mongering oh this is like all super terrible and like oh I have to like leave the company now it's like not further not further this kind of like evil that they're about to like breed right there um um and I think that's kind of like one problem I think on the flip side where people are not afraid enough about this sort of like user tracking I'd like I think um the number of times I had like conversations with my friends on Facebook on not filling in these like social engineering posts and then next time they just do it again that's what I think where the real danger is and I think it's not gonna change unless we all kind of like do it a little bit differently yeah I mean I guess uh uh on the on the social engineering thing I guess kind of the concept of it just being very convincing so I guess like there was a lot about the recommendations and how that would put people in kind of like a political uh what do you call it like uh when you're TR like a rabbit hole where yeah where you're just seeing what you want to see and then there's just Echoes and you never hear another yeah yeah sorry but yeah and I I think um I'm curious what you think about like the kind of in the in the what has inspired so much of the AI uh overlords are coming hype uh what do you think about kind of like the auto gbtv the ability of it to kind of decompose tasks and then use memory and I think it's sort of uh a pretty in it's a pretty crazy jump it seems to me at least that like now it can come up with an action plan and like execute this action plan and it's like connected to the Internet with with the chat gbt Marketplace or like the Lang chain tooling now I can write emails I can write so on the internet it might as well be a person it seems sure but I mean it's like again like if you look at if you look at GPT three from like you know like two years ago when was it I mean it had like you know this um this thing of like being able to like generate text so I was like I forgot like her name she kind of like co-wrote uh was it a book or something uh about her grief with gpt3 my gpd3 would just like put out like rationales more or less and she would like then edit it and so on and I think this is um you kind of and it's we're still doing the same thing it's just like well the quality got better but this is also like you know we figure things out and I mean sure you know like if you look at uh I'm not sure whether you remember the first iPhone you know I was like oh boy copy and paste right so I mean and look at the iPhones we have today or like other smartphones I want to name any Brands but like um it's like of course you know you kind of like slowly figure things out if you look at Chain of Thought prompting for example right like I mean it's it's not that you have it's not a new mathematical model it's just like a different way of using it and we know that from uh gpt2 which is you know like very old right we know that that actually was working really well in this like few shot setting right which counts like now I mean that's like what Chain of Thought prompting like falls into and like we knew that well maybe gpd2 like out of the box with like direct answer it wasn't the best but really like at the time people said you know what actually this is actually not bad technology if you use it as a future prompting and I think the instruction based method is just sort of like a logical follow-up of it like oh let's maybe prompt it with some shots and not just like clear the session and throw it away but like maybe like preserve this right like I think it's sort of like a over time it's like uh it's not that um there was like this one big thing that just that suddenly appeared overnight no it's like it's like steady amount of work over a decade by by a bunch of people and then there were like some people had some new ideas like oh look I found this thing or like me saying oh here was the thing we didn't think will work oh my God it actually worked actually pretty well and like what does this open up and the next person like learns from it and say oh now we add this one here and this one here um I think this is like where uh um whenever we give our touring Awards we always like pretend that there's like this one or few people who kind of like did it all by themselves but like in price it's like never the case right um and I think this is also like why this development was um like kind of like observable right like I think maybe if people like stopped looking after they played around played around with like gpd3 once or twice and then said like yeah okay like this is like neat but like it's not yet ready uh you just like don't keep an eye on the development and then you get surprised but um I wouldn't say that this is like something where overnight our machines became intelligent I think over the last decade Bit by Bit by Bit of machines all machines became more intelligent and more helpful to us well I have one more on I have to give you a take on this with the for the sake of ref perspective for those listening the last podcast we did or I don't know what the order but the podcast with Bob on generative feedback loops the entire transcript is 13 000 tokens I imagine this podcast of Professor Dietz is probably about 20 000 tokens am I talking too fast so the whole transcript of everything we've said in this hour and a half is probably 20 000-ish tokens so these new models like gbt4 with 32 000 token inputs or the Mosaic ml MPT that do 65 000 token inputs I mean what what can we expect with that I think you know and that's like a very old machine learning Mantra like the more training data the better um short of uh well the training day should be correlating with the task that you wanted to be good for right like um garbage in garbage out of course also holds here um I think part of this I mean I don't know I I don't I don't talk to I mean I don't know the details about any of the commercial available models but like my hunch is that they probably now have consumed the whole internet and and some more um and like this is where we are right now and there are still problems so I think next thing we need to do is to be a little bit smarter in spending our training data wisely um then I hear things like uh several trillion parameters and like the machine learning is like uh do you have the training data to serve up on these degrees of freedom right like and um and like the third part of me thinks is like you know like all the like all the regressive language models I think you know it blows my mind how well that works I did if you had asked me like a decade ago whether this is like the right way of doing everything I would probably say no probably not okay so kudos to them um but I also think that it's probably the right architecture like if you look at the architecture underneath it and how it learns it's the right architecture for anything that's all like generative but not everything in the world is generative I think at the moment people pretend that it is um and like maybe you can turn a lot of things into generative but like there are other problems that are not necessary about like all the regressing words word by word um like as I said initially with retrieval metric learning right like bring the things that close together that are that are relevant bring them far apart if they're like not relevant bring things close together when they're about the same subtopics bring them far apart further apart when they are like about different sub topics right you can write build up a space um this is not necessarily how other regressive language models work right the question now that I have and that's honestly a research question is can we do with fewer parameters by having maybe a let's say medium smart language model not one that like memorizes all the facts but maybe one that maybe can like Leverage search engines more effectively and if you see this with you know retrieves augmented generation and so on right um but like can we maybe also do that with knowledge graphs and so on and we see that like with the the tool Integrations that we now have like in open ai's product tool right can we maybe do away with some of the latent parameters that are currently being used in kind of like just like teaching like using language as a means of like expressing things expressing search requests interpreting what the user wanted to know interpreting what we see and bringing that one together rather than just like sort of like a like a student in class like I know the answer I know the answer but like can we maybe um trained like a machine the way that maybe we humans would like uh or saying humans would do that I mean the humans that memorize phone books I'm not one of them so I need I need to look up the things again and again and again again because it will not stick in my brain so is there something is that maybe like a different it's a very different approach um and like given that it took uh open AI like a decade plus like get to that particular to really fine tune all the architecture here I don't know maybe we'll take another five six years like to rock on completely alternative approaches and then we will have to see um which one actually ends up getting us further to maximum usefulness let's call it this way right so it's sort of like they're like other architectures that kind of like might maybe be worth while exploring but then uh again we end up with the researcher standoff where people say unless you compare to this thing which is like overly tuned and like forced and Polished we don't want to hear about you we don't want to hear about your ideas I was like well this is like this way we're just gonna be like stuck in our little research Optimum and all computer science professors will form this point forward be condemned to only ever do prompt engineering which I think would be probably better be done in the humanities department but like okay but like I think this is like where the news is still out on like whether that is the only architecture that you ever need or whether they're like other architectures that might be better better as in like requiring like less three less fewer degrees of freedom uh requiring like less training data using the training day like more effectively and doing something that are kind of like they're just like the architecture is better matched like other tasks because I think not everything is like other regressive generation but it could also be wrong you don't know uh we should meet again in like a decade and then I can say when I was wrong yeah that sounds great uh yeah amazing so Professor Deeds thank you so much for your time this is such an awesome podcast and thank you everyone for listening thank you Connor ", "type": "Video", "name": "neurosymbolic_ai_in_search_with_professor_laura_dietz__weaviate_podcast_49", "path": "", "link": "https://www.youtube.com/watch?v=2s_GGMZ_Zgs", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}