{"text": "Hey everyone! Thank you so much for watching the Weaviate Podcast! This is pretty novel episode featuring both Weaviate ... \nhey everyone thank you so much forwatching the weba podcast I'm superexcited to do two things we've neverdone on the weba podcast before firstlywe're welcoming both we VA co-foundersBob Van light and Eddie and delocker andbecause we just need to bring everyonein on this because our guest is someonewho has dominated the vector databasemarket and so I'm so excited to welcomeJohn dagdoll and John can you tell usabout hyperdb and how you just figuredit all out so quickly sure yeah sohyperdb it's a hyper fast local Vectordatabase we're uh we call ourselves a BSdatabase as in a better search databaseum yeah I'm happy to tell you more ifyou've got some questions for me it'sjust um you've you started you were sofast uh John so tell us a little bitabout like if you say for example we areis that like your whole team or is likea royal Wii what are we if you say wewhat are we talking about because yeahyeah we're a wild worldwide community ofdevelopers it started with me but assoon as I put the project online we gotPR's and contributions from all overum so yeah now we're a diverse team wegot a great uh Discord we call it thehyper debit card so yeahum interesting and yeah go aheadhave you been able to raise money so faryetwe have a lot of interest from VCSthey've reached out especially after theinitial announcementum we've actually raised 600 milliondollars so yeahwow congratulations and why because it'slike a trend uh while raising money isaffected to be to have your logo on theNASDAQ uh thingy why have you decided tostay silent and not do that well we'realso stealth even though we have a lotof PRokaythat's very very smart yeah that is veryinterestingum I was really inspired I saw a lot ofcompanies you know putting their puttingtheir logos out and raising money fromVCS and you know that I looked into thisapproximate nearest neighbor databasething and I thought to myself well Icould approximately make a nearestneighbor database and so that was wherethe idea for hyper DB was bornum we're the fastest Vector database inmany ways we're the fastest to athousand GitHub starsum we're the fastest pip installand we had the fastest externalcontributor uh joinwow and but I think you're you'reactually you're even still downplaying alittle bit becauseum I'm very curious to hearum the I mean what you've been creatingin and and people can sit on GitHubright inum yeah actually this it all comestogether in this nice file the Galaxymath rain shit.pi can you maybe sharewhat's what what brought you to thisyeah to this Insight in creating thisyeah I just I I like to name files sothat if you just read them you know whatthey are and we really believe thatthat's the key to hyper DB's successum we do things like Hardwareaccelerated math kernel blastsum so very fast cosine similarity andthen also we have some some reallyinteresting things so alignment is a isthis problem that is is now reallyreally trendy in AI that you've probablyheard of so actually we're also analigned Vector database uh and we try tobe metaphysically aligned with the thenature of reality and so if you look atsimilarity metric you can see it bringsin some of the the metaphysicalRandomness that is actually inherent tolifeI I can really hear the the BS thebetter search and all of this so greatyeah it is unbelievable it's it's it'sfantastic congratulations it's just I Iremember we sold and we were like whoathis is just sometimes you just have toyou know you see something happening andyou just said okay so much and thatespecially means a lot coming from youBob yeahthank you for saying I think it would beinteresting to learn a little bit moreabout you John and what you're doing andwhat you're actually working on so it'slike the becauseum a lot is happening in the space andum it's actually it's just it was just Imean I think what you've done is you didit exactly at the right time and it waslike the right thing to do and it isalways good to keep everybody on this ontheir toes in this way so we we just youknow we really appreciated that but wewould love to learn more aboutthe actual child and the actual thingthat you're working on so maybe youcould share a little bit Yeah so foranyone listening that hasn't come caughtonto the joke yet uh hyperdubu was kindof just a joke that I put out on Twitterum there is a real GitHub repo it doesactually work for everything it says itdoesum but I I noticed so I've been workingin in natural language processinglanguage Technologies for five six yearsnowum I'm just finishing my PhD at UCBerkeley in the materials sciencedepartment but I do scientific naturallanguage processing so things likeextracting data out of research papersand training language models to help uswork on like figure out what we shouldwork on next and I've been using hybridsearch Vector database kind of stuff fora few years now and then I just explodedall over Twitterum people were raising money all overthe place and it became kind ofespecially poignant because of the thelanguage models uh using them as forretrieval augmented generation and Ithink it got a little out of hand insome some waysum especially just kind of the hypetweets all the time so I thought youknow why don't I make my ownum so on a Saturday night I kind of wasjust a little I don't know I don't knowWham I built this this repo and I'm Iused uh like I generated a logo that Ithought looked kind of hyper and then Iput it on Twitter and then it went viralI didn't expect it to go like this bigum yeah it got seen by half a millionpeopleum it hit the top spot on Hacker News uhI had dozens like I'm not kidding dozensof of VCS reaching out to me very bigname VCS uh so it was it was kind offunny and they would say things like heywe checked out your project we thinkit's really cool we'd love to meet youand it was just kind of I got us I got afeeling or I got a A View into what theworld must be like for some of thesecompanies that have a lot of hype goingon right nowyeah yeah no that's any and that'sinteresting and I think what's sointeresting about what you're saying istheum so what's interesting today I I I I Iput something on on Twitter that waslike I saw this nice and I forgot whichuh repo uh it was on but we can add thatto the the show notes Here you saw thisnice tree right so where these how thesemodels evolved and at the the bottom ofthis tree you see like glove fastx andthose kind of things and I remember thatthat for me at least that seat wasplanted like hey wait a second you canactually do somethingum we can do something with theseembeddings when it comes to to to searchand and those kind of things I rememberthat the might actually be funny toshare so the first the very very veryvery very very first prototype that I uhthat I that I built for me was actuallyalso in Python and basically what I didwas that I had a few of these paragraphsand I took these individual words fromthe paragraphs and then I justcalculated centroids based on the wordsthat I got from that funnel that waslike that you could download from the uhfrom the glove uh um repoum that'sum that was actually built very fast andand it was interesting right but thenthe the Kudos are actually building adatabase an architecture in a databaseand what it means to build a database Ithink that that 100 goes to a good goesto hn but that insight and like hey waita second these the defectors can be usedto for for better indexing and betterbetter better searching umum um that's an opportunity we believethat that's an opportunity for a newdatabase in the market but I'm curiousto hear from you John it's like what doyou thinkhappened in the in in the um I mean it'seasy to say for example you know inNovember we got like little GPT thingand that accelerated that is true butI'm just curious what you think was thatpeople all of a sudden what they sawthat they didn't see before thatyeah because we had gpd3 which has a lotof the capabilities of chat GPT I meanalmost all of them like chat GPT is kindof just like aa tuned version of of that modelum I think it really was kind of the UIchanges that that being able to havethat back and forth conversationumlike when you when you work with gpt3it's just trying to continue whateveryou wrote and so it's not a natural kindof interaction you have to kind ofabstract your thinking and understandwhat the model is doing in order to workwith it but I think when when openaireleased chat gbtuh I think I recall like Sam Altmansaying in some interview or somethingthat they were surprised no one else haddone it and so that's why they did itand then released it I don't think theyexpected it to go as big as it didum yeah but that's a much more naturalway of like interacting with with AI andthen I think a lot of people there arethese moments where like a a switchflips in their mind which is like theycan imagine themselves using somethingfor the first time I think a lot ofpeoplelike uber for example I don't know ifyou remember your first Uber ride butfor me it was very like weird I'm likeI'm gonna get into a stranger's car thatand I like see them on this app likeokay and then you do it and then yourealize like it's not weird and it'snatural and it's good and then it justis a new way of life and I think thatthat happened with with NLP and andlanguage models and stuff with chat gbtthat back and forth conversation openedpeople's eyes to what's possible andthen they could ask it to do somethingrather than try to like create abeginning of a prompt that thencompletes into something that theywanted it to doum and then they realized with the truepower of these models areum and then in terms of the the vectordatabase uh part of thisum I totally agree with you that it'slike word devec was that moment for mewhen I saw the word to BEC paper andthen I started playing around with itbeing able to do math with words wasjust like mind-blowingum for for analogies and things likethatand so yeah I think that the the vectordatabase piece is trying it's like thememory of a language model so how do youhow do you get it to to use specificinformationum in its generations and soyeah and I think Lang chain is also partof this so so Lang chain isfor people that haven't played aroundwith it it's kind of a library of abunch of scripts for chaining togethercalls to llms and different prompts andyou can change the prompt based on whathappened in the previous stepum and it's got a lot of attention it'sone of these super hot projects rightnowum but combining that with the the flipswitch in people's minds uh really madeVector databases really important on themap I think uh at least in the like thepublic mindset right now yeah I thinkwhat might be interesting also aquestion for you hn of course we uh I Iknow the I kind of know the answer butit wouldn't be nice for the people thatthat thatum listen to the podcast sowhat was for you the first time that youhad this Insight from a databaseperspective from a fact databaseperspective you were like oh wait asecond I'm just not chaining algorithmsthere's a bit more to actually buildinga production system what was the firstwhat was the first time that you're likeoh wait a secondyeah I think that was uh it's hard tosay in time but I I know the species uhVC back companies always thinking likeuh financing faces and I know that thiswas around our our seed a phase becausewe we had we had just started yeahexperimenting with isn't it exactly asBob said before like these these kind ofsmall paragraphs and seeing does thisactually work and at that time deviatewas because we also came from thatdirection of Knowledge Graph and waskind of intended as like almost like astateless layer on top of on top ofknowledge graphs and I mean buildingsomething stateless is relatively easyand that was kind of like what I didbefore is there a whole running 12Factor app sort of stateless loads inthe cloud making sure that they scalewhich is switches in hindsight supereasy compared to making a database scaleum but I know that that we were we werealready sort of kind of experimentingwith this okay do we really want tobecome our own database and I rememberthat we actually hid that information insome of the the the first talks that wehad with we see companies reaching outbecause we're just like okay this is toocrazy this is like we're we're not therewe need to First prove that thisactually works before we we tell othersthat we're building a database and yeahit did work and I mean the rest ishistoryum and to me this is this isto this day something like when I readthese tweets like hey if you have ahundred embeddings maybe you don't needa database maybe you can just run it inmemory like for me there's always likeit's not just about scale there's somuch more like if you want to serve thisin production if you want that to havethat be highly available if you wantbackup solution if you want filters ifyou want like all these kind of featuresthat if you want a migration path forpeople who come from uh from and I thinkthis is also interesting in the contextof Lang chain and stuff with whichbrings new users in but you also haveusers who already use a search solutionif you want to give them migration pathto sort of more modern search they'renot going to drop all these hundreds offeatures that they already have and sortof database I think is the wrapper termfor for everything that's going on hereand umyeah so yeah making sure that that worksat scale and at production quality isum unfortunately a bit more work thanjust um yeah putting yeah there's likemultiple types of scale too there's likethe scale of your data so what Irecommend is if if you have like a likeless than a hundred thousand vectorsthen you just want to like mess aroundwith stuff on your computerusing like an external database thatyou're actually like sending data out ofyour house into their servers and thenback in just to do like little thingslike that probably is not the right youknow tool for that job but if you needto have something that's gotI mean availability all over the worldand needs to have latency under like 10milliseconds and uh like productionapplications that's a whole differentset of needs rightum and then also justso I I uh during my PhD we created acouple scientific search engines um thatwe serve to the world actuallyum one was on covid literature and onewas on Material Science literature andthe pain of getting that notification attwo in the morning that something wentdown and that you have to fix it it'sjust yeah it's it's something that stillI wake up in with nightmares and the thethe solutions that are hosted or offerkind of more robustnessum they really help with that kind ofthing so if you're trying to build likea product that you're going to give toother peopleuh definitely that's something toconsider um and then alsoI think a lot of peoplewe're not really at least in the waythat we're having public discussionslike not here but you know in General onTwitter and stuffum people are not making the distinctionbetween databases and search engines andI think that that's actually kind ofsomething that we should be talkingabout as a community you know what whatwhat are the needs of a databaseuh you like and what are the needs of asearch engine uh maybe we want to getinto that here but that's that'sactually a very good point and and I Iwanna I wanna addum uh two things to that right so wealso of course deal with librariesso we have the yeah like like and we ofcourse have to hypnotize on the podcasttalk about face and those kind of thingswith with the libraries the databasesthe search enginesum and of course uh embedded also startsto play a role right so I think thatduckdblet the way in that and it's veryinteresting because it's it's a new wayof of also working at a umum with data and then and in factorsplay role in that so I kind of see thesekind of these fourum you know the these these four thingsI'm actually curious um from from bothof you to to um to hear the uh what youthink about that right so how you howyou how you look at these four thingsand how you because I notice I spend alot of time of my time talking to peopleexplaining these four Concepts and andhow they're different I'm just curioushow how you guys look at thathey you you want to start John oh sureyeah um so II think that the user is is oneimportant factor so like for librariesthe user is kind of a developer rightsomebody's trying to achieve a goal andthey they don't want to bring everythingfrom maybe like they just need a littlelittle part of the puzzle maybe theythey want to add a semantic feature totheir like a semantic similarity featureto some analysis that they're runningum in that case you might not want toset up an entire database just to dolike calculating similarities betweenmaybe a thousand things or somethinglike thatum and then I think also there's maybe afifth thing I would add which would bethe dataum because what you're actually startingwith is so important uh even I mean thatthat's like the the biggest lesson Ilearned in all of the research I've doneum or in this space at least inscientific language processing what datayou put into this stuff has profoundeffects on on how it performs so forexample if so one of our papers in theearly days we trained were devec on acorpus of research papers and then weused the word tobaccum just it predicts the Sim the the thelikelihood that two words are going toappear together in a corpus uh and youcan actually ask it the probability ofwords that never occur in the originaltraining set and then you can use thatto make predictions about what shouldco-occur and like we actually discovereda bunch of new materials that wayum but if you train the same thing onjust if you just mix in a bunch ofunrelated like non-non-material sciencetext or even Material Science text us ona different type of materials uh domainthe performance just disappears and sothat's that's a really key pieceespecially when you're using semanticsimilarity and stuff like thatumand then you know I'm not I wouldn'tcall myself an expert on on any of thisstuff to be honest uh I use it a lot butI'm not developing these algorithms forlike I'm not developing Vectorsimilarities approximate years neighboralgorithms or anything like that butthat's actually interesting it'sinteresting to hear it from theperspective of a a user who'sknowledgeable in the NLP space right sothat that's what makes it in my opinionextremely interestingyeah if I'm hopping in quickly Iremember that um I think it was 2019that paper you were part of that had theunsupervised latent space of MaterialsScience and I love that like that wasone of the first papers that I saw theseclusters of some domain like scientificliterature mining we also had Kyle lowon the weba podcast what maybe like yeahbecause what's the current state ofscientific literature mine the covetsystems one of the biggest like what arethe frontiers of it yeah I think um whatthe court what Kyle and and the umthat team did on the core data set wasreally interesting like that I thinkso the the pandemic accelerated a lot oftrends that were sort of alreadyhappening and I think text mining ofscientific literature was actually oneof thoseum it was the first time that we had alarge-scale specificdata set of full full research papersmade available to the research Communitywith no restrictions on how you coulduse themum that was a really interesting momentand that was a very it's a very still avery interesting data set becauseusually the licensing problems with thecopyright of research paperscan can really slow things down uh forexample we have a bunch of full text inin for the work that we do but we can'tshare any of it with other researcherswe can't even share the database ofabstracts that we use to train ourmodels so so nobody can they can use themodels that we've trained but we can'tactually just give them the originaldata that it came fromum and so that that's that's one Trendthat I think as now everybody kind of isjust putting stuff on archive first oreven just never putting it in a in apeer-reviewed journal that's copyrighted[Music]um that's definitely I think a trendthat's gonna it's gonna be importantum I think you also see a lot of likesearches becoming very important becausethe quantity of papers coming out andquantity of data not just in in sciencebut in the World At Large like peopleare publishing things in blog posts thatwould have been research papers a fewyears ago and so just having like a goodsense of what's out there and how tofind it is going to be really importantum and I One Trend that has not caughton yet that I think is actually going tobe really big in the near future atleast in scienceum it hasn't caught on yet is like theseAI assistant kind of chat gbt stylethings that allow you tothere's like a lot of common datamanipulations that we do like maybe gothrough 100 papers and then pull out aspecific number that we want to make aplot of so that we can try to analyze atrend that's going to be the kind ofthing that before you had to have I meanyou had to be somebody like me that likespent years figuring out how to how tomanipulate data like teach yourself howto code and then learn these theselanguage model technology things andthen put it together into one thing justto make a plot out of that or you cangive it to what they do is they hire anundergrad intern and then give them thismind-numbing task of pulling thesenumbers out of papers or something butprobably in a year or two it's going tobe something that you asklike a chat gbt like research assistantif I could just I think this is a greattransition into a recent research paperof yours on structured informationextraction I I love this topic of justlike you mentioned you know I rememberback when I was wrestling with the chord19 days at two and I've always mess withthat data set also and partial throughthe schemanow the language models can kind of likehelp with that can you tell me aboutwhat you're learning about thatyeah um so this is something that we'vealways been this was the goal of ourprojects all along was to extractresearch so so I got into machinelearning because I I started as acomputational material scientist so whatwe do is we we simulate materials onsupercomputers at the atomic level andthen instead of doing experiments youcan just kind of calculate what theproperties of the material are going tobe before it's ever made in a laband we were generating a lot of datathis is uh we and we make it availableto the World on something called thematerials projectmaterialsproject.org if you want tocheck it outum and those data that data set size isin the order of like 100 000 maybe 200000 materials now and then we have a lotof diverse data for those materials butuh it was a lot so I was like okay maybewe can do some machine learning on thisso I started learning ml a bit andtrying to train property predictionmodels and things like thatand then I realized very quickly that wedon't have enough data to do the thingsthat like we really dream of doing hereand if you look and just where is thedata in the world on on scientificknowledge it exists mostly in the textand tables and figures of researchpapersand so that's like how I got intothat um and so our original goal is whydon't we just extract the data out andbuild data sets in the train machinelearning models on those and then whatwe found is actually the the structuredinformation extraction problem wasn'tsolved yetum and it still was it was it still ispretty hard but the new language modelsare really powerful and if you fine-tunethem you can actually have them extractstructure Json documents that you couldthen just insert straight into adatabase uh like something like VBAum and then get kind of this reallypowerful mix of structured data you havethe the original text from whateveryou're extracting from you can buildyour own features on top of that andthen that could be the the layer thatenables these like scientific researchassistant models that I was talkingaboutyou know I think this is a great on theum Vector databases what do they add agreat angle to it because once you havethese filters you can do filtered Vectorsearch it's not just like cosinesimilarities because you have thesefilters um so this is a great ediancould you maybe quickly explain like howdoes filtered Vector search worksure uh filtered basically you'veexplained it right now[Laughter]without going too much into how it worksunder the hood the idea is that uh thevector and the object that the vectorbelongs to it they're not two separateentities they're not and and I thinkthis is this also comes back a bit intolike what is the separation between thedatabase and a search engine like in V8we make sure that those lift togetherthey scale together and they're they'realways together and why because we wantyou to be able to use those structuredproperties in combination with your youroriginal uh or with your your vectorsearch basically so you can kind ofcombine the best of Two Worlds thetraditional angle that the filtering soagain sort of if we're looking at themigration path if someone comes from theSQL world and says but I want to setwhere price equals lower than twentydollars then they don't want to sort oflose that just because they're soe-commerce is a nice application and saythey're they're looking for or abeautiful dress to wear in the summerwithin a certain price range they're notgoing to drop that that price range justbecause it's now now the NLP part of itis is betterum but they still want to want to keepthat and similarly that also allows forfor hybrid search so the the bm25 andum and Vector embedding based searchbecause depending on on what the modelis trained of sometimes or not justbecause based on the the sort of indomain out of domain but also just ingeneral they're not necessarily meant tomatch keywords but sometimes you do needto match keywords in your kind ofapplication and having that in it andnot just being like a vector being thisabstract thing that maybe gives you anID back but having the actual object andit allows you to to to filter on it todo keyword matching on it to toaggregate on it so so faceted search forexample it's also for e-commerce issuper important where you you returnresults and then you want to have thesekind of ranges like it's it's lowestprice highest price average price allthese these kind of things and and theseI call them database features wasprobably not the right term but it helpsto to sort of paint the picture ofum yeah what is it Beyond just pureVector searchyeah and I think that like aggregationsand things like that are reallyimportant or groupsum so you know you might want to saylet's let's stick with the scienceexample sohigh energy physics papers if you wantto say you know what is the averagenumber of authors on a high energyphysics paperthat's kind of a difficult task to to domanually and it's even difficult if youhave even if you have just kind of atraditional table of all those papers uhbecause you need to get a sense of likewhat is it a higher what is a highenergy physics paper within that youmaybe previously you would have traineda supervised machine learning model tomake like a binary label for just thatlabel then you'd have to go and labelthat data is this a high energy physicspaper no yes no yes no maybe you woulduse like a bag of words features or likeTF IDF features or something to try totrain a model on that maybe you couldhave just done like some some manualkeywords to look for but with semanticsearch you could just kind of grab acouple high energy physics paperabstracts and say just give me a bunchof documents that are similar to thisand then give me the average of thenumbers of authors or somethingum and so that that's like a reallypowerful workflow I think um yeah andthat these things enable yeah and tobuild on top of what you're saying whichis just saying John so it's like uh it'snot out yet but when this podcast willbe out it will be out so because aeconomy maybe in a bit you can saysomething about as well because onething that we're looking at is what wecall these generative feedback loops andthat is something that's veryinteresting as well so exactly based onthe example that you just gave John isyou get some information from thedatabase and put it in the in the in theuh generative llm but then you feedbackloop that back in and get a vectorrepresentation uh uh for it and I thinkthat those kind of things also veryexciting so I mean Connor you you knowmore about this and I but so maybe youcan you can say something about this butfor the for people who don't know yetwhat it is but what that exactly doesuh well I think um well I think you dida great job of explaining the wholeconcept of it and I think it kind of itit's kind of like how we open thepodcast talking aboutnot like the height necessarily butthings like Auto gbt laying chain thiskind of like you know I think it startedacademically with the Chain of Thoughtreasoning showing that it could havelike a task planso there's that that's one angle that Ilike a lot about this save thegenerations back in the database becauseyour database is like uh it's more oflike a living entity maybe like the thedata ingestion the continual things itcan do with itself sort of and save itsoutputs soI mean I think like and I would love Iwould love to get your perspective onthis with the scientific literaturemining example because uh I had to giveJerry Lou from llama index a shout outbecause I've been learning so much ofthese little things you can do but Ilove this like compare contrastdocuments prompt so you know you uploadyour new paper about some material andthen it can like sample passages to putinto the input to form up thiscomparison maybe like automaticautomated literature reviews that arekind of like sourced this way where youyou know each comparison is twoparagraphs save that back in thedatabase with the cross reference inWikia speak has you know has comparisonso like you know that kind of automatedanalysis of your materials papers yeahand I think that that approach is reallyinteresting because it leverages what soI think think uh for people that haveworked with language models for a whileum you kind of get an intuitive feelingfor their strengths and weaknesses anduh those are different than I think whatpeople are attributing to them todayum so let me give an exampleum if you ask a language model to tojust tell you some facts about stufflike really well-known facts that appearmillions of times in the training setlike the Eiffel Tower is in Paris orsomething those are going to be in themodel's output but if it's onlyencountered something like a handful oftimes or once or twice it's not going tospit you it's not going to give thatfact back to you and it doesn't makefact-based reasoning decisions that thatnot at least not in a structured strongway yetum but it is really good at manipulatinguh content into formats that make sensewithin the context and so like whatyou're saying if you give it a coupleabstracts and then say tell me what thewhere these abstracts agree and disagreethose models will be very good at thatkind of thing that's just their likereally strong suitum and so I think that that you can getaround the the hallucination problemsand some of these these weeks weaknessweak areas of llms right now byleveraging kind of what what thecommunity's been buildingum and like when chat gbt came out thatkind of chat ubt is sort of a gpt3 alittle fine-tuned for for how it shouldoutput answers but combined with aessentially like a vector database rightwhere it's like looking up past messagesthat it sent and you sentum to to give you better context when itneeds it or to get better context whenit needs it like in fact when I saw chatGPT and I got first access to it I Idm'd my friend Joe bergum uh who is uhhe's he's the the head of Vespa AI uhwhich is like Yahoo's Vector databaseI'm sure you guys are familiar with Joebut of course yeah but I'm like hi Joeyeahthanks for watching by the way yeahum but I I DM them I said hey I think ifwe just connect an llm up to to a VespaDB like I think that just creates such aGPD kind of experienceum and yeah it it just this explosion ofthoughts happen in my mind when Istarted seeing like all thepossibilities here with the fact thatpeople wanted to use them right and Ithink that's another thing like the usermaybe there's a Sixth Element to thatthing which is the user you know whatare they trying to accomplishI think people's imaginations have beenexpanded recently and what they theythink they can doexactly and that's also something sothat's what he what he like how thiswhole conversation started right thatquestion I'd like what that I wascurious what you thought that happenedand I think exactly what you just saidthat's the thing right we see that withVivid as well the people like oh wait asecond so now I can basically have myown data whatever that means or whateverthat is right you can inject that andthen get these results out Ium funnily enough I always use theEiffel Tower and is in Paris as anexampleum because one of the things that thatyou know also been experimenting with islike if you if you just basically overyeah for for lack of better terminologyif you overwrite the knowledge that themodel has with prompt injection so andthe example that I often use is if youhave something like uh the Eiffel Towerwas in Paris but it's moved by truck toBarcelona and then basically if you nowhave the question where's the EiffelTower and from the vector database youcan get out the um uh that that documentthat says something headed the Avatarhas moved and you can use it as a promptinjection and you can basically uh uh inyour in your prompt say okay you mustbase your answer on the followinginformation we're giving you and that isI think that is in that is very excitingbecause then basically you're trying touse the model more for its languageunderstandingrather than the knowledge that it has soI I have another question because a lotis dominated for obvious logical reasonsa lot of is dominated in discussion byum by language models and we kind of canalso see with like multi-model modelsand image models those kind of thingsI'm curious because you also beenworking in in other fields John what doyou thinkum what what what different types ofmodels or what kind of different typesof embeddings will we see in youropinion and if there are notuh language models that are not imagemodels will we see other things for Idon't know yeah anything that can cometo mind yeah I think that there's umsoI think at some point we're gonna haveit's beyond like an image modelumI think that this is what some of thethe AI like the quieter AI startups aredoing like the big ones um which isyou're going to be able to have likestructuredembeddings or latent representations oflike a user's intent using something solike what was the sequence of of thingsthat they just did on their computerthat will like inform what we what theywant to do next and like I think it'snot hard to imagine a near future whereit's just embedded in the operatingsystem of the computer you're using andI mean it just like you notice that youwant to do something and it'll just doit for you or like suggest hey do you itlooks like you areyou know you have a PDF open do you wantme to just summarize it for you realquickum instead of you having to like write aprompt that says summarize this documentor something like thatI think there's also a lot ofopportunities inlike multimodal but understanding likehow information is spatially laid outnot just like an image embedding butlike let's imagine we we all see lots ofPowerPoints probably PowerPoint slidesare laid out in a there's like semanticmeaning and where stuff is and what sizeit is and what color it is and whatimages go along with itum Beyond just like a single embeddingright there may be like contextualunderstanding there like what was theprevious slide what was the train ofthought that this has been going onthrough here so there's like right nowwe're just scratching the surface withhow we how we represent informationthere's so many deep deep levels that wecould get intoum so that's actually where I'minterested in going in in my near futureis is especially this kind ofthese like deeper ways of thinking abouthow do we represent information how dowe leverage that to do useful stuffvery interesting will that how do youthink that embeddings is for the for thecoming for the coming years that that'sthe way to go or do you do you first seesomething like something new somethingdifferent I think we're going to see alot of I think you guys haveexperimented with this a bit which islike the query expansion stuff usingusing these models where you you canbasically like if you tell an LM heythere's like more ways you can interactwith a search experience uh to getinformation you're interested in likeyou can tell them about the differentfields that are in your DB and like whatpossibilities there are in there uhespecially if you can then like finetune it just a little bit to like workbetter with your database I think reallyinteresting stuff is going to come outof thatum I think multi-vector stuff is reallyinteresting to me so you have likemultiple documents you might have likean embedding for each sentence within aparagraph so like you might do one oneembedding search to find the rightparagraph and then another one to findthe right sentence and then use that asevidence for somethingum how do you how do weuh so like right now embeddings when youjust do a query embedding lookup they'rejust doing a cosine similarity or somesort of nearest neighbor similaritysearch for things that like seem toalign together but that's not like theoptimal I meanlike a query looks different than adocument right like big questions whereis the Eiffel Tower maybe the documentsays the Eiffel Tower isn't where thatmight be similar but likeanother documents might say like whereis the Eiffel Tower's Builders grave orsomething and then that might like alsobe similar because it has where isEiffel Tower and stuff in itum especially if your your embeddingsaren't like from a really deep modelumand so I thinkthat's one problem is that that queryanswer alignment thing that might belike solved soon uh where where you haveanother model that is justre-positioning the query vectors intothe document space in a better wayum you may also want to do things likecontextual embedding of like there mightbe like Fast embed where you takeembeddings as they are and then youre-morph those based on the context thatyou're looking for so like you mighthave a bunch of documents but you reallyonly care aboutlike one aspect of that that thatspace that you're searching in so if youhave a bunch of um like fashiondescriptions of like fashion itemsuh if someone is really just looking forlike material based stuff like whatmaterial are they made out of like theydon't care about like the cut of thethingum you might do like a if that isn'tlike an explicit column in your databaseyou might not be able to do a lookup onthat with like semantic search butprobably there's a way with ML that youcould realign those two things just toredistribute them based on more materialinformation rather than like the overallinformation of the thingum yeah yeah things like those I thinkare really interesting areas that thisis all going to go intoyeah it's super interesting I I have thesame thing with the interfaces right sowe so for example what you now see withthese models and then for exampletranslate something to SQL or for thatmatter uh we've had career those kind ofthingsthat I would not be surprised that we'regoing to see Innovation where that justgoes away that would just literallydirectly go from natural language to aform of doing a lookup in the databaseyeah I don't know how it will work yetbut I I those kind of things I thinkwill we will see um as well and I'm Ihave one more question that I'm verycurious to get your thoughts on on Johnso one of the things that I this kind ofrelated to how we started the thepodcast right and how everything is likenow you know that that everything isgrowing very fast and rapidly and andand I think it would be fair to say thata certain type of hype is happening oneof the things that I I always say isthat I think that the umum so so the the term that we've adoptedto somehow share that with the outsideworld to to make sure where we believewhere things are going it's like we'veadopted this term AI native and one ofthe things I always say that I believeis thatum it's very exciting of all the thingsthat you can do now with purely with themodels right so and people will buildnew products people will build newstatus but what I actually believeis that in in the not too distant futureum it will just be sprinkled ineverything right so you gave the exampleof theum of doing something on your laptopthat you might open like PowerPoint andyou you get some suggestion or somethingis happening why these models incombination with these embeddings andthese database play play a roleum would you think that do you thinkthat's a fair assessment of of how yousee things developing or or would I bestretching it when I said it yeah my soI'm not you know the deepest uh experton all this like there are probablypeople out there that have an evenbetter view into where things are goingbut I think definitely that's going tobe the future we live in like AI isgoing to be so it's just going to belikepart of everythingum because it the way I the mental modelI use for this is that there's like thisset of problems that we know how toanswer with step-by-step solution thatwe know all this all the steps so likethat's just code rightum so I know how to display a button onsomething that is rendered by a browserso that when your user clicks it doessomething like that is something I canlike break down in the step-by-stepsolutionbut I would not be able to write a pieceof step-by-step code to do imageclassification for example of like whatis a dog and what is a cat that'd beincredibly hard to do almost impossiblebut the beauty of machine learning isthat it lets us create programs likethat we can run on computers that dothings that we don't know how to writethis explicit step-by-step solution forjust by showing it enough data of theexamples of what we want it'll do it andso before you imagine like we had likeonly this part of the world that wecould build in because we knew how towrite code for it but now like the restof the world that we didn't know how towrite code for before is available to usand so I think that's actually where ahuge number of problems that people runinto or like human desires and like theproblems we want to solve required thatthat higherlevel of of thinking or or kind of wayswe didn't know how to write code tosolve it um I think that's going to bethe the story of the next like 25 yearsyeah I have one more thing on that Johndo you like I love this kind of Step byStep where you know we could easilyDefine a task now the task is moreabstract and I think the next step onthat is the tasks that we don't evenknow our tasks already that's reallyinteresting I think the answer to thatis this open-ended open-endedness stufflike uh from like I remember like Jeffcloon and Kenneth Stanley had done a lotof this they have this like umthe the initial experiment was thisthing called poet where it was like abipedal walking agent and um all sortsof environments for it to walk in andnow it's they they are testing this inin Minecraft simulationsso I think with the with the largelanguage models and how we're simulatingthem like you're good to have like alittle economy where they each haveroles and you can simulate this andcreate these like open-ended worlds soevery do you like this idea ofopen-endedness yeah that sounds awesomeI uh I think that that's especiallygoing to be interesting so uh I don'tplay a ton of video games anymore Idon't have a lot of time uh that I spenddoing that but I still think about thema lot for some reason and I think thatlike it's just kind of this this idea ofthis like Holo deck that you can just gointo and experience a different worldthat has its own like story and lifegoing on in its ownthings like that that is an enticingidea to me that we could do that in amore serious way too not just forentertainment but for you knowunderstanding economics orlike even even you know how how have webuilt this city this way like let's saywe're going to redevelop a certain areawhat would the impact on people be likewould it have any weird externalitiesthat we're not anticipating right nowlike maybe you could simulate that withsome agents uh in a like a long and andfigure out like in the next 50 yearshow's this area going to look uh thingslike that but not only that so I so theum the the podcast that Connor and Irecorded about um these degenerativefeedback loops that werewhat can this lead to right so in in oneexample that I that I uh often give uslike in the form of newspapers so thatwe could say like you can get to asituation whereum you might be reading a uh a newspaperthat just shows a completely differentarticle like as in the text in thearticle based on my preferences and myknowledgeum as opposed to what is shown to somesomebody else so if there might be anarticle about specifically highlightingsomething about you know maybe machinelearning then for John for you it mightshow more detail uh um or or agenda foryou and for me it might beum you know more holistic view or it youknow tell it to my interest but I couldimagine that we're going to seeplatforms and I I would also not besurprised if that starts withum uh with for example newspapers ormaybe music or movies those kind ofthingswhere and then building on what you justalso said Connor is the um that thatjust is completely different at somepoint for for everybody else that is noteven like a article that's different butjust that you just get your completelyowned space in in the news realm forexample or in in entertainment for thosekind of things but you just see thingsthat are tailor-made to you and andwhere there might even be agents thathelp you navigate to that world that isthere made for you so I I can definitelyuhum I I can I can definitely see that Ican also see the scaling uh uh issuesthat might come with that agent butthat'syeah I love the I love the idea of ofdynamically adjusting the the not justthe content but also the modality likeif if you maybe prefer reading a longarticle or you prefer watching a shortvideo or something like that there'slike so many different ways to consumeanything really and I guess right nowyou just have to sort of either you pickthe largest user group and you produceit for for that particular group or youproduce multiple things but the idea ofjust having the content just be therejust once and and have the user on theFly turn this into a video or a text ora blog post or scientific article thatthat sounds really enticing as well yeahlike I could imagine a future where I'mwatching a video at home and then I needto drive somewhere and so like itseamlessly transitions into an audioonly version version of it but likeexpands the description of stuff so thatyou don't need to see the visuals andthen you know maybe I I get out my carand I go into a coffee shop and it swapsto like a text version that is easilyreadable on my phone like so that theinformation is the is consistent betweenall of those versions but the the likeactual delivery mechanism has changedum I think also so like this this ideaof everything is going to be customtuned to us there's also this reallyinteresting alternative uh like thingthat will probably happen in parallelwhich is like what why do we consume artright now it's like movies or somethinglike I like to use Wes Anderson as agood example like his movies are sodifferent from other movies and likefrom what we would have createdourselves in our own imaginations likethose images and the colors and stuffthat like we we kind of it's delightfulto like live in someone else's mind fora little bit like that's kind of justinteresting to humans I think to peopleand I think that like the power of thesegenerative models is going to be thatlike you can have are people with likeyou could go go see someone else'shyper-tuned version of the world andthat would be probably extremelyinteresting and stimulating for peopleand so we're all going to be able to beour own like Wes Anderson like we'llhave beautiful amazing stuff that wecould share with others so they can kindof visit us in our worlds and stuffum I think we're going to see just a lotof really good art coming out in thenext this interactive art things likethat yeah yeah and it's nice and so alsosomething purely by coincidence that wediscussed yesterday also with Connor isthat the you often seeum there's this this uh this author Ireally like umor Bruce Sterling who writes about theseideas about these Concepts and then hesays like if you want to see theseInnovations then look at music it's likeoften it's first happened somewheresomebody does something with you knowmusic so it can be generative music orthose kind of things and then it slowlytrickles into other art forms and thenit trickles into into into business andso it's um exciting to see what willhappen but I I can I can see this thisis just aum I can just see this happen it's likenot not very hard to imagine so yeahthanks for sharing this is greatyeah I'm sorry I think so much aboutthat I because I think a lot about weaveyet we have ref to VEC which is ourapproach to personalized embedding whereit's like we use the graph structure ofwith users and products and I love whatyou're saying like if the four of uswere to watch a movie together we couldmaybe average our four embeddings andthen search with that Vector so I justyeah but anyways this is super excitingyeah and Bob you at first I rememberyou'd pitched the idea with uh Marco andChris of like an embedding that you takeeverywhere you know like your digitalkind of embedding that you take all overthe Internet and what that idea was socoolyeah exactly and and that that's thatthat's a little bit complex in the senseof then then that somehow needs to bealigned with other uh with all the othermodels but but the point of that wasmore like a a representation that you sothe the example that I gave is thatwould be nice if you would have arepresentation so that if I to stay inin the the realm of art that if I go toNetflix right that I presented with myembedding or my identity and if I go toDisney plus that I again presented withmy uh with my embedding or pluralembedding whatever but conceptuallythat's the idea right so and as you canbasically say okay this is this is whatI'm interested in and then um that itgenerates stuff for you I I can I cansee that happening we we we talked aboutyou mentioned Wes Anderson the other daysomebody made this this video I saw onTwitter uh with like this generativeStar Wars moviewith in the style of Wes Andersonum and I think what's very interesting Ican now somebody made that right sosomebody was rendering these frames andthen you know probably somewhere inFinal Cut just you know got the gotthese things together that is just thatis just work that can be automated rightso um the time that you're watching ashow on Netflix and that's just like heyin 15 minutes from now your next showwill be rendered for you based on whichthat's that's so gonna happen that'sjust I I bet a nice bottle of wine onthat that that's gonna happen in the nottoo distant future yeah yeah I like thisidea of having this embedding you canbring with you that kind of describeswho you are and like what you enjoy andwhat you're looking for[Music]um it's sort of like it'd be really coolif you could you could uhdecouple it from like ad targeting in awayum like it's not what age am I and youknow what part of my life am I in likeI'm looking for more this is what I'minterested in seeing right now likebeing able to provide that to to therecommendation systems no matter whereyou go on the web and have like auniversal system that you could justgive them permission to use yourpersonal vectorand then are your personal embeddings uhbecause like for example yeah like Ilike certain types of restaurants likeatmosphere to me is really importantlike how did the restaurant feelarchitecturally inside and like beingable to go to a new city and then justpop that into the search and be able tolike have it recommend placesspecifically for me in the context ofthat City that'd be coolyeah or the I think the example that Igave on a podcast I if I remembercorrectlyum uh is the uh is it a car right solet's say that you rent a car and whatyou already see now with a Tesla thatyou can adjust it for like how you liketo drive when it when it drives for youthose kind of thingsthat you just you know you just rent acar you go in the car and the car justokay this is the type of driver Bobisn't what he's interested in and heymaybe at like a busy day so let's justyou know relax a bit more whateverwhatever the thing does right but Ithink that's an example ofum uh uh where such an embedding doesnot have to have specific informationlike my age or those kind of things butthat it just knows what type of driverum uh that I that I am so it's okay butI always like to do those like I like todecouple these things in the in thebrainstorm process so basically we'renow in this realm of brainstorming aboutthe opportunities and I always like todecouple to risk the risk from itbecause the sometimes what happens withthese um uh with these creativeprocesses when thinking about these kindof things if you then try to reserve alittle bit in your mind for like okaythis might be a problem then you'rebasically you hit a roadblock and you'rethinking so I always like to go throughthe whole process of thinking about itand then getting going end-to-end and Ihad like these uh these these thesespeculative design kind of methods forinstance okay now we're like end to endin the opportunitylet's write them down or those kind ofthings and then let's revisit what youknow potential risks might be orsomething but that's just more apractical thing but I I like the tothink about these kind of things and toshare this with world because that'sreally nice and I like I love what thisuh this podcast turned into because Ithinkum more and more people are gettinginspired by these ideas like hey youknow I'm working in whatever they'redoing right and I can align this ideawith what I'm trying to build so that'sthat's exactly that's very cool thankyouI've very recently had an exact exampleof the serves personalized in a biddingapproach my my Spotify contract was tiedto my phone contract which I had no ideabut when I switched my phone contractall of a sudden I had no more Spotifysubscription so I thought like okay Ialready already pay for YouTube premiumso why not give me YouTube music a shotand it was interesting to for the firsttime and I don't know how many years toto retrain basically an algorithmrecommendation algorithm to retrain itlike what music do I do I like and it'skind of like on the one hand I wish thatI could have just taken my Spotifyembedding so to speak and just put itinto into YouTube music which kind oflike opens up that question of whoshould own what data like is isrecommendation data that's that's kindof specific to you as a user like shouldyou have like a like a a a a a requestwhere you can just download this andpersonalize it but at the same time itwas also an opportunity to really thinkabout likewhat music do I listen to BecauseSpotify recommends it to me as opposedto because I actually want it so likehow do I want to influence thisretraining so not just have yourpersonalized embedding but also thinkabout how it evolves and how you maybewant to want to change ityeah I think it's it's that's really andthat Sparks a lot of ideas for me toobecauseum I've I I use YouTube more than I likeI don't uh watch TV I just watch YouTubefor the most part I have it on my AppleTV on my like and it's it's I'm reallyit gets hooked on these like cons likeit shows you oh nothing but gardeningvideos for like weeks and you're likestop showing me gardening videos I don'twant to watch these anymore but youwatch one video and it just like oh likethe recommendation system thinks oh nowthis is all you want to seeum but it'd be really nice to have likemore trainability into these things orbe able to just write out like what youwant like heystop and then have it adjust the rankingalgorithm to give you you know somethingthat's more aligned with what you wantyeah it's it's it's it's fascinatingit's it's interesting I noticed that Irecently was using a um it was like oneof these speakers that you can buy andthey have like their own apps but theywere connected to the to the Spotify APIbut they didn't have the you know thethe suggestions and the ranking of uhSpotify itself and then you noticealready how good it is inside spot ifyou're in Spotify because I try to findan album I just couldn't and I knew thatit was just that this app this other appthat was connected to this to theSpotify uh API just had like very basickeyword matching and if you try to findan album that has like I don't I don'teven remember what I was trying to findbut I found some pretty weird albumswith the same words in there so it'slike um uh but it's a good point andthat next generation of really usinglanguage to just describe that or but Ithink also conceptually that we justneed to go to a situation where you'retelling YouTube something like we're nottalking to each other like hey YouTubeappreciate the the gardening videos butI kind of had it my garden is done rightso I want to see something else yeahexactly yeah I think just just the Iremember the first time that I putsomething in a that I that I that I madea prompt that I wrote a prompt andthat's something sensible came out thatI remember like whoa I need to get usedto this Paradigm Shift of writing aprompt and not doing something in acertain structure I really really reallyneeded to get used to that so but Ithink the um uh um so even my point iseven if these platforms get to the pointwhere they accept that and I canactually properly do that just changingpeople's behavior that they start tointeract with these machinesum uh um uh in a way that is likebasically another person I find itfascinating I once there's actually a Ithink it's like a paper maybe it's likea psychology paper or something but butit's like that somebody published aboutthe question that if you interact withthese machines if you if you should saypleasethere was like a whole thing that theywere and then it was like related toChildren right so if you for example ifyou ask something from another humanbeing you'd say please but um you knowshould you teach our children to alsoyou know politely ask the machine to dosomething for you it's it's a it's it'sinteresting it's exciting stuff that'shappening well who have you have usedplease before in chat GPT I'm definitelyguiltyI'm not decided on whether I think uheven AI like I think definitely not atthis level is AI like actually consciousbut uh some some people I you know Irespect their opinions on things they'relike yeah maybe we shouldhave a more open mind about whatConsciousness means and I'm like okaywell it doesn't hurt to be polite atleast you know like if some super raceof aliens out there comes into Earth andthey're like 10 000 times more smarterthan us if they said please to me Iwould be like you know okay that'd benicegreat yeah thank you I think about itsaying thank you would be worth theextra request to the API thoughyeah so like you knowso I think actually we could get to thiskind of instruction fine-tuning databaselookups sort of or I don't know what tocall it that's a bad that's a bad way toputting it but like being able tocreate a like a model that you just sayhey can you downrank gardening videosfor me or like say it in a more naturalhuman way and then it would translatethat to uh things that could go into thecall to the search back end that likedownranks things with certain keywordslike you might know it might know how tomake the database do what you're askingit to do like maybe this is somethingthat that you guys could pursueum being able to just take a user's likecontextual prompt in and then translatethat to database you know query featuresthat that make the search more relevantto what they're actually looking forBeyond just the queryyeah and that's actually that's that's athat's a very interesting point and andum bring something else uh um to mind isthat something that is super excitingalso for me to see is that what's kindof new in infrastructure is that ordatabases specifically isum no models no effects of databaseright that so it's like they they gohand in hand andum the people that are building thesemodels and I work on these models wewe're working with a lot of them andjust just as you just did John and we'regetting suggestions I was like yeah howcan we do that from the perspectivedatabase and and how can we and thenwhat's the what's the where does thedatabase start why does it endsbasically those kind of things and alsowith the models I think that issomething that I'm super excited aboutbecause it just basically means morepeople working together on solving theseproblems andum in the end yes it's exciting uh butit's also just people working togetherright so that's yeah that's that's youknow I'm I'm that's something I'm maybeeven the most excited about so that'sthat's cool yeah and then we can likeimagine a future where there is nodistinction between your database andthe model and it's just one thing likethat you say here's a document insert itand it does and then you say hey get medocuments that match this kind of Queryprofile and then it just pulls them outor or you can mix in like you haveimages and documents and audio and it'sjust all just like a blob but it's anintelligent blob that knows what's in itand knows how that stuff relates to eachother like you won't even have toexplicitly create indices yourself likeit'll just do that based on the datathat's in itum yeah that's actually why I'm why I'mthe theum the term Vector database right so theterm factor is and I I get it Iunderstand whyum it grew into being you know beingcold like that and and why we call itthat butactually I hopeuh that in the in the note to this infutureum our users don't even have to worryabout the fact that it's an embeddingthat's being stored so the example thatI often give isum if you use a traditional searchenginedo you know what kind of indexes startswhen you search for somethingmost users don't so and I hope that weget there that that we get there as wellthat's also why why I think it'simportant that the the accessibility tothe models but also to the database sothat you move as much to a naturallanguage as possibleum that that's important because thatjust gives a lot of people access to usethese Technologies in their stack ratherthanum you know complicating it with thekind of language and if people need tolearn what embedding is and those kindof things so it's aum uh so long story short I I agree withyou John I hope that at some point thisjust becomes like one Big Blob of youknow stuff that people can just oh Iwant to use this for my next project orwhatever and then it just embed itregardless if that's like in in thecloud on their laptops in their in theirphones in the cars I don't really careabout this but that's the um I I reallyhope that there will beumthat that will happen sooner than laterI think to some degree we almost alreadyhave that if you depending on who youdefine as the user because for us fromour perspective it's typically the onethe the database operator or the onethat would spin up bb8 but the end userthat just sees the search interface whatare the odds that they know that there'sa vector search going on like if you useGoogle right now what what how much doyou know about what's going on under thehood so and I think that as as more andmore vector and and similar searchsolution make it into production thatalso means that more and more end usersare experiencing many basically thebenefits of vector search without evenknowing that it's that's thereyeah I like this like abstractionconcept from computer science where youjust kind of handle something and thenthat's no longer a consideration youneed to make and and you can think of itas a different thing like like a keyvalue store you're not thinking abouthow like those the data is being likelaid out in memory and stuff you justthink of it as I put a key and I get avalue out and I think like we're goingto keep abstracting stuff higher levelsso thatyou know right now the abstraction levelthat that like software Engineers thinkuh about Vector databases like I need toembed vectors and put them into acertain place and then I need to youknow do do lookups like whateverwhatever but I think like at a certainpoint we're just going to have thisagain like the abstraction layer isgoing to increase and it's just going tobe like a thing you can put things intoand get things out and you're not goingto think about anything about how it'sactually works on the insideum and thenthen what's possible right so like nowyou don't need to think about thosethings in order to build a build an appand who's going to be able tolike we're going to be able to think ithigher and higher levels which is reallyI think that's where like reallyinteresting things come out and you kindof see that starting to happen with thellm community uh like they they sort oftreat the vector database that they'reusing or you know maybe a hyperdb likenumpy array cosign lookup thing but theytreat whatever that is like they don'tactually care how it's implemented andthat's why sort of they'll just pipinstall something and then use it evenif it's sending their vectors out to athird-party like server just to dosearch on a 10 10 documents or somethingbecause they just want to think at thehigher level of I'm instructing an AI todo something it needs to be able to likehave some data and look it upum and so this is kind of like the trendwe're going intoyeah exactly I mean it exactly andthat's like um I think this is gonna gofor like at least the coming but yousaid 25 years probably that's gonna uhthat's gonna happen sothank you for sharing this it's superexciting also what you're working onbecause the um we of course we besidesof course hyperdp we didn't do with theother things uh where that you wereworking on the in-depth so that's nicethank you for sharing yeah thanks forhaving me on I really enjoyed talking toyouyeah thanks so much thank you thank youso much Johnthank you so much to John dagdollen forjoining the wevia podcast to talk abouthyperdb and all this super exciting workon scientific literature Mining andMaterial Science please follow Johndaglin on Twitter at jmdagdollen thanksagain John", "type": "Video", "name": "HyperDB with John Dagdelen, Bob van Luijt, and Etienne Dilocker - Weaviate Podcast #46!", "path": "", "link": "https://www.youtube.com/watch?v=85VZFQw_7Oc", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}