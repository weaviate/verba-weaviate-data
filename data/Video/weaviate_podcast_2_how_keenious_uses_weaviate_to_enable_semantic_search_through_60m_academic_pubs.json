{"text": "Join \u202aConnor Shorten (Henry AI Labs) and Charles Pierse (Keenious) for the second Weaviate vector search engine Podcast.\u202c \nhere with charles pierce a machine learning engineer at kenius at kenius they're building a really exciting scientific literature mining tool using tools like deep learning and vector search in order to let you search through the scientific literature to find relevant papers and relevant information for whatever you're researching so really exciting thing about keeney is that stood out to me is it's uh plug into google docs and microsoft word as you're writing a paper or drafting up an idea you can highlight text and then just query the keynes through this plugin and it will search through the scientific literature to help you find relevant ideas so i think this is an extremely exciting and powerful idea so i'm really excited to talk to charles about kenius and all these different ideas around scientific literature mining deep learning and vector search and the grand vision of where we think this kind of thing is headed so thanks so much charles for coming on this podcast connor thank you very much uh i'm honored honored to be honored to talk about genius and our experience with kind of vector search in general and what we've been doing with we've a couple of the past couple of months so yeah thank you very much super cool so before we get into kind of the details of it could you explain to me uh like where kenius is at how it's organized and sort of also introduced the problem of scientific literature mining yeah so uh genius is it's an academic search tool um as you mentioned and i suppose the core of what kenius tries to do is just to make research um and academic publications easier to to search and explore and to discover so kenya's kind of takes kind of a holistic approach towards research in that we we try and cater to researchers from all levels and that's kind of from undergraduates all the way up to phds so our kind of guiding philosophy should be that you know we want to kind of create that wikipedia effect of going down a black hole of like you know discovering topics and we want to do that with research publications and research research journals or any kind of entities within within research so our kind of guiding light is always to make that process of exploration fun and add a bit of serendipity that's kind of how we describe it it's serendipitous search so you know we we're not like kind of an exactly a traditional academic search tool where you type in a single kind of forward query and get back exact results we of course can do that but we also like to add in this kind of serendipitous like hey here's an intro here are also some other interesting results that might not match exactly on keywords whether within the kind of within the academic sphere of what you're what your research you know what you're looking for um and of course then clenius obviously has we we don't limit ourselves to short queries uh you can search uh you can search on genius with uh documents of any arbitrary size so there really is no no limit you can if you if you're if you've got a paper with i don't know ten thousand to a hundred thousand words you can search using that paper our search engines optimize to conduct queries that big so it's it's all kind of possible um and where we're at now with genius is that probably for around the last two years um we've been kind of in heavy development of the of the product um and over the last maybe eight nine months we've been expanding heavily to integrate kind of some a lot of knowledge graph features so um we've been working a lot on kind of becoming as well as being an add-on becoming kind of a goat a kind of a single centralized like kind of just database for searching authors and topics and institutions so you can you can really search through any kind of entity type now um and we're we're really trying to kind of like kind of introduce a introduce a new way of discovering academia to kind of compete with google scholar in a way that we think is more organic and in a way that we think kind of facilitates uh serendipitous discovery in kind of an easier way super cool so i think starting on the on the comparison of google scholar and so anyone um listening charles has written a really great article that details these topics uh about using wev8 and searching through 60 million academic papers and yeah this topic of serendipity really stood out to me it's very interesting because we talk about neurosymbolic search where you have the neural search where you're using these vector embeddings and you're looking for the nearest neighbor in these vector embedding spaces then you also have symbolic filters which is like google scholar where you have keywords so say you type in data augmentation you're doing data augmentation research it'll match the data augmentation keyword whereas this idea of serendipity that charles is describing is in between matching the keywords as well as this kind of neural search so it's kind of like this um this uh range i guess where you're either looking for an exact match of the keyword or you're looking for a set center of the fuzzy discovery of the neural search engine so this is this kind of like how you're thinking about neurosymbolic searches and that it enables this kind of creativity yeah that's that's exactly the point is that their search is a funny thing and that there are times when we have we do searches where they are certainly the the intent is to do kind of a keyword search and that's fine and you know most search engines today behave like that and they're great but neurosymbolic search and kind of neural search is what's most interesting to us and to me i you know i'm fascinated by it because it kind of it's it's only in its infancy now but already with in in the ways that it's kind of it's shown its usefulness it kind of i think it works in a in a way that very human and very unders like kind of very easy to understand from the standpoint of how we associate ideas in our own heads you know they they're not necessarily interlinked via keywords but they do exist in these spheres of kind of context or sphere like you know yeah exactly context and spheres kind of these spheres of relatedness that aren't explicitly connected through keywords so what we really try and do is kind of write these heuristics where we understand we try and understand when our user might be looking to do a very strictly a very strict search and their intent is to find exact keywords because of course you know that's a very it's really important to be able to satisfy that need as well and then we try and also solve for the case where a user might be like hey i don't really understand this topic too well or this is something that's new to me and i just want to ground myself in all the relevant research around this topic or this concept like kind of conceptual field and to be able to conduct search there is what really interests us and that's what we think we do well and that's what that's kind of i suppose that's our unique selling point at the moment is that we we really feel we can we can do that kind of context-based neurosymbolic search really well and help students and researchers find find things they wouldn't be able to find kind of via phrasing a query or anything like that normally yeah i'm super excited about the idea of in context and i really want to get into your use of knowledge graphs and the graph structured embeddings i don't think i think the use of citation networks is one of the most popular examples for communicating the idea of graph embeddings in deep learning and you know the you're probably 101 graph neural network tutorial will be with the citation network so i'm really excited to get into that but i want to stay a little more on this neural symbolic thing and this idea of classifying the user intent in order to maybe add on symbolic filters because i think maybe the the interface that scales you between neural search and symbolic search like for example in wva you have to use graphql to add these kind of symbolic filters so is there a layer in between the search that classifies the user intent and predicts whether they are going to need a symbolic filter on it or predict whether they're in the say discovery phase and they want that kind of uh uncurated result that would come from neural search absolutely yeah now we we have we have kind of a bunch of uh kind of learned over time heuristics that have kind of brought us that that brought us to that point so you know one very simple heuristic you can think of is literally just the length of a query um if you if you have a if you have a few short words well you know i'm talking under five six words that query there's probably a higher chance that the user there might know exactly what they're looking for and or like have a few keywords keywords in mind so when we do our search it's not that we um turn off the nor symbolic search or the the semantic aspect of the search but we might dampen the results you know so we have this kind of trade-off between how we value and weight um value and weight or weight or search results so one example of a heuristic might be with this the length of a query that you know if it's really short and kind of exact well then we know that the keyword search might be really appropriate here because this person has an idea but then we also have a feature in genius where if you if you like a particular paper you can kind of click and find similar articles um or find similar papers button and we're always focusing on making that even kind of that feature easier or more apparent but with that feature what it really does is in that when we can we consider that intent as being the user really being open to explore you know because in in that instance they don't have an explicit query they're just saying hey i like this paper um so then we really will really bump up the the semantic aspect of the search um and we'll we'll really kind of focus in on let's say using our knowledge graph search there um and really valuing the semantic vectors over a keyword search because we find them those to be much more useful especially with the not since we've introduced the knowledge graph than the text search because the knowledge graph tends to really find you these gems kind of in the research proximity of a paper you know so you'll kind of find that you start all these milestone papers come up as well as just really interesting kind of papers that you couldn't really get um with it with an exact query because you don't know how to search you might know exactly what what what the field is you're you're looking at or the subfield you're looking at is so do you think about like um like user embeddings like you have returning users and like you know maybe using their specific some kind of embedding their specific behavior to kind of guide that yeah so that that's something where we we've looked into that and we we have like some pretty cool ideas to do that but we're not doing it just yet um in terms of like it there's a lot of the time with search engines like this there's kind of this uh you need to hit a critical mass um of like user embeddings to get there because we have you know over 60 million papers it takes it takes some time to collect enough data to to really build like rich and rich embeddings off of that you know you actually need quite a quite a bit of quite a bit of user data to start getting useful uh item embeddings for recommendation there but that's that's certainly going to be happening um and that's why actually knowledge graph the knowledge graph embeddings were so attractive to us because they kind of solved that cold start problem where you can get really good recommendations um from papers with kind of a zero like you know theoretically zero information about users and and their likes and interests that's so interesting i'm definitely gonna be you know coming back to this interview and thinking further about that one that kind of like maybe like a semi-supervised approach where you have some label data and um and mostly unlabeled data but in the case of this 60 million graph it's like semi-supervised in a very extreme case where you have a extremely small amount of labels so so let's transition to this cold start problem and and um and like what that looks like with paper recommendation i suppose the way that we look at the at the cold star problem with the way we had looked at is that we were looking for a solution where we let's say let's say there's an instance where a user has they don't have a they're in there they don't have a paper that they're currently writing and they don't have a query they don't even have a query to write they might have they might have an idea of a field of study or concept that they're interested in they might have an author that they're interested in or maybe a professor mentioned a seminal a seminal paper let's say we'll take for example attention is all you need you know that the seminal kind of transformers um burp paper so that might be all they have they might they don't know what query to write so we kind of viewed the cold start problem as being a way to give recommend really rich recommendations for papers without like the user having a document or having it being able to formulate a query so the first stage of that has been with this just the using paper identities but we're kind of we're we're getting close to being able to pretty much search from any entity type which is super exciting um but right now the way you'll be able to do it is if you have a paper like attention is all you need that's the paper is all you need to the name of the paper is all you need to that's an awful pun to um to get a recommendation really and you can feed that paper in or you can feed a collection of papers in and we'll get an average we'll get an average kind of embedding for you and we'll we'll search off that paper for you and find we can find like hundreds of thousands of papers in its proximity and you know some people might say oh you're just going to get the papers that it was that it cited but no what's going to happen is you you're of course that actually how we measure how good the model is that we build is how many papers obviously from that it's cited that it returns but after that then you're going to start seeing you know these uh papers that papers inside decided and so on and so forth and you know you get this kind of indirect relationship that's what graphs you know that's the power of knowledge graphs they allow you to to query indirect relationships um and the knowledge graph embeddings which we have you know ideally what they'll do is all the papers around attention is all you need will be embedded in a latent space with other relevant papers to that to that paper outside of its citation graph so before we get into the graph a little more do you think search and recommendation systems are kind of the same tasks like do you find yourself the the lessons and i think like rexis is what they use in the papers it's all the same kind of thing and also do you like re-ranking is that also kind of like all the same thing really it's we we we we've had this conversation so much at work where it's it's kind of in my opinion it's they're kind of melding into into the same thing it's getting to a point where when does a when does a search become a recommendation when does a recommendation become a search because you know if if here's if we're getting users to input like anything like entities such as papers or authors or fields of study well that's a query but the query is a solid entity and then we're recommending based off of that entity so the line is the line is kind of kind of pinning down i suppose because you know the experience in genius is that you can feed in both a query a document or now just a paper name but we're still going to give you the same type of results list back of papers so if the outcome is the same the the difference is starting to kind of become hard to decide um so and in terms of the the re-ranking reranking's really interesting um because i i suppose with re-ranking the way let's say for example how google use it they have some really clever clever ways of using it where it is kind of maybe more in the traditional search space and then they find all these you know they don't just use the query as the re-ranking factor they use things like geographic location previous intents previous searches to to re-rank your results for you so i think re-ranking is for me it's like a way of ensuring relevancy from a result set and that that's what i find really cool you know we use re-ranking we have a genius has a really interesting bookmarking system where we if you as you say if you find like hundreds of papers you're like we will rewrite those papers when you go into your bookmark system and let's say if you're reading it if you're currently writing an essay about um optimizers or and how optimizers works work in neural networks well then the papers that you see first in your bookmark toolbar will be papers on that and we do that automatically so you might have you and then the next week you might be writing a paper on um i don't know the attention mechanisms and then every paper in your bookmark system about it the attention mechanism will be ranked first so we found that to be a really interesting use case of re-ranking where we we contextually re-rank depending on what you're doing so yeah i guess like with with the way i think about it is like maybe when you have the recommendation system kind of problem set up you maybe have like the reinforcement learning optimization as you are and and i think the genius is a very cool interface for this as you like as you if the uh user cites the paper it's like the reward for saying you recommended a good paper they cited it so that kind of thing of um of having some kind of maybe reinforcement learning feedback is that do you think reinforce and learning is useful or do you think it's more of a researchy idea um i i think reinforcement learning is going to in the next five years is probably going to explode much more into the mainstream kind of ml world than it has over the last 10 in that exactly like you said i think reinforcement learning kind of the last maybe five or six years has been focused a lot of it has been focused on like games and atari and solving those types of problems but now like the reward functions are looking at things like okay what we define a reward function according to a user like or a user citing a paper and and now all the same algorithms from that have been used previously are applicable and you know the internet and recommendation systems are completely based off of you know netflix you watch a film that's a that's a a one plus in terms of uh this agent system or this reinforcement and learning architecture so for from a lot of papers i've been reading lately it seems that that kind of crossover into the mainstream is happening i'm not like hugely fluent on everything reinforcement learning but from what i do know is uh over what i want what from what i have read and heard is it it does seem like it's it's kind of crossing that threshold um kind of the way you know natural language processing did six or seven years ago where it was kind of before that image was the images and was it was everything and now the kind of text is text and natural language processing is kind of the the key modality right now when people think of kind of state of the art and i think reinforcement learning might be going there next and primarily because natural language processing is incredible but most data sets that you know users or companies have they're not actually text completely textually driven they're they're tabular they're they're split up into scalar values and you can you can use that much more in reinforcement learning systems as inputs than you can purely text data of course text is always great because it's a you can use those embeddings as additional features but you can use everything with reinforcement learning yeah and i think like with reinforced learning it's like you start off with these q tables that evaluate state action pairs and that's fine if you're uh say the cardinality of actions isn't too bad but when you say you're using reinforced learning for text generation and you're going to iteratively select tokens to generate out of a vocabulary of like 30 000 tokens that's much harder than uh left right up down in an atari game so i think that's where a lot of the problem with reinforced learning for like q learning for say text summarization or chat bots or anything so i think but i think with re-ranking you've already kind of filtered down the action space to these uh like one 1000 or 100 that come from the course because it's like information retrieval and then it's like the refinement stage so there's like it's like this pipeline where we're seeing information retrieval and supervised learning or say reinforcement learning but like this kind of uh stages of coarse-grained fine-grained optimization kind of and exactly you know i love that topic of like um information retrieval and supervised learning but before before i go getting too off the rails with that so i really want to talk about the knowledge graph at uh kenius and because it's so interesting that um that you're using the citation network instead of say the um the text embeddings that would come from like siamese bert and so again tell me about like generally how you think about graph embeddings and then the things that go into thinking about building this yeah so for for this knowledge graph part uh part of kenya's research we're using uh knowledge graph embeddings and you know i probably got into i started using knowledge graph or like learning about knowledge graph embeddings about like a year a year and a half ago and i just found them like so fascinating the same i found them just as fascinating as i found text and document embeddings maybe three three years ago it got me probably more excited and the reason i think it's so exciting is that knowledge graphs are a really great abstraction around data because this is how i've come to understand knowledge graphs and that any data set can really be abstracted to a knowledge graph it's just it's really just kind of an arbitrary way a very useful way of modeling modeling data in a graph like structure that we understand that can be multi-entity multi-relational whatever you have so it's a very it's a very interesting way of modeling data and because we humans are very good at understanding these knowledge graphs and that model we've learned to build these knowledge graph embedding algorithms off of those and what was so fascinating to me was that that these embeddings could kind of feed off of all the different entities within uh kind of a really related graph and that they could every embedding it's not just it's not like in text where that's the only information it has is the text it has it can have so much context imbued into the latent into latent space from you know so many different elements that these embeddings are just the potential for richness from them was huge huge for me and you know in terms of if i think if i think of what's the kind of one of the greatest features in search i think knowledge graph embeddings have to be up there because again going back to that problem of text text embeddings and document embeddings are so powerful and so amazing and we really learned so much about embedding search from those but not every organization or company or individual has these super super rich text data sets but i'd be willing to bet that most companies and organizations have fairly rich you know populated data tables and like that's that's that's where the meat of a lot of companies data is it's actually in these tabular data sets that are you know they're if even if they're tabular they're they're you those can be that can be abstracted to knowledge graphs because that's all knowledge graphs are it's an abstraction so if you can imagine your data set as a knowledge graph well then you can formulate a training process to turn that knowledge graph into embeddings and then you can turn every entity in your knowledge graph into a searchable embedding which means you could do something like what like what we can do is you can get an author and you can search papers from an author or you can search authors from from authors and you can do all this end to end relational searches from any entity to any other entity so kind of for me the potentials there are fairly fairly limitless because you can kind of start to do these really cool queries that you could just never do before with with it with entities and you can like kind of the same way word embeddings work you know the uh man plus man plus uh queen is equal to king you know just with the same word embedding idea there is this kind of additive and like average embedding factor where you can you can find like the an average embedding for you know two two types of entities and then search off of that so that you can if they're a really really amazing and the entities embeddings are a really amazing tool to kind of conduct kind of so many different types of searches off of and i just find that really really interesting um and i think what's happened maybe the last four or five years is there's just been tons and tons of research being published on um models uh kind of models for graph embeddings and they're you know they're only getting better um and it what from what i've seen in maybe the last 18 months is there's just been an explosion about you know graph neural networks is slightly different the it's kind of there's a bit of confusion with graph neural networks but the two fields are combining and the graph embedding space has really picked up and there's just some really great work being done there and especially with the multi-entity stuff i think that's really really interesting yeah so it's such a general framework and i'm even i'm having a hard time wrapping my head around kind of the scope of these i think ontologies as they call them where you're just like as you mentioned like you you we have these sql tables where say you you have like a purchasing table and you link it with a key id to go get the item table and then say like a customer database table as we have these kinds of linkings in these relational database systems and you could turn any of this into a knowledge graph where the um the edges that link the product keys between sql tables say that's like a different kind of relational edge and then they form these big uh graphs do you have like a motivating example of what an ontology looks like for scientific literature mining like i could imagine i have a collection of papers and maybe they linked to like an organization id like say they were published in eurips or icml and or maybe they were they're linked to some uh like topic like what are the what are the ontologies look like for literature mining yeah so here's here's our ontology like you know the basic um kind of academic graph um so you have entities so i would say the kind of the primary entities in an academic graph are papers uh or journals uh papers or publications so that's one type of entity um and then you have uh journals so where the where the papers are are published you have authors people that write the paper so all of these you can kind of see in a way there all of these entities starting to revolve around the the paper entity because that's kind of the first class citizen maybe of this one that doesn't always need to be the case so you've papers you've authors your journals um and then you might have concepts so a lot of a lot of papers are tagged with metadata the way a film would be tagged with a genre so um attention is all you need might be tagged as computer science as kind of the high level concept and then it might get natural language processing and artificial intelligence as the next layer maybe linguistics and then you might start seeing stuff about the encoder decoder architecture that's getting like that's getting down on a lower level so now all of a sudden the the paper attention all you need has author x and y and has uh has the field of study or concepts uh computer science uh natural language processing and so on and then the the paper might be published at a conference so a conference becomes another um conference can become another entity um so and that's just that's a very basic kind of description of maybe an ontology with five five different entities and then all those entities can relate to each other in different ways so and then you know there's there's so many different like mini entities you can add into this ontology and you can even have um two entities can have two different types of two or more different types of relations between them so you know and direct relations don't need to be symmetrical they can be asymmetrical so and the ac the asymmetry is also important when you're modeling these embeddings because you know you don't want to imply sometimes that asymmetry is just as important to imply that something that something in a network doesn't flow the other direction you know just because eyesight attention is all you need does not mean that i wrote it yeah yeah i also really like like with that line of thinking like causal graphs and thinking about like putting the causal dags into graph neural networks and that kind of thinking is really exciting so one kind of question i have about this is like we know that deep learning generally with small data sets doesn't work that well so do you need so then as we're looking at this graph data are you going to need like a massive set of node types and a massive set of entity relations to kind of make deep learning work well with this kind of thing there is something interesting about uh this is something i personally i i haven't read any research about this but i have been thinking about this in terms of knowledge graph embeddings which is that maybe overfitting isn't so much a problem with small graphs because and here's here's the way i think about that in that overfitting might not be as much as a problem with a a small data set because with a lot of knowledge graph um embeddings you can't you know if a new entity gets introduced to the graph you have to you typically have to remodel everything you have to rebuild the model because it's very every model every entity um every additional entity has to be added to the to the total embedding so that it just doesn't work you have to pretty much remodel redo the model when as new entities are added so getting back to it overfitting might not be such a bad problem with a small data set because what you really want is just to find the best the best embeddings to solve this typically the prediction task is like you have a head relation and tail and it's like predict the tail given ahead in relation so you know if you're if you're as you're building these models if let's say the validation and test results are coming out good and you know having scoring well on all your all your ranking metrics well then that means that your embeddings are you know representative and rich so in a sense because it's kind of a closed world of your just all the entities in your embeddings it's not like new text is coming in as you might have in a sentiment classification tasks like these are your entities so whether it's like 30 000 or 30 million like this is the entity embedding of your of your entire world like so to speak so in that case i think it's kind of interest i've been thinking about this recently that overfitting is okay or not the model having a small set of data is kind of okay because if it's learning if it's learning those representations and it's it's searching well around that space well then maybe that's good enough maybe that's all you need so and you know i've had some kind of fun side projects where i've you know only had 30 000 30 000 or so funnily enough um entities and it's been pretty good from what i've seen yeah i think there are definitely applications where overfitting is is even the goal like like when you're trying to compress images with deep neural networks overfitting is great yeah like um auto encoders if you over fit it but then you have a that you can get a latent space from the overfitting that's useful but i guess what i was trying to get at is is and you talked about it quickly with this i think the word they use to describe this is open set classification so if you take like the canonical deep learning example of cfar 10 where you classify images into like deership frog bird that and then you you don't assume that that there are going to be new classes added it's going to be those 10 classes all the time whereas i imagine these graphs and we talk about scientific literature mining as the application you would imagine adding new node types so like you want to have this flexible interface where you add new node types new edge types to keep this flexibility where you're saying uh like you just can imagine any kind of relation between two objects kind of so i see it as kind of an open set classification problem but anyways maybe that is getting too off the track with kind of just thinking about graph data and the differences i see in kind of making these ontologies work compared to kind of like the problems like glue benchmark c410 and most of the deep learning academic data sets so what have been some of like the key challenges in organizing this knowledge graph i i saw you recently spoke about pi torque big graph and i think that that in itself is kind of alluding to what some of the biggest challenges here and i think it a lot of it comes down to a lot of these tools are a lot of the knowledge graph embedding tools are kind of in their infancy they're not as they're not as kind of feature-rich or you know the community communities aren't as big so probably the hardest thing i find with knowledge graph embeddings is kind of the some of the tooling around it like pretty much our entire system for building our knowledge graph is custom because you know we had so many we had like so there's 60 60 plus million entities but you know you know how big citation graphs are that you're talking like billions of edges between all of the the authors and papers so that gets really tricky to do um and even just building those edge lists and build building those headsets um it takes like we're lucky to have a big work kind of a or work workhorse machine um that we use and it can store all that stuff in memory but it took a lot of optimization to get it there and then you know with the the graph training it's it takes up a lot of a you have to you have to when you're training these graphs you have to hold the entire thing in memory so you know you're if you're talking like 500 like uh embeddings of 500 dimensions for each entity well then that's under 60 million that's 500 multiplied by 60 million multiplied by 32 or 64 bit and it starts it starts to hog memory pretty fast um and the problem is you have to typically have all of these entities in memory somewhere it's not like in in some uh language modeling tasks where you can mini batch it you kind of you always have to have ins either in a in gpu or cpu remember in those memories have all those entities ready to go and as well as the relations um so honestly the hardest part about this task right now is um just the pipeline like kind of efficiently designing these pipelines and i think you know that's where we're really happy where we got that too and it was it was that was like 80 of my work to get it to that point you know that we knew that we pretty much knew that we could build the structure you know the models would it was a you know a pretty we knew that the models would find the relations between the academic graph you know that's kind of a proven problem so we knew we could get it there but that the trick was just setting up the infrastructure and i think you know that's the greater problem at hand and most machine learning problems these days is good infrastructure and you know i sometimes i don't think enough uh time is given to in terms of tuning to just like oh how do you how do you build an edge list of three billion edges and like load that into memory fast and how and how how do you how do you add custom filtering onto that to add some rules and you know we had to learn a lot of that um and it's a it's a really important part probably the most important step because if you make little mistakes there or the script that does it is inefficient and there's data loss well then you're in trouble so yeah the the hardest part for us was infrastructure and you know we actually as i spoke about pie torch big graph we initially started off using that tool but actually moved away from it just because um it was really really really great too but the you know the the the documentation wasn't so up to date anymore and the the community it's not been fully maintained and you know we couldn't take on uh we it was kind of a risk if we maybe took on something like pi torch big graph and it it's not going to be maintained going forward then we need to keep this graph up to date so um you have to make choices like that so with the infrastructure is it like mostly these distributed like data sharding model partitioning kind of or like um i guess just embedding table it's not really like a model right with these kind of algorithms yeah it's it's the it's the distributed nature of doing it and at in the end we were like just about by the skin of our teeth able to um avoid doing a distributed setup for training the the knowledge graph but we know that's not that's not going to be the case going forward because our data sets increasing so fast so we needed to kind of find find tools that are ready to go in terms of being distributed so yeah that that's what was really important um and there's there's actually some really cool work out there in terms of that kind of big graph like you know billions of entity learning and like by george big graph of course is up there you know there it is it does do that there's just a bit of trepidation as to whether how long it would be continually going super cool i just want to ask you a quick question about the nature of these graph embeddings and like you have to have the entire data set as the input and that's kind of the nature of these of working with graph data could you maybe do like i don't know if this like i haven't thought through this at all but like maybe you have like a minimum spanning tree or maybe you can just kind of like isolate nodes and take a lot of it off of the input is would any of that kind of stuff work and then you have the adjacency matrix right like um have they really achieved like i they call they talk about like permutation variance to the adjacency matrices where you scramble the orders and then you get a totally different like kind of looking one zero matrix with the thing does that kind of stuff work or and are you convinced these graph neural network approaches or are you mostly looking at like complex uh the pie torch big graph the way that they do the just an embedding table it's not a sequential neural network yeah for i like from from what we've seen and used right now the best results are coming from these kind of just tables like kind of complex rotate transient all of that family of embeddings where it's effectively a very very very shallow network it's like do you even consider it a neural network or is it just like a look up you know that's a what but it works really well i think in the last two years or sorry since 2020 which is two years unfortunately um is we've seen that there is research coming out that's combining graph neural network approaches um the problem is it's it's adding way more time to an already slow fairly slow process um in terms of what changes can be made can you do we always need to store the entities in in memory i i'd like to think not i don't i'm not really sure like what's being done in research right now in terms of like counteracting that i'd love if there were solutions like that work that eventually do kind of solve that a little bit better because it is it kind of makes it prohibitive to a lot of people that want to just get started you know if they have a large data set and they want to build a knowledge graph embedding you know they might need a machine with like you know 100 gigs of ram you know not everyone has that um and then in terms even in terms of just hosting those things in in production it's very expensive to provision machines of that size so yeah i don't know what the what what's ahead for like kind of these knowledge graph embedding methods whether they're going to focus on improving the actual just the the kind of the the scoring functions and kind of just improving the quality of the embeddings or if they're going to figure out a way to optimize the how they actually like do it whether it's like a mini batch approach or whatever um obviously with the with the sharded approach what is cool about you know doing the sharding is you can of course theoretically train on a graph of any size you just add an add a new shard but again you can only do that if the the size of the data set is still if it's a thousand gigabytes in memory well then it's just a thousand gigabytes started up 10 times into on like so either way right now as things stand it's you're storing everything in memory so yeah i don't i hope it would be amazing if we kind of move into an approach where you can kind of batch it to some degree but i i'm not sure if where kind of the research stands on that right now well do you like the uh like deep walk or no to vect style of uh you just walk through the neighborhood to get sort of like a self-supervised learning objective where the goal is to predict your neighbors such that you can kind of batch it up and isolate the node embeddings yeah the the notes of echo idea is is really cool you know it's very you know coming from natural language processing it it it kind of works it's very intuitive to to understand it from what i know though is no no to vec and deep walk to date haven't had kind of the same results as kind of complex and rotate and these very specific um uh k knowledge graph embedding methodologies um but yeah you know that's not to say that you couldn't use some sort of graph neural network a hybrid approach to to actually do exactly that to like to you just feed in feed in sub graphs as input and then use those sub graphs to start predicting it like adjacency and all of that kind of stuff yeah i think maybe an interesting research idea would be like because in uh transient complex you have the contrastive alignment that helps with embedding learning so maybe it with deep walk if you did uh like so what it is if people aren't familiar is it's you are in a graph and you like kind of flip a dice and uh or roll a dice and then you traverse the edges to just keep doing random walking along the graph maybe you would have the positive pairs like if you do three traversals and the negative pairs are like 8 10 you know like k and n to do the two parameters and maybe then having the contrastive learning objective would be something that deep walk is currently missing but yeah deep deep walk sounds nice because you don't have to put the whole graph into the memory and it sounds like that's something that's given you a headache yeah it doesn't sound fun well yeah that's exactly i'd i'd really love if that's the way if with deep water that's the way things could go um it would be really amazing because it would just speed up training so much because the the problem is a lot of a lot of um graph embedding models are actually done on cpu because you use the machines typically you use the entire machines ram to store all the embeddings and then even even let's say any any of the the approaches that are using gpus it's usually a hybrid mix of like well the the embeddings are in uh kind of just the machines normal ram and then we sub batch some of them into into the gpus ram but you know there's not a lot of gps out there with kind of 100 gigs plus of ram so you're going to need like an array of them so yeah if you can do this this mini batch you know like effectively just pumping in like sub graphs in as the batches into it that would be like a super super elegant approach so as i said you know i'm if i hope that research comes out in the in the next couple years will be greatly helpful to me so if there's any uh researchers thinking about working on that that would be really amazing yeah yeah so so so many interesting topics around graph learning and um so kind of transitioning into the webv8 vector search engine and before we get particularly into uh how you've used it in your experience with it i think kind of staying on this topic of the graphs we recently had two web demos of wikidata and wikipedia so how do you think about just from a high level like of the embeddings and the differences between what you would learn from wikidata and doing say pytorch big graph complex these kind of algorithms on the wiki data embeddings compared to wikipedia where you say siamese bird to contrast sentences and overall think about what what you would do with neural search for those two kinds of data sets well the wiki data in data set is a really great example to work from because it's it's it's a natural ontology it the ontology is perfectly structured to do to to build probably you know the richest knowledge graph um embeddings possible and that's you know that's what wiki data do provide you know that's how wikipedia is part of they they power their own knowledge graph using using that ontology so it's a what you described there's a really nice way of talking about the benefits of both because you know it's showing that you you use it's using your data in the right way and squeezing the most out of your data so with wikidata you you have this natural hierarchy and ontology and relatedness between topics concepts classes uh individuals so the whole modeling is done in this kind of graph like structure so you of course will when you're building your knowledge graph embeddings you'll exploit that graph structure and you'll build your your edge list based off of that and then you'll train your model to predict on these tasks and then you can do novel novel entity uh this uh kind of uh discovery via those learned embeddings so you know you might discover you know the the footballer cristiano ronaldo even though imagine in a world where he's never been related to manchester united might get linked through you know they have similar you know managers or teams that he's played for that those kind of things will appear um so yeah and then with the just the wikipedia what's amazing is you see you know just the power of document and semantic embeddings with text and again it just show it it really it kind of comes down to like what's your input what what inputs do you have at hand and then what's your expected output because you know uh in and then you just this is how we look at search it's like it's kind of they're all coalescing into one and that you know you might have a search query therefore you'd like text to work with therefore you search wikipedia for text and you'll find things that are semantically related there but if you can identify an actual concrete entity well then the richer search studio might just be to search on that entity so i think really what the two show is that they're both like the entity embeddings and these like latent embedding methods that we've developed over the last 10 10 or so years or even longer of course i they're kind of all distilling down to the same thing to the point that you know you can use entity embeddings to improve the quality of a language model and you can use language model embeddings to improve the quality of knowledge knowledge knowledge graphic so really all of these embeddings are just kind of describing like that we we've learned ways to model kind of semantic relationships for any type of input or entity and you know this is extending just beyond uh knowledge graphs and text but also to images and to sound you know any modality can be embed into a latent space and you can search off of that yeah like uh the multi-modal learning thing is so interesting but i think particularly the relationship between graphs and text is one of the most interesting ones to study right now so i mean yeah this idea sounds so great being like this is an entity-centric query let's go get the graph embedding for this one it's particularly useful for this one but have you seen do you have any like um references or anything that stood out on some example where they really do really bring this to life i've seen my favorite one is really where they traverse the knowledge graphs to create natural language sentences and just use that as training data for the language model it's it's it's a little bit of like a naive kind of data augmentation strategy but to me it's the paper the paper is titled uh turning tables and then some other description but that's the high level thing if you want to search it anyone listening but so basically you traverse the knowledge graphs to form sentences and the sentences of the training data for the language model one kind of interface for the two things but like so so what you're describing is like a late fusion technique where you have the two embeddings and then later they come together and or some kind of query model says let me see the graph embeddings for this particular one one thing i think that i've noticed going on with a couple of search or recommendation systems i use both like you know google or something like spotify i a lot of those engines tend to have if you put in let's say if you type in a particular artist into spotify or let's say an actor ben affleck into google if they can if you search and they can relate that entity with a very very high confidence to an actual like like via text so like via those two words just like ben affleck that the entity ben affleck exists exactly as it looks or like within a very very high confidence score this is that entity well then they just conduct they'll do their tech search and then they'll conduct a knowledge graph search on that entity to find all of that nice rich metadata you see over on the right-hand side and that's really the power of the two and it's the same in spotify where you know if you're typing in a musician or a song or something like that they they do mix these modalities where they'll use text that you're they'll turn your text query into an entity search in the background because you know they can relate it to being a concrete entity um and that's i think that's you know that's kind of showing that you know knowledge knowledge graph search can be realized in many ways you know all you need to do is get those embeddings and then you just need to figure out ways to you know of course you can't always guarantee that your user is going to like select the entity for you but you know they might they might do it via a query and if you can of course if you can find that entity in some way or another you should search on that because the entity embeddings tend to be very rich like we were discussing earlier on because it's this kind of closed world and they're allowed to overfit um so yeah that's kind of how i think about i've noticed like a lot of a lot of search engines typically do tend to do that these days they tend to like to mix that makes the two or in the background kind of silently resolve to an entity if one exists and the same with genres you know if you type in a genre into into into these libraries they'll find kind of the artists and the songs that revolve or exist within that within that sphere yeah super cool that that definitely makes a lot of sense and it seems like such an exciting area and i i like the spotify example a lot because of the similar to wiki day i guess similar to the scientific papers too but it really helps you visualize this concept of kind of like entity centric searching so so now can you describe you have your graph embeddings and can you describe your experience with using the wva vector search engine to search through the graph embeddings and i really like one of my favorite things about your article describing this is how you describe how the api lets you rotate in plug and play the different components like you can swap out your embedding model swap out your a n index and that's also something that i think is awesome about wv8 yeah so you know we've been once we earlier like it's pretty much since we've had these embeddings uh trained and you know ready to deploy we were like okay what's the next step well it's just not going to be possible to do a brute force search of like 60 million plus embeddings in under two seconds or under a second whatever we need so of course it was going to be um a n but you know there there was a lot of options there's a lot of options out there to choose from but what really just you know we really stood stood out for us with just because of like you know a couple of it's not because of one thing but because a couple of really key features and i think what all these key features kind of allude to is that you know the weave the whole design of a vb8 search engine is is designed for business problems like ours like they're not just trying to theoretically do vector search like straight vector search they understand that vector search is never just you know a flat vector search there's often going to be cases where uh post filtering is gonna or pre-filtering might be needed and that use case is just the the api is just so well designed to those use cases that it became really attractive so you know um and then we also needed we needed this thing to be scalable like kind of horizontally we knew i we had experienced using h and sw but you know there whether we could fit this all in one machine would be was kind of up in the air and then you know by the right now as i speak from as of today you know wb8 is horizontally distributed back then it was just about maybe it was on the roadmap but you know from what we had seen from the team and stuff like that they were just moving so fast we had so much confidence that they were going to get there when by the time we would be going live with them that's kind of exactly what happened which was amazing but yeah we v8 is really it's exactly what vector search needs which is a really really practical useful user api where um this the core parts of the system are are really set in stone but they have they take this modular approach specifically with the uh a n indexes and i think what's really useful about that is you know if we think of keyword search and a lot of keyword search engines that are out there some of them are kind of stuck in the mud in terms of using like older older algorithms just because uh 20 15 years ago the initial code base was designed and it wasn't designed maybe in a super modular way so switching out these ranking algorithms or whatever it is was difficult whereas wev8 is really interesting because vector vector search is again and probably still only in its infancy you know what the the a n indices that we use today probably in five years will be well completely outdated and that built that that knowledge is built into the the architecture of we v8 so that like gives you so much confidence that like if when the new latest and greatest um a n index comes out or a n strategy comes out we don't need to we're not going to have to like rebuild everything or rethink our entire architecture we're just going to like plug and play and that's like that having that confidence in the the search engine you use is like incredible like it's it's so so useful to have that and to have that you know as a as a company that's trying to scale just to to to know that we're not gonna have to like spend like hundreds of hours of engineering time again solving this problem that you know when the feature is ready we'll just it might be like a couple of lines or a config yaml change just to point to this new and rebuild on this new index so that's like you know that's that was such a win in of itself and then it is we're pointing out that you know with the the filtering system the scalar filtering system that's done on the index is very very elegant because it's it's not a post search filter it's a pre-search filter and how they that's that was what we really wanted because we had looked at you know we could have developed our own in-house system that did post search filtering but that's not really what we wanted we wanted pre-search where they would have an allow list and a set list of entities that would be allowed to be in the search and then rank according and retrieve according to that way because your much higher chance of getting back if we ask for a thousand a thousand vectors or a thousand objects we have a much higher chance of getting back a thousand with the pre-filter rather than the post so that was very important because you know if you're building a search engine you kind of want to guarantee that you're going to give at least a page of results to a user um so that was really that was really really amazing to see that and then you know there's you know while we're using rev8 primarily right now for uh the knowledge graph embeddings that we've been testing out some really fun um kind of future future projects with it in the text in the tech space and you know they've it's really helped us re we we had this kind of crazy idea almost just a couple of weeks ago and we're like okay let's see if we can spec this out really fast and we know with just a single weekend hack for me i was able to kind of put it together and i kind of show an early proof of concept just using wev8 and it's because of the the module system in terms of uh you know text to transformers you know that that entire pipeline just saves so much boilerplate code and so much like thinking that you'd have to do as a machine or an engineer just to to get a project up and running and you can really kind of move fast and because because of that modular system it kind of has two advantages one is that you can you can build a module once and then it just you don't have to worry about like where the inference is coming from and you can interact with the api very humanly you can just feed it in text you don't need to do this transformation step of turning that text into a vector yourself because vb8 handles that and it's incredible but also you know just from an open source point of view the fact that these modules can be can actually work just be contributed as an open source contribution you know there's a lot of open source projects out there that are open source in terms of the project is open source but there's a team working on it the vba team are open source and like i have to say they welcome the community with open arms in a very very true open open source fashion and that's very attractive for me um to kind of when i'm deciding on these things and and also to contribute to you know it's it's been fun to contribute where i can to ev8 because it's a very welcoming community you know bob and etienne and everyone there are very very welcoming yeah and to stay on the ver yeah it really reminds me of hugging face how well you can switch out the components and i think just yesterday deepmind had released two papers where one of them is a 280 billion parameter language model and that probably got most of the attention because of you know 280 billion parameter model but the other paper they they published was about information retrieval plus supervised learning and so we've eight is in my view the the perfect platform for testing these ideas of combining information retrieval and then supervised learning so you retrieve documents and then you append on your question answering system and this modularity if you want to swipe out the embedding model for the information retrieval you just point to a different hugging face model path if you want to swipe out the a n index same idea just drag and drop h sw something else and then if you want to replace the downstream question answering thing same idea just to point to another set uh it's you know it's it's simple when you think about it but the way they've implemented it you know it they've made it seem simple but it they've really done like you know some really great work to get it to that point and you you can tell how much kind of thought has been put into the architecture and then how passionate they all are in in what they're working with and it is a very good community to be a part of and there's not all open source communities i like that and it it takes a lot of work to build that kind of community and i i i really really appreciate it and it's very fun to engage with them then and to you know like there have literally been releases that solve my problem like my specific problem there was a release that fixed that and like that's just incredible to to to feel that you know i presented a uh with some sort of problem and then my work alongside ethiopian and it gets solved via release you know that that's very special to to be able to have that kind of help um when when you're building with these tools um and you know it's just as you were saying that in terms of yeah you can switch it out you know the vector search is here to stay in it it's it's only going to become uh bigger so we're going to need some really good vector search solutions and from what i've seen so far like vv8 is by far kind of the most feature-rich that that there is and the the the easiest to interact with and that's down from like you know the api design would be a graphql down to its optimization in its back-end you know it's it's written in go which is which i think is a hugely under-appreciated language in terms of machine learning yeah the applications in machine learning i've thought could be really really useful not maybe not in terms of explicit like modeling or training but in terms of infrastructure and terms like you know vector search like they're doing i think they really understand what the strengths and weaknesses or something like go around that point in in that world and yeah they've they've really done a great job with it yeah if we could stay on the like like go and rust and these kind of things is something that i can't help at all because i don't know too much about but if we get just like i just want to get a little more into the vector solutions and kind of the conceptual idea of uh like the h and sw algorithm and if you wouldn't mind if i could kind of like explain my understanding of hsw from scratch and you could explain to me how the pre-filtering thing works so from the high level overview with these a n index algorithms we have continuous vector embeddings for everything in our data set and we want to try to do say the brute force solution is to do the dot product comparison with every single vector and obviously we want to avoid doing that so we say a naive algorithm would be to do a k-means clustering where you have a centroid that represents that routes you to like you're most similar to this centroid so go look through this uh you know the cluster vectors that produce that centroid in the k-means algorithm so the way that i understand h and sw is that you build up these centroids and then you connect the centroids in a graph such that you can use the small world network effect to say that i'm likely six hops away from the centroid i need to get to so is so that's kind of as far as i understand h sw how does the symbolic filtering work with that yeah and so i think with in terms of the h and sw then what you have is on top of the on top of the navigable navigable small world graph it's like it layers it like an onion so it's like you you can kind of it gets it kind of saves you time and kind of com compute by each level as you traverse down is like the top levels are pretty sparse so because they're virus they can kind of find pretty quickly what the the the shortest distances to your to your query are and then every every s that like downward layer starts to is more populated so you can kind of pick a pick a few candidates from each layer of the onions so to speak and kind of find which one find which vectors are closest to it and then kind of decide pick on the two best routes down down that avenue of uh layers and which roots are going to be uh are scoring highest and then just pick the name the neighbors attached below that in each part of the graph that's on a high level but in terms of how i how i think the from what i've seen in the code and how the pre-filtering is done is imagine uh in terms of post filtering you were to do a query and you wanted it to be um if it's papers published let's say academic papers you wanted papers published from the year 2018 onwards well in a post filtering world what would happen is you do your do your search get back here the top 1000 results and then you post filter you'd actually retrieve the data objects and you'd retrieve the data objects and then you'd filter that set of a thousand to be um you'd filter that set of a thousand and then you might be left with like 200 papers um left and then unfortunately what's happened is you've asked for a thousand papers and you've got 200 because you've applied your filter post fact with the pre-filtering what the way i think they've done it is you have your query and it what it does is it you execute your filter first in terms of okay this has to have an allow like this has to be from the year uh 2018 onwards so that creates what's called like an allow list right it retrieves like a list of ids that meet that criteria so now as you start to traverse the traverse the graph what you do is you pick your you pick your nodes along that in the in the h and sw graph from all the layers down and as you hit a node your first test doesn't meet the criteria and if it meets the criteria great you can look at the node and all its neighboring nodes but if not you have to you can you pretty much add that node to like a skip list and you skip it and you keep trying to fill up the result set until you have a thousand so the idea is that you're you're skipping ones that don't meet that like allow list and you're you're finding the next nearest ones after that because you haven't asked for a filter so the filter might get rid of some really relevant papers or results but you you do have an explicit scalar filter so that's okay you so you just you fill up that result set with the next 1000 results that would like that would have been um kind of right after that according to that filter so that's why it's you know it's it's very powerful to be able to do that and as i said earlier especially when you're designing like kind of a search engine solution like us where you're trying to give as many results as possible and trying to keep that result space um interesting having that pre-filtering super powerful thank you so much for that yeah i i got definitely a better sense of it now i think that made it very clear i don't know if that's like a perfect description of it but from what i've chatted with etienne about it that's like the general gist but of course if there's if they if they listen to this and they have any any extra thoughts please feel free to free to contribute yeah yeah eddie has been explaining it to me and i will probably even ask him again i just trying to get it you know i gotta keep hearing it to finally have it uh i don't know how he stores it all in his head he is very uh he's very very uh well read on hmsw and everything actually yeah yeah they're such a great team and so so to step a little away from wev8 and get back into scientific literature mining and kind of could you kind of tell me like um you know i also really like scientific literature mining i think of what i do with henry ai labs of doing paper reviews as being like a form of manual scientific literature mining and as i think about it i try to think how could i automate these tasks i'm doing how could i turn this into something that would be like an automated system how do you like what's motivated you to work on scientific literature mining in that big picture kind of thinking yeah i i suppose the motivation that i always kind of try and really prioritize for myself is that it's as an undergrad it was really hard it was really hard to get started and and i that's something we always try to emphasize our keynes kenius works for users like we we try and design our product to be like here it's your first semester of university to be your your final year of your phd um but you know for people early on in their academic careers it can be really really hard to conceptualize like a space and like a a like a topic or whatever it is you're working on it it can be really hard to understand what that even encapsulates so for us what's really really exciting when we think about academic search and research mining is figuring out a way just to to mine research and to to make it really intuitive to discover discover new things and you know earlier on i brought up the kind of the wikipedia example where you know we've all been on wikipedia where you go into like a black hole of discovering information about topics and you can learn really fast and you can kind of dig down into different levels of granularity and that's what we try that's what you know that's our north star in terms of emulating that it's making like academia and topics and concepts in academia kind of fun to explore um and making that some making it so that we can enable someone in their first semester to get value out of uh out of academic publications because you know that it can it can be very intimidating academic publications can be really intimidating and it can be hard to look at a paper and to start working on it or start reading it or to to know even if it's relevant so we feel that the sooner we can get people comfortable with discovering papers and researching them and finding kind of the topics that they're about the better you know it's it's it's good for researchers everywhere if everyone learns to kind of research a little bit better or understand what like what their own interests what their field of research revolves around you know so that's how that's kind of how we think of think of it do you think genius itself could become a scientist like it could have a text generation connect to your system and it itself would be a scientist yeah we've we've we've done some we've had some fun with just uh text generation models just like internally just to play with and just to look at even just to the point of like abstract generation um it is quite cool um i'm not sure if it's like if genius is ready just yet to like do it itself but it can write some kind of like semantically convincing abstracts if and and paper titles um but and you know there there is a serious use case from that and that you could actually have a block of text and you could suggest like a title or you could suggest um something like that off of off of a document so in that case is that considered writing science absolutely i would say so you know titles are really important to finding papers but yeah i i think like probably it's most efficient use cases like just being a really good aide right now to to to researchers of all kinds like all levels and i saw one paper that was uh that really stood out to me and further developed my interest in this is titled can we automate scientific reviewing and similar to what you just said they do the same thing of this abstract was written by you know our text generation models so so yeah i think especially things like um survey papers literature reviews it does seem like something like genius or these models and implemented in kenya's are you know maybe like five to ten years away from being able to do a survey paper literature review completely automated so then so an idea that i've been working on is um and i published a paper called keras burt which is where you train a language model on keras similar to the codex idea where you're trying to you know write code with text generation models so trying to see if you can plug the language model into cara like interface it with keras to write deep learning code and run deep learning experiments where our data sets and all the ideas are completely digital anyways like if you have to say do uh by like a biology experiment where you have to have like a real physical say like maybe robot interacting with the world i see that as being a slower interface with this but as you do deep learning research like the kenius ai scientist can write experiment code and deep learning get the results and then learn how to interpret the results and write papers and like be a scientist is that where you think this is headed because that's that's where i think this is i i think you're right i don't think it's outside of the bounds of possibility that that's like where we're going and i i you said it earlier with the systematic review that's like that that to me would be a really good kind of first attempt at like first attempt at trying to see how good it is at that task because you want to kind of ease it into it right you don't want to like take on something too ambitious and you don't want it to publish something that's just absolute junk or just like completely off the bat but this is something like a review a literature review that's like that's manageable and like you know it's it's it it feels like a task where it would be harder to mess that up once it once it gets to that stage and um yeah you know language generation stuff is getting really insane just with what it's getting i i saw that publication you were talking about yesterday i think the model is called gopher from deep mind and like the output it was like the way it was like the the in how informal it was in the conversation was just insane um and so i think i'd be it'd be foolish to to say that in the next 10 years we're not going to get somewhere close to that point especially in terms of like a review literature review i think that's kind of inevitable almost with with ai text generation so yeah so in addition to the literature reviews where yeah it's like it's like the product is the survey paper the introduction to the topic for for someone um so as someone with experience building a software product and bringing this to like a real world sas kind of thing what do you think would go into say you know reviewing your paper you you query like the gbt3 api say or whatever whatever the model is called and then you're kind of building a sas product around automated scientific reviewing like from your perspective what like and i think you have a different way of thinking about this because you have an actual software product and not just it's not just like research ideas so what do you think about that kind of product idea and what what it would take to bring that to life that's interesting because i think academics are like people are where of course people are uh creating these models and that that they're you know the the advances have been really good in terms of natural language generation but academics are also huge skeptics in terms of like accepting accepting what the output so this is a trick and we've discovered this you know we deal with academics a lot so you know you really have to prove a product's worth in order to get it there so i don't know like i think you'd have to you'd have to show that the product is like cost saving or time saving in a really really um in a way that's like kind of been unseen so whether it's like in terms of like reading giving summaries of papers and reading them and giving like um not like generated generated summaries because we've we've experimented with extractive summarization but abstract of summarization is quite difficult and when we've experimented with that it's been pretty bad um so i think if i if i saw in the next couple years that abstractive summarization from like large language models was getting really good that would be a killer use case because in that case what you're talking about is you might actually be saving a researcher like hours in terms of like having to dig through a papers um a 30 page paper and being able to like find its key points and letting it letting a researcher like giving it a kind of deep not just like an abs like not like just the abstract but giving it like key points from inside the paper about maybe like what algorithms are being used or that stuff that they could like ident effectively helping them identify what parts of a paper are relevant to their own research area that to me would be really really amazing and then you you really need to figure out a metric for ranking the quality of those abstractions and that to me that that's a lot of the time what we um always circle back to is how do you rank it's the relevancy like how do you how do we judge a good search result and how do you in this situation how would you judge a good kind of abstractive summary um of like 20 papers you know so you'd and you just you do that based off of um when you're developing a product you can do that based off of like input signals like uh whether it's a like button or that they they cited it or whatever so you just you you learn from these signals what's working is that does that answer your question a bit yeah yeah and um i think i'm one of the biggest fans of the research from uh the allen institute with uh like what lucy wang and um sorry and kyle lowe published two of two researchers that i follow closely like from on twitter and seeing all the things they do with the allen institute and semantics scholar is they've done such a good job of breaking down all these tasks like you mentioned like um like classifying what they call site tenses like citation sentences so you classify it of the intent so so yeah it's like again there's there's like abstractive summary pretty ambitious first step it might be better to first just like have models that classify like was this experiment set up correctly uh do they properly [Music] you know communicate the background so yeah i definitely it definitely won't be just right to the reviews and there'll be all sorts of subtests that's an interesting way of thinking about it because i think uh in terms of just actual like structure structural looking for structural appropriateness of a product of a project because there's there's been some really cool output just in terms of language models that you know they look at like document structure um rather than like the text itself and i think that's a that's a really nice point in terms of um you know you could even just identifying that a cert like a certain paper doesn't fit like the criteria of a certain structure like oh you can kind of make an inference that maybe it's not of high quality if you know they haven't introduced uh the the domain problem correctly or you know that the the citations aren't properly done or that it doesn't even have a conclusion you know just being able to detect stuff there's a lot of you know the there's a lot of really good publications out there but there's it's a lot easier to publish nowadays without any peer review and then the quality of those papers can be um fairly variable so being able to assess like high quality papers through algorithms like that and kind of large language ones that would be very very powerful like being able to kind of put a certificate just being able to tag a paper being like of kind of a certain structural quality yes so interesting and um yeah like so we're talking about like um scientific literature mining review platforms like google scholar is i think the famous one that everyone uses to build up their master's thesis and you know semantic scholar as i talk about the allen institute i think in my opinion they've impressed me the most with the research output and almost really leading the topic i'd say but um so what do you think about papers with code are you familiar with that and how they organize it how do you contrast that with genius and think about like generally your stance on what they're building yeah papers where code is really you know we i've i look at them a lot in terms of like presentation of the information they are you know a lot of what we do is um it just goes down to that ux end of things where you actually just try and find a really nice clean way of presenting the information and you try and you try not to overload the the user too much and i think sometimes when we're dealing with these like kind of high concept ai products that element gets overlooked and i think it's really crucial you know that's that's probably the part that we think about and change up the most which is like how good is this ux so the papers were code is really really good for that um and i i've always enjoyed going i always whenever i go on to papers report i've always enjoyed just just the interface and like navigation across the site is really really good um i suppose with us because we we actually extend beyond just scientific literature like we we actually can we can do like science and sorry like literature the arts the humanities history business so for us you know we kind of we have to keep on with some more of a generic like way of presenting our papers and and our publications because it can cover any field so papers of code kind of has the benefit of you know it's papers with code so it it these these things have a kind of you have a paper and you have a data set and then your code presentation typically so we have to abstract that down a little bit more just to kind of a paper structure that being said our data set does actually include links to code to code so it would absolutely be something we could look into in the future when with a bit more um time and manpower you know where a small team at right now um but yeah what just to go back to it papers something like papers or code they are a shiny example of good design and like how good design when search like go hand in hand like search search engine search recommendation systems like it's like a 50 50 split between the quality of the recommendations and search results and the the interface for interacting with those results and that that relationship is super important yeah yeah super and i i love the um the text editor build in i think that is huge i read a paper from some google ai researchers called wordcraft and it documents how they're using like a chat bot to help people write things and i think that integration of the text editor is is a really cool thing that's in kenya that i haven't seen anything else that uh does it that well and i and i love the plug-in with google docs i think that's a really nice uh transition for people so anyway so we've covered so many topics and thank you so much charles i you know i think this was definitely one of the most informative podcasts and you know it was it was a lot of fun to do this so thank you so much thank you very much this was a hell of a lot of fun i really really enjoyed it and thank you very much for for having me on i really appreciate it ", "type": "Video", "name": "weaviate_podcast_2_how_keenious_uses_weaviate_to_enable_semantic_search_through_60m_academic_pubs", "path": "", "link": "https://www.youtube.com/watch?v=hU7GJEidaUE", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}