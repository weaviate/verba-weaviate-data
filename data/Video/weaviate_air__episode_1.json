{"text": " \nforeign [Music] [Music] podcast where we are it's me Sebastian we are a good Etienne Connor and Erica from uv8 we all like hailing from our homes or offices wherever we are and by the way this podcast is 100 live so I would encourage you to say hi on on YouTube uh questions or on on the chat if you have questions fire them up and we'll try to answer them as we go and we are super excited to meet you all um so we have like a packet packed agenda we want to talk about many different topics what's new in the research we want to show you some demo project talk about our roadmap and there's so many cool things that we would like to share and again like I mentioned ask questions as we go and if you have any feedback or ideas in the future or you feel like maybe you should feature in one of the sessions give us a shout and we can for sure get that arranged so the first thing I want to do is talk about our roadmap and so many of you probably didn't know but we published that recently on our vv8 website and I'm going to share our screen and basically this is where we talk we highlight like some of the features that we'll be working on for version 116 for 117 we have some uh also ideas in the backlog and actually it's pretty cool because you can go and up vote for those items um and so you could definitely a stay very informed by what checking out that page but but also you could contribute into uh into how we prioritize each of those items so in case you don't know how to find it just go to uh developers into our documentation and then on the navigation it's just under roadmap and then we could just the future world map so I'm going to take this opportunity that we have at the end our CTO to actually walk over some of the items that we have in the roadmap and um at the end can you tell us what all those items are yeah sure absolutely hi everyone so yeah as Sebastian just said with the roadmap we really want to be a bit more transparent so you may have seen that we've we've been publishing these blog posts whenever we have a release but of course until we get to the point to to have such release ready a lot of planning goes into it and part of that planning is basically prioritizing what features do we want and this is a matter of who uh had some ideas from the community what does the community really need uh what the semi as a business need what do we need for for offering our vvn cloud service offering so it's balancing all these these needs and we want to be a bit more more open about it a bit more transparent about and that is exactly what that roadmap is for so on the roadmap we're trying to to look at the next two or so releases and that that of course that's always super Dynamic so you can see uh current release is 1.15.2 and then uh the next sort of the next minor releases are the ones that we really care about like of course there may be patch releases in between because we fixed something but the minor releases is what we what we really plan for and 1.16 is next you can see an ETA here so it's put on on week 44 which I think is the the first week of November so it's about four weeks from from now which I can actually say because this is live so um and then we also have 1.17 which would be the one after that which would be to towards the end of the year and then as it goes with road maps so so um the further you move in time serve the more the less uh likely it is to stay the way or the more likely it is that something might change and then of course we also have the backlog which are basically uh feature requests or ideas that either we agreed that we want to tackle them but we have not prioritized them yet so you can you could upload for them or it could be um that maybe something is currently in research that we're looking at something and and um yeah we we say like okay this is something that we want to do but we don't want to do it right now because we want to find out how do you as users use it how do we build it from a technical perspective how do we make sure that it has a super great ux because you know BBA is all about the user experience so we want to get that right which could sometimes mean that we put something a bit later on the roadmap um to to make sure that we get it right so that's uh for the roadmap itself but let's also talk about the contents so as I just said four weeks from now is when we're going to have 1.16 out that's of course an estimated time of arrival so could change a bit but I think we're on a good uh schedule for for this one so let me dive into the contents um this one proposal so so this you see here we we have the GitHub issues linked so you could actually open them up like if I open them up I'm not sure I think that would uh not showing the screen sharing here um but doesn't matter like if you if you click on one of those you see the GitHub issues behind them so this one's labeled as a proposal and this one is something that uh was so it was introduced before we had this upload feature um but we know from talking to all of you that this is one of the most requested features that you uh out there have which is dealing with null values in VBA so this means searching for fields that are not set or doing some kind of filters where you uh um assert that a certain field is set or is not set and then do kind of kind of specific behavior with it this also goes for improving the ux around null value so in previous releases there was a difference in setting an explicit or setting a field explicitly to a null as opposed to not setting it sort of tying this all up and really making making uh null values or unset values not just an edge case but an actual sort of feature case that we think about and dealing with it and there will be a new operator to to um yeah search for for whether a field is set or not and we got a ton of input from all of you out there and that's super great please please keep doing that and if you want um you can of course still uh give us feedback but we really love these like uh early feedback Cycles even before something is built involving all of you not just for what you care about but also for for basically yeah how do we have to build it to give you the best possible ux for that feature next one is another one that's that's super popular in the community which is the idea of cross-referencing centroids so this is a module and if you know vba's module system and we have different types of modules you can actually see that in the in the navigation um or you could if I I um if I uh expand it we have retrievers and vectorizers readers and generates Etc and this is basically a vectorizer module so the idea is that you already know the text to VEC modules and in those you would have text input and uh the module at input time or at update time would basically take the object put it into the model and you get a vector out and then that Vector would be created at at or would be indexed while you import this object with Crest cross reference centroids I think that the module is called reftubec you can do that automatically but not based on the contents of the actual object but based on the length of that outgoing or the outgoing links off that object so for example if you have a let's say two classes a class book and a class chapters and then your chapters class would have individual vectors for each chapters then you could just summarize basically the book by yeah summarize all the chapters in a book class by having a object of type book with outgoing references to to those chapters or another use case would be for example a shopping cart where you have items in your shopping cart and then by creating those references and sort of inheriting in a sense uh the the mean Vector of these individual objects in your card you could now index dropping cards so you could do stuff like similarity search for related for related or for similar shopping carts which is super cool for e-commerce use cases for example so lots of great new opportunities there and of course it fits very well into vba's module system into the existing API so that's that's really cool then making I I want to interrupt just for a second so yeah on the cross reference centroids by the way um this is actually a research that corner is working on so if this is a topic that you find interesting and exciting first of all go and upvoted on on GitHub just uh just like at the end was showing you that you can find the links there but yeah of pingers on on a public slug or pink corner and then let's start a conversation especially if you have opinions ideas or uh yeah Connor is very knowledgeable about it and we're still thinking of all sort of interesting ideas on how to do the centroids um so for sure um let us know but yeah at the end you can continue thank you um yeah exactly and then if you have questions we have Connor here and look at that call as well so that's a great opportunity just put them in the chat and then um Conor can can respond a next one is a completely different direction so you can see with every release we're really trying to balance um the needs of the different stakeholders for vb8 release which means there's something feature driven there's something more operations driven this is on the operation side so the node's endpoint is a simple API to uh tell you the status of the nodes in a cluster so these are the notes like if you deployed on on kubernetes for example the nodes or the pods um if you do it agnostic of something like kubernetes it's just the individual deviate notes so basically Management in that cluster and this is a prerequisite for what we're going to do in 1.17 which is going to be super cool as well but also just to get some insights into like is your cluster healthy but then in the future also to to adapt it so right now it's a read-only API but in the future you could use this to to make changes for example let's say you want to take down a note for Nim for maintenance so you could drain the node off workloads and these kind of things so that's that's more an operations uh driven side um yeah which we which we want to introduce in 1.16 as well then the next one is multi-note support for backup so in 1.15 the previous release um we wrote a a long a blog post about it we introduced backups which I believe is still one of the coolest features that we've ever built just because it's it's so ux focused and it's so flexible and you can use backups to uh store a restore backup to and restore from different Cloud providers you could use that to to use a production instance take a snapshot of that production instance and and maybe run it on your local machine so it's super super flexible feature and there was one limitation that we did to to release this a bit sooner and that was in 1.15 that it was limited to a single note viviate instance and that limitation is going to be lifted with 1.16 it will work on a multi-node cluster and this is not just great for for all of you who can use it in a cluster node but this is also super cool for for us basically because it's a building block for what we're going to do in 1.17 so all this kind of multi-node coordination that we're building here you're going to hear that again because we're doing lots and lots more multi-note and cluster stuff in 1.17. then we have another one so this is um also I love these kind of issues because if you see them so so this is I could guess you could either see this as a as a as a buck or as an extension but I love seeing those come in because those two me are signals that people are using and really using vb8 and production in there sometimes running into some sort of limitation where maybe we sent we didn't have something in scope yet and um for this one the the example here is that if you try to use bb8's oidc so oadc is open ID connect so basically a standard protocol for authentication and that works with some oidc providers at the moment but it doesn't work with some others because while everything is compatible with the spec some features just weren't supported yet and we got some feedback that um yeah if you want to do I think it's I think it's Azure ad but I'm not 100 sure like one of those providers we're missing some features and this is about adding those missing features to really support all these providers and yeah make deviate more usable in production for for more users which I always like both that we're doing it but also that that users are requesting this and then we have another one which is so this is a another really interesting one this one was actually driven by our webe account service team um but it's it's something that everyone is going to benefit from so um if you run out of memory on your vv8 machine basically at some points in in previous versions it which is Crash and that's not their greatest ux so we have a read-only feature already that's kind of Dynamics Dynamic so for example if you run out of disk space you can have a configurable threshold to mark your your shards the charts or the components of your index to mark them as read-only and and now we're going to have that same thing as well for running out of memory so basically what a memory threshold is crossed that is as I said motivated from by our BBA cloud service team who is asking for for something like that to make sure that that um yeah the ux is great when when something like this happens so basically if it's read only we can handle it if it's crashing then it's much harder to handle but this is of course something being aware the the needs from our VBA cloud service application really drives the product forward and that everyone benefits from also when you're self-hosting this so I really like how yeah the community needs and the the sort of business needs from from somebody else the company behind vv8 are um pretty much aligned yeah that that's it for 1.16 if you have any questions or feedback super curious to hear them we also have 1.17 on this list but I'm not going to go in detail through this um I think we can for example we could tackle this in a future one but lots of exciting stuff there as well so at the end I've got a question for you so from the list that you just went over uh what is your uh favorite feature that you're looking forward to implementing oh that's a that's a tough question uh let me let me think about this so I think for me oh this is this is really difficult because multiple of them have have good reason for why they would be my favorite can I can I get away with two sure just yeah okay okay then then for two I'm gonna go for the null values for the reason that the the way that we got there was so Community Driven like it was if you open up this this issue which I can't right now because I I shared only a single tap and if I open it it opens in it or it doesn't yeah it opens in a new tab for whatever reason uh so I can can share it um but all of this is community feedback so this is I really just love the the process I think some users have been waiting for this for for a while but at the same time that gave us the time to really go back and forth and get this early feedback end and we can be sure that when we release this feature that it's exactly what users have been asking for which I I love it and and also implementation wise it's super cool that that yeah it's not too difficult to do with our inverted index that we already have so we have good building blocks for that and then the the other one uh for me is going to be the multi-node cluster backup support which I think from a feature perspective is very very minimal it's just like okay it was a limitation and what not 15 you just had single node now you can do multi-node but the kind of coordination that we do with multi-nodes in the background that is a building block for replication and now I'm spoiled it basically what we're going to do in 1.17 but one not 17 is going to be all about like Dynamic cluster scaling and and um and replication and having the building block in for that that is just that's a a big win for me right now excellent excellent thank you for the review and um yeah this is pretty pretty exciting and I encourage everybody to uh review the page and if you feel like you like any of those features upvote it and then let's see all those thumbs up going up uh and then because that definitely helps us to put more effort in specific like you know more popular features uh not to say that we we will not take care of the other ones but uh that's kind of like up you know thumbs up always helps our engineering team yeah especially for the features that are in um in in the backlog basically they're not prioritized yet because then we know like this is something that you want that's a very good point right because once it's in 116 we kind of work on it already right yeah yeah yeah like push things forward a bit more yeah yeah like we're probably not going to remove something from the list for 1.16 simply because it's it's just four weeks out we we could still add something that that's something that could always happen but basically the further we go in the future the more Dynamic it is and the more uh we can still change it perfect uh thank you at the end so and and I have to say like I can guess quite easily what's Conor's favorite feature on the list because that's definitely the cross-reference centroid uh we all want to see it in there so um let's move to the next part of the session uh so in this part uh it's uh I'm going to pass it on to Connor who will give you an overview of like cool research that's been happening uh in AI uh so let me just share Connor's screen because he prepared a small presentation around that um and yeah and as as he goes through like uh different items like uh please uh comment out uh give us a shout if you actually like any of those researchers or if you think like we should include that in movie eight like that would be quite interesting to see too um but yeah Conor uh what did you prepare for us awesome well first of all it's really cool to follow Eddie and with this I think it's so interesting seeing kind of the muscle behind the cloud service and the oidc authentication all these things that make it the search database and then kind of coming in this intermediate between say the ref to VEC and the muscle again of Parker Duckworth our engineer who built this together and then kind of then the research side so I think you can hopefully see the flow of how all these things come together and I think it's really interesting so as a part of my section I'm going to be kind of covering some new things that I saw in AI this month that I think are just extremely interesting and are things that maybe we can see how to integrate with weedgate and develop as features that are kind of adjacent things that fuel the models and fuel the pipelines and these kind of things so it's definitely sort of biased towards search with this selection of of what I think is interesting that came out this month and then um I say like kind of it's it's my opinion sort of it's not like everyone's Collective opinion if I say something that's kind of opinionated about some of these things so start off with kind of just a quick topic overview I tried as best as I could to make this kind of sequentially organized a little bit but really it's a it kind of the first general thing is about training retrieval models how do we get these models that produce embeddings of data and what are the new advances in that then we have some new advances in learning to search and then this Chain of Thought prompting thing continues to evolve and this self-ask thing is just a massive step through with this and the way that we use these language models and the way that we tie these language models with search engines so I'd say if I had a central topic for this it's thinking heavily about what is the relationship between large language models and the vector the weba vector search engine and sort of language models and search and how they play together so then we'll kind of look at one paper that um you know maybe the title generate rather than retrieve isn't a title that we would love with our current design so I'd like to kind of you know still entertain these arguments and say what they're saying is the drawback to the Gen to the current retrieve and read Pipeline and how they generate then then read pipeline work and so sort of my counter Arguments for this as well I think I want to talk a little more about retrieval augmented language models so Facebook AI I think other institutions as well they have this Atlas model where it's this 11 billion parameter retrieved and read that also achieves this few shot learning and I listened to Patrick Lewis uh talk at the Boston NLP Meetup about this about how you can decouple Knowledge from reasoning essentially with this kind of Paradigm and this is also they have a new re image and model Imogen is the uh the Google diffusion text image model and so they have a retrieval augmented diffusion model as well that I'd like to talk about with this General class of retrieval augmented language models so very heavy in the theme of language models and search what is the relationship what do they each offer how do they complement each other and play together so then I mean this other paper is just wild two exclamation marks this set fit contrastive learning can achieve few shot learning as well this way of fine-tuning sentence Transformers and then putting a classification head on top of it the I just was like I can't believe this can achieve that as well and then I'd like to just quickly uh touch on some exciting emerging applications um like Facebook has a make a video and then there's a new um uh edit eval which is about sort of creating data sets around editing text not just generating text and I think this is incredibly interesting as well and then we have just an absolutely incredible interview study of ml Ops practices this is just like the sort of like the ml Ops book it's a paper but it's like the ml Ops book that you've always wished you had with describing like best practices and organizing these experiments and deploying these models and just all sorts of incredible like nuggets to take away with if you like that kind of thinking so to kick it off let's talk about promptigator so promptigator is super interesting different retrieval tasks have very different search intents in other words different definitions of relevance so the title is few shot dense retrieval from eight examples but the idea being that we need to generate data to train our retrieval models depending on what kind of application you have there are many different distributions of search queries and intents with your search so if you look on the far left you see with Ms Marco you say you have questions like surgeon salary per year but Ms Marco is just like thing you would things you would hit the Bing search engine with compared to Fever where you have claims like music artists is a profession of Christina Aguilera's or like entity surge or counter argument retrieval so hopefully just from looking at these different kind of queries you can see that they require different kinds of query embedding models will work better if they're more tailored to a particular kind of query distribution so what they're doing is they have they're using large language models to generate training data for retrieval models for particular kind of search tasks or search retrieval needs so what you do is you have this few shot prompt where you say give eight examples again of what a document query pair would look like for this particular task and then you just swipe in your whole you just rotate in your whole data set filling in that D and it will generate queries for each of the documents depending on your task so as an example this arguana's data set is different from natural questions Ms Marco you're particularly looking for counter arguments in the search task so you know you make some claim like language models only achieve good performance at 10 billion parameters and then you want to go hit the scientific literature and find counter arguments to that it's a different kind of search task than question answering in these other models so few shop propagator is able to successfully adapt to this task with a few examples by generating training data like this and then you use this training data to train the text retrieval models so pretty much the idea is you use the large language model to generate a training data set to distill into say the 22 million parameter retrieval model and I think this makes a lot of sense as a is like an interesting way for how we use language models in Search and particularly the you know the search Vector search setup that we're envisioning so here's some results of the propagator and you can also train a cross encoder this way so when you retrieve you can say retrieve a thousand examples and then re-rank them with a cross encoder and svidlon has done this incredible illustration of a comic book with a fisherman and this example where with the retrieval you cast the big fishing net and then you get some fish onto the boat and then the fishermen have to look through each of the fish and that's the idea of having a cross encoder that does those pairwise but you can also train it by bootstrapping the data for that in the same way and it's also interesting to see this evaluated on the um beir Benchmark of diverse domains and diverse information retrieval tests so the next topic I thought was interesting it wasn't a whole paper but uh this query to query model where it's saying two queries are equivalent if the user is searching with those queries are looking for the same set of results and that's kind of the that's the core motivation for how we're going to bootstrap this training function to further improve these query embedding models so it starts off with some motivation about different aspects of querying where uh where you you have the same query and you're looking for the same thing even though it's a difficult sort of natural language understanding task you might say uh The Rock Dwayne Johnson if you're say looking for movies and you're referring to the same person and all these other examples of how these queries can differ each other but have the same information needs so what they do is they use a query log and so I imagine that as we think about things we build into weviate is you would have some kind of search log with the clicks and you would see what queries resulted in the same uh in the same click so it's different queries result in the same clicks and you use that to bootstrap this positive labeling as we have this contrastive learning framework which is how we're producing these things we're thinking the same results those are positives versus negatives so they've open source the data set and you know reported some results with their particular data set the next topic I think this is crazy interesting as well is about search agents how can we have agents this reinforcement learning State action transition thing that learn how to search and model the rabbit hole of human Searchers so I think this example is really great and I think most of us kind of search like this you might do a query like what is the weather like in Germany in June and then you get some results you go actually let me add the keyword temperatures to this let me add the keyword average to this so that's the key idea is we're going to be having three actions to refine the query with the bm25 search which is either add another keyword remove a keyword or boost the term importance of a keyword and so the general framework looks like this where you have the hybrid search between bm25 and a dense retrieval model and then you have a T5 re-ranker and then you have this T5 query formulator which is the thing that's trying to reinforced from learning to learn how to control the bm25 to do this depth of searching and I think this could just be an incredibly interesting controller in the kind of design of these search pipelines so then the next topic is um really this is really a mind-blowing thing that's happened in AI yesterday even so I had to kind of scramble to add this to the slides but so the new method uh self-ass that improves results over Chain of Thought prompting by having the language model explicitly State and answer follow-up questions before answering the input question so I'm kind of going to put this here for a second and take a quick breakdown to coffee but okay so here's the idea so in gpt3 they have this thing called in context few shot learning where you provide examples of the task the question would be who lived longer Theodore hacker Harry Vaughn answer Harry Von Watkins and then you give it the new inference the new question that generates the answer so the few shot in the sense is however many of these question answered pairs you're going to put in the input for the gpt3 then they came up with this idea called Chain of Thought prompting and this was absolutely an incredible idea what you you show it how to answer these questions how to decompose these questions explicitly so who lived longer Theodore hacker or Harry Von Watkins and then you explicitly show it how to do this Chain of Thought where you first recall that theater hacker was 65 years old when he died Harry Von Watkins was 69 years old when he died so the final answer is Harry Von Watkins so that worked extremely well for a lot of these things and you see like gpt3 solving math problems doing coding this kind of Chain of Thought prompting is really showing how to query the language model and access what it's learned and now the new idea is self-ass so it's a it's a better way of doing these prompts so you say question who lived longer Theodore hacker or Harry Von Watkins and the new thing is you say are follow-up questions needed here yes and then you ask another question and you keep rolling it this way to answer this thing a particular compositional questions so this is the thing is there are different kinds of questions that you can answer if you just cut this off and say who won the Masters Tournament you're just recalling a single fact compared to multi-hop or compositional question answering where you have to chain together information so they've released this new data set with questions like who won the Masters Tournament the year Justin Bieber was born so it's not like the kind of thing that you've seen in the training data you have to do this compositional reasoning and this compositional generalization this is probably the hottest Topic in deep learning right now uh so oh and then another really interesting thing about this is not just having the language model answer the follow-up queries you would you would send these queries to the search engine and I think this is this diagram right here is just an incredibly interesting visualization of how we can have these large language models we V8 Vector search engine how they can play together to just build incredible technology like this the next huge topic and I think this is just incredibly exciting how these concrete numbers are coming out Mosaic ml has updates on their Mosaic ml Cloud for the cost of training GPT models and we'll sort of get into all the optimizations they do with the multi-node scaling the resumption one uh runs crash or lost bikes are detected and the way that they do the data parallelism with the pi torch fsdb and then the uh the compute optimal trading laws for how they tell you that you know this is this is the compute optimal uh scale of the number of tokens you should train at 30 billion pretty much if you've seen these papers and like neural scaling laws it doesn't make any sense to keep training these models past this compute optimal point so I think looking at this you'll see that it's it's still kind of expensive because we're seeing that there's like this phase shift with these language models where when they hit around that 6.7 billion parameter Mark is when there's this emergent phenomenon where they start to perform really interestingly but I think just getting these details out there having these concrete numbers is just incredibly interesting so now we're going to look into a counter argument about how you would do information retrieval with generate rather than retrieve so the idea being that uh you would generate documents instead of retrieving them and they argue three drawbacks to Modern debts retrieval methods that that I think are kind of worth seeing if these are valid or not the first argument is the representations of questions and documents are obtained independently leading to only shallow interactions captured between them so this is discussing how you would separately vectorize the entire document Corpus and then vectorize the question and saying that this is this is missing out compared to where you say take the question and the document as input to generate something and then they discussed uh you know the problem with say you only embed it into a single vector and I think they cite the Colbert paper on this idea of having uh these multiple Vector representations at the token level as well later interaction and that kind of thing and then they discussed that the sort of they argue that the limitation of the document index is that it limits the sort of size of the embedding vectors and can't use the large language models directly in this way but I would say that there's kind of three drawbacks as well the language models is that they're hard to update they're not as interpretable as the retrieve and read and then you know it's more parameter efficient to do this way because we don't need to store the data in the parameters and that also says it's just there's something to it being like ground truth information that you're retrieving compared to the generation and I don't think it's that it's solved to avoid the hallucination problem things like this but so I yeah I don't want to go in on this too much but they also have this idea where they we're looking into something called bird topic where you have these different clusters and you use this to prompt it to to sample diversity in the generation I think this is an example of you still have the embedding index to get the prompt so they're the way that they're kind of proving it is by using the the embedding set with the Clusters and then finally I'm just it still requires large language models to get this emerging performance so as they're showing this chart it takes up to 100 billion parameters to get this working well so I still think that this idea is isn't as far ahead as just the retrieve and read but it could be interesting to have a hybrid search maybe in the future when we say hybrid search will mean generate and neural retrieve and bm25 rather than right now we're mostly mean neural retrieve and bm25 but anyway so the next topic is about fuchsia learning with retrieval augmented language models decouple Knowledge from reasoning but the idea of being um language models have achieved this few shot learning ability where you can give them like four examples of input outputs and then they can do novel inferences and that's just probably the most exciting thing about language models so this report is studying is can these retrieval augmented language models or rather than just having a whole dense architecture you retrieve and then read can that also perform this few shot learning task so they find that you can using this massively multitask Benchmark and I think it's just incredibly interesting that you can also get this two-shot learning with a much smaller model than a lot of these dense language models and then this is what I think is the big sell of these models what what you're looking at is you you can update these retrieve augmented language models you have uh answers from 2017 that when they when it's 2020 they're outdated so say who won the NBA Championship or who is the president of the United States or like things like this where they change over time with the retrieve augmented language model you can just swap out the information and update it extremely easy and I think that's a really interesting property of this so then we'll talk about what is retrieval augmented models look like in image generation so I I hope that a lot of you are interested in these diffusion models where uh what they do is they you noise it and then you learn to denoise it by having this kind of uned and then attention to the text prompt which helps you in doing this uh learning task so what they're doing is they're retrieving additional images and text prompts to guide the diffusion so it's not just conditioned on the text prompt it's also conditioned on the nearest Neighbors in the database and they share that particularly what this is really good for is generating specific entities so if you're saying um a barbato day I can't say that a Bravado de Church Sierra is standing by a river and it's a particular kind of dog image gen Dolly they won't generate that particular dog but if you augment it with the retrieval component it'll generate that particular thing and I think this incredibly powerful for how these models are going to be actually useful uh so then we'll talk about this idea of set fit that is able to achieve few shot Learning Without large language models and so it's able to do this by say you have eight labeled examples you train a sentence Transformer with uh contrastive learning and then you train a classifier on top of that and surprisingly just this pipeline is able to work extremely well they show that it Rivals the Roberta large is only eight examples on this customer review data set uh so then just quickly I wanted to just say that I think that this kind of application of studying editing text rather than just generating text is going to be extremely interesting for how we interface with these natural language processing systems and having something that can suggest edits to your to your text is probably more useful than something that just generates text directly having like a thoughtful review of something and so they've published this data set where they have these different tasks like Clarity coherence fluency things that say you label for and edit when you're giving somebody a review of their blog post or something okay so finally the last thing is this operationalizing machine learning and interview study uh make generally organizing MLS practices around velocity validation and having versions of models describing this General pipeline of machine learning from data collection to experimentation evaluation deployment and then monitoring and response also things like run layer pipeline layer component layer infrastructure layer and an mlav stack and so there are a lot of really interesting quotes but generally the organized around the idea of velocity where you quickly prototype and iterate on ideas validation how you test your models and then versioning so when the model has failed you can you know roll it back to a previous machine learning model that you had in the system so there's a lot of quotes in here and I I feel like I'm maybe going over the time limit but um like I just highly recommend having to look through this and seeing all this advice on things like Jupiter notebooks how you find subpopulations in your data to do the evaluation and how to really do this kind of versioning I think the whole thing is just chock full of wisdom and how to build these systems okay I hope that was a good overview of new and AI maybe a little longer than I thought so going in but um I think kind of the most interesting thing is thinking about large language models their advances and what this has to do with search perfect thank you Connor for this uh great overview so I think one of the things I was thinking um was can are you going to share the links to any of those papers or like maybe so that if any of us wants to go and find those papers um could we do something about it like uh send it via tweet or something yeah I can put like a blog post with the links to all these papers as well perfect yeah so if you if any of you follows us on like a V8 uh i o um tweet on Twitter handle I forgot how to speak for a moment uh we will just tweet a link to how to find maybe those references and and I think that would be pretty cool because there's so much uh of yeah such a big wealth of knowledge it's great to see um yeah great and uh do you have like a favorite of the papers from those 11 that you talked about I think probably self-ask is the most interesting sort of but uh I mean I think I've already I picked all these things because I think they all do something very interesting but this kind of have the language model prompted to Think Through is I think pretty incredible excellent thank you I mean yeah of course like all of them like are super interesting it's just but we can still have like our favorites uh right that's that's kind of the thing cool all right so let's move to the final part of the presentation so I'm going to invite Erica back to the stream hey Erica um so Erica is going to show us um a quick demo of an application that she's been working on so I'm going to share her screen now um so yeah I'm really excited about um the dog search demo Erica like what can you tell us about it all right a little sneak peek is it contains images of dogs and I'll share the motivation from my little dog Bowen my name is Erica Cardenas and I'm a part of the devrel team and today I will be going over a demo on using the uh inch to back neural module from weaviate uh so this is Bowen the developer Advocate um excuse my little dog at Connors too uh she is two years old and one thing she loves to do while she has a few games um she likes catching uh being chased by humans or other dogs um she likes treats and yeah she's just a really playful dog so here is Bowen in a dog park playing with her best friend Ollie so what she enjoys to do is yeah the chase game kind of running around very fast and um she loves going to the dog park and interacting with a few dogs so this dog park is a little empty but usually there are a ton of different dog breeds so Bowen asked the question of oh can I figure out what kind of uh breed this dog is based off of the image I said sure Bowen let's build this demo with using alleviate and python Plus for the web application right so let's get into it uh so we were building an image recognition uh demo and we're using the inch to back neural module from Wi-Fi um what this does is it converts images into vectors so we can search through them and it uses the resnet50 architecture trained on imagenet and imagenet is a data set that has 20 000 classes over 10 million labeled images so this is quite large and as you can guess there are quite a few images of dog breeds so this is the best reviate module to use but also using the resonant 50 architecture all right so Bowen has the um well Bowen all she had was the idea right so I said okay let's create a data property so this has the name which is the dog breed the image of the dog and also the final path so um later on when I built when I built the web application uh we'll be dropping in an image and it will spit out the most similar um dog image in our data set all right so let's open up the application all right starting off with the docker compose file so maybe it makes this extremely easy so here we have the uh vectorizer module so we just specified that we're using the image to VEC and then also that we are using the resnet 50 model and that's currently the um only one I believe that is offered on wheat beets but I'm sure there will be more soon all right so once we load up our Docker file now we can go on to creating the schema um so here we are just uh connecting to our localhost and then we are building the schema of our DOT class so it is it contains images of different dogs and we also have um we are specifying which backyards are we are using which I have stated um is the image to back all right and then our property so we have breed which is a string we have the image which is a blob type a data type and then we also have the file path so when we use the near image operator it will output the file path to the image um and then we are just going to add the schema now and we need to upload our data objects to aviate so we are again connecting to our local host and uh before this in order to have a blob you need to convert or yeah in order to upload your images to Evie you need to convert your images to base64 values so I've already created the folder that has the conversion um so in lines 10 to 14 I am just opening this and then an 18 to 23 these are just the data properties which we have already specified in our data schema and then we're creating a unique identifier for each data object and then in line 28 we are just uploading this to ev8 so that we can use it and search through and since we are using the python uh we V8 the python client I decided why not build a web application in Python so we are using flask um lines one and seven are just a few libraries that are necessary um to build our application um so here we are building in line 9 to 11 we are building are up and in lines 13 to 27 this is the home page so this is the landing page when we run our application.pi file um it will output the URL and we're going to run that and what you're going to see are the images that are in our data set which are about uh yeah we have 10 different dog breeds in lines 29 to 38 is where we are running the near image or constructing the near image operator in vb8 so we're just limiting that to two outputs and uh yeah just letting it limiting it to two and what is going to um what the output is going to be is the file path and the breed name so if I upload an image of Bowen I want the results to Output golden doodle and a golden retriever rather than a Rottweiler because they are not similar at all I think you guys know but the size and also the color um all right so in lines 42 uh 57 this is really where we're just um opening up our image and we are um so once we upload the image we need to be able to store it and then we also want to Output it so that that's kind of just what this code is doing and then we're just rendering that template and having it structured in that aspect and if we um in line 60 to 61 we're just running the application so I think that was an overview of the code are there any questions Sebastian I don't have it open are we good to see the app I think what we we should probably uh show the app and just to show everyone how yeah how you build it but I think it's really cool because basically that function there where you have just uh calling uh this this search with the near image uh it's really where a lot of the magic happens right like once you imported the data and did the vectorization uh it's really cool so uh what what can Bowen do now with this app show us all right let's all right so here's our app with our 10 dog images we have a Bernice Mountain Dog a corgi Rottweiler we have it all almost right so let's upload an image of a mini golden doodle let's submit it and what comes up is the golden doodle and golden retriever which is exactly what we were looking for so now a phone goes to the dog park and she sees this dog she can say hey that's a golden retriever I know I'm the nearest neighbor to it and I want to play with it so now Bowen's curious mind is uh she's happy huh I could say nice and and what happens if you if you if she tries to look for some friends uh that she's seen yes let's drop in a silver lab that's more similar too all right we have the labrador achiever and gold retriever which basically the same dog so it works and now yeah you can search for various dog images and we can always include more and then also add in more to our data properties like weight and not that we all want to think about this but it's the lifespan of the dog so she's like Hey will this dog be in this dog park 10 years from now maybe maybe not got it yeah I really like how uh in this demo like it's not that like the dogs can be completely like you know can be different color Etc because like uh when when you search for like a golden doodle right like you found one that actually has different fur uh but it's still a similar breed so like the the ml model is actually pretty smart I'm quite impressed um so what's going to happen next with this demo what's what's the plan how can we share with the with our audience all right of course um so I will be pushing this to GitHub so anyone can access it and it also contains a readme file so it's actually quite simple to run it I've made it as simple as possible with just using python um and we can always add to it add more dog breeds add more images and just continue building on this Place yeah because I think we're going to publish it in our uh we made examples um and and I would actually encourage anyone to kind of like hey help us make this application look great and then and also test it out like if you have a whole bunch of Docker images that you want to test out uh you should definitely uh check it out in with examples it should land there soon um but also I I know it already as I'm not gonna ask directly I reckon but we are working on a blog post that explains the whole journey of how this application was built how you could actually use the image to vac uh module um so yeah like it should be up in the couple of weeks and we'll be sharing that for sure yeah um so uh what's Bowen's opinion on it does she like the application has she tried she's happy she's happy is she is she around is she in the room with you yes come on we should we should all show about people and like let me go you know okay the motivation of this app right absolutely yeah let's um the Bowen is a real dog she's a real customer and Erica wasn't building the application just for fun um and we are super excited there she is hey Bowen next time we should definitely get bow and like her own stream all day or is at the dog park so maybe I'll include images of her next time the dog park excellent excellent and I know at the end as a Doctor Who's super cute as well but I guess uh he's not around right oh not not ready for her definitely the dog is too big to lift like that right he's a golden retriever so it's I guess oh Still Still lift him but yeah I was thinking about the selection of dog there's this like this is a great selection of of dogs I don't know if these are like the most common breeds or something but I my parents had a Bernice mountain dog when uh when I was growing up so that was that was super cool now I have a golden retriever um Labradors are super common huskies are super cute German Shepherds are I think they're just super pretty dogs I love this selection yeah just looking at the dogs I have done more to it but yeah these were just the ones that came to my mind like the ones that I see the most often I feel like well thank you perfect thank you for this demo it was it was amazing um and actually so you should be all like uh pretty impressed with this demo because that's something that Erica just started I think last week so this is really like something that you can build uh really quickly if you know you know a bit about vv8 if you know a bit about machine learning if you you know you could pick up flaska over you know a day or two and you could straight away build a really cool demos um so yeah I'm really curious what other ideas Bowen will have for our future demos perfect uh I think this was a pretty successful uh first episode of viviate air uh thank you all for watching us um I I really enjoyed myself there was so much to learn uh but that would be really curious um to learn right like this basically this is the first live episode that we've done and I'm sure we can do it better I'm sure we can maybe include some other ideas um so please share your feedback with us you can do it on Twitter you can join at the uh with this public slack I would definitely recommend doing that uh and um or maybe if you think like you have something really cool to share maybe you build something with viviate uh that could be you know a cool thing maybe you could join us for five ten minutes uh we could always accommodate the format and make that happen but that's at least from me uh anyone else anything to add no well thank you all for joining and if you guys enjoy the demo and replicate it yeah absolutely I love how we're bridging this Gap from from sort of getting started so quickly to going all the way to like super complex cases in production now basically you can you can use VBA to get started and you can use bb8 for you can keep using it as you grow which is which is super cool yeah also thank you for my side super cool I I was planning on on watching this episode and then I got invited last minute so I guess I still watched it yeah I was I was looking at the roadmap page and I was I was going to talk about it in front of everyone and then I was like oh at here doesn't have anything on this calendar let's let's rock him in yeah because I didn't schedule anything at air time exactly so like for anyone that works at semi like if you don't want to be rope team randomly like uh invent a meeting with a customer or somebody of an excuse but it would be great all right very cool super great that you were all able to join us and um see you next month and I think uh just to double check the next episode probably be will be planned for the 2nd of November so the whole idea is that we want to run those on every first Wednesday of the month um so yeah thank you for watching and see you in the next we'll be there thank you ", "type": "Video", "name": "weaviate_air__episode_1", "path": "", "link": "https://www.youtube.com/watch?v=8B0ORWf3OY0", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}