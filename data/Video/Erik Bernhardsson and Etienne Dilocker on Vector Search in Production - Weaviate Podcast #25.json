{"text": "Thank you so much for watching the 25th episode of the Weaviate Podcast! This is a really special episode with Erik ... \nthank youhey everyone thank you so much forchecking out the wevia podcast we have asuper exciting episode today we haveEric burnerton and Eddie and dillockerEric is one of the early thought leadersin approximate nearest neighborscreating the annoy library at Spotify anincredibly interesting algorithm forachieving this approximate nearestneighbor Surge and I mean these two arejust such talented Engineers with somuch experience in building these kindof systems and we're here to discuss themain topic of vector search andproduction running in production whatdoes it take so Eric thank you so muchfor doing the weba podcasthi thanks for uh being here it's it'sgonna be a lot of fun I hope yeah thanksfor for uh yeah having me and of courseEric thanks for for joiningum super cool topic and I think we canwe can go into all kinds of differentdirections for what it means to run a nin production I think the first one tostart is basicallyum that the history like uh Connor youalready mentioned uh Spotify annoy andum yeah Eric you worked at Spotify quitesome time ago I think so yeah do youwant to start maybe telling us a bitabout what you did back then sort of oneof the the first pioneers of ofapproximate news neighbor searchyeah totally so I spent almost sevenyears of Spotify I said 2008 to 2015.and a big part of what I did at SpotifyI was building the music recommendationsystem and I don't want to get likesuper detail like how that works butlike roughly speaking like what we endedup realizing or what I ended uprealizing building this is that uhvarious types of vector models workedreally well so we would you know docollaborative filtering on thisextremely large sparse Matrix of whatusers listen to and then you knowbasically some sort of Matrixfactorization would then lead to vectorsand then once we have those vectorsyou know you could do all these sort ofyou know they have this like niceproperty that you have like a fairly lowdimensional space and you can usenearest neighbors to findrecommendations for people so you kindof projectusers and tracks and artists and albumsinto this we typically it's like 40dimensionsand then in that space it turns out likeif you want to like find goodrecommendations for a user you just lookat like similar near vectors for vectorsthat are close to that user if you wantto find similar music to a differenttrack you take that tracks vector andyou you look at uh in this40-dimensional space What are some othervectors that are close right and so theproblem now is like you have to figureout how to do this like you have to findnearest vectors uh fairly fast right andat Spotify we had a few million tracksat that point that was indexed in therecommendation system so about I thinktwo million tracks or something likethat now it's probably more it's like 1020 million tracks that are indexeduh and uh I looked at a bunch ofdifferent approaches and a bunch ofdifferent existing algorithmsumfor various reasons like one of thethings I realized pretty early on was uhnothing deep into this but like I Iwanted the functionality to end map itbecause what we wanted at Spotify was wehad a fairly static data setbut we needed to do a lot ofrecommendations very quickly and youwhen you deploy this you want theability basically like you know createan index load it into whatever manyprocesses as you have CPUs and then youknow do all this like here's neighborsearch so I basically built a staticfile index based on M map and it built aNoy and noi like basically works youknow kind of splits the like that thepoint space recursively into a bunch oftrees does that a few times to get aforest and then in that Forest you canyou can search I do want to point out Ithink actually today there are a bunchof better models I think I know I likeStills is useful and since I think it'slike one of the few like kind of likesimple like it's just like a fileembedded file and it's like uses M mapuh but of course like today there's DV8and many other ones uh that I thinkprobably do a much better job at findinguh nearest vectors very quicklycool thank you super cool cool summaryand yeah it's super exciting to to hearbasically how how early you were in indoing these things that are noweverywhere and of course recommendationbeing a a big caseum and and I I noticed two things Ithink that we can talk about a bit moreum one is you said essentially the theuh recommendation system or the therecommendation approach was just doing auh near Vector search so basicallyumdo I see it correctly that you never hadto do online model inference that youbasically that the model inference oncebuilt your index and then sort of whenthe user listens to a song or when theyselect the song you really just careabout the nearest neighbors and neverhad to deal uh with the inference or didyou have to do any inference sort of atwhat we would call query time in VBA butI guess in Spotify I don't know playtimeyeah yeah I think of it as like onlineversus offline inference or like batchinference right like we did basicallyzero online inference when I leftSpotify I think they do a lot now uh butwe would actually essentiallypre-compute almost everything right likeso we would do these the collaboratefiltering models we would recomputeevery month or something like thatbecause they were very large and took alot of time to do it now that would giveus a track embeddings right like a fewmillion track commandings users tasteships faster in particular you have thisproblem that new users come in and youwant to give recommendations to themrelatively quicklyso we would recompute those vectorsevery night and then every night wewould basically go through every userthat had some activity last 24 hours andthen pre-compute recommendations forthose users and I don't know if that'slike pretty efficient approach it justturned out that like the way we builthad the system set up at that time madeit a lot easier to do everything sort ofa bachelor in that wayand so that might also explain some ofthe design decisions of how annoy workedit's quite optimized for more likethroughput rather than like sort ofonline latency in particular that youknow talked about the M map you knowit's quite optimized for for doing a lotof well using multi-processing and doinga lot of things in parallel uh butum there's probably many other ways youcan do it today and I'm sure Spotifytoday does a lot more like sort ofreal-time stuff right like as you startlistening to the music probably I'mguessing they you know update thatVector in real time and do inference butI mean there's still like batchdifferent stuff going on in Spotifyright like Discovery weekly you know isonly recomputed every week so I thinkthere's still you know use cases forboth online inference and offlineinferenceyeah cool so super hope this this um thesort of the the yeah doing the inferencein batches and then having that staticdata set that you mentionedum I I think this is yeah as you said aswell it's shifting a bit but I thinkthis is for me one of the typical caseswhere you can easily make this thisdistinction between a search Library ana n search library that typically isbuilt for that static case so beyondbeyond annoy if we look at uh phase orGoogle scan or all these librariestypically they're built for those sortof build once then surf kind of use caseum and and this is for me a nice pointto sort of draw the distinction or dothe distinction between what is alibrary and what is a database becausewhen we started with vv8 one of thethings that we we wanted to give ourusers basically from the get-go is anexperience as they would have in anyother database so not So Much from thelike okay you're starting with a libraryand now you're trying to to sort of getthe library as a service but the otherway round you're starting from a from adatabase like you may be you're used toit to using mySQL database or or nosignal this doesn't matter but basicallyany database in the world you canincrementally sort of build up your dataset you can do updates you can dofiltering these kind of things and thatis something that that we yeah basicallythat led our decisionum to start with hsw as the first Vectorindex we definitely did look at annoy Ithink we even had prototypes before uhwith with annoyum I used it also in this thisconfectionary that we have till this daywhich is basically like a very simple asimple Battle of words model which issort of static it's built on on a gloveor fast text so we have this kind ofstatic and if you just want to searchwithin there we used a noise for that umbut yeah that that kind of sort ofonline changeability that that wasdefinitely one of the the reasons why welooked into into hsw and yeah definitelyone of the the parts that make sort ofdeviate a database as opposed to alibrary I would sayI think there's kind of maybe two thingsgoing on at the same time right likethere's like the sort of online offlinedistinction right like and you look atlike a machine learning modeluh you know you can either use thatmachine learning models of an onlineinference or an offline inference rightand and and and then the separate aspectis is the sort of the crowd support likesupporting like you know crud like whatis it was a stuff for create read updatedelete like the ability to mutate thedata set right and and I think you knowlike my sort of but I think the sort ofIdeal here is like a service that doesall four combinations of those twoattributes right and and also does itwith zero sort of performance lossbecause I think you know the the onlinecase is a lot harder than the offlinecase in many cases right because youneed to lower light latency and I thinkI you know it's easy to sort of give upa lot of the throughput by optimizingfor the online case but actually don'tthink you have touh I also think that sometimes we talkyou know when I look at like machinelearning as a wholepeople generally tend to think of likemodel inference as Premier like anonline thing but if you actually likethere's like you know 5000 startups thatdo like you know model deployments rightbut if you look at actually how peopleuse models in you know real life I wouldsay you know it's fairly evenly splitbetween batch inference and onlineinference right uh batch inferencegenerally has a lot more you know uhit's more important that you have a lotof throughput so I I think but but Iactually think there's ways you canbuild your system that you get you knowthe same throughput even in an onlinemode you just have to be smart about uhyou know batching and other things uh soso to me that's like the dream that andyou know and I think we've beenhopefully it delivers in those things Ihaven't done any benchmarks uh but but Ithink it actually doesyeah I think on the on the the modelinference part uh there's definitelyroom to to grow but on the latency parton on the search definitelyum but yeah so so batching I guess sortof when we think of of batching in inthe ml sense it's typically like thisoffline batching but you can still dolike a a mini batching approach rightwhere you just do the batch just bigenough to basically have the benefits ofsay running on a GPU which paralyzesthem uh enoughum but still have it sort of in areal-time approach where maybe insteadof sending uh or instead of doing ahundred single inference tasks thatwouldn't have to run sequentially justbatch those 100 up which happened maybeI don't know and then over the course of50 milliseconds or so and then have thembatch and and basically get thethroughput this way like trade up a bitof latency for for the higher throughputI I think this is especially importantwhen you have like Matrix algebra goingon in your system right like we eitheryou know especially when you're usinggpus right because like gpus benefit alot from batching if you don't do thatthen you might as well just like runeverything with separate threads andit's like kind of fine you know you havesome locking issues but that's fineum but I I think the sort of minibatching or micro batching that you seein some high performance model servingFrameworks uh they do benefit quite alot when uh when you're using Matrixalgebrayep cool yeah so media at this point isa good good point to to tell a bit aboutthe different options that people haveor that users have to do inference withwith vv8um because as you said some like to doit offline and just sort of onlybasically do the re-index part with V8so this would be the typical case wherethe users provide their own vectors andthey're not using bb8 end to end butbasically batch indexing under do maybedoing some kind of a blue greendeployment where class a so-so classesare the the isolation units in VBA whereClass A would be serving uh with the oldmodel you can prepare Class B build upthe index in the background and thenbasically just switch the load balancerfrom one to another to to do this thiskind of shift so this would be like theweekly exampleum but then also for the the liveinference Parts with vv8's module systemwhich basically gives you the ability toplug inum yeah any kind of kind of model reallyand not just any model but also anymodel provider to do the the end-to-endinference and there what we recentlyadded is support for for the huggingphase API so basically one of thosehosted inference service types so thatyou can really basically do do all threevariants that you want to do and then ofcourse if we're talking about thecombination with crowd all of them themcan be combined with with the crowd partof of the database but you couldbasically bring your own vectors whichum sort of gives you full control abouthow you do the inference you could youcould do it live you could do it or youcould do it online you could do itoffline you can do it with um sort ofhosted together with vv8 so vv8 modulesystem then just brings a smallinference container there you can youcan still sort of split this up into doyou take what what serve what Evaprovides and just plug in your model ordo you replace the entire container sofor example if you say it I can do thisbetter I can optimize this better orsomething I can do it or now the newoption is basically if you want the noOps approach just put use use one ofthose those third-party providers wherewe're supporting a hugging face coher Ithink and oh an open AI also so withthose those three um basically yeahgives you the ability to plug those in Ithink this is super cool I I mean Idon't know like kind of reflecting onthis as like you knowas someone who like spend time on thislike a decade ago or more right like Iwhen I discovered this like vectorapproach like I like I was actually justtalking to someone the other day butlike I actually feel like that's likeone of the most profound insights I'vehad in my life was like this like vectorapproach you know when I realized thatback in like 2008 I'm like this makes somuch sense like you have this like nicespace and like you can think of thingsin terms of you know euclidean you knowgeometry right and and you know and thatsort of mental leap for me was likerealizing like once you embed all thesethings into the space like a lot of sortof you know relations become more likenatural the hard part is the query rightand like 10 years ago or 15 years agowhen I was doing this like it was veryhard to record it so I basically likehad to roll up my sleeves and like buildthis like C plus Librarywith with python bindings uh that Icould import and like use you know formy uh jnk Hadoop jobs uh but I alwayslike was a huge believer in sort ofvector models and and so I'm like onepart of me it's like extremely excitedif the world has come around to likerealize like the sort of power ofvectors yeah I'm very excited about youknow the sort of the new databasescoming out the embedding models and andsort of a general just like acceptancelike you know sort of embracing of youknow the fact that we're in a vectorspace like you can use these like vectormodels for a lot of stuff and and likewhat I what I'm excited about is like Ilook at the you know I look at all theselike technology in the past you knowlike you know a very search algorithmsor various types of ways we did likerecommendation relevance in the pastlike I think there's like a hugeopportunity to take a step back and likerethink so much of that from from groundup right uh and uh and so pretty excitedyou know we've yet is portion of thatkind of stuff and but also many manyother players right like you know inparticular like you know it's notoutside of search there's also a lot oflike work on bedding some other things Ithink is really excitingso that's fantasyyeah and yeah yeah couldn't agree moreand we're basically even though youmentioned 2008 right so even though it's14 years later I think we're we're stillbasically we're still at the beginninglike it's it's such a massive Trend andit's it's gonna yeah it's Gonna Changesurge but but goes beyond search andthen we're really just at the beginningbut yeah what I also really like is thiskind of growing together with the spaceand I think that was something that wetried to be be like from the get-goum while bv8 can be used end-to-end likethat end-to-end user experience is superimportant we never said we need toentirely own the chain end-to-end likewe would say I don't know you could onlyuse it with models that we train orsomething and all of a sudden we'recompeting with these specializedstartups and then not just startups alsoGoogle and Facebook and then all of themare meta nowum but but really just say that okay wewant to integrate with those players inthe space and basicallygrow grow viviate with the space butalso help grow the space with VBAbasicallypartnershipI think that's a good approach I mean ingeneral like I would say when I look atmachine learning like I I think you knowit's kind of bifurcating a little bitwhere like you're gonna have the youknow the Googles and Facebooks and youknow the other big providers liketraining these like enormously complexvery large models open AI Deep Mind andcohere and a few other ones right andmost people want to want me to train amodel like they could just like takethese models and use the embeddings thatcome out of these models or use thepredictions or whatever right likeembeddings are often like thepenultimate or the the you know sort ofsome intermediate layer in these modelsuh and and then like do their own youknow sort of fine tuning on top of thatso I think that's like a big shift inlike how people work with machinelearning also in the lastfive ten years five years maybe evenlike three years I want to sayuh but I think it also opens up you knowsort of makes a lot easier to to usethese models right like in the past whenI did things I had to do the whole thingend to end right like now I can justlike download a transforming model fromhacking face and and do you knowtwo-thirds of it and they can like throwsome like simple stuff on top of itwhich makes it a lot easier to do thesethings and with great quality too thereare so many like pre-trained models forEnglish and and computer vision and Imean any language really and and thosemodels make the life a lot easier for alot of these for people trying to buildthe recommendations or classification orany sort of you know industry machinelearning applicationyeah and it's and it's basically gettingbetter day by day so another topic thatI want to talk about is benchmarksyou're of course um famous for for the an Benchmark website but before we gointo thatum we talked a bit about about what youdid at Spotify but I'm also supercurious about what you're doing rightnow and um yeahyeah I'm working on this uh startupcalled modal I I started it uh I wouldsay about a year ago and it was stillpretty early days but the idea is I'msort of basically like I guess like thebest way to put it is like I'm buildinga data tool I always wanted to have for20 years and so I I found that like whenthey look at data teams how they operateand how to productionize things and howto scale things out and schedule thingslike and how they work withinfrastructure and the tools they haveit's all kind of janky like there's youknow there's so much like time wasted onlike you know dealing withinfrastructure product you know settingthings up like dealing with kubernetesand Docker and you know AWS andterraform and Helm and all this stuffright and and I think as a as a resultyou know like building code and runningdata applications today you know takesfive times as much time as it should douh I I mean I literally like you knowI've been wasting like the last threedays like trying to configure like vpcsenabled yes and like I really thinkthat's like hell for developer to everhave to deal with uh and um and so sowhat is modal like yeah model basicallylike you know we built our own sort ofLambda style like infrastructureprovider for data jobs right like wemake it very simple Tech code andproductionize that in the cloud like weare a cloud provider in that sense likewe take people's code put it incontainers and run it in cloud and wecan do it at extremely fast because weended up building our own uh containerruntime and a bunch of other stuff fromfile system and many other things and sothe end result is like you know if youwant to do especially if you're an earlystage tech company you don't want to setup all this like traditional you knowall the infrastructure uh using modelyou can you can immediately you know doeverything from like you know uhschedule retraining of your jobs todeploying your friends to scaling outlike large scale like batch inferencelike you know a large scalemapping over you know various types ofsort of embarrassingly parallel taskslike trust coding web scrapingsimulations and back testing and andother things and and do build a lot ofend-to-end infrastructure for machinelearning but also like other like youknow more like mundane data tasks likereporting or whatever uh and do thatvery easily without having to thinkabout infrastructure so sort of you knowkind of selfishly building a tool I waswanted to have but uh you know also sortof think that many other people wouldbenefit from this tool as wellreally cool I I saw it I think it was ascreenshot or a short video on onTwitter where you shared basically theAPI and do I understand it correctlythat I can basically write python codeand I just annotate a function and thenit runs in the cloudyeah and I think the it's sort of thisidea that I think other people have hadtoo which is sort of people sometimesreferred as the self-provisioningruntime like the idea that likeeverything is just code right and thecode itself specifies what sort ofinfrastructure it needs including thecontainer specification the parallelismlike all these other things and thenwhen you run the code the code just likegets those resources in the cloud foritself so it's a sort of idea of youknow you take the app code they also putin all that you know container code andenvironments and and chrome jobs and andcredentials and all the stuff and justlike right all of it in code right likethere's like no config in model likeeverything is code andum which makes it very concise makes itvery easier to run and um uh it makes ita lot easier to maintain right and soyeah like everything in code uh issomething I don't know if you everlooked at palumi but it's sort of thesame idea for taking even further meonly does the infrastructure in codelike we also do the we do everythinglike the infrastructure and the app codetogether all in Python really reallycool can can users try this out like canI just could I just register right nowor in in what state is it or would Ihave to wait a bit sure no but but we'reworking on so we're still in early datastage test right and we have a bunch ofusers using this uh and a few payingcustomers and so we're you know we'reslowly scaling up and and you know ifyou want if you're interested in modelfeel free to go to model.com and jointhe wait listum you know it would sort of definitelygonna make more announcements in thenext few months and and gradually openup and add more beta testers so ifyou're interested in trying outdefinitely go to model.com and setup orput your name on the white listcool nice yeah so as I mentioned beforewe we talked about model I mentioned uhbenchmarks and of course there is a nbenchmarks which um is I would say thede facto standard for comparingum yeah comparing a vector surge I don'twant to say either libraries ordatabases because I guess youtechnically have a mix of them in therebut maybe I'm just going to sayalgorithms and their implementationswould that be correct yeah I thinkthat's correct and it's mostly librarieslike it sort of started out at almostyou know five ten years ago and backthen it was mostly libraries around Imean a m Benders marks was like one ofthese projects that like I got annoyedbecause I would read like various likepapers at conferences and they all hadtheir own like obscure like Benchmarksetups and and of course like every liveEminem also biased because I built thenoi but like every Library maintainer Ifelt at that time would build their ownBenchmark suite and you know the world'slike their library was the fastestum and and I found a lot of you knowvery frustrating but also peoplesometimes would come up with new typesof like a n algorithms and like and notBenchmark them right like one of thethings I was always was frustrated waslike this research and localitysensitive hashing well calories let'simagine like basically it doesn't workin my opinion like it's a terriblealgorithm but like people keep releasingpapers about it because they had thislike nice mathematical properties butlike if you actually run the benchmarkson it it's just like awful and so yeahso there's a couple of different reasonswhy I was frustrated and ended upbuilding my ownbenchmarking Suite initially was kind ofjanky and you have to to like installall the stuff and it barely would workbut uh a few years in I actually set itup in a nice way to sort ofcontainerized everything it made it easyto reproduce I added more libraries uhand so yeah so it's going prettyextensive Benchmark speed I think it'sshowing a little bit of age in the sensethat it doesn't support crud it's veryyou know all it does is likeyou know a kind of static offline uhbatch inference and really just measuresthroughput uh so kind of going back tothe first thing we talked about itdoesn't handle you know the crud case itdoesn't really Benchmark that it alsodoesn't really Benchmark latency uh soso some libraries or databases Mayoptimize for latency at the cost ofthroughput and sorry and Benchmarkdoesn't really optimize for that or itdoes really take that into accountum but I think all in all like you knowto me like it was something at that timeand maybe still uh there was very muchneeded in the space because there's onlylike libraries out there making claimsabout you know their performance uh anduntil any other benchmarks I basicallydidn't feel like there was like a sortof a neutral semi quasi neutral becauseagain I'm the author of annoy too butbut you know sort of Benchmark Suitethat actually try to compare all ofthoseyeah yeah and then I mean the the factthat you're not trying to sell somethingwith it I think that that sort of givesyou a lot more credibility like if if weas semi would basically put out somesort of a comparative Benchmark rightnow where we would Benchmark let's saybb-8 against I don't know ourcompetitors or something I think thatwould be you would always have to takethat with a grain of solvent I mean youshould becauseumso yeah it's reallyyeah I agree yeah and there's all theselike weird ways you can like kind offake it too like one of the things I Ikind of was you know felt with the noisewith sort of a m like it's kind of hardtoo because this is sort of a weirdtrade-off between like okay what is thedesired recall and what is their desiredthroughput right like if you if you wantto maximize throughput you can like youknow make the recommendations reallyterrible and vice versa if you want toyou know make the recall extremely goodthen you can like you know uh you knowmake it very slow and so one of thethings I also did it in benchmarks Ipushed for a lot is this sort of youknow you have to look at the the wholeFrontier like the whole Pareto Frontierof like you have to actually make a 2dplot and like you know plot thetrade-off curves and do that for everysingle Libraryand what that means is like for everyLibrary you have to run all these likedifferent parameters and then computethat sort of you know the trade-offcurve after the fact like after you haveall that data so so it's sort ofit's a little bit tricky to do thatthing you actually have to run you knowlast time I ran it it took I thinksomething like two weeks to run all thebenchmarks uh and uh it was a fairamount of compute that goes into therebuilding those benchmarks so if anyoneis asking like why haven't I haven'tupdated in a while is because it justtakes a little bit of time to seteverything up and then run it but Ishould do that at some point againyeah yeah definitely it's super coolyeah and I think that that Frontiercurve I think everyone who's looked atsome kind of a n and Benchmark or or asort of a non-comparative vector searchBenchmark everyone knows those kind ofgraphs where like top and to the rightis is best so that's that's yeah it'snice to hear that you came up with thatbecause um basically the first time Ilooked at an a n Benchmark which was a nbenchmarks that was just there so Ididn't didn't even think about that yeahsomeone had to come up with that at somepointyeah I don't know if I necessarilyinvented that I'm sure there was in someolder papers too but I definitely youknow I do think that Hayden hadbenchmarks like pushed for that insteadof popularized that and you know madethat you know the sort of the hopefullythe de facto way to compare things islike you know looking at the 2D Frontieryou know making that trade-off veryexplicit I think is very importantyeah yeah absolutely so in in ourbenchmarks that we have which are notcomparing bb8 against something else butwe're just basically showing like thisis how bv8 performs under thesecircumstances stances we also have thatand and it's I think this is a good toolas well this this kind of Frontier justto to educate users becauseum and I I've had a couple ofconversations with users if you'resaying like oh I I want a n this is socoolum I I'm using this a n system and thenthey're like why doesn't it have perfectrecall and then a conversation typicallygoes like do you know like are you awarewhat a n is like the a and a n standsfor approximate nearest neighbors that'sbasically that trade-off between recalland if you're like oh okay yeah thatmakes sense but then having those kindof graphs and seeing like even in anapproximate nearest neighbor situationyou can still achieve High recall youjust need to need to basically give up abit of latency and throughput and justuse the Benchmark as a as a guidebasically of how to set parameters andhow to configure it I think that'sthat's also super super helpfulso that's maybe not a coincidencemaybe some kind of subconscious decisionfun fact one of my daughter's name isAnne Ann but it's not it's a purecoincidence we had that name in thefamily and uh although she was bornafter we had benchmarks so maybesubconsciously influenced do you alsohave a child called k nbut uh yeah maybe maybe one day yeah thefact the funny thing is I haven't reallythought about that until now it's kindof weird maybe I did name her afterapproximately there's neighbors I'mgonna tell her that which is when she'solderyeah so so um benchmarks um basicallywe've talked a bit about the the valuethat they provide and um I think in a ina sense it'sum it's really good to to have or to togive use these kind of insights in uminto how these these algorithms performand at the same time I thinkas a user how much do you care basicallylike is there a point where you go okayit's just fast enough or do I need tolike of course everyone wants to havethe the best but um yeah what is sort ofif we're talking about let's sayum a two millisecond versus a fourmillisecond latency like is thissomething that matters to the user Imean my opinion is like you know it likegoing to 100 I don't think is ever worththis because there's like a point whereit just like takes longer and longer tolike really you know essentially justyou're just doing like exhaustive searchbut like if you can get to like 99.9percentyou know that's like usually like prettymuch like good enough right that's likealmost as good as like 100 and you knowgoing to 99.9 or like whatever like 99uh that usually ends up being like a 10xor 100x improvement over exhaustivesearch or maybe even more a thousand Xif you have like you know very largedata set and so I I think that's kind ofThe Sweet Spot is like you know for formost users if I just had to pick a pointfor them I'd probably pick you know thenine you know the the three nines 99.9that percentile and you know that'sclose enough to 100 that practice youknow won't be a problem uh but still youknow implies like a pretty you knowsubstantial performance Improvement butI'm curious what you think at the endactuallyyeah yeah soum definitely like I I kind of looked atthis from the perspective of latency andnot so much recall but I I like the waythat you're looking at this of sort ofoptimized for recall first and then seewhat what latency you you get and uh thepoint that that I was going to make isbasicallyum that let's say these two numbers thatshe said like two milliseconds or fourmilliseconds I think for the kind ofslos that users have to meet for forwhatever they're doing on top of ofvector search they're probably notserving pure Vector search to the userso they're probably building some kindof application on topum let's say they have 100 100millisecond SLO for forum the end-to-end thing then it'sprobably not going to matter if it's twomilliseconds or if it's fourmilliseconds howeverthis you can't really look at latency inisolation because latency probably alsodives into throughput at least for thesame same kind of Hardware cost likeassuming that that um it scales linearlyacross threats and you have a singlethreat and on that single threat it'stwo milliseconds or four millisecondsthat's basically twice the throughputand um that I think is is much moreinteresting and there I think if if weif we take this one step further andthink about how do you actually run uh an in production and um for example usingthe vviad cloud service where we nowhave usage-based pricing then it it sortof it I think it becomes a matter of ofgood enough like I need this kind ofkind of latency SLO and I need this kindof throughput but I can basically getthe throughput through horizontalscaling which of course increases yourinfrastructure cost but if you haveusage based pricing then you don'treally care so much about the theinfrastructure cost so that's basicallywhere I think yeah you need to kind ofprove that it's fast and fast enough andthat it's never going to be too slow toachieve your your goals but at the sametime yeah at the end it's basically it'smore kind of an optimization that wehave to do internally to to run moreprofitable on the V8 cloud service thanthan what the user should ultimately endup carrying aboutyeah and it is of course use casespecific right like what is the cost ofa true of a false negative right so sobasically like you know the fact thatlike there was something in the resultset that you know the the a n algorithmdidn't find right and it's it's going tobe very high for search right like youknow if users searching for somethingand you don't find it like that's kindof a bad experience right forrecommendations like not so much rightlike it if you're just making arecommendation if you want to recommendlike you know 20 tracks you know tosomeone at Spotify and it turns out likeactually you know if you have done anexhaustive search you know that you knowthe 21st track wouldn't have been therebecause it would have been another trackLike No One's Gonna notice right so Ithink it's extremely you know so formaybe like recommendations like youdon't have to go to like you know 99.9maybe it's fine to go to like 95thpercentile like I don't knowright and and that's you know those arethe trails you have to think aboutyeah yeah great pointyeah yeah and I think also you shouldtake into account how good is your modelactually at predicting like even if youhave 100 recall that doesn't mean thatthat from a user's perspective the thematch is good if the model just createdbad and Bendix basically like it couldbe the the true nearest neighbor butjust yeah it was just the wrongembedding basicallyyeah and I also wonder to what extentyou know people then end up like youknow doing sort of a multi-stagere-ranking anyway like at Spotify whatwe ended up doing was we actually had anensemble method although I think theychanged that lateruh but but so what we would do was weactually had not just one vector modelbut we had you know I don't know half adozen Vector model plus a bunch of otherstuff and and so what we would do islike we would use each of these Vectormodels uh you know to search forcandidates and so if we you know if wehad to generate 100 recommendations fromuser we would ask you know each Vectormodel like give me a thousand that youknow tracks right and then we'd pullthem and then we end up with like 5 000tracks and then we would you know webasically re-rank it using an XT boostuh gradient boosted decision tree basedon a bunch of other features too uh uhthat that you know all kinds of like youknow some of them are like not at alllike collaborative filtering Vectorbased like someone that were just likeis it Christmas then you know we shouldboost crisp like there's like all theselike you know weird features right andthen we would re-rank based on that andand and I thinkI don't know I think it depends on theuse case like I think you know sort ofadvanced you know the companies machinelearning practitioners like Spotify oryou know larger like e-commerceapplications I think they're alwaysgoing to have this like multi-stageapproachum but of course like you know for a lotof like early stage startups or a lot ofyou knowcustomers that don't have you know awhole machine learning department theymight just want to take the the outputfrom the embeddings and just return thatto a customer and I think that's goingto be good enough in many casesyeah or do some some minimal kind ofre-ranking with them so for example thenwe're we're getting in the direction ofhybrid search where um so for for ourlisteners hybrid search is basically thethe idea that if we're in the context oftext you have your dense Vector modelthat basically yeah creates your yourvector embeddings but you also havetraditional search so to speak so bm25bm25f these kind of algorithms that umboost keywords or boost keyword matchesor phrase matches Etc and um yeah withhybrid search the idea is to to combineboth of them and um combining can beindependent combining could mean thatyou do some sort of minimal getre-ranking or boosting based on onkeywords based in like do the vectorsearch for Bluestone keywords or do itthe other way aroundum and um that can already also helpbasically overcome limitations of eitherthe a n algorithm if the recall isn'thigh enough or the model soa text model standard Transformer modelsfor example they perform pretty bad outof domain for for exact matches so thatis something that can be overcome withwith hybrid search and there I thinkwe're also trying to to Really lower thebarriers of Entryum for yeah as you said for for likesmaller startups that don't have a wholeAI Department working on this by makingthis easier and easier with with bb8yeah totally and I'm kind of curiousabout like the evolution I mean this maybe a side topic but like I feel like youknow 10 years ago like you know youwould just start with like you knowsomething like elastic doing likeinverted indexes and that would be likeyou know you would productionize thatand then you would have search right andthen you knownow today it feels like okay you startwith like maybe you know invertedindexes or you start with Vectordatabases and then at some point youknow you start adding features and youstart breaking it up into like amulti-stage pipeline you have like bothvector and you know inverted indexesworking conjunction then you throw in abunch of other features too and then youthrow it like you know throw in likeextra boost on top of that or whateverand you know you have this like you knowthree four stages of you know candidategeneration candidate re-rankingfiltering right like I I'm kind ofcurious uh you know what do you see inthe world like you know of search andrelevance today is that sort of anaccurate way to think about itoh yeah absolutely absolutely and Ithink you have all stages basically youhave companies doing just one stage twostage you have multiple stages like wehave use cases where we're from ourperspective as semi basically we don'teven see what's happening like all weknow is the customer tells us well weuse VBA for Canada generation and thenwe have that that kind of Pipeline ontop of it and of course that that issomething that's that's specific to themand and probably we're all there magicis happening and something that they'renot going to be very vocal about becausethat's that's kind of their their secretsauce so yeah sometimes we as thedatabase provider as the vector searchprovider we only see that that firststage the candidate generation stageum but even in the candidates generationstage I think we can so so for examplewith hybrid search we can incorporatelike a bid more on on of that part andwho knows maybe uh later on it could beeven even higher if you could do fourstage ranking or or search withyeah I think that makes sense becauselike if I think you know users willgenerally start with something that youknow does that the simple thing the sortof you know pure Vector approach rightbut like you know over time you know hasto get more and more advanced like youknow it's sort of nice to sort of offerthose things too like as to start tothink about you know re-ranking and andyou know multi-stage pipelinesum I think like offering that you knowas a black box or not not actually as ablack box but like it's kind of a graybox like you know you can feed some datainto it but you know 100 sure how itworks and to me that makes a lot ofsense as a productyeah one one uh sort of two-stage uhpipeline approach that we we've actuallyhad for a while but I keep forgettingthat it's a two-stage approach is thatthe question answer extraction that youcan do with VBA where basically you justhave the the dense or whatever a searchyou use as as candidate retrieval andbasically use the the question answerextraction model that also returns ascore as a re-rank step or even if youeven if you don't do the re-ranking justto extract the the uh the kind ofinformation from that text method that'sa very simple but it's also a two-stagekind of pipeline that you can also doout of the box basically with uv8 yeahthanks a lot says at Spotify anincredibly important uhsort of one station felt in the pipelinewas was just like removing tracks thatthe user had already listened to whichkind of makes sense like if you'rerecommending music you obviously don'twant to recommend tracks the usersalready listened to so so that was thelast step in the pipeline we basicallyused Bloom filters for that uh becauseit's very space efficient uh so we wouldrecompute Bloom filters every night andthen use those as sort of binaryrepresentations and to filter out thecandidates very quicklyso we didn't have to so it actually wasat the last stage we would we wouldgenerate candidates remove everythingthat was already in the bloom filter andthen and then re-rank the resulting onesand Bloom filter also has uh falsenegatives right like Bloom filters butoccasionally uh flag something asbelonging in the I guess you should callit false positive but from the usespoint of it turns into false negativethey will they will sometimes think thatyou know sometimes because the bloomfilter has is approximate we would thinkthat okay the user had already listenedto this track but actually they didn'tit was just like a false positive so wewould then remove that turning it tofalse negative where the user wouldn'tactually get that recommendation becauseyou know the bloom filter thought thatthe user already had listened to it butyeah I mean I'm just like mentioning aslike you know sort of one example oflike you know one stage in this likemulti-stage pipeline I'm talking aboutand I think everyone everyone's pipelinewill look a little bit differentdepending on the use case yeah yeah whenyou think of of stages it always soundslike super complex but can be somethingsuper simple is that what I really likeis that you're essentially usingdatabase technology there are plenty ofloom filters in in vva just for the theobject store which is an LSM based storeand and super cool that you were yeahusing using Bloom filters there as wellum so what I find super interestingabout removing this in the last partum if I understand it correctly that isessentially a post-filtering step so inthe worst case you could run into asituation where you would run out ofcandidates like if the if the user haslistened to everything then everythingwould be removed from the search yeah sothat that's another a situation wherewhere I think the the pre-filtering thatyou can do in bb8 would be super helpfulthese days because you can just removethem before generating the candidatesyeah I don't know if that was inpractice I think it's in theory wouldwas a problem at Spotify but in practicewe generated so many candidates that itkind of we I mean we were generated like10 000 candidates for every user rightlike plus you know and do that you knowtimes like a number of different modelsthat were all Vector based so so in theend like pooling those like we're gonnaend up with like 20 30 000 candidatesand then we rank them first like filterout using blue filter then re-rank themright uh so I think in practice like foryou know occasionally they would end upwith like you know maybe one lessrecommendation but but I think in almostevery case like we had it more thanplanningyeah great example of basically you needto do whatever is right for your usecase I could imagine search cases wherethat would be very problematicyeah thank you so much for joininglooking at the time to see where we'reapproaching our our end this was superfun super super nice to hear yeah hereyeah hear about Spotify and Noy hearaboutum yeah a n benchmarks and then ofcourse about modals so do check outmodal as we heard you can't register yetbut you get well you can register forthe for the wait list right so do dothat and uh check out VBA as well ifyou've if maybe Eric was the reason yougot here and not not deviate if youhaven't heard of vb8 then check out thatas well check out our other videos anduh yeah thank you so much for for cominghad a great timeyeahsomeone's going to talk about this stuffthanks so much Eric", "type": "Video", "name": "Erik Bernhardsson and Etienne Dilocker on Vector Search in Production - Weaviate Podcast #25", "path": "", "link": "https://www.youtube.com/watch?v=gXPuhyM11_k", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}