{"text": "ANN Benchmarks are a tool for evaluating the performance of in-memory approximate nearest neighbor algorithms. Etienne ... \n[Music]hey everyone thank you so much forwatching the we va podcast we have suchan exciting podcast today eddie anddilocker is coming on the show again totalk about a n benchmarks approximatenearest neighbor benchmarks and how youcan find the optimal parameters forwev8's implementation of h sw so to takea quick step back before diving into itat the high level idea with the we v8vector search engine we're looking athow we can encode objects into vectorrepresentations and then once we havethese vector representations you saytake your search query similarly embedit into a vector space and then you wantto find the most similar vector andone of the parts about this that makesit so interesting is once you talk aboutbillions of vectors and like anabsolutely enormous amount of vectors todo that similarity search with andthat's where this thing aboutapproximate nearest neighborbenchmarks and algorithms like h and swcome into the picture because they letyou do this in a reasonable amount oftime find the most similar vector in aabsolutely enormous collection ofvectors if you're talking about you knowlike all the tweets on twitter orjust like i'm sure that people out therecan imagine absolutely enormous amountsof objects that you'd want to searchthrough so eddie and thank you so muchfor uh coming back on the vva podcastand can you uh tell us about the a nbenchmarksthanks for for having me it's been quitea while i think that i've been here uhso very happy to to be back uh yeah thebenchmarks i think is probably the mostrequested well feature is not a featurei guess in vb8 but one of the mostrequested topics overall from from amultitude of directions so new usersmight be worried if i'm using vv8 can ithandle the loadthat i would receive in in production uhusers evaluating different vector searchengines might be wondering okay this ishow how quick or fast is it um and andall that we had before was basicallythis like very vague claim that you cando a a vector surge in in considerablyless than 100 milliseconds and that'ssort of if if we look at the benchmarksthat we just released like i think maybewe were a bit too modest with that claimbecause i think that's that's typicallythe the search latencies are much betterumbut really benchmarking like it's such acomplex topic and i think you can't putit in like a single statement of sayinglike yes you need to put some numbersomewhere on the website like you needto get people the impression okay uhspeed and throughput is a concern for usand i think that was the the initialidea of just having something like thatin our in our github uh readmeum but yes the benchmark show right nowit's it's such an interesting topic withdifferent latencies and and how likelatency and throughput the connectionbetween those two um then of course dataset sizes uh vector dimensions like allof these things have an influence on onumwhat you can seeand yeah i think it's it's it's superexciting because vv8 is is fast i thinkwe're we're sort ofdefinitely in a very good state with ourperformance and why not be supersuper vocal about it why not show whatwe can do and not just make these likevague claims like yes it's fast butwe're not going to tell you how fastokay so can we maybe step through thecomplexity of what makes each differentdata set so you know say you have uh abillion paragraphs from wikipedia thathave been encoded compared to i don'tknow a billion images or like what whatare the different things with respect toeach of the data sets when you're tryingto benchmark an approximate nearestneighbor searchyeah uh yeah so if we if we look at umthe current benchmarks what we see issort of an and what i would have assumedbefore is size is the different the themost important factor like i would haveassumed sort of without any context ummaybe that let's say if you havesomething that's a hundred thousandobjects and you have a million objectyou would think that the million objectones is considerably slower and if youbrute force this which has a basicallyuho of n complexity like linear complexitythat would absolutely be true like aproof for a search through a millionobjects would be roughly ten times asslow as uhone through a hundred thousand objectsuh but of course we're using a n uh uhindices like in our case h and sw andwe've talked um at least twice i thinkone in once initially and once also withuh yuri on the show we've talked abouthnsw and the whole point of like thisthis complex graph structure that hnswis the whole point of it is really thatwe don't have that linear umkind of kind of a latency increase or orumyeah throughput decrease however youwant to see itand um it should have been reallyobvious saying that now it should havebeen really obvious that data set sizeisn't the biggest factor but it's stillit's nice to see it and it's it's in asense umyeahit shouldn't be surprising but it stillkind of is and it's nice to to see thatso umthat is i think thea very interesting learning uh also whenapplying this to different data sets umwhen users in the community tell ussomething about their data set i thinkthe first thing that they would mentionis how many objects it has andit's it's actually for performance itmight not be that relevant it might berelevant for like resource planning andfor for cost estimates and these kind ofthings but for performance what we seeumyou can generally get the highestthroughput um two things have the thebiggest impact one is the vectordimensionality and i think this alsorelates a bit to your question aboutlet's say these are paragraphs fromwikipedia or maybe these are imagesdepending on the model used um differentmodels use different dimensionality andtraditionally i'm not sure if this istrue anymore but traditionally we wouldsee that like text based models haverather few dimensions so maybe like 384on on something like uh centertransformersum and image based ones would have veryhigh dimensional analytics so 1024dimensions for example and this wouldactually be the biggest impact uh umthat you could have in on performanceand if we were diving a bit intohow hmsw works and and what's happeningis the approximate uh part basicallytells youuh the index does something smart so tospeak that you don't have to evaluatethe entire index it's a neighborhoodgraph soby using this a n model that that agentsw hasit basically tells you here is a smartway to only evaluate let's say fivepercent of the index because these fivepercent are close to uh to your searchquery umandwhatuh sorry if we if we do this we we cankind of see why it doesn't matter somuch if we're if we're evaluating out ofa hundred thousand objects or out of amillion objects because this fivepercent of course is made up number likeit could be that in in a million objectssuddenly we're only evaluating maybe 0.5however the dimensionality of the vectoris something like if you've narrowedthis down to making this up let's say ahundred thousand vector comparisons thenyou really see that the cost of doing ahundred thousand vector comparisons witha thousand and twenty four dimensionsis higher than doing it with 384um that said i'm not sure if this thissort of text is low dimensional and animage is high dimensional that's stilltrue because for example we're seeingclip and then clip um it's the samevector space so so we're it seems to bevery possible to to compress that uhimage information in a in a relativelylow dimensional vector spaceum but i think it is something to tothink about just in general likeif users or if users are using out ofthe box models then it's something tothink about like do i really need theone that has such high dimensionalitycould i maybe achieve the same thingwith with a lower dimensionality andsame thing for if users are trainingtheir own modelsjust think about think about thedimensionality like do you really needum maybe even 384 which seems to be likethe sweet spot right now for text likehow much performance drop would you haveif you cut that in half because the thethe sort of benefits that you would getfrom an engineering perspective is halfthe memory potentially half it's notentirely linear but potentially half thethe latency like double the throughputof course it's not not yeah not linearin that aspect but still you're going toget better throughput and better uhlatency souh yeah that's maybe maybe a long answerto your question about different datasets like really think about thedimensionality of your data set and ifyou actually need it or if you can maybeget a free speed up by by reducing ityeah quickly the the idea of like howmuch can you compress into the vectorsit kind of reminds me of argumentsaround like you know is intelligencecompressionlike is being able to find the minimumdescription length of a program is thatthe ultimate way of uh havingintelligence and and you know that 384dimension thing is so interesting and uhso quickly i i did later in the podcasti want to go a little more into binarypassage retrieval and i remember ourbroadcast with yuri malkov and hearingabout product quantization and you knowstarting to get a taste of that and imaybe i want to quickly bring up againlocality sensitive hashing and kind ofhow with the problems with that i guessit's not because it's not learnable iswhat i had taken away from you or youknow we could uh rehash that out alittle bit on the podcast a little moreand then that maybe knowledgedistillation to try to compress that butbut kind of what i wanted to step backinto is so i'm i'm a wee v8 user and andi'm coming to these benchmarksso is it the dimensionality of thevectors again the so it sounds like theapproximate nearest neighbor datastructure structures like you know hnswand i really enjoyed uh eric bernardsonhas a blog post series on explaining howannoy works and i highly recommend thatto listeners who areyou know not who are still gettingcaught up as a way of understanding howthe data structures divide the space butso for a new wev8 user coming to the newbenchmarks webpage is that is thedimensionality of the vectors is thatthe key thing that they should look atto compare the benchmarks with theirdata set or is there more to it thanthatuhyes yes and no so um i think it's one ofthe learnings that i did um but i thinkthat the great thing about thisbenchmark page is it'sit tends to be it's basically justinformation and you can interpret in inwhatever way you want and that's alsowhy we use different data sets in thebenchmark so that you could pick the onethat represents your use case uh orclosest and that that gives you i meanthat can help you in different stagesbasically it could be uh prior to usingvva to know what you could expect fromvv8 but it could even be helpful in likea debugging scenario let's say um you'reusing vv8 and you're not getting thekind of performance that you wouldexpectby picking the thedata set that's closest to yours fromthe benchmark list you could say okaylike they were using this specificmachine they were using uh this manyobjects with this many vector dimensionsand they were getting i don't knowmaking this up 5 000 queries per secondthroughput i'm only getting 500 then youhave a very good indication thatsomewhere in in that setup something isgoing wrong and then of course the superinteresting question is like where is itgoing wrong but i thinkuh debugging something is much easier ifyou knowthat you can expect more from it than ifyou're if you're not sure like if you'resaying like this kind of like of the gutfeeling it's it's not as fast as itcould be but what is reasonable and ithink that is one of the the questionsthat we also really wanted to answerwith those benchmarks umgiven these things so so two twoquestions basically given theseparameters this is what you can expectand then the second question is bycomparing the different data sets to oneanother changing these kind ofparameterswhat what would change and and thereyeah as i said before one of the biggestlearnings for me was the that the vectordimensionality is a muchmore impactful than the data set sizewould it be useful to maybe look at likea histogram of distances betweenmaybe you sample five queries and thenyou plot the histogram where say it'slike a gaussian looking thing of youknow what the average distances are tothe data set would that kind of thingimpact the hsw parameters uh yes you areuh raising something super interestingum because i i think i'm not sure ifyou're if you're referring to that butit matches perfectly that uh twitterthreat that we saw from from nielsreimers abouta sort of distribution of vectorof vector points in the space and he wasdoing that in in the context of usingrandom vectors and if you use randomvectorsbasically by definition they'll beevenly distributed there's like everythere's there's no reason that thereshould be clusters or there's no reasonthat um yeah objects are relatively farfrom one another so you see that thatdistribution curve um where basicallyeverything is close and the problem in aneighborhood graph is we i think weinitially talked about this when we wetalked about agents w like it it's basedon that fact um thatif you let's say you want to want tomake a connection from uh someone inflorida usa to frankfurt germany um thenin the best case you might just onlyhave to know one person but that personknows someone there so and this is ithink the the the more common example isum you're just five or six hops or anyperson on earth is five or sixconnections away from from knowingbarack obama or any other uh famousperson in the worldum and that only holds trueif some of those distances are actuallylarge like if iflet's say i know my neighbor and myneighbor i mean physical neighbor and myneighbor knows someone else in the samecity and they know someone else in thesame city then i can do 10 hops and i'mnot anywhere closer from frankfurt toto floridaso it kind of depends on thatthat distribution of objects of havingsort of long enough edges so to speakbecause it's a graphandthat is the problem that if you do um ifyou use random vectorsall distances are going to be equal sohow do you sort of move in the rightdirectionwhere it's closest to you but still farenough that you're actually jumping uhenough distance and there the the superinteresting learning is that if you usean actual data set you kind of get thatnaturally like you're you're notengineering your data set to besort of i don't know to have clustersand have large distances betweenclusters it's just something thathappens like whatever data set you youtake um if it's if it's imagesthere's bound to be some clustering ifit's text there's bound to be some someclustering um so simply by using likein a sense it's simpler than randombecause you feel like maybe i need toengineer this in a specific way wherethe distances are are under control butironically just not doing that and justusingactual data that somehow has a has ameaning on it gives you that perfectdistribution that that works so wellwith these a n indicesby the way also other ones like not notjust agents w i think is a is a famousexample one but if we think of umfor example ivf so so the inverted fileone um same idea basically you you startpartitioning your data set into clustersand then ideally if your search querycan be answered by a single cluster youcan skip the others but exactly the sameproblem here like if you think of of atwo-dimensional space where points arecompletely evenly distributed so youhave like almost like a checkerboardpattern or something where the pointsare basically where the lines intersecthow do you cluster that like is itviable to put that into one cluster thatmatches everything well yes but then youdon't have the benefits of cluster ifyou do four clusterswhere do you draw the lines like everycombination is basically equally as goodwhereas um if these natural like if youhave this natural clustering uh that'swhere these these algorithms umreally benefit from and yeah that wasinteresting to also to also see thatlike you can um if you runum with with random vectors as opposedto like keep all the the the data uh thesame as on an actual data set andbasically try to copy that with randomvectors you can actually get the samekind of speed and throughput but at avery very bad recall and um then justusing the actualbecause and and that's specific toagents w because h w at some point itjust stops the search when it thinksit's it's covered it well enough and uhthe fact is basically that well enoughis just way way worse so i thinksomething uh might be making this up buton on like one million objects of 120a.d i think the difference that we couldsee something like 20 recall with thesame parameters where you would get97 recallwithin with an actual data setinteresting so soto recover that would instead of randomvectors where i guess like the randomprior is that it's going to benormally distributed evenly spaced outif you had um you know algorithmicallygenerated vectors that but therandomness came from like a gaussianprior or bimodal gaussian priori'm now going to reveal that i don'tremember too many probabilitydistributions but i think like poissonthere's like other distributions rightlike would that kind of way ofalgorithmically generating vectorsrecover the properties of real worlddata setsi i think yes like i i don't know whysomeone would go through that effort buti think like assuming that there is away that you could randomly generatedatathat maybe even through trainingsomething that is trained to reproducerandom data that sort of matches thedistribution of something that exists ii think you could get thereum but in the context of benchmarking ithink it's much easier to just use astandard data set basicallyyeah and i'd really like to talk alittle more about uh clustering i thinkso clustering is the key thing hereright like the the just therepresentations of these vectors areclustered and so the algorithms exploitcluster structure in order tofacilitate faster searchand clustering is also kind of i'd readan interesting paper that something likelearning to classify without labelswhereyou basically assign semantic categoriesto clusters and you use that to classifyuh d do you see that as um and i knowalso wev8 has a zero shot classificationbuilt built into it as well how do yousee that like idea of umyou knowlike maybe to provide a little morecontext is i'm in i'm looking into thisidea of doing the twitter analytics withweaviate and so what i'm trying to do iscombine like the usual descriptivestatistics where you look at uhbasically segmenting where you kind oftry to like look at the view count andthe engagement rate and you try to lookat the the way that these two symbolicproperties are distributed and now i'mtrying to add this semantic componentor you can cement you can segment by thesemantic clusters to to do that kind ofsegmenting that data scientists kind ofdo so maybe this question i hope itisn't too broad but how do you thinkabout that idea ofclustering to form semantic categoriesand how that might differ from kind ofthe school of thought aroundsymbolically labeling things and thenfitting classifiers to them to formcategories yeahyeah yeah i thinkit sounds like you're pitching a newcustom module for vb8 so that's that'sreal good yes and i think umthe only step really that we needbecause if we naturally have thoseclusters and we can discover thoseclusters those clusters basically have aa centroid point or a centroid vectorthat represents the cluster so reallythe only thing that we need to do isjump from that centroid to somethingthat can sort of classify it in a way soif we think of the thecontextionary module that we have whichis very primitivekind of it's not a deep learning modelor maybe there's deep learning involvedin the training but in the way that weapply it it's essentially just a lookuplist for words and and vectorsand by having such a simple mechanismyou can easily do it the other wayaround if you have like this might mightbe a viable option if you already havesome data just calculate the centroidvector and just ask the contextionaryassuming it's in the same vector spaceof course as the conjecture be like whatare the nearest words that you know offin thatin that space and then if weand that could be something like thelabel or or something such more complexand then if we think of deep learningmodelsum and and you probably know this waybetter than i do but i could imaginethat that's not too different fromgenerator models right like if a if idon't know you have something like atext summarizer i i could imagine thatyou could tweak that in a way where youjust give it an input vector and tell itto to i don't know create a label orsomething so basically text to vec in inthe opposite way like back to text thatshould be doable rightand yeah i've been i mean i'm prettyobsessed with this idea of prompting andhow the t5 texas text transfertransformer shows that you can kind ofunify all the tasks into languagemodelingand uh so yeah that idea of uhclassifying it like zero shot by havingthe kind of prompting interface and soi've been really curious about uhrecommendation and that kind of thingand maybe do you think thatrecommendation could be also put intothat language modeling framework wherethe prompt is um you knowsay i'm recommending movies and so iwould say uhthe the user is eddie and dilocker helikesdogs and and wine sayand you use that as the inputrepresentation like the prompt and thenand then it like well so and then it theprompt then it goes like so what moviesdo you think eddie and like eddie andliked iron manlike the history of the how they do therecommendation and then you just turn itinto a language modeling problem whereyougenerate the kind of next movie do youthink that kind of thing would work orit's probably too grandiose of a way offormatting the tasknow that i i i think that couldabsolutely work because what i know or isort of have to build this base on whati know is that um we see users usingvector search as the first step of therecommendation pipeline where they usevector search basically just to generatecandidates and then have some otherlogicto to um sort of baselike let's say staying with the movieexample um we're taking the last moviesthat i've watched and then we're nowlooking for for something that's in someway related and related i think doesn'tnecessarily have to mean like becausethis was a comedy this has to be acomedy but it could be could be anythingand and thensort of to to have yeah these otherinputs in there as well i think i couldabsolutely see that sort ofas yeah something that you would eitherdo through through re-ranking which isbasically what our users are alreadydoing by applying theirml logic on on something that'sthat's originally a vector search ormaybe even by by building this into themodel itself basically that yeah thesimilarity search wouldn't necessarilyreturn something that's similar butwould return somethingthatyeah maybe is similar in the sense ofthe user likes this therefore they alsolike this so where the the vectors pagewith space would maybe not so muchrepresent umthe thein the case of movies like the moviesbut maybe the users where you thensearch for similar users or make thesethese these kind of jumps in that spaceyeah one paper i really liked is uh it'sa doctor query and what they do is theyrun a a model that predicts a questiongiven a document so it takes thedocument as input generates a questionand then what it will put into thevector database is that pair ofgenerated question and then the documentso it's kind of like a way of adaptingit to question answering because thenyou kind of have that like lexicalsimilarity sort of with the style ofasking a question so yeah i'm curiousabout that idea ofadding prompts to queries maybe to tohave it go into the space and and thenmaybe the particular applicationrecommendation butmaybe to step out a little bit i'm i'mvery curious about re-ranking it lookslike there's quite a few ways to thinkabout re-ranking and i'd like to startwith uh you know i know you implementedbinary passage retrieval and really gotinto the details of that i'd like totalk about that idea of maybe a coarsegrain stage one retrieval and then amore fine-grained stage two retrievaland whether just with binary passageretrieval as the coarse grain step andthen maybe just re retaining thefloating point values of say the top 5000 retrieved uh candidates and thenhavingit maybe like a brute force searchwithin that second stage or some otherthing how do you think about these likemulti-stage refining pipelines maybeyeah yeah i think there's almost no wayaround them becauseif you so so bpr i think is or themotivation behind bpr is basicallyuh performance and or sort of memorycosts by by uh originally searchingthrough these compressed vectors umthe goal is then to to yeah sort of havea smaller vector space and thereforesmaller resource requirements um andthen the re-ranking is only to get backto the original quality um but i thinkre-ranking has much more potential thanjust sort of uhyeah sort of improving upon the loss ofof compressionby producing something that's actuallybetter and like in the simplest sensecould be for example re-ranking uhbased on keyword matching so so let'ssay you have auh event so the typical problem here ofthese pre-trained for example sentencetransformer models isthey are great on general purpose databut the closer that you move to umdomain-specific data that they haven'tbeen trained onthe worse they become one way of courseis tofine-tune them but that's maybe notalways an option so for example ifsomeone who's notfrom the ml space just wants anout-of-the-box solution that worksokayish then fine-tuning may not be anoption because they've maybe nevertrained the model before and don't evenwant to want to get into thatand then let's say we have a case wherewe have a model that's generally quiteokay so let's saye-commerceyou search for for a brand name and likewinnerapparel or something and then it mightbe really good to to make thatconnection from like winter apparel tolet's say a jacketum but it's it's very bad at matchingthat to the brand name that was actuallyin there so let's say you have nikeadidas whatever in the search query andthen the model almost ignores that uh soif the original candidate selection wasgood enoughthen you could even re-rank this withsomething super primitive such as bm25which is basically just keyword matchinguhthe the problem here is of course ifthose matches weren't in there like ifyou you can only ever re-rank basicallywhat was already matched so i think youneed to be in a situation where thematches were good enough but you maybedon't necessarily agree with the orderso like the i don't know top 200 onesare goodbut you can really only recommend oneout of those top 200 and you don't agreewith with the order within those top 200and i think that's where re-rankingreally shines yeah that's a reallyinteresting flow of um you have say thethe wikipedia sentence trained sentencetransformer that can do like pretty youknow semantics similarity cover a prettymassive distribution of text and thenonce you get like the top 5000 now youhave the bm25 lexical style re-rankingwhich what are the you know like becauseyou want the exact term and we talkabout things like serendipitousdiscovery with respect to how peoplereally interpret what's returned from avector search engine and that kind offuzzy distance and that makes a lot ofsense to me and i'm also thinking aboutthis idea of say pairwise classifiersand personalization so we have um youknow eddie and connor and we'rerecommending movies would we have youknow we could re-rank this list byhaving some kind of label data set wherewe havepairs of movies eddie and chooses moviea then you know we show eddie in movie ceddie and chooses movie e and then youuse the pairwise thing to do there-ranking what do you think about thatkind of approach to ityeah just i i really i think the the thegreat way of reranking is that you canre-rank on on anything really like ifyou have the initial list umanything basically that you can trainsomething on i think that's that's youyou can re-rank based on it and maybeevento go outside of the the space of umof machine learning itself it could alsojust be some simple business logic let'ssay to sort of stick with the e-commerceexample againit might be that the shop is notnecessarily interested inuh presenting the best match but maybein what they have the highest margin onso it could be like that you put inthese these completely different wherewe tell the the the um out of the box uhyeah trained on wikipedia data like howis that model supposed to know that ifthey sell let's say nike over adidasthat they get a higher margin um butthrough re-ranking i think you canreally sort of yeah put potentially inand whether this is this could besomething as simple as if brand equalsnike then plus two or something or itcould be like this complex model that'sbasically learned that um yeah if wesell nike shoes in summer then umourbottom line sort of improves and um thatdeviates a bit from your originalquestion about pairwise ranking um but ithink it's sort of what i want to conveyis basically that that anything goesyeah that's one of my favorite thingsabout the vector search engine and we'veeaten studying weave it is the way thatit can plug in symbolic algorithms withthe neural retrieval you have likesymbolic ordering of how you thenprocess the neural algorithm and i lovethe playing of those two algorithms andi think that's a really nice transitionto what i wanted to talk to you aboutnext and you know i recently had theopportunity it was such a great time toattend the knowledge graph conference innew york with laura andsee laura's presentation on questionanswering watch the room reacting to andit was really just such an incredibleexperience to see and i really wanted toget your perspective on semantic webontologies andunderstand how you think about thesekind of thingsso sofor for me i think this this ties verywell into into the previous questionbecause umlike i i see myself and my role a bitmore inenabling the platform to then buildthese kind of use cases on top so so i idon't think i'm an expert on knowledgegraphs um but i might well be an experton uh sort ofproviding the platform that you need tosearch through through knowledge graphsand umyeah i ii almost like that i i don't have a goodanswer on on the knowledge like i youyou were part of the knowledge craftconference you can tell me probably alot about what was going on there and ii wouldn't even know so i i really likethis that that it's in a sense vv8 is soso general purpose so to speak like it'sgood at specific things but still it'sso so general purpose that there's sucha wide variety of like yeah frome-commerce to to knowledge graph to tomove your recommendation it's likealmost feels like the base of anythingthat you want to do in in that space inthe futureyeah the the class property design ofwva where you can have these crossreferences between different classes i'mstarting to see how kind of like iperceive as elegant this abstraction isthat i've seen like in our we've eightslack uh someone had asked you know howdo i encode multiple languages and bobhad responded you could have a crosscross-reference that links between thetwo languages as different classes so isee that as a way to do say likemultimodal image text where you canhave a cross-reference to the otherimage as well as this kind of ontologyrelation style where you sayuh connor is an employee of semitechnologies uh isuh uh is a business category vectorsergeantyou know like these this kind of way ofrelation style i think it's such aninteresting thing and then within eachthing you have these uh h sw indexstructures within each class so kind oflike a quick clarifying question so eachclass gets gets a approximate nearestneighbordata structure correct correct so thatthe class is essentially like anamespace or in in my sql world i thinkit's called databases so where you havethe whole database and you haveindividual databases andum yeah in kubernetes you would call ita namespace um so yeah it's really thethe unit of isolation basicallyumso so what so in one we've eightinstance i could have say three h and swindexes for the threevery cool yeah i think that's such aninteresting part of it anddoing that kind of linking uh is reallyjust one of the topics that isinteresting to me the most right nowdefinitelyand um so so maybe transitioning fromthe uh knowledge graph thing and it's abit jumping to a different topic butso i wanted to ask about we va custommodules and if you could tell me a bitmore about what it takes to extend oneof the modules withuh with a with it it seems like to me ifyou want to say point touh anothersay hugging face model path you you lookat this like python inference containerand i'm sorry this question is kind ofgoing around the place for our listenersbut maybe could you start with theunderstanding of wev8 core and then likethe python inference containers yes yesabsolutely sovb8 core in itself is a vector searchengine basically that means vva does notunderstand anything but vectors and thethe objects that are attached to thatvector so often called metadata i don'tthink we use that term but it's it'svery commonly used in the spaceand and of course the whole object has alot of complexity around it as well withdifferent data types but essentially thethe idea is that if you use vv8 withoutany modules vva doesn't actuallyunderstand how to go from let's say textor image or any of the those to to thatso if you use for example the the neartext in the api uh you need to provide amodule thatbasically does that translation and umyeahone of the ways uh to use sort of acustom module i think there areseveral levels sort of off ofabstraction or not not maybe ofabstraction but of how deep in the stackdo you want to go to createsuch a a custom module and as youalready mentioned starting withsomething existingcan be super helpful so for examplestarting with the we have the texteffect transformers module and the pointof that is basically this textvac uhtranslation so if you use this um allyour objects that you import will beturned into or will be vectorized andthe the vector will bestored in an index in the hmsw index umand the same is true at query time soessentially you can use vv8 like atraditional search engine that supportstext now and of course if you add animage module it would be same for forimage sowhat that does um this module isbasicallyit extends vvate a tiny bit um in asense that it tells vba okay now youwill have a near text search operatorfor example because that's that's notpart of like it's not that it'sthere in vv8 core but you can't use itand now you need a module it's just it'sjust not there if there's no module sothis is sort of and and this is i thinkthe the extreme strength of that modulesystem that any new module could extendvba in any way that we can't evenimagine yet and and um basically yeahyou have this small piece of codein vv8 itself i guess or closely runningin v8 core like it would from from anengineering perspective would run aspart of the same like it would be aplug-in that runs as part of the sameprocess that vba is but then what thatsmall piece of code can do is it canjust send requests to something else sohere this you you mentioned the thepytorch inference container here theidea is that a vector search engine hasvery very different requirements from afrom a resource and a resource andinfrastructure perspective than let'ssay model inference so the idea is thatyou split that out so basically a microservice pattern we split that out andvva that that does vector searchcomparison which is most likely cpubound ummakes that network request to somethingelse which could for example run a modelthat's running uh on a gpu like thesedeep learning models they tend to runvery well on gpu or there are alsoefforts to optimize them for differentcpus but typically they run well on ongpus so what you can doin that journey basically is i thinkthree different parts to to come up witha custom module the first one would beyou take that inference container thatexisting inference container that'sbuilt for uh for transformer models andyou simply run it with a different modelso you could let's say download a modelfrom from hugging phase or you couldhave a locally compiled model and aslong as and there there are instructionshow to do that uh in our documentationas long as you get that new model insideof that container you can reuseeverything there so in a sense you couldcall this a custom module alreadybecause it's something that wasn't thereout of the box you have now your i don'tknow fine-tuned model therethe second step is you could saythe use case that i want to do is thesame i still need text to vecbut my model architecture is sodifferent that i can't use the pie torchcontainer anymore so for example uhsomething completely new comes up somesome new way of of running a model or itcould be um maybe not something new itcould be like like onyx or these uh sortof optimized compiled models that simplyhave a different architecture what youcan do in this case is sayi want to keep the part in vva thatcontrols the api because my api is stillgoing to befrom text to vec and i'm still usingthis near text umyeah near text search parameterbasically but how that's done like theimplementation is completely replacedand that would be sort of at the at themicro service level where we're nowsaying we're simply replacing onemicroservice with another and the onlything that needs to match is the api aslong as this api contract between bb8and umand uh the inference container is upheldyou can entirely replace it you can dowhatever you want and i think this ismore commonly something that peoplewould start calling a custom modulebut then if there's a third option sothe third option iswhat if we want to for example support acompletely different media type so letme think of one that we currently don'tsupport so let's say audio to that youwant to start with audio too like thatmeans you can't just replace theinference container that does text tovec because of course the the interfaceis yeah it takes text and you now need acompletely new api you need to to get umanswer if that thataudio part in it i don't know let's sayfor the sake of argument you would justupload an mp3 file or something likethat umand for that you actually need to changethe entire chain of the module sobasicallyyou need to change that part thatextends the vba api so basically theplug-in that runs in the same processand then most likely you would still runwith some sort of an inference containerbut that's that's actually not part ofthe module system that's that'sbasically just a convention that theexisting modules use so you could um ifit's not needed you could run it insidethe plugin directly and never have thatsplit out microservice or you could sayprobably a bad example for for audio toevent but for the sake of argument let'ssayyou need three steps and you need threedifferent models let's say onei don't know one cleans the audio thenext one uhsort of cuts it into chunks and then thethird service actually vectorizes somade up pipeline but if that was yourpipeline you could spin up threecontainers for example and that i thinkis really the strength of the modulesystem thatin the end it's just a tiny piece of ofof plug-in code that extends the vv8 apiand then can do whatever it wants withthat api and that gives you these threelevels basically of of hooking into itand integrating uh something custom intoityeah that's super i i think theextensibility of that is superinteresting and i i do think there's abit to impact and i i'm really impressedwith the uh google summer of codeinitiative in the we vva projects thati'm seeing and the titles of them soundkind of like this thing like the idea ofuh you knowmaybe just adding a new hug and facemodule and understanding how to do it orhow to add audio to vec but if we couldif you maybe take me through you know iwant to add let's say i want to add anew tokenizer and i want to add a newhugging face module would i need topull request text event transformers addin my two things and then uh and thenpush it back to the main uh github thinguh yeah yeah essentially if you want itso so the the uh sort of pushing it backpoint would mean um that you wouldrelease it for everyoneumthat's one option another option wouldalso be that you have something privatethat you don't want to release back tothe community soin either way i think you woulduh so so for the for the first one whereyou want to release it you woulddefinitely have tofork it issue a pull request and withthe pull request is merged then it couldbe available for for everyoneum if you do it privatelyuh there is sort of asmoother process for this where you umdo this at the docker level wherebasically when you do a docker build ithink there's one environment variablewhere you can put in the hugging phaseuh a url string so umthe the uh hugging phase bundles up themodel yeah the models with their theirtokenizer and everything like underunder one string right that looks a bitlike a like a github repo and yeahorganization and repo and if you i thinkwe have these uh docker files where youjust put in exactly that string and ifit exists and if it's accessible then itwill download it and sort of build thatin your container um so yeah if you ifyou don't plan on unpublishing it if youonly plan on using it you can even takethat stuff but if you want to publish itthen the pull request would be the rightyeah that's so interesting for me uhtrying to get deeper into weaving it andtrying to really understand it and forme i'm a little scared of things like uhdocker files and go and i've been tryingto just like you know roll up my sleevesand get into the details of it but itdoes feel pretty accessible the dockercontainers that i think there's a bit ofa learning curve for it if you'retotallynothing but i do think that it's prettyaccessible andso great i think that was a really greatuh recap of a bunch of different topicsthat i wanted to ask you about andmaybe any closing thoughts on theapproximate nearest neighbor benchmarksand changes to the website and helpingpeople understand uh how to configuretheir h sw through the use of thesebenchmarksyeah i would say first of all check thebenchmarks that's that's the mostinteresting thing like look at them beconvinced that that bb-8 can match yourperformance goals and then share thebenchmarks that's of course also superinteresting for usto to spread the words umyeah and and uh everything in thebenchmark oh yeah that is something thati actually haven't mentioned yeteverything in there is open source umour intention is that that you canreproduce like we're very transparentabout every single step that we do inthere we we ran those uh on a singlemachine we ran bb-8 on a single machinein uh gcp that was i think a c2 standard30 or something it's it's in the articleum and we ran uh the benchmark script ona separate machine which was justsort of best practice for forbenchmarking like you don't want yourbenchmark script and your servercompeting for the same resource and wesplit that out into onto two differentmachines umand uh the the repository to to importeverything to run all the scripts uh toto compile everything down to uh the thegraphs that we're showing in the articleall of it is open source so if you thinkwe made a mistake or if uh you think wewe yeah in either direction basically umif you think we're we're you know doingsomething that that shows numbers thatare too good or we're not optimizingsomething um it's open source everyonecan contribute and i think that thatwould be my my key message thereyeah super cool it seems so excitingdeveloping all the benchmarks and havingall the research and the science thereproducibility that comes out of havingopen source reproducible benchmarks sothank you so much eddie and i reallyenjoyed this vba podcast i'm learning somuch about we've got i really love thistopic andthings we discussed like the classproperty referencing i think all this isjust so interestingawesome thank you thanks for having metime went by very quickly it was anice one thank you[Music]", "type": "Video", "name": "Etienne Dilocker on ANN Benchmarks - Weaviate podcast #16", "path": "", "link": "https://www.youtube.com/watch?v=kG3ji89AFyQ", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}