{"text": "Hey everyone, thank you so much for watching the Weaviate podcast! I am so excited about this episode! ChatArena is a software ... \nhey everyone thank you so much forchecking out the weba podcast I'm superexcited about our latest guests we haveyushang Wu a PhD student at UCL who'sformerly been interned at the EllenInstitute meta Ai and yushing hasproduced one of the most interestinglibraries around this kind of future oflarge language models where they talk toeach other and I think this is such aninteresting topic so firstly you Shanethank you so much for joining thepodcastthank you Conan thank you for having mehere awesome so this chat Arena that'sthe big uh the title of the podcast andthe thumbnail uh so can you dive intothe origin story and what it's aboutyeah so Channel started as a smallresearch tool that I built over aweekend and I was struck by this idea ofhaving multiple chat gpts to talk toeach other because that would be reallycool if say each chat GPT would play adifferent role right and we may be ableto create a really interestingconversations so normally how we woulddo that is that well we could open twoChachi PT like web pages one on the leftone on the right and we copy and pastebetween their like responses rightthat's just going to be like reallytedious work so I would say when the APchild gbt API came out would say waitthere is something that's really goodreally cool that we can do here rightlike soand then I'll just like build this likea small demo uh over the weekend and Ishow it to researchers around me andthey're very excited well with this newtool so we quickly expand this projectinto a more well-designed anduser-friendly package for developing allsorts of multi-aging language games sonow it's supporting not just chat gbtbut all a lot of like a large languagemodel apis and also we could Define orcreate different in language gameenvironments with this package soroughly a month ago we released thisthrough publicly and since then we'vebeen released uh receiving lots offeedbacks from our researchers arounddevelopers and Industrial partners andthis package is still like Fast evolvingand we're really excited with like whatwe can build upon thisyeah and I think maybe before we diveinto the technical detail and thenuances a little more just setting thestage of um you know like chat like kindof what you and I hope to achieve rightnow is that um you know in conversationwe can explore some new knowledge and umso maybe if we could talk a bit abouthow this works you you sort of wouldprompt one language model to say be LexFriedman and another one to be SamAltman and then they talk to each otherplaying these roles is is that kind ofthe general setup of we have like roleswhether you're impersonating a personyeah yeah indeed uh so you could startwith say setting the c or this stage forthe players by specifying what we callenvironment description or Global promptthis description would describe theenvironment or the scenario that theseplayers will be acting in so for exampleif you want to set up a like a podcastbetween like scripman and Sam Altman yousay well you are now participating in apodcast andwhat is generally in a podcast is thatthere is a interviewer or the host andthe guest and the host is next Fruitlandthe guest is Sam Altman and you maystart with introducing yourself so thisis kind of a description of the scenarioand then for each of the players oragents in this environmentyou give their specific prompts so yougive you tell one of the agents or youare next you'll be acting as nextfrittman and this is something aboutnext treatment so you may give it a bioof extreme learning his interests or hislike previous podcaststopics and then for another agent yougive a Sam Altman his bio and his latestupdates for example right so and thenthis would said that we just set thescene and then we just let it run so allyou need to do is just tell these modelsscenario they are in and what theyshould be acting as and the rest wouldbe our child Arena handles all theunderlying like mechanisms sayprompting and querying cha GPT handlingall the communication managing all thestatus like the game state for exampleso those things can be similarseamlessly handled so that's the kind ofa general use case obviously yeah I'm soexcited to dive into the what makes thisa game a bit more but first I want tosay a little more about maybe we talk abit more about the retrieval augmentedprompting I think our weeviate listenerswould be very curious about like what aweeviate system design looks like and sokind of as a fun project I've been doingis I take these podcasts and Itranscribe them with whisper and I putthem into Eva and so I'm curious if youthink like um like say we have one uhdatabase class that contains all podcasttranscriptions and it has a symbolicfilter for speaker maybe also a symbolicfilter for which particular podcast it'ssampled from and so you could have thatuh like a symbolic wear filter on top ofvector search for when you're retrievingfrom Connor shorten to prompt thelanguage model to say like you saidthings like this in the past what do youthink about that kind of system designfor how you tell how you really make thelanguage model like you know to take myideas so to sayyeah well that's actually a veryinteresting question like having thiskind of long-term memory right like asyou said that these since that you havelike past podcast episodes are likelike it's clearly going to exceed theGPT even GPT Force like memory lengthright so maybe one way it should do itright is you havingat the player levelyou could give it this database as youuh as you mentioned and then at theunderlying when it's say in the processof the podcast and it dilemma thequeries that database and say well forexample when we are talking about say AIsafety for example I'm sure that lackstreet but no like your your podcastwill have lots of mention to that andthen you just dynamically and advertlysearch that database and find out whatyourtake what what's your stance in thistopic in general and then that couldsummarize ithaving some kind of like a summarizationmodel to summarize kind of your take andthen that will feedback to your agent orplayers so I thinkthere is a lotwe provide a lot of flexibility on theplayer side that you could incorporatevery complex mechanism into the playerso it's not just like say uh justcalling open AI chat gbt apis and infact you could Define and create anylike kind of program and as long as thatjust satisfy the interface and thatunderlying program can handle all yourlike long historiesand and an oil past experience so I feelthat that's aone way to implement what you uh whatyou have in mindyeah that kind of chat history thing I'mit's so interesting to see what'shappening with that even just with thethe chat gbt interface as it is um OneMore Concept I'm curious your opinionsare uh we're kind of trying to Pioneerthis term generative feedback loops thatroughly describes the idea of generallyyou retrieve from a database to promptinject into the large language model andthen you save that generated result backin the database and you know thatcontinues on and on and things like whatwe're talking about where their agentsare talking to each other because I canimagine like um like from ourconversation now I expect to leave witha new stance on multi-agent largelanguage model chat games so it's likewhen they have these conversations rightthey should save their their stances andkind of but so then you need to likeupdate the stances is it is it clearthis kind of concept like that like soyeah what do you think about that kindof like the evolution of is you startoff with your um you know Sam Altman thebeginning of all everything he said onthe free podcast ever and then and thensimulate thousands of conversations andnow you kind of develop like this halfartificial half real or whatever thejust composition of the takes yeah yeahI think that's actually really excitingDirection indeed like having thisfeedback loop and then modify its likememory right like modified its kind ofstatus and this keep evolving right thiskind of like self so I think this isactually really one of thestrength of having Ai and AI to interactwith each other is that they couldsimulate first of all you needed thisenvironment for them to to interact inright and then once you have it like youcould have simulated loads of loads oflike interactions between them and thenthey could keep evolving and improvingtheir strategyand up updating their history and inthose same in another way it's updatingtheir policy as well so in areinforcement learning sense right thisis improving their policies kind of likealphago in a sense that by self-playingthat it improve it's like it's goplaying a strategy so I guess in thesame way that you could do it inlanguage games as well andin the same way as you said like thereare different localisms to in toincorporate this kind of uh histories orexperience from the past maybecompressing them and then into into somesort of vectors and then that will helpimprovingfuture of future strategiesyeah well I think the all theself-improvement it's it's kind of liketeacher student knowledge distillationand or like just that whole idea of kindofyeah reinforce like uh two agents talkto each other maybe a third one judgesit I think actually before I even pickyour brain more about how the policyimproves and whether there's continuallearning in this kind of system can wemaybe set the stage for the the gamelike the moderated uh system chat Ithink it's called could you explain likehow the game is set upyeah so in that environment I think thisis one of the most novel part of chatarena is that it provides a LOM as partof the environmentso maybe I could record back to what youwere saying in the kind of likeimproving sense like self-improvementkind of sense is that you may have onemoderator in the environment that'sgoing to achievegive you feedbacks when you areinteracting when you're playing in thisgame right and then with that feedbackand by the way this feedback isgenerated by another larger probablylarger LOM and andin that sense you may improve yourstrategy but this is just only one wayto use moderator conversation so but ingeneral this is just like this is a verygeneral purpose environment that theEnviro the game transition is no longermaintained by some fixed program thatdetermines the program or someheuristics but rather it's bya hybrid system with a llm insideso with this the strength of thiscom this combination is that you couldDefine very like flexible and open-endedenvironments so say for example likeuh AI dungeon for example like it couldhave a dungeon master so having an llmto play as a dungeon master and the gametransition right isdetermined by this like gpt48 model thathas really good understanding of thegame dynamics of pungent andthat would allow you to to like creategames that's not possible before andthis is one use case and I could imaginelike there's lots of use cases that youcould use this for for so I guesswe have to be involved I I think I'mlimited in terms of the imagination tobe honest so that's why we release itand and we asked like we really welcomelike our users to create their own andbe imaginative and share their like kindof games that they're creatingit it I I think I see two things herewith there's kind of like theopen-endedness discussion generallywhere I think uh there's like that workfrom Jeff Clune Kenneth Stanley andtheir teams around um you know likethere was the poet algorithm which islike bipedal walking agents with uhdifferent environment terrains andyou're trying to like have an open-endedexploration of the terrains you walk onand then they did this with Minecraftwhere it's like you know just go try toexplore it it so I think we could comeback to that kind of like connection tothe expiration part of reinforce andlearning but um this kind of concept oflike language only games I'm verycaptivated by this and what you'resaying like with the um sort of like theAI dungeon thing where the moderatorlike proposes the transitions in thegame but I kind of want to if we couldjust stay a little more on this kind oflike we're having a podcast or likethere was this like there's like thisSports Talk Show where there's like fourguys there were men and women and thenuh in the grid and they kind of likeeach have 30 seconds to like make asmany points as they can about like theCeltics game or something and they andthey like score their points is thatkind of like like so you know it's likemy agent your agent Sam Altman's agentand you know let's say Elias tutskiversagent and we each get like you knowthree paragraphs to make points aboutmulti-agent RL is that like the kind ofgame that might lead tolike some intelligent artifacts sort ofbeing produced by itI think that's totally possible indeedlike uhbut I guess that's having agents somoderator is a special kind of agentthat's sitting on top of all the playersso I guess one difference that we wantto emphasize with this moderativeconversation is that moderator is kindof like a super agent it's kind of likethe root user in Linux that it couldcontrol the on like the game Dynamicsand it could do things that likenormally normal players can't forexample it could terminate again itcould choose who to speak next or it mayeven kick out like one of the playerslike not behaving properly right likesyou may imagine that the game that youwere talking about like maybe there isthis kind of this moderator or the hostof that show for example that he has theprivilege actually or she has thatprivilege to uh to to do like certainthingsthat's fascinating and I think there'skind of two angles I'd like to stay onthis moderator concept the first ofwhich is scientific literaturescientific reviewing and the peer reviewprocess I'm sure as a PhD studentan awesome time with that but likeum as we see like oh obviously like witharchive it's already kind of giving usan example of what this looks like withhumans who can just upload blogs dressedup as research papers and then prettysoon probably the language models willbe able to do this like just generatethings so we probably need some kind ofreview system in place and I I don'tknow if it could just be like a likebecause I don't think it can just belike a classifier trained on you knowiclr versus anything else so do youthink maybe this system could be like asolution to say scientific uh peerreviewwell I think it could be but I would bevery cautious if like we are using so Iwould insist that like like I don't wantmy papers to determine buy a gpt4because that could it's because you maybe able to if you know that like it'sgpt4 anything that could be it could beeasily a hacked or somewhere like butI think on the up on on the on the likepositive side I think it could at leastalleviate a lot of like reviewingburdens butumbecause like me also being like areviewer for like lots of conferencesand like I I feel that pain too like I'msure that's the area chair or PCS rightthey will have like even more loads onthem to determine that so having thissort of systems maybe one like maybemaybe helpful to to reviewing systemsand I could imagine this is not just beuseful for reviewing but say ma likemarking right like I do some liketeaching assistant like remarks sayhundreds of like assignments andit could help it could be helpful tojust toto do some sort of thingsumI guess one way that chat Arena could beuseful insay reviewing systemscould be that you could create likedifferentreviewers from different backgrounds andhaving them to havelike abundant discussion so you know howdifficultto discussyeah right right so but if you couldhave say like AIS but like maybemoderate like of course you have tomoderate them like but then you havemoderate a conversation between these AIreviews you could have really goodconversations and discussions of that ofa submission and thenyou may actually come up with a morelike a more balanced and a morecomprehensive reviewif that makes sense no yeah that I lovethat uh sorryI love that perspective it's like um youknow like instead of it the the like inthe review process they'll like nitpicksome subtle detail or maybe theiropinion about it and maybe the chatarena is saying you know you argue forthe paper you are you against it basedon this reason and thenthey go at it and then the moderatorsays reject except kind of I think yeahthat kind of thing I think is veryfascinating and then so then the otherthing you said about the the Linuxexample is another thing I think thiswill be extremely impactful for is kindof like the code like the codeapplication domain where you know you'remaking pull requests and there's a themoderator is sort of like the uh lookingat the architecture the themaintainability of this code and so andI mean that is the this concept of likelarge language models becauseI think the other thing about whenyou're doing the code thing and and itdoesn't quite exactly map to the chatArena thing because I think they canwrite some code and then they can chainthe code output into python or whateverto test it and then see that it works sojust that one little tool use thing thatI think is in the middle of these kindof systems butyeah what do you think about thisGeneral kind of thing of like chat Arenabut for pull requests and uh like amaster of the Repositorycould be actually really like reallyuseful like case application likeyou could have likeumI may see in this way uh so for exampleyou may haveum a moderator let's just say oh well Ihave some sort of umarequirement that I need to implementright and then it just gives it to wellit manages this kind of a workspace andthen we and then you may have likedifferent agents or code like toimplement different parts of it and theywould you may ask them to likework together like by pull requests andthen there are like tests you need somebut some some major May write the unittests the other agent May write the codeitself and then they may end upand then all the moderators isdoing is just check whether this theproduced code like the repository canend up satisfying all the requirementsandbut I I think there is a lot to do herelike it's very it's way more complexthan that like you may have to do allthe kind of unit tests but alsointegration tests like having puttingall the different components togetherandumand version management like so lots ofdependencies[Music]umbut yeah I I don't think this is kind ofa a very like aone of probably one of the mostpotential like the use case that has themost potentialyeah let me so I think kind of atransition topic for I think people outthere hopefully are starting to thinkabout a certainly understand thisconcept of role-playing large languagemodels that chat with each other and aremoderated them let's talk about scalingthis out like how many agents are wetalking aboutyeahso theoretically this is like the thepackage supports like almost infinitenumber as long as the as long as theylike length the it fits the kind of likecontext nav of the large language modelright so butwe do found out that like at least thecurrent ROMsare very are still Limited in terms ofwhat we call agencysowhen we scale out like the having toomany number of players in an environmentthey may be find it hard to rememberwhat their own role because I think thecontextness would be like populated bythe things that the other agents savedand the natural thing is that they wouldthey it's very easy that they forgotlike like like what what their whattheir role they are assigned to so Ithink that means that there are twoaspects in this in this question likeone is on the LOM or on the agent itselfwhether it has that kind of capabilityto adapt to to play in thislike large number for for this big groupof eight of AIS and the second ishow well does your environment supportthe scalingso some games for example may not bevery like uh like like like suitable forscaling for example tic-tac-toe rightthat's just only two things you can'tfit three players certain games willhave the kind of upper limit so whichcomes to the second question is how dowe defined in game environments that'sgoing tosupport or at least would benefit fromscaling number of Agents hmmyeah I mean it's it's so fascinatinglike I can't even just think like aboutlike a company and like you know saylike we V8 the experience that I've hadit's like as it's grown like I joined at11 people and now I think it's aboutlike 28 and growing and it's like yousee the the roles what what is it whatconstitutes being a job evolves overtime like someone who just maintains theclients or the modules maybe someparticular climate just that kind ofevolution and it's not it's not justlike you have as many agents as you canfit right from the start because that'sprobably not the best way to do thisrole based multi-agent uh system uh yeahso that's so fascinating I'm reallycurious like um what led you to thiswere were you studying multi-agingsystems alreadyso this is actually a really fascinatingtopic like because like me ML andalcohol like core developers and we geta lot of feedback from UCL dog Groupwhich they like study a lot ofmulti-aging IR problems and continuouscontrol and all kind of RL problems andso so this is really fascinating areaandthe question is whetherI do think like that we still need tocreate that kind of environment thatso the real world scenario it's likeit's hyper complex and the task it'ssolving is also like very complex like acompany that like so like a revert likethe product that you're building and allthere are so many rows and so many likerequirements right whereas the kind ofgames that RL area is not studying isstill relatively toilish right in a waythat's it's like they're all in similarenvironments and soI guess the questionso right in chaturina I think one thingis that we do want to tackle the kind ofthis chat this Challenge and see whetherwe could createenvironments that could fit more agentsand because that part is the scalabilitypart is actuallythe more interesting scientific questionhere andwhich also comes with a lot ofchallenges thatwe do found that these current AI I meaneven the largest uhms like gpt4would often fall short in handlingagency in such environmentsnot a known could never known likecollaborating and finding the optimalstrategy in in in this in theseenvironments so I feel that there's alot to do inunderstanding how LM behave in thislarge scale I mean like large group uhAI environment andI feel that this is still around thevery early stage so child arena is atthe moment is just wanting to buildenvironments and that would be the firststep to exploremulti-agent RL problems for llmsumyeah I mean that it's so fascinatingthat marriage of multi-agent RL with thecapabilities of the large languagemodels and yeah when I when I also firstcame across multi-agent reinforcedlearning it was mostly you know likevery simple grid World kind ofenvironments and now we're seeing thethis open-endedness enabled by largelanguage models is yeah it's it's reallyinspiring and umyeah I I guessum I I wanted to kind of do a long rangereference to something you said earlierabout alphago I think this is veryfascinating because of um like alphagothe way it works is it uh takes you knowit takes the board State as input and itpredicts an action that's like theneural network policy part but then whatthey do is they add a uh like a MonteCarlo tree search on top of that whereyou know you you make your move then yousend me then you you know sample likefour different moves and then you make amove on all those let me do the tree topdown but if you see me but like you knowyou simulate all these games and thenwhen you're at the leaf nodes you'relike the moderator in this case wouldsay like this conversation path becauseit's like right now in our conversationit's like there are different things Icould say to you to continue ourconversation I could say like let's goback to talking about you know continuallearning in this or let's talk about llmproviders like I have all thesedecisions of like as as we're chattingthen the next thing I could say right soso will this tree search thing besomething that because I I understandthat that tree search thing is likeParamount to the success of alphagoyeah well I feel that this is one thingif not the biggest thing that's lackingin lom's is that they don't have thisresearch and planning planning aheadright like so looking ahead this kind ofcapability is really lacking because sojust as an example we when I play thetic-tac-toe in chat Arena right you havetwoto gpts and the the first player wouldlike place the like at the place thetheir bark at the center of thetic-tac-toe board so that's that's areasonable actionbut then they start to just likerandomly putting their their marks likethere's you don't really see that sortof like a planning and the incentive towinlike to connect three three marks rightso but I would say if any like if thelrm has any capability that to doMCTS right and to do something lookahead right it would be able to figureout that which place is the like it isit's the optimal or at least better likea place to play their Mark to right sowhich I feel that this is actuallysomething that's really like lacking inllms if they want if we want to get tothem todo really well in say in not justtic-tac-toe but any sort of game RealWorld games that read that requiresplanning ahead for example we may wantto likeschedules and meetings in the in theweeks ahead and we may need to like movethings around like that sort of thingslike oh how would I if I would bewhat would I lose if I if I if I don'tgo to this conference or yeah that otherconference right this kind of real lifeplanning thing although I would saydegenerative agent paper that you refertothat shows some early that primitivebehaviors on planning a party or kind ofthing but that is like abut that is still like like veryprimitive and doesn't have the kind ofsearch required that kind of search kindof thing soI feel that this part is reallyfascinating uh area Icould imagine that these there are theselike I'm open AI orthese big Tech like big this Lancompanies may be looking at the intothis because it seems to be a naturalmove as and also open AI is like theydid a lot of Il right and dmont did alot of IO so I didn't feel that it'snatural that they in the next generationof ROMs they may put this sort ofmechanism into your armsyeah and I think um I think the term thethe research area that we're gettinginto now is model-based reinforcementlearning and and maybe maybe some peoplewould like to call that theory of mindif it's purely we're talking about aconversation but like model basedreinforcement learning roughly describesbeing able to predict uh Statetransition state action transitions tothe next state maybe reward potentiallysome sometimes they set it up that waysometimes they don't but it's like umyeah it's so fascinating what you'resaying because with the tic-tac-toeexample it's like when I put my circlein the middle of the board the otheragent has to have some policy of wherethey're going to put their EX for me tostart doing this tree search and withthe with me trying to tree search aconversation I need to have a good modelof like what you're going to say next inorder for me to really see like whereare all these conversation topics wouldend up taking us at the very end yeahyeah oh wow yeah I meanso much excitingyeah the modeling part I feel thatthat's also just fascinating that onething that I found in somein the conversation kind of environmentlike having into like creating podcastsI feel that it kind of demonstratesstart to demonstrate this Behavior bylike say if you are giving like thepodcast like the hostthe bile of their guest they are morelikely to produce more betterconversations right so which I feel thatthat suggests that makes it indicatethat it is possible like modeling likehaving this like model based style ispossible butis it good enough at the moment I don'tknow and I my take is that we still needto improve on this aspect like not justbypromptingbut really training optimizing our irmstoumto learn that kind of behavioryeah if I doing another long-rangereference is kind of like generativefeedback loop concept kind of the ideaslike um so in the database I have uh youknow all of my papers I publish all thepapers you've published and and I'm andI'm using it to sync up questions to askin the podcast and then I save thosequestions back to the database so that Ican retrieve those questions forprompting when needed so like you knowwe're chattingand maybe I need to like have like thethree Mo the three best transitions sendinto questionsjust like these kind of this kind oflike offline computation you can do toprepare and then have it and then haveit there for when you when you wouldneed that kind of thing but but stuffthat wasn't already in the database likeif I you know upload this podcast uh thepodcast I can summarize it maybe doingone of these like chunk by chunk kind ofiterative refining prompts or somethingbut I like process the data and createartifacts that I then can reference tocause the language model to actuallycontinue playing the role like stayfocused on what it's doing so let me askabout uh maybe as this I am veryimpressed by the large language modelsbut do you have any cynicism in theirability to maintain a roleso I thinkwhen I play with Chad Arena likemy take is that it's like it'sthere are two things like one thing isthatso for some models likeCloud for example from empopic like youcould almost like in the first try ortwo like you could get it to like tounderstand the role and they keep andthey have that kind of remembering butfor some models like for chap GPT asfrom my experience is thatand sometimes wellmaybe like it depends on it depends onthe kind of game environment that's intoand also the configuration but we doneed to like carefully prompt engineerthechargerbt to to to stick to its ownrules sothat's why I'm saying that there's liketwo aspects here one is the kind ofconfigurationthat that they're interacting in and thesecond is how much effort you put intothe like into the prom engineering tomake that worksowellI think we could remove this friction byproviding some examples but just ingeneral that I think that LMS at themoment because the way that they aretrained on with is this iohf and thislikechatting with just one one user andbeing a helpful assistantwell they may still be knacking in termsof understandingthe roles that they are assigned toespecially under multi-agingenvironments so they are used to talk toOne customer one user but if they areput into like a large groupwhere other agents are probably AIS someof them may be humansthey may end up getting like um confusedespecially over long terms like longHorizons if their interaction keepsgoing and going andthat means that they're like contactsniff is like longer and longer andtheir attention will make a diffusedthenI do found that like at the at laterstage of the conversation it tend it itbecomes more plus like more likely toconfuse it's um it's on um its own rowssowhich I think this may be able to helpby like having Vivid or like this Vectordatabases and retrieval augmented systemto keep reminding yourself the kind ofstatus that I mean the role that theyare assigned to butI guesseven now like we neck we still lack ofthe kind of understanding of agency andwe neck a kind of aBenchmark as well to really checkin what kind of case like in what kindof scenarios at what percentage of thetime that they would confuse themselvesand then we and then we optimize and fixthose problems so I feel that this is atthe early stage that we both have todevelopenvironments benchmarks and also bettermethods including the retrievalaugmented methods to improve the agencyyeah that's amazing I mean I also I likeI kind of think like the solution tohallucination which is very closelyrelated to following your role in thecontext yeah is just to change thereinforce and learning objective from isit useful to the hallucination thing butas you mentioned then it becomes wellhow do you collect a data set like thatat scale yeah that's why that's kind ofwhat brings me into like why I thinkChad Arena these kind of ideas are goingto be so valuable is because you you thebent the benchmarking of these systemsis like really hard like I think likethe big bench thing was like one of themost impressive efforts to this bigbench data set it came up with all thesetasks tons of examples I think it tookthem like three months or so to beat allthe tasks sothere's that so there's that and but thethe thing about that that I think isvery like immediately valuable andshould have will just have so muchimpact is um there were all these newlanguage models coming out you mentionedanthropics cloud and obviously we havelike chat gbt gbt4 we have models fromcohere we have models from hugging facewe have the Llama models we have openAssistant you can just go on and on socan we likeplug these models into this game andthen you know have our little tournamentbecause I think I thinkuh collectively right now we're alllooking for the best AGI sort of thebest like just what is the smartestmodel likeyeah so that's actuallyspoiler that we are actually we areplanning to work on this Benchmark tolike touh to evaluate the kind of like allsorts of not just agency but also cialintelligence capabilities of these llmsand because by Design our chat Arenasupports like a lot of different likeapis including those what we said likeCloud open AI hug and face and coherethese are already that are supported inthe uh in in our package and that's alsojust from the start that we actually arereally curious aboutevaluating different language models butalsoevaluating how well they will worktogether or communicate against eachother so it's kind of like thetournament you're saying but it's notjust competitive tolerance but it couldbe collaborative tolerance right so ifthey would be like you could ask so Ithink one thing that would treat aboutlike is that I askthe ask cloud and open and check GPT todiscuss how they would they couldcollaborate so it's asking them tocollaborate to discuss how they willcollaborate so and kind of likerecursive problem but like and then theyjust come up with some really reallynice like like um nice niceconversations on how we have AIS tocollaborate so this that thing isreally possibleuh with chadarina and similarities andthen wewant to see howAISwould behave in these scenariosthey may be different like hypothesislike they may worked better if they arelike from the same API or trainingsimilar data but we're also curious tosee if they are having like trained withdifferent data have you know Specialtieslike they may be I come from verydiverse backgroundswould that be beneficialor not right like you were you know mytake is that it could be it should belike if we have more diverse agents tointeract in the environment butthat's still a big research questionyeah that's amazing I mean it's justlike with real humans like how you weall know someone who helping everyonethinks me this way but like it was likesmart but then they are very like youknow they they're so stubborn in theirways that they can't accept another ideaor things like this that would that likeit's not being a great software engineerisn't just about like how well can youreverse a linked list is about like canyou also work with the team and I likehow there's like this Dimensions tomeasuring intelligence and yeah it'salso interesting um so maybe kind ofwrapping up I really want to get youropinion on a kind of like a a directionof the kind of like large language modeltool use space is how you see thedifference between the chat gbtMarketplace and then uh you know like uhsoftware that helps you write your owncode designing tools like uh Lang chainor llama index or maybe kind of Auto gbtas being like Auto gbt to me is likesimilar to the chat gbt Marketplace inspirit like kind of how are you thinkingabout that kind of emerging uh area ofthiswell I think that's actually like verypromising Direction indeed like havingthistool use it's kind of like the it's veryintuitive idea to be honest right likewe use lots of tools but maybe adifferentso I think that on on that line ofresearch and also product I think therewill be a lot more products orprojects or tools that will come out inthat domain andthat's really fascinating uh DirectionbutI think what what more interests me ishow do you have differentumagents that's going to use maybedifferent toolsdifferent chain of tools right or theymay have different expertises right likeit's a bit different from True use thatusing two tools but actually it's havingmultiple agents that they could dodifferent to different things right likethey could use different tools or maybethey they don't have to share the sametools by the way like and they may havedifferent expertises right like that'sit's more like like real life like incompanies I'm sure that like programmersuse different tools than the like acustomer service right then I I theneven like developers like front-enddeveloper may have these different toolsthan back-end developers right so youwill see thatso that part of the the theum Direction which is kind of a focusnote to the tool use that means thathaving more diverseto use and uh between different agentswould beprobably a compliment to what you to theum chat gbt Market space or Lang chainfor example and to me I feel that that'suh another very interesting Directiontoobut I would say these two are like verywell complement each other and thebetter the better to use agents the moretools that's available to the agentsthat means that each of these agentswill have better capability uh tofulfilling like even more complex tasksbut also how do you to get multipleagents to collaborate in aenvironment would be another kind oflike ainteresting questionyeah I mean amazing I mean it's like thenext level of the abstraction but I likehow you said the orthogonal thing reallystuck with me because it'sit's kind of like um like when westarted doing this there was likeretrieve and read and uh you knowretrieved and read meant like you knowVector search or sparse search and thenuh read like re-ranking models that takeeach querying document as input at onceyou know or like questionnaireextractive question answering models andthat had like this dag flow and now thislike Auto gbt thing has more of like atree structured computation flow but nowyou're taking the tree and you're like Idon't I don't know quite what this lookslike yeah but it seems like yeah yeah[Laughter]and it's like the next abstraction Yeahwell yeah you Shang thank you so much Ithink you know Visionary pioneering thisCutting Edge technology and it was sointeresting to talk to my simulatedversion of me has the updated stanceI could really say like a simulated uhpodcast for this one if we have put thissummarize it and and give it tochaturina I was curious to see how itworksyeah awesome thank you thank you forhaving me indeedtalk with you thank you so much maybebefore we uh conclude do you want tomaybe give links to anyone listening towhere to follow your work or maybe somerecent I mean obviously chattering iswhat we're talking aboutyeah so you could try out our ChannelArena like uh from our hugging facespace or you could just go tochatarena.org that will direct you toour GitHub homepage and there will be alink to that our demo and you can alsofind updates on me on yushang.me adoptme so uh for for my latest updates aswell and uh it also follow me on Twitteruh and yeah I think this is reallyexciting uh direction that and we arereally want to uh and we really want towelcome our community to join us topushing forward the boundary ofmulti-agent language games and alsomulti-aging collaboration in general anduhand for that only with Communityparticipation and andcontribution we could build more diverseenvironments and more interesting usecases uh for for these agents to playawesome thanks everyone for watchingthank you oh", "type": "Video", "name": "ChatArena with Yuxiang Wu - Weaviate Podcast #47!", "path": "", "link": "https://www.youtube.com/watch?v=_0ww8Q0Bq2w", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}