{"text": "Hey everyone, thank you so much for watching the 51st episode of the Weaviate Podcast with Greg Kamradt and Colin Harmon! \nhey everyone thank you so much for watching the wevia podcast I'm super super excited about this podcast we have Greg kamrat and Colin Harman these two are both uh prolific entrepreneurs in the space of llm Agents uh Greg has made all sorts of amazing content about Lang chain and different examples of uh prom says AI early signal series and uh Colin has given this really impressive lecture on hallucinations and how that is manifested in agents and how to fix it at the haystack conference so I thought it would be so exciting to bring these two together and just hash out everything with our current understanding of Agents laying chain llama index and just how this whole Space is evolving uh so firstly guys thank you so much for joining the podcast absolutely thanks for having us happy to be here awesome so could we do a round of intros uh Greg can you tell us about like how you came to be working in this space yeah absolutely so my background is actually on the B2B products side of the house so I used to run a growth team over at Salesforce for sales and service cloud and then I was the first operations hire at digits which is a series C fintech company and I have a history of teaching people how to do data analysis and build data products but this year my focus has been teaching people how to use AI tools to build AI products and it's just a fascinating space right now because not only is the applications evolving but even the tools are evolving themselves and so it's really a turbulent time which is fun to be in yeah amazing I think um I can't speak to enough of how much your videos have helped me understand Lang chain and it's very cool hearing the Salesforce background because that that uh write 100 sales emails with the Y combinator video you did I can't wait to dive into that because I think that's such an interesting topic with how this like you know personalized retrieval augmented generation can impact that kind of thing um so before we dive into it any further Colin could you also kind of tell the story of like how you can be working in this space yeah absolutely so a few years ago I was working as a machine learning engineer and um had some exposure to natural language processing and kind of decided to go all in on that and that was it turns out a pretty good time to make that decision um and then you know my in my current role I'm the head of Technology at Nash which builds uh Enterprise search and automation applications for heavy Industries so upon starting there also got really into the information retrieval side of things and um as both of you know both of those Concepts have kind of exploded in the past year two years so it's been a great time to be in that area and and you know following content like um Connors and Greg's has been super helpful and um it's very important so uh yeah that's how I ended up here and and now just trying to you know find the future of how do you put these things into products and and understand it properly yeah fascinating I think maybe also to kick things off if we could do a round of just like how are we each thinking about like Lang chain llama index Chad gbt Marketplace just generally the space of like large language models using tools this General concept of agency like like how how would you define it to someone um yeah I'll get i'll get started with that but really I think my my opinion on it is a little um maybe a little more old school basically um I I've been asking myself this question okay we're talking about AI a lot right and a year ago what did an AI team do and what what did you need to provide value with AI and the answer to that was basically you needed a significant amount of talent you needed a significant amount of data and you needed in many cases a lot of compute resources as well right so that's what AI was um however not with language models if you want to be AI you want to do language models you don't need any of those things right thanks to people like you guys anyone can figure out how to use these and you don't need compute to do it you can use it like a software tool so I'm thinking of language models now as a type of software just another Block in the software stack this is not AI it doesn't require special talent doesn't require special data right because the data comes with the tool um so broadly I think of of Agents as a type of application that uses language models right and I think I think you're starting to see some hints of that from entities like Microsoft talking about things in that way as well this is just the new normal and it's going to be part of you know every not every system but a large large proportion of systems out there so um agents in particular if I were to make that more specific I'd say agents are aspects of those applications that choose and use various subsystems so I'll leave it at that and we can iterate on it a bit yeah and then just to join in on there I 100 agree I think that we're seeing a pattern here where you see an early iteration of a tool that's just clearly going to be what the future is going to look like now the the other side of that coin is that the reliability piece and so you're seeing things like the baby AGI and the auto GPT is it a question that they're going to be that's going to be the model for the future without a doubt it won't be the exact same thing but that sort of framework is going to be prevalent for sure we aren't quite there yet because we're solving a whole bunch of other problems that come with it but um I am all in on agents I'm a Believer count me in for it yeah I think those are both great uh you know great overviews from just the concept of just large language models being just like a compute primitive this kind of like person in the computer that you can just put in any intermediate layer of some you know transformation of data across an API or doing different kinds of skills that you can compress into natural language um so I you know in preparing for this podcast I took a look at blank chains documentation to see like what's the newest you know presentation of the ideas and so Harrison the latest abstraction is thinking that large language models can be based around you know data aware large language models and then agent uh a gen agent center there's some kind of like agent agentic I've never seen that word before like agent icy but so I say these two things as like you know you connect to the data like in a vector database and that's where you know our interests around this really comes and then also connecting with the apis so I guess kind of I want to start off by diving into the data aware llms and sort of what you guys are seeing with you know I know Colin has done a lot of work on hallucinations and you know Greg has tons of videos on ingesting particular kind of data into something like a vector database so that you can then retrieve the context and facilitate the generation so how you guys currently think about this kind of like making large language models customized to your data through the use of like you know connecting it to databases yeah I'll jump in quickly on that one my view on it is it's a very romantic idea to think that a language model can do anything that you want it to right and it communicates and the story tells very well that you can throw whatever command at it whatever data at it and it's just going to magically return things back to you but I think what we're seeing here is that language models are really good at some sort of tasks they're not wonderful at all tasks and that's okay because we don't want to over overload the system with too many um too many different types of requests and an example of that is where you see people say hey language model please think out loud first and then answer my question as opposed to just hey go answer my question for that so when it comes to adding data to the context of your language model I see too many folks try to throw the kitchen sink and just throw every single thing that they can on there where I think in reality you can get a really long way with better prompting and more signal to noise ratio within the context that you're passing in the first place which just speaks to the programmatic ability to do really awesome retrieval in the first place as opposed to giving everything to the language model yeah and I think a lot of it is about just how many places in kind of a search pipeline you can inject a large language model so from data ingestion using the large language model to kind of extract and format the data for the schema say you have like this High H lowercase y capital D capital E is like this idea of where you you take a query and you have the large language model generate a potential document and you search with that document or say using the large language model to cut the search results say type 10 results passive language model language what else has only give these two to the next step in the chain or say the large language model re-ranks it it's like there's so many places to put the large language model in this kind of retrieval Pipeline and get better search results but I think a great topic Colin would be talking about this hallucination problem how like where are we at with hallucination and fixing it with the kind of retrieval yeah um I thought Greg brought up a great point right asking the language model to do the wrong task and that I would say is is one of the big problems here I was just talking to a client today about about you know how you can do better on math problems when you use you know true thought chain of threat prompting systems um but why would you want to solve a math problem probabilistically because you know these models have a certain error rate on these math problems when we know how to solve math problems right we we've figured that out that came with when computers were invented right so um there's there's a big question of don't solve the wrong problem or don't solve a problem with the wrong tool pick the right tool for the problem and um and then getting back to okay like how do you use these language models and applications really step one for 95 of applications is going to be connect this to your proprietary data or whatever data you're trying to attend your application over so retrieval necessarily is the most important part of any of these Real World Language model applications just because um look at any software application right those are based on data as well software applications use databases they use search um so the same thing needs to happen with uh with language models because if you don't do that that's not a truly useful product it's like a demo right or you can do it in chat GPT so for most people building building businesses you need to build something better than what you can do in chat GPT and the easiest and most straightforward way to do that is connect to the important data and that yeah that can be that could be a vector index a Keyword Index like bm25 it could also be managed index like Bing search API or it could be um it could be a structured database which I know Connor you're you're into the the querying using language models thing and we've been doing that for a while now too and every single one of those can be optimized using language models throughout the process so so yeah you have this concept of okay retrieve and then generate but generate can also bleed into that retrieve step and it doesn't have to be a one directional process right you can go back and forth so there's a lot of ways to improve it but it's most basic you need to retrieve if you want to deliver business value yeah I I love that not a one directional thing I mean as you mentioned like yeah I love that um like I think now llama index and Langston are both calling it The self querying retriever where you ask it you know like uh What uh uh like how long do golden doodles live on average as a dark question think about the mortality of gold noodles but like and then you you would give it like the you know symbolic schema that you like you know Vector databases like weaviate in addition to storing your unstructured text chunks you also usually have some symbolic data around the text chunks and we integrate that kind of stuff into the vector index so you have filtered search but so you so you know you give it the properties in the prompt and it might say you know where animal equals dog and then you know you have the symbolic filter so there's like that notion to it where you can just use more of the levers to the search engine it kind of is like with web GPT you have these search actions like you know do you want to scroll to the next page of the Bing search results and and this kind of thing and you know but so there's like that there's like using the llm to control all the levers of the vector database but I also really love this concept of um you know like an interface and this is kind of how I see client Frameworks even like stepping like into the software hat of like you know database client Frameworks like I see something like Lang chain llama indexes orchestrating like Eva and like say neo4j and then like an SQL system and like using the unique benefits of combining your data in each of these ways another kind of really interesting area of retrieval from different kinds of information sources but I think it would be a great transition into this kind of tool use now because we've already kind of transitioned from retrieval and we're now kind of making it more like a tool like you know I'm really curious about like how you guys are seeing things like you know zapier I know Greg has opinions on zapier and like using the calendar apis and like how to how does the tool use kind of come into this picture yeah quicker than that one I think just how I'm confident in that agent Paradigm will obviously be what's happening in the Future tools are the the other side of the coin that come with it I mean that's how you get them to interact with our lives I just saw this quote within the human Loop blog post that said uh Sam Altman suggested that a lot of people thought they wanted apps to be inside of chat gbt so they thought they wanted plugins in chat GPT but in reality what they really wanted was chat GPT in their apps so it's not chat gbt as the central point we're going to interact with all your tools it's rather because really what's the incentive for the third party applications to support that heavily right they what they want is they want the users in their app and they want the chat gbt like abilities within their own app in the first place so as we think about tools I think it's going to be a really interesting dynamic between what's best for the user and what's best for the business because unfortunate not unfortunately but the way that market dynamics usually work is what's best for the business is what's going to come out in the very first place now open source software will of course help out the user and go from there but um I think this is a dynamic we still don't know how it's going to play out quite yet it's so fascinating you brought that up like we did podcast fans stay tuned for uh a deep dive on Chad gbt marketplace with Yana wellender who's building craftful so craftful with a K is um you know it's like a product manager inside of chat gbt sort of so what the product is is it's like prompts that product managers use like for analyzing customer feedback or like you know suggestions for what you do so it's kind of like skill based prompting like I think summarization has been one of the big likes the most successful skill to prompt it with like create and refine mapreduce like how you summarize with a skill and so so on this chat gbt Marketplace thing oh man I think this is so interesting and especially like you know Greg's such a prolific content creator I think this applies to you so interestingly is like and yeah like everyone really but like imagine like taking all your expertise on how to use Lang chain and like kind of setting up like instead of like a course you would create now you create like a set of prompts and it's like a product on the chat gbt Marketplace and coming back to that market dynamics thing and like the business around it it's like it's like yes I want the users in my app but the exposure of the App Store might be so much like you know kind of it's pretty fascinating I don't know what do you think about that kind of oh I mean you you've kind of it's such an interesting topic to me the difference between Chad gbt Marketplace versus just the API but I think the marketplace offers a lot of marketing yeah I'd say another part of it really like maybe what goes under that that Sam Altman quote is that the llm is a feature now of a different product right and a lot of people are still thinking of it as a product but now it's just a feature right it's just software so you have a lot of people working on projects that are okay like there's some tool I use some software tool I use well I'm going to make a startup to do that with an llm well that's just going to be a feature in the incumbent in one to two months guaranteed unless you're talking about a really really slow um incumbent so these llms it's just going to be a feature it's going to make its way into everything it's because it's software now right you don't need to hire an AI team there's no barrier to entry um and I think there will still be benefit from having you know possibly a app in the in the Chachi PT Marketplace but um truly most of the the really valuable products are things that aren't going to just work in the chat GPT Marketplace because how many apps can you truly make how many um how much value can you truly provide with like a one-to-one okay you know query or you know um chat chat entry and then computation like that is very limited and there's more benefit coming from integrating that into a different platform or a different application you know and building on what Colin just said there another statement I believe to be true is that there will be some Central repository for all the memory about Greg or about any personal person so Greg Greg's style my writing style my preferences all that will be held somewhere I it my hypothesis is it will not be application specific so for example Salesforce will have a language model that it's going to know how I interact with Salesforce all right that's great so we'll Zoom so we'll probably Chrome right but what's the language model and where's my central repository for all my preferences across all of those apps or whatever it may be so the reason I bring this up is it's still unclear to me if a chat GPT like tool will be that Central repository that knows everything about me or if a Google's just going to try to go in there because if you think about most my activity it's all through the browser right and if you're Google and you did this for me you'd capture 95 of what I have going on um it's still unclear how that's going to play out but I think it's going to be a mixture of both where applications will have their llm but also there's going to be a Greg llm that's going to be personalized to me that everybody else will have as well so you think that'll be cross businesses that won't be proprietary to a single company I I well so I think that like obviously Salesforce will have their own and gong will have their own and zoom will have their own and all that but then in order to automate my own work I'm going to want something more local to me so I think that because um we won't live in an llm constrained world like there's going to be like an infinite amount as many as many language models as you want um so I think that there will be one that is personalized to me that I own that's a little closer to me um and interacting with other llms from other tools it's really I mean it's inspiring me to think about like kind of like the private GPT and that whole topic I know of you know both of you with this kind of like Enterprise B2B experience on these things like yeah like you know I know just from like hanging out with friends outside of the weeviate circle that a lot of them say you know I can't use chat gbt for work because I can't just like you know put my documents into chat gbt because of the security yeah I'm curious like how how you see the emerging Trends in this like like are more like you know companies gonna go to open Ai and say like hey open AI we need you to set this up inside of our cloud like the model inference server inside our cloud is that something that maybe you know open AI or cohere you know anthropic these big model providers would look to or would this maybe be the open source language models or will people start you know training their own language models with maybe you know Mosaic and ML and tools like that yeah sure yeah there's a lot there's a lot there um so yeah you're absolutely right a lot of Enterprises are not comfortable with sending data to open AI um there's some ways that open AI is getting around that and when I say open AI that that'll include you know Google's offering Palm whatever any of these language model providers so often the way they mitigate that first objection is by saying okay well now we're in your cloud provider platform right we're in AWS we're in gcp we're in Azure so you can use that and then you don't have to go outside of azure and then the next level is data retention so I think with most most of these systems you can opt out of data retention now that's a huge deal for infosec another step that I'm not sure exactly where we are on this is dedicated instances right so you can get that I'm you will probably be able to get dedicated instances of some of these super high performing language models pretty soon and then it probably ends there for the managed models right and then you step into open source world and in open source world you have those previous options but you also have private Cloud you have on-prem and you will even have Edge and Edge is also going to be interesting because we're probably we're probably close to a point where your um your Windows PC or Apple MacBook may end up having a llm built into it right and we saw the Palm models they had one that you could fit on smartphones right so at some point the compute may come with your device and that changes things a lot right because then it doesn't leave your device that's not it doesn't leave your Cloud it doesn't leave your device you can do anything you want with that probably there's still a little friction just getting these infosec organizations to catch up with all these Concepts and understand okay what is safe what isn't safe are these things stateful how do we know it for sure but um I was just looking at a company the other day called ask Sage and they're doing they're providing open AI for government entities including you know military right so the fact that that is gaining traction um using those those open AI instances and content retention turned off is a pretty good sign that enterprises and organizations are starting to understand and realize that they need this and they're willing to take some risks or at least understand those risks better in order to do it nice the um I agree with Colin that the ability like these models let me rephrase um Sam Walton has another quote that I really enjoy which is the cost of intelligence will go to zero right and the cost to serve that intelligence will also go to zero now TBD on the timeline for that but that's the direction it'll go so I agree with Colin fully that the ability to have compute uh Intelligence on our Edge devices will 100 be there now we'll we'll the the market adopt that that's a little bit of a different question for me and the example I want to give is um take for example iMessage versus signal signal uh uh uh touts that they're end and encrypted right well are we all using signal today not really we still we still use iMessage and I know that there's encryption and everything around there but I think the point is I think that where this will go is I think just the way that we trust Google and all these big on all these other big info companies to handle our data our Gmail our drives and all that I think that'll be the same level of comfortability that we get to with language models we're just um we kind of jumped into a cold pool and we're still feeling the shock of the water right now but I have a feeling that we're going to warm up right to it and once Google or once this becomes the norm in a google-like company starts to serve this for us we're all gonna we're all gonna be okay with it yeah that that whole thing you know all that introduced so many new ideas to me I'd never actually considered llm on the devices like right into the chip like the new M1 chip also comes with a apple gbt in it and that's that's a really cool idea all these things and then think about the market adoption like I think either we could take this this topic further and talk maybe about like the kind of medical use cases and the evolution of that or I think we could talk about sort of pivoting topics entirely and maybe step back into our conversation broadly on agent use and before we dove into this um Greg you had brought up the Chain of Thought Auto gbt so let me actually ask you guys both quickly do you think we should yeah why don't we it was just as the interview host I'll hijack the topic and what let's talk about let's talk about Chain of Thought prompting and auto gbt how do you guys currently see that um I'll give just a very quick opinion on this like I said at the beginning of the interview not only are the applications and use cases evolving we still don't know like what's the right way to run these things in our business which is super interesting but the tools themselves are still evolving so what is the best framework for an agent to Think Through you know we're still figuring that out and the the way that we do figure this out is through market adoption and we see what handles most of the use cases and we let the market help us figure out what to do here now the fact that we're coming out with new Frameworks every single week and we haven't yet settled on one I see that as a beautiful way that Innovation happens and you can't speed this process up anymore let the dust settle let's see what kind of things come through here and we need to trust that Lang chain and llama index and grip tape and fixie and all these folks will be the ones who will take advantage of these new Frameworks and provide them for the end users like us yeah grip tape that's it I haven't heard of that one before but I like that name behind it like uh guardrail is another one that I know with like the preventing hallucinations like having layers at the end of that yeah it's also interesting I mean I guess my thing about the auto gbt kind of craze in that is just this idea of like you know coming up with a plan and then sort of executing the plan asynchronously is sort of like the Computing Paradigm that I think is really really mind-blowing with this kind of idea is like if I say you know I need to I need to come up with I don't know like a way to optimize my code at the lowest level and it's like research about arm processors research about simd instructions it's like it can like paralyze all this research and like coordinate it how do you think about that kind of component of Auto gbt is like letting all these language model thread it's like a new kind of like multi-threaded programming is how I see it yeah um so I think there's some challenges to adoption with the rogpt Paradigm and uh it's something that works really well for an ad hoc Quarry right it's fun it's very cool and it demo as well it demos so well right but it lacks the things that make it valuable to a a serious Enterprise an organization and that could be anyone right that could be you doing your job that could be an organization buying it for their for their people that could be a university giving it to their researchers right and what it lacks is um repeatability for one thing and then kind of this auditability observability that we don't quite have great Frameworks for yet but I'm sure that's coming but to flesh out the repeatability portion a little more let's imagine you have some knowledge workers in an organization right um you could say all right look Auto GPT can do everything that they do but that's probably not going to work very well because at some point you're going to need to compare that with a similar task that a different knowledge worker has done um so what I think is going to happen in these organizations are people are going to look at these knowledge worker pieces of work work objects that they produce and what you want to do is group them into basically workflows is a term I've been using I've heard a lot of other people use it as well so let's say let's just take a concrete example you're a data scientist and you're doing topic modeling okay should be familiar to our audience but that's something that you want to roughly follow the same pattern every single time because you're going to share that with other people right and they're going to try to replicate it and if they try to replicate it and their Auto GPT does it a different way you're going to get different answers and what are you going to do so I think what's going to happen is um people will gradually approach all these problems of various fields and kind of segment them into workflows and you'll have some very frequent ones and you'll have some you'll have a long tail right so you have some tasks people do a lot topic modeling you'll have other tasks that people do infrequently like training a new llm right and so you're going to take those high frequency workflows and you're going to try to automate them and that might not be totally deterministic right there there might be some some routing decisions made within there um so that could be thought of as maybe a sub-agent but then you're going to have some supervisory agent that is choosing that workflow or choosing hey this doesn't fit with anything I'm you know really trained how to do so I'm going to go the long tail route and just go full auto GPT um however that's again not as likely to to be as useful number one because it's harder to trust and number two because hopefully if you did this right those are less frequent tasks so if you can use your language models and your tools and your retrieval to automate these high frequency workflows I think that's how we're going to see a lot of a lot of automation adopted in terms of these like knowledge worker tasks that people would expect Auto GPT to to address Colin question for you on that one um for these for these Advanced workflows there's kind of three pieces there's the language model as the reasoning engine there's the task and the prompt that you give it and then there's the memory in the context that it receives right I can see one argument that says once you get to a high enough reasoning level like high enough intelligence level for a language model then you could fine-tune that workflow just through the prompt and through the context that you're feeding it so for example the data topic modeling well do you need to have a specialized reasoning reasoning engine for that data topic modeling or do you just need one of sufficient level pass it the best prompt you can pass it the instructions on how to do topic modeling in the first place and then let it run wild that could end up being sufficient yeah it's very possible but even then you know you have kind of added some deterministic information some you've given it a structure so that structure I think over time will probably evolve toward what you described um yeah it well I think you know earlier when I brought up uh what Yana is building with craftful and the child GBC Marketplace is very similar to this idea of like you know I compress like Martin grutendors The Bert topic expert in you know topic model the expert into like a set of prompts on how to run topic modeling analysis is like the craftful ideas you take these prompts on how you generally do like user interviews manage user feedback and and yeah so it's so fascinating I think I think of this as kind of like a skill prompt and I got that kind of like skill prompt from looking at Microsoft semantic kernel and that's like the abstraction that came around like um you know like a prompt for how to do question decomposition like our follow-up questions needed this is kind of a topic around skill prompts it's really related to everything on agents is what is the evolution of few shot examples do we still need to give a few examples of how to use agents or with you know because Chad gbt like it you know it seems like a lot of time like I think react was a paper that was like zero shot tool use so it's like you don't need to give it examples or train out how to use a tool so what do you think fuse shot prompting give it a few examples of using a tool is that still needed yeah I think it's it's definitely still needed and you look at how how people build plugins right now like I like you men I like that you mentioned semantic kernel um I think that's a could end up being a good standard going forward because look how they built that they look at how everyone was building plug-ins and then they standardized it and generalized it right and that's not something you really get from the open source Community which is kind of just purely expanding it doesn't have a good contract stage yet whereas Microsoft with that framework has done their expand and contract already um but in terms of if you want to give a system new capabilities with a new tool um it's most likely that you want to do that with fuse shot um you sure you could just describe it but why would you do away with giving it additional information I think there is a place that fails though which is let's say you have multiple tools and the tool could couldn't include a retrieval system uh you know Atomic tool or also a workflow let's say let's say these interact with each other or they're dependent on each other each other in some way then the kind of oh I'm adding a plug-in so here's my few shots and here's my you know interface that kind of breaks because you need few shots that cross between the different tools plugins workflows whatever and um that may be a time where you'll need to either develop a lot more few shots but you can also see how that would like the permutations of that would would get out of control pretty quickly or possibly even train a specialized model to do that sort of planning that it needs to do in order to figure out how to use this this environment of tools rather than just thinking about it is you know I can do one or two things um yeah I was gonna say I'm with Colin of course nobody knows but my hypothesis is that a few shot examples will still be around because even if you craft the most perfect prompt I don't think you're going to account for every single situation and giving like a picture speaks a thousand words well so does a few examples as well like the story of a lot of machine learning is you know examples and then just the research has been how do we learn from as little data as possible and now we've seen that um calling you said something though I I hadn't heard that abstraction before open source is about the expanding whereas like a centralized entity is the contraction I think that you know like it makes a lot of sense and I think that is really interesting and then something I think is really fascinating as well is I think Greg is one of the world's experts on keeping up with this expanding of what people are doing with prompts Greg has a series called early AI signals and you can see the you know notion template really nice organization of these things and I think this would be a perfect transition Greg if you could talk about like this expanding and how you're keeping up with it sure absolutely so um I have a small side project called early signals and it started as an experiment really because there used to be the saying that every spreadsheet template was a future startup and if you looked at the Craigslist home page every link on there was a future startup it's like home rental Airbnb car rental Toro et cetera and I was uh just on just social media in general Twitter Youtube Hacker News all that stuff and I noticed that people were using chat gbt for ways that it was not intended to be used they didn't really know you know how it was going to be used so people saying oh I use chat GPT for therapy hmm interesting I use GPT to write my cover letters to help me with my resume and all this and I thought to myself man is chat GPT really the optimal product experience to execute against those workflows likely not so this could be an opportunity to productionalize that that workflow now the hard part about this and the piece I need to emphasize is you do not have a defensible business if you just productionalize a prompt so it's a starting point I I believe and there's the hint of it and somebody needs to go out and go build more defensibility around it but early signals I have a collection of those ideas and um it's about weekly I try to go through and say say my favorite five but then give folks the access to I think we're up to like 70 to or 80 different workflows and the important part for each one of these is that I need to show where a user has said that they do this thing so I don't want it to be somebody's idea I wanted to be a user says I do this right now and so you already have a little bit of user for uh adoption for right there yeah I think it's so useful it's such a cool you know it's so interesting just going through it I think like from like the AI girlfriend to like the uh yeah just like um the whole collection of all these things that people do with it and I mean yeah I I I'm just like I'm I'm still kind of like my mind is blowing through my head thinking about this kind of Open Source expansion kind of idea because I do think like Lang chin like when it first came out the way that it was like open source and this kind of collecting the prompts and it's very similar to what you're doing with the early AI signals is just like maybe if I connected to like hugging face in the model Hub the open source like how they've managed to seize open source and it's like because they have you know it's like what are we gonna do with this new tool and it's so creative and it's just pretty interesting uh quick quick I think another Sam almond quote that I really enjoy and I keep on quoting them here but um the reason the reason he States why they release slow is because the collective intelligence of the human population is unpredictable it's unpredictable they have no idea what what humans are going to do so it's like all right here's chat gbt what do people do here's plugins what do people do here's API you know Etc et cetera um I think that open source expansion open source moves quick like you're talking about Indie hackers all over the world that are putting out really innovative ideas one of the Prime examples of this is baby AGI the founder of that was not a technical by trade person per se he's a VC so how cool is it that somebody who isn't necessarily technical is building this tool that all people around the world can take advantage of and I think that I think that speaks to the open source types of world on there now um proprietary and closed will all will catch up to it but they're driven less by let's provide um selfless Innovation out into the world and they're more commercially driven but it's all it all it all follows I think it depends on that this stage we're in also right because we're still very early and talking about something like agents no one even agrees on the abstractions right like I I was looking at uh fixie which is a pretty cool company and um they have a you know open source package available for agents as well and they call everything agents so like a plug-in for them is an agent right so we can't even agree on the abstractions and eventually we probably will and at that point we need to contract the um we need to focus right and that's not something we're getting a lot of at this stage from tools like Lane chain for the the general agent stuff and from llama index your other example for the ingestion stuff right I think both of these started out very successful because they gave random people quick cookbooks on how to put things together right that was the value they provided it was simple abstractions a collection of wrappers that was basically it like I think a lot of people ended up starting using Lang chain just because it was marginally you know four lines of code easier to do that and instantiate weeviate than it was to instantiate deviate from the like the weeviate documentation which isn't the fault of webe that's just how software works right so they made a wrapper that shrunk it um and same with the openai endpoint so that was valuable to people for a while and I think a lot of people are still primarily deriving value from it for that reason however as it as it balloons as it gets bigger and bigger you're going to start to lose the cookbook of the system because there's too many options and I think you'll see that happen to llama index really quickly is everybody builds a different document parser right and so all of a sudden I go to this I go to this GitHub and I want to find a document parser and instead of having three options where the differences are clearly articulated I now have 2500 right because that's what you're going to have look at hugging face it even happens on hugging face how many models are on hugging face thousands how many of them are useful very very few we don't trust hugging face to tell us which hogging face models are useful even we often get that from somewhere else so um yeah these these open source expanding Frameworks will need to be careful um and be sure to do some Contracting at some point or else these Frameworks that are much more opinionated like semantic kernel are gonna eat their lunch because they were developed kind of with the same process originally right these these Microsoft people just built a bunch of plugins but then they took that learning and in an organized way turned it into a true framework that people could agree on and was as widely valuable yeah that is that is just gold insights I I feel like I take took away so much from that I mean um like we think a lot about the weevier cookbook and how we want to design this thing and yeah it's like you know Tech search with this data set text search with that slightly different data set where you'd use different properties is that the best way to design a cookbook or do you just end up with like 2 000 examples and it's like that just confuses you compared to like one text one image one multimodal and just keeping it to the point it's pretty fascinating um I guess I kind of like in this topic of Open Source I thought maybe there is a link to jump to this next topic which is multi-agent systems like where we have it's kind of like it kind of is similar to Auto gbt to me but like you know say you have like multiple agents that like live in some kind of simulation I mean I had uh you Shang Wu on the podcast who's built chat Arena and what chattering is about is like you know we Greg Colin Connor we each are like retrieval augmented chat Bots that talk to each other and maybe a third language model is judging like who's saying the best points and stuff like these kind of like chat games but like how do you think about that kind of like multi-agent uh llm systems I um quick comment on that one if you were to ask why do we do this multi-agent thing in the first place and it's really uh deficiency in the current models right now not to be able to handle that type of computation or that type of prediction or whatever it may be right and so I I think that is the use case going to be there in the future where you want to interact with an arena of people sure we're seeing the market already want that right now is the answer multi-agent well it's a pretty convenient way to constrain One agent to like think about a certain thing and constrain its memory and all that um is that the only way you can construct that type of application no and so is that the framework that I think is going to be the one that persists uh still TBD I'm not going to make a hypothesis not yet yeah I think you're totally on base Greg um a lot of yeah the reason you do that is to make up for their shortcomings and if you had a smarter model why would you need to have two of them talking to each other if it can just you know understand okay well I've got this stuff in my context and I should do something a little differently because that's all the other one does it's just like they're just swapping contexts in a in a different sort of way I think the place where we might see more of that being necessary is yeah further toward the edge more open source where you you maybe have the smaller uh specialized models like for example that that one we kind of talked about where it's trained to use a certain group of tools together but um as you get smarter models it shouldn't be as important I mean I think it's just absolutely fascinating I I think it's very related to just like real companies kind of like like if I think about how like you know if I'm if I'm playing this these roles in this multi-agent system the first person is like looking at the Twitter feed you know doing the early AI signals curation and then sees this thing and says I think this could fit in weeviate just like someone who's just picking things I think could go in webiate then you pass that to like the product manager role playing LM who you know has this particular retrieval and maybe also fine-tuning to use those kind of tools to say okay here's the proposal then the engineer you know who's more familiar with the code base and the internals of the database and stuff like okay and then uses the chains of like the you know code execution tool used to like prototype and develop a prototype and then you know you have like some kind of maybe internal pull request review that happens with role-playing of like different engineer llms and then you have like the marketing and like you know without explaining like all the roles of the engineering company like do you think you don't think do you think that thing would be superseded by just one large language model that sees the new thing on Twitter have her ingest data however it comes up with ideas and just end to end just I don't need this kind of role playing it's just like totally unnecessary uh I think my previous statement was just assuming they're all built in from the same language model and the same model that comes in from there now when you start to speak around specialized tasks I think in in that case it's still TBD but a lot of popular opinion is around that you're gonna have specialized models that come around and then with that if that precipitates specialized agents then you'll have a multi-agent world to complete those tasks yeah I mean it's like well they're kind of like two emerging topics in large language models I think which is the first of which is fine-tuning is becoming cheaper we see like the Q Laura the quantize low rank adaptation that's making it look like you can you know I think they say they fine-tuned a 65 billion parameter or large language model on a 48 gigabyte GPU and so it's like it's like that kind of thing is going to get a lot easier like way easier than it's ever been right how do you think about that kind of Trends in fine tuning uh yeah I mean they're definitely making progress I think there's still some unknowns there was a paper that came out recently talking about how the non the non-managed models it turns out don't generalize nearly as well as as things like GPT 3.5 so I'm sure we can link that I don't recall the title of it at the moment um but if you if you look at that what is it saying it's saying these open source models aren't as good as we thought they were and they don't generalize as well to unseen tasks that actually makes a case for more fine-tuning right if your business has certain tasks you expect you need to do there's more need for you to fine-tune those models again stepping aside from the the super powerful model is the gpt4s of the world if you're going toward these smaller models then yeah fine tuning will probably be more important and it does seem to be getting way cheaper and that goes hand in hand with the hosting costs or the inference costs as well right they're kind of tightly correlated so with that that quora paper that was really cool I'm excited about that um yeah you can run inference and training for now it's it's accessible to you know you need a little a couple talented people to do it probably but um that's kind of your only obstacle yeah I think that's exactly correct I mean you need to you need to then have like the you know all the ml Ops skills to take advantage of that kind of thing but then if it saves you money saves you that much money compared to like all these repeated inferences of the super smart thing so then the second big Trend I'm very curious about are these like really long input lengths like anthropics is 100k input lengths how do you think that'll change agents I don't know do you know how they do that either you guys know how they did that did they just pay the price or or did they have some trick I feel like people are still trying to figure that out well I think with mosaics uh MPT they talked they you know talked about Alibi attention and how you can do this kind of like sparse attention where yeah I mean I don't know the exact mechanics of it and I'm sure they optimize it like all the way down to the Cuda cores and like you know have a lot of engineering that goes into that but yeah one one quick thought about it um and then I'd love to hear what you think Greg but with the longer attention I think training probably becomes a lot more difficult and expensive too so beyond the compute which ordinarily with with attention skills quadratically right um that's a problem but then also if you want to generate fine-tuning examples that um they replicate some long context tasks that you want to do in the wild you need to generate some examples of that right and so if you're having people right 80 000 word examples then you're going to spend a lot of money doing that you probably need pretty smart people generating those examples but then the other side of things is with longer context length some applications look different right you don't have to do as much retrieval there's a there's a certain window that opens up of data that where you can just put that in the in the context in the prompt and it's not clear how much further we'll be able to go but that definitely does change okay how often do you need to do retrieval um to yeah you can put some in the prompt you know I think maybe I'm wearing the adversarial hat being in a vector database company but we're already seeing papers like large language models are distracted by relevant context calling in your Haystack presentation you talked about n greater than one search result in the prompt you know it becomes trickier so yeah I'm I think that it's the the pro of retrieval is like you could still pack a hundred thousand with all sorts of information sources as you search across classes with different queries and stuff just to pack this prompt as densely as possible yeah and then generally I think it'd be hard to train those models I agree with that yeah and for me I think that long context weight length it demos really well it does well on Twitter and I think the reason why people are excited about it because it's storytells really well too it's like oh now pass a book into this whole thing however the minute the benchmarks start to go down I become less interested and so really is kind of a dramatic statement I don't care I don't care as much about context length at all I want improved reasoning cheaper and then longer contact well no improved reasoning cheaper lower latency and then uh longer contacts contacts lengths for that because like Khan said which I agree with it's a bit of a it's a controversial statement but a longer context length allows you to be lazier on retrieval and it almost makes up for your inability to not do retrieval as well as you should be doing in the first place potentially I know it's a bit it's a bit of an overstatement but I think that I am fine with managing a shorter context length and needing to beef up my deterministic retrieval to start then um then somebody's saying oh now you can do a million tokens it forces you to build a better system doesn't it yeah fascinating uh Greg and Colin I thought this was such a great tour of all these topics of llm Agents I mean I learned so much on these podcast uh those podcasts um wrapping it up uh Greg and Colin could you each maybe uh give listeners like where to find you keep up with your content hopefully they're you know that's why I read the podcast and want to just dive into all the online content you have um yeah absolutely so two places on YouTube I run underneath the channel called Data independent you can find me over there with a bunch of uh Lang chain content early signals and all that good stuff and then most of my communication happens on Twitter so I'm just at Greg camerad hey everyone apologies the recording crashed right as we were doing the outros you can find Colin on his blog at colinharman.substack.com and you can also find calling on LinkedIn at Colin Harmon one more quick bonus on the outro you can check out Colin's new talk at Haystack us 2023 stop hallucinations and half truths and generative search now uploaded to the open source connections YouTube channel as a bonus you can see the ordis Chrome plugin from Alexa gordick this new AI summarization tool for YouTube another really cool thing uh and then also in the spirit of it here's Greg's Channel data Independence so many incredible videos on lighting chain tutorials uh new things about AI the early signal series all sorts of cool stuff so thank you so much for watching the podcast and please be sure to check out Greg and uh Collins videos as well as well as all sorts of other content thanks again ", "type": "Video", "name": "greg_kamradt_and_colin_harmon_on_llm_agents__weaviate_podcast_51", "path": "", "link": "https://www.youtube.com/watch?v=iB4ki6gdAdc", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}