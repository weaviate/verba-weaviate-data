{"text": "NLP frameworks like Deepset's Haystack are powerful tools to help data scientists and software engineers work with the latest and ... \nhey everyone thank you so much for checking out the fourth episode of the we va podcast today i'm joined with malte peach the cto of deep set ai which has created the haystack vector search engine today we're going to talk about all sorts of topics related to vector search engine the haystack library and the different things that they've built and all sorts of cool exciting things around these ideas in neural search so to get started uh malte could you tell us about your uh mission of haystack and sort of your vision and understanding of vector neural search engines yeah sure um so um basically obviously my personal background is pretty much described with machine learning engineering and um yeah there was probably one key moment in my life that made me up ending ending up in nlp and i was when i did some research in us back on like healthcare data back then um some numerical values some like um blood measurements time series data all of that we built like a fancy model uh predicted some um some some nice things in the end doctors told us uh yeah that's that's not new uh we knew that uh it's correct what you predicted but they are not super exciting uh and then it turned out the only like or they would say the most exciting part uh that they were curious about was some part where we modeled or used data textual data coming from handwritten notes of doctors and from modelling perspective that was very naive modelling i would say but in the end it was the biggest value and um that's i would say how i ended up in nlp and also why we found a deep set in 2018 uh because we really saw and believed hey like there's so much text data out there in basically every company but it's in most cases not really used there's like it's a lot of gold out there but not really leveraged and in uh 2018 we thought okay yeah they're tooling was well okay but like the models were quite primitive but we really believed hey there must be like there must be something happening in the next years there will be innovation there will be something similar to like imagenet on on computer vision there will be this wave of new nlp models that that make this text data available and that's basically we started deep set and worked with many industry clients then bert came out there was quite like i would say this imagenet moment and then things accelerated a lot um and yeah what we what we saw from working with all these industry customers um was basically that it's always every company that we worked with had this issue of accessing information from this these text amounts these documents and finding it and extracting it and that's basically where how we started haystack with the belief okay let's build a framework that leverages latest research and bridges this gap to production in the industry to make it simple to adopt these latest research methods and really use them in that same production and all let's say around this this case of uh new research if you want to say so uh we usually say like about finding the information and also extracting it so not only this classical search uh setting where you type something in you get your results that could be also that you extract certain entities or certain um certain information and kick off other processes or so on um yeah so that's basically how we started haystack and uh got uh got pretty well adopted faster than we thought uh yeah we have no contributors from from all around the world from netflix many other companies use it in production and um yeah what we what we hear basically as feedback is um and also use it as a strong philosophy of us um that the framework is really a lego lego box building blocks that you can stick flexibly together to some pipelines and then you move that oil production you can exchange one of these pieces easily if a new model comes out so i would say that's that's pretty much something i just want dna and in the dna of this whole chain and yeah for me i'd say like my vector search imagenet moment was when i first came across the co-search system from salesforce research and this idea of the pipelines is the first time i really saw this diagram where you look at the document index the retrieval pipelines going into different downstream applications like summarization question answering or say a chatbot and this kind of idea of having these flowing systems for me co-search was my imagenet realization when i first became really excited about these kinds of systems so i'm really impressed as i was looking through the haystack how to use it and the different components of it i really love the pipelines and so before we get into sort of the details of the kind of like the library design i want to ask about more of your opinions on retrieval augmentation and kind of like retrieval transformers and it's obviously very popular now with things like deep minds retro and open ai's web gpt this really exciting idea of retrieval augmented transformers and before i give you a chance to talk i want to kind of quickly pitch this idea of do you think that maybe the shape of say agi or like a powerful ai the next generation of that will be that you have such a powerful reasoning model that all you have to do is just plug in your data and then it can just retrieve it and then this reasoning model will be able to adapt to any kind of data that you retrieve such that the retrieval augmented pipeline is so strong that you don't really need as much fine tuning and then from there we can talk about the farm library and haystack and all sorts of things is debate around retrieval augmentation and then the need for fine-tuning um yeah so i i definitely see that retrieval augmented pipelines or models are like a super important piece towards maybe aji at some point and um and i mean i think you can take it from two sides or two perspectives uh one let's say just coming from plane transformer models and if you talk about something like question answering retrieval is just basically the way to speed things up right and to make it scale to millions of documents having like some kind of filter before and uh and really just seeing it that way um and that's how we i think initially kind of started it um then i think with the um say the rise of all these gigantic language models and more like generative approaches um it's really i think now about these two schools to say mindsets to beliefs what where what is today actually helpful and what where will end up in the future um i'm pretty sure that for today and the next years um i would place my bet on retrieval augmented pipelines um mainly for two reasons um one is basically interpretation so um if you let's say have something like a gpg3 or like a from omai one of the models um and you ask the query a question and it gives you the answer uh it's super hard to understand if that's correct or not now you don't know how it was generated what kind of information is it based on and that's a very powerful thing with the with retrieval and extractive methods right that you our users often it's they get these results but then they often also where was that written like give me the exact passage and what what real data is that based on and that's very easily possible the second thing you already mentioned like fine tuning or the way to adapt it to new data sets if i have something like gpd3 or another generative model um usually trained on a big public corpus from the internet if that's your domain perfect but our customers are mainly like enterprise clients maybe from aerospace domain from some legal domain from finance some very deep tech stuff and there are usually like words and meanings that are very different to general internet wikipedia corpus and yeah i mean this this big models are not trained on it so they don't work and they get outdated very easily right if you ask one of the not saying our one-year-old models about omicron or kovit or whatever they will won't know and it's very hard to to update why with retrieval it's just hey index on your document today and out of the box my my model knows or can find this information um so i think these are two powerful advantages um still like retrievers dance retrievers for example there there is i think some um many cases need for fine tuning and also like get a lot of boost if you fine-tune for your domain um but it's then usually some something you do once and you can still like ingest new data and you're fine and you don't need to retrain like every i don't know second day yeah i love those two arguments for the benefits of retrieval the interpretation of seeing what it's returned and then the ability to adapt to new data sets and uh changing information and i think those are two huge selling points and so kind of to dig a little deeper into the fine-tuning part i want to ask a little more about what do you perceive as being more valuable for most use cases fine-tuning the vectorizer so say fine-tuning the dense passage retrieval step the the siamese bird or whatever you're using to encode the data or fine-tuning the reader or the reason or say it and that kind of thing and say not only just fine-tuning it on your data set but fine-tuning it to uh to be processing the retrieved context so so when you're fine-tuning the question answering model have it be fine-tuned to the retriever component of it so it's used to seeing that additional context and then that's very in that specific kind of retrieve context from the end-to-end system um very good question i'd say it really depends on the domain and use case and the data set um so i look a bit back at our customers in many cases i think we we get a big boost when fine-tuning the the reader part as well especially if it's like very specific domains very specific questions um and the style is important about the answer as well right sometimes it's not these days not only about factual questions anymore like asking i know where was isn't that founded or which here but it's really more open questions uh interpretory questions like i don't know what's the what's the strategy of this competitor in china and there you can really get uh get good performance if a few labels doesn't require much fine tuning but the bit helps a lot um and um i think on the receiver side like vectorizer um it's it's still helpful um if um your data set is very large and um if um also like combinations of retrievers don't work out for you so what we sometimes do is combining a sparse retrieval with dense retriever and if you kind of hit a barrier there um then then of course fine-tuning uh punching your achiever also can be an option now and i think that this is a as i said like this as this depends it's very important that you have the tooling to find out right that if you build a pipeline um that you have a way to easily analyze like what is my bottleneck is it the retriever that drops performance or is it the reader or any other component that i have afterwards and that was also i think one one of the motivations back then to to introduce these flexible pipelines in haystack and recently we refactored the whole evaluation part so you can get reports okay that's performance of of retriever node of the reader node and you really see what what is worth improving and fine tuning super cool and um so i'm really curious about this uh farm library that you've built out for uh fine tuning and the different components that go into it we'd imagine that uh fine tuning any kind of deep learning model you'd want to do things like maybe have these adapter layers like the compactor adapter these kind of things so that you don't have to fine-tune 100 of the parameters of the pre-trained model uh maybe things like a hyper parameter optimization with like a hyperband kind of these kind of libraries for that kind of search things like you know sparsity and then and then more so just like standard tools for training deep learning models like mixed precision and i saw gradient accumulation in farm these kinds of things that generally uh facilitate training any deep learning any large deep learning model so what kind of things are specific to farm and specific to fine-tuning the reader models with the uh like with the retrieval appendage as a part of the pipeline um so farm was basically our i think the first open source project that we published back then and kind of haystack came afterwards and actually now migrated quite some some parts from farm uh to haystack so we have it really like all integrated so um basically all of the modeling related retrievers to readers is now happening in in haystack um but still farmers from a design perspective quite interesting the core idea back then was that we really have one say language model as a component and then multiple prediction heads that you can stick up the stick upon this language model and um this is something we for example now think a bit about for for some question answering tasks um might be helpful to have one prediction head that for example um gives you the um the span answer but another one that for example can can classify this answer or can give you um just binary like yes no like if this is the span that i found and there's like a yeah it's like a yes uh answer or no answer um and uh all what you mentioned to um fine tuning tooling that is out there um is i think there's like a lot of potential and we uh we just implemented um a distillation approach installation is to there's a lot of methods out there but i think there's still um a lot of potential to to improve and uh and um has a huge benefit for um for industry and production um tiny bird is serving a nice nice idea and example um so it's i think it's one degree about the modeling part distilling maybe from a larger model the knowledge to something smaller um but also combining this idea with something like data set augmentation so everything that helps me as a developer in industry to to fine tune a model with less data that's that's uh that's super nice um and ideally it's then also faster for inference yeah and i think the um the adding of the retrieval component you don't need to store the knowledge in the parameters of each of the separate heads so you can get even more efficiency gains of not needing to have some 12 layer 100 million parameter encoder base that then attaches to each of the heads hopefully the retrieval model can replace that and then these models can be more parameter efficient so kind of transitioning a bit away from the topic of fine tuning i was really impressed when i came across the deep set cloud gui it's beautiful i love looking at it such a cool way of organizing the tasks around constructing your say first example of vector search if anyone listening to this has their data set and they just want to see one of these pipelines come together i highly recommend checking out this deep set cloud gui it's as easy as pick your language upload your documents click and pick the components of the pipeline from retriever question answering or retriever summarization and then and then even from there the rest api deployment and i love that idea of just the easy search api deployment so how do you see that kind of thing of um of this gui interface design what kinds of things have gone into the uh into the development of the deep psychology ui so for us was really important to find a say a complimentary product or open source uh project haystack we didn't want to end up with a with a model where we say okay like there's a i know super nice performing model but we don't publish in open source we that's part of the uh the commercial offering um at the same time of course we're a company we need to maintain the open source project so we need a sustainable business model so the idea of this combination now is really that we have haystack as a python framework uh who really helps developers um to build easy prototypes and solve the problem of scatter technologies so you have models you have databases you have under rest apis it's quite hard to stick all of that together and [Music] have all these skills in say one person or a single team and hashtag open source is meant for that it's a python developer framework to solve it and if that's fine for you you can just go ahead with that bring that to production build everything you want around it fine um still what we saw is that it's not always only about the technologies but it's also a lot about workflows about collaboration and uh having really the whole um say lifecycle the ml of lifecycle of a product and um and that's why we built deepsea cloud that's basically one sas platform where you really can start as you said you upload your corpus you index it you can configure your pipelines in different modes either from code or just from a yammer that you put there and you can easily share demos with colleagues get your feedback hey do these results make sense yes or no and instead of then having this feedback in excel sheets floating around you have it like all integrated in your in your database and can easily say ah like okay i got this feedback this pipeline is better than this one or trigger some retraining fine tuning based on this feedback create labels so it's really like all integrated and once you once you found say the perfect pipeline or that fits your needs just basically one click to scale it and bring it to production and we will do all the the scaling in the background in our cluster it's fully hosted and you can integrate them basically the api to your own product uh wherever you want this functionality yeah i think this modularity is so exciting this idea that you can just point to the api endpoint to add in some kind of say you want to have model inference as a part of the pipeline and you want to just point to the api and plug it into the existing pipeline and generally the idea of sharing the search api is such that anyone can integrate anyone's data set connected to these pipelines by just querying one of these endpoint demos and uh say on wev8 we have the wikipedia demo and we have just the public endpoint so if you if anyone in their working directory wants to just paste in this address you can just start clearing the vector search engine and people can share their data sets and this is really exciting like open source collaboration of uh sharing all these different things and so i want to ask you kind of uh we've seen things like hugging face spaces and and the model hub as they share model weights and increasingly hugging faces hosting raw data sets what do you think about the future of organizing these vector search demos and then having these ability to not only just access data sets but to be able to just quickly apply all these functionalities like search just through these public endpoints yeah so if it's uh for support amazing work that tuckerface is doing and we are close exchange with them and it's really great what they are building and what they're doing for the whole whole space um and um like how we see how we see it and what we are doing um is basically i would say one layer above probably so for example we integrate with a huge phase model hub so if you use deepsea cloud you can basically load any model that you have hosted there or that is public there and i still think that that right now what is missing is this kind of let's say orchestration layer where you bring things together we can say okay this model this data set or my own data set um here's a quick demo and i can share with my colleagues so i can share it in the public um and uh and that's exactly i think what we are building what i think many others are also building i think it's important to to have um to really empower developers to to cover this whole say lifecycle to show something and i think that's something missed also in in many uh ml projects now that you focus a lot on the modeling part but then if you show your colleagues or others and it's it's something quite hard to relate to it and for others to try it out and i think this is uh so important like um first of all to validate what you are building as an engineer but also to say trigger creativity and and inspiration so um if for example people from from some business departments they they saw some of our demos and um and they thought ah like that's cool i have some people be a different use case but can i also use it for this and that for for example chatbots we have some some people who um who use now qa for answering questions within chatbots or for parsing let's say if you have incoming documents every time an invoice comes in you want to ask five questions and uh like who who did issue with this invoice uh what's the amount and kind of the answer you use uh used to store it in a structured database and kick off other automated processes and i think all this this kind of innovation is so much easier if you have something tangible something you can try out and and share with others yeah and congratulations again on the deepsea cloud gui it is such an amazing organization of this orchestration layer and user interface to just point to different data set endpoints different retriever models and and now let's get into kind of these different flavors of retriever models you mentioned the idea of combining tfidf and bm-25 with say siamese bird sentence bert and having these two different kinds of ways of of different ways of structuring your retrieval model but i kind of think another thing that's interesting as we translate into the connection between the we vva document store and then the haystack pipelines is the idea of symbolic annotation of the neural vectors and of the neural search so for example if you're searching through scientific papers and you want to add the symbolic filter published in cvpr or published in icml or authored by a particular well let's say an institution could say an author might not have that many publications such that you need to really do a neural search through it but these kind of symbolic filters on top of the neural search have you thought a lot about what how that kind of changes neural search and how that kind of maybe offers another way of looking at the retrieval pipelines between say tfid fbm25 being one thing and then vector distance being a different thing yeah i think that's a an absolutely brilliant feature that vb8 has and uh and actually i think differentiates vva to many of the other vector search engines out there and um for us uh was also i think the one of the main reasons why we integrated into haystack because we heard that a lot from the community we saw that a lot in our with our own customers that really this combination of say structured data and metadata that you can filter plus a vector search is super powerful and um i mean first of all it's a nice nice way to kind of narrow down your search day so if you have really like millions of documents in most use cases there is some some text some i don't know time stamp something that you can that helps you to narrow down your search space immensely and this of course the die has direct impact on the search quality um and at the same time it was tricky to implement so it's uh it really has to i think be closely tied to the vector search engine um and has to happen if you have something like approximate nearest neighbors um which i think is quite important at in production deployments and then uh it becomes tricky and um and they are having this combination i think is super nice in general i would say leveraging metadata or structural information as uh is super helpful um one thing for example on our growth roadmap that you want to explore further as well to leverage document structure uh even more so that you can say you have a pdf so you have like a lot of titles in there maybe captions of images and as of today most uh most search engines and uh and models um treat that in the end as similar like plain text uh but really using the information hey this is another headline or um this is i don't know the the title of the the chapter um this makes makes life so much easier at query time um and i think also for uh like building embeddings then for these kind of uh information is a nice direction in future that we're not it's into hard filtering or then bm25 on this kind of metadata but really embed those titles embed the whole document structure and and use that at queer time yeah and it's interesting because you can still use these filters in the h sw uh a n index algorithm so we build these data structures up so that we can facilitate the speed of doing vector distance comparisons but you can still add these symbolic filters within something like an h and sw graph as eddie and dillocker at wv8 has explained many times and finally starting to understand it a little bit but um so let's get into this um query classifier the idea that the query classifies whether this is a tf idf query or if this is a neural search query and i want to get your thoughts on whether you think it's a worthwhile direction to say have a query refinement step where it adds the symbolic annotation onto the neural query so rather than saying oh no this is mostly keyword we want to make like say um say you google something about a company like uber and then you want to do a regular expression symbolic filtering or say make sure uber is in the title of the return article do you think we could have a intermediate query refinement neural layer trained with uh you know gradient descent and some kind of annotated data set for this that would add the symbolic annotation onto the neural search layer rather than say separately querying a tf idf index or separately querying say like even an sql index because it's like a purely symbolic search or it looks purely symbolic different from say you know some kind of sparse some kind of like machine learning style based representation of the data do you think that kind of thing could be uh fruitful yeah i mean in general i think it's it's uh it's an interesting direction um the career classifier in haystack pretty much comes from the uh i would say from a from the user behavior what we saw is that um many companies if they already have a product which allows search people are used to keyword search right that's what they type in and it takes some time to um to make them aware hey like there is a if you there's a smarter way of searching right and uh if you really put a full sentence a full question whatever more context in then you get better search results and that's the same thing with google right they are slowly transitioning towards uh towards say more contextual search and they suggest queries and um they display hey is that what you like the question that you they were asking and um and i think that all goes towards this zero click search that you have searched something and then you directly see what you want and you don't need to click on the on the website and then find what you're looking for um but i think yeah there is this uh educational period and um and that's where we uh where we implemented where i added this clear classifier that you can really see hey this is a keyword query uh and then maybe just use your existing old search engine probably just plain pm25 or whatsoever and you know on the other side if it's already a semantic um query you can route it to your to your second stack and uh and that really giving you say both of the best of both worlds but if because if you have i think really it's like classical keyword queries um what we saw is that at least the most most dense retrievers don't work that well if you just query for let's say uber um yeah probably really looking specifically for this one um and and bm25 it probably outperforms yeah we've talked about this topic many times we love this term of serendipity this idea of uh you know not really knowing what you're searching for sort of is a good way of thinking about how to traverse through neural search results and also sort of blurring the lines between the task descriptions of uh like retrieval re-ranking and then recommendation systems all kind of blurring into the same kind of task with searching with uh neural search and and yeah i really like the idea of using the user behavior as you kind of uh fine-tune this way of thinking about it so maybe thinking about like you know dressing up the query with neurosymbolic and maybe even graph structured cross-referenced linking then having maybe like a special user input embedding specific to each user based on their user data or something to help them kind of ex help them understand the neural search because yeah it's it's definitely interesting when you search for something get a completely unrelated thing but because it's like this fuzzy way of relating the things it's definitely an interesting thing and um so transitioning into some kind of new innovations around the space i really want to get your take quickly on um on what you think will be the impact of like having longer input sequences to transformers so say going beyond 512 tokens models like big bird sparse transformer long form and these kind of things of especially it seems with retrieval being able to not just average out the embeddings but maybe have the attention within in like the parametric kind of processing within the same input um i think that's a an obvious and a big step forward and and the super important one i think at the moment developers pretty much got used to this 512 tokens it already seems like a fixed concept in the mind of developers but of course it's not and and i think it's just was for me but actually it's a bit surprising that it's uh it takes such long time to kind of make the steps i mean there's of course some some models out there big bird you mentioned long former and so on um but still i think for many tasks they don't perform equally well um i do also believe that for retrieval it can make a big difference um um and um you know that one big impact i think will be on the speed side if you you really have an efficient model there i don't need to like split documents any further like in these these passages have sliding windows and all of that um it will be immensely helpful and i think it's just a for me it's just a matter of time to uh that we get to a point where we don't think of 512 anymore and i think maybe it'll come in parallel advances in thinking about tokenization like uh things like i think it's called engram transformers they look at uh different ways to not just have subword or bipolar level encoding where they have other kinds of strategies of maybe tokenizing and that might come into play with the things like bot like computational bottlenecks compared to all isomorphic kind of transformer designs and maybe these kinds of things and so one other thing maybe is using the document structure could be a way to further increase the retrieval step what are your thoughts on kind of incorporating the structure of a document whether it's a scientific paper and you maybe have like this is the introduction this is the related works and i'm sure all sorts of industry things have that kind of style where there's some mana it's not just like a block of text from the top to the bottom yeah i think it becomes immensely helpful if you if you go towards a real world documents that are like not always structured in the same way um one example is for example uh so like you know company wikis or like short documents of let's say meeting notes uh no one writes like a full full length paragraph explaining everything in full context but it's often really i know five headlines three bullet points that's it and uh what we see is that um yeah if you have a model that is trained on say wikipedia or natural questions and then to try to apply it to such a document format that's quite tough and um and that's why i think like making use of this kind of document structure even more like formatting what is bold and just like what we used from let's say the visual editor i think is also helpful to to give us input to our models and and let them leverage this as well yeah and i really like this paper called a hypertext language model where the htlm where they keep the html html tags from the web scraping so that you have the uh you know ul tag li that you have that kind of structure and then they do things like when they're prompting it to get the inference they'll just add the title task to like title brackets mask and then it performs better because you the scale of the data and the scale of that kind of free annotation so then another kind of thing that's like lurking in these text data sets mostly are tables and especially with you know i'm really interested in looking through scientific paper data sets and having these tables and so what do you firstly what do you think is the best way to represent tables for the downstream processing is it say html tags where you have say table header table row that maybe i don't know if that's the best way of doing it i've seen an interesting thing of like wrapping it in panda's data frames and trying to have that kind of pipeline what's your thinking around table question answering within this kind of framework um yeah so we see that's a super interesting direction and um when we started with haystack pretty much focusing on text data but it was uh i think uh clear from from day one that it will evolve to more data types and the vision for hashtag is really to um to have a semantic layer that you have like any say textual input any query you want to find information and query that into your whole say data base or data lake whatever is in there and and of course many others are focused on images also interesting but what we saw from community and then our clients is actually that tables is the more pressing demand after the tax documents especially from financial financial institutions they have like a lot of annual reports for example where information is stored in tables scientific papers you mentioned it in technical documentation we often have also kind of table overviews and making sense out of that is super helpful um in terms of representation yeah i think um there are there's still not really a standard out there when you look also at papers and models how they do it um what we thought that we found is um data frame is from a user perspective now again is kind of a standard interface it's not really standard for the modeling part yet but it's a very nice let's say exchange format and you can easily get another table out of of sql put in a data frame you can pass a table from a pdf document put it in a pandas data frame you can do some interactions easily with it you can inspect it and then you can kind of pass it down to a model and uh how it's represented there it's then a bit of a question of what the model wants and expects um yeah so overall i think it's a it's a super interesting direction and last year also like a lot of innovation happened there with tapas making big steps forward but we also recently implemented there's another model called raw column intersection so i think there's still also a lot of different approaches out there and we'll see which will which will make it at the end uh that's i think also the exciting part uh about this this whole field still um but um i think they are now at a tipping point where they become useful for for industry and that's uh that's quite quite interesting um you they i'm not sure if everyone is unaware of what you can do there right now but it's uh it's you can really ask questions where the model then finds the the specific cell in the table so you can ask i don't know who won the champions league last year uh or soccer champions league last year and it will find the the club who won that um but you can do also like aggregation operations and that's i think quite quite interesting that you can ask how many times did uh bayern munich won the championship and it would basically kind of create a something like a sql query and ask like okay where in this table is this club and count how often it appears or you can do like an average of this and um and uh if you think this a bit further it opens up a whole new kind of data set which is then not only the small table in the paper but it's really like a whole sql table or whole secret database and you have a model that kind of produces the sql query and um and i know you can have a uh maybe a business analyst and you want to ask like what's the average revenue for uh i don't know china last week in this product segment and you can have a basically a model that builds this query and gives you the answer and um i think this would be like it's more powerful yeah i love this idea and i've um i like this paper called turning tables where the idea is instead to have like a natural language generator from the table so you parse the table into natural language and then maybe you know you don't have to have be so multi-modal between table and text and you just kind of have all text even if it's in these two different kind of styles i think it would be really cool kind of also maybe to try collecting uh data sets of have a table the table and then the image like the plot that describes what's in the table and then maybe also like what they call the cytance or maybe like the figure scitants that where the figure is being referenced in the text to kind of come up with those kinds of tuples and see if that can kind of power the application of that kind of idea of reasoning through tables and another really like kind of interesting idea i think is adding images videos i think videos too there's like a lot of video information things like as we record this podcast and all sorts of it kind of is like easier to make videos than it is to make uh to write write articles and maybe also there's information in the audio like the tonality the way that you say things probably some more information there for some applications what do you think about like image search and adding these kinds of data types as well to the pr probably like text search is kind of like the dominant thing it seems um yeah i think it really depends on the industry and um and for sure i think there's everything that is in the web is is mostly i'd say on these data types uh images videos audio like super interesting um we had a few months ago like um something you call hacky friday so once a month in the company every developer or every every employee actually can work on anything right that he or she is interested and uh and two developers there built like a podcast search for example where you can search for podcasts and i think for these kind of use cases that's super nice and and if you also think it a bit further um really having them multi-modal models that that not only let's say can query it but can really learn from different modes and combine this knowledge i think that's an interesting so that you maybe your company you don't have so much video data but you're using a model that used video data to to gather um say the the initial knowledge and you can still apply it to other data sources i think that's super interesting and um think with uh some of the current models we are a bit going in this direction um [Music] so i think it's uh as we mentioned earlier um if you have a multimodal model i'm still curious if um if these models will become then very efficient if you're say just using them for text data or if you have like say a lot of overhead a lot of extra parameters just to cover let's say audio but maybe in your deployment you actually don't care about the audio so is is that really a value um or is it just overhead that you carry around and you know let models grow and influence times can explode yeah i've been thinking about that so much as well i really like this paper called vulcanization where they're able to use images to facilitate like the glue benchmark for language understanding and uh as i'm trying to process uh like scientific text and deep learning thinking maybe the figures the illustrations of of the algorithms could maybe be useful and hopefully yeah like efficiency gains achieved by this kind of multimodal fusion and and another thing uh just like another kind of data modality would be like graph structure so what do you think about graph structure and i think when i think about graph structure i think about how much the complexity of it can kind of blow up unless it's like a citation graph or like a friendship or like something that's natively graph structured but this idea of like particularly adding graph linking between uh any kind of thing that might be in your database and then maybe having like knowledge graph style like pie torch big graph deep walk no defect these kind of embeddings on that kind of graph structured uh adding it to any kind of data say sort of artificially um yeah i mean um if if it works out if you have such a graph that's awesome i think you can leverage it a lot um and and do a lot of interesting uh inference a lot of interesting queries um [Music] i mean i think there are these two kind of categories right like more say classical knowledge graphs and and a lot of stuff that happened also in the early 2000s um and then more recently i would say these uh graph neural networks that that really use their structure also at modeling time um for the let's say the more classical part more classical knowledge graphs um we actually explored this direction um earlier this year because we heard it also a lot from community people um having also some some of these like bigger corporates for uh especially having uh such uh structures in place um and want to invent them to use or to leverage at uh at such time at query time um and if you have a high quality graph i think that's awesome and it's hard to beat and if you have uh if you look at google search um still a lot of the uh the answers uh are powered by um some some knowledge graph um the biggest problem that i see there in practice is if you're not one of the top 10 tech companies out there um it still needs a lot of effort to produce this knowledge graphs ideally automatically you just have a corpus and create this graph automatically out of it and then to maintain it now to really make sure that the quality is is consistent over time if things change because i think the worst thing is if you have a knowledge graph with every knowledge base if you have a knowledge group that's outdated then it's it's it's really bad um so i think if there is a way to efficiently construct these kind of knowledge graphs that would make a big leap um yeah right now i think it's for many companies quite quite tough to create one yeah and i think there's kind of like two sides of as we mentioned earlier with this idea of query refinement and adding symbolic tagging to your neural search that's one way to use the knowledge graph whereas the other way would be you use the knowledge graph in the training loop to influence the vectorization of your original data objects and that second one being the one that's maybe more prohibitive and maybe more challenging to really make it happen but things like say the we v8 layer make it really easy to just kind of use your knowledge graph annotation to to filter your search and guide it and help it that way whether really getting a multimodal graph embedding added to an image embedding text embedding that thing might be a little more challenging to really uh work out and practice and so that kind of thing yeah thinking about that kind of graph structured and we it's definitely one of my kind of favorite things about the weevil vector search so we've covered a ton of different topics i think already and i'm curious like um kind of what's on your roadmap in the terms of like which kind of idea is exciting you the most right now about vector search engines overall so i think it's generally like what we uh it's a lot still about uh making this uh easily scale and uh what we look right now or like what we implemented recently is uh is basically deploying pipelines uh with array framework i'm not sure if you had a look at it but it's like really a super exciting framework for distributed computation and uh really makes it easy um to for example take a pipeline with different nodes and then run nodes independently on different machines scale them independently and and have them all connected so that's a second production deployment side and quite interesting then everything let's say around just data augmentation and simplifying this fine-tuning domain adaptation step so um for example one paper that we recently looked at is called like gpl like generated pseudo labeling um for unsupervised unsupervised dense retrievers um and the idea there is basically that you create you have a model that creates some query answer pairs or create document pairs in that case and you use a cross encoder to kind of label this and score this and cross encoder usually gives you better performance for these type of query tasks and that's why they're used for for re-ranking um but they are rather slow so use this kind of let's say bigger model teacher model again to create a data set without any human labels just you put a corpus and you get these labels and then you train a smaller buy encoder based on this data set and i think these kind of approaches like using models like bigger models more expensive models to create something useful then to create like to train a smaller one this kind of uh let's say tricks is what really interests me um and i think are like quite helpful for for industry um that's one direction the other i think is everything around continual learning i think really incorporating human feedback um either if the model is already in production um probably want to measure okay what what are people searching what uh what do they think of these results incorporating that in your in your model retraining but also in earlier steps if you do some labeling how can you fuse in model predictions there like everything that's i would say between uh human and machine collaboration is what we are doing these days um it fascinates me yeah awesome that's a lot of interesting stuff so to kind of uh unpack it a little bit and go step by step yeah as as we were talking earlier about uh the farm fine tuning library and maybe things like that might be specific to retrieval augmented pipelines that idea of having the knowledge distillation from the cross encoder or like the tri encoder even where you have say query uh relevant or like um yeah like query relevant document and then like negative relevant document right and the kind of design of a try encoder or as you generalize that to however but the difference being that it's in the input directly and then you have the attention over this whole thing the idea of distilling those representations down into the siamese encoder which is faster doesn't require as many comparisons for inference and yeah i think that's really interesting of like maybe like a unique part of a fine-tuning library that would be appended to a vector search engine library kind of so to say and then yeah i really like the data augmentation uh the idea of like robustness and being robust to negations and that kind of thing and really testing that in uh retrievals because uh yeah just in general that idea that if you add like not or switch the named entity it doesn't react to that it sounds like a huge problem for retrieval pipelines and then yeah continual learning that catastrophic forgetting thing definitely still seems to be like the achilles heel of deep learning even if it does seem like big models somehow don't aren't affected by it i guess because they have the parametric capacity to store all these tasks in it and then kind of lastly um to come back to the distributed pipeline in ray and uh distributing the competition the notes could you give me like an example more so so i can better understand how like what parts of the retrieval component are being uh parallelized so it's uh i would say it's not so much about say the single retrieval um node but in in in haystack really more if you have bigger pipelines where typically let's say there's a this might be a dense retriever there might be also a sparse retriever then maybe you can find it then there's a reader model maybe you have a summarizer as well and and what ray allows you is to basically abstract from these nodes and put them on the like encrypted with the resources they need so you can say okay maybe this dpr retriever like super heavy model okay let's put a gpu node on it but uh maybe for some i don't know sentence transformers or the sparse retriever um cpu node um and for the the reader model again something else and um and that's basically what you what you need to think of from a development perspective the rest is more or less handled by ray um and if you will think about production use cases um it's really that you can let's say the deploy your pipeline and then let it auto-scale and uh and with some restrictions that you say okay this node shiva is always on the gpu or like there's many gpus and please equip a new resource and spin up a new machine if the traffic is kind of growing and um and i would say what we are doing is basically using this rare framework under the hood uh again building the orchestration on top so that it really works for for these nlp pipelines retrieval based pipelines um doesn't really need to worry about scaling anymore so that's usually you need uh like a single cloud instance and then ray will wrap say like docker containers that partially like portion up the single cloud instance or is it you have multiple machine multiple cloud machines that ray is routing it through entirely different machines so it's kind of like a hybrid between the two where uh ray say constructs these docker containers that say how many what percentage of the resources say to use on each machine and then it kind of routes through that is that kind of the correct understanding of it yeah kind of so it's really i would say like a similar bit similar to the kubernetes cluster and you still have multiple machines on the cloud and then on top you have this basically this ray cluster which makes use of these machines you have like a master node you have some uh some additional nodes and uh and and you can split them the resources independently so you can say really okay i want to use for this node uh 1.5 gpus and uh and ray will take care of placing this uh within the cluster within the machines super cool and so it kind of is like a question of wrapping this up i wanna i'm curious about uh like as i personally have been kind of navigating deep learning technology and uh trying to learn how to build things i thought i found it very useful to have kind of like one application in mind that i would really like to see come together is that or compared to say where you're building out a technology company like haystack and you see all these different use cases what do you think about kind of the philosophy of either looking at like thinking about things that will generalize to all the applications or maybe digging into one specific thing that you would really like to see come to life like the podcast search for example yeah i mean so what we are i mean there's a lot of use cases out there that we are super curious to to see and uh uh and really like when this when you see that from community or from clients but um we as a company are not let's say building or focusing on one of these solutions um but we really enable these use cases and build a platform that helps developers out there to build and to um and to help to build these products and use cases as easily as possible and uh that's for me uh uh we have like a slack channel where we share this regularly like what people from community share or like customers and it's just so fascinating to see like what what people build themselves instead of let's say hey we built or we provide a solution for financial research it's like of course you can like optimize this endlessly um but it's quite narrow and uh and uh yeah i'm a big fan of uh giving this flexibility um and at the same time probably yeah building the tooling for let's say a few areas to really make it easy to build these final use cases yeah i think like anyone kind of working in almost like developer tools if you will like has to be able to have that kind of generalist hat thinking where you kind of are switching in a use case in your head and yeah i think that's a really interesting way of thinking about it might be do you think it's like harder to do it that way to keep adapting to some new thing yeah i mean it's like it's of course if you have something very generic it's i would say constant back and forth like you know you have like your hypothesis hey that's what people need and then you need kind of to wait for okay that's what they actually built with it and that's how they used it and this was maybe helpful it's not but you always think reliant on this feedback loop to understand and uh and that's why i think it's uh it's so important to do that on open source because the feedback loop is quite faster you see what people are doing what helps them what not and it really helps to build a nice developer tooling and imagine a closed source you always have to know sell it to someone ask them for feedback um it's just ways more away slower awesome thank you so much malt for coming on the wvva podcast and uh to anyone listening i highly recommend checking out the deep set cloud it's a graphic user interface for setting up this haystack pipeline where you select your language you upload your data you can even drag and drop pdfs they have a pdf extractor built into the haystack library that could you could drag in some say archive pdfs and then get your first vector search going that way and it's a super cool way in and clicking around the pipeline i think it's one of the most exciting uh ways to visualize what's going on with plugging these different parts of this end-to-end retrieval augmented pipeline together so again thank you so much malt for coming on the wva podcast and thank you everyone to listening and please subscribe for more podcasts like this ", "type": "Video", "name": "weaviate_podcast_4_on_deepset39s_haystack_and_how_they_leverage_the_weaviate_vector_search_engine", "path": "", "link": "https://www.youtube.com/watch?v=9DTDUHs3aB0", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}