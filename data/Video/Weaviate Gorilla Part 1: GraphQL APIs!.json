{"text": "Hey everyone! Thank you so much for checking out the 1st episode of our Weaviate Gorilla project! We trained LlaMA 7B to write ... \nhey everyone thank you so much forwatching movie it on YouTube I'm superexcited to present the weeviate gorillaproject we fine-tuned the open sourcellama 7 billion parameter large languagemodel to translate from natural languagecommands into the weeviate graphqlsearch apis so we're better equippingthe large language models to useweeviate by interfacing them with ourgorillas and gorillas are these smallerlanguage models that are specialized ona particular set of API through the useof retrieval aware fine tuning so thisproject also has a nice side effect ofmaking it easier for humans to useweeviate because by translating fromnatural language commands into levia'sgraphql apis it lightens the learningcurve a little bit from learning how todo you know compositional queries andjust knowing all the queries that you'reable to execute which is another kind ofnice side effect of this project is itserves as a query router there's a lotof interesting discussion aboutcombining SQL queries with Vector searchand the gorilla has a nice kind ofoff-the-shelf effective it takes thenatural command and it out to whetherthe alleviate aggregate query which ishow we do symbolic aggregations like SQLstyle or the gate query as well as thesenice trick shots where you can do avector search and then do symbolicaggregations on the results of thevector search so all sorts ofinteresting things there I would saywith this project if you're curiousabout the future of llms and Tool use Iwould kind of say software broadly ifyou have a set of apis and you want tosee how we did it how we useself-instruct prompting to generate atraining data set how we fine-tunedllama 7B using hugging faces amazingpath library and then substratusorchestrating kubernetes and k-8'straining as well as you know visualizingthe results and how we're thinking aboutevaluating this kind of thing so reallyquick one more thing that we'll get intoin the discussion but I want to quicklypresent in the introduction is theimpact that this might have on softwareIntegrationswe can imagine a natural languagecommand build a question answeringsystem using llama index and weviatevisualized and streamlit and similarlyto how you know code interpreter on openAI is able to just you give it a fileand say make me a graph of this we'repretty we're getting pretty close to LMSthat write code and use specificlibraries like we V8 and all these kindof things so I think this is such anexciting project I had so much funworking on this let's dive into it thisvideo explained the weevier gorillaproject continuing on the introductionwith a bit more of a visual Flair thehigh level idea is LOM tool useconnecting large language models withexternal tools that allow them tosupercharge their capabilities and bemore productive generally so for exampleif we want to answer the question what'sthe weather like in Boston right nowthere's no way that we can rely onlanguage modeling the internet or evenreinforcing learning from Human feedbackto answer a question like this theemerging solution to questions like thisis to connect large language models withthird-party apis so we have our largelanguage model and then we have somekind of weather API in order for thelarge language model to talk to theweather API it needs to format itsrequest in the API compatible way sothis API may have input arguments likeCity where it expects a string likeBoston Massachusetts maybe it expects azip code and so you would have the zipcode and needs to learn to format therequest in this particular syntax so ifit expects the string BostonMassachusetts for example and insteadthe large language model says zero twotwo one zero the API may be unable torespond as well as processing say thedate argument so apis have a particularkind of syntax that they expect and weneed to get our large language models tofollow this syntax the API example maybe how the weather example might be alittle simple but you can imagine withweba we have more complex apis than thatso the general idea is connecting largelanguage models to all these externaltools to supercharge it keep itsknowledge up to date as well as to letit execute computation so we connect LMSto calculators or code executors searchengines or databases as well as thingslike weather apis or say your personalcalendar as LMS are becoming ourco-pilots and assistants in our lives solet's dive into weeviate as a tool forlarge language models in this project wealready assume that we have alleviateinstance running with the data schemaand data loaded into it and we'relearning how to format API requestssearch requests to this running databaselater in the discussion we'll discussthe more open-ended idea of lettinglarge language models create new classespopulate new data and all those excitingdirections so let's say we have somekind of natural language command with apretty complex weviate query what is theaverage complexity level of yoga posesthat are similar to warrior pose with amaximum distance of 0.15 we translatethis into the weva query where we useaggregate our yoga pose class we useVector search and then we use a symbolicaggregation to get the averagecomplexity of the results from ourVector search so this is a bit of aconfusing query that I don't think a lotof new leviate users know you can dothis as well as other things like thisso the general idea is to let youtranslate from natural commands intothese queries so we need to generate atraining data set that takes in thesenatural commands the API reference forthis composition of aggregate VectorSurge and then calculating the mean ofthe results of a particular property inthe wevia class we returned as well asthe custom schema for yoga pose whichhas properties such as this complexitylevel as well as some vectorizedproperty that's letting us Vector searchwarrior pose so as this may be alreadyevident making it easier for largelanguage models to use tools also makesit easier for humans to use them so thisis a proposal for the auto API where wetake a natural language query like showme the full name and email of contactsthat contain John and their full nameand then under the hood the wev8 graphqlgorilla will translate this into theproper graphql query using your schemaas well as the API reference and thenexecute the query also giving you theoption to visualize the generated queryusing the following syntax so we'll talkabout the auto API proposal a bit laterin the video in addition I think thisvideo will be interesting to anyone outthere who's wondering how do I fine-tunean llm for my API so whether you have aset of apis and you want to alsofacilitate this natural language commandto using your software I think you'll beinterested in this project so let's diveinto the overview of everything we didto create this model here's everythingwe did to train the wevigate graphqlgorilla in a two minute overview webegin with four data sets we have aknowledge base where we have syntheticdatabase schemas we give gbt4 a prompton what a levia database schema lookslike as well as asking it to write atleast two text properties at least oneinteger or number property as well as atleast one Boolean property and at leastone cross reference from this class toanother class we create 50 such toyschemas from Cars to instruments to allsorts of things so then we have ourknowledge base of API references thiscontains all of the apis and we V8 howhybrid search wear Auto cut re-ranking46 such apis some of which are Atomicfor example bm25 only describing bm25 aswell as some compositional APIreferences like how to use bm25 intandem with the wear filter then we havetask examples these are manually writtenexamples of how to translate from an APIreference and a a custom schema into anew query as well as how to translatefrom a custom schema API reference andquery into a natural language commandbecause we're going to be generatingsynthetic examples to then train with sothe first thing we do is we take theknowledge base of synthetic databaseschemas and API references as well asthe example of how to do this task andwe create new queries by looping throughall of the database schemas and all ofthe apis so now we've created 2300 newqueries for these synthetic schemas wethen use this to create natural languagecommands for when someone would want toexecute these queries so now we havethis is the entirety of theself-instruct algorithm now we havethese two data sets of queries as wellas the natural commands for when wewould want to execute these queries wealso can use these uh this naturallanguage command set to evaluateretrieval we'll put the natural languagecommand as our query and we'll see ifit's able to return the API referencethat was used to produce the syntheticnatural language command and syntheticquery we then take the new queries inthe natural language commands and wetemplate this into our fine-tuning dataso in the fine-tuning datathe input will be the synthetic databaseschema the retrieved API reference aswell as the synthetic natural languagecommand and will predict the syntheticquery we use this in substratusorchestrating kubernetes and k8'straining also using the hug and face peflibrary to train our Guerrilla largelanguage model we then evaluate ourgorilla large language model by firstlysimply asking does it execute and we V8by looping through the schemasinstantiating them in Wii V8 and theneven if you don't have any data inweviate if you execute a query if yougive it a incorrectly formatted query itwill give you an error message otherwiseit will just you know give you an emptylist of results so we can test quicklyif the query executed we also use llmevaluation which is where you give aninstruction response paired to gbt4and you ask it did this response followthe instruction you could similarly tryto maybe correct the response by usingthings like reflection prompting butthis is another way to get evaluationmetric off the shelf we can also use theperplexity metric where we see uh youknow we force the language model togenerate the ground truth queries thereis a bit of variance in the queries forfor some of them that might make thisdifficult as well as the engram mesh sowe'll talk more about evaluation laterin the presentation really quicklybefore we dive further into the detailsof self-instruct prompting and how wetrain these models and evaluated themhere is the proposal for the auto API soif you have a second I'd reallyappreciate if you could check out thisAPI let us know if firstly you like theway that this looks if this is somethingthat would be useful to you as well assome of the details of particularly howwe would package this if if that makessense so overall this is the idea ofhaving an auto API where you could justgive a natural language query and thenyou could see the generated query aswell as under the hood Auto wouldtranslate and then execute the query sothere's all sorts of details in thisabout how exactly we would serve theWi-Fi Guerrilla model how exactly wewill do the retrieval aware inference soif you have a second please leave athumbs up if you think this would beinteresting it really helps usprioritize what to work on so thank youso much for checking this out so divingfurther into how we train the Evagraphql gorilla we're going to coverfour main parts self-instruct datageneration fine-tuning llama 7Bevaluating the model and then discussionand next steps for the gorilla projectso beginning with self-instruct datageneration so we start off by creatingsynthetic schemas for all sorts offictional webia use cases we do this byprompting gbt4 here is an example of aweeva database schema and then we giveit an example of the Json for a manuallywritten schema then we give itinformation about weva classes andproperties just describing how classesare the atomic abstraction for some kindof object and then it has theseAssociated properties and then someinformation about properties like howthey can be text you specify one textproperty to vectorize the object as wellas you know in properties Boolean andthen cross references from classes toother classes such his book has authorauthor being another class so then weprompted could you please design fivemore fictional schemas for each couldyou please include at least two textproperties at least one inner numberproperty at least one billion propertyand at least one cross reference for thecross-reference class can you pleasecreate that class as well with at leastone text property and at least one inproperty so this lets us then generatesynthetic cross-reference classes wheresay we we search through books then weget the author and then we want to seeuh let's say the average let's say youwant to do a symbolic query on theauthor that you've linked this way andyou want to say the average number ofbooks they've written or something likethat so we can do this kind of thing byadding these properties and making surethat each of these synthetic schemas areable to cover an exhaustive set of thensynthetic queries so for this step Icurrently did it by just manuallylooking through the schemas to make sureeach one was correct because an errorhere would Cascade severely into therest of the data the result of promptinggbg4 like this is that we end up with 50synthetic schemas so for example here wehave a book class a description a bookfrom the library configuring the hswvector index the model that we want touse in this case the hugging phaseTransformers to vectorize each bookobject in our class as well as theproperties we have title the textproperty summary text property pagecount in is available Boolean and thenauthor the cross reference to the authorclass so we generate 50 such syntheticuse cases of weviate across all sorts ofdifferent applications of leviate frommusic to video games to say clothingtravel destinations or even AI modelsthemselves we generate all sorts ofsynthetic use cases that we can then useto create these synthetic queries andthen have training data for our gorillamodel so overall it takes about twohours to generate 2 300 queries and thiscosts about 12 using the um in this casewe're sorry we're using gbt4 and and thethe GUI to generate the syntheticschemas and then we plug the syntheticschemas into a prompt template with theAPI references and an example of how towrite a query for a custom schema intothe prompt so there I'd say theinteresting thing here is that there aretwo knowledge sources the API referenceand the custom schema as well as a taskexample task examples a few shotexamples kind of got swept under the ruga little bit with the whole rohf thingbut I would say it is Paramount to thesuccess of this project is usingexamples of tasks can supercharge thiskind of prompting so I highly recommendyou know whatever you're doing withlarge language model prompting to addexamples of the task you're trying tocomplete so so then this takes two hoursto Loop through the 50 synthetic schemasthe 46 apis and generate 2 300 queriescosting about 12 using the openai gbt3.5 16k API so here are some futuredirections for the data creation sofirstly validating the queries so we canyou know Loop through each of theschemas load in the Json create theweeviate schema and then execute thequery but I think you want to have a wayof doing this asynchronously doing thisin the background where you generate thequeries on one thread and then you arevalidating the queries somewhere else soit doesn't block the program and slowthis down because uh two hours isn'tsuper fast and you don't want to beadding that extra layer in there thatcould you know blow it up so another wayto get more data would be to add theprevious example again so you'd say youknow here's the previous example of aquery generated and also if that didvalidate that would be a really greatquery and what that would result in isdiversity in the kind of query sent thekind of filters used if you're promptingit to write a custom wear filter as wellas which properties it then accessesfrom the query so another interestingthing is thinking about Atomic andcompositional apis so this is quite adeep topic where with weaviate forexample you can combine bm25 with wearas well as other features like usingunderscore additional to get the vectorof the object so thinking about whetherso we have 46 apis but it's not exactlythat's not the combinator works of allthe compositional apis that you could dofrom the set of the atomic apis so wecould probably create even moredocumentation synthetically throughgenerative feedback loops by combiningour Atomic apis where appropriate andthen creating more documentation on howyou might combine all sorts of apisparticularly from this perspective of uhgorilla so now that we have our trainingdata set created by self-instructprompting using the API referencessynthetic database schemas and taskexamples we can now fine-tune the Llama7 billion parameter large language modelso to do this we teamed up withsubstratus AI and particularly Samstalinga really LED all this I'm goingto do my best to kind of explain hiswork on this so we begin by loading theparameters for hugging faces a languagemodel fine tuner we'll see this laterthen we load in the model we we alreadyhave this model saved in our directorywhere we've saved you do the Dot frompretrain and you have the Llama 7billion which is pretty straightforwardto figure out how you do that on onhugging face so this is one interestingdetail I'm not sure if I have thiscompletely correct but I think what youdo is you load the model in 8-bitprecision and then I think once it getsinto memory then you convert it back tofloat16 I'm not sure exactly how that ifthat's correct but so then we load ourdata set and again our I don't know ifsome this in the video yet but our thisdata set is open sourced on WE V8hugging face so then here's the promptthat we use we put in the instructionand then the response is the completionand this is what you use to pass tohugging faces fine tuner so then we haveour model we have the config for ourmodel things like the positionembeddings the max length from the modelthen we add the special padding tokenwith the you know the open squarebrackets capital letters pad then wetokenize the data set with the maxlength and then the padding truncatingsequences that are too long okay so thenwe have our data set now we're going touse this incredible PFT Library so oneof the most interesting things that arehappening in deep learning is sparsefine tuning when we fine-tune somethinglike Lama 7B we don't need to update 7billion parameters rather we can upupdate a subset of the parameters andthere are quite a few algorithms forwhat how exactly you update the fewparameters Laura low rank adaptation isone way where you do a matrixfactorization and you only need toupdate the eigenvalues of this Matrixfactorization so it's a bit tricky butit is one of the most interesting waysof having this you know Vector that'ssparse relative to all the parameters asyou see we have uh 6.7 billionparameters in Lama and we only need totrain 8 million of the parameters byusing this sparse fine-tuning thing withLaura which it is interface with huggingface and you know I say this a lot onthe podcast and stuff I feel likehugging face has created such anincredible Library also Mosaic mlthey've made it so much like they'veabstracted so much of this and it workspretty well that I personally don't findmyself feeling like I need to investinto unpacking the details of these kindof things but unless that's your thingobviously then then dive into it butanyway soso now that we have our model set up andthe training data set now we use thedata collator for language modeling soright now with leviate Gorilla we'rejust language modeling by using that umyou when you give it this prompttemplate uh sorry this prompt templateshown here it will only language modelthe completion part instead of theinstruction as well which is kind of anice effect of this and it'll also dothings like um you know back in the daywith hugging face language modeling youwould just basically concatenate all thetext you had into one gigantic text fileand it would just randomly sample fromthat but this is doing it has more stuffnow on uh separating each input outputexample from each other so so then oncewe train the model you can see our losscurves that we'll visualize in a secondokay so as shown in the notebook now Igrab that uh the training loss and stepsdrop that into a text file and give itto open ai's code interpreter which Ifeel like is a neighbor to our gorillaproject here and asked it to visualizethis data so we see this learning curveyou always have some variants inlearning curves but generally we seethis decreasing law us and this is quitelazy you know we only have the trainingloss for now it would be good to showthat overfitting curve where you alsohave the test loss and you see if thetest loss is decreasing with thetraining loss but for now we just wantedto you know get running with having fita model but we do when we're showing yousome results at the end of the uh thepresentation as well as the blog postthose are from held out schemas and APIreferences and we have done some traintest splitting just but we've justmanually inspected it instead of havingit in our quantitative evaluation Loopso with concluding here are some ideas Ihave about fine-tuning these kind ofmodels so firstly in a new podcast thatwe're going to be releasing on Wednesdayfarshad farabakshian describes this ideaof skill versus knowledge and giving theexample of a lawyer for how to thinkabout for one class of thinking aboutfine tuning in this way of thinking youare a lawyer and you have the skill ofhow to parse these legal documents youknow like me personally if you gave meif I had all these legal documents and Iwas your lawyer you would be in troublebut uh lawyer who's been to law schoolhas fine-tuned in a way to have theskill of reading the the knowledge soyou have the retrieval augmentedgeneration to provide the knowledge aswell as learning the skill for how toparse the knowledge and I think that'sone really strong way of thinking aboutfine-tuning you've always had this kindof argument around domain-specificknowledge like the idea that you wouldneed to take the gbt3 language while onthe internet and then fine-tuning it onmedical information that idea has beenaround forever and I think that's verysimilar to the lawyer example but nowwe're seeing this new one of tool use sothe exciting thing about tool use and Ithink one of our interesting researchquestions here is how much can wecompress this gorilla model because theLlama 7 billion parameter model ischeaper to serve than these you knowmassive 200 billion plus parameter largelanguage models so how far can wecompress it to using the Translatingnatural language commands into thegraphql apis and this would make it makethe whole thing cheaper more economicaland let it do several Generations likeunlocking all this kind of like tree ofthoughts planning all that kind of stuffokay so now let's dive into some resultsof our wivier graphql gorilla so takenfrom the natural language command andagain we so we have a few training runsthere are a few models if you go tohugging face and you look at the modelson substratus a AI these are models thathave done the train test split and we'relooking at novel API references as wellas schemas so what this means is that inthis case we have a contact you knowlike this is like the contact schema andwe're generating a new query so in thiscase just a single wear filter this isthe new query that's being shown but inthis case we still have we it still hasprobably seen the wear filter in thetraining data set but in some kind ofcompositional API or I think actuallythere are two API references one for thelike operator particularly so that couldbe the case as well but anyway so ittakes the query show me the full nameand email of contacts that contain Johnand their full name and it formats thewevia query using the proper get syntaxproper and so here's so there are acouple things to this so firstly itknows the names of all the arguments youknow where is how you do the filter pathfull name being the property the likeoperator and then it correctly does youknow John asterisks for how you would dothe full name John and their full nameand then it's accessing these propertiesit's correctly closing the squarebrackets the curly brackets and allthese kinds of details for how you sendan API request that will execute on thedatabase here's another example of amore complex query so get me instrumentswith a hybrid search of piano so cuttingresults off with the first steep drop inthe hybrid search score and showed thename description you're introduced andwhether it is a string instrument andthe name and genre of the players so nowwe're doing the composition of hybridwith auto cut so what autocut does asmentioned in the national languagedescription it stops showing searchresults once they're no longer goodaccording to the slope in Vectordistance so we see how it's able tocombine hybrid with autocut as well asdo this cross reference for the playersof the instrument so you know played byname genre so this I think is a greatexample of how it's combining all sortsof things about weeviate's graphqlinterface to write these kind of queriesfrom a natural description okay so nowlet's dive into one of my favorite sideeffects of the gorilla and this trainingdata set is Gorilla as an off-the-shelfSQL versus Vector search query router sofor example when we ask it the naturallanguage command show me the number ofcourses the gorilla is able to translateit to aggregate course meta countinstead of just doing some kind of yoursearch query so it's able todifferentiate between Aggregate and getand let you plug in these two differentkinds of categories now here issomething that I really like iscombining Vector search with aggregatequeries what is the average complexitylevel of yoga poses that are similar towarrior pose with a maximum distance of0.15 what this lets you do is search forthe nearest neighbors to warrior pose inthe vector space and then do a symbolicaggregation on the data points in thatVector space so I presented this at odscLondon in 2022 I love using this for sayTwitter analytics it's just somethingthat I use in my life where you have allthese tweets and you want to know thingslike you know what is the average linkclicks do people like these kind oftweets and rather than having tocategorize your tweets you can just giveit a natural language query like tweetsabout new papers or maybe tweets aboutnew llm papers and it can filter it andthen you can do these symbolic queriesso I love seeing that gorilla is able toto do this kind of thing from a naturalcommand I'm so so excited about this SQLVector query router provided fromnatural language commands Okay soalthough you've seen some good exampleswhat do bad examples look like now thisis a query from gorilla that will notexecute because it's missing a commabetween bm25 and where so it's thelittle details like this maybehallucinating an operator or giving anincorrect say giving a string for Valuenumber or a property that doesn't existthese are the kind of hallucinationsthat would cause this to fail so let'sstep a little more into how we plan tograduate our evaluation of these modelsso firstly there's sort of the does itexecute thing that that this query wouldfail but you still could have caseswhere the query executes but it doesn'tfollow the instructions so oneinteresting strategy for doing thisobviously there would be a lot of humanannotation that went into projects likethis in the past but we could maybe usethe higher capacity gpc4 model andprompt it with does the response followthe instructions another interestingidea is reflex collection promptingwhere you use that kind of reflection tomaybe correct the response so it did itfollow the instructions no how would youfix it and that might be another way tofix the queries then and get them backinto the trending data or something likethat or have some kind of samplingmechanism like that a couple other morequantitative metrics we can do groundtruth perplexity that's one of the mostcommon metrics you see and I think thatworks pretty well where you for sorrythe language model to Output the groundtruth synthetic query and there's alsoan engram match wherethis is an interesting idea where forexample if we're doing this kind of bm25wear thing we would see how many of thekeywords it matches with get job listingbm25 query so we could do something likethis also to see how well it followedthe particular API reference so here aresome of the research questions we haveabout our wevia graphql gorilla as wellas the future of this project so firstlythe most important practical questiondoes weviate graphql gorilla generalizeto new schemas as we plug this modelinto the auto API trained on our dataset of fictional schemas is it going togeneralize to your schema to measurethis where train test splitting oursynthetic schemas into train tests butthey're into 40 training 10 testing butthere are other kind of ideas we can dolike controlling the variance of howmany text properties whether there's anin-property things like this to add morecoverage to our data set to hopefullyyou can put it in the training data andit corrects it that way but also atleast we have some kind of metric somekind of ability to see where it'sfailing the next interesting questionespecially with the maintenance of thismodel is does wva graphql gorillageneralize to new apis let's say theauto introducing the new auto API mightbe a little too meta but let's say weintroduce a re-ranker that takes insymbolic properties to do there-rankings of something like XG boostlike some kind of new search API and weVA will do we need to retrain this modelor by using retrieval aware training isit going to be able to just be able toread the new API reference and write thenew queries so I think it's quitepromising this is one of the biggestappeals of retrieval aware training isby putting the API reference in theinput the model is learning to read theAPI reference and that might help withthe maintenance and continual learningof this modelthe next big question is a bit more it'sa bit more academic but it's verypractical in this setting is atomic andcompositional apis so the reason I sayit's academic is this idea ofcompositional generalization is one ofthe most interesting things in deeplearning that avocado shaped armchairthe reason that's so popular is becauseyou're combining the concepts of avocadoshape with armchair and then creatingthis new image in the dolly model's caseso in our case a compositional API wouldbe you know combining bm25 with wearwith say autocut as well and imaginingwhether our data set should only beAtomic apis with some examples of thecompositionality and what kind ofcompositionality does it generalize tothe next big question is retrievalevaluation this is one of the biggestfindings from the original gorilla paperfrom shashir Patel tianjinzang andcollaborators is showing that when theydon't have the Oracle context in theirfine-tuned Guerrilla model theperformance degrades quite severely sohow do we get the best retrieval for ourwev8 graphql gorilla this has actuallybeen one of the most eye-opening lessonsfor me in this project is in this casewe have 46 apis and I think it's betterto classify which API you want to userather than doing the embeddingsimilarity now the interesting thingwith this is scale of course so you knowwhen I only have 46 apis I can easilymanage this you know classification dataset where I train the classifier to gofrom the natural language commands tothe API but if I scaled this and weimagine say 5000 apis then I imagineretrieval is going to be quite importantbut it really shows the value of havingthese symbolic wear filters and how thatcan help improve relevance in retrievalso I think this is going to be one ofthe most interesting questions withbuilding these models further the nextinteresting question related to this isthe robustness of the wev8 graphqlgorilla 2 noisy retrieval so you knowsay we try to correct our retrieval byretrieving three results rather thanjust one is Gorilla still going to beable to parse that out and use thecorrect reference from the three searchresults as we saw from the Lost in themiddle paper it doesn't look like thisis going to be super easy to justcorrect retrieval Errors By retrievingmore results the next big question isthe robust business of the Wega graphqlgorilla to paraphrases of the net of thenatural language commands to thentrigger the generation of the graphql sofor example our gbt4 our gbt 3.5 sorrythat is being prompted to generate thenatural language commands it might havea particular kind of style in tone likeget me the show me the and then itfollows this particular thing of maybeit has the search parameters firstfollowed by the properties it wants tosee how robust is this going to be tosuper casual natural language commandsfor retrieving from your database or youknow increasingly formal requests so wecan similarly use self-instruct in gbt4and so on these large language like theyou know the largest large languagemodel 7 billion is also quite large butto have paraphrases of the naturallanguage commands see what happens byeither adding that to our training dataset or adding that to our testingevaluation so following the presentationof these research questions here's adiscussion of how I see this space ofev8 and gorilla generally the gorillaidea of fine-tuning llms to useparticular tools so the first thing I'mkeeping an eye on is the development ofthe gorilla open source repositorygorilla and API store for llms so I'vedone a paper summary video diving intothe original exploration of gorilla thatexplores this really interesting thingof formatting apis for deep learningmodels so in this case the naturallanguage command would be something thatindicates whether you want to use animage segmentation model say an imagegeneration model or maybe a you knowsentiment classification text model fromthe hugging face model Hub torch Hubtensorflow Hub and routing this intoformatting the correct API request so weV8 firstly is quite related to thiswhere you know if you want to do cementembedding surge which is a deep learningmodel thing you also need this kind ofinfrastructure of building up a vectorindex which makes it a unique kind ofmodel inference problem in this categoryso my big question with adding alleviateto the API zoo in the gorilla project ishow we want to interface the class andthe property soa common thing you see in in like layingchain or llama index is you just callthe class like document and then youhave a text key content and so you justkind of interface those two and then youjust interface the uh the vector searchbut I'll be really interested to seewhat happens as different kinds of apisare added to this gorilla thing and moreon this shortly the next Superinteresting thing will be extending weV8 graphql gorilla to leviate pythongorilla via JavaScript gorilla we viaJava gorilla weba go gorilla so we V8 inaddition to this graphql API also hasprogramming language clients so forexample to do the same kind of wearfilter in Python you can do client.querydot with where and pass it in thispython dictionary you can also doclient.query.raw and pass in the stringof the graphql query is one way of doingthis in Python but the thing aboutpython that opens you know opens thewhole gorilla project up to probablyit's more exciting uh you know Generalscope is allowing it to create classesto import data to do things like addingcross references or maybe the cloudmanagement stuff like replicationconfiguring multi-tenancy all this kindof stuff because once you open it up toalleviate python gorilla now it has allthe levers it needs to control theleviate vector database now here's whatI think is the really exciting future ofgorillas and I think seeing maybe thepython gorilla and kind of the vision ofwhat that could be how it handlescreating the schema connecting to theclient you know maybe if you're runningweeviate embedded it can instantiate allof weaviate but importing data as wellas the querying I think this reallyopens up what we can do with these apisand probably the most interesting thingto me at least is how this will changesoftware integration so imagine anatural language command where you saybuild a llama index query Engine withweeviate from my notion workspace titledbiochemistry chapter four now it willjust take that and do everything youneed to create this kind of technologyfor you because the gorillas know how touse the apis to achieve each of theseparts now we can imagine level 2 addingto the level 1 prompt please chunk thetext with unstructured and vectorize thechunks with open AI embeddings pleaseadd a cohere re-ranker and Mosaic ml'sMPT 30 billion large language modelplease create a visualization of thesystem and streamlit we can maybeimagine also saying please visualize theembeddings using arise AI or nomic AI sothere's there's so much we can imagineto adding all the software togetherthrough natural language commands so thequestion to me though of how how do weget there isn't quite clear yet I thinkthere are three General kind of Pathwayswe have one weeviate maintains onegorilla where we generate all thetraining data manage the model for allthe Integrations that we've particularlyyou know decided to include in ourtrading data set so that would mean youknow like we have we have codingexamples of how to use wevia with llamaindex and so we've created thosesynthetic examples and trained ourgorilla on it the second idea could bewe have interfaces such that deviatesGuerrilla talks to llama indexes gorillaso we you know both models know theirapis and maybe they would also have tohave some kind of orchestrator thatknows what goes to leviate and what goesto llama index and then maybe the thirdthing is Gorilla emerges as anindependent third party that manages allthe documentation of these uh softwaretools and the apis and how they connectwith each other so I think theredefinitely is going to need to be somekind of hierarchy some kind oforchestration that knows how to connectthese things together as well as theformatting of the particular apis but aswe saw from obviate graphql's gorilla'sability to do compositional queries itmight be able to just you generate areference of combining like fivedifferent things and it might be able tojust do that from one query so I'm superexcited about working on the developmentof this I think this will have a massiveimpact on how quickly we can test newideas and I really just think it'scontinuing this theme of llms that writecode and code interpreter but usingparticular libraries I think that reallyopens up what this is able to accomplishso thinking about how we VA can controlthe entire database through maybe thepython clients creating classes creatingnew schemas adding properties you knowimporting data that might be a littletoo future looking I think the mostimmediate thing in front of us isinterfacing this weeviate graphqlgorilla to Eva users as well as llmsthrough the auto API so if you have asecond please check out the GitHub issueit really means a lot and let us knowwhat you think about just thumbs up ifthis would be useful to you or if yousee any holes in the design of it anyideas on this presentation so toconclude with some high level directionsfor this whole Space of llm tool use Ithink we're really seeing the evolutionof retrieval augmented generation fromthe original conception from Lewis andothers where we have this kind ofembedding based retrieval to takecontext and decompose the problem oflanguage modeling and to retrieve thenread we're now seeing this use of searchdatabases as a whole entire tool and Ithink it's really interesting to readthis paper on self-driving databaseManagement Systems quoted a trueself-driving database management systemautomatically one decides what actionsto use to optimize itself two decideswhen to deploy those actions and threelearns from those actions all withoutany human intervention so I think thisis quite a bold Vision where we canimagine you know actions to optimizeitself whether it's configuring at thelowest level the hnsw parameters likethe EF construction the number ofneighbors or with product quantizationhow big of segments to use maybe thePrecision for the centroid IDs all thesekind of hyper parameters for tuning thesearch database as well as actions suchas creating new classes creating newproperties in the case of the generativefeedback loops maybe taking your datatransforming it into new data byprompting llms and then saving that databack into your database by using theseAPI is interfaced with things like thegorilla algorithm and I think generallyjust having these databases that areobserving the queries that you're seeingfrom I think the original conception ofthis was say building index structureslike if you're seeing a particular kindof join in an SQL system or a particularkind of filter you might build up andyou know cache these kind of indexesthat you're seeing all the time but nowwe're seeing I think a more open-endedinterpretation of that where you alsocould do things like you know create anew class that has a particular kind ofdata in it and Route queries to that orsay if you go deep into hsw there issome research on how you can improve thespeed of filtered Vector searches byincreasing the connectivity of the graphbut generally I think by exposing LMS tothese apis we're going to see thisreally interesting evolution of llms andthese search databases thank you so muchfor watching this presentation of thewevier graphql gorilla to connect withus at webva we have a slack Communitywhere everyone on the team includingmembers of the community are are tryingto answer your questions about buildingsemantic search applications it's Ireally vouch highly for this community Ithink you'll enjoy joining it and askingany questions you have about BuildingSystems with wev8 next up is the TwitterLinkedIn weeviate.io if you want to keepup with the new developments of weviatenew releases of the software as well asblog posts and research projects likethis all these sources will be great foryou know keeping up with the informationchannels of weviate and finally I highlyhighly recommend checking out the newverba retrieval augmented generationwith weeviate this is a full stack demousing you know a react front end as wellas the ev8 back end and it's a reallyexciting new demo project from wev8 soplease check that out and thank you somuch for watching the weeviate graphqlgorilla project", "type": "Video", "name": "Weaviate Gorilla Part 1: GraphQL APIs!", "path": "", "link": "https://www.youtube.com/watch?v=Zqxd1BnoQQQ", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}