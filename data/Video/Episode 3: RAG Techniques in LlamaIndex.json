{"text": "Welcome to episode 3 of the Weaviate and LlamaIndex series! In this video, I cover four query engines implemented in ... \nhi everyone welcome to episode 3 of the weevie and llama index Series in this video I'll be going over four Advanced query engines implemented in llama index I'll start off with the SQL router then I'll jump over to the sub question query engine the recursive router and then the self-correcting let's jump into the video let's begin with the sequel router query engine in this example I am asking what is the longest we beat podcast rather than routing to my Vector database because it's not a semantic query it is going to route to the SQL database and it will output the podcast that has the longest duration the sub question query engine breaks down complex questions into sub questions so in this example I have what is rough to back and weavate in order to answer this question it needs to be broken down into two sub questions so I have first one is rough to back and what is VV those two questions both go through my Vector my weebe Vector database and it outputs the response so each question is going to generate an answer and then in order to combine it into one you have to pass it through the response synthesizer and it outputs the answer of ref to back vectorizes an object and it stores the embeddings in webiate cursive retriever takes the reference node relationships rather than only outputting a node that is most relevant to your query so in this example I have brought what is reftubec the first chunk is what is capable of answering my question so we take that chunk and we find the index where this was discussed so in this case it is podcast number 31. so once I we are in that index we take the original query which is what is rough to back along with the chunk or node that is most relevant and it outputs the answer the self-correcting query engine uses an llm to evaluate its response so in the example again of what is rough to back it answers rough to back vectorizes an object if my evaluation is prompted with not being too vague or not being too long it will then say meh that's not a great output so we're gonna hit the original along with the evaluator to make a new query so instead what is being passed in is what is reftubec and how does it vectorize objects so give it a little more information it says that the output is like a thumbs up it's great because of the evaluation that it has been prompted with previously and it outputs the answer that is a bit longer and answers how refactorizes objects let's begin with the SQL router so first we'll need to connect to a review instance and in this case I'm just using review embedded we'll need to Define our schema which I'm using the podcast and then we'll load in the data so I'm just using the YouTube transcript reader that you can find on the Llama Hub and then passing in different URLs then I'm going to be building the reviewed index and if you aren't familiar with this you can watch episode 2. after that I will need to create my SQL table because a reminder when I ask a question it's going to Route it to either my weeviate Vector database or mySQL database okay so I'm creating my podcast stats table and it just create contains three different properties so podcast title views and duration okay now I'm just gonna add data to it then I'm creating the SQL table in llama index and now just setting it up for the text to SQL prompt then I'll need to build the query engine now the next step is to have llama index know about these tools so I am defining what my weeviate Vector database is so saying that it can handle semantic questions about weave release podcasts and then for my sequel one saying that it can translate a natural query into a SQL query and index or go into that database now we can ask the question so the first question is which release podcast had the most views rather than going to the vector database it's going to hit the SQL database so it's going to Output the podcast title and then the number of views that it had moving on to the second question of tell me about a new feature in review it 120 that cannot be handled by a SQL database so instead it's going to go to your weeviate index or web database and then answer the question now we'll jump over to the sub question query engine so you'll need to connect your webaid instance again and in this example I'm also using the be embedded defining your schema so in this example I'm using the blog post then I'll need to load in the data and from the Llama Hub I'm using the simple web page reader so just passing in the URL to the blog post that I want to query then I'm constructing my Vector store passing in my openai key I'm passing in the client which is connecting to the BB embedded then my class which is blog posts and then text key and then content which is the property then I'm setting up the storage for the embeddings and then setting up the index with the blog and then the storage and then defining my query engine then I want to set up the sub question query engine here I have the blog post and then a description about it so the blog post is about the integration of llama index and weavate and this is important because in the sub question query engine you can actually have it reference various sources but in this example I'm only using one now the fun part of course is querying so I have how does llama index help data indexing and deviate and right off of the bat you already know that that question needs to be separated into multiple parts and as you can see with this beautiful coloring we it generated three sub questions so it has what is llama index what is viviate and how does llama index integrate with weaviate each color corresponds to the question and answer and then again it passes it through the response synthesizer to gather all of the previous outputs into one simple answer so it says that llama index helps data indexing and we be by providing tools and capabilities for data ingestion Etc if you would like to learn more about how home index helps data indexing and mediate you can check out the blog post on the on rebate.io by Jerry now I'll go over the recursive retrieval query engine so again connect to your webiate instance and Define your schema so in this example I'm using the weeviate blog post and the hugging phase blog post and I'm saving it as two separate classes and each have the content property then I want to load in the data so again passing in my openai key and then grabbing the data by passing in the URL which is using the simple web page reader so I am grabbing the P Cube rescoring from the Wii V8 blog and then from hugging face the ram efficient pie torch blog posts then now I'll need to create my index so I'm providing a summary of what each index is so for weviate I'm saying uh this node provides blog posts for maybe a vector database and then for hugging face just explaining that it will contain tools from training machine learning models okay and now I'm building out my index so when it's retrieving the most relevant node it will then and enter the index that contains either information about weavate or hugging base then I'll need to build out the recursor retriever query engine so the first question that we have is what is product quantization and this is obviously from the Wii Vape blog so you can see that that is where it's entering once it has the question that is entering the review blogs index and then it will output the response of what product quantization is similarly we can do the same for hugging face so I have what does fsdp do it is entering the hugging face blogs and then outputs the answer the last query engine I'll be covering is the self-correcting query engine so again connect your bb instance and in this demo I'm using the revape blogs and then I'm just passing in the data by using the simple directory reader then I'm constructing my we beat Vector store again passing in my index name which is a class along with the property and then setting up the yeah the index and then jumping into a query so this is a query without the self-correcting so I'm asking what is reftubec and you can see that the answer is kind of it's pretty short and doesn't provide too much information or doesn't answer the question how I'd like so this is where you can configure this with the self-correcting query engine and notice in this first line the first library or the first function that I'm importing is the evaluation guide and then the default guidelines so I just want to share what is set when you import that and what it is doing is uh finding this parameter that has three different prompts for the large language model to consider when it is doing the evaluation of the response so the first one is the response should fully answer the query it should avoid being too vague or ambiguous and then the response should be specific and use statistics or numbers when possible in my question it doesn't need the last one but regardless it's still it's still a really good prompt to improve the response from the query engine I added on so I'm taking the default guideline but then I'm also including that the response to tried to summarize where possible so it's not too long of an answer and also because I'm being charged for this I don't want it to be extremely information heavy and then I have that the response should mention weaving and not be too big so kind of tricky but this is the job for the large Target Model to figure out now I want to see where it the evaluation is coming into play with the original query that I asked so now I'll see how can the response be improved and I want to see the thinking of the large language model so it's saying that the response fails to mention weevi and it is too vague so it's saying okay how can I improve this which is great so here is the improved answer or like a bit of the answer which is how it can mention maybe and how it can improve the information so then it has it ends with this question of what is rough to back and how does it work with webe now I'll print the final answer that it outputs and also I want to add that you can specify the number of times that you want it to evaluate itself in this example I it's only doing it once but maybe you're like maybe the third time is the charm and that is what you set it to maybe your answer improves or maybe it just gets Source it's just something to decide um okay so the final answer that it outputs is rough to back is a method of representing so it defines what rough to back is and how it is used in deviate and then also the applications so to me this is an A plus answer thank you so much for watching episode three of the movie and llama index series I hope you enjoyed this video and if you'd like to begin from the start of this series you can check out the links on this video or down below in the description take care and thanks for watching bye say bye boy ", "type": "Video", "name": "Episode 3: RAG Techniques in LlamaIndex", "path": "", "link": "https://www.youtube.com/watch?v=Su-ROQMaiaw", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}