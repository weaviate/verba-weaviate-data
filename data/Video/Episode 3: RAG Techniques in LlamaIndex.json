{"text": "Welcome to episode 3 of the Weaviate and LlamaIndex series! In this video, I cover four query engines implemented in ... \nhi everyone welcome to episode 3 of theweevie and llama index Series in thisvideo I'll be going over four Advancedquery engines implemented in llama indexI'll start off with the SQL router thenI'll jump over to the sub question queryengine the recursive router and then theself-correcting let's jump into thevideo let's begin with the sequel routerquery engine in this example I am askingwhat is the longest we beat podcastrather than routing to my Vectordatabase because it's not a semanticquery it is going to route to the SQLdatabase and it will output the podcastthat has the longest duration the subquestion query engine breaks downcomplex questions into sub questions soin this example I have what is rough toback and weavate in order to answer thisquestion it needs to be broken down intotwo sub questions so I have first one isrough to back and what is VV those twoquestions both go through my Vector myweebe Vector database and it outputs theresponse so each question is going togenerate an answer and then in order tocombine it into one you have to pass itthrough the response synthesizer and itoutputs the answer of ref to backvectorizes an object and it stores theembeddings in webiate cursive retrievertakes the reference node relationshipsrather than only outputting a node thatis most relevant to your query so inthis example I have brought what isreftubec the first chunk is what iscapable of answering my question so wetake that chunk and we find the indexwhere this was discussed so in this caseit is podcast number 31. so once I weare in that index we take the originalquery which is what is rough to backalong with the chunk or node that ismost relevant and it outputs the answerthe self-correcting query engine uses anllm to evaluate its response so in theexample again of what is rough to backit answers rough to back vectorizes anobject if my evaluation is prompted withnot being too vague or not being toolong it will then say meh that's not agreat output so we're gonna hit theoriginal along with the evaluator tomake a new query so instead what isbeing passed in is what is reftubec andhow does it vectorize objects so give ita little more information it says thatthe output is like a thumbs up it'sgreat because of the evaluation that ithas been prompted with previously and itoutputs the answer that is a bit longerand answers howrefactorizes objects let's begin withthe SQL router so first we'll need toconnect to a review instance and in thiscase I'm just using review embeddedwe'll need to Define our schema whichI'm using the podcast and then we'llload in the data so I'm just using theYouTube transcript reader that you canfind on the Llama Hub and then passingin different URLs then I'm going to bebuilding the reviewed index and if youaren't familiar with this you can watchepisode 2.after that I will need to create my SQLtable because a reminder when I ask aquestion it's going to Route it toeither my weeviate Vector database ormySQL databaseokay so I'm creating my podcast statstable and it just create contains threedifferent properties so podcast titleviews and durationokay now I'm just gonna add data to itthen I'm creating the SQL table in llamaindex and now just setting it up for thetext to SQL prompt then I'll need tobuild the query engine nowthe next step is to have llama indexknow about these tools so I am definingwhat my weeviate Vector database is sosaying that it can handle semanticquestions about weave release podcastsand then for my sequel one saying thatit can translate a natural query into aSQL query and index or go into thatdatabase now we can ask the question sothe first question is which releasepodcast had the most views rather thangoing to the vector database it's goingto hit the SQL database so it's going toOutput the podcast title and then thenumber of views that it had moving on tothe second question of tell me about anew feature in review it 120 that cannotbe handled by a SQL database so insteadit's going to go to your weeviate indexor web database and then answer thequestion now we'll jump over to the subquestion query engine so you'll need toconnect your webaid instance again andin this example I'm also using the beembedded defining your schema so in thisexample I'm using the blog post thenI'll need to load in the data and fromthe Llama Hub I'm using the simple webpage reader so just passing in the URLto the blog post that I want to querythen I'm constructing my Vector storepassing in my openai key I'm passing inthe client which is connecting to the BBembedded then my class which is blogposts and then text key and then contentwhich is the property then I'm settingup the storage for the embeddings andthen setting up the index with the blogand then the storage and then definingmy query enginethen I want to set up the sub questionquery engine here I have the blog postand then a description about it so theblog post is about the integration ofllama index and weavate and this isimportant because in the sub questionquery engine you can actually have itreference various sources but in thisexample I'm only using onenow the fun part of course is queryingso I have how does llama index help dataindexing and deviate and right off ofthe bat you already know that thatquestion needs to be separated intomultiple parts and as you can see withthis beautiful coloring we it generatedthree sub questions so it has what isllama index what is viviate and how doesllama index integrate with weaviate eachcolor corresponds to the question andanswer and then again it passes itthrough the response synthesizer togather all of the previous outputs intoone simple answer so it says that llamaindex helps data indexing and we be byproviding tools and capabilities fordata ingestionEtc if you would like to learn moreabout how home index helps data indexingand mediate you can check out the blogpost on the on rebate.io by Jerry nowI'll go over the recursive retrievalquery engine so again connect to yourwebiate instance and Define your schemaso in this example I'm using theweeviate blog post and the hugging phaseblog post and I'm saving it as twoseparate classes and each have thecontent propertythen I want to load in the data so againpassing in my openai key and thengrabbing the data by passing in the URLwhich is using the simple web pagereader so I am grabbing the P Cuberescoring from the Wii V8 blog and thenfrom hugging face the ram efficient pietorch blog poststhen now I'll need to create my index soI'm providing a summary of what eachindex is so for weviate I'm saying uhthis node provides blog posts for maybea vector database and then for huggingface just explaining that it willcontain tools from training machinelearning models okay and now I'mbuilding out my index so when it'sretrieving the most relevant node itwill thenand enter the index that contains eitherinformation about weavate or huggingbasethen I'll need to build out the recursorretriever query engine so the firstquestion that we have is what is productquantization and this is obviously fromthe Wii Vape blog so you can see thatthat is where it's entering once it hasthe question that is entering the reviewblogs index and then it will output theresponse of what product quantization issimilarly we can do the same for huggingface so I have what does fsdp do it isentering the hugging face blogs and thenoutputs the answer the last query engineI'll be covering is the self-correctingquery engine so again connect your bbinstance and in this demo I'm using therevape blogs and then I'm just passingin the data by using the simpledirectory reader then I'm constructingmy we beat Vector store again passing inmy index name which is a class alongwith the property and then setting upthe yeah the index and then jumping intoa query so this is a query without theself-correcting so I'm asking what isreftubec and you can see that the answeris kind of it's pretty short and doesn'tprovide too much information or doesn'tanswer the question how I'd like so thisis where you can configure this with theself-correcting query engineand notice in this first line the firstlibrary or the first function that I'mimporting is the evaluation guide andthen the default guidelines so I justwant to share what is set when youimport that and what it is doing isuh finding this parameter that has threedifferent prompts for the large languagemodel to consider when it is doing theevaluation of the response so the firstone is the response should fully answerthe query it should avoid being toovague or ambiguous and then the responseshould be specific and use statistics ornumbers when possible in my question itdoesn't need the last one but regardlessit's still it's still a really goodprompt to improve the response from thequery engine I added on so I'm takingthe default guideline but then I'm alsoincluding that the response to tried tosummarize where possible so it's not toolong of an answer and also because I'mbeing charged for this I don't want itto be extremely information heavy andthen I have that the response shouldmention weaving and not be too big sokind of tricky but this is the job forthe large Target Model to figure outnow I want to see where it theevaluation is coming into play with theoriginal query that I asked so now I'llsee how can the response be improved andI want to see the thinking of the largelanguage model so it's saying that theresponse fails to mention weevi and itis too vague so it's saying okay how canI improve this which is great so here isthe improved answer or like a bit of theanswer which is how it can mention maybeand how it can improve the informationso then it has it ends with thisquestion of what is rough to back andhow does it work with webenow I'll print the final answer that itoutputs and also I want to add that youcan specify the number of times that youwant it to evaluate itself in thisexample I it's only doing it once butmaybe you're like maybe the third timeis the charm and that is what you set itto maybe your answer improves or maybeit just gets Source it's just somethingto decideum okay so the final answer that itoutputs is rough to back is a method ofrepresenting so it defines what rough toback is and how it is used in deviateand then also the applications so to methis is an A plus answer thank you somuch for watching episode three of themovie and llama index series I hope youenjoyed this video and if you'd like tobegin from the start of this series youcan check out the links on this video ordown below in the descriptiontake care and thanks for watching byesay bye boy", "type": "Video", "name": "Episode 3: RAG Techniques in LlamaIndex", "path": "", "link": "https://www.youtube.com/watch?v=Su-ROQMaiaw", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}