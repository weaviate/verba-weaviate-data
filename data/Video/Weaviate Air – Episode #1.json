{"text": " \nforeign[Music][Music]podcast where we are it's me Sebastianwe are a good Etienne Connor and Ericafrom uv8 we all like hailing from ourhomes or offices wherever we are and bythe way this podcast is 100 live so Iwould encourage you to say hi on onYouTube uh questions or on on the chatif you have questions fire them up andwe'll try to answer them as we go and weare super excited to meet you allum so we have like a packet packedagenda we want to talk about manydifferent topics what's new in theresearch we want to show you some demoproject talk about our roadmap andthere's so many cool things that wewould like to share and again like Imentioned ask questions as we go and ifyou have any feedback or ideas in thefuture or you feel like maybe you shouldfeature in one of the sessions give us ashout and we can for sure get thatarranged so the first thing I want to dois talk about our roadmap and so many ofyou probably didn't know but wepublished that recently on our vv8website and I'm going to share ourscreen and basically this is where wetalk we highlight like some of thefeatures that we'll be working on forversion 116 for 117 we have some uh alsoideas in the backlog and actually it'spretty cool because you can go and upvote for those itemsum and so you could definitely a stayvery informed by what checking out thatpage but but also you could contributeinto uh into how we prioritize each ofthose items so in case you don't knowhow to find it just go to uh developersinto our documentation and then on thenavigation it's just under roadmap andthen we could just the future world mapso I'm going to take this opportunitythat we have at the end our CTO toactually walk over some of the itemsthat we have in the roadmap and um atthe end can you tell us what all thoseitems areyeah sure absolutely hi everyone so yeahas Sebastian just said with the roadmapwe really want to be a bit moretransparent so you may have seen thatwe've we've been publishing these blogposts whenever we have a release but ofcourse until we get to the point to tohave such release ready a lot ofplanning goes into it and part of thatplanning is basically prioritizing whatfeatures do we want and this is a matterof who uh had some ideas from thecommunity what does the community reallyneed uh what the semi as a business needwhat do we need for for offering our vvncloud service offering so it's balancingall these these needs and we want to bea bit more more open about it a bit moretransparent about and that is exactlywhat that roadmap is for so on theroadmap we're trying to to look at thenext two or so releases and that that ofcourse that's always super Dynamic soyou can see uh current release is1.15.2 and then uh the next sort of thenext minor releases are the ones that wereally care about like of course theremay be patch releases in between becausewe fixed something but the minorreleases is what we what we really planfor and 1.16 is next you can see an ETAhere so it's put on on week 44 which Ithink is the the first week of Novemberso it's about four weeks from from nowwhich I can actually say because this islive soum and then we also have 1.17 whichwould be the one after that which wouldbe to towards the end of the year andthen as it goes with road maps so so umthe further you move in time serve themore the less uh likely it is to staythe way or the more likely it is thatsomething might change and then ofcourse we also have the backlog whichare basically uh feature requests orideas that either we agreed that we wantto tackle them but we have notprioritized them yet so you can youcould upload for them or it could beum that maybe something is currently inresearch that we're looking at somethingand and um yeah we we say like okay thisis something that we want to do but wedon't want to do it right now because wewant to find out how do you as users useit how do we build it from a technicalperspective how do we make sure that ithas a super great ux because you knowBBA is all about the user experience sowe want to get that right which couldsometimes mean that we put something abit later on the roadmap um to to makesure that we get it right so that's uhfor the roadmap itself but let's alsotalk about the contents so as I justsaid four weeks from now is when we'regoing to have 1.16 out that's of coursean estimated time of arrival so couldchange a bit but I think we're on a gooduh schedule for for this one so let medive into the contents um this oneproposal so so this you see here we wehave the GitHub issues linked so youcould actually open them up like if Iopen them up I'm not sure I think thatwould uh not showing the screen sharinghere um but doesn't matter like if youif you click on one of those you see theGitHub issues behind them so this one'slabeled as a proposal and this one issomething that uh was so it wasintroduced before we had this uploadfeature um but we know from talking toall of you that this is one of the mostrequested features that you uh out therehave which is dealing with null valuesin VBA so this means searching forfields that are not set or doing somekind of filters where you uh um assertthat a certain field is set or is notset and then do kind of kind of specificbehavior with it this also goes forimproving the ux around null value so inprevious releases there was a differencein setting an explicit or setting afield explicitly to a null as opposed tonot setting it sort of tying this all upand really making making uh null valuesor unset values not just an edge casebut an actual sort of feature case thatwe think about and dealing with it andthere will be a new operator to toum yeah search for for whether a fieldis set or not and we got a ton of inputfrom all of you out there and that'ssuper great please please keep doingthat and if you want um you can ofcourse still uh give us feedback but wereally love these like uh early feedbackCycles even before something is builtinvolving all of you not just for whatyou care about but also for forbasically yeah how do we have to buildit to give you the best possible ux forthat feature next one is another onethat's that's super popular in thecommunity which is the idea ofcross-referencing centroids so this is amodule and if you know vba's modulesystem and we have different types ofmodules you can actually see that in thein the navigationum or you could if I Iumif I uh expand it we have retrievers andvectorizers readers and generates Etcand this is basically a vectorizermodule so the idea is that you alreadyknow the text to VEC modules and inthose you would have text input and uhthe module at input time or at updatetime would basically take the object putit into the model and you get a vectorout and then that Vector would becreated at at or would be indexed whileyou import this object with Crest crossreference centroids I think that themodule is called reftubec you can dothat automatically but not based on thecontents of the actual object but basedon the length of that outgoing or theoutgoing links off that object so forexample if you have a let's say twoclasses a class book and a classchapters and then your chapters classwould have individual vectors for eachchapters then you could just summarizebasically the book by yeah summarize allthe chapters in a book class by having aobject of type book with outgoingreferences to to those chapters oranother use case would be for example ashopping cart where you have items inyour shopping cart and then by creatingthose references and sort of inheritingin a sense uh the the mean Vector ofthese individual objects in your cardyou could now index dropping cards soyou could do stuff like similaritysearch for related for related or forsimilar shopping carts which is supercool for e-commerce use cases forexample so lots of great newopportunities there and of course itfits very well into vba's module systeminto the existing API so that's that'sreally cool then making I I want tointerrupt just for a second so yeah onthe cross reference centroids by the wayum this is actually a research thatcorner is working on so if this is atopic that you find interesting andexciting first of all go and upvoted onon GitHub just uh just like at the endwas showing you that you can find thelinks there but yeah of pingers on on apublic slug or pink corner and thenlet's start a conversation especially ifyou have opinions ideas or uh yeahConnor is very knowledgeable about itand we're still thinking of all sort ofinteresting ideas on how to do thecentroidsum so for sure um let us know but yeahat the end you can continue thank youum yeah exactly and then if you havequestions we have Connor here and lookat that call as well so that's a greatopportunity just put them in the chatand then um Conor can can respond a nextone is a completely different directionso you can see with every release we'rereally trying to balanceum the needs of the differentstakeholders for vb8 release which meansthere's something feature driven there'ssomething more operations driven this ison the operation side so the node'sendpoint is a simple API to uh tell youthe status of the nodes in a cluster sothese are the notes like if you deployedon on kubernetes for example the nodesor the podsum if you do it agnostic of somethinglike kubernetes it's just the individualdeviate notes so basically Management inthat cluster and this is a prerequisitefor what we're going to do in 1.17 whichis going to be super cool as well butalso just to get some insights into likeis your cluster healthy but then in thefuture also to to adapt it so right nowit's a read-only API but in the futureyou could use this to to make changesfor example let's say you want to takedown a note for Nim for maintenance soyou could drain the node off workloadsand these kind of things so that'sthat's more an operations uh driven sideum yeah which we which we want tointroduce in 1.16 as wellthen the next one is multi-note supportfor backup so in 1.15 the previousreleaseum we wrote a a long a blog post aboutit we introduced backups which I believeis still one of the coolest featuresthat we've ever built just because it'sit's so ux focused and it's so flexibleand you can use backups to uh store arestore backup to and restore fromdifferent Cloud providers you could usethat to to use a production instancetake a snapshot of that productioninstance and and maybe run it on yourlocal machine so it's super superflexible feature and there was onelimitation that we did to to releasethis a bit sooner and that was in 1.15that it was limited to a single noteviviate instance and that limitation isgoing to be lifted with 1.16 it willwork on a multi-node cluster and this isnot just great for for all of you whocan use it in a cluster node but this isalso super cool for for us basicallybecause it's a building block for whatwe're going to do in 1.17 so all thiskind of multi-node coordination thatwe're building here you're going to hearthat again because we're doing lots andlots more multi-note and cluster stuffin 1.17.then we have another one so this is umalso I love these kind of issues becauseif you see them so so this is I couldguess you could either see this as a asa as a buck or as an extension but Ilove seeing those come in because thosetwo me are signals that people are usingand really using vb8 and production inthere sometimes running into some sortof limitation where maybe we sent wedidn't have something in scope yet andum for this one the the example here isthat if you try to use bb8's oidc sooadc is open ID connect so basically astandard protocol for authentication andthat works with some oidc providers atthe moment but it doesn't work with someothers because while everything iscompatible with the spec some featuresjust weren't supported yet and we gotsome feedback that um yeah if you wantto do I think it's I think it's Azure adbut I'm not 100 sure like one of thoseproviders we're missing some featuresand this is about adding those missingfeatures to really support all theseproviders and yeah make deviate moreusable in production for for more userswhich I always like both that we'redoing it but also that that users arerequesting this and then we have anotherone which is so this is a another reallyinteresting one this one was actuallydriven by our webe account service teamum but it's it's something that everyoneis going to benefit from soum if you run out of memory on your vv8machine basically at some points in inprevious versions it which is Crash andthat's not their greatest ux so we havea read-only feature already that's kindof Dynamics Dynamic so for example ifyou run out of disk space you can have aconfigurable threshold to mark your yourshards the charts or the components ofyour index to mark them as read-only andand now we're going to have that samething as well for running out of memoryso basically what a memory threshold iscrossed that is as I said motivated fromby our BBA cloud service team who isasking for for something like that tomake sure that thatum yeah the ux is great when whensomething like this happens so basicallyif it's read only we can handle it ifit's crashing then it's much harder tohandle but this is of course somethingbeing aware the the needs from our VBAcloud service application really drivesthe product forward and that everyonebenefits from also when you'reself-hosting this so I really like howyeah the community needs and the thesort of business needs from fromsomebody else the company behind vv8 areum pretty much alignedyeah that that's it for 1.16 if you haveany questions or feedback super curiousto hear them we also have 1.17 on thislist but I'm not going to go in detailthrough thisum I think we can for example we couldtackle this in a future one but lots ofexciting stuff there as wellso at the end I've got a question foryou so from the list that you just wentover uh what is your uh favorite featurethat you're looking forward toimplementingoh that's a that's a tough question uhlet me let me think about this soI think for me oh this is this is reallydifficult because multiple of them havehave good reason for why they would bemy favorite can I can I get away withtwosure just yeah okay okay then then fortwo I'm gonna go for the null values forthe reason that the the way that we gotthere was so Community Driven like itwas if you open up this this issue whichI can't right now because I I sharedonly a single tap and if I open it itopens in it or it doesn't yeah it opensin a new tab for whatever reason uh so Ican can share it um but all of this iscommunity feedback so this is I reallyjust love the the process I think someusers have been waiting for this for fora while but at the same time that gaveus the time to really go back and forthand get this early feedback end and wecan be sure that when we release thisfeature that it's exactly what usershave been asking for which I I love itand and also implementation wise it'ssuper cool that that yeah it's not toodifficult to do with our inverted indexthat we already have so we have goodbuilding blocks for that and then thethe other one uh for me is going to bethe multi-node cluster backup supportwhich I think from a feature perspectiveis very very minimal it's just like okayit was a limitation and what not 15 youjust had single node now you can domulti-node but the kind of coordinationthat we do with multi-nodes in thebackground that is a building block forreplication and now I'm spoiled itbasically what we're going to do in 1.17but one not 17 is going to be all aboutlike Dynamic cluster scaling and and umand replication and having the buildingblock in for that that is just that's aa big win for me right nowexcellent excellent thank you for thereview and um yeah this is pretty prettyexciting and I encourage everybody to uhreview the page and if you feel like youlike any of those features upvote it andthen let's see all those thumbs up goingup uh and then because that definitelyhelps us to put more effort in specificlike you know more popular features uhnot to say that we we will not take careof the other ones but uh that's kind oflike up you know thumbs up always helpsour engineering team yeah especially forthe features that are in um in in thebacklog basically they're notprioritized yet because then we knowlike this is something that you wantthat's a very good point right becauseonce it's in 116 we kind of work on italready right yeah yeah yeah like pushthings forward a bit more yeah yeah likewe're probably not going to removesomething from the list for 1.16 simplybecause it's it's just four weeks out wewe could still add something that that'ssomething that could always happen butbasically the further we go in thefuture the more Dynamic it is and themore uh we can still change itperfect uh thank you at the end so andand I have to say like I can guess quiteeasily what's Conor's favorite featureon the list because that's definitelythe cross-reference centroid uh we allwant to see it in there so um let's moveto the next part of the session uh so inthis part uh it's uh I'm going to passit on to Connor who will give you anoverview of like cool research that'sbeen happening uh in AI uh so let mejust share Connor's screen because heprepared a small presentation aroundthatum and yeah and as as he goes throughlike uh different items like uh pleaseuh comment out uh give us a shout if youactually like any of those researchersor if you think like we should includethat in movie eight like that would bequite interesting to see tooum but yeah Conor uh what did youprepare for usawesome well first of all it's reallycool to follow Eddie and with this Ithink it's so interesting seeing kind ofthe muscle behind the cloud service andthe oidc authentication all these thingsthat make it the search database andthen kind of coming in this intermediatebetween say the ref to VEC and themuscle again of Parker Duckworth ourengineer who built this together andthen kind of then the research side so Ithink you can hopefully see the flow ofhow all these things come together and Ithink it's really interesting so as apart of my section I'm going to be kindof covering some new things that I sawin AI this month that I think are justextremely interesting and are thingsthat maybe we can see how to integratewith weedgate and develop as featuresthat are kind of adjacent things thatfuel the models and fuel the pipelinesand these kind of things so it'sdefinitely sort of biased towards searchwith this selection of of what I thinkis interesting that came out this monthand then um I say like kind of it's it'smy opinion sort of it's not likeeveryone's Collective opinion if I saysomething that's kind of opinionatedabout some of these things so start offwith kind of just a quick topic overviewI tried as best as I could to make thiskind of sequentially organized a littlebit but really it's a it kind of thefirst general thing is about trainingretrieval models how do we get thesemodels that produce embeddings of dataand what are the new advances in thatthen we have some new advances inlearning to search and then this Chainof Thought prompting thing continues toevolve and this self-ask thing is just amassive step through with this and theway that we use these language modelsand the way that we tie these languagemodels with search engines so I'd say ifI had a central topic for this it'sthinking heavily about what is therelationship between large languagemodels and the vector the weba vectorsearch engine and sort of languagemodels and search and how they playtogether so then we'll kind of look atone paper that um you know maybe thetitle generate rather than retrieveisn't a title that we would love withour current design so I'd like to kindof you know still entertain thesearguments and say what they're saying isthe drawback to the Gen to the currentretrieve and read Pipeline and how theygenerate then then read pipeline workand so sort of my counter Arguments forthis as well I think I want to talk alittle more about retrieval augmentedlanguage models so Facebook AI I thinkother institutions as well they havethis Atlas modelwhere it's this 11 billion parameterretrieved and read that also achievesthis few shot learning and I listened toPatrick Lewis uh talk at the Boston NLPMeetup about this about how you candecouple Knowledge from reasoningessentially with this kind of Paradigmand this is also they have a new reimage and model Imogen is the uh theGoogle diffusion text image model and sothey have a retrieval augmenteddiffusion model as well that I'd like totalk about with this General class ofretrieval augmented language models sovery heavy in the theme of languagemodels and search what is therelationship what do they each offer howdo they complement each otherand play together so then I mean thisother paper is just wild two exclamationmarks this set fit contrastive learningcan achieve few shot learning as wellthis way of fine-tuning sentenceTransformers and then putting aclassification head on top of it the Ijust was like I can't believe this canachieve that as well and then I'd liketo just quickly uh touch on someexciting emerging applicationsum like Facebook has a make a video andthen there's a new um uh edit eval whichis about sort of creating data setsaround editing text not just generatingtext and I think this is incrediblyinteresting as well and then we havejust an absolutely incredible interviewstudy of ml Ops practices this is justlike the sort of like the ml Ops bookit's a paper but it's like the ml Opsbook that you've always wished you hadwith describing like best practices andorganizing these experiments anddeploying these models and just allsorts of incredible like nuggets to takeaway with if you like that kind ofthinking soto kick it off let's talk aboutpromptigator so promptigator is superinteresting different retrieval taskshave very different search intents inother words different definitions ofrelevance so the title is few shot denseretrieval from eight examples but theidea being that we need to generate datato train our retrieval models dependingon what kind of application you havethere are many different distributionsof search queries and intents with yoursearch so if you look on the far leftyou see with Ms Marco you say you havequestions like surgeon salary per yearbut Ms Marco is just like thing youwould things you would hit the Bingsearch engine with compared to Feverwhere you have claims like music artistsis a profession of Christina Aguilera'sor like entity surge or counter argumentretrieval so hopefully just from lookingat these different kind of queries youcan see that they require differentkinds of query embedding models willwork better if they're more tailored toa particular kind of query distributionso what they're doing is they havethey're using large language models togenerate training data for retrievalmodels for particular kind of searchtasks or search retrieval needs so whatyou do is you have this few shot promptwhere you say give eight examples againof what a document query pair would looklike for this particular task and thenyou just swipe in your whole you justrotate in your whole data set filling inthat D and it will generate queries foreach of the documents depending on yourtask so as an example this arguana'sdata set is different from naturalquestions Ms Marco you're particularlylooking for counter arguments in thesearch task so you know you make someclaim like language models only achievegood performance at 10 billionparameters and then you want to go hitthe scientific literature and findcounter arguments to that it's adifferent kind of search task thanquestion answering in these other modelsso few shop propagator is able tosuccessfully adapt to this task with afew examples by generating training datalike this and then you use this trainingdata to train the text retrieval modelsso pretty much the idea is you use thelarge language model to generate atraining data set to distill into saythe 22 million parameter retrieval modeland I think this makes a lot of sense asais like an interesting way for how weuse language models in Search andparticularly the you know the searchVector search setup that we'reenvisioningso here's some results of the propagatorand you can also train a cross encoderthis way so when you retrieve you cansay retrieve a thousand examples andthen re-rank them with a cross encoderand svidlon has done this incredibleillustration of a comic book with afisherman and this example where withthe retrieval you cast the big fishingnet and then you get some fish onto theboat and then the fishermen have to lookthrough each of the fish and that's theidea of having a cross encoder that doesthose pairwise but you can also train itby bootstrapping the data for that inthe same way and it's also interestingto see this evaluated on the um beirBenchmark of diverse domains and diverseinformation retrieval testsso the next topic I thought wasinteresting it wasn't a whole paper butuh this query to query model where it'ssaying two queries are equivalent if theuser is searching with those queries arelooking for the same set of results andthat's kind of the that's the coremotivation for how we're going tobootstrap this training function tofurther improve these query embeddingmodels so it starts off with somemotivation about different aspects ofquerying where uh where you you have thesame query and you're looking for thesame thing even though it's a difficultsort of natural language understandingtask you might say uh The Rock DwayneJohnson if you're say looking for moviesand you're referring to the same personand all these other examples of howthese queries can differ each other buthave the same information needs so whatthey do is they use a query log and so Iimagine that as we think about things webuild into weviate is you would havesome kind of search log with the clicksand you would see what queries resultedin the same uh in the same click so it'sdifferent queries result in the sameclicks and you use that to bootstrapthis positive labeling as we have thiscontrastive learning framework which ishow we're producing these things we'rethinking the same results those arepositives versus negatives so they'veopen source the data set and you knowreported some results with theirparticular data setthe next topic I think this is crazyinteresting as well is about searchagents how can we have agents thisreinforcement learning State actiontransition thing that learn how tosearch and model the rabbit hole ofhuman Searchers so I think this exampleis really great and I think most of uskind of search like this you might do aquery like what is the weather like inGermany in June and then you get someresults you go actually let me add thekeyword temperatures to this let me addthe keyword average to this so that'sthe key idea is we're going to be havingthree actions to refine the query withthe bm25 search which is either addanother keyword remove a keyword orboost the term importance of a keywordand so the general framework looks likethis where you have the hybrid searchbetween bm25 and a dense retrieval modeland then you have a T5 re-ranker andthen you have this T5 query formulatorwhich is the thing that's trying toreinforced from learning to learn how tocontrol the bm25 to do this depth ofsearching and I think this could just bean incredibly interesting controllerin the kind of design of these searchpipelines so then the next topic is umreally this is really a mind-blowingthing that's happened in AI yesterdayeven so I had to kind of scramble to addthis to the slides butso the new method uh self-ass thatimproves results over Chain of Thoughtprompting by having the language modelexplicitly State and answer follow-upquestions before answering the inputquestionso I'm kind of going to put this herefor a second and take a quick breakdownto coffee butokay so here's the idea so in gpt3 theyhave this thing called in context fewshot learning where you provide examplesof the task the question would be wholived longer Theodore hacker HarryVaughn answer Harry Von Watkinsand then you give it the new inferencethe new question that generates theanswer so the few shot in the sense ishowever many of these question answeredpairs you're going to put in the inputfor the gpt3 then they came up with thisidea called Chain of Thought promptingand this was absolutely an incredibleidea what you you show it how to answerthese questions how to decompose thesequestions explicitly so who lived longerTheodore hacker or Harry Von Watkins andthen you explicitly show it how to dothis Chain of Thought where you firstrecall that theater hacker was 65 yearsold when he died Harry Von Watkins was69 years old when he died so the finalanswer is Harry Von Watkins so thatworked extremely well for a lot of thesethings and you see like gpt3 solvingmath problems doing coding this kind ofChain of Thought prompting is reallyshowing how to query the language modeland access what it's learned and now thenew idea is self-ass so it's a it's abetter way of doing these prompts so yousay question who lived longer Theodorehacker or Harry Von Watkins and the newthing is you say are follow-up questionsneeded here yes and then you ask anotherquestion and you keep rolling it thisway to answer this thing a particularcompositional questionsso this is the thing is there aredifferent kinds of questions that youcan answer if you just cut this off andsay who won the Masters Tournamentyou're just recalling a single factcompared to multi-hop or compositionalquestion answering where you have tochain together information so they'vereleased this new data set withquestions like who won the MastersTournament the year Justin Bieber wasborn so it's not like the kind of thingthat you've seen in the training datayou have to do this compositionalreasoning and this compositionalgeneralization this is probably thehottest Topic in deep learning right nowuh so oh and then another reallyinteresting thing about thisis not just having the language modelanswer the follow-up queries you wouldyou would send these queries to thesearch engine and I think this is thisdiagram right here is just an incrediblyinteresting visualization of how we canhave these large language models we V8Vector search engine how they can playtogether to just build incredibletechnology like thisthe next huge topic and I think this isjust incredibly exciting how theseconcrete numbers are coming out Mosaicml has updates on their Mosaic ml Cloudfor the cost of training GPT models andwe'll sort of get into all theoptimizations they do with themulti-node scaling the resumption one uhruns crash or lost bikes are detectedand the way that they do the dataparallelism with the pi torch fsdb andthen the uh the compute optimal tradinglaws for how they tell you that you knowthis is this is the compute optimal uhscale of the number of tokens you shouldtrain at 30 billion pretty much ifyou've seen these papers and like neuralscaling laws it doesn't make any senseto keep training these models past thiscompute optimal point so I think lookingat this you'll see that it's it's stillkind of expensive because we're seeingthat there's like this phase shift withthese language models where when theyhit around that 6.7 billion parameterMark is when there's this emergentphenomenon where they start to performreally interestingly but I think justgetting these details out there havingthese concrete numbers is justincredibly interestingso now we're going to look into acounter argument about how you would doinformation retrieval with generaterather than retrieve so the idea beingthat uh you would generate documentsinstead of retrieving them and theyargue three drawbacks to Modern debtsretrieval methods that that I think arekind of worth seeing if these are validor not the first argument is therepresentations of questions anddocuments are obtained independentlyleading to only shallow interactionscaptured between them so this isdiscussing how you would separatelyvectorize the entire document Corpus andthen vectorize the question and sayingthat this is this is missing outcompared to where you say take thequestion and the document as input togenerate somethingand then they discussed uh you know theproblem with say you only embed it intoa single vector and I think they citethe Colbert paper on this idea of havinguh these multiple Vector representationsat the token level as well laterinteraction and that kind of thing andthen they discussed that the sort ofthey argue that the limitation of thedocument index is that it limits thesort of size of the embedding vectorsand can't use the large language modelsdirectly in this waybut I would say that there's kind ofthree drawbacks as well the languagemodels is that they're hard to updatethey're not as interpretable as theretrieve and read and then you know it'smore parameter efficient to do this waybecause we don't need to store the datain the parameters and that also saysit's just there's something to it beinglike ground truth information thatyou're retrieving compared to thegeneration and I don't think it's thatit's solved to avoid the hallucinationproblem things like this butso I yeah I don't want to go in on thistoo much but they also have this ideawhere they we're looking into somethingcalled bird topic where you have thesedifferent clusters and you use this toprompt it to to sample diversity in thegeneration I think this is an example ofyou still have the embedding index toget the prompt so they're the way thatthey're kind of proving it is by usingthe the embedding set with the Clustersand then finally I'm just it stillrequires large language models to getthis emerging performance so as they'reshowing this chart it takes up to 100billion parameters to get this workingwell so I still think that this idea isisn't as far ahead as just the retrieveand read but it could be interesting tohave a hybrid search maybe in the futurewhen we say hybrid search will meangenerate and neural retrieve and bm25rather than right now we're mostly meanneural retrieve and bm25but anyway so the next topic is aboutfuchsia learning with retrievalaugmented language models decoupleKnowledge from reasoning but the idea ofbeing umlanguage models have achieved this fewshot learning ability where you can givethem like four examples of input outputsand then they can do novel inferencesand that's just probably the mostexciting thing about language models sothis report is studying is can theseretrieval augmented language models orrather than just having a whole densearchitecture you retrieve and then readcan that also perform this few shotlearning taskso they find that you can using thismassively multitask Benchmark and Ithink it's just incredibly interestingthat you can also get this two-shotlearning with a much smaller model thana lot of these dense language modelsand then this is what I think is the bigsell of these models what what you'relooking at is you you can update theseretrieve augmented language models youhave uh answers from 2017 that when theywhen it's 2020 they're outdated so saywho won the NBA Championship or who isthe president of the United States orlike things like this where they changeover time with the retrieve augmentedlanguage model you can just swap out theinformation and update it extremely easyand I think that's a really interestingproperty of thisso then we'll talk about what isretrieval augmented models look like inimage generation so I I hope that a lotof you are interested in these diffusionmodels where uh what they do is they younoise it and then you learn to denoiseit by having this kind of uned and thenattention to the text prompt which helpsyou in doing this uh learning task sowhat they're doing is they're retrievingadditional images and text prompts toguide the diffusion so it's not justconditioned on the text prompt it's alsoconditioned on the nearest Neighbors inthe database and they share thatparticularly what this is really goodfor is generating specific entities soif you're saying um a barbato day Ican't say that a Bravado de ChurchSierra is standing by a river and it's aparticular kind of dog image gen Dollythey won't generate that particular dogbut if you augment it with the retrievalcomponent it'll generate that particularthing and I think this incrediblypowerful for how these models are goingto be actually usefuluh so then we'll talk about this idea ofset fit that is able to achieve few shotLearning Without large language modelsand so it's able to do this by say youhave eight labeled examples you train asentence Transformer with uh contrastivelearning and then you train a classifieron top of that and surprisingly justthis pipeline is able to work extremelywell they show that it Rivals theRoberta large is only eight examples onthis customer review data setuh so then just quickly I wanted to justsay that I think that this kind ofapplication of studying editing textrather than just generating text isgoing to be extremely interesting forhow we interface with these naturallanguage processing systems and havingsomething that can suggest edits to yourto your text is probably more usefulthan something that just generates textdirectly having like a thoughtful reviewof something and so they've publishedthis data set where they have thesedifferent tasks like Clarity coherencefluency things that say you label forand edit when you're giving somebody areview of their blog post or somethingokay so finally the last thing is thisoperationalizing machine learning andinterview study uh make generallyorganizing MLS practices around velocityvalidation and having versions of modelsdescribing this General pipeline ofmachine learning from data collection toexperimentation evaluation deploymentand then monitoring and response alsothings like run layer pipeline layercomponent layer infrastructure layer andan mlav stack and so there are a lot ofreally interesting quotes but generallythe organized around the idea ofvelocity where you quickly prototype anditerate on ideas validation how you testyour models and then versioning so whenthe model has failed you can you knowroll it back to a previous machinelearning model that you had in thesystemso there's a lot of quotes in here and II feel like I'm maybe going over thetime limit but um like I just highlyrecommend having to look through thisand seeing all this advice on thingslike Jupiter notebooks how you findsubpopulations in your data to do theevaluation and how to really do thiskind of versioning I think the wholething is justchock full of wisdom and how to buildthese systemsokay I hope that was a good overview ofnew and AI maybe a little longer than Ithought so going in but um I think kindof the most interesting thing isthinking about large language modelstheir advances and what this has to dowith searchperfect thank you Connor for this uhgreat overview so I think one of thethings I was thinking um was can are yougoing to share the links to any of thosepapers or like maybe so that if any ofus wants to go and find those papersum could we do something about it likeuh send it via tweet or somethingyeah I can put like a blog post with thelinks to all these papers as wellperfect yeah so if you if any of youfollows us on like a V8 uh i oum tweet on Twitterhandle I forgot how to speak for amoment uh we will just tweet a link tohow to find maybe those references andand I think that would be pretty coolbecause there's so much uh of yeah sucha big wealth of knowledge it's great toseeum yeah great and uh do you have like afavorite of the papers from those 11that you talked aboutI think probably self-ask is the mostinteresting sort of but uh I mean Ithink I've already I picked all thesethings because I think they all dosomething very interesting but this kindof have the language modelprompted to Think Through is I thinkprettyincredibleexcellent thank you I mean yeah ofcourse like all of them like are superinteresting it's just but we can stillhave like our favorites uh right that'sthat's kind of the thingcool all right so let's move to thefinal part of the presentation so I'mgoing to invite Erica back to the streamhey Ericaum so Erica is going to show usum a quick demo of an application thatshe's been working on so I'm going toshare her screen nowum so yeah I'm really excited aboutum the dog search demo Erica like whatcan you tell us about it all right alittle sneak peek is it contains imagesof dogs and I'll share the motivationfrom my little dog Bowenmy name is Erica Cardenas and I'm a partof the devrel team and today I will begoing over a demo on using the uh inchto back neural module from weaviateuh so this is Bowen the developerAdvocateum excuse my little dog at Connors toouh she is two years old and one thingshe loves to do while she has a fewgames um she likes catching uh beingchased by humans or other dogsum she likes treats and yeah she's justa really playful dog so here is Bowen ina dog park playing with her best friendOllie so what she enjoys to do is yeahthe chase game kind of running aroundvery fast andum she loves going to the dog park andinteracting with a few dogs so this dogpark is a little empty but usually thereare a ton of different dog breeds soBowen asked the question of oh can Ifigure out what kind of uh breed thisdog is based off of the image I saidsure Bowen let's build this demo withusing alleviate and python Plus for theweb application right so let's get intoit uh so we were building an imagerecognition uh demo and we're using theinch to back neural module from Wi-Fium what this does is it converts imagesinto vectors so we can search throughthem and it uses the resnet50architecture trained on imagenet andimagenet is a data set that has 20 000classes over 10 million labeled imagesso this is quite large and as you canguess there are quite a few images ofdog breeds so this is the best reviatemodule to use but also using theresonant 50 architectureall right so Bowen has theum well Bowen all she had was the idearight so I said okay let's create a dataproperty so this has the name which isthe dog breed the image of the dog andalso the final path soum later on when I built when I builtthe web application uh we'll be droppingin an image and it will spit out themost similarum dog image in our data setall right so let's open up theapplicationall right starting off with the dockercompose file so maybe it makes thisextremely easy so here we have the uhvectorizer module so we just specifiedthat we're using the image to VEC andthen also that we are using the resnet50 model and that's currently theum only one I believe that is offered onwheat beets but I'm sure there will bemore soonall right so once we load up our Dockerfile now we can go on to creating theschemaum so here we are just uh connecting toour localhost and then we are buildingthe schema of our DOT class so it is itcontains images of different dogs and wealso haveum we are specifying which backyards arewe are using which I have stated um isthe image to back all right and then ourproperty so we have breed which is astring we have the image which is a blobtype a data type and then we also havethe file path so when we use the nearimage operator it will output the filepath to the imageum and then we are just going to add theschemanow and we need to upload our dataobjects to aviate so we are againconnecting to our local host and uhbefore this in order to have a blob youneed to convert or yeah in order toupload your images to Evie you need toconvert your images to base64 values soI've already created the folder that hasthe conversionum so in lines 10 to 14 I am justopening this and then an 18 to 23 theseare just the data properties which wehave already specified in our dataschema and then we're creating a uniqueidentifier for each data object and thenin line 28 we are just uploading this toev8 so that we can use it and searchthroughand since we are using the python uh weV8 the python client I decided why notbuild a web application in Python so weare using flaskum lines one and seven are just a fewlibraries that are necessaryum to build our applicationum so here we are building in line 9 to11 we are building are upand in lines 13 to 27 this is the homepage so this is the landing page when werun our application.pi fileum it will output the URL and we'regoing to run that and what you're goingto see are the images that are in ourdata set which are about uh yeah we have10 different dog breedsin lines 29 to 38 is where we arerunning the near image or constructingthe near image operator in vb8 so we'rejust limiting that to two outputs and uhyeah just letting it limiting it to twoand what is going toum what the output is going to be is thefile path and the breed name so if Iupload an image of Bowen I want theresults to Output golden doodle and agolden retriever rather than aRottweiler because they are not similarat all I think you guys know but thesize and also the colorumall right so in lines 42 uh 57 this isreally where we're just um opening upour image and we areum so once we upload the image we needto be able to store it and then we alsowant to Output it so that that's kind ofjust what this code is doing and thenwe're just rendering that template andhaving it structured in that aspect andif weum in line 60 to 61 we're just runningthe application so I think that was anoverview of the code are there anyquestions Sebastian I don't have it openare we good to see the appI think what we we should probably uhshow the app and just to show everyonehow yeah how you build it but I thinkit's really cool because basically thatfunction there where you have just uhcalling uh this this search with thenear image uh it's really where a lot ofthe magic happens right like once youimported the data and did thevectorization uh it's really cool so uhwhat what can Bowen do now with this appshow usall right let'sall right so here's our app with our 10dog images we have a Bernice MountainDog a corgi Rottweiler we have it allalmost right so let's upload an image ofa mini golden doodlelet's submit it and what comes up is thegolden doodle and golden retriever whichis exactly what we were looking for sonow a phone goes to the dog park and shesees this dog she can say hey that's agolden retriever I know I'm the nearestneighbor to it and I want to play withit so now Bowen's curious mind is uhshe's happy huh I could saynice and and what happens if you if youif she tries to look for some friends uhthat she's seen yes let's drop in asilver labthat's more similar too all right wehave the labrador achiever and goldretriever which basically the same dogso it works and now yeah you can searchfor various dog images and we can alwaysinclude more and then also add in moreto our data properties like weight andnot that we all want to think about thisbut it's the lifespan of the dog soshe's like Hey will this dog be in thisdog park 10 years from now maybe maybenotgot it yeahI really like how uh in this demo likeit's not that like the dogs can becompletely like you know can bedifferent colorEtc because like uh when when you searchfor like a golden doodle right like youfound one that actually has differentfur uh but it's still a similar breed solike the the ml model is actually prettysmart I'm quite impressedum so what's going to happen next withthis demo what's what's the plan how canwe share with the with our audienceall right of course um so I will bepushing this to GitHub so anyone canaccess it and it also contains a readmefile so it's actually quite simple torun it I've made it as simple aspossible with just using pythonum and we can always add to it add moredog breeds add more images and justcontinue building on thisPlaceyeah because I think we're going topublish it in our uh we made examplesum and and I would actually encourageanyone to kind of like hey help us makethis application look great and then andalso test it out like if you have awhole bunch of Docker images that youwant to test out uh you shoulddefinitely uh check it out in withexamples it should land there soonum but also I I know it already as I'mnot gonna ask directly I reckon but weare working on a blog post that explainsthe whole journey of how thisapplication was built how you couldactually use the image to vac uh moduleum so yeah like it should be up in thecouple of weeks and we'll be sharingthat for sure yeahum so uh what's Bowen's opinion on itdoes she like the application has shetriedshe's happy she's happy is she is shearound is she in the room with youyes come on we should we should all showabout people and like let me go you knowokay the motivation of this app rightabsolutely yeah let's umthe Bowen is a real dog she's a realcustomer and Erica wasn't building theapplication just for funum and we are super excited there she ishey Bowen next time we should definitelyget bow and like her own streamall day or is at the dog park so maybeI'll include images of her next time thedog park excellent excellent and I knowat the end as a Doctor Who's super cuteas well but I guess uh he's not aroundrightoh not not ready for herdefinitely the dog is too big to liftlike that righthe's a golden retriever so it's I guessoh Still Still lift him but yeah I wasthinking about the selection of dogthere's this like this is a greatselection of of dogs I don't know ifthese are like the most common breeds orsomething but I my parents had a Bernicemountain dog when uh when I was growingup so that was that was super cool now Ihave a golden retrieverum Labradors are super common huskiesare super cute German Shepherds are Ithink they're just super pretty dogs Ilove this selection yeah just looking atthe dogsI have done more to it but yeah thesewere just the ones that came to my mindlike the ones that I see the most oftenI feel likewell thank you perfect thank you forthis demo it was it was amazing um andactually so you should be all like uhpretty impressed with this demo becausethat's something that Erica just startedI think last week so this is really likesomething that you can build uh reallyquickly if you know you know a bit aboutvv8 if you know a bit about machinelearning if you you know you could pickup flaska over you know a day or two andyou could straight away build a reallycool demosum so yeah I'm really curious what otherideas Bowen will have for our futuredemosperfect uh I think this was a prettysuccessful uh first episode of viviateair uh thank you all for watching usum I I really enjoyed myself there wasso much to learn uh but that would bereally curious um to learn right likethis basically this is the first liveepisode that we've done and I'm sure wecan do it better I'm sure we can maybeinclude some other ideasum so please share your feedback with usyou can do it on Twitter you can join atthe uh with this public slack I woulddefinitely recommend doing that uh andum or maybe if you think like you havesomething really cool to share maybe youbuild something with viviate uh thatcould be you know a cool thing maybe youcould join us for five ten minutes uh wecould always accommodate the format andmake that happen but that's at leastfrom me uh anyone else anything to addno well thank you all for joining and ifyou guys enjoy the demo and replicate ityeah absolutely I love how we'rebridging this Gap from from sort ofgetting started so quickly to going allthe way to like super complex cases inproduction now basically you can you canuse VBA to get started and you can usebb8 for you can keep using it as yougrow which is which is super cool yeahalso thank you for my side super cool II was planning on on watching thisepisode and then I got invited lastminute so I guess I still watched ityeah I was I was looking at the roadmappage and I was I was going to talk aboutit in front of everyone and then I waslike oh at here doesn't have anything onthis calendar let's let's rock him inyeah because I didn't schedule anythingat air timeexactly so like for anyone that works atsemi like if you don't want to be ropeteam randomly like uh invent a meetingwith a customer or somebodyof an excusebut it would be great all right verycoolsuper great that you were all able tojoin us and um see you next month and Ithink uh just to double check the nextepisode probably be will be planned forthe 2nd of November so the whole idea isthat we want to run those on every firstWednesday of the monthum so yeah thank you for watching andsee you in the nextwe'll be there thank you", "type": "Video", "name": "Weaviate Air \u2013 Episode #1", "path": "", "link": "https://www.youtube.com/watch?v=8B0ORWf3OY0", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}