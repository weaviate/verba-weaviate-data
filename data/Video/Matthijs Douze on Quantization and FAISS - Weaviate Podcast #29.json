{"text": "Hey everyone, thank you so much for watching another episode of the Weaviate podcast! This episode features Matthijs Douze, ... \nhey everyone thank you so much for \nchecking out another episode of the \nwevia podcast this is a super exciting \nepisode of BBA podcast we have a \nresearch scientist for meta AI Matisse \nduzy uh his research publication list is \njust amazing the amount of work he's \ndone in the space of vector analysis \nproduct quantization all sorts of things \nof deep learning really is really truly \none of the most impressive scientists \nI've had the opportunity to talk to so \nMatisse thank you so much for joining \nthe podcast \nyeah thank you very much for hosting me \nawesome so can we kick this off by \ntelling us about the history of the \nresearch uh like how did you come to be \nworking on these things what first \ninspired your interests \nyeah so \num yeah I can say a little bit about my \nbackground so \num I have a PhD in computer vision \nbasically so that's my background uh I \ndid it in in France and uh then I moved \nto \num \nto a research uh institution the which \nis inria and where I met harveyjigu who \nhe has an expertise more in anything \nrelated to coding encoding decoding the \nkind of things that's used for GSM \nnetworks and uh and so he was the main \ninspiration to move towards thinking \nabout how to better compress uh \ncompressed compressed vectors because \nbasically there's one very clear \napplication for this in computer vision \nat the time that was very important \nwhich is that images were analyzed by \nextracting sift features from them and \nsift features I just \num 128 dimensional vectors that are a \nnew extract \nin the order of hundreds to a thousands \nper image and those those were early \nembeddings so that means that it's a \nrepresentation of a small part of the \nimage and then you could do a couple of \nthings with those you could use them for \nimage classification but the the part \nthat we're most interested in was image \nindexing which means uh which meant at \nthe time and still means now finding \nsimilar images for example images that \nrepresent the same object or the same \nbuilding \nand to do that you had to \num you had to find which where the \nnearest embeddings the nearest sift \nvectors from the ones that are in the \nother image \nand so there was this um at the time \nthere was this very interesting work \num that came from uh from the Andrew \nzisman's lab and uh uh and which which \nwas basically led by Joseph Savage and \nuh which basically uh reduced this Bunch \nthis big number of CIS vectors so you \nhad like like a thousand sift vectors \nfor one image which was pretty heavy and \nto reduce that into a bag of words and \nback of words just means that you reduce \neach Vector into a single identifier a \nsingle a single number that was \num assigned by nearest neighbor uh \nnearest neighbor search so searching the \nnearest centrates to each of the vectors \nand just keeping that only information \nabout that vector \nand so that means that if you had \nif you had a like say 1000 centroids you \nwould have the only information that you \nkeep from all those heavy sift vectors \nin the on the image is a kind of \nhistogram over the Thousand centuries \nabout how many sips vectors were falling \ninto those sift actions \nso and it was called \num a bag of bag of visual words because \nin a sense by analogy with text you \nwould reduce the the the you know the \ncontinuous space of the the set vectors \ninto a single a single token a single a \nsingle word uh and that represented the \nimage and then the images could be \ncompared and the basically what's what \nhappened there is that this represents \nthis back of word representation that \nwas used for many many applications \nincluding classification but what it \nalso enabled was uh to be able to \num to do large-scale indexing so that \nmeans since it's so compact you could \nsay okay I have uh I have uh ten \nthousand a hundred thousands a million I \nthink before us the the largest \napplication that was at scale 1 million \nuh one million uh images and you could \nindex those and that was that was quite \nnovel at the time that it was possible \nto really find in in real time so there \nwas a work \num that was coming from uh Nissa and \nstevenius where they basically had a \ncollection of CD covers and they were \nshowing it to a webcam and the webcam \nwould find in real time uh what were \nthose covers what those covers were \ncorresponding to and this was really \nenabled by this uh this bag of fart \nrepresentation \nso that was so the back and forth's \nrepresentation was used to uh quite \nextensively at the time and uh it has \nbeen expanded and so on but uh what I \nwhat the the second or the The \nInnovation that came from this work by \nuh by cevich and this woman was the fact \nthat they used an inverted index so that \nmeans uh it's inverted because you start \nfrom uh from \num from from those those histograms of \nof visual words and instead of stacking \nthose histograms or visual words you \ninvert the index and you for each visual \nword index you record which images \nand contain that particle particular \nvisual word \nand uh so that made it much faster \nbecause \nwhat it enables is that if you increase \nthe number or the the size of the visual \nvocabulary so instead of having a \nthousand you can say I have ten thousand \nhundred thousands Etc \nuh you can you you get a very sparse uh \nsparse histograms obviously and that \nmeans that the inverted index when you \nactually want to find which visual words \nare in common between the query image \nand a database image you need to visit \nfewer a very small fraction of that of \nthat data set \nso that was \num so I think that that was a bit the \nbackground when we arrived so the the \nkey elements that we had there was uh \nthe the fact that we had \num we had this representation of uh High \ndimensional vectors with a single \ninteger which is exactly quantization \nand so that's where you know the \nexpertise of harveya started to be very \nuseful and we have this inverted file \nstructure that was the start of a lot of \nfruitful \num indexing methods that were developed \nlater including the ones that we \ndeveloped \nso then we arrived \nand uh so we we recognized this uh the \nquality of this uh of this inverted list \nand the potential the potential that it \nhad to do large scale indexing and um \nand so what we added to that the first \nthe first thing we added is actually uh \nthinking that within those inverted \nlists so the inverted lists are in the \nin the in the initial \num uh backup visual word representations \ncontained only the document IDs or the \nthe image IDs that contain those \nspecific visual words and so the idea \nthat we came with was to add a kind of \npayload for each of those uh instances \nwhere we kind of refine a little bit the \nrepresentation of the of the the vectors \nbecause uh because \nrepresenting a 128 dimensional vector by \na single integer is a very crude \nquantization and so what we did at the \ntime is that we we used a pretty \nstandard \nsystem that existed at the time and it \nwas uh it was to do a kind of \nbinarization and that we we called \nHamming embedding and so having \nembedding basically consists in taking \nthis 128 dimensional Vector applying a \nrandom rotation to it and then keeping \nthe sign of each of the components after \nrotation \nand so then we get a binary Vector which \nat the time we didn't use the 428 \nDimensions but we used just 64. and then \nwe had a binary representation of 64 \nbits and we could do that both on the \nquery side and on the database side and \nthen comparing binary vectors it's very \nvery efficient to to compute the to \ncompare those with Hamming distances \nand so then then we had \num \nuh we had a image indexing system that \nwas very efficient and that was based on \nuh on what currently we would call an \nIVF an inverted file and having a \nbattery Banning so \num a binary representation of the of the \nthe vectors that are stored with in that \ninverted file so that was the first \nstage \nand we got we it was very successful in \nterms of of large-scale image indexing I \nremember redoing the demo with the \nwebcam with uh with a laptop and uh and \na webcam and uh and I'd scale 10 million \nimages and an external hard drive \nwhich uh so for the technical details \nwhich which didn't have a partition at \nall on it and so there was no file \nsystem because we need to access very \nquickly we need to access the images to \ndisplay the results so we were accessing \ndirectly the offset on the disk uh of \nthe the actual images \nand uh and this was this was working \npretty well and um and so that was the \nfirst iteration of uh of uh of uh of \nthis combination of \num of the the IDF which where the \nobjective is really to to to very \nquickly prune the data set though the \nparts of the data set where you need to \nsearch and an encoding method uh whose \nobjective is to get an approximately \nreasonable or as good as possible \napproximation of the of the \num of the \nof the vectors \nso it turns out that so at the time \nthere was the the there was a lot of \nwork around binary representations for \nfor vectors so uh there was a whole \nliterature around localized locality \nsensitive hashing which \nis not exactly uh the same as a binary \nrepresentation but very often a binary \nrepresentation is is based on the \nlocality sensitive hashing Theory and um \nand so that there were interesting \ntheoretical properties \nuh and uh so there was a spectral \nhashing uh which was a work by taralba \nand uh so there was a literature around \nthat and uh but what we so there the \nexpertise of Harvey that he had uh for \nfor anything related to quantization uh \ncame in very useful because he knew and \nit became clear afterwards that actually \nuh binarization is a very crude way of \nof doing quantization so basically it is \nquantization because you you transform a \ncontinuous signal into into an integer \nbasically but there are much better ways \nof uh of or much less lossy ways of \nencoding vectors than doing uh than \ndoing binarization \nso that maybe we can go a little bit \ninto the theory of um of quantization so \nuh the parts that I know if I'm I can't \nsay I'm much of an expert but I got I \nget got some experience and some very \nbasic principles \nso the the first \num the first two principles are the \nLloyd principles so uh for quantization \nand uh basically since you since you map \na continuous signal to our continued \ncontinuous Vector continuous High \ndimensional Vector to \num to uh to one single uh representation \nso it's to one single integer then and \nyou always have a reconstruction of that \nof of the approximation of the of the of \nthe vector \nand so uh so in order for this \napproximation to be uh to be optimal \nthere are uh there are two necessary and \nnot not sufficient but necessary \nconditions \nand the first one is that each they are \nvery natural the first one is that when \nyou have a vector and when you look at \nthe whole set of possible \nreconstructions that you can make with \nyour quantizer so what that we call \ncenturies in general uh then uh the uh \nthe vector should be assigned to the \nnearest centroid so it's if you pick one \na centroid that is not the nearest then \nby definition you are doing something \nsub-optimal so you always should always \nassign to the nearest vector \nand the second one uh so so this is \nquite natural the second one is specific \nto the to the to the L2 distance to the \neuclidean distance if you minimize the \nthe if you minimize the the the squared \nuh error of the Reconstruction uh then \neach centroid should be the center of \nmass of all the vectors that are \nassigned to it \nin the distribution \nand uh so those those are two principles \nand the actually the very nice thing of \nof this of those two principles is that \nit translates to the k-means which is \nalso called The Noise Lloyd's algorithm \nto uh to do uh to do clustering and as \nwell as to do quantization because the \ncanines is an uh basically what you do \nis you you take a training set that you \nsuppose is representative of the of the \ndata distribution and then you you you \nalternate between two steps the first \none is to estimate or let's start with \nthe assignment so you start with a set \nof of initial centroids that are \ndetermined with some heuristic or \nrandomly and then you you assign to each \nuh you assign each training Vector to \nthe nearest centrate so that you you you \nbasically you do the assignment step and \nthe second step is you update the \ncentroids by by Computing the center of \nmass of all the points that were \nassigned to that that centroid \nso k-means is is one of the huge \nsuccesses of of uh of quantization and \nof many machine learning algorithms it's \nvery simple \nand um \nand actually it gives you uh it gives \nyou a quantizer if you have a \nrepresentative trading points it gives \nyou a quantizer that is that has that \nfollows those two properties of the the \noptimality of the of the two lights \nconditions \nand um so what's so this is very good so \nwhat's the problem with k-means the \nproblem is that say that you you have \nbudget to \num to represent a vector with 64 bits so \nuh what happens is that you cannot \nreally say okay I'm going to do a \nk-means where the the indices are going \nto be encoded into 64 bits because 64 2 \nto the 64. it's really a lot of \ncentroids it's actually more than much \nof uh of the high numbers that we find \nin modern computer science so so it's \njust not possible it's not possible to \ndo this to use this amazing cayman's \nalgorithm at that scale it is possible \nand that's what we do to use it for IVF \nfor cost quantization so for I for \ninverted files uh we have the the degree \nof freedom to choose the number of \ncenturies that we want to use and in \ngeneral it is beneficial to use a large \nnumber of centroids but we're not going \nto to have 2 to the 24 the 2 to the 64th \ncenturies we're going to have like uh \nbetween uh uh a thousand ten thousand \nhundred thousand one million this this \norder of magnitude number of centroids \nso for this we can use k-means directly \nand we definitely do that uh to to to do \nthis first step of what we call course \nquantization so the the inverted file \nthat's going to to allow us to to search \nonly a really small hopefully a small \nsubset of the data set and still not \nlose too much accuracy in this process \nbut when we when we when we're talking \nabout the payload so the the the parts \nthat you going to use to approximate the \nvector and that you store in the \ninverted lists uh then you you cannot \nyou I mean if you have a payload of \neight bits it's fine but in general you \nhave a larger payload and the reason is \nbecause it doesn't make much sense to \nhave eight bits because the even the \nimage identifier is going to be longer \nthan that \nand that's also start in the inverter \nlists and so if we want to go to 64 bits \nthen uh so the the the fundamental idea \nof the product quantization which \nalready existed but was never used for \nuh similarity search per se the idea \nthere is to is to say okay we cannot \nreally afford to do a 64 bits by uh by \nhaving a vocabulary that's that spans \nthat has one explicit centroid stored \nfor every uh for every uh set rate of \nthe two to to the 64. so what we're \ngoing to do we're going to do a \ntrade-off we're going to just chunk or \nto we're going to take the vector the \ninput vector and split it into sub \nvectors and then apply this quantization \nthis K means quantization or this \nexhaustive conversation apply it only on \nthe sub vectors \nand this is \num it's very it's it's it solves our \nproblem uh of scale because let's say if \nwe need 64 bits uh let's say that we can \nsplit those in eight times eight bits \nand eight sub vectors that each are \nencoded in eight bits and then doing the \nk-means for to get 8-bit vectors it's \njust okay means with 256 centroids and \nthis is I mean this is you could almost \ndo it by hand and um \nand then uh to and then you can encode \neach of those Circ vectors into separate \nuh into a separate representation and \nthen just concatenate those \nrepresentations and uh and you get an \napproximation of the the vector \nso uh so then we are down to uh to \nhaving \num \nto having uh encoding costs that's very \nreasonable because at encoding time what \nyou need to do is is exhaustively find \nthe nearest centroid for each of the sub \nvectors but since you need to search \nonly 256 hundreds it's uh it's pretty \nefficient and uh and uh uh and and the \nstorage the other problem was the \nstorage of the centroids this and since \nyou need to store only small centroids \nin in for each of the uh for each of the \nsub vectors it's it's pretty efficient \nactually uh the starting the centroids \nis as large as storing 256 vectors \nthemselves because if you add the sizes \nof the sub vectors you end up with the \ninitial size of the data vectors \nso that was that was uh very interesting \nin terms of storage and in terms of \nassignments and so decoding is just a \nlookup and you separately look up each \nof the vectors and one very interesting \nproperty that we already that we also \nhad and that's uh that was kind of lucky \nthat it turns out this way is that it's \nalso possible to do compressed domain \ndistance computations \nso compressed demand distance \ncomputations means that if you have a \nquery Vector \num so in general \nI wouldn't say in general but very often \nyou want to compress the database \nbecause it's size constrained but the \nquery vectors come as a float so you \ndon't really need to compress them and \nso \num and so what you can do there is to so \nthe the basic algorithm that you would \ndo with uh with an igf and the PQ or \nwith the PQ payload to compute those \ndistances is to take the query vectors \nthat are not compressed decompress the \nthe database vectors or you scan the \ninverted list you decompress each of the \nvectors and then you compute the \ndistance just by Computing L2 distance \nand and so that's fine \nbut it turns out that it does something \neven more efficient that you can do is \nnot decompressing the the the database \nvectors at all but when you know at the \npoint when you know the query Vector you \ncan you can say okay uh for each of the \nsub vectors of those query vectors I \nhave only 256 possible Dimensions \nbecause there are 256 hundreds and so I \ncome I can just instead of computing it \nevery time you can just say okay I only \nhave 256 possibilities so I just need to \ncompute those this and all those 256 \ndistances and what I'm scanning I'm just \nyou know looking up those distances and \nand compute what's the what's the and \nand then I don't need to compute \nactually compute the distance and this \nis possible so it's possible to do that \nwith uh with any quantizer you can \ncompute the businesses with all the \ncentroids and since it's a finite number \nof some trades you you always know that \nit you you will have pre-computed the \ndistances but what makes this possible \nwith the product quantizer is or what \nwhat's convenient with the product \nquantizer is that uh the distance is \ndecompose across Dimensions with L2 \ndistance or with L1 distance or with \nmany distances actually you you can uh \nwhen you you can chunk the the vectors \ninto parts and uh summing up the \ndistances in the sub in the subparts to \nget the total distance between between \nthe vectors and so that's or I mean it's \nnot true for L2 distance it's Square \nit's too true for squared L2 distance \nand so we always compute squared all two \ndistance and so \nand so in those sub vectors then uh we \nwere \num we uh we're adding together the sub \nvectors uh the distance of the sub \nvectors and and and basically when we \nhave 64 uh bits uh 64 bits \nrepresentation we have uh we just have \nuh a lookup to do for every of the sub \nvectors when we compute distances and um \nand then some summing them together so \nthat's for uh to do one distance \ncomputation instead of doing a \ndecompression plus plus uh plus L2 \ndistance what we do is we do eight \nlookups and seven additions to get the \nthe actual result \nso um okay so that's that was the \nprinciple of her quantization \nuh so I I'm I see that I'm kind of \ndiverging a little bit from the History \npart so let's go back back to the the \nhistory of product quantization so \nbasically this uh this all happened in \nthe so that that was back in 2009 I \nthink so and this was all you know uh \ngenerated by the by the the the the \nbrain of uh are they and so I was \nimplementing and together we \nwe made we made a paper about this uh \nthat we submitted to a journal to Pammy \nso that was the uh the IVF uh so it's it \nwas the product quantization paper which \ncontains both the idea of doing uh \nproduct quantization so it's called yeah \nby the way it's called the product \nquantization because you have a product \nspace when you have sub vectors like \nthis it's like when you look at it from \na space perspective you basically have a \nCartesian product of the subspaces and \nso that's why it's called the product \nquantization \nuh but but the the term wasn't wasn't \ninvented by by us it it existed before \nit's uh it's a relatively classic in the \nin the coding literature \nso uh we published this paper and um and \nso there were \num \nuh so it we we compared it uh with uh \nwhat we had previously the our Hamming \nembedding method uh so which was based \non on a binary representations and \num and it turns out so uh it turns out \nthat it was it was very fast and uh I \nthink \nI think at the time \nat the time maybe the it was so we were \nquite convinced that it was a very good \nmethod \nbut in the end it took a very long time \nuh before before uh people actually \nrealized that uh that uh binary \nrepresentations are \nare \num are just sub-optimal so it's it's so \nI think much of the story afterwards was \na kind of fight well I \nit was a very you know very polite fight \nbut still it it took it took a lot of \nEducation to uh to to to to convey this \nmessage that despite the huge \num amount of literature and theoretical \nresults that there is around uh locally \nsensitive hashing uh that binary \nrepresentations are just too crude to be \nuh to be efficient because uh because \ntheir their representation uh \ncapabilities are insufficient I mean \nit's it's just you cannot \num \nyou cannot you cannot even look at the \nat the Lloyd's optimality conditions \nbasically a binary presentation in its \nbest form would be so that's interesting \nactually it would be a product \nquantization where you have a single bit \nper you have sub vectors of size one so \nthat's a scalar and you have one bit per \nper sub vector and so it's a very \nspecial case of product quantization \nwith a very crude way of comparing them \nif you use Hamming distances but you \nthere are extensions of binary \nrepresentations where you actually do \nyou do asymmetric binary search so the \nsame you you don't take code or you \ndon't take the binary representation of \nthe query Vector but you you take the \nyou take the floating Point vector and \nyou can you can \nuh make it so that uh \nthat you can get to floating Point \ndistance but then you you kind of lose \nthe advantage of doing very quick uh \nhaving distance comparisons in the \nbinary domain \nokay so to come back to the history so \nuh the the the \nproduct quantization uh basically it's \nuh we we've done we and then other \npeople have done many follow-ups in that \nfield and so the follow-ups are \nare interesting I think that um so there \nsince there are two components of uh of \nuh of the uh of the the what we call IVF \nPQ so inverted file plus PQ payload \nrepresentation uh so there have been uh \nimprovements on both sides on both of \nthe on the IVF side so the inverted file \nrepresentation and on the PQ \nrepresentation \nuh so uh so before we started so I'm \ngoing to kind of to reattach this to the \nhistory I can say what what happened \nbefore uh before we started on the the \nface Library which is uh which what the \nbig software and undertaking so at the \ntime so in terms of software let's talk \na bit about software so uh back in uh in \n2000 uh 2009 we we produced a software \nthat was called PQ codes and that \nimplemented all of this uh in in uh in C \nplus plus and \num no in C actually right because we had \nan inversion of C plus plus at the time \nwhich I to a certain extent that I still \nhave and uh so it was in C and but it \nwas a closed Source library because \num we decided that we wanted to sell it \nand uh uh and at the time it was not so \nclear that you could and be open source \nand sell something so it was close to so \nand we sold it to uh to a few companies \nthat were using it for uh for \nlarge-scale indexing \nuh so uh what happened uh so that's what \nso in a sense I think that the facts I I \nthink back in the time people were not \ndoing that much uh open sourcing uh even \nin the research domain it was not at all \nobvious that that if you if you found \nsomething or if you publish the paper \nyou you'd open source it and we didn't \ndo that we didn't do that for several \nfor several of the papers and um and \nmaybe at the time it was not that clear \nas well that uh open sourcing is is just \na a royal way to increase the impacts of \npapers and um and so we we kind of uh we \nkind of expected that people would be \nre-implementing it and uh that that \nwould be enough but \nso I I think this is something that \nreally flipped in the in the last uh in \nthe last maybe 10 years or so um and so \nso what what happened is that uh there \nwere PQ implementations that started to \npop up uh so uh at Microsoft uh at \nGoogle had a early PQ implementation as \nwell and so the the Improvement and \nbut \num in this in this in this that it was \nstill not clear \nat the time there was no real uh very \nbig uh or established Benchmark for uh \nfor uh for for a near sniper search and \nand basically the the open sourcing of \nthose methods came in parallel with \nbenchmarks that were established to uh \nto actually really compare them and to \nto make the state of the art clear \nuh so but so that that's that's uh \nthat's something that happened on the \nsoftware uh and on the and on the you \nknow on the \non the adoption side of of things \nso what happened so I can say a few \nwords about what happened in research \naround the inverted files on the one \nhand and on the PQ on the other hand so \num one of the one of the the main pain \npoints of the ivfpq method was that \nthat the first level course quantization \nwas uh \nwas was a limiting factor because if you \nwant to index more vectors you need to \nhave a larger \num a larger vocabulary so I can explain \nthis a little bit so \nbasically uh when you do a search in an \nivfpq \nindex there are two components of this \nof the search time and the first one is \nto do the course quantization so taking \nthe query vectors the query vector and \ndetermining which inverted lists must be \nvisited and so that boils down to \nfinding the top \nand so it's in face it's called n probe \nthe top and probe number of inverted \nlists that need to be visited and so \nthat's the first stage and it's it is \nalso a nearest neighbor search problem \nbecause you find the nearest neighbors \nof the of the query vector and the \nsecond the second stage is to do \num is to actually scan those inverted \nlists and compute the distances using \nthose lookup tables \nand uh so it turns out so you need to \nfind a balance between those two costs \nand the the the \nuh it it turns out that when you scale \nthe data set to larger sizes uh in \ngeneral the number of centroids needs to \nscale as the square root of the number \nof of the number of vectors that you \nwant to index because if you scale it as \nfast as the number of if you don't scale \nit at all then the inverted list will \njust grow proportionally to the number \nof vectors so it so the cost is going to \nbe proportional to the um or the scaling \ncost is going to be proportional to the \nuh to the search time to the number of \nfactors but and if you if you scale the \nnumber of centuries as quickly as the \nnumber of vectors on the other hand then \nthe inverted lists stay about as long \nbut the course quantization cost is \ngoing to scale linearly with the number \nof vectors and So to avoid this you kind \nof spread the effort onto both of them \nand to do this a rule of thumb is to is \nto scale it it's a as a square root \nso if you scale it as a square root when \nyou start getting to 1 billion vectors \nuh it's starting to be a bit slow \nbecause you're in the order of hundred \nthousand vectors uh maybe a million in \ngeneral it's a bit larger so it might be \na million and if you have a million \ncentroids to compare with uh it becomes \nit becomes slow \nand so there have been several uh \nseveral propositions to improve this uh \nimprove this course quantization cost \nand the first one which was quite clever \nactually it was a method method by \nbabenko and lempitsky which consisted in \nuh in breaking down the the the the the \nthis are choosing the centroids as the \nrepresentation space of a product \nquantization itself \nso to make it very clear if you if you \nwant to have one million centroids you \nsay Okay I I have \num I have a thousand uh some trades for \nthe first half of the vector and I have \na thousand some trades for the second \nhalf of the vector and then I if I take \nagain the the prob the Cartesian product \nof those two sets I get a million \ncentroids and I can do efficient uh \nefficient uh uh lookup to lookups or \nefficient nearest neighbor searches to \nfind the nearest centuries of the the \nquery vector so this this was the first \num quite uh quite effective way of um of \nfinding the news neighbors or or doing \nefficient course quantization \num or maybe there was an earlier one \nwhich was doing hierarchical k-means \nwhich is also quite natural so it means \nif you have a if you want to have a \nmillion uh a million uh Sun trades you \nyou start by by doing a k means in 1000 \nand then within each of those clusters \nyou do again one thousand and um \nso both so remember that that the \nk-means is in some respects it is the \noptimal \nwell if K means found the global Optimum \nwhich is not true but which is a good \napproximation k-means gets you the best \nset of centroids that you can find but \nuh given that you you need to find a \ntrade-off between speed and accuracy \nthose two methods doing hierarchical \nquantization or hierarchical or k-means \nand doing the doing the the the the \nwhat's what's what they call the \ninverted multi-index which means finding \nthe finding the two sub vectors and \nhandling those separately it was \num it was it was also a good option that \nthat states the best so the best course \nquantizer I think for large scale \napplications until uh until uh around \n2017 or 2018. and uh and uh when people \nrealized that you could as course \nquantizer you could use to use graph \nbased methods to to do similarity search \nso I know that you already had a whole \npodcast about graph based methods and uh \nso maybe I can say a little bit how this \nincludes in this uh in this story about \nuh about inverted files and product \nquantization so basically graph based \nmethods are are very very fast and \naccurate they are not very scalable \nbecause there's a very big overhead to \nstart the graphs themselves but yeah so \nthe graph based methods they um so they \nare very they're very fast and accurate \nbut they have a scalability issue \nbecause starring the starring the the \ngraph structure itself becomes skills uh \nliterally with the size of the data set \nand uh and it becomes a dominant cost \nat when the data sets when the data set \nbecomes larger it becomes a problematic \nbasically I mean it's it's always the \nsame problem in operations research once \nuh when a problem doesn't is is not a \nlimit you ignore it but once uh one is \nit becomes one is becomes a limiting \nfactor you you start worrying about it \nand uh so basically yeah so uh the uh so \nin particular hnsw which is really a \nvery impressive algorithm uh it's it \nscales at the size of \nuh of a million maybe 10 million but \nbeyond it's it's very low slow to build \nand uh and and it takes just a huge \namount of memory and so um so so hnsw is \nactually but this makes it the perfect \ncandidate for for uh course quantization \nand uh I think that um uh so \num uh the same babenko and Yuri they \nmade they made a paper about using it as \na cross quantizer and it's it is very \ngood and that's uh that's how the the \ngraph based methods can be included into \num into the ivfpq system \nso that's what so that's about the cross \nquantization uh and basically what \nhappens is that \num \nevery Improvement that we have on this \ntask of news neighbor search it can be \napplied to cross quantizers and so \nthat's and quite it's quite easy to uh \nto inject those improvements into into \nthe into the ivfpq framework so that's \nabout the cost quantizer then we have \nthe the the product quantizer \nso there were \num there were several improvements over \nthe over the \num uh of the the core product quantizer \nthe first \num maybe the well maybe the first one is \nis to just do re-ranking so basically \nusing a product quantizer as a first \napproximation that gives you the top so \nsay that you need the top 10 results \nthen you find the nearest neighbors with \nuh with with ivfpq and you take the top \n100 and then you you compute exact \ndistances or distances with a better \napproximation for the top 100 and keep \nonly the top 10. and this is this is \nreally a very effective method it's it's \nit's really what enables you to get a \ngood recall at one so really get the the \ngood results at the very first uh for as \nthe very first search result \num without impacting too much the the \nsearch time the problem is that you need \nto some auxiliary storage which might be \nRam but uh it could be disk also or SSD \nto start the the high quality \napproximate mention of the vectors or \nthe full vectors \nso that's the that's the first thing \nthen there were some \nuh there were some attempts to improve \nthe to improve the the quality of the \nproduct quantizer and the first problem \nof the product quantizer is that it's \narbitrarily uh chunks the vector into \ninto subsections and um if you if if it \nso happens that in your data set all of \nthe variants of the data set is only in \nthe last 10 components of your thousand \ndimensional vectors then you are \nallocating a lot of bits or a lot of uh \nencoding capacity to the first parts of \nthe vector and those are completely lost \nand uh so \num there's one very simple and the \nunfruitful method that was applied on \nprivate quantizer which is called optim \noptimized product quantization which was \na an early weight work by Kevin hay when \nthe and became the or the very \nsuccessful \narchitecture or CNN architecture \ndeveloper that we that we know and it \nworks of meta now and that that method \nconsisted in applying or finding and \napplying a random not random but a \nrotation to the input vectors \nso that the the energy in each subvector \nwas balanced the objective was to find \nthis this rotation so that the the the \nthe the energy was spread equally across \nthe sub vectors and um and since it's a \nrotation a rotation doesn't change the \nthe euclidean distance so it's you don't \nsee it on the euclidean distance and \nthis is really useful for many uh many \ndistributions that wouldn't naturally be \nwell balanced \nuh so then then there was uh maybe worth \nmentioning the lopq method which is a \nlocally optimized PQ method uh and this \none consists uh but this is specific to \nuh or it it applies on an igfpq index \nand basically the problem with IVF PQ \nindex is that \num each each \num \neach uh \nin each event inverted lists you use the \nsame PQ the same trained product \nquantizer \nto to encode what's in those inverted \nlists and this it's a bit it's a bit \nunnatural because in fact since the role \nof those uh inverted lists is is to make \ncells so it makes cells in the embedding \nspace and so you could say that points \nwhere you already know that they fall \ninto one of those cells they're probably \nthey don't probably don't have the same \ndata distribution of as if they fall in \nanother cell and so what lopq does is \nthat it trains as a product quantizer \nseparately for each of the cells \nso the but then there's a trade-off \nbecause it's expensive to train because \nyou need to to store all this \ninformation separately for each of the \ncells but it brings a a fair a fair \nImprovement of the of the recalls \num uh on on most data sets \num \nokay so \num yeah so maybe so I'm going to \ncontinue a bit with the history because \nhere we are about at uh 2015 so 2015 \num Harvey and I joined Facebook so \nFacebook is the old name of meta maybe \nyou'll remember \nand um uh and we joined Facebook that \nwas opening an office in in Paris and uh \nso uh we basically moved to Paris and uh \nand basically it was pretty clear since \nthe beginning uh that we needed to do \nsomething about uh nearest neighbor \nsearch in Facebook uh for production \nsystems because uh the the systems were \nvery far from state of the Arts and um \nand so uh this needed to be improved and \nuh so and so when so have they arrived I \nthink six or seven months before I \narrived and here I had already started \nwith this face project and uh which \nmeans uh Facebook AI similarity search \nand um so uh so then we um so so we \narrived there and um and so we we we we \nstarted you uh creating this uh piece of \nsoftware called face uh Facebook AI \nsimilarity search \n[Music] \num \nbasically \num uh we since since the start we said \nwe wanted to be open source and uh uh \nand I did so uh the head of um of \nFacebook uh AI was um Facebook AI \nresearch was Janika and he was very \nsupportive of that of that and so uh and \nso we started working on on face \nand uh so we uh uh and basically our I \nmean I arrived after and how they had \nstarted implementing it in C because you \nknow \num because C plus plus is uh is too \ncomplicated so uh so but the people in \nproduction they were telling us uh okay \nuh I mean it's already complicated we \ndon't want to have this and see you so \nso I rewatched it in C plus plus and I I \ntook over uh the as as the lead \ndeveloper of face pretty quickly at the \ntime there was um \nuh there was a \num everybody was using Lua as the \nscripting language and so there was a \nscripting language Bridge uh with uh \nface \nthat remained internal until uh 2017 I \nthink \num so so yeah I mean I my personal taste \nis that Lua is really crappy language \nit's and so I was pretty happy when uh \nso I I did python into face for face \nquite quickly and using Swig and um and \nI kind of and in the end we when \neverybody switched over from Lua to \npython when pytorch was created we kind \nof forgot about the Lua the Lua \ninterface which is a good riddance and \num \nuh and so and one important uh aspect of \nthis is that there was an engineer at uh \nat Fair Jeff Johnson he's one of the \noldest members of um of fair in terms of \nuh you know number of years at Facebook \nand uh and he got this Library caught \nhis interest and he decided to do a GPU \nversion of it so GPU meaning Nvidia GPU \nbecause I mean that's kind of the \nstandards uh at Facebook \nand he started developing this and um \nI think it was a it was a pretty \ninteresting project for him because uh \nbecause there were several aspects or \nthe algorithms were not not out of Out \nOf Reach in terms of optimization on \ngpus which sometimes sometimes happens \nif there's really two irregular Behavior \nor graph algorithms are very hard to \noptimize in gpus but this problem of \noptimizing ivfpq is was actually pretty \num pretty uh pretty reachable for uh for \nfor gpus and it so he made a very \nefficient GPU method and actually it \nturns out that we decided to publish a \npaper about face and the it was clear \nthat the flag \nthe flagship property that we want to \nshowcase for face was the the GPU the \nGPU implementation \num and so so yeah that that was in 2016 \nuh then 2017 started we started to \nnegotiate when we would actually be \nallowed so there were two aspects to \nthis the first one was internal adoption \nso there was a lot of work that that \nJaved was very much involved in in \nexplaining to uh to prod people at \nFacebook how interesting it was to have \nto have this to use this library to use \na conversation based methods to do \nsimilarity search \nand uh on the uh on the other hand there \nwas uh there was the external impact so \nthat means how are we going to open \nsource it and actually it took us quite \na lot of time to convince \num to convince our management uh well \nfirst to uh to open source that but not \nso much of a problem but the real \nproblem was to get it to open source it \nwith uh with the MIT license \nand basically so \nthis is something well open sourcing was \nreally something I discovered when I \narrived at uh at Facebook it's uh it is \nactually it is very hard for companies \nto for other companies to adopt open \nsource software that that doesn't have a \nvery permissive license because you know \nfor example the GPL is not possible \nbecause it's it's it's it contaminates \nand so and so we when we initially open \nsourced the the library in with the the \nCreative Commons and non-commercial \napplications the companies we talked \nwith told us we cannot use it and so \nwhich makes sense and so we can we went \nback to our management saying we want to \nhave we want this library to have real \nimpacts and so if we want that we need \nto open source it in uh with a \npermissive license and so \nthis took a long time to negotiate but \nin the end we were allowed to open \nsource it that way \nand uh and so uh basically I think that \num \nour point was that the similarity search \nspace was not mature yet so that at the \ntime in 20 around 2017 it was like \npeople were using uh flan they were \nusing uh annoy and they were using this \nkind of libraries which in our \num in our opinion where \nI mean not state-of-the-art compared to \nwhat what you already had in research \nfor several years and so uh having a \nstrong solid open source Library which \nwith more or less industrial support and \nuh that could could have a larger impact \nand so um so then we uh we we were \nallowed to open source it with the so we \ngot the the the proper license that we \nwanted and \num and basically \nthen then that I mean that ball was \nrolling and um \nso after that the the history of face \nwas \num several stages of additions of \nseveral methods so uh the first one \nbeing hnsw so it became uh when the when \nthat work uh came out it became pretty \nclear that it covered a kind of a space \nof operating points where we were really \nfar from the state of the art so uh so \nwe implemented or implemented hnsw into \nface \num then there was and um \nso uh there was a \nH so there was this method so the so \nthis is interesting \none one uh one uh so when you look at \nhow uh IVF PQ Works uh so you have the \nproblems of the Cross quantization and \nthe second part is how to optimize the \nscanning of the inverted lists which is \nthe second part of the cost and the \nsecond part of the costume basically \nit's the cost is dominated by uh by the \nmemory lookups into the lookup tables so \nyou have lookup tables you do lookups \nand the problem is that that modern \nprocesses are not at all efficient for \nlookups they are efficient for \narithmetic throughput but not for \nlookups and so um so what we did so it's \nnot what we did but uh there has been a \nline of research around storing those \nlookups in simd registers and um and so \nthere's early work by uh by people from \nTechnicolor um I'm thinking of a guy \nnamed Andre a and um they basically \nexplored this this direction and uh but \nthe the industrial application of this \nwas the the scan uh algorithm or the \nscan Library uh which was recently open \nsourced by Google and basically they \nhave a very very cleverly optimized \num \nivfpq implementation where the whether \nthe lookups or the lookup tables are \nstarted matches this and well the whole \nprocess of uh of computing distances is \nvery well optimized and uh so they they \nhad very good operating points and so uh \nand so we also imparted this into uh \ninto uh into phase \nso that's uh that's a bit uh of what we \ndid and I think in terms of so let to \ncome back to uh to uh to the \nquantization which is uh one of the the \nmain topics uh uh of of face and also of \nuh of what we were discussing uh so the \nquantization currently what we're \nlooking into is uh so we have the \nproduct quantization but \num uh actually it's there there are \nquantization methods that get better \naccuracy uh because uh product \nquantization has this restriction that \neach sub Vector is encoded separately \nand so uh so we lose the kind of uh \nstatistical dependence between the sub \nvectors even if we do an a rotation so \nthat this dependence is minimized \num and so what we are looking very much \ninto here currently is additive \nquantization methods \nand the additive quantization means that \ninstead of having sub vectors and you \nconcatenate sub vectors you have \nyou have a lookup tables that span the \nwhole Vector to encode and but you have \nseveral of the those lookup tables and \nyou pick one vector from each of the \nlookup tables and you just sum them up \nso and then you you have to encode only \nthe the ID of the vector that you picked \nin each of the lookup tables \nso it can be seen as a generalization of \nPQ because if the lookup tables are zero \noutside of a sub Vector if each lookup \ntable is zero outside of sub Vector then \nit boils down to doing PQ \num it's a generalization so it has the \npotential to be more accurate and the \nproblem is uh what it it's much more \ncomplex to train the lookout tables and \nto do the encoding the encoding is uh \nit's not like just finding the nearest \nneighbors it's um it's a it's a \ncombinatorial optimization problem uh \nthat that is NP hired if you if you want \nto solve it exactly and so you solve it \nonly by approximations \nand so \nuh and so basically we are looking into \nhow to do those uh approximations \nefficiently there are several uh several \ndirections for this and two of them are \nimplemented in Phase the first one is uh \nlocal search quantization which is uh \num which is a work via from the PHD of \nJulieta Martinez and uh that uh that \noffers a good trade-off between uh \nbetween the accuracy and encoding speed \nuh knowing that uh that encoding speed \ncannot be as good as that of PQ but it's \nstill it's based on the simulated \nannealing uh from with random \nindustrialization and it kind of \nconverges into \num into a relatively good additive \nadditive conversation method \nand the second one is just residual \nquantizers so that residual quantizes \nmeans you use the you use the first \nlevel quantizer and then you keep the \nresidual with respect to the vector that \nyou want to encode and that gets you a \nsecond level quantizer and then you \nencode it with a second level quantizer \netc etc \num and but if you do that in a greedy \nfashion it's not good and so in order to \navoid to do this in a greedy fashion \nyou'd use beam search and so which is \nexpensive so again there's a trade-off \nin terms of of speed versus accuracy \nyeah so that's um that's a bit what we \nwhat we are currently working on uh in \nPhase uh So currently \num just to say So within uh within uh \nmeta the the team the core team that \nworks around face is uh is about five \npeople uh not everyone is working \nfull-time on this \num but it's that's that's about the the \nskill of the efforts at Facebook it's \nsuper cool yeah that was a brilliant \ntour of product quantization so much \nknowledge um I'm also really excited in \nthis VBA podcast to welcome Abdel \nRodriguez to the webia podcast uh Abdel \nis working on this kind of product \nquantization weavier uh Abdul could you \ntell us about kind of where we're at \nwith the product quantization and any \nquestions you have for Matisse \nso thanks Connor and thanks uh \nMatthias for for the nice history and \nintroduction so I I actually we are a \nvery \nin the very beginning of the product \nquantization part now because we we have \nbeen \ntrying to improve the indexing algorithm \nand and trying to make it scalable on \nwhen when we have more data \nwell we have we will have more \nrequirements and and we we have to deal \nwith it and we are currently \nexperimenting with having some \ninformation on disk some information on \nmemory and and the part that we need in \nmemory of course is \nsome representation of the vectors \nand uh we are currently playing a bit \nwith the with the \na compression of these vectors and \nand again we are we are scratching the \nsurface here now we we have a very \nuh \nvery simple implementation of uh of PQ \ncurrently with k-means and and \nsegmenting the the vectors \nand we would like to explore a bit the \noptimized product quantization the \noptimized PQ next \nand one thing we we have is one problem \nwe have is that normally we don't build \nuh so we we don't have all the \ninformation and we build an index in but \nbut we we we normally build \nincrementally our our indexing which \nmeans we need some some algorithms that \ncould take over this uh capacity to to \nadd new vectors or delete vectors that \nyou have instead of just building \neverything together and of course \nk-means \ncould somehow be incrementally updated \nif you keep at least the number of \nclusters which is uh something that we \nhave but I'm also wondering about in the \ncase of up the optim opq this rotation \nMatrix how how how hard in terms of \nperformance would it be to to make it \nalso incrementally updatable things like \nthat I I don't know if you have some \nexperience in this direction that it \nwould be nice to to hear a bit about it \nsure uh so \nI think it's a it's a it's an \ninteresting and recurrent problem \num \nuh what happens is that uh so I think \nthat there are two things to distinguish \nhere it's which is an increasing \ndatabase database side size uh because I \nmean indeed you add incrementally you \nadd more vectors uh the the other can \nthe other thing is um is the drift in \nthe data distribution addressed in the \ndata distribution is in addition to \nadding vectors they have they have \nbehaviors that you've never seen before \nand during the training phase \num I think the increasing database size \nsize is not necessarily a problem if you \nif you've had enough data to train from \nthen uh \nto be to be very concrete a way I would \nImplement a database where you don't \nknow in the beginning how big it's going \nto grow it's uh you accept the first 10 \n000 vectors you don't encode them at all \nyou just keep them as is if you then you \nwhen you go to a million you you do some \nsome cheap or some simple indexing say \nwith hnsw \nand then when it grows beyond that you \nand you start to \nto require some type of encoding then \nyou can start thinking of uh training a \nproduct quantizer or some some other \ntype of quantizer but at that point you \nhave enough training vectors to actually \nactually train it so so it makes sense \nto to go to the to go that path \num \nuh which you I mean if you after if you \nhave 10 000 vectors you can't \nuh 10 000 vectors use no I it's it's a \nbit too small to to even train your \nproduct quantizer so you would even want \nto have more \num the other problem is uh is uh \ndrifting the data distribution which uh \nwhich we observe also with some kind of \napplications uh one one funny anecdotes \nmaybe is that we um uh we we have we \nhave an indexing we observe really a lot \nof data drift in in images that come in \nthat comes with that are uploaded to \nFacebook so I've worked together with \npeople who index those images and you \nhave data drifts with memes but also \nwhen there's a new Instagram filter that \ncomes out that kind of you see a drift \nin the in the type of images that you \nget and uh and so \nso it's a and and the problem with that \nis if you if you update the training \nyeah the main problem with any quantizer \nis that if you if you update the \ntraining then uh or if you do for \nexample online K means to adapt to some \ntrades of the k-means then the the the \nthe vectors that are newly encoded they \nare not comparable anymore with the the \nones that were encoded before and so um \nand so it's it's not clear to me by \ndefault how uh how to how to use those \nupdated centroids \nso um yeah it's a \nsomething to think of yeah so when you \nhave the online clustering you can move \nthe mean but then you need to recompute \nthe centralizers at like very basic \nunderstanding the high level idea yeah \nit also depends I guess if you have more \nintensive \nchanges in some parts you don't have to \nrecode everything but that part's \naffected I would guess but \nmm-hmm \nso maybe we'll also transition to the \ntopic of generally the \nwrapping the vector index around a \nlibrary compared to a database so maybe \nedian could um explain kind of the some \nof the features of the database and the \ndistinction between how you're packaging \nup the vector index \nso yeah sure this I think we've we've \ndiscussed this uh before already in in \none of the podcasts but it is a \nrecurring topic and we do see that that \ncoming up from from users \num whereas I think one of the the first \nand most obvious distinct differences \nthat we see and end of charismatize I'm \nalso super interested about your \nperspective on this as someone who's \nbeen working on the library because \nmine's a bit biased of course because \nI've been working on the database side \nuh what one that that comes up very high \non the list typically is this this \nincremental updateability which I think \nis not like this can be a library versus \ndatabase part but it doesn't necessarily \nhave to be because hnsw you can use it \npurely from a library perspective and it \nis incrementally changeable uh something \nthat needs to be trained beforehand so \nfor example a quantizer that is maybe \nnot as updatable so in in this case \num the library versus database technical \ndistinction doesn't so much \num \nsort of determine of whether it's \nupdatable or not more that within the \ndatabase you tend to go for these kind \nof updatable cases so for us \num from a database perspective typically \nwhat we say the kind of ux that we want \nis the one that people know from \nnon-machine learning databases so if I \njust spin up in my SQL database spin up \nbecause Android database typically I \nshould start using it and I don't \nnecessarily know what I'm going to do \nwith it tomorrow I might update \nsomething I might delete something I \nmight read in between I might do that \nall concurrently \num and then of course you have to do \ncapacity planning there as well in some \ndatabases scale more dynamically than \nothers but this is a big part sort of \nthis this usage journey of using it \num yeah directly basically uh um or \nwe're using it like a like a database \nbut there's there's uh way more so so \none of the things for example that's \nalso super important to me is the kind \nof durability aspect failure recovery \nmode so so how does it react so so for \nexample something I think an in \nplacement has correct me if I'm I'm \nwrong I think \num what I typically see in libraries for \npersistence is snapshotting that you \nwould build something and once it's \nbuilt you would snapshot it to disk and \nthen you could load the the snapshot \num whereas in in a database such as VBA \nfor example \num the the update process itself is \nalready persistent so if vv8 crashes I \ndon't know let's say you import 10 \nmillion and bb8 crashes at number 7 \nmillion then you can just restart it and \nimport 7 million and one so so this kind \nof incremental durability crash recovery \num everything that's written is written \ninto a writer headlock is is a big thing \nand then um and maybe that's also an \ninteresting one uh with Facebook because \nI think there's a a separate library \nthat I believe is not not exactly face \nbut but built on top of face that \ndistributes a face across multiple \nmachines and that is also something \nthat's very big in the in the \num in yeah for vv8 or for databases in \ngeneral so \num yeah the whole scaling aspect is \nsomething that you get out of the box \nfor free as well that's that's my short \nmy short overview of the the differences \nbut I'm very curious to hear yours as \nwell in the type yeah sure uh so \num I think that's face explicitly tries \nnot not to go into the field of being a \ngeneral purpose uh Library so there are \ntwo reasons of that the first one is \nthat I think that face is already a very \ncomplex piece of software uh if you if \nyou were to have to support that it \nwould mean that the number of code lines \nwould be multiplied by a factor three or \nsomething which is not something we we \nplan to plan to do the second thing also \nis that in general I observed that SQL \ndatabases are I don't know about vv8 but \nvery often databases have \nan order of magnitude storage more than \nwhat's strictly required by the amount \nof data that you have in this for \nexample I've read somewhere guidelines \nthat if you want to set up a mySQL \ndatabase then you should plan for uh \nfive times as many disk space as what uh \nthe the raw data I would use and this is \nsomething that's face \nwe want to give the opportunity for \npeople to you know use 90 of their RAM \nand store the an index in that and that \nthey don't wonder where uh about too \nmuch about overheads basically and so uh \nand this is \nuh yeah it would it's it happened \nseveral times that we're operating very \nclose to uh what's possible on a single \nmachine and uh for this uh we we give up \nmany functionalities like what you say \nuh being able to do uh ID lookups uh \nbeing able to \nbe being able to snapshots or this kind \nof things and it's \nyou know that's that's the point but \ndefinitely I wouldn't recommend face as \na final production ready database system \nit's it's really intended to be at the \ncore of maybe another \nmore broad scale database system \nfantastic well thank you so much from \ntires Abdel Eddie and such an \ninformation dense podcast so interesting \nlearning about all these things thank \nyou so much for your time \nyeah thank you thank you nice yeah yeah \nthank you all yeah I \n", "type": "Video", "name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "path": "", "link": "https://www.youtube.com/watch?v=5o1YTp1IL5o", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": [{"text": "hey everyone thank you so much for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 0, "tokens": 0, "vector": null, "score": 0}, {"text": "checking out another episode of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1, "tokens": 0, "vector": null, "score": 0}, {"text": "wevia podcast this is a super exciting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 2, "tokens": 0, "vector": null, "score": 0}, {"text": "episode of BBA podcast we have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 3, "tokens": 0, "vector": null, "score": 0}, {"text": "research scientist for meta AI Matisse", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 4, "tokens": 0, "vector": null, "score": 0}, {"text": "duzy uh his research publication list is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 5, "tokens": 0, "vector": null, "score": 0}, {"text": "just amazing the amount of work he's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 6, "tokens": 0, "vector": null, "score": 0}, {"text": "done in the space of vector analysis", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 7, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantization all sorts of things", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 8, "tokens": 0, "vector": null, "score": 0}, {"text": "of deep learning really is really truly", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 9, "tokens": 0, "vector": null, "score": 0}, {"text": "one of the most impressive scientists", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 10, "tokens": 0, "vector": null, "score": 0}, {"text": "I've had the opportunity to talk to so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 11, "tokens": 0, "vector": null, "score": 0}, {"text": "Matisse thank you so much for joining", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 12, "tokens": 0, "vector": null, "score": 0}, {"text": "the podcast", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 13, "tokens": 0, "vector": null, "score": 0}, {"text": "yeah thank you very much for hosting me", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 14, "tokens": 0, "vector": null, "score": 0}, {"text": "awesome so can we kick this off by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 15, "tokens": 0, "vector": null, "score": 0}, {"text": "telling us about the history of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 16, "tokens": 0, "vector": null, "score": 0}, {"text": "research uh like how did you come to be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 17, "tokens": 0, "vector": null, "score": 0}, {"text": "working on these things what first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 18, "tokens": 0, "vector": null, "score": 0}, {"text": "inspired your interests", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 19, "tokens": 0, "vector": null, "score": 0}, {"text": "yeah so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 20, "tokens": 0, "vector": null, "score": 0}, {"text": "um yeah I can say a little bit about my", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 21, "tokens": 0, "vector": null, "score": 0}, {"text": "background so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 22, "tokens": 0, "vector": null, "score": 0}, {"text": "um I have a PhD in computer vision", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 23, "tokens": 0, "vector": null, "score": 0}, {"text": "basically so that's my background uh I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 24, "tokens": 0, "vector": null, "score": 0}, {"text": "did it in in France and uh then I moved", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 25, "tokens": 0, "vector": null, "score": 0}, {"text": "to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 26, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 27, "tokens": 0, "vector": null, "score": 0}, {"text": "to a research uh institution the which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 28, "tokens": 0, "vector": null, "score": 0}, {"text": "is inria and where I met harveyjigu who", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 29, "tokens": 0, "vector": null, "score": 0}, {"text": "he has an expertise more in anything", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 30, "tokens": 0, "vector": null, "score": 0}, {"text": "related to coding encoding decoding the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 31, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of things that's used for GSM", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 32, "tokens": 0, "vector": null, "score": 0}, {"text": "networks and uh and so he was the main", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 33, "tokens": 0, "vector": null, "score": 0}, {"text": "inspiration to move towards thinking", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 34, "tokens": 0, "vector": null, "score": 0}, {"text": "about how to better compress uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 35, "tokens": 0, "vector": null, "score": 0}, {"text": "compressed compressed vectors because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 36, "tokens": 0, "vector": null, "score": 0}, {"text": "basically there's one very clear", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 37, "tokens": 0, "vector": null, "score": 0}, {"text": "application for this in computer vision", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 38, "tokens": 0, "vector": null, "score": 0}, {"text": "at the time that was very important", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 39, "tokens": 0, "vector": null, "score": 0}, {"text": "which is that images were analyzed by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 40, "tokens": 0, "vector": null, "score": 0}, {"text": "extracting sift features from them and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 41, "tokens": 0, "vector": null, "score": 0}, {"text": "sift features I just", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 42, "tokens": 0, "vector": null, "score": 0}, {"text": "um 128 dimensional vectors that are a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 43, "tokens": 0, "vector": null, "score": 0}, {"text": "new extract", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 44, "tokens": 0, "vector": null, "score": 0}, {"text": "in the order of hundreds to a thousands", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 45, "tokens": 0, "vector": null, "score": 0}, {"text": "per image and those those were early", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 46, "tokens": 0, "vector": null, "score": 0}, {"text": "embeddings so that means that it's a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 47, "tokens": 0, "vector": null, "score": 0}, {"text": "representation of a small part of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 48, "tokens": 0, "vector": null, "score": 0}, {"text": "image and then you could do a couple of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 49, "tokens": 0, "vector": null, "score": 0}, {"text": "things with those you could use them for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 50, "tokens": 0, "vector": null, "score": 0}, {"text": "image classification but the the part", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 51, "tokens": 0, "vector": null, "score": 0}, {"text": "that we're most interested in was image", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 52, "tokens": 0, "vector": null, "score": 0}, {"text": "indexing which means uh which meant at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 53, "tokens": 0, "vector": null, "score": 0}, {"text": "the time and still means now finding", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 54, "tokens": 0, "vector": null, "score": 0}, {"text": "similar images for example images that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 55, "tokens": 0, "vector": null, "score": 0}, {"text": "represent the same object or the same", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 56, "tokens": 0, "vector": null, "score": 0}, {"text": "building", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 57, "tokens": 0, "vector": null, "score": 0}, {"text": "and to do that you had to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 58, "tokens": 0, "vector": null, "score": 0}, {"text": "um you had to find which where the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 59, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest embeddings the nearest sift", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 60, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors from the ones that are in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 61, "tokens": 0, "vector": null, "score": 0}, {"text": "other image", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 62, "tokens": 0, "vector": null, "score": 0}, {"text": "and so there was this um at the time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 63, "tokens": 0, "vector": null, "score": 0}, {"text": "there was this very interesting work", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 64, "tokens": 0, "vector": null, "score": 0}, {"text": "um that came from uh from the Andrew", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 65, "tokens": 0, "vector": null, "score": 0}, {"text": "zisman's lab and uh uh and which which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 66, "tokens": 0, "vector": null, "score": 0}, {"text": "was basically led by Joseph Savage and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 67, "tokens": 0, "vector": null, "score": 0}, {"text": "uh which basically uh reduced this Bunch", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 68, "tokens": 0, "vector": null, "score": 0}, {"text": "this big number of CIS vectors so you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 69, "tokens": 0, "vector": null, "score": 0}, {"text": "had like like a thousand sift vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 70, "tokens": 0, "vector": null, "score": 0}, {"text": "for one image which was pretty heavy and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 71, "tokens": 0, "vector": null, "score": 0}, {"text": "to reduce that into a bag of words and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 72, "tokens": 0, "vector": null, "score": 0}, {"text": "back of words just means that you reduce", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 73, "tokens": 0, "vector": null, "score": 0}, {"text": "each Vector into a single identifier a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 74, "tokens": 0, "vector": null, "score": 0}, {"text": "single a single number that was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 75, "tokens": 0, "vector": null, "score": 0}, {"text": "um assigned by nearest neighbor uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 76, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest neighbor search so searching the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 77, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest centrates to each of the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 78, "tokens": 0, "vector": null, "score": 0}, {"text": "and just keeping that only information", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 79, "tokens": 0, "vector": null, "score": 0}, {"text": "about that vector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 80, "tokens": 0, "vector": null, "score": 0}, {"text": "and so that means that if you had", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 81, "tokens": 0, "vector": null, "score": 0}, {"text": "if you had a like say 1000 centroids you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 82, "tokens": 0, "vector": null, "score": 0}, {"text": "would have the only information that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 83, "tokens": 0, "vector": null, "score": 0}, {"text": "keep from all those heavy sift vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 84, "tokens": 0, "vector": null, "score": 0}, {"text": "in the on the image is a kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 85, "tokens": 0, "vector": null, "score": 0}, {"text": "histogram over the Thousand centuries", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 86, "tokens": 0, "vector": null, "score": 0}, {"text": "about how many sips vectors were falling", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 87, "tokens": 0, "vector": null, "score": 0}, {"text": "into those sift actions", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 88, "tokens": 0, "vector": null, "score": 0}, {"text": "so and it was called", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 89, "tokens": 0, "vector": null, "score": 0}, {"text": "um a bag of bag of visual words because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 90, "tokens": 0, "vector": null, "score": 0}, {"text": "in a sense by analogy with text you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 91, "tokens": 0, "vector": null, "score": 0}, {"text": "would reduce the the the you know the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 92, "tokens": 0, "vector": null, "score": 0}, {"text": "continuous space of the the set vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 93, "tokens": 0, "vector": null, "score": 0}, {"text": "into a single a single token a single a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 94, "tokens": 0, "vector": null, "score": 0}, {"text": "single word uh and that represented the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 95, "tokens": 0, "vector": null, "score": 0}, {"text": "image and then the images could be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 96, "tokens": 0, "vector": null, "score": 0}, {"text": "compared and the basically what's what", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 97, "tokens": 0, "vector": null, "score": 0}, {"text": "happened there is that this represents", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 98, "tokens": 0, "vector": null, "score": 0}, {"text": "this back of word representation that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 99, "tokens": 0, "vector": null, "score": 0}, {"text": "was used for many many applications", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 100, "tokens": 0, "vector": null, "score": 0}, {"text": "including classification but what it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 101, "tokens": 0, "vector": null, "score": 0}, {"text": "also enabled was uh to be able to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 102, "tokens": 0, "vector": null, "score": 0}, {"text": "um to do large-scale indexing so that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 103, "tokens": 0, "vector": null, "score": 0}, {"text": "means since it's so compact you could", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 104, "tokens": 0, "vector": null, "score": 0}, {"text": "say okay I have uh I have uh ten", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 105, "tokens": 0, "vector": null, "score": 0}, {"text": "thousand a hundred thousands a million I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 106, "tokens": 0, "vector": null, "score": 0}, {"text": "think before us the the largest", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 107, "tokens": 0, "vector": null, "score": 0}, {"text": "application that was at scale 1 million", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 108, "tokens": 0, "vector": null, "score": 0}, {"text": "uh one million uh images and you could", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 109, "tokens": 0, "vector": null, "score": 0}, {"text": "index those and that was that was quite", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 110, "tokens": 0, "vector": null, "score": 0}, {"text": "novel at the time that it was possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 111, "tokens": 0, "vector": null, "score": 0}, {"text": "to really find in in real time so there", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 112, "tokens": 0, "vector": null, "score": 0}, {"text": "was a work", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 113, "tokens": 0, "vector": null, "score": 0}, {"text": "um that was coming from uh Nissa and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 114, "tokens": 0, "vector": null, "score": 0}, {"text": "stevenius where they basically had a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 115, "tokens": 0, "vector": null, "score": 0}, {"text": "collection of CD covers and they were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 116, "tokens": 0, "vector": null, "score": 0}, {"text": "showing it to a webcam and the webcam", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 117, "tokens": 0, "vector": null, "score": 0}, {"text": "would find in real time uh what were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 118, "tokens": 0, "vector": null, "score": 0}, {"text": "those covers what those covers were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 119, "tokens": 0, "vector": null, "score": 0}, {"text": "corresponding to and this was really", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 120, "tokens": 0, "vector": null, "score": 0}, {"text": "enabled by this uh this bag of fart", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 121, "tokens": 0, "vector": null, "score": 0}, {"text": "representation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 122, "tokens": 0, "vector": null, "score": 0}, {"text": "so that was so the back and forth's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 123, "tokens": 0, "vector": null, "score": 0}, {"text": "representation was used to uh quite", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 124, "tokens": 0, "vector": null, "score": 0}, {"text": "extensively at the time and uh it has", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 125, "tokens": 0, "vector": null, "score": 0}, {"text": "been expanded and so on but uh what I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 126, "tokens": 0, "vector": null, "score": 0}, {"text": "what the the second or the The", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 127, "tokens": 0, "vector": null, "score": 0}, {"text": "Innovation that came from this work by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 128, "tokens": 0, "vector": null, "score": 0}, {"text": "uh by cevich and this woman was the fact", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 129, "tokens": 0, "vector": null, "score": 0}, {"text": "that they used an inverted index so that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 130, "tokens": 0, "vector": null, "score": 0}, {"text": "means uh it's inverted because you start", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 131, "tokens": 0, "vector": null, "score": 0}, {"text": "from uh from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 132, "tokens": 0, "vector": null, "score": 0}, {"text": "um from from those those histograms of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 133, "tokens": 0, "vector": null, "score": 0}, {"text": "of visual words and instead of stacking", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 134, "tokens": 0, "vector": null, "score": 0}, {"text": "those histograms or visual words you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 135, "tokens": 0, "vector": null, "score": 0}, {"text": "invert the index and you for each visual", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 136, "tokens": 0, "vector": null, "score": 0}, {"text": "word index you record which images", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 137, "tokens": 0, "vector": null, "score": 0}, {"text": "and contain that particle particular", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 138, "tokens": 0, "vector": null, "score": 0}, {"text": "visual word", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 139, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so that made it much faster", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 140, "tokens": 0, "vector": null, "score": 0}, {"text": "because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 141, "tokens": 0, "vector": null, "score": 0}, {"text": "what it enables is that if you increase", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 142, "tokens": 0, "vector": null, "score": 0}, {"text": "the number or the the size of the visual", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 143, "tokens": 0, "vector": null, "score": 0}, {"text": "vocabulary so instead of having a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 144, "tokens": 0, "vector": null, "score": 0}, {"text": "thousand you can say I have ten thousand", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 145, "tokens": 0, "vector": null, "score": 0}, {"text": "hundred thousands Etc", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 146, "tokens": 0, "vector": null, "score": 0}, {"text": "uh you can you you get a very sparse uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 147, "tokens": 0, "vector": null, "score": 0}, {"text": "sparse histograms obviously and that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 148, "tokens": 0, "vector": null, "score": 0}, {"text": "means that the inverted index when you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 149, "tokens": 0, "vector": null, "score": 0}, {"text": "actually want to find which visual words", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 150, "tokens": 0, "vector": null, "score": 0}, {"text": "are in common between the query image", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 151, "tokens": 0, "vector": null, "score": 0}, {"text": "and a database image you need to visit", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 152, "tokens": 0, "vector": null, "score": 0}, {"text": "fewer a very small fraction of that of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 153, "tokens": 0, "vector": null, "score": 0}, {"text": "that data set", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 154, "tokens": 0, "vector": null, "score": 0}, {"text": "so that was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 155, "tokens": 0, "vector": null, "score": 0}, {"text": "um so I think that that was a bit the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 156, "tokens": 0, "vector": null, "score": 0}, {"text": "background when we arrived so the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 157, "tokens": 0, "vector": null, "score": 0}, {"text": "key elements that we had there was uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 158, "tokens": 0, "vector": null, "score": 0}, {"text": "the the fact that we had", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 159, "tokens": 0, "vector": null, "score": 0}, {"text": "um we had this representation of uh High", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 160, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vectors with a single", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 161, "tokens": 0, "vector": null, "score": 0}, {"text": "integer which is exactly quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 162, "tokens": 0, "vector": null, "score": 0}, {"text": "and so that's where you know the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 163, "tokens": 0, "vector": null, "score": 0}, {"text": "expertise of harveya started to be very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 164, "tokens": 0, "vector": null, "score": 0}, {"text": "useful and we have this inverted file", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 165, "tokens": 0, "vector": null, "score": 0}, {"text": "structure that was the start of a lot of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 166, "tokens": 0, "vector": null, "score": 0}, {"text": "fruitful", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 167, "tokens": 0, "vector": null, "score": 0}, {"text": "um indexing methods that were developed", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 168, "tokens": 0, "vector": null, "score": 0}, {"text": "later including the ones that we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 169, "tokens": 0, "vector": null, "score": 0}, {"text": "developed", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 170, "tokens": 0, "vector": null, "score": 0}, {"text": "so then we arrived", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 171, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so we we recognized this uh the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 172, "tokens": 0, "vector": null, "score": 0}, {"text": "quality of this uh of this inverted list", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 173, "tokens": 0, "vector": null, "score": 0}, {"text": "and the potential the potential that it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 174, "tokens": 0, "vector": null, "score": 0}, {"text": "had to do large scale indexing and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 175, "tokens": 0, "vector": null, "score": 0}, {"text": "and so what we added to that the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 176, "tokens": 0, "vector": null, "score": 0}, {"text": "the first thing we added is actually uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 177, "tokens": 0, "vector": null, "score": 0}, {"text": "thinking that within those inverted", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 178, "tokens": 0, "vector": null, "score": 0}, {"text": "lists so the inverted lists are in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 179, "tokens": 0, "vector": null, "score": 0}, {"text": "in the in the initial", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 180, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh backup visual word representations", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 181, "tokens": 0, "vector": null, "score": 0}, {"text": "contained only the document IDs or the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 182, "tokens": 0, "vector": null, "score": 0}, {"text": "the image IDs that contain those", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 183, "tokens": 0, "vector": null, "score": 0}, {"text": "specific visual words and so the idea", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 184, "tokens": 0, "vector": null, "score": 0}, {"text": "that we came with was to add a kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 185, "tokens": 0, "vector": null, "score": 0}, {"text": "payload for each of those uh instances", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 186, "tokens": 0, "vector": null, "score": 0}, {"text": "where we kind of refine a little bit the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 187, "tokens": 0, "vector": null, "score": 0}, {"text": "representation of the of the the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 188, "tokens": 0, "vector": null, "score": 0}, {"text": "because uh because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 189, "tokens": 0, "vector": null, "score": 0}, {"text": "representing a 128 dimensional vector by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 190, "tokens": 0, "vector": null, "score": 0}, {"text": "a single integer is a very crude", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 191, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization and so what we did at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 192, "tokens": 0, "vector": null, "score": 0}, {"text": "time is that we we used a pretty", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 193, "tokens": 0, "vector": null, "score": 0}, {"text": "standard", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 194, "tokens": 0, "vector": null, "score": 0}, {"text": "system that existed at the time and it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 195, "tokens": 0, "vector": null, "score": 0}, {"text": "was uh it was to do a kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 196, "tokens": 0, "vector": null, "score": 0}, {"text": "binarization and that we we called", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 197, "tokens": 0, "vector": null, "score": 0}, {"text": "Hamming embedding and so having", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 198, "tokens": 0, "vector": null, "score": 0}, {"text": "embedding basically consists in taking", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 199, "tokens": 0, "vector": null, "score": 0}, {"text": "this 128 dimensional Vector applying a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 200, "tokens": 0, "vector": null, "score": 0}, {"text": "random rotation to it and then keeping", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 201, "tokens": 0, "vector": null, "score": 0}, {"text": "the sign of each of the components after", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 202, "tokens": 0, "vector": null, "score": 0}, {"text": "rotation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 203, "tokens": 0, "vector": null, "score": 0}, {"text": "and so then we get a binary Vector which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 204, "tokens": 0, "vector": null, "score": 0}, {"text": "at the time we didn't use the 428", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 205, "tokens": 0, "vector": null, "score": 0}, {"text": "Dimensions but we used just 64. and then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 206, "tokens": 0, "vector": null, "score": 0}, {"text": "we had a binary representation of 64", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 207, "tokens": 0, "vector": null, "score": 0}, {"text": "bits and we could do that both on the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 208, "tokens": 0, "vector": null, "score": 0}, {"text": "query side and on the database side and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 209, "tokens": 0, "vector": null, "score": 0}, {"text": "then comparing binary vectors it's very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 210, "tokens": 0, "vector": null, "score": 0}, {"text": "very efficient to to compute the to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 211, "tokens": 0, "vector": null, "score": 0}, {"text": "compare those with Hamming distances", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 212, "tokens": 0, "vector": null, "score": 0}, {"text": "and so then then we had", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 213, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 214, "tokens": 0, "vector": null, "score": 0}, {"text": "uh we had a image indexing system that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 215, "tokens": 0, "vector": null, "score": 0}, {"text": "was very efficient and that was based on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 216, "tokens": 0, "vector": null, "score": 0}, {"text": "uh on what currently we would call an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 217, "tokens": 0, "vector": null, "score": 0}, {"text": "IVF an inverted file and having a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 218, "tokens": 0, "vector": null, "score": 0}, {"text": "battery Banning so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 219, "tokens": 0, "vector": null, "score": 0}, {"text": "um a binary representation of the of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 220, "tokens": 0, "vector": null, "score": 0}, {"text": "the vectors that are stored with in that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 221, "tokens": 0, "vector": null, "score": 0}, {"text": "inverted file so that was the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 222, "tokens": 0, "vector": null, "score": 0}, {"text": "stage", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 223, "tokens": 0, "vector": null, "score": 0}, {"text": "and we got we it was very successful in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 224, "tokens": 0, "vector": null, "score": 0}, {"text": "terms of of large-scale image indexing I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 225, "tokens": 0, "vector": null, "score": 0}, {"text": "remember redoing the demo with the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 226, "tokens": 0, "vector": null, "score": 0}, {"text": "webcam with uh with a laptop and uh and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 227, "tokens": 0, "vector": null, "score": 0}, {"text": "a webcam and uh and I'd scale 10 million", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 228, "tokens": 0, "vector": null, "score": 0}, {"text": "images and an external hard drive", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 229, "tokens": 0, "vector": null, "score": 0}, {"text": "which uh so for the technical details", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 230, "tokens": 0, "vector": null, "score": 0}, {"text": "which which didn't have a partition at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 231, "tokens": 0, "vector": null, "score": 0}, {"text": "all on it and so there was no file", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 232, "tokens": 0, "vector": null, "score": 0}, {"text": "system because we need to access very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 233, "tokens": 0, "vector": null, "score": 0}, {"text": "quickly we need to access the images to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 234, "tokens": 0, "vector": null, "score": 0}, {"text": "display the results so we were accessing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 235, "tokens": 0, "vector": null, "score": 0}, {"text": "directly the offset on the disk uh of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 236, "tokens": 0, "vector": null, "score": 0}, {"text": "the the actual images", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 237, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh and this was this was working", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 238, "tokens": 0, "vector": null, "score": 0}, {"text": "pretty well and um and so that was the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 239, "tokens": 0, "vector": null, "score": 0}, {"text": "first iteration of uh of uh of uh of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 240, "tokens": 0, "vector": null, "score": 0}, {"text": "this combination of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 241, "tokens": 0, "vector": null, "score": 0}, {"text": "um of the the IDF which where the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 242, "tokens": 0, "vector": null, "score": 0}, {"text": "objective is really to to to very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 243, "tokens": 0, "vector": null, "score": 0}, {"text": "quickly prune the data set though the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 244, "tokens": 0, "vector": null, "score": 0}, {"text": "parts of the data set where you need to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 245, "tokens": 0, "vector": null, "score": 0}, {"text": "search and an encoding method uh whose", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 246, "tokens": 0, "vector": null, "score": 0}, {"text": "objective is to get an approximately", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 247, "tokens": 0, "vector": null, "score": 0}, {"text": "reasonable or as good as possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 248, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation of the of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 249, "tokens": 0, "vector": null, "score": 0}, {"text": "um of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 250, "tokens": 0, "vector": null, "score": 0}, {"text": "of the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 251, "tokens": 0, "vector": null, "score": 0}, {"text": "so it turns out that so at the time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 252, "tokens": 0, "vector": null, "score": 0}, {"text": "there was the the there was a lot of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 253, "tokens": 0, "vector": null, "score": 0}, {"text": "work around binary representations for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 254, "tokens": 0, "vector": null, "score": 0}, {"text": "for vectors so uh there was a whole", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 255, "tokens": 0, "vector": null, "score": 0}, {"text": "literature around localized locality", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 256, "tokens": 0, "vector": null, "score": 0}, {"text": "sensitive hashing which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 257, "tokens": 0, "vector": null, "score": 0}, {"text": "is not exactly uh the same as a binary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 258, "tokens": 0, "vector": null, "score": 0}, {"text": "representation but very often a binary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 259, "tokens": 0, "vector": null, "score": 0}, {"text": "representation is is based on the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 260, "tokens": 0, "vector": null, "score": 0}, {"text": "locality sensitive hashing Theory and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 261, "tokens": 0, "vector": null, "score": 0}, {"text": "and so that there were interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 262, "tokens": 0, "vector": null, "score": 0}, {"text": "theoretical properties", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 263, "tokens": 0, "vector": null, "score": 0}, {"text": "uh and uh so there was a spectral", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 264, "tokens": 0, "vector": null, "score": 0}, {"text": "hashing uh which was a work by taralba", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 265, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so there was a literature around", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 266, "tokens": 0, "vector": null, "score": 0}, {"text": "that and uh but what we so there the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 267, "tokens": 0, "vector": null, "score": 0}, {"text": "expertise of Harvey that he had uh for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 268, "tokens": 0, "vector": null, "score": 0}, {"text": "for anything related to quantization uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 269, "tokens": 0, "vector": null, "score": 0}, {"text": "came in very useful because he knew and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 270, "tokens": 0, "vector": null, "score": 0}, {"text": "it became clear afterwards that actually", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 271, "tokens": 0, "vector": null, "score": 0}, {"text": "uh binarization is a very crude way of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 272, "tokens": 0, "vector": null, "score": 0}, {"text": "of doing quantization so basically it is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 273, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization because you you transform a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 274, "tokens": 0, "vector": null, "score": 0}, {"text": "continuous signal into into an integer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 275, "tokens": 0, "vector": null, "score": 0}, {"text": "basically but there are much better ways", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 276, "tokens": 0, "vector": null, "score": 0}, {"text": "of uh of or much less lossy ways of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 277, "tokens": 0, "vector": null, "score": 0}, {"text": "encoding vectors than doing uh than", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 278, "tokens": 0, "vector": null, "score": 0}, {"text": "doing binarization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 279, "tokens": 0, "vector": null, "score": 0}, {"text": "so that maybe we can go a little bit", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 280, "tokens": 0, "vector": null, "score": 0}, {"text": "into the theory of um of quantization so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 281, "tokens": 0, "vector": null, "score": 0}, {"text": "uh the parts that I know if I'm I can't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 282, "tokens": 0, "vector": null, "score": 0}, {"text": "say I'm much of an expert but I got I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 283, "tokens": 0, "vector": null, "score": 0}, {"text": "get got some experience and some very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 284, "tokens": 0, "vector": null, "score": 0}, {"text": "basic principles", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 285, "tokens": 0, "vector": null, "score": 0}, {"text": "so the the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 286, "tokens": 0, "vector": null, "score": 0}, {"text": "um the first two principles are the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 287, "tokens": 0, "vector": null, "score": 0}, {"text": "Lloyd principles so uh for quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 288, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh basically since you since you map", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 289, "tokens": 0, "vector": null, "score": 0}, {"text": "a continuous signal to our continued", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 290, "tokens": 0, "vector": null, "score": 0}, {"text": "continuous Vector continuous High", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 291, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional Vector to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 292, "tokens": 0, "vector": null, "score": 0}, {"text": "um to uh to one single uh representation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 293, "tokens": 0, "vector": null, "score": 0}, {"text": "so it's to one single integer then and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 294, "tokens": 0, "vector": null, "score": 0}, {"text": "you always have a reconstruction of that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 295, "tokens": 0, "vector": null, "score": 0}, {"text": "of of the approximation of the of the of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 296, "tokens": 0, "vector": null, "score": 0}, {"text": "the vector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 297, "tokens": 0, "vector": null, "score": 0}, {"text": "and so uh so in order for this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 298, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation to be uh to be optimal", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 299, "tokens": 0, "vector": null, "score": 0}, {"text": "there are uh there are two necessary and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 300, "tokens": 0, "vector": null, "score": 0}, {"text": "not not sufficient but necessary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 301, "tokens": 0, "vector": null, "score": 0}, {"text": "conditions", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 302, "tokens": 0, "vector": null, "score": 0}, {"text": "and the first one is that each they are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 303, "tokens": 0, "vector": null, "score": 0}, {"text": "very natural the first one is that when", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 304, "tokens": 0, "vector": null, "score": 0}, {"text": "you have a vector and when you look at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 305, "tokens": 0, "vector": null, "score": 0}, {"text": "the whole set of possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 306, "tokens": 0, "vector": null, "score": 0}, {"text": "reconstructions that you can make with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 307, "tokens": 0, "vector": null, "score": 0}, {"text": "your quantizer so what that we call", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 308, "tokens": 0, "vector": null, "score": 0}, {"text": "centuries in general uh then uh the uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 309, "tokens": 0, "vector": null, "score": 0}, {"text": "the vector should be assigned to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 310, "tokens": 0, "vector": null, "score": 0}, {"text": "nearest centroid so it's if you pick one", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 311, "tokens": 0, "vector": null, "score": 0}, {"text": "a centroid that is not the nearest then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 312, "tokens": 0, "vector": null, "score": 0}, {"text": "by definition you are doing something", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 313, "tokens": 0, "vector": null, "score": 0}, {"text": "sub-optimal so you always should always", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 314, "tokens": 0, "vector": null, "score": 0}, {"text": "assign to the nearest vector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 315, "tokens": 0, "vector": null, "score": 0}, {"text": "and the second one uh so so this is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 316, "tokens": 0, "vector": null, "score": 0}, {"text": "quite natural the second one is specific", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 317, "tokens": 0, "vector": null, "score": 0}, {"text": "to the to the to the L2 distance to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 318, "tokens": 0, "vector": null, "score": 0}, {"text": "euclidean distance if you minimize the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 319, "tokens": 0, "vector": null, "score": 0}, {"text": "the if you minimize the the the squared", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 320, "tokens": 0, "vector": null, "score": 0}, {"text": "uh error of the Reconstruction uh then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 321, "tokens": 0, "vector": null, "score": 0}, {"text": "each centroid should be the center of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 322, "tokens": 0, "vector": null, "score": 0}, {"text": "mass of all the vectors that are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 323, "tokens": 0, "vector": null, "score": 0}, {"text": "assigned to it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 324, "tokens": 0, "vector": null, "score": 0}, {"text": "in the distribution", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 325, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so those those are two principles", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 326, "tokens": 0, "vector": null, "score": 0}, {"text": "and the actually the very nice thing of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 327, "tokens": 0, "vector": null, "score": 0}, {"text": "of this of those two principles is that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 328, "tokens": 0, "vector": null, "score": 0}, {"text": "it translates to the k-means which is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 329, "tokens": 0, "vector": null, "score": 0}, {"text": "also called The Noise Lloyd's algorithm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 330, "tokens": 0, "vector": null, "score": 0}, {"text": "to uh to do uh to do clustering and as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 331, "tokens": 0, "vector": null, "score": 0}, {"text": "well as to do quantization because the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 332, "tokens": 0, "vector": null, "score": 0}, {"text": "canines is an uh basically what you do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 333, "tokens": 0, "vector": null, "score": 0}, {"text": "is you you take a training set that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 334, "tokens": 0, "vector": null, "score": 0}, {"text": "suppose is representative of the of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 335, "tokens": 0, "vector": null, "score": 0}, {"text": "data distribution and then you you you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 336, "tokens": 0, "vector": null, "score": 0}, {"text": "alternate between two steps the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 337, "tokens": 0, "vector": null, "score": 0}, {"text": "one is to estimate or let's start with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 338, "tokens": 0, "vector": null, "score": 0}, {"text": "the assignment so you start with a set", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 339, "tokens": 0, "vector": null, "score": 0}, {"text": "of of initial centroids that are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 340, "tokens": 0, "vector": null, "score": 0}, {"text": "determined with some heuristic or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 341, "tokens": 0, "vector": null, "score": 0}, {"text": "randomly and then you you assign to each", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 342, "tokens": 0, "vector": null, "score": 0}, {"text": "uh you assign each training Vector to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 343, "tokens": 0, "vector": null, "score": 0}, {"text": "the nearest centrate so that you you you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 344, "tokens": 0, "vector": null, "score": 0}, {"text": "basically you do the assignment step and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 345, "tokens": 0, "vector": null, "score": 0}, {"text": "the second step is you update the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 346, "tokens": 0, "vector": null, "score": 0}, {"text": "centroids by by Computing the center of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 347, "tokens": 0, "vector": null, "score": 0}, {"text": "mass of all the points that were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 348, "tokens": 0, "vector": null, "score": 0}, {"text": "assigned to that that centroid", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 349, "tokens": 0, "vector": null, "score": 0}, {"text": "so k-means is is one of the huge", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 350, "tokens": 0, "vector": null, "score": 0}, {"text": "successes of of uh of quantization and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 351, "tokens": 0, "vector": null, "score": 0}, {"text": "of many machine learning algorithms it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 352, "tokens": 0, "vector": null, "score": 0}, {"text": "very simple", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 353, "tokens": 0, "vector": null, "score": 0}, {"text": "and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 354, "tokens": 0, "vector": null, "score": 0}, {"text": "and actually it gives you uh it gives", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 355, "tokens": 0, "vector": null, "score": 0}, {"text": "you a quantizer if you have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 356, "tokens": 0, "vector": null, "score": 0}, {"text": "representative trading points it gives", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 357, "tokens": 0, "vector": null, "score": 0}, {"text": "you a quantizer that is that has that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 358, "tokens": 0, "vector": null, "score": 0}, {"text": "follows those two properties of the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 359, "tokens": 0, "vector": null, "score": 0}, {"text": "optimality of the of the two lights", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 360, "tokens": 0, "vector": null, "score": 0}, {"text": "conditions", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 361, "tokens": 0, "vector": null, "score": 0}, {"text": "and um so what's so this is very good so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 362, "tokens": 0, "vector": null, "score": 0}, {"text": "what's the problem with k-means the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 363, "tokens": 0, "vector": null, "score": 0}, {"text": "problem is that say that you you have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 364, "tokens": 0, "vector": null, "score": 0}, {"text": "budget to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 365, "tokens": 0, "vector": null, "score": 0}, {"text": "um to represent a vector with 64 bits so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 366, "tokens": 0, "vector": null, "score": 0}, {"text": "uh what happens is that you cannot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 367, "tokens": 0, "vector": null, "score": 0}, {"text": "really say okay I'm going to do a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 368, "tokens": 0, "vector": null, "score": 0}, {"text": "k-means where the the indices are going", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 369, "tokens": 0, "vector": null, "score": 0}, {"text": "to be encoded into 64 bits because 64 2", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 370, "tokens": 0, "vector": null, "score": 0}, {"text": "to the 64. it's really a lot of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 371, "tokens": 0, "vector": null, "score": 0}, {"text": "centroids it's actually more than much", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 372, "tokens": 0, "vector": null, "score": 0}, {"text": "of uh of the high numbers that we find", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 373, "tokens": 0, "vector": null, "score": 0}, {"text": "in modern computer science so so it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 374, "tokens": 0, "vector": null, "score": 0}, {"text": "just not possible it's not possible to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 375, "tokens": 0, "vector": null, "score": 0}, {"text": "do this to use this amazing cayman's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 376, "tokens": 0, "vector": null, "score": 0}, {"text": "algorithm at that scale it is possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 377, "tokens": 0, "vector": null, "score": 0}, {"text": "and that's what we do to use it for IVF", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 378, "tokens": 0, "vector": null, "score": 0}, {"text": "for cost quantization so for I for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 379, "tokens": 0, "vector": null, "score": 0}, {"text": "inverted files uh we have the the degree", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 380, "tokens": 0, "vector": null, "score": 0}, {"text": "of freedom to choose the number of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 381, "tokens": 0, "vector": null, "score": 0}, {"text": "centuries that we want to use and in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 382, "tokens": 0, "vector": null, "score": 0}, {"text": "general it is beneficial to use a large", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 383, "tokens": 0, "vector": null, "score": 0}, {"text": "number of centroids but we're not going", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 384, "tokens": 0, "vector": null, "score": 0}, {"text": "to to have 2 to the 24 the 2 to the 64th", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 385, "tokens": 0, "vector": null, "score": 0}, {"text": "centuries we're going to have like uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 386, "tokens": 0, "vector": null, "score": 0}, {"text": "between uh uh a thousand ten thousand", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 387, "tokens": 0, "vector": null, "score": 0}, {"text": "hundred thousand one million this this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 388, "tokens": 0, "vector": null, "score": 0}, {"text": "order of magnitude number of centroids", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 389, "tokens": 0, "vector": null, "score": 0}, {"text": "so for this we can use k-means directly", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 390, "tokens": 0, "vector": null, "score": 0}, {"text": "and we definitely do that uh to to to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 391, "tokens": 0, "vector": null, "score": 0}, {"text": "this first step of what we call course", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 392, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization so the the inverted file", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 393, "tokens": 0, "vector": null, "score": 0}, {"text": "that's going to to allow us to to search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 394, "tokens": 0, "vector": null, "score": 0}, {"text": "only a really small hopefully a small", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 395, "tokens": 0, "vector": null, "score": 0}, {"text": "subset of the data set and still not", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 396, "tokens": 0, "vector": null, "score": 0}, {"text": "lose too much accuracy in this process", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 397, "tokens": 0, "vector": null, "score": 0}, {"text": "but when we when we when we're talking", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 398, "tokens": 0, "vector": null, "score": 0}, {"text": "about the payload so the the the parts", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 399, "tokens": 0, "vector": null, "score": 0}, {"text": "that you going to use to approximate the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 400, "tokens": 0, "vector": null, "score": 0}, {"text": "vector and that you store in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 401, "tokens": 0, "vector": null, "score": 0}, {"text": "inverted lists uh then you you cannot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 402, "tokens": 0, "vector": null, "score": 0}, {"text": "you I mean if you have a payload of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 403, "tokens": 0, "vector": null, "score": 0}, {"text": "eight bits it's fine but in general you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 404, "tokens": 0, "vector": null, "score": 0}, {"text": "have a larger payload and the reason is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 405, "tokens": 0, "vector": null, "score": 0}, {"text": "because it doesn't make much sense to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 406, "tokens": 0, "vector": null, "score": 0}, {"text": "have eight bits because the even the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 407, "tokens": 0, "vector": null, "score": 0}, {"text": "image identifier is going to be longer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 408, "tokens": 0, "vector": null, "score": 0}, {"text": "than that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 409, "tokens": 0, "vector": null, "score": 0}, {"text": "and that's also start in the inverter", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 410, "tokens": 0, "vector": null, "score": 0}, {"text": "lists and so if we want to go to 64 bits", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 411, "tokens": 0, "vector": null, "score": 0}, {"text": "then uh so the the the fundamental idea", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 412, "tokens": 0, "vector": null, "score": 0}, {"text": "of the product quantization which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 413, "tokens": 0, "vector": null, "score": 0}, {"text": "already existed but was never used for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 414, "tokens": 0, "vector": null, "score": 0}, {"text": "uh similarity search per se the idea", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 415, "tokens": 0, "vector": null, "score": 0}, {"text": "there is to is to say okay we cannot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 416, "tokens": 0, "vector": null, "score": 0}, {"text": "really afford to do a 64 bits by uh by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 417, "tokens": 0, "vector": null, "score": 0}, {"text": "having a vocabulary that's that spans", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 418, "tokens": 0, "vector": null, "score": 0}, {"text": "that has one explicit centroid stored", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 419, "tokens": 0, "vector": null, "score": 0}, {"text": "for every uh for every uh set rate of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 420, "tokens": 0, "vector": null, "score": 0}, {"text": "the two to to the 64. so what we're", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 421, "tokens": 0, "vector": null, "score": 0}, {"text": "going to do we're going to do a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 422, "tokens": 0, "vector": null, "score": 0}, {"text": "trade-off we're going to just chunk or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 423, "tokens": 0, "vector": null, "score": 0}, {"text": "to we're going to take the vector the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 424, "tokens": 0, "vector": null, "score": 0}, {"text": "input vector and split it into sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 425, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors and then apply this quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 426, "tokens": 0, "vector": null, "score": 0}, {"text": "this K means quantization or this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 427, "tokens": 0, "vector": null, "score": 0}, {"text": "exhaustive conversation apply it only on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 428, "tokens": 0, "vector": null, "score": 0}, {"text": "the sub vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 429, "tokens": 0, "vector": null, "score": 0}, {"text": "and this is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 430, "tokens": 0, "vector": null, "score": 0}, {"text": "um it's very it's it's it solves our", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 431, "tokens": 0, "vector": null, "score": 0}, {"text": "problem uh of scale because let's say if", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 432, "tokens": 0, "vector": null, "score": 0}, {"text": "we need 64 bits uh let's say that we can", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 433, "tokens": 0, "vector": null, "score": 0}, {"text": "split those in eight times eight bits", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 434, "tokens": 0, "vector": null, "score": 0}, {"text": "and eight sub vectors that each are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 435, "tokens": 0, "vector": null, "score": 0}, {"text": "encoded in eight bits and then doing the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 436, "tokens": 0, "vector": null, "score": 0}, {"text": "k-means for to get 8-bit vectors it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 437, "tokens": 0, "vector": null, "score": 0}, {"text": "just okay means with 256 centroids and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 438, "tokens": 0, "vector": null, "score": 0}, {"text": "this is I mean this is you could almost", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 439, "tokens": 0, "vector": null, "score": 0}, {"text": "do it by hand and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 440, "tokens": 0, "vector": null, "score": 0}, {"text": "and then uh to and then you can encode", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 441, "tokens": 0, "vector": null, "score": 0}, {"text": "each of those Circ vectors into separate", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 442, "tokens": 0, "vector": null, "score": 0}, {"text": "uh into a separate representation and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 443, "tokens": 0, "vector": null, "score": 0}, {"text": "then just concatenate those", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 444, "tokens": 0, "vector": null, "score": 0}, {"text": "representations and uh and you get an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 445, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation of the the vector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 446, "tokens": 0, "vector": null, "score": 0}, {"text": "so uh so then we are down to uh to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 447, "tokens": 0, "vector": null, "score": 0}, {"text": "having", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 448, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 449, "tokens": 0, "vector": null, "score": 0}, {"text": "to having uh encoding costs that's very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 450, "tokens": 0, "vector": null, "score": 0}, {"text": "reasonable because at encoding time what", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 451, "tokens": 0, "vector": null, "score": 0}, {"text": "you need to do is is exhaustively find", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 452, "tokens": 0, "vector": null, "score": 0}, {"text": "the nearest centroid for each of the sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 453, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors but since you need to search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 454, "tokens": 0, "vector": null, "score": 0}, {"text": "only 256 hundreds it's uh it's pretty", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 455, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient and uh and uh uh and and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 456, "tokens": 0, "vector": null, "score": 0}, {"text": "storage the other problem was the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 457, "tokens": 0, "vector": null, "score": 0}, {"text": "storage of the centroids this and since", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 458, "tokens": 0, "vector": null, "score": 0}, {"text": "you need to store only small centroids", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 459, "tokens": 0, "vector": null, "score": 0}, {"text": "in in for each of the uh for each of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 460, "tokens": 0, "vector": null, "score": 0}, {"text": "sub vectors it's it's pretty efficient", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 461, "tokens": 0, "vector": null, "score": 0}, {"text": "actually uh the starting the centroids", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 462, "tokens": 0, "vector": null, "score": 0}, {"text": "is as large as storing 256 vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 463, "tokens": 0, "vector": null, "score": 0}, {"text": "themselves because if you add the sizes", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 464, "tokens": 0, "vector": null, "score": 0}, {"text": "of the sub vectors you end up with the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 465, "tokens": 0, "vector": null, "score": 0}, {"text": "initial size of the data vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 466, "tokens": 0, "vector": null, "score": 0}, {"text": "so that was that was uh very interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 467, "tokens": 0, "vector": null, "score": 0}, {"text": "in terms of storage and in terms of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 468, "tokens": 0, "vector": null, "score": 0}, {"text": "assignments and so decoding is just a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 469, "tokens": 0, "vector": null, "score": 0}, {"text": "lookup and you separately look up each", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 470, "tokens": 0, "vector": null, "score": 0}, {"text": "of the vectors and one very interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 471, "tokens": 0, "vector": null, "score": 0}, {"text": "property that we already that we also", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 472, "tokens": 0, "vector": null, "score": 0}, {"text": "had and that's uh that was kind of lucky", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 473, "tokens": 0, "vector": null, "score": 0}, {"text": "that it turns out this way is that it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 474, "tokens": 0, "vector": null, "score": 0}, {"text": "also possible to do compressed domain", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 475, "tokens": 0, "vector": null, "score": 0}, {"text": "distance computations", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 476, "tokens": 0, "vector": null, "score": 0}, {"text": "so compressed demand distance", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 477, "tokens": 0, "vector": null, "score": 0}, {"text": "computations means that if you have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 478, "tokens": 0, "vector": null, "score": 0}, {"text": "query Vector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 479, "tokens": 0, "vector": null, "score": 0}, {"text": "um so in general", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 480, "tokens": 0, "vector": null, "score": 0}, {"text": "I wouldn't say in general but very often", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 481, "tokens": 0, "vector": null, "score": 0}, {"text": "you want to compress the database", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 482, "tokens": 0, "vector": null, "score": 0}, {"text": "because it's size constrained but the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 483, "tokens": 0, "vector": null, "score": 0}, {"text": "query vectors come as a float so you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 484, "tokens": 0, "vector": null, "score": 0}, {"text": "don't really need to compress them and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 485, "tokens": 0, "vector": null, "score": 0}, {"text": "so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 486, "tokens": 0, "vector": null, "score": 0}, {"text": "um and so what you can do there is to so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 487, "tokens": 0, "vector": null, "score": 0}, {"text": "the the basic algorithm that you would", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 488, "tokens": 0, "vector": null, "score": 0}, {"text": "do with uh with an igf and the PQ or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 489, "tokens": 0, "vector": null, "score": 0}, {"text": "with the PQ payload to compute those", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 490, "tokens": 0, "vector": null, "score": 0}, {"text": "distances is to take the query vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 491, "tokens": 0, "vector": null, "score": 0}, {"text": "that are not compressed decompress the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 492, "tokens": 0, "vector": null, "score": 0}, {"text": "the database vectors or you scan the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 493, "tokens": 0, "vector": null, "score": 0}, {"text": "inverted list you decompress each of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 494, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors and then you compute the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 495, "tokens": 0, "vector": null, "score": 0}, {"text": "distance just by Computing L2 distance", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 496, "tokens": 0, "vector": null, "score": 0}, {"text": "and and so that's fine", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 497, "tokens": 0, "vector": null, "score": 0}, {"text": "but it turns out that it does something", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 498, "tokens": 0, "vector": null, "score": 0}, {"text": "even more efficient that you can do is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 499, "tokens": 0, "vector": null, "score": 0}, {"text": "not decompressing the the the database", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 500, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors at all but when you know at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 501, "tokens": 0, "vector": null, "score": 0}, {"text": "point when you know the query Vector you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 502, "tokens": 0, "vector": null, "score": 0}, {"text": "can you can say okay uh for each of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 503, "tokens": 0, "vector": null, "score": 0}, {"text": "sub vectors of those query vectors I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 504, "tokens": 0, "vector": null, "score": 0}, {"text": "have only 256 possible Dimensions", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 505, "tokens": 0, "vector": null, "score": 0}, {"text": "because there are 256 hundreds and so I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 506, "tokens": 0, "vector": null, "score": 0}, {"text": "come I can just instead of computing it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 507, "tokens": 0, "vector": null, "score": 0}, {"text": "every time you can just say okay I only", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 508, "tokens": 0, "vector": null, "score": 0}, {"text": "have 256 possibilities so I just need to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 509, "tokens": 0, "vector": null, "score": 0}, {"text": "compute those this and all those 256", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 510, "tokens": 0, "vector": null, "score": 0}, {"text": "distances and what I'm scanning I'm just", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 511, "tokens": 0, "vector": null, "score": 0}, {"text": "you know looking up those distances and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 512, "tokens": 0, "vector": null, "score": 0}, {"text": "and compute what's the what's the and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 513, "tokens": 0, "vector": null, "score": 0}, {"text": "and then I don't need to compute", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 514, "tokens": 0, "vector": null, "score": 0}, {"text": "actually compute the distance and this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 515, "tokens": 0, "vector": null, "score": 0}, {"text": "is possible so it's possible to do that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 516, "tokens": 0, "vector": null, "score": 0}, {"text": "with uh with any quantizer you can", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 517, "tokens": 0, "vector": null, "score": 0}, {"text": "compute the businesses with all the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 518, "tokens": 0, "vector": null, "score": 0}, {"text": "centroids and since it's a finite number", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 519, "tokens": 0, "vector": null, "score": 0}, {"text": "of some trades you you always know that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 520, "tokens": 0, "vector": null, "score": 0}, {"text": "it you you will have pre-computed the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 521, "tokens": 0, "vector": null, "score": 0}, {"text": "distances but what makes this possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 522, "tokens": 0, "vector": null, "score": 0}, {"text": "with the product quantizer is or what", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 523, "tokens": 0, "vector": null, "score": 0}, {"text": "what's convenient with the product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 524, "tokens": 0, "vector": null, "score": 0}, {"text": "quantizer is that uh the distance is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 525, "tokens": 0, "vector": null, "score": 0}, {"text": "decompose across Dimensions with L2", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 526, "tokens": 0, "vector": null, "score": 0}, {"text": "distance or with L1 distance or with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 527, "tokens": 0, "vector": null, "score": 0}, {"text": "many distances actually you you can uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 528, "tokens": 0, "vector": null, "score": 0}, {"text": "when you you can chunk the the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 529, "tokens": 0, "vector": null, "score": 0}, {"text": "into parts and uh summing up the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 530, "tokens": 0, "vector": null, "score": 0}, {"text": "distances in the sub in the subparts to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 531, "tokens": 0, "vector": null, "score": 0}, {"text": "get the total distance between between", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 532, "tokens": 0, "vector": null, "score": 0}, {"text": "the vectors and so that's or I mean it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 533, "tokens": 0, "vector": null, "score": 0}, {"text": "not true for L2 distance it's Square", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 534, "tokens": 0, "vector": null, "score": 0}, {"text": "it's too true for squared L2 distance", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 535, "tokens": 0, "vector": null, "score": 0}, {"text": "and so we always compute squared all two", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 536, "tokens": 0, "vector": null, "score": 0}, {"text": "distance and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 537, "tokens": 0, "vector": null, "score": 0}, {"text": "and so in those sub vectors then uh we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 538, "tokens": 0, "vector": null, "score": 0}, {"text": "were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 539, "tokens": 0, "vector": null, "score": 0}, {"text": "um we uh we're adding together the sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 540, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors uh the distance of the sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 541, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors and and and basically when we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 542, "tokens": 0, "vector": null, "score": 0}, {"text": "have 64 uh bits uh 64 bits", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 543, "tokens": 0, "vector": null, "score": 0}, {"text": "representation we have uh we just have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 544, "tokens": 0, "vector": null, "score": 0}, {"text": "uh a lookup to do for every of the sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 545, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors when we compute distances and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 546, "tokens": 0, "vector": null, "score": 0}, {"text": "and then some summing them together so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 547, "tokens": 0, "vector": null, "score": 0}, {"text": "that's for uh to do one distance", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 548, "tokens": 0, "vector": null, "score": 0}, {"text": "computation instead of doing a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 549, "tokens": 0, "vector": null, "score": 0}, {"text": "decompression plus plus uh plus L2", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 550, "tokens": 0, "vector": null, "score": 0}, {"text": "distance what we do is we do eight", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 551, "tokens": 0, "vector": null, "score": 0}, {"text": "lookups and seven additions to get the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 552, "tokens": 0, "vector": null, "score": 0}, {"text": "the actual result", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 553, "tokens": 0, "vector": null, "score": 0}, {"text": "so um okay so that's that was the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 554, "tokens": 0, "vector": null, "score": 0}, {"text": "principle of her quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 555, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so I I'm I see that I'm kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 556, "tokens": 0, "vector": null, "score": 0}, {"text": "diverging a little bit from the History", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 557, "tokens": 0, "vector": null, "score": 0}, {"text": "part so let's go back back to the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 558, "tokens": 0, "vector": null, "score": 0}, {"text": "history of product quantization so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 559, "tokens": 0, "vector": null, "score": 0}, {"text": "basically this uh this all happened in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 560, "tokens": 0, "vector": null, "score": 0}, {"text": "the so that that was back in 2009 I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 561, "tokens": 0, "vector": null, "score": 0}, {"text": "think so and this was all you know uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 562, "tokens": 0, "vector": null, "score": 0}, {"text": "generated by the by the the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 563, "tokens": 0, "vector": null, "score": 0}, {"text": "brain of uh are they and so I was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 564, "tokens": 0, "vector": null, "score": 0}, {"text": "implementing and together we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 565, "tokens": 0, "vector": null, "score": 0}, {"text": "we made we made a paper about this uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 566, "tokens": 0, "vector": null, "score": 0}, {"text": "that we submitted to a journal to Pammy", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 567, "tokens": 0, "vector": null, "score": 0}, {"text": "so that was the uh the IVF uh so it's it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 568, "tokens": 0, "vector": null, "score": 0}, {"text": "was the product quantization paper which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 569, "tokens": 0, "vector": null, "score": 0}, {"text": "contains both the idea of doing uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 570, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantization so it's called yeah", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 571, "tokens": 0, "vector": null, "score": 0}, {"text": "by the way it's called the product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 572, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization because you have a product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 573, "tokens": 0, "vector": null, "score": 0}, {"text": "space when you have sub vectors like", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 574, "tokens": 0, "vector": null, "score": 0}, {"text": "this it's like when you look at it from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 575, "tokens": 0, "vector": null, "score": 0}, {"text": "a space perspective you basically have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 576, "tokens": 0, "vector": null, "score": 0}, {"text": "Cartesian product of the subspaces and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 577, "tokens": 0, "vector": null, "score": 0}, {"text": "so that's why it's called the product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 578, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 579, "tokens": 0, "vector": null, "score": 0}, {"text": "uh but but the the term wasn't wasn't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 580, "tokens": 0, "vector": null, "score": 0}, {"text": "invented by by us it it existed before", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 581, "tokens": 0, "vector": null, "score": 0}, {"text": "it's uh it's a relatively classic in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 582, "tokens": 0, "vector": null, "score": 0}, {"text": "in the coding literature", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 583, "tokens": 0, "vector": null, "score": 0}, {"text": "so uh we published this paper and um and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 584, "tokens": 0, "vector": null, "score": 0}, {"text": "so there were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 585, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 586, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so it we we compared it uh with uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 587, "tokens": 0, "vector": null, "score": 0}, {"text": "what we had previously the our Hamming", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 588, "tokens": 0, "vector": null, "score": 0}, {"text": "embedding method uh so which was based", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 589, "tokens": 0, "vector": null, "score": 0}, {"text": "on on a binary representations and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 590, "tokens": 0, "vector": null, "score": 0}, {"text": "um and it turns out so uh it turns out", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 591, "tokens": 0, "vector": null, "score": 0}, {"text": "that it was it was very fast and uh I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 592, "tokens": 0, "vector": null, "score": 0}, {"text": "think", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 593, "tokens": 0, "vector": null, "score": 0}, {"text": "I think at the time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 594, "tokens": 0, "vector": null, "score": 0}, {"text": "at the time maybe the it was so we were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 595, "tokens": 0, "vector": null, "score": 0}, {"text": "quite convinced that it was a very good", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 596, "tokens": 0, "vector": null, "score": 0}, {"text": "method", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 597, "tokens": 0, "vector": null, "score": 0}, {"text": "but in the end it took a very long time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 598, "tokens": 0, "vector": null, "score": 0}, {"text": "uh before before uh people actually", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 599, "tokens": 0, "vector": null, "score": 0}, {"text": "realized that uh that uh binary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 600, "tokens": 0, "vector": null, "score": 0}, {"text": "representations are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 601, "tokens": 0, "vector": null, "score": 0}, {"text": "are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 602, "tokens": 0, "vector": null, "score": 0}, {"text": "um are just sub-optimal so it's it's so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 603, "tokens": 0, "vector": null, "score": 0}, {"text": "I think much of the story afterwards was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 604, "tokens": 0, "vector": null, "score": 0}, {"text": "a kind of fight well I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 605, "tokens": 0, "vector": null, "score": 0}, {"text": "it was a very you know very polite fight", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 606, "tokens": 0, "vector": null, "score": 0}, {"text": "but still it it took it took a lot of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 607, "tokens": 0, "vector": null, "score": 0}, {"text": "Education to uh to to to to convey this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 608, "tokens": 0, "vector": null, "score": 0}, {"text": "message that despite the huge", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 609, "tokens": 0, "vector": null, "score": 0}, {"text": "um amount of literature and theoretical", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 610, "tokens": 0, "vector": null, "score": 0}, {"text": "results that there is around uh locally", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 611, "tokens": 0, "vector": null, "score": 0}, {"text": "sensitive hashing uh that binary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 612, "tokens": 0, "vector": null, "score": 0}, {"text": "representations are just too crude to be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 613, "tokens": 0, "vector": null, "score": 0}, {"text": "uh to be efficient because uh because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 614, "tokens": 0, "vector": null, "score": 0}, {"text": "their their representation uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 615, "tokens": 0, "vector": null, "score": 0}, {"text": "capabilities are insufficient I mean", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 616, "tokens": 0, "vector": null, "score": 0}, {"text": "it's it's just you cannot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 617, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 618, "tokens": 0, "vector": null, "score": 0}, {"text": "you cannot you cannot even look at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 619, "tokens": 0, "vector": null, "score": 0}, {"text": "at the Lloyd's optimality conditions", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 620, "tokens": 0, "vector": null, "score": 0}, {"text": "basically a binary presentation in its", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 621, "tokens": 0, "vector": null, "score": 0}, {"text": "best form would be so that's interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 622, "tokens": 0, "vector": null, "score": 0}, {"text": "actually it would be a product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 623, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization where you have a single bit", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 624, "tokens": 0, "vector": null, "score": 0}, {"text": "per you have sub vectors of size one so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 625, "tokens": 0, "vector": null, "score": 0}, {"text": "that's a scalar and you have one bit per", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 626, "tokens": 0, "vector": null, "score": 0}, {"text": "per sub vector and so it's a very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 627, "tokens": 0, "vector": null, "score": 0}, {"text": "special case of product quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 628, "tokens": 0, "vector": null, "score": 0}, {"text": "with a very crude way of comparing them", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 629, "tokens": 0, "vector": null, "score": 0}, {"text": "if you use Hamming distances but you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 630, "tokens": 0, "vector": null, "score": 0}, {"text": "there are extensions of binary", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 631, "tokens": 0, "vector": null, "score": 0}, {"text": "representations where you actually do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 632, "tokens": 0, "vector": null, "score": 0}, {"text": "you do asymmetric binary search so the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 633, "tokens": 0, "vector": null, "score": 0}, {"text": "same you you don't take code or you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 634, "tokens": 0, "vector": null, "score": 0}, {"text": "don't take the binary representation of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 635, "tokens": 0, "vector": null, "score": 0}, {"text": "the query Vector but you you take the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 636, "tokens": 0, "vector": null, "score": 0}, {"text": "you take the floating Point vector and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 637, "tokens": 0, "vector": null, "score": 0}, {"text": "you can you can", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 638, "tokens": 0, "vector": null, "score": 0}, {"text": "uh make it so that uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 639, "tokens": 0, "vector": null, "score": 0}, {"text": "that you can get to floating Point", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 640, "tokens": 0, "vector": null, "score": 0}, {"text": "distance but then you you kind of lose", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 641, "tokens": 0, "vector": null, "score": 0}, {"text": "the advantage of doing very quick uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 642, "tokens": 0, "vector": null, "score": 0}, {"text": "having distance comparisons in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 643, "tokens": 0, "vector": null, "score": 0}, {"text": "binary domain", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 644, "tokens": 0, "vector": null, "score": 0}, {"text": "okay so to come back to the history so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 645, "tokens": 0, "vector": null, "score": 0}, {"text": "uh the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 646, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantization uh basically it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 647, "tokens": 0, "vector": null, "score": 0}, {"text": "uh we we've done we and then other", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 648, "tokens": 0, "vector": null, "score": 0}, {"text": "people have done many follow-ups in that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 649, "tokens": 0, "vector": null, "score": 0}, {"text": "field and so the follow-ups are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 650, "tokens": 0, "vector": null, "score": 0}, {"text": "are interesting I think that um so there", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 651, "tokens": 0, "vector": null, "score": 0}, {"text": "since there are two components of uh of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 652, "tokens": 0, "vector": null, "score": 0}, {"text": "uh of the uh of the the what we call IVF", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 653, "tokens": 0, "vector": null, "score": 0}, {"text": "PQ so inverted file plus PQ payload", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 654, "tokens": 0, "vector": null, "score": 0}, {"text": "representation uh so there have been uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 655, "tokens": 0, "vector": null, "score": 0}, {"text": "improvements on both sides on both of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 656, "tokens": 0, "vector": null, "score": 0}, {"text": "the on the IVF side so the inverted file", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 657, "tokens": 0, "vector": null, "score": 0}, {"text": "representation and on the PQ", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 658, "tokens": 0, "vector": null, "score": 0}, {"text": "representation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 659, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so uh so before we started so I'm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 660, "tokens": 0, "vector": null, "score": 0}, {"text": "going to kind of to reattach this to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 661, "tokens": 0, "vector": null, "score": 0}, {"text": "history I can say what what happened", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 662, "tokens": 0, "vector": null, "score": 0}, {"text": "before uh before we started on the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 663, "tokens": 0, "vector": null, "score": 0}, {"text": "face Library which is uh which what the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 664, "tokens": 0, "vector": null, "score": 0}, {"text": "big software and undertaking so at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 665, "tokens": 0, "vector": null, "score": 0}, {"text": "time so in terms of software let's talk", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 666, "tokens": 0, "vector": null, "score": 0}, {"text": "a bit about software so uh back in uh in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 667, "tokens": 0, "vector": null, "score": 0}, {"text": "2000 uh 2009 we we produced a software", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 668, "tokens": 0, "vector": null, "score": 0}, {"text": "that was called PQ codes and that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 669, "tokens": 0, "vector": null, "score": 0}, {"text": "implemented all of this uh in in uh in C", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 670, "tokens": 0, "vector": null, "score": 0}, {"text": "plus plus and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 671, "tokens": 0, "vector": null, "score": 0}, {"text": "um no in C actually right because we had", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 672, "tokens": 0, "vector": null, "score": 0}, {"text": "an inversion of C plus plus at the time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 673, "tokens": 0, "vector": null, "score": 0}, {"text": "which I to a certain extent that I still", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 674, "tokens": 0, "vector": null, "score": 0}, {"text": "have and uh so it was in C and but it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 675, "tokens": 0, "vector": null, "score": 0}, {"text": "was a closed Source library because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 676, "tokens": 0, "vector": null, "score": 0}, {"text": "um we decided that we wanted to sell it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 677, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh uh and at the time it was not so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 678, "tokens": 0, "vector": null, "score": 0}, {"text": "clear that you could and be open source", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 679, "tokens": 0, "vector": null, "score": 0}, {"text": "and sell something so it was close to so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 680, "tokens": 0, "vector": null, "score": 0}, {"text": "and we sold it to uh to a few companies", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 681, "tokens": 0, "vector": null, "score": 0}, {"text": "that were using it for uh for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 682, "tokens": 0, "vector": null, "score": 0}, {"text": "large-scale indexing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 683, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so uh what happened uh so that's what", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 684, "tokens": 0, "vector": null, "score": 0}, {"text": "so in a sense I think that the facts I I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 685, "tokens": 0, "vector": null, "score": 0}, {"text": "think back in the time people were not", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 686, "tokens": 0, "vector": null, "score": 0}, {"text": "doing that much uh open sourcing uh even", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 687, "tokens": 0, "vector": null, "score": 0}, {"text": "in the research domain it was not at all", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 688, "tokens": 0, "vector": null, "score": 0}, {"text": "obvious that that if you if you found", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 689, "tokens": 0, "vector": null, "score": 0}, {"text": "something or if you publish the paper", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 690, "tokens": 0, "vector": null, "score": 0}, {"text": "you you'd open source it and we didn't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 691, "tokens": 0, "vector": null, "score": 0}, {"text": "do that we didn't do that for several", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 692, "tokens": 0, "vector": null, "score": 0}, {"text": "for several of the papers and um and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 693, "tokens": 0, "vector": null, "score": 0}, {"text": "maybe at the time it was not that clear", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 694, "tokens": 0, "vector": null, "score": 0}, {"text": "as well that uh open sourcing is is just", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 695, "tokens": 0, "vector": null, "score": 0}, {"text": "a a royal way to increase the impacts of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 696, "tokens": 0, "vector": null, "score": 0}, {"text": "papers and um and so we we kind of uh we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 697, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of expected that people would be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 698, "tokens": 0, "vector": null, "score": 0}, {"text": "re-implementing it and uh that that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 699, "tokens": 0, "vector": null, "score": 0}, {"text": "would be enough but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 700, "tokens": 0, "vector": null, "score": 0}, {"text": "so I I think this is something that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 701, "tokens": 0, "vector": null, "score": 0}, {"text": "really flipped in the in the last uh in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 702, "tokens": 0, "vector": null, "score": 0}, {"text": "the last maybe 10 years or so um and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 703, "tokens": 0, "vector": null, "score": 0}, {"text": "so what what happened is that uh there", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 704, "tokens": 0, "vector": null, "score": 0}, {"text": "were PQ implementations that started to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 705, "tokens": 0, "vector": null, "score": 0}, {"text": "pop up uh so uh at Microsoft uh at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 706, "tokens": 0, "vector": null, "score": 0}, {"text": "Google had a early PQ implementation as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 707, "tokens": 0, "vector": null, "score": 0}, {"text": "well and so the the Improvement and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 708, "tokens": 0, "vector": null, "score": 0}, {"text": "but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 709, "tokens": 0, "vector": null, "score": 0}, {"text": "um in this in this in this that it was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 710, "tokens": 0, "vector": null, "score": 0}, {"text": "still not clear", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 711, "tokens": 0, "vector": null, "score": 0}, {"text": "at the time there was no real uh very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 712, "tokens": 0, "vector": null, "score": 0}, {"text": "big uh or established Benchmark for uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 713, "tokens": 0, "vector": null, "score": 0}, {"text": "for uh for for a near sniper search and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 714, "tokens": 0, "vector": null, "score": 0}, {"text": "and basically the the open sourcing of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 715, "tokens": 0, "vector": null, "score": 0}, {"text": "those methods came in parallel with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 716, "tokens": 0, "vector": null, "score": 0}, {"text": "benchmarks that were established to uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 717, "tokens": 0, "vector": null, "score": 0}, {"text": "to actually really compare them and to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 718, "tokens": 0, "vector": null, "score": 0}, {"text": "to make the state of the art clear", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 719, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so but so that that's that's uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 720, "tokens": 0, "vector": null, "score": 0}, {"text": "that's something that happened on the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 721, "tokens": 0, "vector": null, "score": 0}, {"text": "software uh and on the and on the you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 722, "tokens": 0, "vector": null, "score": 0}, {"text": "know on the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 723, "tokens": 0, "vector": null, "score": 0}, {"text": "on the adoption side of of things", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 724, "tokens": 0, "vector": null, "score": 0}, {"text": "so what happened so I can say a few", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 725, "tokens": 0, "vector": null, "score": 0}, {"text": "words about what happened in research", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 726, "tokens": 0, "vector": null, "score": 0}, {"text": "around the inverted files on the one", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 727, "tokens": 0, "vector": null, "score": 0}, {"text": "hand and on the PQ on the other hand so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 728, "tokens": 0, "vector": null, "score": 0}, {"text": "um one of the one of the the main pain", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 729, "tokens": 0, "vector": null, "score": 0}, {"text": "points of the ivfpq method was that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 730, "tokens": 0, "vector": null, "score": 0}, {"text": "that the first level course quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 731, "tokens": 0, "vector": null, "score": 0}, {"text": "was uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 732, "tokens": 0, "vector": null, "score": 0}, {"text": "was was a limiting factor because if you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 733, "tokens": 0, "vector": null, "score": 0}, {"text": "want to index more vectors you need to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 734, "tokens": 0, "vector": null, "score": 0}, {"text": "have a larger", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 735, "tokens": 0, "vector": null, "score": 0}, {"text": "um a larger vocabulary so I can explain", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 736, "tokens": 0, "vector": null, "score": 0}, {"text": "this a little bit so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 737, "tokens": 0, "vector": null, "score": 0}, {"text": "basically uh when you do a search in an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 738, "tokens": 0, "vector": null, "score": 0}, {"text": "ivfpq", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 739, "tokens": 0, "vector": null, "score": 0}, {"text": "index there are two components of this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 740, "tokens": 0, "vector": null, "score": 0}, {"text": "of the search time and the first one is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 741, "tokens": 0, "vector": null, "score": 0}, {"text": "to do the course quantization so taking", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 742, "tokens": 0, "vector": null, "score": 0}, {"text": "the query vectors the query vector and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 743, "tokens": 0, "vector": null, "score": 0}, {"text": "determining which inverted lists must be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 744, "tokens": 0, "vector": null, "score": 0}, {"text": "visited and so that boils down to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 745, "tokens": 0, "vector": null, "score": 0}, {"text": "finding the top", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 746, "tokens": 0, "vector": null, "score": 0}, {"text": "and so it's in face it's called n probe", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 747, "tokens": 0, "vector": null, "score": 0}, {"text": "the top and probe number of inverted", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 748, "tokens": 0, "vector": null, "score": 0}, {"text": "lists that need to be visited and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 749, "tokens": 0, "vector": null, "score": 0}, {"text": "that's the first stage and it's it is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 750, "tokens": 0, "vector": null, "score": 0}, {"text": "also a nearest neighbor search problem", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 751, "tokens": 0, "vector": null, "score": 0}, {"text": "because you find the nearest neighbors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 752, "tokens": 0, "vector": null, "score": 0}, {"text": "of the of the query vector and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 753, "tokens": 0, "vector": null, "score": 0}, {"text": "second the second stage is to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 754, "tokens": 0, "vector": null, "score": 0}, {"text": "um is to actually scan those inverted", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 755, "tokens": 0, "vector": null, "score": 0}, {"text": "lists and compute the distances using", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 756, "tokens": 0, "vector": null, "score": 0}, {"text": "those lookup tables", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 757, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so it turns out so you need to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 758, "tokens": 0, "vector": null, "score": 0}, {"text": "find a balance between those two costs", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 759, "tokens": 0, "vector": null, "score": 0}, {"text": "and the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 760, "tokens": 0, "vector": null, "score": 0}, {"text": "uh it it turns out that when you scale", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 761, "tokens": 0, "vector": null, "score": 0}, {"text": "the data set to larger sizes uh in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 762, "tokens": 0, "vector": null, "score": 0}, {"text": "general the number of centroids needs to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 763, "tokens": 0, "vector": null, "score": 0}, {"text": "scale as the square root of the number", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 764, "tokens": 0, "vector": null, "score": 0}, {"text": "of of the number of vectors that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 765, "tokens": 0, "vector": null, "score": 0}, {"text": "want to index because if you scale it as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 766, "tokens": 0, "vector": null, "score": 0}, {"text": "fast as the number of if you don't scale", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 767, "tokens": 0, "vector": null, "score": 0}, {"text": "it at all then the inverted list will", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 768, "tokens": 0, "vector": null, "score": 0}, {"text": "just grow proportionally to the number", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 769, "tokens": 0, "vector": null, "score": 0}, {"text": "of vectors so it so the cost is going to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 770, "tokens": 0, "vector": null, "score": 0}, {"text": "be proportional to the um or the scaling", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 771, "tokens": 0, "vector": null, "score": 0}, {"text": "cost is going to be proportional to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 772, "tokens": 0, "vector": null, "score": 0}, {"text": "uh to the search time to the number of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 773, "tokens": 0, "vector": null, "score": 0}, {"text": "factors but and if you if you scale the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 774, "tokens": 0, "vector": null, "score": 0}, {"text": "number of centuries as quickly as the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 775, "tokens": 0, "vector": null, "score": 0}, {"text": "number of vectors on the other hand then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 776, "tokens": 0, "vector": null, "score": 0}, {"text": "the inverted lists stay about as long", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 777, "tokens": 0, "vector": null, "score": 0}, {"text": "but the course quantization cost is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 778, "tokens": 0, "vector": null, "score": 0}, {"text": "going to scale linearly with the number", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 779, "tokens": 0, "vector": null, "score": 0}, {"text": "of vectors and So to avoid this you kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 780, "tokens": 0, "vector": null, "score": 0}, {"text": "of spread the effort onto both of them", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 781, "tokens": 0, "vector": null, "score": 0}, {"text": "and to do this a rule of thumb is to is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 782, "tokens": 0, "vector": null, "score": 0}, {"text": "to scale it it's a as a square root", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 783, "tokens": 0, "vector": null, "score": 0}, {"text": "so if you scale it as a square root when", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 784, "tokens": 0, "vector": null, "score": 0}, {"text": "you start getting to 1 billion vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 785, "tokens": 0, "vector": null, "score": 0}, {"text": "uh it's starting to be a bit slow", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 786, "tokens": 0, "vector": null, "score": 0}, {"text": "because you're in the order of hundred", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 787, "tokens": 0, "vector": null, "score": 0}, {"text": "thousand vectors uh maybe a million in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 788, "tokens": 0, "vector": null, "score": 0}, {"text": "general it's a bit larger so it might be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 789, "tokens": 0, "vector": null, "score": 0}, {"text": "a million and if you have a million", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 790, "tokens": 0, "vector": null, "score": 0}, {"text": "centroids to compare with uh it becomes", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 791, "tokens": 0, "vector": null, "score": 0}, {"text": "it becomes slow", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 792, "tokens": 0, "vector": null, "score": 0}, {"text": "and so there have been several uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 793, "tokens": 0, "vector": null, "score": 0}, {"text": "several propositions to improve this uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 794, "tokens": 0, "vector": null, "score": 0}, {"text": "improve this course quantization cost", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 795, "tokens": 0, "vector": null, "score": 0}, {"text": "and the first one which was quite clever", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 796, "tokens": 0, "vector": null, "score": 0}, {"text": "actually it was a method method by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 797, "tokens": 0, "vector": null, "score": 0}, {"text": "babenko and lempitsky which consisted in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 798, "tokens": 0, "vector": null, "score": 0}, {"text": "uh in breaking down the the the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 799, "tokens": 0, "vector": null, "score": 0}, {"text": "this are choosing the centroids as the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 800, "tokens": 0, "vector": null, "score": 0}, {"text": "representation space of a product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 801, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization itself", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 802, "tokens": 0, "vector": null, "score": 0}, {"text": "so to make it very clear if you if you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 803, "tokens": 0, "vector": null, "score": 0}, {"text": "want to have one million centroids you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 804, "tokens": 0, "vector": null, "score": 0}, {"text": "say Okay I I have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 805, "tokens": 0, "vector": null, "score": 0}, {"text": "um I have a thousand uh some trades for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 806, "tokens": 0, "vector": null, "score": 0}, {"text": "the first half of the vector and I have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 807, "tokens": 0, "vector": null, "score": 0}, {"text": "a thousand some trades for the second", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 808, "tokens": 0, "vector": null, "score": 0}, {"text": "half of the vector and then I if I take", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 809, "tokens": 0, "vector": null, "score": 0}, {"text": "again the the prob the Cartesian product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 810, "tokens": 0, "vector": null, "score": 0}, {"text": "of those two sets I get a million", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 811, "tokens": 0, "vector": null, "score": 0}, {"text": "centroids and I can do efficient uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 812, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient uh uh lookup to lookups or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 813, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient nearest neighbor searches to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 814, "tokens": 0, "vector": null, "score": 0}, {"text": "find the nearest centuries of the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 815, "tokens": 0, "vector": null, "score": 0}, {"text": "query vector so this this was the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 816, "tokens": 0, "vector": null, "score": 0}, {"text": "um quite uh quite effective way of um of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 817, "tokens": 0, "vector": null, "score": 0}, {"text": "finding the news neighbors or or doing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 818, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient course quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 819, "tokens": 0, "vector": null, "score": 0}, {"text": "um or maybe there was an earlier one", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 820, "tokens": 0, "vector": null, "score": 0}, {"text": "which was doing hierarchical k-means", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 821, "tokens": 0, "vector": null, "score": 0}, {"text": "which is also quite natural so it means", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 822, "tokens": 0, "vector": null, "score": 0}, {"text": "if you have a if you want to have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 823, "tokens": 0, "vector": null, "score": 0}, {"text": "million uh a million uh Sun trades you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 824, "tokens": 0, "vector": null, "score": 0}, {"text": "you start by by doing a k means in 1000", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 825, "tokens": 0, "vector": null, "score": 0}, {"text": "and then within each of those clusters", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 826, "tokens": 0, "vector": null, "score": 0}, {"text": "you do again one thousand and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 827, "tokens": 0, "vector": null, "score": 0}, {"text": "so both so remember that that the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 828, "tokens": 0, "vector": null, "score": 0}, {"text": "k-means is in some respects it is the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 829, "tokens": 0, "vector": null, "score": 0}, {"text": "optimal", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 830, "tokens": 0, "vector": null, "score": 0}, {"text": "well if K means found the global Optimum", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 831, "tokens": 0, "vector": null, "score": 0}, {"text": "which is not true but which is a good", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 832, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation k-means gets you the best", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 833, "tokens": 0, "vector": null, "score": 0}, {"text": "set of centroids that you can find but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 834, "tokens": 0, "vector": null, "score": 0}, {"text": "uh given that you you need to find a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 835, "tokens": 0, "vector": null, "score": 0}, {"text": "trade-off between speed and accuracy", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 836, "tokens": 0, "vector": null, "score": 0}, {"text": "those two methods doing hierarchical", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 837, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization or hierarchical or k-means", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 838, "tokens": 0, "vector": null, "score": 0}, {"text": "and doing the doing the the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 839, "tokens": 0, "vector": null, "score": 0}, {"text": "what's what's what they call the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 840, "tokens": 0, "vector": null, "score": 0}, {"text": "inverted multi-index which means finding", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 841, "tokens": 0, "vector": null, "score": 0}, {"text": "the finding the two sub vectors and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 842, "tokens": 0, "vector": null, "score": 0}, {"text": "handling those separately it was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 843, "tokens": 0, "vector": null, "score": 0}, {"text": "um it was it was also a good option that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 844, "tokens": 0, "vector": null, "score": 0}, {"text": "that states the best so the best course", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 845, "tokens": 0, "vector": null, "score": 0}, {"text": "quantizer I think for large scale", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 846, "tokens": 0, "vector": null, "score": 0}, {"text": "applications until uh until uh around", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 847, "tokens": 0, "vector": null, "score": 0}, {"text": "2017 or 2018. and uh and uh when people", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 848, "tokens": 0, "vector": null, "score": 0}, {"text": "realized that you could as course", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 849, "tokens": 0, "vector": null, "score": 0}, {"text": "quantizer you could use to use graph", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 850, "tokens": 0, "vector": null, "score": 0}, {"text": "based methods to to do similarity search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 851, "tokens": 0, "vector": null, "score": 0}, {"text": "so I know that you already had a whole", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 852, "tokens": 0, "vector": null, "score": 0}, {"text": "podcast about graph based methods and uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 853, "tokens": 0, "vector": null, "score": 0}, {"text": "so maybe I can say a little bit how this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 854, "tokens": 0, "vector": null, "score": 0}, {"text": "includes in this uh in this story about", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 855, "tokens": 0, "vector": null, "score": 0}, {"text": "uh about inverted files and product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 856, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization so basically graph based", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 857, "tokens": 0, "vector": null, "score": 0}, {"text": "methods are are very very fast and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 858, "tokens": 0, "vector": null, "score": 0}, {"text": "accurate they are not very scalable", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 859, "tokens": 0, "vector": null, "score": 0}, {"text": "because there's a very big overhead to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 860, "tokens": 0, "vector": null, "score": 0}, {"text": "start the graphs themselves but yeah so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 861, "tokens": 0, "vector": null, "score": 0}, {"text": "the graph based methods they um so they", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 862, "tokens": 0, "vector": null, "score": 0}, {"text": "are very they're very fast and accurate", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 863, "tokens": 0, "vector": null, "score": 0}, {"text": "but they have a scalability issue", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 864, "tokens": 0, "vector": null, "score": 0}, {"text": "because starring the starring the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 865, "tokens": 0, "vector": null, "score": 0}, {"text": "graph structure itself becomes skills uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 866, "tokens": 0, "vector": null, "score": 0}, {"text": "literally with the size of the data set", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 867, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh and it becomes a dominant cost", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 868, "tokens": 0, "vector": null, "score": 0}, {"text": "at when the data sets when the data set", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 869, "tokens": 0, "vector": null, "score": 0}, {"text": "becomes larger it becomes a problematic", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 870, "tokens": 0, "vector": null, "score": 0}, {"text": "basically I mean it's it's always the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 871, "tokens": 0, "vector": null, "score": 0}, {"text": "same problem in operations research once", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 872, "tokens": 0, "vector": null, "score": 0}, {"text": "uh when a problem doesn't is is not a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 873, "tokens": 0, "vector": null, "score": 0}, {"text": "limit you ignore it but once uh one is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 874, "tokens": 0, "vector": null, "score": 0}, {"text": "it becomes one is becomes a limiting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 875, "tokens": 0, "vector": null, "score": 0}, {"text": "factor you you start worrying about it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 876, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so basically yeah so uh the uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 877, "tokens": 0, "vector": null, "score": 0}, {"text": "in particular hnsw which is really a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 878, "tokens": 0, "vector": null, "score": 0}, {"text": "very impressive algorithm uh it's it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 879, "tokens": 0, "vector": null, "score": 0}, {"text": "scales at the size of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 880, "tokens": 0, "vector": null, "score": 0}, {"text": "uh of a million maybe 10 million but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 881, "tokens": 0, "vector": null, "score": 0}, {"text": "beyond it's it's very low slow to build", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 882, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh and and it takes just a huge", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 883, "tokens": 0, "vector": null, "score": 0}, {"text": "amount of memory and so um so so hnsw is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 884, "tokens": 0, "vector": null, "score": 0}, {"text": "actually but this makes it the perfect", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 885, "tokens": 0, "vector": null, "score": 0}, {"text": "candidate for for uh course quantization", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 886, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh I think that um uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 887, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh the same babenko and Yuri they", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 888, "tokens": 0, "vector": null, "score": 0}, {"text": "made they made a paper about using it as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 889, "tokens": 0, "vector": null, "score": 0}, {"text": "a cross quantizer and it's it is very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 890, "tokens": 0, "vector": null, "score": 0}, {"text": "good and that's uh that's how the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 891, "tokens": 0, "vector": null, "score": 0}, {"text": "graph based methods can be included into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 892, "tokens": 0, "vector": null, "score": 0}, {"text": "um into the ivfpq system", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 893, "tokens": 0, "vector": null, "score": 0}, {"text": "so that's what so that's about the cross", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 894, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization uh and basically what", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 895, "tokens": 0, "vector": null, "score": 0}, {"text": "happens is that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 896, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 897, "tokens": 0, "vector": null, "score": 0}, {"text": "every Improvement that we have on this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 898, "tokens": 0, "vector": null, "score": 0}, {"text": "task of news neighbor search it can be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 899, "tokens": 0, "vector": null, "score": 0}, {"text": "applied to cross quantizers and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 900, "tokens": 0, "vector": null, "score": 0}, {"text": "that's and quite it's quite easy to uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 901, "tokens": 0, "vector": null, "score": 0}, {"text": "to inject those improvements into into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 902, "tokens": 0, "vector": null, "score": 0}, {"text": "the into the ivfpq framework so that's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 903, "tokens": 0, "vector": null, "score": 0}, {"text": "about the cost quantizer then we have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 904, "tokens": 0, "vector": null, "score": 0}, {"text": "the the the product quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 905, "tokens": 0, "vector": null, "score": 0}, {"text": "so there were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 906, "tokens": 0, "vector": null, "score": 0}, {"text": "um there were several improvements over", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 907, "tokens": 0, "vector": null, "score": 0}, {"text": "the over the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 908, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh of the the core product quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 909, "tokens": 0, "vector": null, "score": 0}, {"text": "the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 910, "tokens": 0, "vector": null, "score": 0}, {"text": "um maybe the well maybe the first one is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 911, "tokens": 0, "vector": null, "score": 0}, {"text": "is to just do re-ranking so basically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 912, "tokens": 0, "vector": null, "score": 0}, {"text": "using a product quantizer as a first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 913, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation that gives you the top so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 914, "tokens": 0, "vector": null, "score": 0}, {"text": "say that you need the top 10 results", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 915, "tokens": 0, "vector": null, "score": 0}, {"text": "then you find the nearest neighbors with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 916, "tokens": 0, "vector": null, "score": 0}, {"text": "uh with with ivfpq and you take the top", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 917, "tokens": 0, "vector": null, "score": 0}, {"text": "100 and then you you compute exact", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 918, "tokens": 0, "vector": null, "score": 0}, {"text": "distances or distances with a better", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 919, "tokens": 0, "vector": null, "score": 0}, {"text": "approximation for the top 100 and keep", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 920, "tokens": 0, "vector": null, "score": 0}, {"text": "only the top 10. and this is this is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 921, "tokens": 0, "vector": null, "score": 0}, {"text": "really a very effective method it's it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 922, "tokens": 0, "vector": null, "score": 0}, {"text": "it's really what enables you to get a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 923, "tokens": 0, "vector": null, "score": 0}, {"text": "good recall at one so really get the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 924, "tokens": 0, "vector": null, "score": 0}, {"text": "good results at the very first uh for as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 925, "tokens": 0, "vector": null, "score": 0}, {"text": "the very first search result", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 926, "tokens": 0, "vector": null, "score": 0}, {"text": "um without impacting too much the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 927, "tokens": 0, "vector": null, "score": 0}, {"text": "search time the problem is that you need", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 928, "tokens": 0, "vector": null, "score": 0}, {"text": "to some auxiliary storage which might be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 929, "tokens": 0, "vector": null, "score": 0}, {"text": "Ram but uh it could be disk also or SSD", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 930, "tokens": 0, "vector": null, "score": 0}, {"text": "to start the the high quality", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 931, "tokens": 0, "vector": null, "score": 0}, {"text": "approximate mention of the vectors or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 932, "tokens": 0, "vector": null, "score": 0}, {"text": "the full vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 933, "tokens": 0, "vector": null, "score": 0}, {"text": "so that's the that's the first thing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 934, "tokens": 0, "vector": null, "score": 0}, {"text": "then there were some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 935, "tokens": 0, "vector": null, "score": 0}, {"text": "uh there were some attempts to improve", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 936, "tokens": 0, "vector": null, "score": 0}, {"text": "the to improve the the quality of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 937, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantizer and the first problem", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 938, "tokens": 0, "vector": null, "score": 0}, {"text": "of the product quantizer is that it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 939, "tokens": 0, "vector": null, "score": 0}, {"text": "arbitrarily uh chunks the vector into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 940, "tokens": 0, "vector": null, "score": 0}, {"text": "into subsections and um if you if if it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 941, "tokens": 0, "vector": null, "score": 0}, {"text": "so happens that in your data set all of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 942, "tokens": 0, "vector": null, "score": 0}, {"text": "the variants of the data set is only in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 943, "tokens": 0, "vector": null, "score": 0}, {"text": "the last 10 components of your thousand", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 944, "tokens": 0, "vector": null, "score": 0}, {"text": "dimensional vectors then you are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 945, "tokens": 0, "vector": null, "score": 0}, {"text": "allocating a lot of bits or a lot of uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 946, "tokens": 0, "vector": null, "score": 0}, {"text": "encoding capacity to the first parts of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 947, "tokens": 0, "vector": null, "score": 0}, {"text": "the vector and those are completely lost", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 948, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 949, "tokens": 0, "vector": null, "score": 0}, {"text": "um there's one very simple and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 950, "tokens": 0, "vector": null, "score": 0}, {"text": "unfruitful method that was applied on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 951, "tokens": 0, "vector": null, "score": 0}, {"text": "private quantizer which is called optim", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 952, "tokens": 0, "vector": null, "score": 0}, {"text": "optimized product quantization which was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 953, "tokens": 0, "vector": null, "score": 0}, {"text": "a an early weight work by Kevin hay when", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 954, "tokens": 0, "vector": null, "score": 0}, {"text": "the and became the or the very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 955, "tokens": 0, "vector": null, "score": 0}, {"text": "successful", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 956, "tokens": 0, "vector": null, "score": 0}, {"text": "architecture or CNN architecture", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 957, "tokens": 0, "vector": null, "score": 0}, {"text": "developer that we that we know and it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 958, "tokens": 0, "vector": null, "score": 0}, {"text": "works of meta now and that that method", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 959, "tokens": 0, "vector": null, "score": 0}, {"text": "consisted in applying or finding and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 960, "tokens": 0, "vector": null, "score": 0}, {"text": "applying a random not random but a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 961, "tokens": 0, "vector": null, "score": 0}, {"text": "rotation to the input vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 962, "tokens": 0, "vector": null, "score": 0}, {"text": "so that the the energy in each subvector", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 963, "tokens": 0, "vector": null, "score": 0}, {"text": "was balanced the objective was to find", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 964, "tokens": 0, "vector": null, "score": 0}, {"text": "this this rotation so that the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 965, "tokens": 0, "vector": null, "score": 0}, {"text": "the the energy was spread equally across", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 966, "tokens": 0, "vector": null, "score": 0}, {"text": "the sub vectors and um and since it's a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 967, "tokens": 0, "vector": null, "score": 0}, {"text": "rotation a rotation doesn't change the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 968, "tokens": 0, "vector": null, "score": 0}, {"text": "the euclidean distance so it's you don't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 969, "tokens": 0, "vector": null, "score": 0}, {"text": "see it on the euclidean distance and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 970, "tokens": 0, "vector": null, "score": 0}, {"text": "this is really useful for many uh many", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 971, "tokens": 0, "vector": null, "score": 0}, {"text": "distributions that wouldn't naturally be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 972, "tokens": 0, "vector": null, "score": 0}, {"text": "well balanced", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 973, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so then then there was uh maybe worth", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 974, "tokens": 0, "vector": null, "score": 0}, {"text": "mentioning the lopq method which is a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 975, "tokens": 0, "vector": null, "score": 0}, {"text": "locally optimized PQ method uh and this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 976, "tokens": 0, "vector": null, "score": 0}, {"text": "one consists uh but this is specific to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 977, "tokens": 0, "vector": null, "score": 0}, {"text": "uh or it it applies on an igfpq index", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 978, "tokens": 0, "vector": null, "score": 0}, {"text": "and basically the problem with IVF PQ", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 979, "tokens": 0, "vector": null, "score": 0}, {"text": "index is that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 980, "tokens": 0, "vector": null, "score": 0}, {"text": "um each each", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 981, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 982, "tokens": 0, "vector": null, "score": 0}, {"text": "each uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 983, "tokens": 0, "vector": null, "score": 0}, {"text": "in each event inverted lists you use the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 984, "tokens": 0, "vector": null, "score": 0}, {"text": "same PQ the same trained product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 985, "tokens": 0, "vector": null, "score": 0}, {"text": "quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 986, "tokens": 0, "vector": null, "score": 0}, {"text": "to to encode what's in those inverted", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 987, "tokens": 0, "vector": null, "score": 0}, {"text": "lists and this it's a bit it's a bit", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 988, "tokens": 0, "vector": null, "score": 0}, {"text": "unnatural because in fact since the role", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 989, "tokens": 0, "vector": null, "score": 0}, {"text": "of those uh inverted lists is is to make", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 990, "tokens": 0, "vector": null, "score": 0}, {"text": "cells so it makes cells in the embedding", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 991, "tokens": 0, "vector": null, "score": 0}, {"text": "space and so you could say that points", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 992, "tokens": 0, "vector": null, "score": 0}, {"text": "where you already know that they fall", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 993, "tokens": 0, "vector": null, "score": 0}, {"text": "into one of those cells they're probably", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 994, "tokens": 0, "vector": null, "score": 0}, {"text": "they don't probably don't have the same", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 995, "tokens": 0, "vector": null, "score": 0}, {"text": "data distribution of as if they fall in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 996, "tokens": 0, "vector": null, "score": 0}, {"text": "another cell and so what lopq does is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 997, "tokens": 0, "vector": null, "score": 0}, {"text": "that it trains as a product quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 998, "tokens": 0, "vector": null, "score": 0}, {"text": "separately for each of the cells", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 999, "tokens": 0, "vector": null, "score": 0}, {"text": "so the but then there's a trade-off", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1000, "tokens": 0, "vector": null, "score": 0}, {"text": "because it's expensive to train because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1001, "tokens": 0, "vector": null, "score": 0}, {"text": "you need to to store all this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1002, "tokens": 0, "vector": null, "score": 0}, {"text": "information separately for each of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1003, "tokens": 0, "vector": null, "score": 0}, {"text": "cells but it brings a a fair a fair", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1004, "tokens": 0, "vector": null, "score": 0}, {"text": "Improvement of the of the recalls", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1005, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh on on most data sets", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1006, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1007, "tokens": 0, "vector": null, "score": 0}, {"text": "okay so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1008, "tokens": 0, "vector": null, "score": 0}, {"text": "um yeah so maybe so I'm going to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1009, "tokens": 0, "vector": null, "score": 0}, {"text": "continue a bit with the history because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1010, "tokens": 0, "vector": null, "score": 0}, {"text": "here we are about at uh 2015 so 2015", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1011, "tokens": 0, "vector": null, "score": 0}, {"text": "um Harvey and I joined Facebook so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1012, "tokens": 0, "vector": null, "score": 0}, {"text": "Facebook is the old name of meta maybe", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1013, "tokens": 0, "vector": null, "score": 0}, {"text": "you'll remember", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1014, "tokens": 0, "vector": null, "score": 0}, {"text": "and um uh and we joined Facebook that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1015, "tokens": 0, "vector": null, "score": 0}, {"text": "was opening an office in in Paris and uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1016, "tokens": 0, "vector": null, "score": 0}, {"text": "so uh we basically moved to Paris and uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1017, "tokens": 0, "vector": null, "score": 0}, {"text": "and basically it was pretty clear since", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1018, "tokens": 0, "vector": null, "score": 0}, {"text": "the beginning uh that we needed to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1019, "tokens": 0, "vector": null, "score": 0}, {"text": "something about uh nearest neighbor", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1020, "tokens": 0, "vector": null, "score": 0}, {"text": "search in Facebook uh for production", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1021, "tokens": 0, "vector": null, "score": 0}, {"text": "systems because uh the the systems were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1022, "tokens": 0, "vector": null, "score": 0}, {"text": "very far from state of the Arts and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1023, "tokens": 0, "vector": null, "score": 0}, {"text": "and so uh this needed to be improved and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1024, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so and so when so have they arrived I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1025, "tokens": 0, "vector": null, "score": 0}, {"text": "think six or seven months before I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1026, "tokens": 0, "vector": null, "score": 0}, {"text": "arrived and here I had already started", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1027, "tokens": 0, "vector": null, "score": 0}, {"text": "with this face project and uh which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1028, "tokens": 0, "vector": null, "score": 0}, {"text": "means uh Facebook AI similarity search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1029, "tokens": 0, "vector": null, "score": 0}, {"text": "and um so uh so then we um so so we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1030, "tokens": 0, "vector": null, "score": 0}, {"text": "arrived there and um and so we we we we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1031, "tokens": 0, "vector": null, "score": 0}, {"text": "started you uh creating this uh piece of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1032, "tokens": 0, "vector": null, "score": 0}, {"text": "software called face uh Facebook AI", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1033, "tokens": 0, "vector": null, "score": 0}, {"text": "similarity search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1034, "tokens": 0, "vector": null, "score": 0}, {"text": "[Music]", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1035, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1036, "tokens": 0, "vector": null, "score": 0}, {"text": "basically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1037, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh we since since the start we said", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1038, "tokens": 0, "vector": null, "score": 0}, {"text": "we wanted to be open source and uh uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1039, "tokens": 0, "vector": null, "score": 0}, {"text": "and I did so uh the head of um of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1040, "tokens": 0, "vector": null, "score": 0}, {"text": "Facebook uh AI was um Facebook AI", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1041, "tokens": 0, "vector": null, "score": 0}, {"text": "research was Janika and he was very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1042, "tokens": 0, "vector": null, "score": 0}, {"text": "supportive of that of that and so uh and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1043, "tokens": 0, "vector": null, "score": 0}, {"text": "so we started working on on face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1044, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh so we uh uh and basically our I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1045, "tokens": 0, "vector": null, "score": 0}, {"text": "mean I arrived after and how they had", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1046, "tokens": 0, "vector": null, "score": 0}, {"text": "started implementing it in C because you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1047, "tokens": 0, "vector": null, "score": 0}, {"text": "know", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1048, "tokens": 0, "vector": null, "score": 0}, {"text": "um because C plus plus is uh is too", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1049, "tokens": 0, "vector": null, "score": 0}, {"text": "complicated so uh so but the people in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1050, "tokens": 0, "vector": null, "score": 0}, {"text": "production they were telling us uh okay", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1051, "tokens": 0, "vector": null, "score": 0}, {"text": "uh I mean it's already complicated we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1052, "tokens": 0, "vector": null, "score": 0}, {"text": "don't want to have this and see you so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1053, "tokens": 0, "vector": null, "score": 0}, {"text": "so I rewatched it in C plus plus and I I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1054, "tokens": 0, "vector": null, "score": 0}, {"text": "took over uh the as as the lead", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1055, "tokens": 0, "vector": null, "score": 0}, {"text": "developer of face pretty quickly at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1056, "tokens": 0, "vector": null, "score": 0}, {"text": "time there was um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1057, "tokens": 0, "vector": null, "score": 0}, {"text": "uh there was a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1058, "tokens": 0, "vector": null, "score": 0}, {"text": "um everybody was using Lua as the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1059, "tokens": 0, "vector": null, "score": 0}, {"text": "scripting language and so there was a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1060, "tokens": 0, "vector": null, "score": 0}, {"text": "scripting language Bridge uh with uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1061, "tokens": 0, "vector": null, "score": 0}, {"text": "face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1062, "tokens": 0, "vector": null, "score": 0}, {"text": "that remained internal until uh 2017 I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1063, "tokens": 0, "vector": null, "score": 0}, {"text": "think", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1064, "tokens": 0, "vector": null, "score": 0}, {"text": "um so so yeah I mean I my personal taste", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1065, "tokens": 0, "vector": null, "score": 0}, {"text": "is that Lua is really crappy language", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1066, "tokens": 0, "vector": null, "score": 0}, {"text": "it's and so I was pretty happy when uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1067, "tokens": 0, "vector": null, "score": 0}, {"text": "so I I did python into face for face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1068, "tokens": 0, "vector": null, "score": 0}, {"text": "quite quickly and using Swig and um and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1069, "tokens": 0, "vector": null, "score": 0}, {"text": "I kind of and in the end we when", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1070, "tokens": 0, "vector": null, "score": 0}, {"text": "everybody switched over from Lua to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1071, "tokens": 0, "vector": null, "score": 0}, {"text": "python when pytorch was created we kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1072, "tokens": 0, "vector": null, "score": 0}, {"text": "of forgot about the Lua the Lua", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1073, "tokens": 0, "vector": null, "score": 0}, {"text": "interface which is a good riddance and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1074, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1075, "tokens": 0, "vector": null, "score": 0}, {"text": "uh and so and one important uh aspect of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1076, "tokens": 0, "vector": null, "score": 0}, {"text": "this is that there was an engineer at uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1077, "tokens": 0, "vector": null, "score": 0}, {"text": "at Fair Jeff Johnson he's one of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1078, "tokens": 0, "vector": null, "score": 0}, {"text": "oldest members of um of fair in terms of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1079, "tokens": 0, "vector": null, "score": 0}, {"text": "uh you know number of years at Facebook", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1080, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh and he got this Library caught", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1081, "tokens": 0, "vector": null, "score": 0}, {"text": "his interest and he decided to do a GPU", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1082, "tokens": 0, "vector": null, "score": 0}, {"text": "version of it so GPU meaning Nvidia GPU", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1083, "tokens": 0, "vector": null, "score": 0}, {"text": "because I mean that's kind of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1084, "tokens": 0, "vector": null, "score": 0}, {"text": "standards uh at Facebook", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1085, "tokens": 0, "vector": null, "score": 0}, {"text": "and he started developing this and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1086, "tokens": 0, "vector": null, "score": 0}, {"text": "I think it was a it was a pretty", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1087, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting project for him because uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1088, "tokens": 0, "vector": null, "score": 0}, {"text": "because there were several aspects or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1089, "tokens": 0, "vector": null, "score": 0}, {"text": "the algorithms were not not out of Out", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1090, "tokens": 0, "vector": null, "score": 0}, {"text": "Of Reach in terms of optimization on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1091, "tokens": 0, "vector": null, "score": 0}, {"text": "gpus which sometimes sometimes happens", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1092, "tokens": 0, "vector": null, "score": 0}, {"text": "if there's really two irregular Behavior", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1093, "tokens": 0, "vector": null, "score": 0}, {"text": "or graph algorithms are very hard to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1094, "tokens": 0, "vector": null, "score": 0}, {"text": "optimize in gpus but this problem of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1095, "tokens": 0, "vector": null, "score": 0}, {"text": "optimizing ivfpq is was actually pretty", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1096, "tokens": 0, "vector": null, "score": 0}, {"text": "um pretty uh pretty reachable for uh for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1097, "tokens": 0, "vector": null, "score": 0}, {"text": "for gpus and it so he made a very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1098, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient GPU method and actually it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1099, "tokens": 0, "vector": null, "score": 0}, {"text": "turns out that we decided to publish a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1100, "tokens": 0, "vector": null, "score": 0}, {"text": "paper about face and the it was clear", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1101, "tokens": 0, "vector": null, "score": 0}, {"text": "that the flag", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1102, "tokens": 0, "vector": null, "score": 0}, {"text": "the flagship property that we want to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1103, "tokens": 0, "vector": null, "score": 0}, {"text": "showcase for face was the the GPU the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1104, "tokens": 0, "vector": null, "score": 0}, {"text": "GPU implementation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1105, "tokens": 0, "vector": null, "score": 0}, {"text": "um and so so yeah that that was in 2016", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1106, "tokens": 0, "vector": null, "score": 0}, {"text": "uh then 2017 started we started to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1107, "tokens": 0, "vector": null, "score": 0}, {"text": "negotiate when we would actually be", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1108, "tokens": 0, "vector": null, "score": 0}, {"text": "allowed so there were two aspects to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1109, "tokens": 0, "vector": null, "score": 0}, {"text": "this the first one was internal adoption", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1110, "tokens": 0, "vector": null, "score": 0}, {"text": "so there was a lot of work that that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1111, "tokens": 0, "vector": null, "score": 0}, {"text": "Javed was very much involved in in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1112, "tokens": 0, "vector": null, "score": 0}, {"text": "explaining to uh to prod people at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1113, "tokens": 0, "vector": null, "score": 0}, {"text": "Facebook how interesting it was to have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1114, "tokens": 0, "vector": null, "score": 0}, {"text": "to have this to use this library to use", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1115, "tokens": 0, "vector": null, "score": 0}, {"text": "a conversation based methods to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1116, "tokens": 0, "vector": null, "score": 0}, {"text": "similarity search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1117, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh on the uh on the other hand there", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1118, "tokens": 0, "vector": null, "score": 0}, {"text": "was uh there was the external impact so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1119, "tokens": 0, "vector": null, "score": 0}, {"text": "that means how are we going to open", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1120, "tokens": 0, "vector": null, "score": 0}, {"text": "source it and actually it took us quite", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1121, "tokens": 0, "vector": null, "score": 0}, {"text": "a lot of time to convince", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1122, "tokens": 0, "vector": null, "score": 0}, {"text": "um to convince our management uh well", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1123, "tokens": 0, "vector": null, "score": 0}, {"text": "first to uh to open source that but not", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1124, "tokens": 0, "vector": null, "score": 0}, {"text": "so much of a problem but the real", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1125, "tokens": 0, "vector": null, "score": 0}, {"text": "problem was to get it to open source it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1126, "tokens": 0, "vector": null, "score": 0}, {"text": "with uh with the MIT license", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1127, "tokens": 0, "vector": null, "score": 0}, {"text": "and basically so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1128, "tokens": 0, "vector": null, "score": 0}, {"text": "this is something well open sourcing was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1129, "tokens": 0, "vector": null, "score": 0}, {"text": "really something I discovered when I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1130, "tokens": 0, "vector": null, "score": 0}, {"text": "arrived at uh at Facebook it's uh it is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1131, "tokens": 0, "vector": null, "score": 0}, {"text": "actually it is very hard for companies", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1132, "tokens": 0, "vector": null, "score": 0}, {"text": "to for other companies to adopt open", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1133, "tokens": 0, "vector": null, "score": 0}, {"text": "source software that that doesn't have a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1134, "tokens": 0, "vector": null, "score": 0}, {"text": "very permissive license because you know", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1135, "tokens": 0, "vector": null, "score": 0}, {"text": "for example the GPL is not possible", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1136, "tokens": 0, "vector": null, "score": 0}, {"text": "because it's it's it's it contaminates", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1137, "tokens": 0, "vector": null, "score": 0}, {"text": "and so and so we when we initially open", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1138, "tokens": 0, "vector": null, "score": 0}, {"text": "sourced the the library in with the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1139, "tokens": 0, "vector": null, "score": 0}, {"text": "Creative Commons and non-commercial", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1140, "tokens": 0, "vector": null, "score": 0}, {"text": "applications the companies we talked", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1141, "tokens": 0, "vector": null, "score": 0}, {"text": "with told us we cannot use it and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1142, "tokens": 0, "vector": null, "score": 0}, {"text": "which makes sense and so we can we went", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1143, "tokens": 0, "vector": null, "score": 0}, {"text": "back to our management saying we want to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1144, "tokens": 0, "vector": null, "score": 0}, {"text": "have we want this library to have real", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1145, "tokens": 0, "vector": null, "score": 0}, {"text": "impacts and so if we want that we need", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1146, "tokens": 0, "vector": null, "score": 0}, {"text": "to open source it in uh with a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1147, "tokens": 0, "vector": null, "score": 0}, {"text": "permissive license and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1148, "tokens": 0, "vector": null, "score": 0}, {"text": "this took a long time to negotiate but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1149, "tokens": 0, "vector": null, "score": 0}, {"text": "in the end we were allowed to open", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1150, "tokens": 0, "vector": null, "score": 0}, {"text": "source it that way", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1151, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh and so uh basically I think that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1152, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1153, "tokens": 0, "vector": null, "score": 0}, {"text": "our point was that the similarity search", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1154, "tokens": 0, "vector": null, "score": 0}, {"text": "space was not mature yet so that at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1155, "tokens": 0, "vector": null, "score": 0}, {"text": "time in 20 around 2017 it was like", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1156, "tokens": 0, "vector": null, "score": 0}, {"text": "people were using uh flan they were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1157, "tokens": 0, "vector": null, "score": 0}, {"text": "using uh annoy and they were using this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1158, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of libraries which in our", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1159, "tokens": 0, "vector": null, "score": 0}, {"text": "um in our opinion where", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1160, "tokens": 0, "vector": null, "score": 0}, {"text": "I mean not state-of-the-art compared to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1161, "tokens": 0, "vector": null, "score": 0}, {"text": "what what you already had in research", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1162, "tokens": 0, "vector": null, "score": 0}, {"text": "for several years and so uh having a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1163, "tokens": 0, "vector": null, "score": 0}, {"text": "strong solid open source Library which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1164, "tokens": 0, "vector": null, "score": 0}, {"text": "with more or less industrial support and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1165, "tokens": 0, "vector": null, "score": 0}, {"text": "uh that could could have a larger impact", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1166, "tokens": 0, "vector": null, "score": 0}, {"text": "and so um so then we uh we we were", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1167, "tokens": 0, "vector": null, "score": 0}, {"text": "allowed to open source it with the so we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1168, "tokens": 0, "vector": null, "score": 0}, {"text": "got the the the proper license that we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1169, "tokens": 0, "vector": null, "score": 0}, {"text": "wanted and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1170, "tokens": 0, "vector": null, "score": 0}, {"text": "um and basically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1171, "tokens": 0, "vector": null, "score": 0}, {"text": "then then that I mean that ball was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1172, "tokens": 0, "vector": null, "score": 0}, {"text": "rolling and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1173, "tokens": 0, "vector": null, "score": 0}, {"text": "so after that the the history of face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1174, "tokens": 0, "vector": null, "score": 0}, {"text": "was", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1175, "tokens": 0, "vector": null, "score": 0}, {"text": "um several stages of additions of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1176, "tokens": 0, "vector": null, "score": 0}, {"text": "several methods so uh the first one", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1177, "tokens": 0, "vector": null, "score": 0}, {"text": "being hnsw so it became uh when the when", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1178, "tokens": 0, "vector": null, "score": 0}, {"text": "that work uh came out it became pretty", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1179, "tokens": 0, "vector": null, "score": 0}, {"text": "clear that it covered a kind of a space", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1180, "tokens": 0, "vector": null, "score": 0}, {"text": "of operating points where we were really", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1181, "tokens": 0, "vector": null, "score": 0}, {"text": "far from the state of the art so uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1182, "tokens": 0, "vector": null, "score": 0}, {"text": "we implemented or implemented hnsw into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1183, "tokens": 0, "vector": null, "score": 0}, {"text": "face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1184, "tokens": 0, "vector": null, "score": 0}, {"text": "um then there was and um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1185, "tokens": 0, "vector": null, "score": 0}, {"text": "so uh there was a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1186, "tokens": 0, "vector": null, "score": 0}, {"text": "H so there was this method so the so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1187, "tokens": 0, "vector": null, "score": 0}, {"text": "this is interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1188, "tokens": 0, "vector": null, "score": 0}, {"text": "one one uh one uh so when you look at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1189, "tokens": 0, "vector": null, "score": 0}, {"text": "how uh IVF PQ Works uh so you have the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1190, "tokens": 0, "vector": null, "score": 0}, {"text": "problems of the Cross quantization and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1191, "tokens": 0, "vector": null, "score": 0}, {"text": "the second part is how to optimize the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1192, "tokens": 0, "vector": null, "score": 0}, {"text": "scanning of the inverted lists which is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1193, "tokens": 0, "vector": null, "score": 0}, {"text": "the second part of the cost and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1194, "tokens": 0, "vector": null, "score": 0}, {"text": "second part of the costume basically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1195, "tokens": 0, "vector": null, "score": 0}, {"text": "it's the cost is dominated by uh by the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1196, "tokens": 0, "vector": null, "score": 0}, {"text": "memory lookups into the lookup tables so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1197, "tokens": 0, "vector": null, "score": 0}, {"text": "you have lookup tables you do lookups", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1198, "tokens": 0, "vector": null, "score": 0}, {"text": "and the problem is that that modern", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1199, "tokens": 0, "vector": null, "score": 0}, {"text": "processes are not at all efficient for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1200, "tokens": 0, "vector": null, "score": 0}, {"text": "lookups they are efficient for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1201, "tokens": 0, "vector": null, "score": 0}, {"text": "arithmetic throughput but not for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1202, "tokens": 0, "vector": null, "score": 0}, {"text": "lookups and so um so what we did so it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1203, "tokens": 0, "vector": null, "score": 0}, {"text": "not what we did but uh there has been a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1204, "tokens": 0, "vector": null, "score": 0}, {"text": "line of research around storing those", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1205, "tokens": 0, "vector": null, "score": 0}, {"text": "lookups in simd registers and um and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1206, "tokens": 0, "vector": null, "score": 0}, {"text": "there's early work by uh by people from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1207, "tokens": 0, "vector": null, "score": 0}, {"text": "Technicolor um I'm thinking of a guy", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1208, "tokens": 0, "vector": null, "score": 0}, {"text": "named Andre a and um they basically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1209, "tokens": 0, "vector": null, "score": 0}, {"text": "explored this this direction and uh but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1210, "tokens": 0, "vector": null, "score": 0}, {"text": "the the industrial application of this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1211, "tokens": 0, "vector": null, "score": 0}, {"text": "was the the scan uh algorithm or the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1212, "tokens": 0, "vector": null, "score": 0}, {"text": "scan Library uh which was recently open", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1213, "tokens": 0, "vector": null, "score": 0}, {"text": "sourced by Google and basically they", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1214, "tokens": 0, "vector": null, "score": 0}, {"text": "have a very very cleverly optimized", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1215, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1216, "tokens": 0, "vector": null, "score": 0}, {"text": "ivfpq implementation where the whether", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1217, "tokens": 0, "vector": null, "score": 0}, {"text": "the lookups or the lookup tables are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1218, "tokens": 0, "vector": null, "score": 0}, {"text": "started matches this and well the whole", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1219, "tokens": 0, "vector": null, "score": 0}, {"text": "process of uh of computing distances is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1220, "tokens": 0, "vector": null, "score": 0}, {"text": "very well optimized and uh so they they", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1221, "tokens": 0, "vector": null, "score": 0}, {"text": "had very good operating points and so uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1222, "tokens": 0, "vector": null, "score": 0}, {"text": "and so we also imparted this into uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1223, "tokens": 0, "vector": null, "score": 0}, {"text": "into uh into phase", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1224, "tokens": 0, "vector": null, "score": 0}, {"text": "so that's uh that's a bit uh of what we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1225, "tokens": 0, "vector": null, "score": 0}, {"text": "did and I think in terms of so let to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1226, "tokens": 0, "vector": null, "score": 0}, {"text": "come back to uh to uh to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1227, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization which is uh one of the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1228, "tokens": 0, "vector": null, "score": 0}, {"text": "main topics uh uh of of face and also of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1229, "tokens": 0, "vector": null, "score": 0}, {"text": "uh of what we were discussing uh so the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1230, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization currently what we're", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1231, "tokens": 0, "vector": null, "score": 0}, {"text": "looking into is uh so we have the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1232, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantization but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1233, "tokens": 0, "vector": null, "score": 0}, {"text": "um uh actually it's there there are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1234, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization methods that get better", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1235, "tokens": 0, "vector": null, "score": 0}, {"text": "accuracy uh because uh product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1236, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization has this restriction that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1237, "tokens": 0, "vector": null, "score": 0}, {"text": "each sub Vector is encoded separately", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1238, "tokens": 0, "vector": null, "score": 0}, {"text": "and so uh so we lose the kind of uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1239, "tokens": 0, "vector": null, "score": 0}, {"text": "statistical dependence between the sub", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1240, "tokens": 0, "vector": null, "score": 0}, {"text": "vectors even if we do an a rotation so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1241, "tokens": 0, "vector": null, "score": 0}, {"text": "that this dependence is minimized", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1242, "tokens": 0, "vector": null, "score": 0}, {"text": "um and so what we are looking very much", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1243, "tokens": 0, "vector": null, "score": 0}, {"text": "into here currently is additive", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1244, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization methods", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1245, "tokens": 0, "vector": null, "score": 0}, {"text": "and the additive quantization means that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1246, "tokens": 0, "vector": null, "score": 0}, {"text": "instead of having sub vectors and you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1247, "tokens": 0, "vector": null, "score": 0}, {"text": "concatenate sub vectors you have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1248, "tokens": 0, "vector": null, "score": 0}, {"text": "you have a lookup tables that span the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1249, "tokens": 0, "vector": null, "score": 0}, {"text": "whole Vector to encode and but you have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1250, "tokens": 0, "vector": null, "score": 0}, {"text": "several of the those lookup tables and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1251, "tokens": 0, "vector": null, "score": 0}, {"text": "you pick one vector from each of the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1252, "tokens": 0, "vector": null, "score": 0}, {"text": "lookup tables and you just sum them up", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1253, "tokens": 0, "vector": null, "score": 0}, {"text": "so and then you you have to encode only", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1254, "tokens": 0, "vector": null, "score": 0}, {"text": "the the ID of the vector that you picked", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1255, "tokens": 0, "vector": null, "score": 0}, {"text": "in each of the lookup tables", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1256, "tokens": 0, "vector": null, "score": 0}, {"text": "so it can be seen as a generalization of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1257, "tokens": 0, "vector": null, "score": 0}, {"text": "PQ because if the lookup tables are zero", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1258, "tokens": 0, "vector": null, "score": 0}, {"text": "outside of a sub Vector if each lookup", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1259, "tokens": 0, "vector": null, "score": 0}, {"text": "table is zero outside of sub Vector then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1260, "tokens": 0, "vector": null, "score": 0}, {"text": "it boils down to doing PQ", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1261, "tokens": 0, "vector": null, "score": 0}, {"text": "um it's a generalization so it has the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1262, "tokens": 0, "vector": null, "score": 0}, {"text": "potential to be more accurate and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1263, "tokens": 0, "vector": null, "score": 0}, {"text": "problem is uh what it it's much more", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1264, "tokens": 0, "vector": null, "score": 0}, {"text": "complex to train the lookout tables and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1265, "tokens": 0, "vector": null, "score": 0}, {"text": "to do the encoding the encoding is uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1266, "tokens": 0, "vector": null, "score": 0}, {"text": "it's not like just finding the nearest", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1267, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbors it's um it's a it's a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1268, "tokens": 0, "vector": null, "score": 0}, {"text": "combinatorial optimization problem uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1269, "tokens": 0, "vector": null, "score": 0}, {"text": "that that is NP hired if you if you want", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1270, "tokens": 0, "vector": null, "score": 0}, {"text": "to solve it exactly and so you solve it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1271, "tokens": 0, "vector": null, "score": 0}, {"text": "only by approximations", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1272, "tokens": 0, "vector": null, "score": 0}, {"text": "and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1273, "tokens": 0, "vector": null, "score": 0}, {"text": "uh and so basically we are looking into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1274, "tokens": 0, "vector": null, "score": 0}, {"text": "how to do those uh approximations", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1275, "tokens": 0, "vector": null, "score": 0}, {"text": "efficiently there are several uh several", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1276, "tokens": 0, "vector": null, "score": 0}, {"text": "directions for this and two of them are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1277, "tokens": 0, "vector": null, "score": 0}, {"text": "implemented in Phase the first one is uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1278, "tokens": 0, "vector": null, "score": 0}, {"text": "local search quantization which is uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1279, "tokens": 0, "vector": null, "score": 0}, {"text": "um which is a work via from the PHD of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1280, "tokens": 0, "vector": null, "score": 0}, {"text": "Julieta Martinez and uh that uh that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1281, "tokens": 0, "vector": null, "score": 0}, {"text": "offers a good trade-off between uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1282, "tokens": 0, "vector": null, "score": 0}, {"text": "between the accuracy and encoding speed", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1283, "tokens": 0, "vector": null, "score": 0}, {"text": "uh knowing that uh that encoding speed", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1284, "tokens": 0, "vector": null, "score": 0}, {"text": "cannot be as good as that of PQ but it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1285, "tokens": 0, "vector": null, "score": 0}, {"text": "still it's based on the simulated", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1286, "tokens": 0, "vector": null, "score": 0}, {"text": "annealing uh from with random", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1287, "tokens": 0, "vector": null, "score": 0}, {"text": "industrialization and it kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1288, "tokens": 0, "vector": null, "score": 0}, {"text": "converges into", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1289, "tokens": 0, "vector": null, "score": 0}, {"text": "um into a relatively good additive", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1290, "tokens": 0, "vector": null, "score": 0}, {"text": "additive conversation method", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1291, "tokens": 0, "vector": null, "score": 0}, {"text": "and the second one is just residual", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1292, "tokens": 0, "vector": null, "score": 0}, {"text": "quantizers so that residual quantizes", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1293, "tokens": 0, "vector": null, "score": 0}, {"text": "means you use the you use the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1294, "tokens": 0, "vector": null, "score": 0}, {"text": "level quantizer and then you keep the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1295, "tokens": 0, "vector": null, "score": 0}, {"text": "residual with respect to the vector that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1296, "tokens": 0, "vector": null, "score": 0}, {"text": "you want to encode and that gets you a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1297, "tokens": 0, "vector": null, "score": 0}, {"text": "second level quantizer and then you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1298, "tokens": 0, "vector": null, "score": 0}, {"text": "encode it with a second level quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1299, "tokens": 0, "vector": null, "score": 0}, {"text": "etc etc", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1300, "tokens": 0, "vector": null, "score": 0}, {"text": "um and but if you do that in a greedy", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1301, "tokens": 0, "vector": null, "score": 0}, {"text": "fashion it's not good and so in order to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1302, "tokens": 0, "vector": null, "score": 0}, {"text": "avoid to do this in a greedy fashion", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1303, "tokens": 0, "vector": null, "score": 0}, {"text": "you'd use beam search and so which is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1304, "tokens": 0, "vector": null, "score": 0}, {"text": "expensive so again there's a trade-off", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1305, "tokens": 0, "vector": null, "score": 0}, {"text": "in terms of of speed versus accuracy", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1306, "tokens": 0, "vector": null, "score": 0}, {"text": "yeah so that's um that's a bit what we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1307, "tokens": 0, "vector": null, "score": 0}, {"text": "what we are currently working on uh in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1308, "tokens": 0, "vector": null, "score": 0}, {"text": "Phase uh So currently", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1309, "tokens": 0, "vector": null, "score": 0}, {"text": "um just to say So within uh within uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1310, "tokens": 0, "vector": null, "score": 0}, {"text": "meta the the team the core team that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1311, "tokens": 0, "vector": null, "score": 0}, {"text": "works around face is uh is about five", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1312, "tokens": 0, "vector": null, "score": 0}, {"text": "people uh not everyone is working", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1313, "tokens": 0, "vector": null, "score": 0}, {"text": "full-time on this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1314, "tokens": 0, "vector": null, "score": 0}, {"text": "um but it's that's that's about the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1315, "tokens": 0, "vector": null, "score": 0}, {"text": "skill of the efforts at Facebook it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1316, "tokens": 0, "vector": null, "score": 0}, {"text": "super cool yeah that was a brilliant", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1317, "tokens": 0, "vector": null, "score": 0}, {"text": "tour of product quantization so much", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1318, "tokens": 0, "vector": null, "score": 0}, {"text": "knowledge um I'm also really excited in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1319, "tokens": 0, "vector": null, "score": 0}, {"text": "this VBA podcast to welcome Abdel", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1320, "tokens": 0, "vector": null, "score": 0}, {"text": "Rodriguez to the webia podcast uh Abdel", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1321, "tokens": 0, "vector": null, "score": 0}, {"text": "is working on this kind of product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1322, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization weavier uh Abdul could you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1323, "tokens": 0, "vector": null, "score": 0}, {"text": "tell us about kind of where we're at", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1324, "tokens": 0, "vector": null, "score": 0}, {"text": "with the product quantization and any", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1325, "tokens": 0, "vector": null, "score": 0}, {"text": "questions you have for Matisse", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1326, "tokens": 0, "vector": null, "score": 0}, {"text": "so thanks Connor and thanks uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1327, "tokens": 0, "vector": null, "score": 0}, {"text": "Matthias for for the nice history and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1328, "tokens": 0, "vector": null, "score": 0}, {"text": "introduction so I I actually we are a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1329, "tokens": 0, "vector": null, "score": 0}, {"text": "very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1330, "tokens": 0, "vector": null, "score": 0}, {"text": "in the very beginning of the product", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1331, "tokens": 0, "vector": null, "score": 0}, {"text": "quantization part now because we we have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1332, "tokens": 0, "vector": null, "score": 0}, {"text": "been", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1333, "tokens": 0, "vector": null, "score": 0}, {"text": "trying to improve the indexing algorithm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1334, "tokens": 0, "vector": null, "score": 0}, {"text": "and and trying to make it scalable on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1335, "tokens": 0, "vector": null, "score": 0}, {"text": "when when we have more data", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1336, "tokens": 0, "vector": null, "score": 0}, {"text": "well we have we will have more", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1337, "tokens": 0, "vector": null, "score": 0}, {"text": "requirements and and we we have to deal", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1338, "tokens": 0, "vector": null, "score": 0}, {"text": "with it and we are currently", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1339, "tokens": 0, "vector": null, "score": 0}, {"text": "experimenting with having some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1340, "tokens": 0, "vector": null, "score": 0}, {"text": "information on disk some information on", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1341, "tokens": 0, "vector": null, "score": 0}, {"text": "memory and and the part that we need in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1342, "tokens": 0, "vector": null, "score": 0}, {"text": "memory of course is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1343, "tokens": 0, "vector": null, "score": 0}, {"text": "some representation of the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1344, "tokens": 0, "vector": null, "score": 0}, {"text": "and uh we are currently playing a bit", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1345, "tokens": 0, "vector": null, "score": 0}, {"text": "with the with the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1346, "tokens": 0, "vector": null, "score": 0}, {"text": "a compression of these vectors and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1347, "tokens": 0, "vector": null, "score": 0}, {"text": "and again we are we are scratching the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1348, "tokens": 0, "vector": null, "score": 0}, {"text": "surface here now we we have a very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1349, "tokens": 0, "vector": null, "score": 0}, {"text": "uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1350, "tokens": 0, "vector": null, "score": 0}, {"text": "very simple implementation of uh of PQ", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1351, "tokens": 0, "vector": null, "score": 0}, {"text": "currently with k-means and and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1352, "tokens": 0, "vector": null, "score": 0}, {"text": "segmenting the the vectors", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1353, "tokens": 0, "vector": null, "score": 0}, {"text": "and we would like to explore a bit the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1354, "tokens": 0, "vector": null, "score": 0}, {"text": "optimized product quantization the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1355, "tokens": 0, "vector": null, "score": 0}, {"text": "optimized PQ next", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1356, "tokens": 0, "vector": null, "score": 0}, {"text": "and one thing we we have is one problem", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1357, "tokens": 0, "vector": null, "score": 0}, {"text": "we have is that normally we don't build", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1358, "tokens": 0, "vector": null, "score": 0}, {"text": "uh so we we don't have all the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1359, "tokens": 0, "vector": null, "score": 0}, {"text": "information and we build an index in but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1360, "tokens": 0, "vector": null, "score": 0}, {"text": "but we we we normally build", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1361, "tokens": 0, "vector": null, "score": 0}, {"text": "incrementally our our indexing which", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1362, "tokens": 0, "vector": null, "score": 0}, {"text": "means we need some some algorithms that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1363, "tokens": 0, "vector": null, "score": 0}, {"text": "could take over this uh capacity to to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1364, "tokens": 0, "vector": null, "score": 0}, {"text": "add new vectors or delete vectors that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1365, "tokens": 0, "vector": null, "score": 0}, {"text": "you have instead of just building", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1366, "tokens": 0, "vector": null, "score": 0}, {"text": "everything together and of course", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1367, "tokens": 0, "vector": null, "score": 0}, {"text": "k-means", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1368, "tokens": 0, "vector": null, "score": 0}, {"text": "could somehow be incrementally updated", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1369, "tokens": 0, "vector": null, "score": 0}, {"text": "if you keep at least the number of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1370, "tokens": 0, "vector": null, "score": 0}, {"text": "clusters which is uh something that we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1371, "tokens": 0, "vector": null, "score": 0}, {"text": "have but I'm also wondering about in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1372, "tokens": 0, "vector": null, "score": 0}, {"text": "case of up the optim opq this rotation", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1373, "tokens": 0, "vector": null, "score": 0}, {"text": "Matrix how how how hard in terms of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1374, "tokens": 0, "vector": null, "score": 0}, {"text": "performance would it be to to make it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1375, "tokens": 0, "vector": null, "score": 0}, {"text": "also incrementally updatable things like", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1376, "tokens": 0, "vector": null, "score": 0}, {"text": "that I I don't know if you have some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1377, "tokens": 0, "vector": null, "score": 0}, {"text": "experience in this direction that it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1378, "tokens": 0, "vector": null, "score": 0}, {"text": "would be nice to to hear a bit about it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1379, "tokens": 0, "vector": null, "score": 0}, {"text": "sure uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1380, "tokens": 0, "vector": null, "score": 0}, {"text": "I think it's a it's a it's an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1381, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting and recurrent problem", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1382, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1383, "tokens": 0, "vector": null, "score": 0}, {"text": "uh what happens is that uh so I think", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1384, "tokens": 0, "vector": null, "score": 0}, {"text": "that there are two things to distinguish", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1385, "tokens": 0, "vector": null, "score": 0}, {"text": "here it's which is an increasing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1386, "tokens": 0, "vector": null, "score": 0}, {"text": "database database side size uh because I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1387, "tokens": 0, "vector": null, "score": 0}, {"text": "mean indeed you add incrementally you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1388, "tokens": 0, "vector": null, "score": 0}, {"text": "add more vectors uh the the other can", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1389, "tokens": 0, "vector": null, "score": 0}, {"text": "the other thing is um is the drift in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1390, "tokens": 0, "vector": null, "score": 0}, {"text": "the data distribution addressed in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1391, "tokens": 0, "vector": null, "score": 0}, {"text": "data distribution is in addition to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1392, "tokens": 0, "vector": null, "score": 0}, {"text": "adding vectors they have they have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1393, "tokens": 0, "vector": null, "score": 0}, {"text": "behaviors that you've never seen before", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1394, "tokens": 0, "vector": null, "score": 0}, {"text": "and during the training phase", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1395, "tokens": 0, "vector": null, "score": 0}, {"text": "um I think the increasing database size", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1396, "tokens": 0, "vector": null, "score": 0}, {"text": "size is not necessarily a problem if you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1397, "tokens": 0, "vector": null, "score": 0}, {"text": "if you've had enough data to train from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1398, "tokens": 0, "vector": null, "score": 0}, {"text": "then uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1399, "tokens": 0, "vector": null, "score": 0}, {"text": "to be to be very concrete a way I would", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1400, "tokens": 0, "vector": null, "score": 0}, {"text": "Implement a database where you don't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1401, "tokens": 0, "vector": null, "score": 0}, {"text": "know in the beginning how big it's going", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1402, "tokens": 0, "vector": null, "score": 0}, {"text": "to grow it's uh you accept the first 10", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1403, "tokens": 0, "vector": null, "score": 0}, {"text": "000 vectors you don't encode them at all", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1404, "tokens": 0, "vector": null, "score": 0}, {"text": "you just keep them as is if you then you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1405, "tokens": 0, "vector": null, "score": 0}, {"text": "when you go to a million you you do some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1406, "tokens": 0, "vector": null, "score": 0}, {"text": "some cheap or some simple indexing say", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1407, "tokens": 0, "vector": null, "score": 0}, {"text": "with hnsw", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1408, "tokens": 0, "vector": null, "score": 0}, {"text": "and then when it grows beyond that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1409, "tokens": 0, "vector": null, "score": 0}, {"text": "and you start to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1410, "tokens": 0, "vector": null, "score": 0}, {"text": "to require some type of encoding then", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1411, "tokens": 0, "vector": null, "score": 0}, {"text": "you can start thinking of uh training a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1412, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantizer or some some other", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1413, "tokens": 0, "vector": null, "score": 0}, {"text": "type of quantizer but at that point you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1414, "tokens": 0, "vector": null, "score": 0}, {"text": "have enough training vectors to actually", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1415, "tokens": 0, "vector": null, "score": 0}, {"text": "actually train it so so it makes sense", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1416, "tokens": 0, "vector": null, "score": 0}, {"text": "to to go to the to go that path", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1417, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1418, "tokens": 0, "vector": null, "score": 0}, {"text": "uh which you I mean if you after if you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1419, "tokens": 0, "vector": null, "score": 0}, {"text": "have 10 000 vectors you can't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1420, "tokens": 0, "vector": null, "score": 0}, {"text": "uh 10 000 vectors use no I it's it's a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1421, "tokens": 0, "vector": null, "score": 0}, {"text": "bit too small to to even train your", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1422, "tokens": 0, "vector": null, "score": 0}, {"text": "product quantizer so you would even want", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1423, "tokens": 0, "vector": null, "score": 0}, {"text": "to have more", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1424, "tokens": 0, "vector": null, "score": 0}, {"text": "um the other problem is uh is uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1425, "tokens": 0, "vector": null, "score": 0}, {"text": "drifting the data distribution which uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1426, "tokens": 0, "vector": null, "score": 0}, {"text": "which we observe also with some kind of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1427, "tokens": 0, "vector": null, "score": 0}, {"text": "applications uh one one funny anecdotes", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1428, "tokens": 0, "vector": null, "score": 0}, {"text": "maybe is that we um uh we we have we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1429, "tokens": 0, "vector": null, "score": 0}, {"text": "have an indexing we observe really a lot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1430, "tokens": 0, "vector": null, "score": 0}, {"text": "of data drift in in images that come in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1431, "tokens": 0, "vector": null, "score": 0}, {"text": "that comes with that are uploaded to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1432, "tokens": 0, "vector": null, "score": 0}, {"text": "Facebook so I've worked together with", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1433, "tokens": 0, "vector": null, "score": 0}, {"text": "people who index those images and you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1434, "tokens": 0, "vector": null, "score": 0}, {"text": "have data drifts with memes but also", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1435, "tokens": 0, "vector": null, "score": 0}, {"text": "when there's a new Instagram filter that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1436, "tokens": 0, "vector": null, "score": 0}, {"text": "comes out that kind of you see a drift", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1437, "tokens": 0, "vector": null, "score": 0}, {"text": "in the in the type of images that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1438, "tokens": 0, "vector": null, "score": 0}, {"text": "get and uh and so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1439, "tokens": 0, "vector": null, "score": 0}, {"text": "so it's a and and the problem with that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1440, "tokens": 0, "vector": null, "score": 0}, {"text": "is if you if you update the training", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1441, "tokens": 0, "vector": null, "score": 0}, {"text": "yeah the main problem with any quantizer", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1442, "tokens": 0, "vector": null, "score": 0}, {"text": "is that if you if you update the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1443, "tokens": 0, "vector": null, "score": 0}, {"text": "training then uh or if you do for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1444, "tokens": 0, "vector": null, "score": 0}, {"text": "example online K means to adapt to some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1445, "tokens": 0, "vector": null, "score": 0}, {"text": "trades of the k-means then the the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1446, "tokens": 0, "vector": null, "score": 0}, {"text": "the vectors that are newly encoded they", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1447, "tokens": 0, "vector": null, "score": 0}, {"text": "are not comparable anymore with the the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1448, "tokens": 0, "vector": null, "score": 0}, {"text": "ones that were encoded before and so um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1449, "tokens": 0, "vector": null, "score": 0}, {"text": "and so it's it's not clear to me by", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1450, "tokens": 0, "vector": null, "score": 0}, {"text": "default how uh how to how to use those", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1451, "tokens": 0, "vector": null, "score": 0}, {"text": "updated centroids", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1452, "tokens": 0, "vector": null, "score": 0}, {"text": "so um yeah it's a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1453, "tokens": 0, "vector": null, "score": 0}, {"text": "something to think of yeah so when you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1454, "tokens": 0, "vector": null, "score": 0}, {"text": "have the online clustering you can move", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1455, "tokens": 0, "vector": null, "score": 0}, {"text": "the mean but then you need to recompute", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1456, "tokens": 0, "vector": null, "score": 0}, {"text": "the centralizers at like very basic", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1457, "tokens": 0, "vector": null, "score": 0}, {"text": "understanding the high level idea yeah", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1458, "tokens": 0, "vector": null, "score": 0}, {"text": "it also depends I guess if you have more", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1459, "tokens": 0, "vector": null, "score": 0}, {"text": "intensive", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1460, "tokens": 0, "vector": null, "score": 0}, {"text": "changes in some parts you don't have to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1461, "tokens": 0, "vector": null, "score": 0}, {"text": "recode everything but that part's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1462, "tokens": 0, "vector": null, "score": 0}, {"text": "affected I would guess but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1463, "tokens": 0, "vector": null, "score": 0}, {"text": "mm-hmm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1464, "tokens": 0, "vector": null, "score": 0}, {"text": "so maybe we'll also transition to the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1465, "tokens": 0, "vector": null, "score": 0}, {"text": "topic of generally the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1466, "tokens": 0, "vector": null, "score": 0}, {"text": "wrapping the vector index around a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1467, "tokens": 0, "vector": null, "score": 0}, {"text": "library compared to a database so maybe", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1468, "tokens": 0, "vector": null, "score": 0}, {"text": "edian could um explain kind of the some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1469, "tokens": 0, "vector": null, "score": 0}, {"text": "of the features of the database and the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1470, "tokens": 0, "vector": null, "score": 0}, {"text": "distinction between how you're packaging", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1471, "tokens": 0, "vector": null, "score": 0}, {"text": "up the vector index", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1472, "tokens": 0, "vector": null, "score": 0}, {"text": "so yeah sure this I think we've we've", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1473, "tokens": 0, "vector": null, "score": 0}, {"text": "discussed this uh before already in in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1474, "tokens": 0, "vector": null, "score": 0}, {"text": "one of the podcasts but it is a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1475, "tokens": 0, "vector": null, "score": 0}, {"text": "recurring topic and we do see that that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1476, "tokens": 0, "vector": null, "score": 0}, {"text": "coming up from from users", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1477, "tokens": 0, "vector": null, "score": 0}, {"text": "um whereas I think one of the the first", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1478, "tokens": 0, "vector": null, "score": 0}, {"text": "and most obvious distinct differences", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1479, "tokens": 0, "vector": null, "score": 0}, {"text": "that we see and end of charismatize I'm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1480, "tokens": 0, "vector": null, "score": 0}, {"text": "also super interested about your", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1481, "tokens": 0, "vector": null, "score": 0}, {"text": "perspective on this as someone who's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1482, "tokens": 0, "vector": null, "score": 0}, {"text": "been working on the library because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1483, "tokens": 0, "vector": null, "score": 0}, {"text": "mine's a bit biased of course because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1484, "tokens": 0, "vector": null, "score": 0}, {"text": "I've been working on the database side", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1485, "tokens": 0, "vector": null, "score": 0}, {"text": "uh what one that that comes up very high", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1486, "tokens": 0, "vector": null, "score": 0}, {"text": "on the list typically is this this", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1487, "tokens": 0, "vector": null, "score": 0}, {"text": "incremental updateability which I think", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1488, "tokens": 0, "vector": null, "score": 0}, {"text": "is not like this can be a library versus", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1489, "tokens": 0, "vector": null, "score": 0}, {"text": "database part but it doesn't necessarily", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1490, "tokens": 0, "vector": null, "score": 0}, {"text": "have to be because hnsw you can use it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1491, "tokens": 0, "vector": null, "score": 0}, {"text": "purely from a library perspective and it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1492, "tokens": 0, "vector": null, "score": 0}, {"text": "is incrementally changeable uh something", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1493, "tokens": 0, "vector": null, "score": 0}, {"text": "that needs to be trained beforehand so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1494, "tokens": 0, "vector": null, "score": 0}, {"text": "for example a quantizer that is maybe", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1495, "tokens": 0, "vector": null, "score": 0}, {"text": "not as updatable so in in this case", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1496, "tokens": 0, "vector": null, "score": 0}, {"text": "um the library versus database technical", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1497, "tokens": 0, "vector": null, "score": 0}, {"text": "distinction doesn't so much", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1498, "tokens": 0, "vector": null, "score": 0}, {"text": "um", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1499, "tokens": 0, "vector": null, "score": 0}, {"text": "sort of determine of whether it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1500, "tokens": 0, "vector": null, "score": 0}, {"text": "updatable or not more that within the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1501, "tokens": 0, "vector": null, "score": 0}, {"text": "database you tend to go for these kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1502, "tokens": 0, "vector": null, "score": 0}, {"text": "of updatable cases so for us", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1503, "tokens": 0, "vector": null, "score": 0}, {"text": "um from a database perspective typically", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1504, "tokens": 0, "vector": null, "score": 0}, {"text": "what we say the kind of ux that we want", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1505, "tokens": 0, "vector": null, "score": 0}, {"text": "is the one that people know from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1506, "tokens": 0, "vector": null, "score": 0}, {"text": "non-machine learning databases so if I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1507, "tokens": 0, "vector": null, "score": 0}, {"text": "just spin up in my SQL database spin up", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1508, "tokens": 0, "vector": null, "score": 0}, {"text": "because Android database typically I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1509, "tokens": 0, "vector": null, "score": 0}, {"text": "should start using it and I don't", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1510, "tokens": 0, "vector": null, "score": 0}, {"text": "necessarily know what I'm going to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1511, "tokens": 0, "vector": null, "score": 0}, {"text": "with it tomorrow I might update", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1512, "tokens": 0, "vector": null, "score": 0}, {"text": "something I might delete something I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1513, "tokens": 0, "vector": null, "score": 0}, {"text": "might read in between I might do that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1514, "tokens": 0, "vector": null, "score": 0}, {"text": "all concurrently", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1515, "tokens": 0, "vector": null, "score": 0}, {"text": "um and then of course you have to do", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1516, "tokens": 0, "vector": null, "score": 0}, {"text": "capacity planning there as well in some", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1517, "tokens": 0, "vector": null, "score": 0}, {"text": "databases scale more dynamically than", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1518, "tokens": 0, "vector": null, "score": 0}, {"text": "others but this is a big part sort of", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1519, "tokens": 0, "vector": null, "score": 0}, {"text": "this this usage journey of using it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1520, "tokens": 0, "vector": null, "score": 0}, {"text": "um yeah directly basically uh um or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1521, "tokens": 0, "vector": null, "score": 0}, {"text": "we're using it like a like a database", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1522, "tokens": 0, "vector": null, "score": 0}, {"text": "but there's there's uh way more so so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1523, "tokens": 0, "vector": null, "score": 0}, {"text": "one of the things for example that's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1524, "tokens": 0, "vector": null, "score": 0}, {"text": "also super important to me is the kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1525, "tokens": 0, "vector": null, "score": 0}, {"text": "of durability aspect failure recovery", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1526, "tokens": 0, "vector": null, "score": 0}, {"text": "mode so so how does it react so so for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1527, "tokens": 0, "vector": null, "score": 0}, {"text": "example something I think an in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1528, "tokens": 0, "vector": null, "score": 0}, {"text": "placement has correct me if I'm I'm", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1529, "tokens": 0, "vector": null, "score": 0}, {"text": "wrong I think", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1530, "tokens": 0, "vector": null, "score": 0}, {"text": "um what I typically see in libraries for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1531, "tokens": 0, "vector": null, "score": 0}, {"text": "persistence is snapshotting that you", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1532, "tokens": 0, "vector": null, "score": 0}, {"text": "would build something and once it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1533, "tokens": 0, "vector": null, "score": 0}, {"text": "built you would snapshot it to disk and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1534, "tokens": 0, "vector": null, "score": 0}, {"text": "then you could load the the snapshot", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1535, "tokens": 0, "vector": null, "score": 0}, {"text": "um whereas in in a database such as VBA", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1536, "tokens": 0, "vector": null, "score": 0}, {"text": "for example", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1537, "tokens": 0, "vector": null, "score": 0}, {"text": "um the the update process itself is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1538, "tokens": 0, "vector": null, "score": 0}, {"text": "already persistent so if vv8 crashes I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1539, "tokens": 0, "vector": null, "score": 0}, {"text": "don't know let's say you import 10", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1540, "tokens": 0, "vector": null, "score": 0}, {"text": "million and bb8 crashes at number 7", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1541, "tokens": 0, "vector": null, "score": 0}, {"text": "million then you can just restart it and", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1542, "tokens": 0, "vector": null, "score": 0}, {"text": "import 7 million and one so so this kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1543, "tokens": 0, "vector": null, "score": 0}, {"text": "of incremental durability crash recovery", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1544, "tokens": 0, "vector": null, "score": 0}, {"text": "um everything that's written is written", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1545, "tokens": 0, "vector": null, "score": 0}, {"text": "into a writer headlock is is a big thing", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1546, "tokens": 0, "vector": null, "score": 0}, {"text": "and then um and maybe that's also an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1547, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting one uh with Facebook because", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1548, "tokens": 0, "vector": null, "score": 0}, {"text": "I think there's a a separate library", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1549, "tokens": 0, "vector": null, "score": 0}, {"text": "that I believe is not not exactly face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1550, "tokens": 0, "vector": null, "score": 0}, {"text": "but but built on top of face that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1551, "tokens": 0, "vector": null, "score": 0}, {"text": "distributes a face across multiple", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1552, "tokens": 0, "vector": null, "score": 0}, {"text": "machines and that is also something", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1553, "tokens": 0, "vector": null, "score": 0}, {"text": "that's very big in the in the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1554, "tokens": 0, "vector": null, "score": 0}, {"text": "um in yeah for vv8 or for databases in", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1555, "tokens": 0, "vector": null, "score": 0}, {"text": "general so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1556, "tokens": 0, "vector": null, "score": 0}, {"text": "um yeah the whole scaling aspect is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1557, "tokens": 0, "vector": null, "score": 0}, {"text": "something that you get out of the box", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1558, "tokens": 0, "vector": null, "score": 0}, {"text": "for free as well that's that's my short", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1559, "tokens": 0, "vector": null, "score": 0}, {"text": "my short overview of the the differences", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1560, "tokens": 0, "vector": null, "score": 0}, {"text": "but I'm very curious to hear yours as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1561, "tokens": 0, "vector": null, "score": 0}, {"text": "well in the type yeah sure uh so", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1562, "tokens": 0, "vector": null, "score": 0}, {"text": "um I think that's face explicitly tries", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1563, "tokens": 0, "vector": null, "score": 0}, {"text": "not not to go into the field of being a", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1564, "tokens": 0, "vector": null, "score": 0}, {"text": "general purpose uh Library so there are", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1565, "tokens": 0, "vector": null, "score": 0}, {"text": "two reasons of that the first one is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1566, "tokens": 0, "vector": null, "score": 0}, {"text": "that I think that face is already a very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1567, "tokens": 0, "vector": null, "score": 0}, {"text": "complex piece of software uh if you if", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1568, "tokens": 0, "vector": null, "score": 0}, {"text": "you were to have to support that it", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1569, "tokens": 0, "vector": null, "score": 0}, {"text": "would mean that the number of code lines", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1570, "tokens": 0, "vector": null, "score": 0}, {"text": "would be multiplied by a factor three or", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1571, "tokens": 0, "vector": null, "score": 0}, {"text": "something which is not something we we", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1572, "tokens": 0, "vector": null, "score": 0}, {"text": "plan to plan to do the second thing also", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1573, "tokens": 0, "vector": null, "score": 0}, {"text": "is that in general I observed that SQL", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1574, "tokens": 0, "vector": null, "score": 0}, {"text": "databases are I don't know about vv8 but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1575, "tokens": 0, "vector": null, "score": 0}, {"text": "very often databases have", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1576, "tokens": 0, "vector": null, "score": 0}, {"text": "an order of magnitude storage more than", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1577, "tokens": 0, "vector": null, "score": 0}, {"text": "what's strictly required by the amount", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1578, "tokens": 0, "vector": null, "score": 0}, {"text": "of data that you have in this for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1579, "tokens": 0, "vector": null, "score": 0}, {"text": "example I've read somewhere guidelines", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1580, "tokens": 0, "vector": null, "score": 0}, {"text": "that if you want to set up a mySQL", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1581, "tokens": 0, "vector": null, "score": 0}, {"text": "database then you should plan for uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1582, "tokens": 0, "vector": null, "score": 0}, {"text": "five times as many disk space as what uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1583, "tokens": 0, "vector": null, "score": 0}, {"text": "the the raw data I would use and this is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1584, "tokens": 0, "vector": null, "score": 0}, {"text": "something that's face", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1585, "tokens": 0, "vector": null, "score": 0}, {"text": "we want to give the opportunity for", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1586, "tokens": 0, "vector": null, "score": 0}, {"text": "people to you know use 90 of their RAM", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1587, "tokens": 0, "vector": null, "score": 0}, {"text": "and store the an index in that and that", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1588, "tokens": 0, "vector": null, "score": 0}, {"text": "they don't wonder where uh about too", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1589, "tokens": 0, "vector": null, "score": 0}, {"text": "much about overheads basically and so uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1590, "tokens": 0, "vector": null, "score": 0}, {"text": "and this is", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1591, "tokens": 0, "vector": null, "score": 0}, {"text": "uh yeah it would it's it happened", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1592, "tokens": 0, "vector": null, "score": 0}, {"text": "several times that we're operating very", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1593, "tokens": 0, "vector": null, "score": 0}, {"text": "close to uh what's possible on a single", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1594, "tokens": 0, "vector": null, "score": 0}, {"text": "machine and uh for this uh we we give up", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1595, "tokens": 0, "vector": null, "score": 0}, {"text": "many functionalities like what you say", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1596, "tokens": 0, "vector": null, "score": 0}, {"text": "uh being able to do uh ID lookups uh", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1597, "tokens": 0, "vector": null, "score": 0}, {"text": "being able to", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1598, "tokens": 0, "vector": null, "score": 0}, {"text": "be being able to snapshots or this kind", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1599, "tokens": 0, "vector": null, "score": 0}, {"text": "of things and it's", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1600, "tokens": 0, "vector": null, "score": 0}, {"text": "you know that's that's the point but", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1601, "tokens": 0, "vector": null, "score": 0}, {"text": "definitely I wouldn't recommend face as", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1602, "tokens": 0, "vector": null, "score": 0}, {"text": "a final production ready database system", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1603, "tokens": 0, "vector": null, "score": 0}, {"text": "it's it's really intended to be at the", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1604, "tokens": 0, "vector": null, "score": 0}, {"text": "core of maybe another", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1605, "tokens": 0, "vector": null, "score": 0}, {"text": "more broad scale database system", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1606, "tokens": 0, "vector": null, "score": 0}, {"text": "fantastic well thank you so much from", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1607, "tokens": 0, "vector": null, "score": 0}, {"text": "tires Abdel Eddie and such an", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1608, "tokens": 0, "vector": null, "score": 0}, {"text": "information dense podcast so interesting", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1609, "tokens": 0, "vector": null, "score": 0}, {"text": "learning about all these things thank", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1610, "tokens": 0, "vector": null, "score": 0}, {"text": "you so much for your time", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1611, "tokens": 0, "vector": null, "score": 0}, {"text": "yeah thank you thank you nice yeah yeah", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1612, "tokens": 0, "vector": null, "score": 0}, {"text": "thank you all yeah I", "doc_name": "Matthijs Douze on Quantization and FAISS - Weaviate Podcast #29", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1613, "tokens": 0, "vector": null, "score": 0}]}