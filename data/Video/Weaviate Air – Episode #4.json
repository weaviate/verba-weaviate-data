{"text": "Product from Juraj: https://www.labelator.io Spark connector project: ... \nforeign[Music]episode of viviate air I'm reallyexcited to have you all here like yousee we are already waving to you becauselike everyone is super excited aboutthis new episode and it's it's a niceone because like we're kicking off inthe new year so we are all super excitedabout it uh so you should be really niceand fun so thank you for watching andthank you for listening whether you liveor you're watching the video later uhI'm absolutely pumped to see everysingle one of you hereum so because this is live please ask usquestions as we go right like I will ifif I see any questions popping up like Iwill go and share them with uh like theaudience here and then potentially we'llelect the best person to answer thequestion hopefully it won't be me buthey you never knowum so for today I thought that maybe wecould give you a quick uh update interms of what should you expect fromthis episode right so first up we'llhave our special guest URI who will talkto you about uh label later which is aproduct that he built with weaviate uhso I'm really excited about actuallylearning that what he's built how doesit work and uh euri promised me thatthere will be a demo so how cool is thatuh then later on we'll have Etienne uhour our CTO who will come and talk toyou about the Outlook of vv8 for 2023 sobasically what you may expect of likewhat kind of things can you expect tohappen around vv8 it's not necessarily Aroadmap itself but it's close enoughlike this is kind of like the directionthe general idea and now let him talkabout it more uh then Zen we'll talkabout the spark connectorfor vv8 we've had like a couple of blogposts around it uh but um but Zen reallywanted to also do like a quick demo andthen show you off uh how everythingworks so this is super exciting uh Conorwill talk about the beer benchmarks inviviate and I'm so proud of myself thatI spelled beer correctly but I think umyou know for those of you for for foryou that beer is normal you probablycringe at me but hey I'll take that uhand then Erica will talk about uh someCommunity questions because uh we doreceive a whole bunch of questions uh onon the community slack on and we tend toalways help and and answer them and thensome of them they're worth highlightinguh so Erica will highlight threequestions three uh and then she'll goover them and that'll be cool and thenat the end if you have enough patienceto stick with it and then wait until theend I like to actually show you apreview of our new new website so likethere will be a huge update to the newdocument to the documentation for thereview documentation and in general willbe changing quite a bit around the VividIO websiteum so yeah this is basically the planfor uh this session uh so without anyfurther Ado I want to pass on the buttonto your our special guest who talked tous about the label later hey you'reright welcome to uh Vivid air I'm sohappy you're herehi thank you so much for having me yeahand thank you for the opportunity toshow what I've built with uh vv8 uh I Imust say like uh it was a really longjourney uh until I got there but uhPleasant one so thank you so much uh forhelping me even like with with uhbuilding in and solving my problems soit was cool yeah absolutely to be honestthis is like a two-way street becauselike uh I always loved like this was oneof my first interactions when I joinedthe we data when I joined the companyand the community and like I could seeyou asking a lot of questions but youalso answer a lot of questions so I'msuper pumped to have you here and thennow showing you like hey where is thisall coming from yeah yeah uh yeah whynot help when you know the answer youknowalways are happy to help okay so maybeyou can share my screen and I'lldescribe let's do that I'm building onon the fly so this is laborator uhbasically what is laborator thelaboratory is a tool where you can uhfine tune and build your own uh NLPmodels so usually how how you work as adata scientist you have a data set uhthat you probably you didn't vibratebecause it's kind of at work and thenyou you build a model and deploy it anddo all the the engineering stuff andyeah it's cool but if you want to buildsomething that is uh kind of unique youneed to have a unique data setuh and to label these data it isproblematic and uh I was facing thisproblem I was trying to build somethinguh something special which I couldn'tfind a proper data set for and likeusing the uh common uh annotating toolsuh wasn't really uh working for mebecause I was getting crazy after aftera while so uh I bought this uh itevolved from something else butum it's it's kind of cool so I'll showit to youum what we have here is uh like projectsprojects uh uh basically like imaginelike a data set but combined with modelsand other stuffso uh if you have a project then you canjustpick the project you wanna you wannaopenand let's see this one for exampleand you are immediately like throughinto like documents uh but let's startfrom beginning I will do it if you'd belike uh trying to this product for firsttime you just create a new project let'ssay we want to do some I don't knowcomment moderation that's a use casethat uh our customers are are using tooso let's call it like commentsfirstum and we might have some data or wemight not that's also a common problemit's kind of a chicken problem that ifyou uh want to build a product that isuhum that is really unique and you don'thave map you might not have a a demodata to train the model and you won'tget it and you'll have it of your firstcustomer so let's imagine that you havea problem you that you feel that you canbuild it with you can solve it withdimensional learning with AIuh but you don't have the data the realdata that you you could change them allalong but let's imagine that we havesome data but they are not labeled soI'll just choose this this CSV file withwith some comments downloaded from theinternetand yeah I can choose like the meshlearning task that I want to solve solet's go this time for thisclassification and this is where the vb8uh is coming in uh so when we import thedata they will be imported with thevectors and you can choose like whichmodel you want to start with so if youhave English data you can choose one ofthese and you have if you have adifferent language you can pick uh thismultilingual model that is pretty goodbut we have English this time you canchoose any model from a hugging face Hubthat's that's cool so you can just findyour own uh domain specific model thatyou want to like fine tune and andevaluate furtherhere we can Define our labels so let'ssay comments can be positivenegativeand I don't know maybe toxic uh toxicthat we want to hide and now if I saveit uh the data will start to import intovb8yeah it might take a while but we don'tneed to wait for it so I just hope thetwo projects that this already has beenlabeleduhso actually I I to be honest I labeledthis uh just part of the project thatjust half ago half an hour ago beforethis this presentation just to test itif everything is working so I labeled inhalf an hour like uh 600 uh it's almost700 comments and what is really cool andwhat really really it is enabling me uhas I'm scrolling I'm immediately beingshown like okay there is a comment thereis like document and how many similardocuments are already in the databaseand if this document has some somelabels some some class uh it's verylikely that the most similar ones willhave the same label so in this way maybenot this one but uh in this this way wecan like label all the documents at onceso with one click I let's label 12documents if I will go uh here I can seelike more documents uh this is like morethan an exploratory mode but if I'll goto backlog I'll be showing just thedocuments that are not labeled yetand for example for example here is like60 similar documents so that's like lowHenry for hanging fruit so I can labellots of documents or Advance yes theyare similar but like even this can helpuh to have the model more similarexamples to strengthen the theum the learningso I just labeled 60 documents with withone click so this is the first partwhere we really we read is how pink uhme to to uh label more data more quicklyuhuh then I can skip to this micro topicspart which is more like an exploratorymode where uh as the data were importeduh there was also like topic modeling uhgoing uh underneath it and like thebubbles are basically a clusters of verysimilar uh documents that are similar bytopic so it doesn't necessarily meanthat if you are similar by topic theyhave the same label but it also can helpme if even if they have different labeluh to label them because I will havelike different versions for the samelabel uh and again this will help thethe trainingokay uh if I label like enough data Idon't need to label everything I'll justgo here models and I can train a newmodel so this is like really easy easyUI I can set up some Advanced featuresand uh Advanced uh settings but I don'tneed to I just click train a new modelit will take few minutes to to train sowe don't need to wait for it but yeahwhen it's trained you can see like allthe evaluation parameters confusionmetrics and so on uh I could evencompare like this version of the modelto previous model for example so I cansee like okay this version is fivepercent uh was on this a particular uhpart of the data set uh but here we arebetter because uh he was like twopercent were were mispredicted uh andnow it's now with zero so I can evenlike click uh if I see like here aresome like here are some documents thatare not correctly predicted I can clickinto in this box and in a new tab I willsee like okay uh there is this thedocument and it was labeled negative butit's predicted positive so that'sprobably not good and like we canevaluate by it so uh and this seems tobe like mislabel document so I justmight fix it and uh retrain the model ornot that doesn't really matteruh yeah and if I will go through all ofthese I just want to deploy the modelinto production so that's another thingthat you can do right here just create anew node that is basically spun UPS avirtual machine in the cloud or you canselect like self-hosted machine thatmeans that you will deploy a Dockercontainer and the container you don'tneed to do almost anything it's justlike single Docker run command and everysetup is uh being done here so when thenode is is created I can just uh Definewhich model I want to deploy the prohere so I can just choose from whichproject and which model I want to deployI already have this ready so this is mymy latest modeland yeah if I do this I can just test ituh cool somy first thing that I will usually do islike write bestand the thing is that uh lots of timeswhen I when I tried this with uh modelsthat were trained on on devil data thatdata setI got this like prediction that wascompletely off this time it was probablyright because I have this class naturalbut if I try this with for exampleagnews data set where you have this wordscience and technology then theprediction will be I don't know maybescience or world but just like not truebecause there is not such a class for itbut these models are very often uh likeinclined to give you an answer andthat's a problem that I was also tryingto solve uh and there's another anothervery cool feature that was enabled bybb8so you can Define these routing rulesand for every incoming like prompt youcan Define uh it that it will becompared with all the data that themodel was trained onand you can Define if the similarity tothe data that the model was trained onis up to 80 percent 80 to 100 then likeokay we can be confident enough that uhthe AI the model will give you the rightanswer but but if it's off if it's forexample in the range of uh 50 to 100percentthen I'm not that sure and I want toreview the data so actually if youprompt the model the node it will createa new document in in the project so itwill import data into vb8 and you canreview the predictions and you canimprove uh with time your modelon the data that were not previouslypresent in the data set so you don'tneed to collect all the data and likethen figure out like which we should uhhandle it's going on the Fly and you canbasically continuously learn and improveyour model uh and there is this lastthing that is called manualyou can Define like okay manual meansthe model and the AI doesn't know so ifit doesn't meet any of these routingrules it means that it's so D so uhdifferent than anything that the modeluh have seen before that we don't wantto give you an answer and that's thenyou can connect it with webhooks andwhen you actually uh correct the data orlabel the data in in the project uh itwill be sent to your core product andlike uh it will give you the answer likeasynchronouslyuh there are also a bunch of otherthings you can compare it with your uhwith your examples that is also verycool uh which you can help it can reallyhelp you to uhuh fix the data in the Productionssometimes if your model is uh is workingis in a production and you will figureout for example I will give you aexample what happened to us we deployedthis into production for uh big newsmedia company in Slovakia and uh firstwhat we figured that the model wastrained it had great metrics but we'vewe figured that uh when there were likethree emojis concept one emojis it wasgiving us the same uh label which waslike this is uh this is uh somethingthat is toxicit was before we had lots of data withthis throwing up emojis uh in the dataset and so it was like predetermined todo this and if you would would like tofix it you would need to uh go over thedata retrain the mobile but I could justlike create a example uh with threethrowing up emojis or I can just examplelike uhPro up uh and then you can Define thesimilarity to this example or moreexamples whateverand then you can decide if theprediction is something you wanna gowith manual so you don't under the modelto determine because you know that themodel is not working with this uhspecific area of the embedding space uhpretty wellyes so that was a quick quick uh demo ofwhat I've builtuh I'm happy to answer any of yourquestions if you have somethat's really cool like and uh not evenmy words like Laura was like hey yeahthis is pretty amazing uh to see thatum I think maybe we could leave it forfor like towards the end or somethinglike hey everybody knows where to findyou right uh conscious of time uh likebut if you have questions or somethingyou want to chat more about like some ofthe cool things how he did that like heylet's open up the conversation Let's uhlet's talk on slack and that'll bepretty amazing but yeah you're rightthank you for this demo was reallyamazing that uh it's kind of like an eyeopener it's like oh the kind of coolthings you can deal with it amazingthanks yeah it's really one of thosethose things where if you built such aversatile platform such as vv8 like yousee some kind of use cases that that youexpect but you also know that it's muchmore than a specific use case and thenseeing something like that which is sofar beyond of sort of what we do in on adaily basis that's so cool so inspiringI really really love this thing I Ireally like the sort of hybrid approachof fully automatic fully manual andsomething in between this reminds me ofthe software that I used to uh to do mytaxes with which is kind of similar likeyou can't just trust an AI to do yourtaxes because if it messes up like theconsequences are are massive but if itcan suggest something for you and youcan just say yes or no you still saved alot of times I really like this thisaugmented kind of exactly and it reallyviviate is is uh something that weabbreviated this wouldn't be possiblebecause if I would uh through if Ishould go for through all the data setand compare the incoming data with withany of the data that the model wastrained on it wouldn't be possible butwe deviate I can like do it and it'sstill I can work pretty fastsuper cool then let me let me give youan Outlook of what else to expect inmediate in the coming year and uhstarting first with uh the word Outlookso we were thinking what should we callthis is this a roadmap is this the theOutlookum what are we what are we um sort ofshowing here and we decided on Outlookbecause we do have a roadmap and theroadmap is very precise for what'scoming next or the next step and it getsa bit less precise for one after thatand if we're looking at entire year itgets pretty fuzzy and that is on purposebecause we want to be uh fast to reactto to customer demand user demandCommunity demand to see basically whatis the features that you need but at thesame time we want to give you an Outlookof what to expect to to come this yearso um this is why we have the the 2023outlook here and still of course we willhave our roadmap so if you look at theroadmap you will see the next releasethat comes up has some things thatbasically overlap with this Outlook andthe Outlook is kind of what to expect bythe end of the Year this Outlook is madeup of six specific pillars the first oneis retrieval and ingestion pipelines soum an example for for this kind ofcategory would be a request that nowthat we have the hybrid search APIum one of the first requests that camein is like cool can I use this with q aand the answer is yes soon because rightnow you can't do it yet becausetraditionally basically the the Q a wassort of an implicit pipeline of anear-text search and then an answerextraction and we want to open this upwe want to make this more flexible so inthis this sort of Epic of pipelining theidea is that the user can just decidewhat to pipeline yes there may bepredefined pipelines but you can alsocustomize it and this could go furtherthis could also go for ingestion forexample so a recent feature request wasfor PDF extraction so we do have a PDFextract the text from the PDF then do atext to VEC so you have a two-step sortof ingestion pipeline anything beingrelated to to bm25 and hybrid searchwould also be in this bucketthen coming to the second bucket whichis currently called Beyond billionscales so this is also super superimportant one to me uh last year was thefirst year that we had a billion scaledata set in V8 and that was sort of thebig milestone to to be able to achievethat that uh that scale but it doesn'tstop there we want to continue and wewant to make it better and especially abig portion of that is for examplefilters so filters is something thatmakes bb-8 unique and and powers and Iguess in the use cases that we just sawfrom from Europe I'm sure there's lotsof filtering going on there and umfiltering gets more and more sort ofexpensive from a computational respectperspective as the data set grows andthere we have we have big plans so we'llannounce something soon to make filtersway way faster at the billion scale andthis is one of the examples butbasically uh we want VBA to be evenbetter at the very large scaleum that brings me to the third pillarwhich also has scale in the name whichis the improved Cloud operations andscaling soum big milestone reached at the end ofthe year in in 2022 which was theintroduction of replication which is thethe sort of biggest part of that cloudoperationsum roadmap and um it's it's sort of donein a way that it doesn't stop notbecause it's incomplete because butbecause we can always add more to italways improve it so for example onething that we put out there um that thatour architecture would enable us to dowould be active active multi-dc kind ofreplication so you would replicate yourdata set across the world in differentdata centers if a whole data center goesdown doesn't matter because you have theredundancy with the other Data Centerand you have that sort of proximity tothe user kind of thingum and and we put that out there andthere was a lot of positive feedbackalready which is nice so this gives usgives us a good indication of what youas the users want and um gives us plentyof cool stuff to build in this bucketall also of course any other kind ofkind of operations tooling so forexample we introduced this node APIwhich was a sort of relatively smallinternal request from our internalsolution engineering team but that hashelped a lot and helped in debugging andthese kind of kind of tools that arecheap to build but have this big kind ofimpact they will all be in this bucketor in this pillar then the next one thefourth pillar is something that'sbasically completely new in this yearbecause we've been researching in thebackground and research is somethingthat that takes some time and this yearwe will release not one but two newVector index types so you know sort ofvv8 has been going hand in hand withhnsw for quite a while but um now youwill get more options the first one isonly so to speak an extension to hnswwhere we introduce compression so youstill use an hsw index but your vectorsare compressed and that reduces yourmemory footprint so that's sort of aa very quick way to to lower your memoryusage and then the next one which willbe later this year is a fully disk basedsolution so we also teased that a bit umfrom our from our Italy trip last yearin Novemberum where we showed some some uhobservability graphs with the memory uhgoing down quite a bit and this isum yeah this will be production readywithin this year and of course therewill be previews um and experimentalreleases so you can start playing aroundwith it way way sooner than thatthe fifth bucket is clients and modulesso this isum basically this is this could almostfill an entire BBN episode on its ownthis particular packet um but what wehave in there is everything to do withthe module system so for examplere-ranking with cross encoders that'sthat's the part that also fits in thefirst bucket the um the search andingestion pipelinesum but if you have such a module or Srif you have such a model in the pipelineto to re-rank it needs to come fromsomewhere and that's our module systemum generative search that's sort of theworking title for for I see Conorsmiling and he can he can share way moreabout this than than I can but it's anarea that we're looking into and thatwould have some some cool stuff about itum similar for for the client'singestion pipelinesum also something that we have in thisepisode even the the vb8 spark connectorso plenty more in that category to toimprove ingestion ingestion speedingestion resilience these kind oftopics which all also sort of fits invery nicely with the the replicationMilestone so if the client side isresilient and now the server side isresolient then basically that meansanything can happen and you will stillsucceed with your import which is supercool and the sixth one is probably themost important pillar which is the onethat has the most open the mostGreenfield kind of area is our communityso you know our community roadmap whichgives youum a chance to participate in ourprioritization we have this this upvotefeature which isso cool to see for us to to see sort ofokay if if someone creates a featurerequest is this sort of an edge casethat just a single user wants or is thissomething that there is a lot of demandfor and then if something suddenly popsup with like 20 uploads then you knowwow okay this is cool and this makes itvery easy for us to to uh say like yeahlet's focus our energy on that and italso makes it a bit easier to becausethere's only so many things that we canfocus on at the same time it also makesit a bit easier to say this is why we'renot focusing on this particular featureright now because look at this there's alot of demand for for this one and umyeah super super happy that we have thisroadmap and please keep submitting youryour feature requests please keepupvoting your feature requests andplease keep this as the third one that Ifind super cool keep advocating for thefeatures that you want so we haveCommunity users say like hey there'sthis feature request this is superimportant featureum if you think so too please upload forit and it led to it to a spiking likefive upvotes which to me me is a supergreat sign that we have a really goodsort of community involvement and reallyare building the kind of things that allof you out there actually needyeah thank you that's that's it for mefrom the the sort of sneak peek into theOutlook of course we will publish thatum that's sort of why I'm not sharinganything other than just talking becauseit's currently uh under development willmake it prettyum the content is already pretty but wealso make the the presentation prettyand then we'll publish this very soonI like the promise that the the one ofthe big features about the roadmo isthat it's going to be pretty uh no butthis is really exciting like it's likeum I've been with the company for likesix months and so much changed and nowyou're talking about all these pillarsuh and then like it shows us that likewe have a very good idea of what we wantto achieve and yet in all of this the Pthere is a big pillar for Community uhfor great people like you right hereright like say if there's something thatwe can do to make you more successful sothat weave it can you know run faster orcan perform a specific task let us knowand then share it with us and talk to usbecause we do listen we do listen and werespond to that so I'm really glad thatIan that you made it like make a pointabout it it's yeahit's um it's community that makes it alltick I have to say yeah and it's reallythat that bi-directional kind of thinglike we're we're helping users like likeyou're right you'll be the example forevery Community you're here todaybecause you're you're in the callum yeah we help the users like you butwe also get so much back from you likeyou and that for for this you areactually a perfect example because somany times you've helped us debug someissues or maybe find something out thatthat um potentially could have been abigger issue if we hadn't caught it soonenough thanks to you and of course we wedo have our own uh QA engineering butsometimes sometimes something slipsthrough and to get that kind of help andand um yeah really sort of helping eachother not just saying like throwing itover the fence and saying okay this isthere's a buck fix it but sort ofhelping each other going back and forthhave these kind of kind of conversationthat is such such a valuable thing aboutthis this um yeah open source also forus not because it's it's not one-sidedright like open source doesn't just meanthat everyone gets to use it for freethere's there's also plenty benefitsthat we get fromyeah I must say that this is somethingthat really distinguish viviate fromfrom other tools that I've used like uhthis this cooperation is really awesomewith you guysthank you so muchI will say really quick um when I wasgoing to the community questions I sawand I believe also from the communitycalled urai the Ruby encyclopedia yousee it's just a lot of questionsyeahevents yeah nicespeaking of those uh yeah sorry go aheadSebastian no no go for it speaking aboutuh Community collaboration and ushelping the community the communityhelping us back I guess that's a reallygood segue into the next topic becauseum as Etienne mentioned the the sparkconnector was developed by the communityum shout out to Sam stalinga Sam Bean wehad a podcast with him this is anotherexample of uh of where the community thethe friends at you.com we're using we V8and they were also using spark uh to uhto develop their ETL pipelines and theywanted to be able to take that data andthen populate uh deviate with it and umif he had mentioned that uh billionscale solution we actually used this wasone of the ingredients that went intothat uh that solutionand I just wanted to talk a little bitabout that give you a small demo andthere's a blog posts and podcasts thatwe've also published around this as wellum just imagine if you could share myscreen here yeah absolutely so let'sshare your screen thank youum awesome so the Wi-Fi spark connectorthe concept behind this is uh prettystraightforward the idea is that if youhave unstructured data uh naturallanguage data image data and you'reworking with it in spark and this iscritical if you're working with a a dataset that's uh of any consequential sizeum when you're getting into the billionsobviously but you're going to be workingin spark whether it's to do ETL you caneven train models within spark if you'rejust visualizing your data you're goingto be working with a distributedframework like spark the main ideabehind the spark the weeviate sparkconnector is that you can easilytake your data data structures withinspark and then use those to populate uhyour weeviate database using using thedata it's already imported into Sparkand you can specify the batch size youcan specify the URL for the weeviatehost and if you have vectorized data youcan even pass that in as a column that'sin your that's in your data frameand this obviously helps with the uhwith the speed of ingestion as wellI wanted to show you a quick demo aswell hereso here I've got uhI've got this notebook let me let me seeif I can zoom in a little bit herefurtherso in order to get this running you'llneed Pi spark you'll need the alleviatepython client and then you can have yourdata ready either on Google Drive or forthis example I've got it ready on diskand really a lot of this is just Pispark functionality so you can import Pispark and then you can start a a sparksession I'm just showing this locallybut usually this would be uh this wouldbe on the cloudso I'm going to start a spark sessionhereso that's getting started and then oncethat's up you can you can view it youcan also use the spark UI to oops let meopen itso you can use the spark UI to to lookat what's going on in the background aswelland thenthe the next step is to get your dataI'm going to import it from a Json filebut you can import it from a parquetfile as well many other formats in whichyou can import it and I'm going to putit into aa panda's uh spark pandas data frameand this is very similar to the codethat we actually used for the onebillion import actually here I'm justshowing you an example of a hundredthousand uh data points from the spheredata setbut we actually use this very codefor that for that jobso once that data is in the spark dataframe you can see what that looks likethe cool thing about the sphere data setis that not only do you have the um thethe Snippetsfor news articles but you also have thevectorized representation of thosearticlesso we're going to use this actually topopulate alleviate as wellso the next step once your data is inspark you can then write it to vva andthis is the novel component where thespark connector comes in rightso I've got a alleviate instance up andrunning locally and then I'm going tocreate a schema that I'm going to useand then this is where the sparkconnector comes in we'll post a linkthat will that will that you can go toto look at the code behind this as wellbut the main idea here is that you cantake your spark data frame your datastructure and you can directly populatewe V8 using that data structure and hereyou have the ability to control forbatch size you can tell it where thehost is located this one this option isinteresting here so this actuallyspecifies the name of the column thatstores the vectorized representationsfor every row so if I scroll back uphere you can see that the vector columnhere has the vectorized representationsthis is how we populate not just the uhnot just the natural language data butalso the vectorized representations intointo eviateso we can run thatand all of this by the way you can youcan have a look at the spark UI all ofthis executes uh starts and executes ajob on the back endthere it is so all of this is uhstarting and executing a job on the backend so you can monitor that as well andthen once you have data in leviate thenyou can just you can you can query thatdata as you would so you can query thetitles for example you can also look atthe urlsum before this there wasn't an easy wayto get data from a spark data structureand to eviate and this uh this reallyhelps with that process so I just wantedto talk a little bit about this ifyou're more interested in the detailshere we've got multiple blog postsaround this and then we've also got thepodcast with uh one of the creators ofthis Sam bean from you.com and then theother one being Sam's delingaamazing uh so we actually already sharedsome of the links uh of the things thatwe talk about in a description or thatwe will talk about and I think I'd beworth adding uh the links to the podcastthat you mentioned then and I knowConnor you did another one recently aswell so I would definitely add those solike uh later on check out thedescription and the links will be thereunfortunately YouTube doesn't allow usto share links directly as comments uhbut we will definitely add that in thedescriptionhey Zen uh this this was pretty uhpretty amazing like I I like how simpleit felt like you were like oh my datasource here here's my structure justprovide the options boom and then we hadthis separate interface to just youcould watch as the data gets importeduh it's it's mind-blowing yeah exactlyand anybody any any data scientist anyapplication that you're working even onthe million uh million scale 10 millionscale you're going to be using adistributed framework like this and tohave a connector that allows you topopulate uh alleviate with that samedata is just very convenientyeah amazing amazingcool thanks for this presentation sonext up uh we have Connorcan you share the screen as welloh yeah let me do that uh where are youheresuper cool so I'm so excited to befollowing Zane on this and talking aboutuh the spark connector and the Big Datauploads and how this relates to the BeerBenchmark so firstly here comes mySebastian calls it Shameless plug uhwe're just publishing our podcast withNils rhymers uh nose rhymers is one ofthe creators of the beer benchmarks it'sbeen incredible working with the cohereteam on uh publishing this scheduling itwith the podcast and everything with theintegration with bb8 so please check outcheck that out it'll be super cool soI'm so excited to tell you about the wegave your benchmarks and our efforts inputting the beer benchmarks into Eva andsort of why we've done this and why it'simportant so oh sorry so let's start offwith you know why is this important sowe begin with sort of two questions forwhy do we want to add the beerbenchmarks to eviate the first questionis well how do we know that hybridsearch is better than either denseVector search or bm25 on their own andthe beer benchmarks presents a set oftests where we can tell you that here'sa performance of dense Vector searchhere's a performance of bm75 hybridsearcheson the data set and then the secondquestion that's very important is how dowe VA users know that hybrid search hasbeen implemented correctly in webiate sostart off with what are the beerbenchmarks beer benchmarks emphasizediversity so let's say You're Building Anutrition facts search app Financialquestion search app or you're searchingthrough tweets it contains this kind ofdiversity of domain it's like esotericstyle of query like the twit the tweetsor things like this so you have thiskind of diversity and that's sort of thecore goal of what's captured in the beerdata sets so another very importantdetail is the size of the data set soyou see on the this 3D plot I think I'vebeen kind of animating it in 3D adds anice Dimension to the visualization butyou see the um the MS Marco data set isthe big data set with 10 million uh youknow down to Natural questions is 2.6and then you know you have Cora cqa dupestack these are the ones say so NFCorpus is about three and a halfthousand so you can you know experimentwith it really quicklyso a lot of these data sets are veryinteresting when you dig into thequeries and the nuances of each of thembut again the the core thing iscapturing diversity so NF Corpusnutrition facts arguana are counterarguments where you're searching for uhdisagreements to some claim which hasall sorts of interesting implications toit FICA Financial questions try covidscientific papers about covid cqa dupestack is like stack Overflow codingquestions Cora you're looking forduplicate questions uh you know fever isfact verification Ms Marco is the Bingweb search API so very interestingdiversity and that's the goal of thebeer benchmarks so now let's talk aboutadding it to Evie so there's five stepsthat we're going to look at how youdownload the data they've provided theseexcellent links that you can just youknow W get and you have data vectorizinguploading to ev8 backups backups beingthe big thing here and then testso starting off you just uh they've metthey've made these super easy todownload so you just kind of go to thislink and then you click the link and youhave the dataso now let's talk about vectorizing sowhat I did with vectorizing is I'mrunning this on the Google collab T4 GPUI thought the T4 might be a little moreaccessible for clocking the times in thea100so you can see how long it takes tovectorize and I think kind of havingthis data table is is useful for peopleto understand like how long does it taketo vectorize Big Dataso I think maybe the most useful nuggetis to see like 500 000 takes about anhour so you know whatever you'rethinking about that's kind of a good wayof thinking about it so then think aboutvectorizing larger scale data sets sowe've done the natural questions and sowhat I've done is I have the Json filewhere you load the entire Json file andthen you chunk it up once you have theJson file and so so you can do that andyou vectorize each of the chunks but thekey thing with parquet is parquet andSpark as Zane is mentioning that it hasa better way of how you uh take just aslice of the data set to chunk it sowhen we're publishing the full blog postwe're going to switch from the Json fileto the parquet for the larger scalevectorizationsso the next step is importing alleviateand so uh with the new uh batch enforcethis is just insanely faster so the uhlike I originally started doing this oneby one and then the new python clientwith the uh batch Imports and dirt coollike what he's done with that is just somuch faster and it's really exciting todo it so so these are kind of some ofthe times that we're seeing withimporting to deviate you can see the thedifferences you see with like thedifference between say Cora and then thetouche 2020 data set the impact of theor uh yeah you can kind of stay withthat one but with track covered you seelike the impact of longer document likesand what that takes in the indexing andso I think there's a lot of this it'skind of more in the database indexingexpertise rather than something I know alot about but I think it's veryinteresting to just see the times twoImports we gate and see how much fasterit's getting I think is incrediblyexcitingso then the thing that I think is addingso much value to this benchmarking theseinformation retrieval data sets inweviate is the impact of the backups soyou see this is this is this is like the16 lines of code you would need to backup one of the beer data sets using likethe command line to pass in the name ofthe data set and then back it up andthen when we want to publish these datasets what you would need to do is youtake the beer data set you put it in thebackups folder the TMP slash backups isempty folder you know you have thequeries for running the test and thenit's just Docker compose up therestore.pi and then you have the dataset sorry I accidentally put thedockercompose.yam while I'm seeing thatnow butI should just say Docker compose up Dand then you have the backups and thenyou can see some of the file sizes forthe backups so I think it's just superinteresting the way that we can sharethese uh data sets that have beenvectorized and loaded into alleviate andyou just bam restore it and then youhave this beer data set to test withthen the thing with the beer benchmarksare the metrics so ndcg is an importantmetric because it accounts for multiplerelevant documents with like multiplerelevance scores so not just binary zeroor one you have this relevant sub I soyou know it could be like one two threefour five so on soyou know pretty much you just uh loopthrough the top ranks add the relevanceand then you have the uh the log overthe position that it was to penalize itfor being lower in the uh ranked listand then you compare the dcg with theideal dcg which is where you sort itbased on the human labeled scores andthen the normalized discountedcumulative game is just dcg over idcg sothen we also looked at average hit atone where you say you know is the firstresult relevant document and thenaverage recall at 100 which is uh recallis how many of the relevant documentsare in the top 100 so say you have youknow 10 labeled relevant documents andsix of them are in the top 100 thatwould be sixty percent is you know inthat top 100.so here's a preview of the results andthe full release will be coming soonbecause there is one key detail that Ileft out which is um uh with the beerdata says with the bm25 it's often to dobm25f in the Hybrid part where you alsouse the title so I missed this detail soit's just bm25 with the uh the contentitself but we'll be adding this andupdating the scores as well so these arejust uh so so these are some earlyresults of using Alpha equals 0.5another thing we wanted to understandwas the impact of the alpha so we variedit from zero being bm25 only to onebeing Vector search only and seeing sortof uh what is the impact as you see onthe far right with the weevier queryclick how should you think about tuningthat Alpha valueso I think this benchmarking is reallyexciting for the continued searchdevelopment of weviate as we're lookingat things like the you know Transformerbased cross encoders that we add as there-ranking like what is the impact ofthat on these uh on this informationretrieval performance how we might lookat xgboost is one way to you know dothis re-ranking and all sorts of thingswe're looking at other strategies ofsearch like Colbert maybe havingmultiple dense Vector models the splayedsparse vectors and also something that'sa little different that I think isextremely exciting is this sort ofintent based re-rankingso now we've kind of answered thesefirst two questions where we're tryingto say you know is hybrid search betterwith by looking through the alphas andseeing where it's better and then uhknowing that it's been implementedcorrectly by checking our scores withthe uh with the scientific literaturearound using the beer data sets anotherthing about some other ways that uh thebeer benchmarks might be useful so thefirst question is can this helpalleviate users choose a model so ifyou're working on a nutrition websiteyour search results are probably similarto the NF Corpus search resultssimilarly if you're answering Financialquestions the fika data set might beable to tell you a lot about your app aswell so we're looking at evaluatingother sentence Transformers again theseare vectorized with the all mini LM l6v2and we can you know there's all sorts oftext embedding models on uh hugging faceand the sentence Transformers that wecan Loop through we can use the open AIembeddings API the cohere embeddings APIand you know give you a sense of theperformance of different models whenthey're evaluated in this uh set ofretrieval metrics so the next question Ithink this is super exciting and this isa super new thing like I'd say like asnew as this week is how do I set up abenchmark like this for my data rightso this is kind of the new idea withgenerative data augmentation the latestpaper is called in pairs V2 there was anoriginal in pairs and then promptegatorso let's take this example so I've takenthis passage from Sebastian's article onhow to use the cohere uh embeddingsmodel in weaviate so you see thispassage you know multilingual modelquick test and the informationSebastian's writtenso the prompt is please write fivequeries we would expect users to searchfor to find information contained in thefollowing passage from the article putthe article name with the subtitle youknow subtitle name please make surethese queries are very specific to theinformation contained in the passage soyou see how chat gbt can generate thesequeries I think the fifth one is is themost sodium one the probability is welook at say uh your eyes tool on how youcan look through uh look through theselabels we'll probably need to do somemore parsing and some more manualcleaning these visualization tools fordata set cleaning I think is a boomingarea and there'll be tons of use casesfor these but this fifth one steps toset up a weeviate instance and import adata set with coherence multilingualmodel this would now be an example of agold document for this query and wecould construct the same kind of testsfor anyone's data set you just rotate inyour passage and it will generate thesedata sets like this so that you canunderstand the impact of bm25 and um anddense Vector search the different modelsthe impact of the Cross encoder you knowcobra when we develop that you can seethe impact of all these things foryourself with your particular data andyour particular applicationso just some final thoughts um I thinkthis this is full stock searchevaluation thing is evolving you've seenedian's a n benchmarks to show you howto tune the EF construction the hswhyper parameters and now we're lookingat the then one layer up you have theerrors that are introduced by theretrieval and re-ranking kind of layerso you know you first you have the hswerrors with things so like as ummentioned the hnswpq the way you canpress the vectors that might impact therecall a little bit depending on the howaggressively you can press them andthings like that and so then we seethese errors and matching the queries ofthe documents that might come from theembeddings and then further up the stackwe have the question answering you knowthe dialogue as we've seen obviouslychat gbt and summarization so we'reseeing this kind of full stack searchthe next big topic is this in domain outof domain and zero shot generalizationso beer was developed to evaluate out ofdomain meaning that uh the models thatyou're encoding the documents with inthe queries they ideally they haven'tbeen trained on the any of the data setsso I think that's kind of an interestingway to set up the benchmarks uhcertainly you would imagine somebodybuilding a building a search app asquickly as possible they want some kindof zero shot model but I think it wouldbe nice if these data sets had some kindof time split to themand we can also evaluate this kind ofimpact of fine tuning and fine-tuningcould be at the vectorization layer itcould also be at the re-ranking layerand I think sort of in the real worldthe symbolic filters and the use ofxgboost re-ranking is also somethingthat's very impactful and maybe tough tocapture in these benchmarks so that kindof is uh also related to the evolutionof benchmarking in weba I think it'svery exciting for us as we're developingnew search features to be participatingin the scientific benchmarking and themetrics and all that and then finallythe last thing is the retrievalaugmented language model training so youknow as Eddie mentioned we're gettingready to make a huge push intogenerative search and we have some superexciting things coming out of that andthe the zero thing the obviousapplication is retrieved and read whereyou retrieve context to give to chat gbtsaying please ground your answer in thisinformation and then you give it theinformation that came out of the vectordatabase and I think what we're going tosee is tons of people training retrievalaugmented language models and I thinkthis idea that you can restore backupfrom weviate and then you have that asyour retrieval augmented component ithas high research and these kind ofthings built into it I think that'sincredibly excitingso thank you so much for listening I'mreally excited to be publishing the fullwe Behavior benchmarks article and themore polished results as we have thehave been 25f to the title as well andso thanks so much for watchingexcellent this was amazing hey Connor sowhen do we plan to publish the blog postis that the thing we're doing next weekuh what two more weeks for that yeahokay okay I should be yeah so there's somuch amazing content coming up but thisyeah this is pretty amazingum thank you for this overviewso uh next up we have Erica and uh Ericais going to go over someCommunity questionsall right I had the honor of going tothe community questions from the pastmonth and I've collected three questionsthat I'm going to cover provide linkswith and then just a quick demo toanswering the first question if youwouldn't mind sharing my screen I don'tmind at all awesome all right so here wehave the first question from Castleum they had asked if they can do exactphrase matchingum because when they search for customeror beta with using the equal operatorthere it's returning either uh an objectthat has customer or beta but notexactly customer beta which is whatthey're looking for and um John andMartin had answered this question so I'mjust going to provide a quick demo onhow this can be fixed you get the exactphrase matchingum so I would quickly go over to thedocumentation just uh so everyone cansee where it is and what I'll be talkingaboutum so how you can fix this umum oh my gosh I completely fine how youcould fix this kind of uh problem withthe exact phrase matching is withtokenizing on the field level ratherthan wordum so I will go over the yes code sorryif that gave everyone a headacheum all right so here I have my schema Imight have done this when I was hungrybecause it is about pasta which is myfavorite meal but as you can see herewith my property meal I have tokenizedit at the field bubble and what this isdoing is it is taking cheese with pastaand tokenizing the sentence as onerather than breaking it out into cheesewith and pasta into separate tokensum all right so I have already uploadedthis and I will go over to the consolewhich I prefer it's very niceall rightyou know what I also should have grabbedthe queryall right so I will use the likeoperatorall right so here I haveum my Valley string with cheese and I'musing the like operator and I want tofind a dish that ha that has cheese init rightum but obviously since I tokenized atthe field level it's expecting cheesewith pasta or cheese without pasta rightum but the cool thing about the likeoperator and it is right here under thefiltersdocumentation is you can use theasterisk so if you have one or moreunknown characters it will find thoseobjects that have keysum so if I if I run this now you havecheese with pasta cheese with rice andcheese without pasta I do not use cheesewith riceum it was Sebastian who suggested maybeincluding hey I'm putting you out thereit's weirdI come to Copenhagen I'll convert youum but if I keep the asterisk becauseI'm I don't know if it if my object haswithin it but I'm going to include pastaum you can see that rice is now kickedout right because it is clear with thefield token that it is pasta and then ifIumjust yeah obviously put rice in it isgoing to find that exact dish that hascheese with riceum so that is the first questionon castles how to find exact matching umyeah so I hope that clears it up andalso it wasum I can provide a link to this demo ifit helps all right the next uh questionis are there any uh good performancebenchmarks on wheat and the answer tothat is yes and I will share with youhow to find it in the documentationum so if you go to the documentationsection on the website and you go tobenchmarks and then a m you have WB A9benchmarks and since we have ending herewhat is a better time than to ask umwhat should people look out for whenthey're reviewing thisyeah yes I saw in the question that thatwas also about a comparative uh sort ofBenchmark and uh this is something thatwe want to leave to to someone elsebecause we're strong Believers and weknow how to run bb8 and we're alsostrong Believers that competingSolutions are very good at running theirsolution but probably not at running bb8and another competing solution the samegoes for us so um for us it's superimportant to be transparent about thesethings and to give the user accurateinformation that really helps them andwe can only make these accurate claimsabout ourselves and then not about itnot about others wouldn't feelcomfortable in in doing that so thesebenchmarks here uh Benchmark vv8 inisolation basically um but withreal-life use cases so we have thesethese data sets I think we have three orfour data sets where we chose differentdata sets um to have somethingrepresenting a smaller data setsomething representing a larger data setum have a low dimensionality I thinkglove 25 is like the low closedcaptioning not available[Music]in general yeah exactly perfect ingeneral there's some sort of a sweetspot and query performance andthroughput is function of recalls so youcan pick your desired recall so forexample in in this thing that we havehighlighted right here we picked aconfiguration that led to 96.56 recalland then with this specific machine youwould get a QPS so queries per second offifteen thousand which is again sort ofa function of the number of CPUs but wealso have the mean latency which is notdependent on the size of the the machinebut that's basically just for for asingle query so this gives you a numberto expect and and this tells you sort oftwo things basically what what we canachieve with vb8 and therefore what youshould be able to achieve with bb8 so umit answers the question is DV8 fastenough for my use case but it alsoanswers the question of am I getting thekind of performance out of vb8 that Ishould be getting out of ev8 so if forwhatever reason you would run that dataset and you would not get that kind ofperformance they would have some sort ofan indicator that maybe something can betweaked maybe something can be optimizedthen maybe the kind of Hardware thatyou're running on is is not ideal soum the last part of the vector search isa disk lookup to to retrieve the objectsmaybe you're using a 20 year oldSpinning Disk and one of the vectorsearch itself is super fast that lastlast step all of a sudden now it takes10 milliseconds where the entire searchshould only take two milliseconds orthese kind of things so great greatindicatorumsomething that that Connor justmentioned right now the evolution of ofbenchmarksum this is a start I'm very proud ofwhat we have here but it's only a startso some of the next steps that we wewant to have is of courseum the kind of yeah the beer benchmarksis an example of a benchmark thatdoesn't Benchmark performance or wellnot not performance in the sense ofthroughput and latency but performancein the sense of accuracy researchquality that is something that wehaven't published yet so that will besuper cool once we have the the beerbenchmarks to have something in thatdirection and then another thing thatwe'll definitely publish this year isbenchmarks for filtered Vector searchbecause right now um these are allunfiltered search which is sort of agood easy thing to compare especiallyalso to to compare with other Solutionsbecause unfiltered is is the easiestlike if you pick another solution thatalso uses hnsw and you have unfilteredversus unfiltered gives you a very easycomparison as filters are introducedum they may have chosen a different wayto do it the quality may be differentthese kind of things so that that'sthat's a bigger topic but it's just asinteresting of course because when areyou going to do an unfiltered searchlike most likely you're going to do somekind of filtering so that's the The NextStep that we want to have in the in thebenchmarks and thenum also maybe different scale so rightnow I think the biggest data set that wehave in here is 10 million um but wewere currently seeing users have datasets and hundreds of millions and in thebillions so maybe also something in thatdirection soum yeah to to answer the question of howdo the benchmarks evolvebasically more benchmarks more use casescovered more more variety in the usecases covered to always answer that thatquestion of can I use vv8 for x and am Igetting the kind of performance out ofV8 that I should be okayawesome thank you so much for sharingthat very helpfuland then all right quickly for the lastquestionum Advent has a would like to contributeto Weeki and is curious on how to dothatum let me go or switch over to mydesktop um so how you can get to thecontributor's guide on the website is ifyou go to developers and then you clickon contributors guide and then what wehave released in late December I believeis the good first issue on GitHubum so here you can go through theseissues and just figure out what you likehow you want to contribute to aviate andyou can review it we also had a questionlike an hour ago from Andrew and heconfirmed that he is watching live soAndrew I hope this answered yourquestion and welcome to the webiatecommunity and if you have any follow-upquestions please let us knowexcellent excellent and I believe weshared a link to this like uh the GitHubuh first good issue or good first issueso if you want to find this link uhcheck in the descriptions andum yeah that's uh that's a good startthank you thank you and this is a goodtransition into seeing the newdocumentationah yeah let's try to do that okay so I'mgonna go last uh because obviously youhave to have priorities in the team uhbut uh have you gone last does itdoesn't necessarily mean that what I'mabout to show is the less exciting andsome of you will be really excited aboutthis thing so this has been in themaking for past few months and we kindof mostly kept it quiet uh and what wereally were trying to do is uh uh asfollows we're trying to migrate the likethe Vivid IO site into like a newtechnology because when I joined thecompany it took like half an hour to 40minutes to build and it was verydifficult to kind of like make thedocumentation do what we wanted toachieve uh but but also like we realizedthat like you know it was time torefresh some of the things that we do sohow about I share my screen and thengive you a preview so this is at themoment like a private deal like on adeployed on Netflix uh but we are usinguh docusaurus as part of our uhtechnology soum the whole video site is going to bebasically built on docusarus which isreact base which allows us to do quite abunch of like amazing things so like ourlanding page will look like this you'llbe able to actually sign up straight foruh our newsletter from here uh is not100 ready ready yet but we should be uhgoing live with it next weekum then we also have like the dartboardand the light mode I know that a lot ofpeople are super excited about the darkmode uh and then like I'll just jumpinto like some examples of like our blogposts uh it's they're going to beredesigned and this is I'm somethingsomething I'm really excited aboutsometimes with some articles we havemultiple authors so you can also sharelike the multiple authors that work oneach of those uh and then you can see itactually looks pretty amazing uhobviously the podcasts have beenredesigned slightly in terms of how itlooks and by the way if you didn't knowyou could actually go and listen to allthe podcasts on Spotify which is reallyreally cool uh and then contributorsguide like Erica mentioned are underdevelopers contributor contributor guideand the documentation it's kind of likethe busy boss here and docusaris givesus some interesting things so we couldhave this uh special I think they'recalled annotations or something where wecould add like additional comments likehey this is like a note or an info uhthe code examples are actually reallylike you could see them there's adifferent style so before it was like abit of a harmonica like we're likejumping between different examples uhbut in this case this is more like adifferent types of tops and thensomething that we did which you mayappreciate or you might find a bitannoying but we actually decided toredesign the layout of navigation so letus know how you would you feel how youfeel about it would you think but we didhave like um some questions as wellabout it where people wanted to justlike expand different bits ofdocumentation uh so now you can do thatum and then yeah we sort of like changedthe whole navigation to kind of focus onhow do I go about getting started how doI install what sort of variousconfiguration references do I need toknow about like Conor was showing anexample of like how backups work uh likeI mean using backups for deer benchmarksso you could actually read about backupshereum the apis like the graphql all of itwent here the rest API are kind of likebunched up together and this is not theend of the journey we will probably dosome more uh changes to thedocumentation so any feedback would besuper usefulum but yeah that's kind of like thegeneral idea of what you can expect fromuh the new site uh and of course likewith the VB cloud service you could gocheck out the pricing uh or just gostraight up to try it out try it out sothat's also available through hereum and before this goes live if you wantto play with it I probably share thelink at this daily filing uh and if youwant to just try to build it yourself uhit's on our GitHub site uh under thedocusarus migration Branch so you couldliterally go and build it yourself uhthis is a great thing I love about it isuh the fact that you can actually go anduh clone it and then set up the wholeenvironment in like 10 minutes and I'mnot kidding it's that easy and it'sreally really fast and then somethingelse we will be adding it's uh is thewell actually it's here already uh ifyou see anything in the documentationand you feel like oh something is wronghere or maybe something we could add ifyou click edit this page it actuallytakes you straight to GitHub where thispage is so you could technically go helpus through this edit this page and thencreate a PR uh which you know CommunityBased product like would love to seeyour PRS if you see any feedbackcomments or changesum so yeahthat's basically all I all we have to toshow and to share uh with youum I'm one thing I'm really curiousabout like uhgive us any feedback and and ideas but Iwant to know like where are you allwatching from there's like a whole bunchof people whether you live or are youwatching later drop it in the commentsbecause that's like that's kind of coolto see uh people coming from all overthe worldum but yeah I think uh that's most thatwe had for today and uh oh I see aquestion from URI about search in thedocsum so it is something that we startedworking on uh so the idea is that we dowant to add search to the documentationuh but it's not gonna go get releasednext week just yetum so Ken uh is working on it uhactively and that is that like once wehave something that is like really readyin a good shape uh we'll be sharingsearch in the documentation because Iagree like on one side good navigationwill help you get to the right pages ina good way but sometimes you just wantto run a quick search soum it's gonna come soon like it's uhit's not really just yet but it's gonnabe sooner than than most of you expect Ijust don't want to throw a date yet uhlike really closeso I'm gonna be alleviate basedit is yes duh you need to ask yes uh soit is going to be like a vivid instanceum I mean some of the things that we tryto figure out the search is uh how doyou how often should we be indexing thewhole documentation should we trigger iton every build uh or should we just doit periodically because like what ifjust somebody added like a new blog postdo it and go and rebuild the whole thingAlthough seeing how it's not like wehave five million pages and howefficient with it is I don't think itwould be much of an issue to kind oflike rebuild the whole index every timeand it's like yeah it's like extra fiveseconds who cares right yeah we did itso fast could also make a veryinteresting case for for our users ofsort of how do you deal with a bulkupdate without a downtime like how doyou doum for example such a such a blue greenkind of deployment where something likethat updates in bulk but you want tohave like a zero downtime switch so wecould could dog food this and and createsome nice content around this as wellyeah totally agree totally agree uh yeahand there'll be a whole bunch of blogposts about it because I mean I thinklike not just blog posts but I like tohave actual active tutorials so becauseblog posts kind of like give you a sneakpeek give you an idea but you still haveto figure out quite a few stats yourselfuh so I'd like to actually create afull-blown tutorial kind of like hey youwant to add search to your site uh be iton documentation or some other contenton the app there here's how you do itlike this is a promise from Sebastianlike we're gonna make it happen and uhJP when you're watching it you know likeI could committed you to do somethingfunforeignI don't think we have any more questionsso we do the customary uh waving toeveryone to say goodbye uh we have ohjust like before that we have donewatching us from San Francisco which isgood uh we have Yusuf Potter fromEngland UK and then we have Ericpullings from einhoven Netherlands sothat's pretty cool it's uh it's good tosee already some people so thank you allfor watching and uh see you next timeand I'll see you on the with its likeand everywhere else Wherever You Arethank you everybody thank you thank youbye[Music]thanks for joining us you're right yes", "type": "Video", "name": "Weaviate Air \u2013 Episode #4", "path": "", "link": "https://www.youtube.com/watch?v=wJqtzGi1FVM", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}