{"text": "Thank you so much for watching! Introduction 0:00 Split after number of tokens 0:52 Rolling window 1:30 Parse by PDF Header ... \nwhen you ask the large language model a question it is important that it retrieves the most relevant information to answer it this is otherwise known as retrieval augmented generation for example when you ask Chacha PT what the name of your dog is it has no clue but if you feed it the data that is in stored in your vector database and maybe you specify that Erica has a dog and her name is Bowen chat gbt is able to retrieve that relevant context and properly answer your question in this video I'll go over how you can chunk your text data so to ensure that the language model is one receiving the most relevant information maybe instead of feeding it the whole PDF document you feed it by Elements which I have a visual for and then two you don't want to go over the context window and this is dependent on which model that you are using starting with the text splitter so what this does is it takes the PDF document which we have here on the left hand side and it it takes the chunks depending on the model or the chunk size that you defined so for example GPT 3.5 turbo 16k has a 16,000 token window but other models have either a smaller or larger window size um so just what this is doing is just splitting up the text once it hits that limit and then boom we have chunk one which is the blue text and then it moves right on to the green window which is the next chunk the rolling window complements the text spitter extremely well and this is because once chunk one is finished chunk two will begin with a few tokens or characters that is included in chunk one so in this example you can see the blue text from this document is the beginning or the start of Chunk 2 and this is very important in documents where the second sentence doesn't make sense because it doesn't have the information from sentence one llama index Lang chain and hstack they all three have this implemented in their Frameworks and at the end of this video I'll share with you the link to the documentation so you can test this out for yourself moving on to how you would trunk PDF documents so previously shre and I partnered up on creating a demo for unstructured so what we did was we ingested PDF documents which were two research papers and then we chunked it by the elements which unstructured has and if you haven't used unstructured before I highly recommend checking it out along with llama index um so what it is doing is it takes the PDF heading so in this example I have the abstract introduction and related work so each section will have its own chunk and this is very important when making queries that are specific to title so this is that kind of semantic region of searching and maybe you'd have like the abstract property introduction property Etc and then this is one way to make sure that you have extremely relevant information if you're interested in using unstructured with llama index so if you start typing in unstructured you can f uh find the file loader here and this is where you can injust txt files doc PowerPoint jpeg all of it then moving on to the Llama index node parser so this is where you would Define that trunk size that I talked about and then also the chunk overlap so um with this chunk overlap of 20 token it is taking the 20 tokens from the previous trunk into the following trunk and this is a lang chain documentation on where they have their text Splitters um so they have I believe code on how to do this and maybe if you want to split the text by the new lines or also the chunk overlap and the chunk size as well and then ending with Hast stack they have the chunk size and then again the split overlap so you can check that out and then I want to end this video with recommending you join uh the arise Workshop that I will be hosting along with Aman from arise and Ronnie from unstructured we will be exploring the trunking techniques and reranking for enhancing your retrieval and the results in your frag application I hope you guys are able to join and I'll see you next time bye ", "type": "Video", "name": "Chunking Methods to use Custom Data with LLMs", "path": "", "link": "https://www.youtube.com/watch?v=h5id4erwD4s", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}