{"text": "Thank you so much for watching! Introduction 0:00 Split after number of tokens 0:52 Rolling window 1:30 Parse by PDF Header ... \nwhen you ask the large language model a \nquestion it is important that it \nretrieves the most relevant information \nto answer it this is otherwise known as \nretrieval augmented generation for \nexample when you ask Chacha PT what the \nname of your dog is it has no clue but \nif you feed it the data that is in \nstored in your vector database and maybe \nyou specify that Erica has a dog and her \nname is Bowen chat gbt is able to \nretrieve that relevant context and \nproperly answer your question \nin this video I'll go over how you can \nchunk your text data so to ensure that \nthe language model is one receiving the \nmost relevant information maybe instead \nof feeding it the whole PDF document you \nfeed it by Elements which I have a \nvisual for and then two you don't want \nto go over the context window and this \nis dependent on which model that you are \nusing starting with the text splitter so \nwhat this does is it takes the PDF \ndocument which we have here on the left \nhand side and it it takes the chunks \ndepending on the model or the chunk size \nthat you defined so for example GPT 3.5 \nturbo 16k has a 16,000 token window but \nother models have either a smaller or \nlarger window size um so just what this \nis doing is just splitting up the text \nonce it hits that limit and then boom we \nhave chunk one which is the blue text \nand then it moves right on to the green \nwindow which is the next chunk the \nrolling window complements the text \nspitter extremely well and this is \nbecause once chunk one is finished chunk \ntwo will begin with a few tokens or \ncharacters that is included in chunk one \nso in this example you can see the blue \ntext from this document is the beginning \nor the start of Chunk 2 and this is very \nimportant in documents where the second \nsentence doesn't make sense because it \ndoesn't have the information from \nsentence one llama index Lang chain and \nhstack they all three have this \nimplemented in their Frameworks and at \nthe end of this video I'll share with \nyou the link to the documentation so you \ncan test this out for yourself moving on \nto how you would trunk PDF documents so \npreviously shre and I partnered up on \ncreating a demo for unstructured so what \nwe did was we ingested PDF documents \nwhich were two research papers and then \nwe chunked it by the elements which \nunstructured has and if you haven't used \nunstructured before I highly recommend \nchecking it out along with llama index \num so what it is doing is it takes the \nPDF heading so in this example I have \nthe abstract introduction and related \nwork so each section will have its own \nchunk and this is very important when \nmaking queries that are specific to \ntitle so this is that kind of semantic \nregion of searching and maybe you'd have \nlike the abstract property introduction \nproperty Etc and then this is one way to \nmake sure that you have extremely \nrelevant information if you're \ninterested in using unstructured with \nllama index so if you start typing in \nunstructured you can f uh find the file \nloader here and this is where you can \ninjust txt files doc PowerPoint jpeg all \nof it then moving on to the Llama index \nnode parser so this is where you would \nDefine that trunk size that I talked \nabout and then also the chunk overlap so \num with this chunk overlap of 20 token \nit is taking the 20 tokens from the \nprevious trunk into the following trunk \nand this is a lang chain documentation \non where they have their text Splitters \num so they have I believe code on how to \ndo this and maybe if you want to split \nthe text by the new lines or also the \nchunk overlap and the chunk size as well \nand then ending with Hast stack they \nhave the chunk size and then again the \nsplit overlap so you can check that out \nand then I want to end this video with \nrecommending you join uh the arise \nWorkshop that I will be hosting along \nwith Aman from arise and Ronnie from \nunstructured we will be exploring the \ntrunking techniques and reranking for \nenhancing your retrieval and the results \nin your frag application I hope you guys \nare able to join and I'll see you next \ntime bye \n", "type": "Video", "name": "Chunking Methods to use Custom Data with LLMs", "path": "", "link": "https://www.youtube.com/watch?v=h5id4erwD4s", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": [{"text": "when you ask the large language model a", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 0, "tokens": 0, "vector": null, "score": 0}, {"text": "question it is important that it", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieves the most relevant information", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 2, "tokens": 0, "vector": null, "score": 0}, {"text": "to answer it this is otherwise known as", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 3, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval augmented generation for", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 4, "tokens": 0, "vector": null, "score": 0}, {"text": "example when you ask Chacha PT what the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 5, "tokens": 0, "vector": null, "score": 0}, {"text": "name of your dog is it has no clue but", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 6, "tokens": 0, "vector": null, "score": 0}, {"text": "if you feed it the data that is in", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 7, "tokens": 0, "vector": null, "score": 0}, {"text": "stored in your vector database and maybe", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 8, "tokens": 0, "vector": null, "score": 0}, {"text": "you specify that Erica has a dog and her", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 9, "tokens": 0, "vector": null, "score": 0}, {"text": "name is Bowen chat gbt is able to", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 10, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieve that relevant context and", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 11, "tokens": 0, "vector": null, "score": 0}, {"text": "properly answer your question", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 12, "tokens": 0, "vector": null, "score": 0}, {"text": "in this video I'll go over how you can", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 13, "tokens": 0, "vector": null, "score": 0}, {"text": "chunk your text data so to ensure that", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 14, "tokens": 0, "vector": null, "score": 0}, {"text": "the language model is one receiving the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 15, "tokens": 0, "vector": null, "score": 0}, {"text": "most relevant information maybe instead", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 16, "tokens": 0, "vector": null, "score": 0}, {"text": "of feeding it the whole PDF document you", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 17, "tokens": 0, "vector": null, "score": 0}, {"text": "feed it by Elements which I have a", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 18, "tokens": 0, "vector": null, "score": 0}, {"text": "visual for and then two you don't want", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 19, "tokens": 0, "vector": null, "score": 0}, {"text": "to go over the context window and this", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 20, "tokens": 0, "vector": null, "score": 0}, {"text": "is dependent on which model that you are", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 21, "tokens": 0, "vector": null, "score": 0}, {"text": "using starting with the text splitter so", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 22, "tokens": 0, "vector": null, "score": 0}, {"text": "what this does is it takes the PDF", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 23, "tokens": 0, "vector": null, "score": 0}, {"text": "document which we have here on the left", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 24, "tokens": 0, "vector": null, "score": 0}, {"text": "hand side and it it takes the chunks", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 25, "tokens": 0, "vector": null, "score": 0}, {"text": "depending on the model or the chunk size", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 26, "tokens": 0, "vector": null, "score": 0}, {"text": "that you defined so for example GPT 3.5", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 27, "tokens": 0, "vector": null, "score": 0}, {"text": "turbo 16k has a 16,000 token window but", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 28, "tokens": 0, "vector": null, "score": 0}, {"text": "other models have either a smaller or", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 29, "tokens": 0, "vector": null, "score": 0}, {"text": "larger window size um so just what this", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 30, "tokens": 0, "vector": null, "score": 0}, {"text": "is doing is just splitting up the text", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 31, "tokens": 0, "vector": null, "score": 0}, {"text": "once it hits that limit and then boom we", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 32, "tokens": 0, "vector": null, "score": 0}, {"text": "have chunk one which is the blue text", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 33, "tokens": 0, "vector": null, "score": 0}, {"text": "and then it moves right on to the green", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 34, "tokens": 0, "vector": null, "score": 0}, {"text": "window which is the next chunk the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 35, "tokens": 0, "vector": null, "score": 0}, {"text": "rolling window complements the text", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 36, "tokens": 0, "vector": null, "score": 0}, {"text": "spitter extremely well and this is", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 37, "tokens": 0, "vector": null, "score": 0}, {"text": "because once chunk one is finished chunk", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 38, "tokens": 0, "vector": null, "score": 0}, {"text": "two will begin with a few tokens or", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 39, "tokens": 0, "vector": null, "score": 0}, {"text": "characters that is included in chunk one", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 40, "tokens": 0, "vector": null, "score": 0}, {"text": "so in this example you can see the blue", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 41, "tokens": 0, "vector": null, "score": 0}, {"text": "text from this document is the beginning", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 42, "tokens": 0, "vector": null, "score": 0}, {"text": "or the start of Chunk 2 and this is very", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 43, "tokens": 0, "vector": null, "score": 0}, {"text": "important in documents where the second", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 44, "tokens": 0, "vector": null, "score": 0}, {"text": "sentence doesn't make sense because it", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 45, "tokens": 0, "vector": null, "score": 0}, {"text": "doesn't have the information from", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 46, "tokens": 0, "vector": null, "score": 0}, {"text": "sentence one llama index Lang chain and", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 47, "tokens": 0, "vector": null, "score": 0}, {"text": "hstack they all three have this", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 48, "tokens": 0, "vector": null, "score": 0}, {"text": "implemented in their Frameworks and at", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 49, "tokens": 0, "vector": null, "score": 0}, {"text": "the end of this video I'll share with", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 50, "tokens": 0, "vector": null, "score": 0}, {"text": "you the link to the documentation so you", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 51, "tokens": 0, "vector": null, "score": 0}, {"text": "can test this out for yourself moving on", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 52, "tokens": 0, "vector": null, "score": 0}, {"text": "to how you would trunk PDF documents so", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 53, "tokens": 0, "vector": null, "score": 0}, {"text": "previously shre and I partnered up on", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 54, "tokens": 0, "vector": null, "score": 0}, {"text": "creating a demo for unstructured so what", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 55, "tokens": 0, "vector": null, "score": 0}, {"text": "we did was we ingested PDF documents", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 56, "tokens": 0, "vector": null, "score": 0}, {"text": "which were two research papers and then", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 57, "tokens": 0, "vector": null, "score": 0}, {"text": "we chunked it by the elements which", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 58, "tokens": 0, "vector": null, "score": 0}, {"text": "unstructured has and if you haven't used", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 59, "tokens": 0, "vector": null, "score": 0}, {"text": "unstructured before I highly recommend", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 60, "tokens": 0, "vector": null, "score": 0}, {"text": "checking it out along with llama index", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 61, "tokens": 0, "vector": null, "score": 0}, {"text": "um so what it is doing is it takes the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 62, "tokens": 0, "vector": null, "score": 0}, {"text": "PDF heading so in this example I have", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 63, "tokens": 0, "vector": null, "score": 0}, {"text": "the abstract introduction and related", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 64, "tokens": 0, "vector": null, "score": 0}, {"text": "work so each section will have its own", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 65, "tokens": 0, "vector": null, "score": 0}, {"text": "chunk and this is very important when", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 66, "tokens": 0, "vector": null, "score": 0}, {"text": "making queries that are specific to", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 67, "tokens": 0, "vector": null, "score": 0}, {"text": "title so this is that kind of semantic", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 68, "tokens": 0, "vector": null, "score": 0}, {"text": "region of searching and maybe you'd have", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 69, "tokens": 0, "vector": null, "score": 0}, {"text": "like the abstract property introduction", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 70, "tokens": 0, "vector": null, "score": 0}, {"text": "property Etc and then this is one way to", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 71, "tokens": 0, "vector": null, "score": 0}, {"text": "make sure that you have extremely", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 72, "tokens": 0, "vector": null, "score": 0}, {"text": "relevant information if you're", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 73, "tokens": 0, "vector": null, "score": 0}, {"text": "interested in using unstructured with", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 74, "tokens": 0, "vector": null, "score": 0}, {"text": "llama index so if you start typing in", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 75, "tokens": 0, "vector": null, "score": 0}, {"text": "unstructured you can f uh find the file", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 76, "tokens": 0, "vector": null, "score": 0}, {"text": "loader here and this is where you can", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 77, "tokens": 0, "vector": null, "score": 0}, {"text": "injust txt files doc PowerPoint jpeg all", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 78, "tokens": 0, "vector": null, "score": 0}, {"text": "of it then moving on to the Llama index", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 79, "tokens": 0, "vector": null, "score": 0}, {"text": "node parser so this is where you would", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 80, "tokens": 0, "vector": null, "score": 0}, {"text": "Define that trunk size that I talked", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 81, "tokens": 0, "vector": null, "score": 0}, {"text": "about and then also the chunk overlap so", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 82, "tokens": 0, "vector": null, "score": 0}, {"text": "um with this chunk overlap of 20 token", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 83, "tokens": 0, "vector": null, "score": 0}, {"text": "it is taking the 20 tokens from the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 84, "tokens": 0, "vector": null, "score": 0}, {"text": "previous trunk into the following trunk", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 85, "tokens": 0, "vector": null, "score": 0}, {"text": "and this is a lang chain documentation", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 86, "tokens": 0, "vector": null, "score": 0}, {"text": "on where they have their text Splitters", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 87, "tokens": 0, "vector": null, "score": 0}, {"text": "um so they have I believe code on how to", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 88, "tokens": 0, "vector": null, "score": 0}, {"text": "do this and maybe if you want to split", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 89, "tokens": 0, "vector": null, "score": 0}, {"text": "the text by the new lines or also the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 90, "tokens": 0, "vector": null, "score": 0}, {"text": "chunk overlap and the chunk size as well", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 91, "tokens": 0, "vector": null, "score": 0}, {"text": "and then ending with Hast stack they", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 92, "tokens": 0, "vector": null, "score": 0}, {"text": "have the chunk size and then again the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 93, "tokens": 0, "vector": null, "score": 0}, {"text": "split overlap so you can check that out", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 94, "tokens": 0, "vector": null, "score": 0}, {"text": "and then I want to end this video with", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 95, "tokens": 0, "vector": null, "score": 0}, {"text": "recommending you join uh the arise", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 96, "tokens": 0, "vector": null, "score": 0}, {"text": "Workshop that I will be hosting along", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 97, "tokens": 0, "vector": null, "score": 0}, {"text": "with Aman from arise and Ronnie from", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 98, "tokens": 0, "vector": null, "score": 0}, {"text": "unstructured we will be exploring the", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 99, "tokens": 0, "vector": null, "score": 0}, {"text": "trunking techniques and reranking for", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 100, "tokens": 0, "vector": null, "score": 0}, {"text": "enhancing your retrieval and the results", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 101, "tokens": 0, "vector": null, "score": 0}, {"text": "in your frag application I hope you guys", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 102, "tokens": 0, "vector": null, "score": 0}, {"text": "are able to join and I'll see you next", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 103, "tokens": 0, "vector": null, "score": 0}, {"text": "time bye", "doc_name": "Chunking Methods to use Custom Data with LLMs", "doc_type": "Video", "doc_uuid": "", "chunk_id": 104, "tokens": 0, "vector": null, "score": 0}]}