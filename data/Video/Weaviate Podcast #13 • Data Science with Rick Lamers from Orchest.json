{"text": "Rick Lamers, CEO and Founder of Orchest.io. Orchest is a tool targeted at data scientists and this software simplifies building data ... \n[Music]hey everyone welcome to the 11th episodeof the we vva podcast today i'm joinedby rick lammers the ceo and founder oforcus.ioorchest is such an amazing software it'sone of those things when i first saw itin my day-to-day workflow i just saidwow this is something that i need to beusing and i'm so excited to be talkingmore about this and learning more aboutthe future of this and how the idea cameabout and all sorts of things related tothis super cool software so with thatsaid uh to kick things off rick can youtell us about uh what is orcisthey connor thanks for having me ofcourse happy to share moreum orcas is really a tool targeted atdata scientiststo simplify building batch datapipelines and sowhat we believe to be true is that datascientistshave this incredibly productive existingworkflow and typically it involves rapiditeration use of jupiter notebooks andthey're they're comfortable andproductive in that environment and wewanted to takethat workflow and bring it closer tothe process of productionizing thesetypes of scripts and notebooksto a batch runnabledata pipeline with all kind ofattributes one might expecta data pipelinedeployment tool to havebut we really had the vision to make itaccessible and familiarto data scientists data analysts who arecomfortable writing python and r uh andeven julia or bash for that matter we'repretty language agnosticand that's what we've tried to build soif the audience is familiar withsomething like apache airflowthey can see orcis as a similar versionto that but a much uhsimpleruh story around how to actually deployit and and really a lot more accessiblein terms of uh more similar to the vibeyou get when you open something likejupiter labyeah i think even if you have noexperience with production anddeployment if you go to orchest and youwatch their introduction video you willinstantly it takes maybe 30 seconds tounderstand how to plug in together thepipelines and i love the way that itdecomposes your jupiter notebook soyou know if you're a data scientistworking with these jupiter notebooks andyou collect these monolithic notebooksand maybe you're organizing them withlike the hashtags to collapse the tabsand have that kind of organizationcompared to these pipelines or you canjust separate out the things so whatkind of things went into the design ofthis ui how do you see the future ofides with with data science notebooksand i love the you know the fusionbetween python scripts and jupyter nopeand jupiter notebooks that are in theorchest layer so how did you come upwith this kind of user interface designand what are your thoughts around itgenerally so so great question and wewe really spent a lot of time thinkingabout the design tool and it was kind ofbuilding something we'd want to be usingourselves we'd been both working as datascientists in the field and larger teamsand what we felt um was thewhat was needed was the flexibility touse the right tool for the joband sowhat we felt like was sometimes theright tool for the job was a notebookbecause we could really appreciate thekind of rebelorientedyou knowstyle of coding in a notebook and forparticular types of tasks that kind ofvery rapid iteration can be very helpfulespecially if you're doing kind ofexploratory data analysis but we alsosometimes felt that once we had a veryclear vision of some sort of isolatedmodular piece of code that is justreally kind of uman abstraction or clear abstraction ofcertain functionality maybe in pythonclasses that it feels very awkward towrite that inside of a notebook so wewanted a tool that could blend thesimplicity of scripting and notebooksand allow us to kind of flexibly piecethem together in a way that requiresvery little changes to the way we workedbecause i remember looking at all kindsofeither ml ops or workflow orchestrationtools and they just asked so much interms of like please change your entireworld view and really buy into ourframework transform your entire you knowtransform your entire code base intothis you know application that's codedagainst our api and there's just so muchbuy-in at the code level uh into thescheduler framework that really didn'tmake sense to us we were like i justwant a way to bundle and connect andschedule this code but i don't want tomake the code like dependent on athird-party framework and really embedthat into the code and i think you knowapache airflow for all the the wonderfulthings it brings and it's really uh aninnovative project that has brought manygood things i think once you realizethat like the the entire scheduling anddata science processing codeis kind of fully intermingled you canstart to realize some of the downsidesespecially if you want to think aboutthe deployments uh in a more a bit moreflexible way where sometimes you'redeploying on your local machine becauseyou're testing but sometimes you want todeploy on a larger cloud cluster andlike how do you not become intermingledwith your scheduling framework too muchyeah the modularity of it is incredibleand i yeah i love that theminimal buy-in when you're adding thisnew ml ops tool i completely understandwhat you're saying where you have allthis integration that you have to do totie your code base into most of theseexisting ml ops toolsso another thing i wanted to talk aboutand something that again just stood outto me is wow i need to have this this isso incredible is the the cloudabstraction that you've provided withoricas and things like say say you havea web scraping python script thatscrapes your data from some website andyou want to schedule that as a cron jobwhere you have it run every day or everyweek or say you want to schedule theretraining of your models every weekonce a week and orcas has this beautifulintegration where to access these cronjob services is just like a few clicksto be scheduling it up can you tell meabout overall this uh this idea of likethese cloud abstractions where yousimultaneously build a software platformfor mobs but you also kind ofabstract away the complexity of thecloud computing into the software aswell yeah i i think you know youmentioned a great example scraping weyou know a friend of mine was trying tobuy a house and he really wanted to makesure that he got uh like quickinformation notices uh the momentsomething came available and so he hewas writing these uh these cloudsscraping umor these python based scrapingalgorithms and and and this bit of codeand umthe advantage that orcas then providesthat if you're thinking about deployingthis as kind of a regular cron scheduledjob to execute you also often need tothink about the dependencies you need tohave installed and in particular i thinkhe was because he was familiar withselenium he wanted to behe wanted to use selenium in the projectand what orchest bundles as part of itsplatform because it's fully based oncontainerizationbehind the scene so not very explicitlyexposed to the user you don't have toknow anything about docker kubernetesbut behind the scenes everything is acontainer it allowed him to just specifythe system level dependencies even andthe python dependencies of the seleniumpython package and he could just bundlethis whole thing and deploy it veryeasily as a pipeline and all he neededto do is in the orca's web ui he justneeded to run the bash commands he wouldnormally use on his local computer rightso it's like whatever you would normallytype into your terminal to make thedependencies work basically one to oneyou can input that into the work is whatwe call environment setup script andit's it's just a bash file that getsexecuted and it's almost likefine-tuning an ml model but it's likefine-tuning a docker image so it's likethe final steps to fine-tuneyour docker image uh to the dependenciesthat you need and therefore it becomesvery easy to take your full pipeline andjust run your quick setup script andthen actually run your code and we canthen deploy that anywhere so for him tobe able to have system level dependencedependencies like selenium really madeit easy to like deploy that as a bundledirectly in the orchest environmentwithout ever having to leave the browserright and i think that's really powerfulthat you can be at the abstraction layerof containers without actually having toworry or know about themso you get the power none of thecomplexity and that's really kind of inline with the main goal of the productit's extremely exciting for the adoptionof the technology and yeah like you saylike you don't even have to leave thebrowser to set up the different dockercontainers and integrate differentscripts that use different kinds of uhdependencies and all flowing into thispipeline sokind of later on in the podcast we'regoing to talk about the integration withwev8 and how you uh connect thesepipelines into we vvates say pythonscript to process the web scrapeddocuments and then put them into yourwebva database but first i want to talka little bit more around these topicsaround ml ops and i think um sopersonally i'm just coming out of aproject where i've developed this thingcalled karasbert it's a language modelof keras information and i've beenadding data sources withthese pipelines that i just think wouldjust fit so perfectly with orcas when isaw the initial diagram i just thoughtwow this is exactly what i'm doing in amuch more organized way i love the lookof this and so thinking about continuallearning and that kind of researchproject as you're integrating andreusing your models andparticularly these um as you add datasources and then you add newgeneralization tests is continuallearning maybe the aspect of ml ops andthen following from here i want to talkabout hyper parameter tuning but iscontinual learning kind of maybe the thekey focus of this i think continuallearning is getting more attention andrightly so i i think the notion that youtrain your model once and that you'rebasically done is kind of ana notion that's no longer held by mostof the ml community they they all kindof realize maybe you start out withsomething but sooner rather than lateryou're going to detect and identify theareas in which your model is notgeneralizing well and you're going towant to feed it examples uh that willbasically fill out those holes if youwill of the the generalization landscapeand the way orcas thinks about this isthat a lot of the retraining can easilybe formulated as a as a scheduled job orjob that gets triggered under a certaincondition and so what we generallyrecommend people to do is they build apipeline and orcas and to make it itempotent so if you run it multiple timesyou will basically get quote-unquote thesame resultbut if in instead of making it truly iitem potent but really kind of make itrefetch the latest kind of trainingsource whatever wherever you have thatstored you basically can kick off apipeline many times whenever you feellike it's a good moment to retrainand of course you also want to get someinsight into how that retraining wentright and that's what where the beautyof having notebooks is part of yourproduction pipeline uh comes in becausea notebook has the element of capturingthe rich data that is generated on diskin the file itself it's the jupyternotebook format it contains this outputand it has a huge advantagewhich means that if you run thispipeline or retrain your model you canalso capture with it not just thetrained artifact but also all these kindofdata points that you might care aboutlike how does the what does thegeneralization look like or you maybeeven have an updated test setbecause you've maybe have expanded yourtest samples in order to now account forthese areas you discovered wereunderperforming so i think the the themodel of batch processing goes hand inhand with continual learning of modelseven if your modelis really just afine tuning of a larger trained model innlp this is often the casei think this this kind of batchmodel just really aligns with thatreality of needing to continuouslyimprove the quality of your predictionsyeah and coming back to this idea of howit's bare bones there's so little buy-infor using the orcas framework if youwant to integrate you know hug and facetransformers the gina ai fine tuner ormaybe you say mosaic mls composerrubrics data labeling or all thesethings like even weights and biaseshyperparameter tuning or say determinedai hyperparameter tuning you canintegrate all these things into thepython scripts and they just easily pluginto oricas which is another thing ijust think is so exciting about this uhso can we talk a little more also abouthyper parameter tuning i know some ofthat is uh built into orcas as well whatare your thoughts around that kind ofidea yeah i think you know anyone who'stried to train a model will discoverthat it's not so much of an exactscience as much of a black art whereyou're really trying toidentifyhow in what configuration is my modelbehaving optimally and it's not alwaysclear a priori how that like what thatlooks like in terms of hyper parameterconfigurationone of the design goals for orcus hasalways been to take the best in classopen source tools at the disposal to youknow the data scientist or the machinelearning researcher engineer and makethem easily integratable in thatenvironment so because we're at theabstraction layer of containers you cantake advantage of the whole range ofopen source uh tools and the ecosystemavailable uh to do your uh your modeltraining and you know a really coolexample that i think the the especiallythe nlp crowd will recognize is the kokiuh text-to-speech speech to text umtools that are available like itscommand line can just be integratedsimply into orchestand that can that can even trigger liketraining jobs that are not evenin a specific language but they'reactually just like command lineinvocation of a tool that's availableand i think this kind of agnosticityreally allows you to take advantage ofall the work that's going on theecosystem and not really tie yourselfinto a specificlanguage or framework andthat's that's been the goal since dayone is how do we empower that existingworkflow but also how do we make sure weleverage uh all of the ecosystem and notjust the the strict subset of pythonbecause frankly if you look at a lot oflike sophisticated statistics a lot ofreally good work is going on in r and ithink you know giving those peoplesecond rate experience would i think bereally bad if you're building anorchestration tool right i think thatshould beat a much moregenericlevel than a biasing a particularlanguageyeah and i think the the integration ofsay in uh in weaviate as we build deeplearning for search and we build searchpipelines you could think of thisorchestration layer is just so amazingthe way that you can connect all thesepipelines so usually in these searchpipelines we have retrieval then we havesome kind of retrieval fusion then wehave say re-rank or question answeringsummarization supervised learning modelsat the end of it so in thisorchestration pipeline you could add theinference features as well the routingin the pipeline connecting the scriptsto each other so it's such a greatabstraction for say you want to haveyour particular component where you'reupdating your embedding model or youhave some other pipeline for how youupdate your re-ranker modeland this whole thing of creating thiswhole end-to-end experience whereit can be not just training but alsoinference have you thought a lot aboutalso the pipelines for maybe say likeensemble learning and aggregatinginferencesi think ensembles area great example of howreal ml has converged torealizing that it's a powerful techniqueeven though like the like thetheoretical analysis of an ensemblemodel is super difficult because you'redealing with sometimes veryfoundationally different concepts of howprediction is generated so integratingthat mathematically is super hard but inpractice it tends to really work superwell right so you might want to make useof it so if you're if you're doing kindof multi-model inference in order to getan ensemble resulthow do you make sure that the code endsup being same like how do you make surethat this thing still feels likesomething you can control i i reallyremember the stories of kagglewherecompetition winners would often oftenhave solutions that are so complicatedthat the winners would not even be ableto implement it for the company who wasorganizing the competition because itwas just so complicated so what we'rereally trying to do in orcas is to getthat modularity where a single step canbecan represent the inference of a singlemodel and you can even have you knowthese steps be parameterizable so youcould even have a single piece of codeor a single script or notebook thattakes in a parameter which basicallychooses the model and then you can usethat same step multiple times in asingle pipeline and then there's somesome insanity and overview right youknow exactly that this step isgenerating uh the result and you canhave it very visually laid outand i feel likethat approach of of providing structureso you at least can see at a glance ofwhat is my pipeline doing in totality isvery powerful if you're not working byyourself in particular i mean it's goodto have overview for yourself buttypically you have a pretty good uhrepresentation of what you're buildingin your mindi'm sure all coders can relate that theycan like blindly navigate the ideas theyhave but that's not so much true ifyou're working together right becauseyou can't really look inside eachother's mental models and so we have toindirectly communicate intent and ithink the dag just really naturallylends itself for this right so that'swhy we really like um the experiencethat we've been getting described backto us from users of orcis they'll tellyou look iremember uh inheriting a pipeline thatwas written in one of these abstractframeworks that allows like almostarbitrary degrees of freedom in terms ofhow the dag is actually generated so itcan take on arbitrary complex shapes andthen getting like an orcis pipelinewhere it's just like prettydeclaratively defined it's just likethis this one defined dag and i can muchmore easilyfind my way through like okay what'shappening start to end and i think youknow you asked about ensembles i thinkit's one of those examples where ifyou've ever touched a code base whereensembles are usedyou'll get that feeling of being a bitlost of like what's happening whereyeah i think it's so interesting too forinteracting components of systems likesay you haveagain these search pipelines where youhave several different components of itand and yeah i love the cargocompetition pipelines that example likeknowing about orcas now it makes it soeasy for me to visualize these thingsthat the dags as you say just thinkingabout plugging it into dags having themodularity and also the cloudintegration coming back to that but itjust makes it so easy to visualize howyou would really engineer things likethis and that's just something that isinspiring so much excitement with meabout learning about orchest and alsosay things like reinforcement learningworkflows where you might have somemodel based agent you might have your qlearning you're separating all thesecomponents out maybe you have like agenerative adversarial network thatgenerates data that comes back into yoursupervised learning modelall these components that flow througheach other and this is justcoming back to i think because there'ssuch a little buy-in it's your pythoncode it's so easy to understand how thisthing connects together so kind of tocome into a like these real examples youhave with orchest um can you tell memore about your integration with um withthe forum scraping and we v8 andcreating the question answering systemyeah of course soumthethe really nice thing like you mentionedwith orcas is that you can take anexisting code base and you know youmight have your work divvied up amonglike five notebooks you maybe havenumbered them neatly and it's like onetwo three four five or you could have acouple of scripts that you usuallyexecute using the command line and youparameterize them like the way to getstarted in org is just like you you dragthat file onto the canvas and it's astep and it will get executed in its owncontainer and you have to do almost nowork to go from existing code base in agithub repository you just import therepo repo as a project directly and youcan get started and so one of thechallenges that i wanted touse as a way to evaluate are we doing agood job with orcus is can itakelike a very simple example of how to usewe v8 from python for data ingest andthen also for for searching with withgraphql um can i can i make an orcishpipeline out of that that does this inthe maze straight in the moststraightforward way and um thatexperience honestly was was really uhlike in a way it was a relief because itwas like testing our internal hypothesesabout like how the product shouldfunction and it turned out to work uh sothat was that was a a nice experienceand the end result is basically a codebase that if you look at it outside ofthe context of orcis you could justrun it and you you could basically justsee all of what's happening for like theingest and and uh querying the we v8engine from a streamlit context so theway this pipeline works is we we allowyou like i mentioned to integratethird-partyservices so we have a streamlitapplication aviate database running andthen the orcis pipeline itself is incharge of fetching data from theinternet uh scraping basically commentsand then injecting them into thedatabase and so the actual pieces ofcode are just like fully independent ofwork it's like streamlit is just astreamlit app it's a python file itloads itself it speaks for itself it'svery simple and then the vv8 umservice running is just like a verysimple instantiation of the containerservicethat we've yet provide so all of thesepieces individuallynothing of that really requires any kindof orcas knowledge but then the finallayer that makes it all work is that youhave this one pipeline file which is theorchest file and that pieces togetherall these things so it pieces togetherthe container services so it has thedefinition for the streamlit containerit has the definition of the vv8container and it has the code inside ofit to drive the streamlit app to drivethe uh the the ingest into ev8 and sothese pieces are basically uh gluedtogether by orcis and the way you dothat is by simply just connecting acouple of things in the graphicalinterfaceand i think like uhthe the fact that that full definitionis then fully versioned as part of therepository and allows someone to takethis pretty complicated uh thing whichis like web scraping that like actuallyscales ingests into a vector databasethenserves aan application on it on its own portthat runs the streamlet uh you know codeto to generate the dashboard that letsyou interface with the vva database froma querying perspective like to have thathas actually worked one simple projectin a normal github repository that youcan import as a template and just startediting and playing with i think thatreally shows the power of three reallycooltools combined right like it's thesimplicity of streamlight it's the it'sthe power of we v8 for both ingest andquerying and then kind of like piecingit together as an orchestrator um thatthat didn't require to change any ofthose other two parts right which wasthe main main idea so yeah that to mewas just usually exciting to be able tolikesee that thesis of integrating otherbest-in-class open source into a singletool come together that was just reallyfun uh honestly to build as a projectyeah and we haven't even talked aboutlike stream lit and gradio and how thatbrings the user interface also it as apart of these pipelines and and againjust easy python code that can bewrapped into these pipelines it's justso exciting and then um so we've talkedso much about the engineering details iwant to kind of step up a little bit andtalk about this application of uhsearching through blogs and questionanswering through blogs do you see thatkind of changing the fundamental waythat we use say kind of like bloggingand social media and that kind ofgeneralthingabsolutely i think we have thisunique opportunity today i meaneverybody has been talking about bigdata and like so much data becomingavailable and like so much data beinggenerated at every given minute but it'sreally true and if you think about theimplication of having this much data itcan actually improve fundamentally howyou operate and i think now that toolsare coming availableto make this easier to doeven with a simple example like like imade like what i built at a high levellike without the technical details is itallows you to search through comments uhof someone on a forum and it's this thisfamous dutch forum it's called tweakersit's for people who love technology andi remember when i was uh thinking aboutgoing to grad school i was doing a lotof searching on the forum because ireally wanted to understand people'sexperiences having gone through that andi realized that the data was publiclyavailable because the forum was publiclyaccessible but the search was reallyhonestly it was quite bad so i reallydidn't have a good way to get to thatdata and query it and so i think withthe amount of data available and nowpowerful paradigms like vector searchengines coming available to be able toactively activate that kind of knowledgewhich is like a huge sea of data but howdo you actually tap into it i thinkthat's the key and applications are nowcoming availablethat make this simple and i think codexyou know is a great example of takingall this embedded knowledge of like howto write uh against a new api ofsomething like writing your first flaskapp with and without codex is just nightand day right and sothat's tapping into source code i'mtapping with that example into all kindsof tacit knowledge that people haveabout like school and educationspecifically in the netherlands and so ifeel likeum actually being able to tap into thatdata um is such an exciting trend and ilove seeing all these kind of likeintuitive or like uh ingenuitiveprojects from people who find publicdata resources and really do somethinginteresting and cool with it and so likeconcepts like open data but even justlike accessibility of like reddit dataform data like i think that's reallyreally excitingyour example with vector search hasreally opened up my thinking about whatmight be the future of say youtubing andmaking content for technical knowledgeand i was thinking a lot about myyoutube channel with deep learningvideos and how we kind of with questionanswering we kind of have like twoparadigms where there's extractivequestion answering and abstractivequestion answering and abstractivequestion answering kind ofencapsulates this idea where like youturn me or say yana kilter someone whomakes content into like a chat bot andnow you can like talk to that chatbotand they can general generate novelresponses compared to extractivequestion answering whereyou really just need to match yourquestion with a clip in the youtubevideo and thinking about your examplewith vector search with this blogwebsite i was thinking a lot about howyou can transcribe all of the youtubevideos to create this big text documentand then with the question answering youcan match it to a text snippet and thenyou know get the 30 second video and ithink that might be the future of usingyoutube where oh my god i couldn't icouldn'tagree more and this specific example issomething i've been bugged out about forso longlook i love podcasts but i have verylimited time you knowwe're very busy and organized and we'relike we're spending so much time workingon the code and on the tool with theusersso i would love to be able to tap intopodcast content how do i do that withoutlistening to all of it there's so muchlocked up and so what i really like isthat they're in our tools that would letyou do a hackathon project where youcouldliterally takeyou know50 of your favorite podcasts downloadall episodes do nlp to extract you knowthe transcripts and then to feed thetranscripts into a vector search engineactually it might be my next projectwith we've eaten orcas but it's reallyreally cool to be able to tap into thatkind of knowledge with the effectivenessof search because without search youknow umyou you wouldn't be able to tap intothat knowledge so you really need a wayto be able to quickly look at a largevolume of data and i think you knowgooglereally did a good job of doing search onthe internet for web pagesbut the world has turned into so muchmore data than web pages in fact i thinkfewer and fewer individuals areproducing web pages right like they'repreproducing rich media content and it'sit's so important that we actually tapinto the knowledge of that type ofcontent uh too and so yeah that justgets me super excited as you can noticeyeah we had um we had alex kanan fromzencaster which is the platform ofrecording this hollywood qualityaudioand uh he explained their efforts withuh with pods podcast transcriptionsearch and yeah it's just such aninspiring thing and and coming back towhat you're saying with the rich mediait reminds me of say jeremy howard withfast ai he made a lot ofvideos where he would be live streamingcoding and so the live streaming codinghe's going to encounter errors doingthat that someone who'spre-meditating a youtube tutorial on saykeras pie torch like here's how you do adata loader you're not going to seethose errors you're not going to quicklysolve them as much so the questionanswering flexibility that's enabled bythese live stream coding sessions whereyou encounter the error and solve it inthe real world and thenusersis put into stack overflow they're lostthey need this new data source to solvethis problem have you thought about likewhat if you try to digitize all yourknowledge and create a system like thisyeah i think the the potential likea lot of people gravitate towards lowfriction content creation which is whythese live streams are such a nicemedium because a lot of very smart uhpeoplelike jeremy howard they they need to beeffective with their time so if they canjust do a live stream where they go intouhprojects and showing things or of howthey're done you know already that's somuch value to be given out but how doyou then increase the value of such uhcontent that's being created i thinkit's by indexing it properly so so youcan very quickly jump into the content ithink a great example of this um wherethe necessity and the value of it is asimple phenomenon of youtube chaptersright like you now go to videos that arelong form or people commentingcommenting like where are the chaptersplease give me the chapters and you knowthere's no reason why with the currentstate of technology we couldn't generatethose chapters or markers or beintelligent about like allowing peopleto to jump to the relevant bit ofcontent uh i think thejeff bezos has an interesting quote healways uh says likebet on the things that are probably notgoing to change right like what issomething that probably nobody's gonnalook back on like i'm not sure if that'sgonna be something in the future and hementioned the example of like peopleprobably don't want to wait longer forthe goods to arrive right likeoptimizing shipping time is probably abet you can make for like the next 10years i think attention and timekind of scarcity for for peopleespecially like you know productiveprofessionalsis definitely going to be a thing in thefuturebecause people are just getting less andless time to get to all the kinds ofthings they could be doing there's justso much interesting stuff to work on andsobeing able to to to work on technologythat taps into thatfoundationalum trend where people are gonna have todo more and less time and are trying todo more and less time like i thinkthat's really powerful and to me likethese type of topics we just discussedthey're like oh in that kind of bucketyeah i love that and i thinkyeah like what won't change like you canbuild this right on top of youtubethere's no need to start an entirely newplatform it integrates perfectly and theorchest layer of adding the web scrapingfrom python it's it made like orcas issuch a brilliant abstraction that itmakes these whole this whole applicationdomain and this whole thing that soundslike a grandiose vision it just it's soeasy to visualize how it would plugtogether with this abstraction so comingback to orcas can you tell me about yourexperience with building a company yourvisions for the future and justyeah like what your experience has beenbuilding this companyyeah happy to dive into that area ithink it'sit's it's one of those things where i'velearned so much over the past two yearsi couldn't really imagine learning somuch and i remember thinking at thebeginning so we started a little undertwo years ago we started working onorchest and i remember thinkingshould i actually start a company now orshould i maybe get a job first and maybeget a bit more experience and then mayberead a bit more about how to start acompany and likelurk some more on hacker news and likeget some more you knowadvice under my belt and i feel like atthat pointirealized thati should probably just go and startbuilding the company becauseit feels like i'm i'm kind of hitting aplateau on the kind of knowledge that icould absorbfrom the sideline so to speak and sogoing into it i realized that was verymuch true it's very much true thatthere's only so much you can learn fromobserving other people doing a thing andi think it's true for many areas i thinkit's true for uh you know good examplesfor me that come to mind are mathematicsand programming like you can read aboutit all day you can read all theprogramming books but unless you've beenin charge of building an actual systemand dealing with the problems ofupdating software state migrationchanges like all of those examples andtheoretical explanations are not goingto stick as much because you don'treally have the kind of experiences tokind of relate that knowledge to and soi very much feel like that with thejourney i've been on with starting thesecompaniesthinking about how to solve the problemsthat come up organically when you starta company and like how do you convincepeople to buy into the vision thatyou're uh trying to realize withouthaving realized that vision like thatrequires in conversation to talk abouttheum you know the ideas you have in a waythat makes it accessible for someone whodoesn't know yet what you're trying totalk about and so vocalizing thoughtsaround a product idea like that'ssomething that's so hard to learn from abook to be honest so i really umlike that you know i decided to takethat leap and i think i would advise iflisteners are thinking about starting acompany to just go and do it i mean imean i know it sounds super cheesy andit's it's advice that's been repeated athousand fold but i i really do thinkthat at some point you just have to jumpin and you'll start to discover allkinds of things about doing it uh and itturns out that there's also a lot ofroom for not doing everything perfectlysoyeah that that to to me has been thereality is like you you kind of can onlylearn it and and grow so much from thesidelines and doing it umactually is is what actually makes youkind oflearn what it's actually all about soi i really enjoy this um this newchapter of uh post graduationum company building it's been so muchfunyeah i think our artificial intelligencesystems can learn a lot from that lessontoo where maybe uh like some kind ofreinforcement learning some kind ofaction would help them even take thatleap as well yeah yeah i think you knowif you're never going to take an actionyou're never going to get that syncol sowhere's the reward right you don't knowwhat has been the most challenging saynew skill for you to learn as becoming aceoi would hands down saythinking about how to make other peoplesuccessfulbecausecomputer science and softwareengineering and even you knowtheoretical research university ispretty individualisticyou just have to really own the materialyou have to go to the lecture understandall the complex topics that are beingcommunicated you try to absorb all of itand you try to synthesize that knowledgeinto uh being able to apply thatknowledge to new problems and like in away just generalize to new cases butthat's like a veryuh individual process it's like you andthe theory right you and the knowledgeand uh what i've realized uh when youstart a company it's you're trying toset up a group of people uh for successand the way to do that is to figure outwhat's preventing them from you knowoperating at maximum velocity so what'sholding them back and it's also aboutprioritizing but also figuring outprioritization in a way where you candirect people to work on the rightthings in a way thatum uhactually works with with with the waythey work so you can't just ask peopleto shift targets every other week rightyou need to also think take into accountthe cost of switching the the cost ofrealigning what you're working on soum uh and you also need to take intoaccount what are their goals right likeif they want to learn more about aparticular area of programming or likehow can you kind of make all these likecombinations um that end up makingpeople uh happy with the kind of workthey're doing and like not uh wastetheir really good potential because youwe we've been able to attract we've beensuper lucky to attract like really smartpeople who really know what they'redoing and like i feel pretty bigpressure umto not mess up you know their capacitylike if i let them work on the wrongthing for months like that's on me i'mwasting their time it's not like theirfault that they're working on somethingand it's like a two-way street rightlike you don'tdictate like what everybody's doing it'slike you talk about it with everyoneinvolved like what do you think weshould be doing what it what is youridea of like what's the highest impactthing we could be doing right now and soi think those are all new experiencesthat umi very muchwas and am challenged by and i try to doas good of a job that you can do withouthaving a phd in that kind of stuff rightyeah it sounds so interesting anddefinitely like something that you needto learn on the job too with thejust the nuances of people'spersonalities and all sorts of thingslike that and so on this topic furtherof um the high impact thing and not togive away the secret but do you havelike alike a thing in the say six months to xyears or however the time span is thatwould be added to orchest that you thinkwould be a game-changing thing we'reworking on something that i think isreally big umandit's it's always been part of the visionbut we're now actually close torealizing it andwe've always felt that there needs to bea proper abstraction so that distributedsystems level performance where thingsare fully distributed runningindependently and performing at themaximum capacity of of machines on whichit's run not by like the the manual workof a coder thatdata scientists can actually takeadvantage of the hardware that we haveat our disposal like these cloudplatforms they have wonderful scalingcapabilities butmore often than not it's stillfrustrating and complicated to actuallytap into it how often do you not findyourself kind of justseriallysaturating a single node that you're onand so we've designed orcas from theground up because of thecontainerization primitives to be ableto schedule over a large cluster maybehundreds of nodes uh in a kubernetescluster to be able to run all kinds ofcode in parallel and even within singlepipelines being able to split upindependent tasks and run themsimultaneously even on heterogeneousnodes so maybe one task is very memorybound and one is very cpu bound andbeing able to allocate there and whatwe're soon to be what we're soonreleasing is as part of the open sourceproject it will be this fullydistributed version where the controlpane of orcas itself is fullyindependent from all of the scheduledtasks that are running as part of thepipelines and so this i think is reallyexciting we're actually going to do alive release at the upcoming datacouncil event in austin so that's goingto be hugely exciting for us and thewhole team and you knowthat vision of making it that simple todeploy these production ready batch datapipelines on a large cluster of hundredsof nodes with the simplicity that wehave in the tool today i think you knowthat is going to be a very excitingmilestone for usyeah i completely agree i i'm thrilledto know about orcas now and i yeah thatabstraction says amazing the clickingthe swiping in and out of differentcloud services within this pipelineabstraction already in the containersincredible so what is um so kind of likeone more medical question about yourgeneral uh training so to say is how doyou kind of do your information dietwhat kind of do you read blog posts doyou read scientific papersexperimentationit's a great question and ii uh i saw this around um i saw thishint being uh given by other people ithink uh just recently i saw i heard itmentioned by the guy who founded appsumowho's an interesting character to followbut it's about umso there are a number of informationsources but how i actually digest it isby writing down a lot i write down a lotand i think paul graham has this reallycool essay as well about how if youhaven't written about a subject youdon't really understand it or you don'treally know enough about it to beconsidered an expert on it because whenyou writeyou kind of have tobe honest about what you actually meanright you can keep stuff pretty vagueinside your head you can like keep itkind of like partially defined where youthink you know but you don't really knowand everybody everyone who's written amasters or pc thesis will knowwhat it's like when you try to formalizeyour thoughts and then discoveringgaping holes in your your understandingsoin terms of information sources i try toreally you know i'm a very active lurkeron hacker news and sometimes responderwhere a lot of interesting softwarethoughts are being shared i think foracademic knowledge on deep learning andi really like also kind of more umquote-unquote simple mathematicalanalyses of maybe like a support vectormachine and its generalizationcapability so likefor papers i tend to rely on liketwitter feeding me uh you know therelevant and interesting articles thatare up in archive um and then umi i tend to browse reddit because ireally like how uh kind of brass tacksit is like people talk about veryspecific types of challenges thatthey're facing in their work and youknow their work as a data scientist andlike tool comparisons and that kind ofinformation and then there are somequite good books that are being writtensothere's lately been a book i picked upthat's about umwe can maybe link it in the show notesbecause i don't know the full name andauthor but it's about basically themodern uh data pipeline uh set up andhow you know to think about thedifferences in etl and elt and how youknow all these concepts kind ofmap to different types of tools andtechnologies now so using like a verydiverse collection from papers to socialchannels like hack news and reddit umand books i will try to distill uh theknowledge into written form that arelike private notes i i don't keep themprivate because i don't want to shareit's more that if i know that they'reprivate i can write more freely and thatit actually works more as a device forkind of processing the informationand i also like to make lists so i havethis website called www.alldatatools.comit's an open source list of all the datatools that i could find that aretargeted at technical professionals so ii excluded like no code tools because ifeel like it's a category that i'm notspecifically trying to map and catalogbut it's it's really kind of away for me to also have a good kind oftaxonomy and list of what's going on inthe space and i like to use that as atree to also kind of connect theknowledge that i'm gaining too so someareas of nlp some areas of moreengineering topics and so you knowthat's just a little bit of how i try tostructure my thought buti don't know what do you dooh uhwell yeah i really like the idea of thelist i've i've tried to take lists but ifind it it can be kind of intractablelike it blows up quickly when i try tojust do a top-down list and i struggletouh keep the high-level categories thatmap the list and keep that ontology sanesort of with deep learning research butyeah i completely agree i love writing ithink writing it forces you to as yousay you know be clear about what youreally know andyeah ifor me writing is definitely a hugesource and then yeah twitter the socialfeeds i definitely disagree with allthat and theni do think running experiments is alsojust a huge way to build your knowledgefurther as you mentioned with theexperience of building a company youneed to actually do it and just ingeneral making sure you're doing itinstead of just talking about it too butyeahreally cool stuff nice so thank you yeahso thank you so much rick uh i thoughtthis was such an informative podcast i'mso excited about orchest and i lovedhearing about the integration with wev8as well i think this is such an excitingthing for the future of data science anddeep learning technology becomingrealized into things like as we talkedabout the uh the future of bloggingwhere you could have a direct questionwith a blog or a youtube channel and ithink all these things are just reallycoming together in such an exciting wayso thank you so much for coming on thewe va podcast thanks for having me[Music]", "type": "Video", "name": "Weaviate Podcast #13 \u2022 Data Science with Rick Lamers from Orchest", "path": "", "link": "https://www.youtube.com/watch?v=QlhTJ2n_Kog", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}