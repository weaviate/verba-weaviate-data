{"text": "Hey everyone! We are super excited to publish this podcast with Vinod Valloppillil and Bob van Luijt on Open-Source AI and ... \nhey everyone thank you so much for watching another episode of the WEA podcast I'm once again super excited to be joined by WEA co-founder and CEO Bob vanl and welcoming a super exciting guest venod valap venod has one of the most impressive resum\u00e9s I've ever seen ever met someone this accomplished in the technology industry uh Google Dropbox Microsoft startups and all these things venot it's such an honor to have you as a part of the WEA team as an adviser and of course today on the weeva podcast thank you so much for joining absolutely glad to be here and can't wait to you know talk more about the future of you know Victor databases and llms so yeah great to Great you know great to have you here fot it's a we're I think we're introduced maybe it was like a year ago or something or say maybe a year and a half ago uh you like fellow entrepreneurs and stuff yeah exactly exactly and and one of the things was the um so of course you know as a as a as a co-founder in my role you're constantly thinking of like okay what's the how does our business evolve right so we have this beautiful thing we do that's as I always tell people like if you peel off the onion you find in the center of the onion you'll find the index which is the that's the vector IND index but then the whole onion sits around that right that goes into like you know how the product evolves and and and how we um uh how we help as I always like how we help people be successful with with llms and and it's it's wonderful um uh you know to work uh to work with you you know and I think it's great if people um you know hear a little bit like how you think and those kind of things and maybe it helps them and maybe it it helps them also to create stuff with W so that's that's great but there is one question that I really want to start with um if you know um can you share maybe with the listeners what's an Halloween document yeah that was uh that was from many moons ago yeah so I started my career in Microsoft long time ago in the early days of Windows Windows n server and so on um and then the Halloween document is over 20 years old I guess at this point and what it was you know it was an interesting piece of computing history and it was basically at that time Linux was just starting to appear on people's Radars and so a bunch of the Microsoft Executives kind of tasked me with hey go figure out what this Linux thing's about and try and start figuring out you know is this something Microsoft needs to worry about and what are we going to do about it and so on um and so you know the Halloween documents was kind of the first of a series of kind of internal memos and internal investigations about you know just kind of educating Microsoft internally about hey what's this open source thing what's this Linux thing and so on um yeah I mean it was It was kind of controversial was kind of interesting because he kind of you know it was always designed for kind of internal consumption inside of Microsoft and through whatever set of paths that end up getting leaked out to the outside world you know generated a a lot of interesting commentary and reaction um but I think I don't know I mean in in hindsight I think most of what the documents were kind of describing and you know you know kind of observing held held true you I think they survived the test of time in fact I was just just talking with somebody else in Microsoft and they were talking about how if you look at Microsoft Azure you know the Cloud Computing Services it's now actually one of the world's largest deployments of the Linux operating system um and many of the you know many of the advantages and in kind of intrinsic you benefits of Open Source you proved out to be true like it's very hard to imagine building any kind of new developer platform or developer service today um without a substantial open source component yeah c can you so what's interesting because um when we just were in the in the green room I guess before we started to record I believe because the documents are in 98 I believe and I believe how old were you again uh in Conor was 23 years old 22 years old yeah yeah yeah yeah so so so and Conor here we go two years old I I I was a little bit older but the what's what's interesting is that especially by the end of last year right so it's now it's now you know early 20 2024 the um the role of Open Source in in in AI in general with the llms with the methology databases and I I want to get to that um but the role of Open Source is such a yeah I mean even when I started my career open source was such a yeah it was everywhere so it's like it was like a no-brainer to work with it can you maybe just for people listening I think it would be interesting so apparently from these documents that was not the case you know in the in halfway through the to the 90s and probably before that was it was it that change that that importance came into for open source that also so money went into open source and those kind of things was that a um uh um was that already established in 98 or was that still on the Forefront that people weren't sure yet what direction it would take and I would love to understand how what what was the big change what was what was the change was like in infrastructure in databases in companies sure that you were like yes what we wrote in these document the whole open source thing that's that's here to stay that's not going to go away when when when was that oh no I mean I think the the most fundamental driver on the open source and this is actually something we touched on in the in the Halloween memos way back in the day at the end of the day the most fundamental driver is the internet itself um right the internet vastly grew the total Computing Universe vastly grew the number of people who are interested um and willing to contribute even small slices of their time to an open source project and then provided this you know interesting unique collaborative framework for kind of stitching together all these little tiny sizes of time um into a cohesive product um I mean you you like you the the vast majority of the history of computing I mean this is you know even work from home is kind of a newish thing or was an internet enabled thing the vast majority of the history of computing was you know dozens or hundreds of people all in the same physical location coordinating together and because they're all in the same physical location they're all employed by the same company they're all building something under you know in you know on on the company's clock on the company's dime um in the company's facilities instead of a single company repo and so on um the internet blew up a lot of those or it provided an alternative I should say to a lot of those assumptions right it meant that now you can have a large distributed Network globally distributed network of people um many of whom were doing you know contributing volunteer Cycles um and so I don't know there's maybe about three or four kind of different variables that all change at the same time right the maybe I'll go back to one of the biggest ones is the total market for software and Computing devices grew astronomically um you know it wasn't you know in the 80s 90s and even in the early 2000s eras of computing if you weren't monetizing the vast majority of your software installs you were on a path to bankruptcy as a company right just literally the total number of installs of a database orever might be measured into tens of thousands or hundred hundreds of thousands and so as a firm trying to pay salaries and so on you need to make sure you're monetizing half if not more right the vast majority of those installations um we're now in a world especially you know in you know with software and especially infrastructure software things like databases things like operating systems and so on where you only need to monetize a tiny percentage you know 1% 2% 5 perent of the total installed base in order to run a viable ongoing concern that can provide support product road maps product Evolution and so on and so so that radical shift right in the numerator that radical shift in the total addressable Market of software meant that business models that only monetized 5% of their installed base were suddenly viable whereas you know a few decades ago it was completely impossible um yeah that's that's super interesting and and and that's an interesting fast forward to today because I I I would love to First double click from that perspective on uh models right so so so I mean it doesn't have to be llms per se well we can take llms as a as an example and one of the um one of my I guess like hobby horses if you will things that I like to talk about there's also there's a blog post about this in the making by the way is that I'm fascinated about the fact that um we are or the companies creating businesses around machine learning models have to deal with the fact that the models today are stateless and uh quickly for the for the people listening who who don't know the the background story so so very quickly to go over that so for a long time when we've building for example infrastructure and those kind of things the thing that we monetized was you know State fullness right so you throw you store something in for example a database or uh or you have something go through like a streaming Kafka thing or whatever right the thing you wanted the state was involved right so if you if you shut down a database or or if you stored something in a database then you know three days later you were still hoping that it was there and kind of that's kind of what you're paying for and that kind of now is separated in storage and computer combination of both or or those kind of things what I found fascinating about llms is that llms um don't have that so um the um let's say let's say for example um when open I released um GPD 3 and a half as a as a behind an an API and people saw that value then that was kind of the only business that they had because the the uh the model has the same problem as I always like to say as an MP3 file is that it's great if you make a beautiful song and I might be paying for that one MP3 file but if you go like hey Connor if you know this is a beautiful MP3 file I share it with you guys you enjoy the music too you're probably not paying for it right because there's no State involved so a way to do that is the you know quote unquote um uh Spotify model which we now see with llms there's a Spotify model to get access to that llm you know you can't get access to the raw thing but it's behind a um a pay and with the working assumption that that's not going to change that for the foreseeable Futures the models will stay stateless I find that fascinating because now people need to think different about how U to build you know a business around these kind of models because not every company is able that can be for security privacy latency reasons whatever get that information from behind a um API based um B Garden if you will I I would love to hear go yeah oh I might actually push back a little bit on the I'm not sure if I'd call the model stat list um and I think it might actually be it's it's potentially even a worse situation than a stateless model right um so i' I've been working in different AI systems you know my first computer vision startup and stuff was maybe I don't know 10 10 years ago I guess at this point um and and so much of the era you know of the you know there there was kind of classical AI with like symbolic systems and so on then kind of deep learning kind of showed up about 10 years ago roughly and it kind of revolutionized all you know the the language and the vision and so on fields and in the early days of deep learning it was all about searching for the right algorithms to feed proprietary data sets into um I I think the big thing that happened with llms you know what would open the ey kind of really pred by putting you know putting cool stuff out in the market you know four three or four years ago was you know in the in the past AI development was grab somebody else's model or grab somebody else's algorithm and bring your data um with open Ai and gpts and so on it became hey we're going to go scour all the data in the world right we're going to grab as much internet data as we can and we're going to give you a whole bunch of data that's prepackaged into a model and that data unfortunately for better and worse there's pros and cons is opaque to me as a model user or me as a model consumer and so it's highly it's a highly stateful model but the risk is that it's frozen and you have no idea what state was fed into that model from the outset um and so things like hallucination or things like jailbreaking and so on are outcomes of the fact that we ultimately don't really especially especially a large commercial bottle we ultimately don't know what was used to bake that model and so God only knows what weird prompt we can throw at it that'll create it to Reg you know it'll force it to regurgitate this crazy training data that was built on um and so for a typical Enterprise it's a it's it's a highly stateful thing but highly black box right it it forces you in a certain Corner yeah so would it be would it be fair to say if we if we want to stick with the with the with the MP3 uh metaphor or analogy I mean an MP3 that has a hundred songs pre-baked right and you're trying to figure out where to skip inside of the MP3 to get that song right exactly or or maybe another way to look at it is that the um so if you have an MP in the way that's different is that the the MP3 file I mean um if the if there's a baseline in there right we can't change we can't change the Baseline but in theory the in the model we can change the Baseline but we we it's a it's a it's a black box it's hard to figure out how to change specifically the Baseline and not by accident the the piano right so how can we can we label that somehow how could we call that is that is that what what kind of uh what kind of state is that so we have pure stateless pure stateful it's somewhere in the middle I guess yeah the the phrase I've often Ed is that it's prebate um yeah it's knowledge it's knowledge that somebody else grabbed and somebody else kind of wrapped into the into the model uh giving you a a baked system yeah but this is this is actually interesting because if we um if you have these three types right so the um with everything that now came into the cloud and when it comes especially to the business around that the people kind of figured out how to build businesses around State pure statefulness databases um infrastructure that kind of stuff on the other hand we have the the the pure stateless Solutions so more on the consumer end I'm thinking you Spotify those kind of things so would you argue that this third new way this that's go with the label pre-baked uh opens up the door for like a new completely new way of creating value and capturing value absolutely right I mean in in and especially both of you guys have an AI background like I mean the old days of AI development and I think Andrew a has a lot of really nice talks that he's given out on this right in classical AI development it was a multi-on right three six n month process to get data prep data clean data test the model build a model throw it out there and then see what works when you have a pre-baked model when you have an llm that already has all this knowledge you know pre-installed into the model um it now becomes you know a multi-week multi maybe maybe weeks or months process to just figure out the right incantation right the right prompt to throw at this baked model in order to get the right output out and so you dramatically shortened the uh time to Value right the time to actually get something out of an llm that you were looking for um as well as dramatically broaden the audience of people who are now able to interact with the llm right you don't need a you know an AI Master AI PhD in order to get an llm to do something for you exactly and and the and where do you think um especially now what we see with with um with something like reg which is so the reason it's so interesting if we besides the academic side of it right so the how do we do it besides the the the new use cases that come out of it but if you look at it from more the well the value creation or the business side if you will um how do you how do you see that evolve what do you think what will happen because of course and I'm I'm this a little bit your self- serving question of course because you know we have the the factor database that we weave together with the with the with the models what what what are your thoughts on that how do you think that will that develop and do you think that open source plays a role in that so um uh I would love to hear your thoughts on that sure sure yeah know I mean I'm definitely a I mean obviously for on multiple levels and have been for a few years now a big believer in all forms of a of retrieval augmented Generation Um even before was kind of called retriever augmented Generation Um I mean there was a paper that Deep Mind put out maybe three or four years ago that I was big fan of and I remember reading the paper back when I was at Google um on a project they called retro and and Retro's goal uh is retrieval uh retrieval it enhanced Transformers or something like that um and Retro's goal or one one of the big findings in retro um which is which was one of the many advantages of what we now call rag but one of the big observations on retro was that if you minimize the amount of data that's packed into the model's own parameters you you know what's called parametric memory and rely on external retrieval to an external database you can end up with something like a 25x smaller model delivering the same performance or the same value as in that case 175 billion parameter gpt3 um you know Retro's goal once again was they were pushing kind of the theoretical extreme to figure out what's the smallest possible model you can build when you have a you know when when you can guarantee that it's always going to be augmented by a database but even that right just just that one issue of model size has dramatic advantages when it comes to developer ergonomics right at 25x smaller model literally is multiple times easier to build and deploy and train and retrain and re and fine tune and so on um and that's before you get into all the other advantages of a retrieval augmented system right a retrieval augmented system you can now independently update the data without without having to update the model weights um the data can be kept fresh um there's a lot of evidence and a lot of the and some of the guys at Facebook and uh Facebook AI research and their paper that coined the term rag um they also cited a whole bunch of other advantages around things like hallucination um you know hallucination and being able to keep the model instead of a guard rail when you have really tight um coupling between the model and the database um I I think it's kind of inevitable like in my case I think you know if I were to look at how would I chart this you know the industry's pendulum swings and so on is you know maybe the first two or three years you know up until 2023 of large language models um a lot of the goal was basically how do you pack as much knowledge into the parametric memory into the parameters of the model as possible in order to deliver the biggest and baddest and craziest pre-baked model um I think a lot of what's going on in 2024 is people are starting to back off now from you know from a you really simplistic view that a bigger model is better um and so now you're starting to see alternate model architectures like mixol you know was really hot but they're mixture of experts you're starting to see rag really become part of the mainstream conversation on models I also think we're not far from seeing a lot more AI um that specifically optimized or specifically targeting the idea that every llm will be paired with some form of external non-parametric me memory over time yeah and do you think this is a great by the way and so do you think so um in the previous podcast we had a conversation with um Paul grth who um where we talked about like knowledge bases uh knowledge stories those kind of things and also he he comes of course more from also from an academic perspective and but one of the things that we try to determine and then we were just you know uh um you know fantasizing on the podcast like what what the direction could this go into right and because the the the the fascination that I have like that this that we still that these weights that they sit like just in a in a binary blob right so what do you think with this with this are we going to go to systems that are more storing and manipulating these weights um uh in near real time or is it just still going to be a different system are we going to do that with Vector edings what do you think what I think this is a this is a very rich topic and there's a you know there are a lot I mean large teams of researchers spending millions of dollars trying to explore explore all the different corners of this particular Universe um I mean and maybe that's a good thing we can drill into a little bit I think there's I know order of magnitude four or five different paths that this industry is kind of walking down right now um you know up until you know let's let's say the Circa 2023 and before path was a really rich framework you know a lang chain or or llama index you know hay stack and so on a really rich framework that was managing the retrieval stack and so encoding content for proper retrieval pulling content out of the out of the vector database and encoding that content into a prompt right in context learning against a large language model and using that to drive language Model Behavior um that you know that architecture is a reaction to the fact that the language model itself is pre-baked and very very high function um you know the language model doesn't really care about the fact at least in this ver version of the architecture the language model never really cared about the fact that there was a retrieval system that was part of the game and a lot of what you were doing was trying to make this retrieval system matter to the language model in the form of in context learning um I think a lot of what's you know a lot of the directions and Explorations that people are make um are pursuing moving forward go on four or five different tracks the one you were kind of hinting at Bob is that um you know there is one angle which is basically you know let's let's revisit the assumption that the language model itself has to be or should be frozen you know are there ways that we can directly edit the parametric memory of the language model um to add facts delete facts and so on I think there were a couple papers you know where they you know you change the capital of France or whatever to Pittsburgh or something in order to make demonstrations of that right um and I think that's an there's early research progress on that it's still a long way to go before you know we really achieve anywhere near the production level capability that we've already started to see with frozen language models um or even more classical techniques like fine-tuning or kind of training your own model um if you you know other directions that we're starting to see a lot of investment in is basically a much richer retrieval stack and so you know you guys just had um Omar kab and Cole bear on where we're talking about what are if you if you assume that the retrieval layer is doing a lot more semantic understanding of the content it's not just simply getting and putting vectors but also doing things like you know bm25 so it's actually got an inverted text index as well as a vector store and then you take another level up where you say what if the retrieval stack is actually a model and of its own right um you end up with much richer retrieval mechanisms that can now be fed into in context learning and then ultimately into a model um and and sent out um another entire different uh Direction and this is the direction that the Facebook team was originally or The Meta team was was originally pursuing when they did what they called retrieval augmented generation is what happens if you co- Trin a language model alongside a retrieval model and so um you know Rag and retro and so on looked you know they they held they were building out variations of both systems right they weren't holding one thing fixed they were co-training both systems for maximum performance um there's a bunch of advantages um from that right at the end of the day and almost all machine Learning Systems end to end training wins it all right um however there's a lot more to this world and a lot more commercial reality to this world than just you know being able to not everybody has the ability or the desire or the interest in training their own custom language model optimized for a particular retrieval stack or particular retrieval set and so it'll be interesting to see how that evolves I mean maybe maybe we reduce the cost on that or maybe it becomes an interesting um thing moving forward um there's also a lot of interest orot another angle that's that we're seeing a lot of is basically for if you look at a lot of what's going on in retrieval augmented generation a lot of the demos retrieval augmented generation they're basically just smarter forms of search um you know you're not asking the model to take the retrieved content and then generate Shakespeare with it or take the retrieved content and turn it into an algebra lesson right A lot of the times what you're doing is you're asking the model um hey just summarize what are the top two or three issues or top two or three findings in this research paper um if the surface area that you're looking for from the language model is that small right it's basically things like text summar text summarization or kind of weaving a cohesive piece of text across the findings across two or three different retrieved blobs um you don't need the full capabilities of gpt3 gp4 and whatever to do that right you end up with a much smaller language model on top of a comparatively much richer retrieval system or retrieval model um so those are a couple examples right and there's still there's maybe like two or three cases um that are still out there for examp another one that comes to mind uh just because I was pretty involved with at Google um is much more formal knowledge representation and so things like knowledge graphs as the basis of retrieval um rather than text blobs at the basis of retrieval and and so I think you know a lot of what I'm kind of looking forward to in 2024 and Beyond is kind of seeing how each these different threads play out all right I think the the desire and the need for memory augmentation that's outside of the model is very clear very very strong um the question is going to be how does it play into model architectures moving forward yeah and I think so Connor didn't you also do some some pay-per-views on that specific topic right I believe that isn't that mgpt also a a way to achieve that or am I am I am I off there um well I think um I think mgbt is kind of about uh so I I I kind of took the end of what you're saying vode it kind of inspired me thinking about like the you know how we had a lot of extractive question answering models like train on the squad data set for example and you know that offers a pretty cool functionality where you can like retrieve search results and then highlight the most relevant things and we have all sorts of tasks like say summarization or text to SQL that do that kind of like um specific task and I think now the what's different more than anything else is we have these models that can produce training data for task specific models and then we can fine-tune them to the smaller specialized thing and allot these use cases but I think where it maybe connects with mgbt is um it kind of connects with um I think it might the context to know that mgbt is kind of related with Guerilla as well in in that Berkeley lab you have shashir Patel also on the paper with Charles Packer and and others and so I was try I think there is a lot of fruit then you you can model the retrieval stack as basically yet another tool um inside of a tool form or inside of a tool you a tool understanding or tool using llm yeah and oh sorry go ahead sorry yeah oh no I was just going to say like agreeing like this whole use a specific tool and train a model for one tool I like that you brought up tools for a lot too it's a really cool yeah yeah and what I find very interesting is that I so I I think that the uh and I I I have to admit that I have some some hopes for it and I'll can give some context to why but the uh uh that the the last point that you made if you know related more to knowledge cfts and those kind of things that I I hope that he we now see this rack use case and that's playing out and people know what it is it's it's in in it's today still primitive right how we do it but it already creates a lot of value for people right so we kind of can see where that's going in the research and how we're contributing from the database perspective but I'm really um uh I hope that um that that after wck that we that that we you know that we can start looking at the at the at the knowledge graphs because the um um it's also what I see online what people are doing I was very happy with that because I'm not sure if people listen No but actually the original the beginning with pv8 was using the embeddings and this is pre llm this is way back uh this was with the GL models I was like trying to solve the um the fuzzy relations in knowledge graphs well where we where we where we couldn't make them because I I thought like you know it's a um back then the whole the semantic web Etc was like a big thing and I was like hey maybe this is a way in link data to make these relations so it's kind of nice to now see that to see that come back and I'm even we're even looking into can we store the complete representation the knowledge uh graph representation so including the weights for example in a graph connection can we actually represent that in Vector space right so we can basically we Traverse the space and for people listening a way to think about it or to visualize it is as I always say it's like a a a knowledge graft today is like a a thing is like that lives in 2D right so it's a you can draw it on a paper and you can say you know I don't know Bob lives in Amsterdam right and that's like how he can make relations or if you want to have weights in there you know the distance between Bob and New York is I don't know how many miles but you know that you can fill it in and I think we can kind of capture that or not kind of I think we can capture that also in in uh in Vector space and the models can help us U move stuff around in in in Vector space so um if that if that's true and if that people start to adopt that that would be amazing because that would be like another big unique use case also for for Vector databases right so I'm I'm very very very um eager to you know and then also what the team is doing explore that further and help people to build these kind of systems because also the thing is like a you know a a graph is often complex also to Traverse and especially to build the infrastructure I mean um I know that from Friends working on graph databases right so if you can represent that in in Factor space that would be that would be amazing because it at least becomes significantly easier to Traverse uh Vector space than the traditional graph so yeah but I mean I defin have a couple reactions to that is like I mean I think yeah I mean so the you know I've spent a lot a fair amount of time in like Enterprise search as well and so the classic you know the the classic thing or the classic marketing problem that everybody has in Enterprise search is they're like how come searching my own internal data set inside of my company why is it so much harder than searching on Google you know how come everything I see on Google just looks so much better and kind of the Dirty Little Secret of a lot of that is that at the end of the day part of the reason the Google search works better obviously they've invested a lot of money and people and energy into that but part of it is also because the underlying content on the web is actually much higher quality content right people have been people similarly invested decades in creating the world's best possible landing page that ansers specific questions and you know and professional graphics and professional content you know describing these individual topics um because the web is so large um by contrast a lot of the content that lives onside of corporate internets or a lot of these private data sets they're just simply is nowhere near the level of you know directed investment around creating the highest possible quality content Corpus and so you know in classic Enterprise search the problem is no matter how good your search system was you're always at the end at the end of the day you're always beholden to what was the underlying content quality I think you have a similar problem with rag um and you know the industry as a whole you know we're moving from crawl to walk right these are you know version three version five kind of problems um but we're not far from hitting we'll soon see a wall where a lot of the problems that we have with rag is that the underlying content itself is kind of messy and so on and a lot of that stems from the fact um that at the end of the day text is a very lossy way of representing information um and so I think there will be a Resurgence of Interest or Resurgence you know a goal to you know to basically mimic what Google had to do on the public uh consumer web is find much more formal deterministic explicit representations of knowledge um that can be much more directly manipulated by machine um and there was a there was a paper just on know maybe a month ago um and llm space moves so fast right but I think it was just a month ago talking about the reversibility curse in llms yeah where if you ask the question about who is Tom Cruz's mother it got it right but if you said you know so and so you know who is so- and so's son the llm had no idea um and it's a perfect example of where this implicit knowledge representation just trained off of text you know leads you into the kind of these weird error cases and it was kind of funny because that was almost exactly or almost precisely a textbook 101 example of something that a Knowledge Graph can trivially conquer right a formal representation could absolutely tell you you know so and so's mother is therefore so and so's son right um and so I I do think there is ultimately going to be some more convergence or some more connection U between much more formal representations of knowledge and then the highly implicit representations of knowledge that you have that are inside of the weight llm yeah if I can oh sorry gohe go I can add one quick nugget I met with um Kevin mang who's the first author of mem from MIT and I think he gives a great example of this reversal curse thing where so as Bob's mentioned you change LeBron James plays basketball to LeBron James plays football and then you ask it who was Kyrie Irving's teammate when they won the championship so it's like how do you resolve these other you know dependencies in the knowledge I find that to be like great on this implicit explicit that's I never thought about it like that that's that's a that's a good one that's that's a good one yeah it's a it's a it's it's fascinating because it it kind of um assumes that everything around it and every you get into this very complex recursive thing where you just basically need to you're you're basically creating another world right so the so the the the model has a world representation and you're basically saying like it's a it's a uh um uh it's it's a different uh you know it's a different world so and and then before you know it we we end up in analytical philosophy so so let's be careful with that one but the with all different world representations but the that's that's a that's a that's a good one it's a so it's more like then the model is at where we are right now what we know is like it's more like a companion right to help you search but I what I also find interesting was the um is the I find human element in this interesting as well and what I mean with that is that that people will take the path of you know least friction so um I I remember so for example the You could argue that if you have the web and the fact that we express web pages in HTML um um let's forget about flashh and stuff for now but just that we have a HTML representation a dumb representation of information on the page right and that a that a search engine like um uh uh like like Google can parse that kind of information and and and and work with it there actually it's kind of understandable why that works because if you look at the common craw for example who is also parsing the information that then in turn is being used by the way I think that the common craw is an example of one of the unsung heroes of all these models that are being that are being traed so if these people are listening and lion or Layon data set as well and all the Imes exactly yeah exactly I I I believe that I might be completely wrong so if I am that my apologies but I think that the that the common CW team is like two people or something it's like a it's a it's it's a very tiny group but the way that they can also store that information in these huge work files and that they that they get that from from uh uh from from HTML um structure that kind of shows already that that's possible and I also remember what I found fascinating was that I remember when Micro Data uh um became part of of the HTML syntax so basically that you could say right okay if I said this pair of Adidas shoes is you know I don't know 150 bucks that you could say like Adidas refers to or Adidas as they say in the US refers to the uh to a brand and then 150 bucks is then the price and what was funny was that I I I I I um I spoke to I guess an expert on the semantic web so micro dat semantic web kind of same thing I guess the um that um he told me he said what's so interesting is that people only tag it properly if it's in their own interest so they're not going to go to lengths to actually tell you that Adidas is the brand but they happily tell you that it's 150 bucks because then it shows up in like the shopping uh uh feature so and what and the reason I bring this up is because what I find so interesting is that one of the things that these llms let's let's stick with language for now because these what these llms do is that they also take a lot of friction away from how we can parse information and yes not everything yet so PowerPoints are still difficult and that kind of stuff but it takes away the friction to um um to build stuff and this is something that goes back to the conversation that we had with joh MAA here on the podcast is that I one of the things that I that excites me so much about this is that it's it it's becoming less Elite to build these kinds of systems and tools so I love the fact that people now with a prompt or with some with a little bit of pip can start to build new products and things right so and that is a really cool thing so the the the point I'm trying to make here is that the um that I believe that the um that this paradigm shift is happening from formal data as we also do it in N graphs to yeah more fuzzy data I guess or informal relationships that we don't even that the model just infers for you and I think that is that is super that is like tremendously exciting so just becomes easier to to build stuff right so and that's something that I'm uh that I'm also very um uh excited about so and the end of the day mean at the end of the day humans do not do formal logic when we communicate right like human communication human visual visual verbal and so on is all fuzzy unstructured data and in our brains to create a formal system around that um and so the vast majority of the content is out there to train on at least the human generated part of it is going to always be that way um yeah I mean yeah and so LM yeah I mean the pursuit of formal you representation knowledge and there's no question that machines need that formal representation um at least today llms kind of cracked that open a little bit um I mean the classic problem in your Adidas example was I mean the classic problem with formal representations is at least to date right that Google Knowledge Graph in a great example um it is an insane you know like thousands upon thousands of people inv investment um to kind of construct and maintain those knowledge graphs or construct and maintain um those you know formal representations um The Hope is that llms dramatically reduce the cost and ongoing M you know the the initial construction cost and ongoing maintenance of a Knowledge Graph and make it something um that brings it within reach um I mean there's obviously a ton of research going to this right now and we'll see we we'll see what kind what they're able to pull off it's definitely hopeful right this is the first significant opportunity in this category in a few years yeah exactly and the the and of course also you know things related what we're seeing now with with multimodality right so I I had a conversation with um I believe it was actually with with I met up with with Neil ryers and I think that we that he explained to me a very simple problem that that he was working on or something that he said like if you have like a um well let's say with Adidas right if you have like um a PowerPoint slide and and and uh and it it might have financial information it's like how much and it might only have the three stripes of Adidas on there right it's like how much uh what was the the the the revenue this year of like the company that it's that you need a multimodal model to infer actually from the logo uh uh that the company refers to Adidas because it's not in the text it's just it's in the um it's inide so that those kind of things are super intriguing but again it is lowering that barrier to to start building these these these kind of these kind of systems so I I have I have another question I want to shift gears a little bit because I and again this is this is a little bit of self- serving question but I think people would love to hear this too if you know so um so of course Connor is talking to a lot of uh um scientists in this space right so they have a a a specific modus operandi how they um you know they do the research and they and they and and how they you know how they bring that into um to Engineers so that Engineers can pick that off the the you know from the academic information and they can build systems around that we have Engineers they have certain way how they build reliable systems um we had John to talk about like how we Design Systems for these people but you are in more in like in the in the product space and especially in the leadership space around that so what's so interesting and I'm I'm I'm in that myself as well so that's why it's a self- serving question the interesting thing is that you need to do a little bit of everything right so we touched upon um uh in this in the the 40 minutes we're talking we talked about um Frameworks you mentioned langu Lama index of this world we talked about Vector databases we we talked about the models we talked about the research that happening we we're talked about value capture and how we create value what's so if something new emerges like this right like these LMS what's your modus of Bry how do you how far do you go in researching these things do you also try them out or do is just theoretical enough for you how do you how do you do that how do you uh um basically how do you do your job what's your Mo what's your modus operandi yeah I mean and you know I think I'm I'm I'm lucky in that uh you know even at a very young age like I I I absolutely remember the first time I saw a computer is actually probably that commodor Vic 20 you know many many years ago um and at that point like I you know as a kid I probably like 8 years old saw a computer and the kid and the the nine-year-old or the 10-year-old who could make that computer do things seemed like a god to me and at that point my career path was set there is no question that this is what I wanted to do um for life and so for me a lot of you that underlying thing starts with just you just have to be genuinely curious about the topic at hand um you know even if this entire industry didn't exist even if it wasn't a well-paid job or whatever I'd still be super fascinated and still super curious about what's going on at the frontiers of AI what's going on at the Frontiers um of computing Enterprise service or servers and clients and the web and so on right and so that that's kind of the first mode of this is you just have to come at it without any real agenda Beyond I just an innately curious and this stuff's fascinating and there's an intellectual Frontier that's being you know that's being settled right now and we're going to go off and try to get to that you know get to that Leading Edge um the reverse side of it is like you know you know I've spent most of my career um in Enterprise and you know and and selling things to organizations and uh large companies and so on and so the reverse side of it is also there which at the end of the day you know most Enterprises you you kind of have to start with what are the use cases and what are the things that what are the problems these guys are trying to solve with technology right the vast majority of Enterprises on the planet are not technology vendors the vast majority of them are companies that are trying to you know provide mortgages to consumers or you know run nursing homes or something like that and so you start with that problem these guys are solving and then it start then you can apply a pretty uh pretty tight uh razor to say well is this particular piece of technology going to be something that accelerates or DEC accelerates or has no impact on what it takes for me to process a mortgage um you know large language models retrieval augmented generation just to kind of Chase that example right the vast majority of the content that's form that's assembled and constructed inide of a mortgage package uh which in the US is now 300 to 500 pages per mortgage is unstructured data right it's all different types of documentation and all different types of content that you are kind of going through the last you know X number of years of your financial life to assemble and provide to your mortgage oper uh Mortgage office um the decision they're making is a mix of both structured and unstructured data um that they're you know using to ultimately evaluate that morgage um application and so from that lens you can come up with a pretty strong idea of okay what are areas that we think that llms and Rag and so on are able to accelerate um you know it makes it a lot easier to process things like a photocopy of a W2 form or look at you know look at checking account information or look at you know read information about the property and so on um you know other Technologies you I'm trying to think of an example but you know virtual reality or ar is unlikely to improve mortgage processing maybe there's some extreme example of it but at least in the short term it's hard to imagine that right um maybe it approves other Industries uh but certainly not some of the ones that I've spent a lot of time working with things like financial services and so on yeah yeah that's it's it's fascinating I think if we so looking at the fact that it's like early 2024 now so if you had to if you had to make a a prediction if we record this podcast again like early 2025 what no let me rephrase question not a prediction but what do you hope to see solved what do you hope like oh it would be amazing if if that would be if that would be solved oh interesting um I mean you I mean a lot of what led to you know I guess me working with you guys and working with the weba team and so on um I do think the vast majority of language models deployed by the by the Enterprise will have some retrieval augmentation um and you know as I was mentioning at least going into 2023 um retrieval augmented language models meant a very specific thing right it meant a very large Frozen high function language model coupled with a you know with a framework that's doing a lot of work and in a vector database or some kind of external repository to pull and get documents I think different components of that architecture we're going to start seeing a refactoring of that architecture and different systems um you know different permutations of that where some of the capabilities that we currently say are part of the framework become part of the vector store or become part of the language model I one scenario I didn't even didn't spend too much time on it like there you know there's the lost in the-middle problem obviously today with a lot of large context language models however there's also a lot of research going into how do we address the lost in the- middle and how do we create massive language models a massive context Windows right and so it's it's something like you know you can imagine we're not too far from a world where if I ask a language model for a you know something a question about black holes instead of just trying to go off and retrieve just information about black holes we just give it the entire physics textbook and let it figure it out right and so so I think that entire idea space is going to get a lot of exploration over the course of 2024 I don't think it'll be one single architecture uh to rule them all um but I mean I I do think there's going to be strong convergence at the end of the day the parametric memory inside of the model will almost always need to be augmented by external um memory that's provided via database oh that's super interesting that is that is super interesting so so you you might foresee the first glimpses of like a like a a new architecture to really be implemented maybe this year yeah I mean I I mean you I think you kind of see those glimpses today right like today you know when when people talk about the Lang chain architecture um you that or you know any of these framework-based architectures you see that architecture today like all the all the functional elements are inside of that architecture they're just kind of allocated in different ways and implemented in different ways you know so things like content chunking today are extremely heuristic based and honestly kind of hacky um we're not far from a world where things like content chunking become a learned behavior and probably and co-trained in adjust in in conjunction with the embedding model and then UL Co train uh you know Crain with the language model itself um and so you know there's definitely some cool startups like contextual AI going after you know those types of scenarios yeah just to make sure that we that we're on the same page so what you're saying is the so basically not now with the chunking we say like okay we have I don't know a 20 Page document and then we chunk it up or paragraph that kind of like add that's going to be fixed in a model you think yeah I think I think you know I mean it's you know if you guys were any of you guys were involved in the early days of NLP I mean you know language tokenization used to be a very hacky thing right and then a bunch of people figured out how to solve language tokenization um via a more modeled based approach um I think you're going to see a similar modeled based approach for a lot of the pieces of a uh of you retrieval augmented generation that makes that makes tense yeah go ahead well I think tokenization is an interesting one because we don't do end to end tokenization really we mostly use like the bite pair encoding still and so I guess I'm actually I'm I'm kind of not in the end to end Camp I really like and this especially comes from the influence of talking with markab about uh the dpy framework and or DSP I never get it right with how to pronounce it but like this idea of like uh having programs where you have these different modules so I think like instead of the architecture as like a Transformer or mixture of experts you think of like rag as one architecture with retrieve and then generate and then you add that like query rewriting part to it now maybe you put reranking in there maybe you put summarizing before you answer and now you've got like this program and so so to me that was what you know kicked off lang Chain's growth is this community sourcing of these pipelines like hey I you know I have it write me an email then I have an editor prompt and then I have like a reviewer prompt and so I think this kind of discovery of the programs is finally getting centralized around this dpy framework and you know that's definitely what I'm like looking forward to working on is our V integration with dsv and yeah I mean we're still in the early Innings right these framework and the L it's maybe even a little too harsh on like they are doing incredible work they and it's the power of Open Source they have an incredible Community you know I mean Lang chain today versus Lang chain one quarter ago are practically you know different products right and so there is a you know it's hard to it's hard to declare a winner and stuff right like it's there's there's teams and there's energy that are just doing incredible work um and we have some sense of what the long-term principles will be right the idea that memory is gonna you know more and more of the memory for a model or for a given task is outside of the model rather than inside of the model interesting I'm actually curious what the uh Conor what your answer is to this to this question as well what what do you hope that by the end of uh if we re record this early 2025 what do you think or hope that will be resolved um well I'm most excited about the LM inference costs going cheaper and faster because I want to see the generative feedback loops thing more where my my dream is like I uh you know I I do Google search of VOD and Bob and I get all the information and then I have llms just like simulate conversations create data and I think that maybe we'll see a world where you have like your personal notes and then the LMS like they do so much exploration within the ideas of your notes that it creates this billion scale Vector index out of the product of the LM like thinking about your results conver in with other llms that play different roles and that's just what I really want to see is the new use cases with absolutely massive Vector search I I hope that's the particular one I don't know if that particularly but just let's see a hundred billion trillion scale Vector search in that totally new use case yeah that's that's I mean that's that's exciting I um um so so so so personally I hope that he and I was thinking about that especially is a combination what you just mentioned vote and and you color in cost going down is that the I'm I'm always fascinated by this concept that I can't the only way I can explain it's like good enough right so that we get to these so we get to a couple of these models that are good enough when it comes to interference and then we try to you know we have all these boosting algorithms we have these these these ports that we have and then the cost goes down and I would I would not on the good enough that's I mean you know especially from a product standpoint I me that is that is one of the that is one of the classic you know classic kind of product strategy problems right it's like you so for example I think we probably all agree that if you look at the stuff purely from an AI standpoint end to-end training almost always wins right however there are other pros and cons of end to- end training Beyond just straight up performance of the model and though and eventually you hit a point where that's good you know your perform model performance is good enough and it's these other secondary factors that drive you in the in one architectural decision direction or another exactly and I and and so and exactly and so so to to to to quickly finish that thought I think so I would not be surprised if the if the iPhone where are we now 14 but like 17 or Android whatever that that's just for an iOS Developer an Android developer that's just an an API when they are when they're writing code that just embeds that llm right that they just basically say okay I'm now building something where I need something LM based or by then probably multimodel based um and that just ships with the uh um uh with the hardware I I would not be surprised if that's where we're going and I that doesn't really matter if it's like a proprietary model or I believe so for example I believe that um the the Google model that Gemini has a I believe it's called Nano I I might be wrong y that is built for that use case so that it ships with Android I think I think that's very exciting as well because it's just going to be like ubiquitous and and it's going to be super interesting course that we're going to see like how will that um uh interact with you know with with uh with retrieval with retrieval systems and how will people be using that so it's a I I I hope that a year from now that that's kind of common ground that these models are not that that just that they're just everywhere and you get them in your phone you get them on your laptop you get them in your fridge and and then it just it's solves you know um these these fuzzy problems for you this is this is great this was a this was a great conversation it's a thanks for joining if you know it was awesome absolutely great to join you guys it was a lot of fun fantastic thanks so much everyone ", "type": "Video", "name": "opensource_ai_with_vinod_valloppillil_and_bob_van_luijt__weaviate_podcast_86", "path": "", "link": "https://www.youtube.com/watch?v=ySNX2cPh5Tk", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}