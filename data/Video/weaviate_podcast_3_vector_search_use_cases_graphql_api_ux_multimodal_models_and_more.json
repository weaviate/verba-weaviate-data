{"text": "Join \u202aConnor Shorten and Bob van Luijt for the third Weaviate vector database Podcast. During the show, they will be discussing\u202c ... \nhey everyone thank you so much for checking out another episode of the we v8 semi technologies podcast i'm here with bob van light ceo and co-founder of semi technologies me personally uh bob has told this story that has really captured my interest in the we v8 vector search engine you know listening to his story telling it on dmitry khan's vector podcast and all the different uh youtube videos on wev8 has really captured my attention and caused me to be really interested in vector search engines so i'm sure that this uh you know another edition of listening to bob tell the story will help you also be further convinced of how exciting this technology is so as we do this podcast um on the semi technologies youtube channel we're sure most of our listeners are already pretty familiar with the basics of vector search engines if you're not uh there's an introduction to we v8 on semi technologies i've made one as well in henry ai labs there's all sorts of resources to get caught up with the basics we're going to kind of go into the details and flesh out these visions for the future these exciting ideas like graphql knowledge graphs neurosymbolic search these recent advances in information retrieval and supervised learning multimodal learning like image text search the demo endpoints the demos and how we see that playing out all sorts of really exciting things going into the research and the future and all these kinds of exciting things so that said um i think the first thing uh to talk about will be uh like what is your vision how did you think of this graphql knowledge graphs because i think this is a really unique flair of we've that i don't see a lot out there a lot well yeah first of all uh uh thanks for having this conversation with me on the on our own podcast i guess but um um yeah so so the originally the idea came from the fact that i was very intrigued by everything that had to do with the with the semantic with the semantic web and those kind of things and if you deal with a semantic web then you're very quickly into the space of um ontologies and there was this one thing in when i went to conferences when i spoke to people that just fascinated me and that was that if we talk about the definitions that we have in ontologies is that people don't agree on things it's just i that's something that fascinates me and that this is causing a lot of problems right so because the um uh if you wanna if we wanna search through specific data sets or if you wanna wanna find something then um that that's hard to do and i once gave a talk in greece and there was like this uh this guy and he said like yeah and he was like he was upset about this as well because he says he said like i'm working for the european union and i'm test by creating the ontology for rivers lakes and seas in europe but he said you know what the problem is i said tell me and he said like so what the rest of europe calls a lake they call a sea in germany i said like so we couldn't agree so i he said like i delivered the ontology and then the people in germany said like no no no that's not a lake that's the seat and so this wasn't a a constantly occurring problem and if you see like public discussions like relative wikidata etc you see that this is a this is a constant problem so then i got introduced to everything related to factorization in nlp bear in mind this is i'm not that old but it's like this is before like birth and transformers and that kind of stuff and i i remember that the first thing that i saw that it was that famous example i believe that it was like uh king minus men plus women and then queen that the result that was like the moment i saw that for the first time i was like boom it just i was like wow and a few years later i got this this very simple idea which is a very very hacky idea right um but i got this idea that i said like what if i just have a bunch of documents just three documents edges or paragraph of text or something i just take the individual words and i just calculate a centroid of all the individual vectors of this of these paragraphs i just wrote that in python so it was really slow but the goal that i had back then was just to figure out like can i can i find that document by searching for context rather than for keywords and when i was able to do that i was like i had this thing that was like boom this is like an opportunity because now we can we can target a note in the graph without knowing what the current anthology is or the keywords are we just have to describe it and then we can find it and from there on we can traverse the the graph so that is what the what the original idea was and and there's way more to say about this but we'll probably touch up on this and related to graphql that's another thing because i am a very very strong believer in a developer user experience and now you have like a problem if you're dealing with a graph like data model and the problem is this so how much flexibility do you want to give the end user to traverse down this graph right so do you want to be super expressive then something like sparkle is interesting or do you want to be less expressive but give a lot of make it easier to use and then we of course have something like like graphql and just asking developers about you know their you know what was very intuitive for them and and and what you know how they um i wanted to use the interface we actually learned that a lot of them liked graphql and that's also what i see when i give demos i just i don't even i i sometimes say it's graphql and if people say like i never heard of graphql it's like don't worry because i'm going to type it out and it's going to be intuitive and um plus the fact that we are not a graph database but really a vector database we said like we we don't have to support all these specific graph things like neo4j does or or draft does that's for them to solve we have this graph like data model where we want to target these nodes and we're going to use graphql to do it because we believe that it's the easiest way for people to use it so that is the the history of that uh interface i have to say um that was just the the concept the actual design uh is done by my colleague laura and she saw there's also some videos from her online and that kind of stuff where she explains what she did there so credits for the design go to her but the the overall concept was like how can we give the best ux to end users to get access to these vectorized data objects yeah and i think um one of the like visualizations of vector search that we like the most is say image search like where we say take fashion mnist and we go find the nearest looking bags but that's missing the metadata of uh of the underlying image data and so having that metadata and then using the graph syntax to be able to traverse it is something that i think is a very exciting visualization and you know the graphql demo the semi console it's a very cool way to start playing around with vector search engines and something that i'm also working on is like a tutorial on using graphql but generally it's pretty easy to get started and wevg8 has at least 15 examples on the documentation for anyone out there looking to get started with graphql and and again wikipedia uh wikidata and also news articles are up there already if you wanted to start playing around with uh graphql so to backtrack a little bit you were talking about uh text embeddings and graph embeddings and this idea that you would use the say average of a paragraph about and lakes in greece to get a text embedding and then go hit the semantic web graph and i was recently talking to charles pierce akinius about how they uh how they have this scientific literature suggestion where you highlight some text and then it goes into the knowledge graph of a citation network so is that the vision that you start off with the text embedding and the text embedding takes you into your position of the graph and from there it's about traversing a knowledge graph yeah so so the original idea was a little bit more abstract so the original idea really was like how can i target this data object in in the graph without knowing what's in it how can i solve that and that is what the embedding sold for me um that can be text embeddings but that can also be as you mentioned image embeddings and those kind of things what's also important to bear in mind is that i i came from from somewhere else as where for example data scientists come from so a data scientist might come from hey this is really cool we can can build a recommendation engine so i'm going to take mnist etc i really came from the from the engineering slash database perspective so like how can we have build a database that is just smarter air quotes in um storing data so it was a completely different approach and that is for example why i love the case of of uh charles and kenya so much because that is that is the that idea in action so they're using that exactly so you have a database that makes it easier for them to search for the um into the content so that's it's a little bit of a different uh point of view and the embeddings are just and i have to be honest here we're just also a little bit lucky right so with with everything that's happening in research because we're now often talking about uh image or text embeddings but um we're looking at use cases for cyber security embeddings and healthcare embeddings you name it and you can store all these embeddings including the meta that are in in wi-fi so i really think that the coming one two years we're gonna see so many cool use cases from stuff that people are creating embeddings off so that that's going to be yeah that's just going to be amazing yeah and we'll definitely get more into all these different use cases and the multimodal and personally i'm working with uh the we're working with the memorial healthcare system data where we have convalescent plasma therapy treatments for cover 19 and we're trying to do this kind of vector search where we're looking for patients and it comes back to this topic that we're talking about where you have an underlying symbolic schema and this kind of idea of neural search and symbolic search and the way that you really want to do neural search so a lot of the times and um charles and kenius outline this really well with this concept serendipity and i hadn't heard this term before and i think this really describes it if you do a text embedding the result that you get might kind of confuse you compared to a regular expression matching so if you search for keywords or like whatever search you do you're going to expect the keywords to be in the result kind of like it's just kind of i think how we're biased to use search engines given google and just our experience with this technology of search engines so i think we're still generally getting used to this neural search and symbolic search so wev8 is a neurosymbolic system i think one of the best one of the you know most applicable neurosymbolic systems that have come to exist so is this something that uh this neurosymbolic kind of categorization do you think this is something that motivates and trading off some symbolic queries as well as this neural search and how do you think about those two kinds of searches yeah so so um uh first of all i i love that example because i'm dealing with that as well so so just for some context so what am i doing like mostly on a daily basis i'm helping users and talking to users like how do you use it and one of the things the patterns that i see is that of course people have like a status quo search engine that they use and then they move to something new and indeed keyword search is very binary in its results right it's true or it's false so if you search for apple and it's it shows you an article about uh toothpaste then you go like ah that's just wrong it's a you can like in a binary face like this there's something wrong with this thing because i search for apple and i get toothpaste that's of course different when we're dealing with um a vector search engine because now we just search for something in the in the vicinity of something and the interesting thing was i was talking to two researchers doing a lot of of work in this space and i like a year ago or something i said like how actually how do we know and he says like well intuition right so if i if i type in landmarks in paris and i happen to have a document about the eiffel tower and it returns the eiffel tower or then it's our human intuition that says like oh yeah that that makes that makes sense so one of the things that we're playing with is that we're saying like well we are returning of course in the results also the what we like to call certainty which is a little bit of an algorithm it's very simple algorithm like how to determine based on the distance you can also return the distance we're also going to work with with different distance metrics and then you can say something about for example cut off points in the distances where it's probably a relevant um result so that's that's the first part of my answer the second part of my answer about keyword search that will definitely play a role i have a um an example on the um in the in the in the demo data set in the wikipedia demo data set um where we deal with named entities so i i often like to take music examples so i i believe that the question that i have there in the demo that it says like what was michael brecker's first saxophone well if you run that query you will get the answer but it's like on the third or the fourth result and there's just one right answer so what you can do is you can mix in the where filter on the end the named entity that's in there michael brecker in this case so you still have the semantic uh query what was microbreakers for saxophone but then you're only saying the where filter this must be related to the keyword match michael brecker and then you still get the right result so what we see happening a lot is that people start to mix in these named entity recognition things where they said okay if the query contains a named entity we're going to do a a scalar search or just a bare filter search in our case on that named entity and the rest of the question we're going to match based on the on the semantics of the question really depends on the use case the third thing that i want to say about that that is about that word serendipity because i love that that word as well um what we see from uh from that point of view is that people come up with a lot of very cool creative ideas to actually use the serendipity to their benefit an example is this so what i did years back when i tried this out with creating centroids on the individual words we now see people do this again for example in e-commerce so let's say you have 100k products and they all have individual factory representations that they got for example from a sentence uh birth um embedding so these they have these embeddings oh sorry model so they have the sentence bird embeddings to them and now somebody adds something to that card so three products to the card what you can actually do is in with yet you can say i'm gonna take the three embeddings of this product in that cart and i'm gonna represent the user based on the centroid of these three embeddings so now if somebody searches for something else you can bias the result towards the centroid of what's in their shopping cart so if somebody has so we we are about to release an e-commerce demo based on this so if somebody has like um all kinds of sporting wear for like a women's sporting wear in there and then somebody searches for a jacket then you can actually buy his results to for example women jackets or if somebody has a lot of things related to yoga in there and somebody and then you search for example for bowl then you can actually show yoga bowls first before showing soccer balls and those kind of things so that is an example where that serendipity is actually used to improve the results and the um and create better search engines for whatever use case people have yeah that's such an interesting uh like another way of looking at the serendipity thing is the biasing it with the nearest neighbor to filter the search and i think generally for everyone listening i'm sure a lot of our listeners have heard about this yet but what makes a part of these vector search engines so different from say just running your data through your neural network and then taking the embeddings and putting them into memory and doing some comparison is there are these uh data structures like the centroids bob is describing that speed up these searches so h and sw is a graph that traverses these centroids to help you find nearest neighbor vectors so you don't do order n compute that you know go through the entire vector set to compute the distance with everyone which would be impossible for massive documents and all these kinds of things so that's a really interesting idea the serendipity of you bias it you say i want something that's kind of similar to this and then the h sw graph can be like okay great i've already built up this index that already helps you do that kind of filtering so then um coming back yeah the idea of the the human intuition that helps us interpret these results and so another kind of topic and i love the idea of these user interfaces for human intuition things like as you mentioned the certainty that gets returned at the neural search is i've personally uploaded my keras data set into eva and i've been playing around with searching for nearby code snippets in the keras code examples and having that certainty that matches it and tells you it's 72 percent or 0.72 as you go down and you see the certainty that that really does improve the user interface and it helps you feel more like okay i i'm getting more of a sense of how this is working and yeah the named entity tagging i love that idea because you can um you can have like the keyword filtering on to come back to the keras bird example people out there are familiar with chaos it's a library for deep learning you might want to have it tag entities like use the attention layer if you're searching for implementations of new transformers so that attention layer is like a named entity uh layer of the keras so then kind of a big a big topic to come out of and then start talking about is going from human intuition to computer intuition and this idea of information retrieval and supervised learning so i think you were really ahead of this and thinking about this early on with the just the modularity and the building in of the question answering modules so what was your thinking early on with the modules and how are you thinking generally about this kind of adding the supervised learning modules functionality on top of vector search yeah so that's a uh um that's a great question thank you but um so one of the things that i was doing is that i knew from the work that i was doing back then so basically helping people to build systems for whatever they were trying to solve was that i knew that if i if we would be working on a on a database that as i always like to describe is the distance between the problem that the database solves and the problem that the end user needs to have solved there's a gap between there because a very simplistic example is um people don't directly connect their app or their front end to weave it right there's always a piece of middleware that does something for their for their use case like you do with any database that's not different for but we appreciate it so but i tried to what i thought about like so what can we do to um bring make bridge that gap right so how can we bridge that gap what kind of things can we release what kind of things can we make to that and the modules are an example of that so then we said like well you know if the majority of people are using for example sentence transformers why not have a modular infrastructure to actually um just offer that to people and likewise when it comes to the for example the hsw plugin which had this here the the whole the credits go to uh to hn for that idea but probably we will see others in the future as well besides hnsw so let's may already be prepared then we can just you know change it and swap something else in so it's more like from the from the inside out and and i'm looking from the outside in 2d to the to ev8 and that's where the idea comes from and now the cool thing is the connor and that is um well i can use the word serendipity again um that we have one like power user who's like hey wait a second wait a second we have like hundreds of models that we use can we actually automatically in the kubernetes cluster spin up and shut down these modules around we evade whenever we need them and we're like yeah sure you can so now we see these new use cases where people start to intertwine the ml stuff with the devops stuff and create this super huge systems where these models pop up shut down and what have you all thanks to the modular infrastructure that we have so i think that's a um yeah that's just amazing to see and and again to recap this the goal here is to bridge the gap from the database to whatever the problem the end user is trying to solve yeah and that modularity connects to sort of the champion open source the hugging face models and it's such a nice modular integration and yeah you can just switch out the the modules if you have a question answering system that's going to be uh performing the task you can just swipe it out with hugging face and hugging face is really great to upload your models to just a personal testimony to it it's it's really nice to train like a language model push it to the model face model hub and then you can have the mask demo now they're building out hugging face spaces they've acquired gradio they're really building this demo interface and you can take all these models and plug them into wev8 and the modularity of that is so exciting i love the modularity of how you can swipe out all these different components i agree i agree with you and what you see is like not only this like because i absolutely am so the hugging face platform is fantastic and and and we we benefit from that as well so that's great but let's also not forget like platforms like docker hub for example right so every time somebody downloads um uh we're slowly approaching 600k downloads by the way but uh that's that's thanks to the docker platform so so so hugging face docker uh kubernetes of course we we benefit from these from these platforms so that is that's just fantastic that they exist and yes and to come back to our information retrieval and supervised learning discussion too i personally one of the systems that first caught my attention was co-search from salesforce research and this was around uh you know this was during peak kind of covet 19 hysteria where we're trying to look for also whatever application deep learning can be used for and one of the most interesting ones was scientific literature mining and so there was a lab i think from johns hopkins and other people they tried to build a labeled question answering data set but they were only able to get like 124 pairs and 23 hours of late of their work quickly you know this rapid scramble kind of thing but so they weren't really able to build a big data set that we were used to using with deep learning so we're looking for these information retrieval components and co-search was this system that said here's our vector index here's how it flows into a re-ranker question answering abstractive summarization all these different tasks and you see how all these different components kind of flow through one another and build this kind of complex system where the modularity of being able to replace these different components is so interesting and so we've seen also some really exciting trends in information retrieval like super charging supervised learning i think most recently well we'll talk about the most recent one but deepmind's retro model is an exciting example where they release two language models this gopher 280 billion parameter model and everyone you know says 280 billion parameters wow then they're also saying here's retro if you add the information retrieval it's better because it has the has the context better that makes a lot of sense to have the context so then kind of coming into the most recent thing and i think transitions really well to weaviate and this idea of computer intuition as we talk about how you use these kinds of search engines and then how machines use these search engines it to me it started off the first paper i became familiar with was facebook ai researchers had a paper titled internet augmented generation where they're querying the bing search api to to do the information retrieval so it's not clearing a vector search index it queries the bing search api and now today or yesterday we have open ai's web gpt where the same idea you query the bing search api but similar to what we're talking about with computer intuition and how you use search engines they're using reinforcement learning to train the model on how to interpret the results of the bing search api so what we've a lets us do is we have our neurosymbolic search and again coming back to this idea of serendipity symbolic filters traversing graphs the models can learn how they're going to really query this search api so they can um you know do these things like question answering and then learn how to use their information retrieval component which is something that i see as being such a powerful supercharger of this yeah no i i agree and i think so what's interesting about what you're saying um right there is that from a from a research perspective i completely get this right because you try to solve a problem and then there's the bing api to give you these results but if we look at one there was also one of the eye openers that i had that was like um let's if we would have if it would live in a world where all data would be publicly available then there would be no room for existence for something like we've hit because you just go to bing or to google and you find anything right so the idea is that i that i had was like so how much data are we talking about actually so how much data is behind closed doors and how much data is actually publicly available and um you know microsoft and google are quite open about how much data they have in their search engines and then if you look at estimations about how much data there's there actually is in the world you get to a number of like 0.0001 of data that google actually has indexed i mean i might be a a decimal point off there but the point is it's far less than one percent so that we thought like hey wait a second so you have the the data you have the models but you also need that search engine if you want to apply this to your own data so if you're like if you're a bank if you're an insurance company if you have a startup with with which that's generating their own data and and that is what plays so well together with these existing models that are trained on this um the information that's publicly available and i think one of the one of the things that i often am in discussion about with with people is the whole concept of fine-tuning right so and that i say i i understand the academ the academic argument for saying like in theory for every case you need to have a fine-tuned model i get that argument but in practice how people use it these general purpose models already bring them the results that they need and and i think that based on these examples that you just gave conor i think we will see more and more of these general purpose models as i like to call them being used by more and more people because they are already giving them the results that they need even if they are trained on stuff or getting to results that come from the bing api or whatever they are coming from right or the common crawl or those kind of things so um i think the point i want to make is that i think like the the trend that i think that i see in the usage of these models is that because these models become so much better over time using them for general purpose use cases becomes easier and easier as well so you need to do less you don't you don't need a phd anymore basically to um use such a model for your for your business or whatever you yeah i think okay so i'm gonna push a little back on the fi on the abandoned fine-tuning idea and i i thought you would i thought you would bring it on yeah so uh so i'll go through a list of citations and the first of which is uh don't stop pre-training it was one of the acl 2020 best paper rewards or it says you know basically they set up their data set of you have news articles imdb movie reviews biomedical papers and computer science papers and they showed how pre how continuing the pre-training for the domain of interest is extremely useful but i think and and i do agree with this idea that foundation model these bigger models on more data are more generally useful but so i think the next paper that we can kind of learn from is i think it's the allen institute why is ft i've made a paper a video explaining this paper on my youtube channel if interested and what it is is it shows this relationship between these large pre-trained models and then these fine-tuned models with respect to in distribution accuracy and out of distribution generalization and flexibility so if you fine-tune the model basically and the algorithm is that you fine-tune the model and then you have a weight space ensemble along the path from the fine-tuned model from the original starting point so i think that that is going to be a very successful way to trade off the out of distribution the generalization the flexibility of these large pre-trained models but then you also want to have you know your in-distribution kind of fine-tuned nature and i i guess generally as a phd student it does kind of break my brain the idea that some kind of general model could be better than you know fine tune on a particular data distribution that idea doesn't really make sense to me but i guess it yeah let me let me let me try to to to to pitch it to you right so what the idea is what's happening there so let's go back to that example that i that i gave off that we were searching for what was michael brecker's first saxophone right so with this out of the box model based on a wikipedia data set we do not find the answer so from from from an um from from an academic perspective if you have defined your research as can i find a answer to a natural language question based on this data set it would say no because it's it's not there right the answer is not there however if you then take off your science hat and you put on your engineering hat you can say like well wait a second the answer was actually in the in the top five results it just wasn't the first one so if i now run these five answers to the q a module and i see what the highest stance what the highest certainty answer is there then i do get the right answer so you can engineer your way to getting the answer and what i'm trying to say is yes i agree that in the ideal world that is solved on the academic level however the models are already good enough to solve it to solve people's use cases so the questions that people have so i agree with your remark you're absolutely right but i'm i'm looking at it from a different perspective i'm looking at from the perspective of is the model already good enough to solve the problem that a that this person has and the reason why i'm talking about this and i'm doing this and i'm saying air quotes when i talk about general purpose models is that we see that if you engineer your way out of it these general purpose models actually can perform better not on every use case of course but on news articles products uh those kind of things then if we extra fine-tune it on these um uh on specific data sets of course fine-tuning is always better but that's not always an option so i'm i'm trying to say like what i love to see is like that you have like the scientific side and the engineering side and they go hand in hand and they help each other to to have these end users build well whatever they want to build with these kinds of databases and models combined yeah so so my take on the engineering solution and thanks to dr mohit bonsal from the university of north carolina for sharing this paper with me and helping me think about these things is so their recent paper is vnl adapter so we're setting things like compactor adapter high performer these are strategies for how we can fine tune clip while only really tuning four percent of the so particularly this paper they only need to fine tune four point four percent of the parameters of clip to still retain the full performance as if you fine-tune this whole model so from the engineering perspective of that headache of trying to store the thing and do that fine tuning thing and all that kind of stuff these compact adapter layers are definitely pushing that in the right direction but then to kind of come back to one thing that i was curious about on this idea when uh you mentioned that like the the answer isn't in the data set the foundation model was say trained on what do you think about say say your goal is um is the we vva documentation right so you're training a question answering system on the we va documentation then i think you need some fine tuning right to navigate the webview documentation because it hasn't seen that data before so yes yes and no so so yes it always makes the results better but again that's so it it we need to be clear about what we define what the right answer is so i define the right answer it's like can we algorithmically get to the right answer in a decent amount of time which is different than does the model directly produce the right results and um so if you if you go for the latter one then the answer is yes you must fine tune it if you go for the pre for the for the first one then you don't necessarily have to fine tune it it will be it will yield better results but you don't necessarily have to do this and i know that i'm i know that i'm trying that i'm throwing a rock in the pond by saying this but the the the the point that i want to make is that is actually a very optimistic point is that these models are already so good that they are helping a lot of people already and yes making them better will bet everybody will benefit from this but i let me let me put it like this so the the other day so a metaphor for this right so the other day i was um i was making risotto and i have like certain ingredients that i have in when i make a risotto so i was getting the stuff and i was getting and then i wanted to have a specific type of cheese so i so i you know i mean in store and i want to buy the cheese and guys like ah we're out of this cheese so now the question is like so from a from a um uh air quotes academic perspective i can't make my risotto anymore because i need to have this cheese to go in the risotto but if not put on my engineering it's like so what do you do you have like similar cheeses and i got like yeah you know if you use this kind of wine you can use this kind of cheese as well so i couldn't make my risotto as i originally intended but from an engineering perspective i just used the different cheese and the people who ate the risotto still were happy with the risotto that i came up with and that is what i meant is that i am very interested in how can we get these models and the things they can do with them to the database into the hands of as many people as possible and part of that comes with the engineering around it and saying like hey these models are so sentence birds for example so many people are benefiting from that without touching the model once because they don't know how to do it right so they go like i want to build this cool app i want to build a cool uh solution i'm going to get a website or whatever and i just want to use that model and they go like wow it works so all the kudos to the team that that worked on on sentence board but i again i want to make this optimistic um [Music] your point then say like so it's already bringing so much value to people even though from an academic perspective it can still be better yeah i think yeah i think we're definitely on the same page with the two different kinds of like most applications yeah like right out of the box the sentence bird is so great and it's so interesting if you have that human intuition and then on the academic side as we you know look at things like what deep mind is doing what openai is doing and our creativity goes crazy and we think you know computer intuition the computers are going to be able to do all these tasks and we get so excited about that idea and then i think we think about two different ways of using we vva where on the left hand for where you have some use case and you have the human intuition already you just the end to end system is good whereas i think the other side you're looking at the python client the api and how you can put that sorry how you can put that into your into your training workflows and do research with it because it's a really exciting uh research platform we've it is like a product and it's like a science platform the science platform is really what excites me a lot as my coming from my background and so i think the transition let's talk about the demos that we have and the apis that are available for the demos and how this enables this kind of research so so with the demos we have uh wikipedia and wikidata and you can you talk about your conversations with wikidata and how exciting that's all been yeah that is that is fantastic because the so there was like so the wiki data it's actually funny story because um i found this repo from facebook research or meta research one of the two um where they had this this big graph data set that they trained on wikidata and so one of the things that i constantly do is that if people like something that they're seeing i want to know why so i asked them why do you like this so what we noticed was that we did a demo data set with wikipedia data and with wikidata so the wikipedia one was just interesting for people to see this at scale they they love it they mostly engineers or as i like to call them tech savvy product managers that play around with the api and you're like oh this is great i want this in my solution as well but but um the b graph one wasn't was another one so somebody was very um enthusiastic about this and so i said like why and um this person told me the following he said well he said so we do we do the research we generate the model and now we have many gigabytes of vectors and um the end the wiki entities related to it and we gotta kind of assume that it works because how are we gonna test that in practice are we gonna gonna load all these things in memory in a python script and search for it on our laptops no we don't because it just it's not practical he said and what you did with we've yet it's just you were actually showing in action what how it works we could actually try out this model that we that we were so um enthusiastic about and that was such an eye opener for me because um that step this proof that step that i always say like you need the in this new ml first worlds right so you need the data you need the models but you also need the database to search through it and we got so much positive uh feedback from from the folks even on wikidata we were like the tool of the week and and then you go like oh this is amazing because people are actually they can they can work with it they can play around with that and we're definitely gonna do more work on making that data set better we're just going to keep that completely open source for people to play around with it i even already know about people who reached out to me that are changing it they forked it and they're changing it to build it even in their own solutions and our own products and i was like yes that's exactly what we want and i hope that that early next year i can share some more cool things about this as well yeah it's so cool seeing the graph embeddings and really looking through graph embeddings wikidata is probably the best example maybe like if we constructed a twitter graph where it's people who follow you and then your nearest twitter neighbor or something like that would be another way of seeing these graph embeddings in action because when you pointed me in the direction of pytorch big graph that was really the first time i'd really looked at uh pi source big graph do you have any other kind of like examples of graph embeddings that inspire your excitement about these kinds of ideas like wikidata graph embeddings yeah so i so sometimes the ideas come from data sets that i see sometimes the ideas come from the models that i see so i was immediately intrigued by a model which is called cyborgs and cyborg is it factorizes cyber security logs and bear in mind so what the problem there is so the problem is um that if something comes from like a weird ip address you can immediately block it but if something else is happening that you can't solve algorithmically and a human needs to look at it that's an opportunity to do something with these embeddings so people started to create embeddings based on cyber security logs and i was like oh boy that's amazing because now you can store all these logs in the weave gate and if new logs come in comes in you can do a similarity search on threads from the past and say like is this somehow related to each other so that's just just one idea another idea that i had was the tremendous amount of work that i see happening for example gene2vec and those kind of things you can easily store a human genome in weaviate with its vector representations and search through it i would love to do some work there as well so essentially we have genes we have same goes for proteins but also customers right so you have a customer that behaves in a certain way um you can create an embedding based on these graph embeddings for this customer so now you get all your customers and alleviate and say like how are they related to each other the the graph relations that people make are amazing so for example um i saw an example about like hotels and people so where you can say okay i have um i have like connor and i have bob right bob booked hotels now we get like john doe in and john doe books one hotel or behaves in a certain way so the embedding that's created for john doe might gravitate towards you so then you know okay let's also show the hotels or the types of hotels that conner is interested in opposed to the ones that bubba is interested in because this person behaves in a similar way that conor is doing and this can go very far this can we're not only talking about the hotels that people booked but even how they search for the website where they where they click on and those kind of things um and what we also see and now i go a little bit away from the embeddings but something where the embeddings are used is that there's this whole thing happening with privacy and like a post cookie world here embeddings help as well because now i can create an you can create an embedding about somebody without knowing who this person is so it's very privacy safe if you will but you can still give a great user experience for whatever tool you are creating based on the embedding that you are creating for this user so it's just there's so much happening that's just fantastic yeah graph structure data representations is such an exciting idea and uh shout out to zach jost at uh welcome ai overlords is his youtube channel and uh he's working on this problem of like fraud detection cyber security and how you can make it a graph structured problem really interesting idea and all sorts of content about graph neural networks graph data is kind of the most natural way to represent some kind of data and yeah biology the protein protein interaction networks the drug target drug repurposing being like the big application sort of to look at all these kind of graph structure data is so interesting when i first was uh looking at graph structured data i was thinking in this context of like system one system two kind of thinking back when that um when that book thinking fast and slow came out and that was kind of an exciting idea in deep learning research and so i always thought of graph structure data as being like the system two component and kind of like causal inference like the way that we you know if we talk about information retrieval and then supervised learning being like system one is information retrieval system two is uh supervised learning reasoning say i always thought graph structured representations would be limited to that second part but now i'm seeing more how graph structure can help you build the embeddings of the data as well as sort of like raw text representations so one kind of question and you know we can just pass this if it if you haven't thought about this but i was thinking about like how do we combine the wikidata graph structured embeddings with the wikipedia text embeddings how do those two things play together oh actually i love that question because i do have some thoughts about this so one of the things that we have within wev8 and that's on purpose is that you don't choose a model to attach to a weave yet no you choose a model that you attach to a class that's in your weave yet so you could create a weavieate that has like the paragraphs from wikipedia with the sentence [Music] burton bettings but you can have another clause in there that represents the wiki data and that you say like okay we're going to use the the big graph embeddings to store that in the same weave yet now now you might say like well but they are completely different vector spaces that is true that is but what you can do for example is that let's say that you somehow start from the perspective of the wikidata the big graph uh embeddings and you you traverse the graph and you end up with stanley kubrick as i always gives an example and now you say okay i want to now know more about this director then you can just do one simple query and say okay i found this wikidata node in the graph now jump to the most similar a note in the in the part of the wikipedia embedding in the sentence and burnings and that is they are not closely related from a from a embedding's perspective because there are different embeddings but you can do the query so you can say oh i know from the wiki data that it's a director with the name danny kubrick and then you can do the semantic query that's handled by the sentence birth model to find it there so you can jump back and forth in that graph and that's really what's solved in the database so um i would i would even like there to go a step further i think that a year from now we're gonna see more and more use case where people have like four or five models just zooming in harmony in in one we've hit instance yeah wow that that's really exciting and i think from here we'll transition to multi-modal learning and getting into this idea of four or five vector spaces and combining the vector spaces but just quickly before we transition that i also wanted to just again like there's wikipedia wikidata and i think another problem that might motivate listeners into doing this research is scientific literature mining where you have citation networks and then you have say the text embeddings of the papers i think that's another very inspiring kind of application domain i see so many scientific literature mining tools out there and people tackling this problem because i think it's a really fun way to think about it and build a research career around these kinds of problems so let's talk about multimodal learning and you know we're talking about combining vector spaces with queries with class property reference class references we're talking about the graphql kind of structure between different things but let's just kind of start with like the image text and the idea of the clip in the v 1.9 from wev8 and how we do image text search and connected to all these kind of exciting ideas yeah so they're like there there are two things um that i think are that are interesting to to say about this so so the first is um using multiple models like for example clip and and and sentence embeddings in one we've gate i i will talk about it in a bit but the second thing is that i wouldn't be surprised if at some point and this is out of my realm of expertise but i would not be surprised if at some point somebody steps up and says okay wait a second we can make relations using v8 as the search engine between two completely different models so for example the the the big graph model and the sentence bet embeddings sends bird embeddings for the wikidata i can say something about their distances by having a natural language query in between i'm gonna train a new model that is gonna try to predict these relations i would not be surprised if we see that happening and if anybody's listening to this podcast who wants to do a uh some kind of a research project around that then they should reach out to me but to the first thing what we see a lot is this so sometimes you have use cases where um [Music] you somehow want to mix image search and text search but also different types of model search into one so so we see people create multiple graphql queries and then you have something which we like to call the the business logic layer or the middleware layer where they do something with these results that they're getting back because um um sometimes somebody uh might uh uh let's say you have an an e-commerce uh solution somebody types in in natural language what they're searching for but on the page that is being presented to the end user you might want to have natural language results so there the products come to the sentence embeddings but maybe you want to have an overview of three products that are similar to the image of the first result or images that are being returned based on the natural language input so then what happens is you have like a e-commerce front-end somebody types in a whatever they're searching for in wev88 we get do a sentence embedding search and a clip search the sentence embedding search returns natural language results so that can be product descriptions reviews but the clip results return images and then people do super cool creative things in actually showing that to end users and how they can um find the products that they're looking for so um that's a little bit different to your question about like um uh uh those multi-modals but what i meant is more that it sparks the a clip for example gives people the capability to now go from a natural language to the image something they couldn't do before and they built very cool things with that and so the more of these types of models we see i don't know what people will come up with but the you know going from doing something with video or with audio or those kind of things our users benefit from that again because they get they get more capabilities to get to potential results in these search results so that serendipity that we talked about earlier to present that for their end users and use these models in in in practice so um it's not a 100 answer to your question but it's like it's more like an example how these new models like clip are being used and what we see people build with them yeah and it's so exciting like um how it really enables that kind of like turning say instagram into a uh like a standard kind of e-commerce platform like if you imagine the way that say like i shop for nike basketball shoes i just look at like the standard shot where they're like centered in the white background and they're like right in the middle imagine to like wanting to see you like what do they look like on the court like what does some players wearing them look like and that kind of search and doing that kind of nearest neighbor where you take this little static picture of them in the shoe box and then you go see what does it look like in action so to say and that is a super sorry for quickly interrupting but i love this example because that is exactly the example where you have multiple models in the database zooming you know and just constantly creating these vectors but that allows you to create these kinds of applications and exactly the example that you just gave was hard to achieve if not impossible without clip but now with clip you can do these kind of things um on the fly so that's nice yeah and clip this has to be in like the top 10 breakthroughs it's such an exciting kind of thing it really definitely is yeah so i agree yeah and then so just like two other things i wanted to just touch on it's kind of like just image nearest neighbor search but also with the metadata annotation and coming back to neurosymbolic search where you know we're talking about text neurosymbolic search which is kind of obvious because you put the regular expression so to say and it's in the original data point it's not really like metadata compared to say when you have an image and then you have the metadata so to give an example of what i'm working with with the kova 19 convalescent plasma therapy thing that i mentioned earlier we have chest x-rays and we want to it's kind of like this idea of precision medicine enabled with vector search where we want to try to find like the nearest patient who had a similar experience to you and kind of what treatment worked for them and search through these large large databases and see you know how we can customize your treatment so to say so when we're searching for nearest chest x-rays maybe that's something we're interested in we could add the metadata like whether you're a cancer patient as well whether you had some kind of pre-existing heart condition and that kind of information would be really useful for interpreting these kinds of medical images and that kind of idea another interesting idea is this new data set that's being led it's ton of tons of researchers i think stanford berkeley i don't know the whole list because it's a very long it's one of these favorites with like 20 30 authors on it but the data set is called wilds and so what wilds is it's about annotating data for the sake of measuring domain generalization and so we have this kind of additional metadata annotations on our image data sets our molecule data sets our text data sets and this metadata that you can integrate through this graphql interface that's what i think really brings home neurosymbolic search and that and that's kind of one of the things that really has excited me so much about this and helped me keep my interest on this particular idea so i think we've you know covered so many topics and about like the technical ideas and these visions for the future but i think a lot of people out there would be curious about like your journey as a you know ceo co-founder of wev8 and you know recently featured in techcrunch and kind of like so what's your experience like with building this out as a company and your vision for the future on how this kind of game is played so to say oh where to start answering this question so the uh so so first of all it's like the joy that you have if you see like downloads going up positive feedback that you're getting that is fantastic and what you said about techcrunch thing etc that's just that's just amazing and that just is proof of showing like hey there's actually stuff happening in the in the world people the mindset of people is moving towards using these vectors in in in production and one of the things that is my personal um goal is to have these things like for example the research that is that is happening so that's that knowledge that people like for example like you have the engineering that is happening that's the knowledge that for example h-n has the the user experience part of it so that's for example knowledge that lara has my role is combining these things together and figuring out how that helps people on a day-to-day basis right so the example that you gave about the uh the the the medical use case right with the x-rays we we have we we know unfortunately i can't say much about it yet but we have these kind of cases as well the most beautiful thing is if you sit with a doctor and you show the first results and this person was does have is like zero knowledge about how it works just like this looks great i see where this is going and i like it very much what i'm seeing that is like in the in the journey that's the most um that's the most beautiful thing and every week i'm uncovering more and more of these cases so that is one of the things that i'm very excited about like i keep just being surprised how big the opportunity is there's like i haven't reached the limit yet so that that's and the third thing is like some people who have looked at uh we've hate might have seen some hints about it already and that is if you find a note in the weavier graph it has its own scheme created to it so it's like you see we've ate colon slash localhost slash and then you find the node in the graph well the fact that it has localhost there assumes that in the future it can maybe be something else than localhost so then it can be somewhere else over the internet and one of the things that is my personal big dream with this if this keeps growing is that the big problem that we talked about earlier about the semantic web and how do we connect these things together is that you can actually say well let's say that i have a dozen or ten dozen you know we've yet spread over the world and i just spread a query over the network and i let these models solve the answer and return the results so very simple example let's say you have a vvh from the new york times and you have a webview from the wall street journal and somebody says like okay what's happening now with covet you shoot it over the network and both of these vp8 instances return the results and you can in graphql represent them to the end user so you get like a as i like to call it the knowledge network and that is something that i'm really excited about about these kind of things as well it doesn't exist yet but if you look at we've hit you see all the ingredients already being there which is just be allowing people to connect data sets together to connect knowledge together to connect insights together outside of one instance and that is something that i'm also super excited about so that that would be my answer i guess yeah that is an exciting vision i really like that like like with um hugging face spaces and you know big thanks to merv and omar for helping me with my personal experience of setting up my kerasper with henry ai on hugging face bases is yeah they're building up all these demos of deep learning models and it's all in one central thing and imagine putting all the demos of we've yate and then you build a model on top of that and that's that's exciting yeah and that is the beauty of course of the whole open source nature of it so i had the hugging face has that we have that it's like it allows people to work together and build these amazing things and back to your question about like what my role my the only thing that i need to do is actually just make sure that these things resonate in harmony that's basically that's what i do so other people do the hard stuff i just i just try to make them resonate in harmony and um well some people might argue that but that's another for another podcast but uh um uh and that is just amazing to see how that works and how enthusiastic people get about it and and that's just i i wouldn't be surprised if this goes x 10 next year right so that's just uh that's just fantastic yeah it's amazing i mean like you're definitely a visionary you see these things ahead and i think that's really exciting to be learning from you about that and yeah that idea just then was so exciting to me and all these things so so thanks so much bob i'm sure we'll do you know more of these podcasts on our webview semi technology podcast i think this is a really great one and thanks again for doing this with me now thanks also for having this conversation with me and as always it's always great to talk to you connor so thank you so much you ", "type": "Video", "name": "weaviate_podcast_3_vector_search_use_cases_graphql_api_ux_multimodal_models_and_more", "path": "", "link": "https://www.youtube.com/watch?v=8wdUREOzi2M", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}