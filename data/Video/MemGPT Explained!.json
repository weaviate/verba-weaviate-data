{"text": "Thank you so much for watching our paper summary video on MemGPT! MemGPT is a super exciting new work bridging together ... \nhey everyone thank you so much for \nwatching this pay-per-view video of mgpt \nmgpt is a super exciting new research \npaper that's bridging together Concepts \nin operating systems with large language \nmodel applications and this is probably \nthe super exciting novel thing about \nthis is this reframing of the \nperspective around retrieval augmented \ngeneration as well as kind of llm tool \nuse into this perspective of thinking \nabout the llm as the processor the \nkernel behind the operating system that \nswipes in its own memory similar to page \nreplacement and all these kind of but \nquickly before we dive further into the \ndetails of mgpt the general setup is \nthat large language models have a limit \non how much text they can process as \ninput so say you're just chatting back \nand forth with one of these large \nlanguage models you can generally get a \npretty large amount of messages so say \ngbt 4 with 8,000 tokens as the maximum \ninput you can trade 140 messages of \nabout 50 tokens back and forth before \nthe chatbot is no longer able to uh \nreason about conversations you had in \nthe past so you know say you fired on \nchat gbt 2 months ago and told it your \nbirthday was October 11th then two \nmonths later it no longer remembers when \nyour birthday was so this is kind of \nframing it in this chatbot perspective \nof how many chats you can have back and \nforth with one of these popular large \nlanguage models if you also think about \nuh chat with your docs you then also \nhave to have uh the specific information \nin the context window which also eats up \nsome of these tokens and thus how many \nmessages you can trade back and forth \nbefore it can reference old messages by \njust looking in the context window so \nretrieval augmented generation has \nemerged as a solution for this is a \nsuper popular technique where you use \nvector eddings and search queries to \nonly populate the input with relevant \ninformation so here's an example without \nrag this use this example of time you \nsay what is rtoc a feature in weate and \nchbt doesn't know what it is but if you \ninstead you know say please ground your \nanswer in the following information and \nthen you ask it what is refc now it \nknows how to answer the question so when \nall the user wants to do is know what \nrefc is we get away with this pretty \nsimple rag setup where we can just \nretrieve some kind of information to use \nin our context window and then answer \nthe question so say we only need 200 to \n300 tokens in this particular example \nbut now let's imagine a long \nconversation where the user is \nrepeatedly asking questions about how to \nuse refc for their particular \napplication and we have to balance me um \nmanaging the memory of this conversation \nhistory as well as lookups from our \nretrieval database so the big idea in \nmgbt and this is super exciting is what \nif the large language model was aware of \nits own input window limitation and took \nactions accordingly so they're extending \nthe large language model with the tool \nuse of knowing when to add retrieval \nresults or say things that it learns \nfrom the conversation into its working \nmemory so let's step into the overall \narchitecture of mgpt so mgpt is the \noperating system for rag applications \nbridging together memory with tool use \nand this particular focus on managing \nthe main context memory so at the heart \nof the oper in system we have the large \nlanguage model processor then we have \nthe virtual context so the main context \nis what's currently in the input for the \nlarge language model to make its \nprediction what's in the external \ncontext is say our Vector database or \nour store of data where we can uh swap \nin and out with the main contexts like \npage replacement and operating systems \nto get the relevant context that we need \nto complete a certain task so this is \nthe the memory part of it and then the \nmemory is managed with functions and \nTool use so tool use is a super exciting \nidea where we conect Lang language \nmodels to things like say calculators or \nmaybe a weather API if you want to ask \nit the question what's the weather in \nBoston right now it needs to send that \nexternal request rather than relying on \nthe information stored in its parameters \nor particularly in the weather API \nexample it's unlikely that you're \nkeeping your vector database fresh with \nwith that particular information so you \nprobably have these kind of external \nservices that work into this picture as \nwell but more interestingly are these \nfunctions around reading and writing \nmemory so reading memory is where you \nyou know read from the vector database \nwe say retrieval a search query and then \nthere's also ideas around pagination and \nquery rewriting in this mgpc paper but \nwe'll get to that later but this is the \nidea of where you read memory to \npotentially add to the main context by \nusing these uh operating system \nfunctions like a pen to the working \ncontext we'll get into that later as \nwell but also interestingly we have \nwrite memory so as you're having this \nconversation history as I'm talking to \nmy chat gbt for a long time the mgbt has \nthese functions around you know Connor \njust told me his birthday is October 11 \nso let me add that to to my uh my \nstorage then we also have this idea of \ninterrupts and events so events are what \ntriggers mgpt to start doing some \nprocessing so whether this could be as \nsimple as I come to Chad gbt and I say \nwhat is rtoc and then that triggers the \nevent that starts all this processing or \nsay I upload a document or say there's a \nsystem message like hey your context \nwindow is at uh 3,500 tokens let's let's \nyou know start trimming it down or you \nhave things like a timer like every five \nminutes maybe it trims down or something \nlike this so you have this kind of idea \naround interrupts from operating systems \nwhere maybe you have some kind of \nasynchronous processing like to the \nlarge language model you say uh research \nhow selfrag works selfrag is a paper \nsimilar to mgbc that came out around the \nsame time so say you're doing that \nasynchronously while you continue the \nchat and then it interrupts and says hey \nI finished this uh research report \nshould I work it into the conversation \nor what should I do with this so this is \nthe general overview of how mgpt works \nso I took this quote from I don't know \nif it's an ex quote but just to \nreference that I got this from outside \nof the paper this was Charles Packer on \nthe amazing run llm podcast with \nProfessor Joseph Gonzalez and he frames \nthis idea of mgbt as an agent that knows \nhow to use memory management tools and I \nthink that's just a perfect way to \ndescribe it a super exciting direction \nfor this whole field of retrieval \naugmented generation is endowing the \nlarge language model with the option to \nwrite to the database as well or in this \nparticular case read WR to its \nparticular main context so you've always \nhad this idea of read from the Save \nVector database and then just kind of \nblindly put it into the main context but \nnow you kind of have this layer in the \nMiddle where you have search results and \nthen you're saying what from the search \nresults am I going to put into my main \ncontext and then kind of keep there as I \ncontinue the conversation so I think \nthis quote is just so powerful an agent \nthat knows how to use memory management \ntools so the general idea here is that \nwe're building an operating system for \nlarge language models and a quick \nquestion I'd ask the audien is what you \nthink about framing Frameworks like Lang \nchain or llama index in this kind of way \nis thinking about them as \noperating systems for large language \nmodels that orchestrate the connection \nbetween language models and tools and \nVector databases and memory but so \ndiving a little further Andre karpathy \nhas also written a really interesting \ntweet on this kind of llms and operating \nsystems and this is quite an interesting \nidea I think of uh taking that next step \nin the thinking of not just llms and \ndatabases but having a whole operating \nsystem that orchestrates this kind of \nthing so from Andre karpathy with many \npuzzle pieces I assume dropping recently \na more complete picture is emerging of \nllms not as a chatbot but the kernel \nprocess of a new operating system so \nwhat we're seeing in mgbt is the llm is \nthe kernel process that's saying I need \nto change my memory I need to use this \ntool or I need to respond to this event \nso it's the kernel and the operating \nsystem that just that is you know \norchestrating how to manage its memory \nand use tools for example today it \norchestrates input and output across \nmodalities text audio Vision code \ninterpreter ability to write and run \nprograms browser internet access or \nembeddings databases for files and \ninternal memory storage and retrieval so \nsome examples of the different kind of \nuh functions it can it can do or memory \nit can access a lot of computing \nConcepts carry over currently we have \nsingle-threaded execution running at 10 \nHerz tokens per second and enjoy looking \nat the assembly level execution traces \nstream by Concepts from computer \nsecurity carryover with attacks defenses \nand emerging vulnerability so that that \nI think there's just so much information \nso much interesting stuff to explore in \nthat in that little text alone this idea \nof you know you know we have single \nthreaded where we just have one llm \nprocess you know where most of I know at \nleast I'm doing this is logging the llm \nin my terminal and just kind of watching \nit Go by because you know you're paying \nfor the tokens but this kind of we SE \nthings like uh maybe Lang Smith is a \ngood example from Lang chain of \nvisualizing these complex prompt chains \nfor uh understanding these execution \ntraces but I think this kind of like \nparallelism you know if you have like \nconcurrency and llm tasks like again \nthat example of like uh research self \nRag and then it's doing This research in \nthe background and then it says hey I \nfinished like there's probably just so \nmuch opportunity from that and so \nfinishing up I also like the nearest \nneighbor analogy of operating system \nbecause the industry is starting to \nshape up similarly Windows uh OS X and \nLinux GPT Palm cloud and llama an \noperating system comes with default apps \nbut has an app store you say the chat \ngbt Marketplace and kind of how code \ninterpreter is plugged in with coh here \nyou have coral and so yeah we're \ndefinitely seeing that kind of app store \naround the language model and then most \napps can be adapted to multiple \nplatforms again the API say wv8 generate \nmodule showing how you can also take the \nthe model out of the app store tldr \nlooking at llms as chat Bots is the same \nas looking at early computers as \ncalculators we're seeing an emergence of \na whole new Computing Paradigm and it is \nvery early so this is a super exciting \ntweet in this whole context of uh llms \nand operating systems so let's dive into \na little more particularly what makes \nthe the mgbt and operating system which \nis particularly this kind of memory \nmanagement as a large language model \ntool so what they're adding in mgbt is \nthe working context append replace these \nkind of functions so you have this kind \nof conversation where you say hello Chad \nwelcome I'm excited to embark on this \njourney with you as a PhD in computer \nscience blah blah blah and then the user \nsays you know this information of my \nbirthday is October 11th and my favorite \ncake is this chocolate lava my favorite \ncake so this is an example of how it \ntakes the conversation history and it's \ndeciding what is important to put in its \ncontext so similarly \nuh it might have a system message that \nsays warning the conversation history \nwill soon reach its maximum length \nyou're making the language model aware \nof its own token limitation say Hey you \nknow you've got 3500 tokens we're going \nto need to compress this so then it will \ncompress it as following it takes the \nconversation history and it depends this \nkey personality trait enjoys high-speed \nAdrenaline Rush activities like Formula \nOne racing and intense gaming sessions \nin csgo so it's doing this to compress \nits context window so similarly with \nsearch we say search will quickly get \ninto recall versus archival storage and \nhow they differentiate that in the paper \nbut you're having this conversation what \nwas the artist you mentioned you could \nget into so the user is asking about you \nknow conversation history so you're then \nlooking into your you know your external \nstorage your vector database where you \nmight have two kinds of vector databases \nyou can have all sorts of kinds of \nvector databases but for now you have \nthe storage of the event history like \nall the conversations between you and \nyour chatbot as well as say like general \ninformation like if you're chatting with \nyour docs this is the conversation we've \nhad these are the docs so two two \ndatabases so say you're searching the \nconversation history about music from \nthere it recovers you know you're \ntalking about you like Taylor Swift so \nit adds that to the working context \nsimilarly we also have replace so this \nis a super exciting idea where you have \nnew information so you used to say you \nknow I was super into horror movies \nrecommend me horror movies and now your \ntastes have evolved and so now you're \ninto romantic comedy so it replaces the \nin context with I watch horror movies to \nromantic comedies so I think another \nreally interesting quot from the paper \nis to think about this as the the mgbt \nis documenting its progress on the task \nby writing to its own working memory so \nit's doing a long task like document \nanalysis it's only writing to its \nworking memory say important things that \nit's going to help it further so it's \nkind of like this idea of distilling The \nCore Concepts into you know what's \nhelping you with your research or \nwhatever you're doing so let's dive a \nlittle further into types of context so \nthese types of context are the explicit \nlabels of the parts of the input window \nto the large language model and I think \nthis kind of Separation this explicit \nthing of these are the system \ninstructions this is the conversation \nhistory this is the working context I \nthink there's just so much more \nopportunity to explore that kind of \nseparation of the parts of the input \nwindow so say you have kind of this uh \nsay you're in these multi-agent \nFrameworks like autogen where you have \nthis uh information about your persona \nlike I am a software engineer I like \ngoang and things like this and then you \nalso have say a highle description of \nlike what you're working on as well as \nthis kind of retrieval context and maybe \nmore immediate recent conversational \ncontext with the other software \nengineers and that multi-agent framework \nbut this kind of separation of the \ncategories of the input window and how \nyou think about retrieving and \naugmenting each particular part of it so \nwe start off with system instructions so \nsystem instructions you know these are \nlike the pre- prompt is like you are a \nhelpful assistant but now that you are a \nhelpful assistant thing has been \nextended with the the descriptions of \nthe tools that you have access to so in \nsay open AI funks you get this like Json \ndictionary that tells you what a \nfunction does and how to format the \ninput output Arguments for sending a \nrequest to that API so if it says hey \nthis is a calculator you can use it to \nadd multiply numbers together this would \nbe how you would uh trigger a request to \nthe \ncalculator the conversational context is \nthen a first in first out cue of recent \nevent history and then an interesting \nthing is this recursive summarization so \none of in my opinion one of the most \ninteresting ideas of Lang chain in llama \nindex has been this idea of uh where you \nwhere you have this kind of recursive \nsummarization so if you have docu you \nhave too many documents that you can fit \ninto one input window you'll you'll have \nsome kind of prompt like please \nsummarize the following documents you'll \nreceive them one at a time as well as a \nsummary so far and then so you keep this \nlocal summary and you just keep looping \nthrough the documents updating the \nsummary and so on so you do this to the \nend of the conversation history so say \nthese are my last 10 you know back and \nforth of the chatbot and these are my \nfirst 200 messages these would be \nrecursively summarized and just \nsomething that can fit in the input and \nthen you have this working context so \nthis working context is where is the \nmemory scratch pad for where the LM \nprocessor is reading say what it's just \nretrieved and it's looking through the \nsearch results and it's saying okay I \nwant to take that and put it in my \nworking context or you know similarly \nlooking through its conversational \nhistory so these this is what's \ncurrently in the in the memory to the \nlanguage model what's currently in \ncontext so then we also have this \nexternal storage if we'll you know go \nall the way back to our picture of this \nwhole thing we have the main context \nthat's of system instructions \nconversational context and then working \nmemory and then we have our external \ncontext which is where our Vector \ndatabase comes into the picture so \nwithin external storage the authors are \nlooking at two different kinds of \nstorage so recall storage this is just \nlike the Raw event log so say it's chat \nhistory or document processing just the \nraw you know what happened I uploaded \nthis document I asked you this question \nabout the document the system ended up \nsending this answer so that I then sent \nthe next question which was this or just \nthe um the archival storage which is the \ngeneral read right store of say \nWikipedia or you know your docs in the \nchat with docs classic example so these \nare kind of the two kinds of storage \nthat we might retrieve from so the \nauthors also present three different \nways of querying these external database \nit can be time based where say you just \nget the most recent events which makes a \nton of sense for conversation history \nbut then say you have information \nstorages then you have text search and \nembedding based search so the next key \npart to this and this is probably the \nkey part is this self-directed editing \nand retrieval so again we saw within \nthat function schema that goes into the \nsystem instructions are going to be how \nyou do this working context out of pen \nworking context out of replace the \nfunctions for how you will take say \nsearch results and then you work that \ninto the working context or update the \nworking context so then we have the \ncontrol flow so events are going to \ntrigger the start of this process so the \nyou know user message system message \nuser interactions and then we have this \nkind of function chaining for how we're \nmanaging retrieval results which is also \na really interesting uh part of this \npaper that I think of as marrying mem \ngbt with web gbt but with this also kind \nof interesting rephrasing of the query \nso with web gbt you had search actions \nso you wouldn't just retrieve and then \njust take the top five results and just \nput those into the into the input you \nwould instead say uh let me see the next \npage of search results because you know \nthis is how humans use things like \nGoogle search as we you know scroll \nthrough the results to try to find the \nthing that we're looking for so mgbt is \nalso adding this thing where uh in \naddition it might look through say you \nknow three pages of results and then \nreflect on uh let me actually try a \ndifferent query this query is not \nspecific enough and I'm learning that by \nlooking at the results that come from \nthis query so that's a pretty \ninteresting additional layer to this we \nsay have things like uh query \nreformulation where you pass the query \nto the large language model and prompt \nit like here's a query uh could you \nplease reformulate it to get better \nsearch results when passed to a search \nengine and things like this but making \nit more meta with this kind of \nself-correcting where it sends this \nquery sees some results and then learns \nfrom that to reformulate the query so as \na quick recap of the core ideas we have \nthe main context that has these explicit \nseparations of the part of the context \nfrom the system instructions to the \nconversational context or the event \nhistory as well as the working context \nand I think this that part of it is just \nsuper exciting the continued exploration \nof how we explicitly separate the \ncontext especially as we get longer and \nlonger context models then we have the \nexternal context which has the recall \nstorage and archival storage or say two \ndifferent ways of thinking about it \ncould be two different classes in a we8 \nvector database instance but two \ndifferent sources to retrieve \ninformation from then we have this \nself-directed editing which is you know \nhow we're augmenting our work in context \nwith things from the event log or say \nour retrieval and then we also have \nthese search actions through the \nretrieval like paging through search \nresults or say formulating a new query \nthen we have this control flow and \nfunction chaining understanding that we \nhave system events that kick off the \nmgbt process as well as say the function \nchaining involved in paging through \nsearch results and reformating the query \nso kind of opening up the framework to \nbe extended in the future now let's dive \ninto sorry now let's dive into some of \nthe experiments in mgbt so they start \noff with the the general questions of \ndoes mgbt improve consistency and \nengaging this so \nconsistency does mgbt leverage its \nmemory to improve conversation \nconsistency can it remember relevant \nfacts preferences and events from past \ninteractions to main coherence this is \nthe whole idea of you know two months \nago you told chat gbt that uh your \nbirthday is October 11th and now you're \ntalking to it later and it's going to \nremind you of your birthday or things \nlike this so then engaging this does \nmgbc produce more engaging dialogue by \ntaking advantage of its memory does it \nspontaneously incorporate long-range \nuser information to personalize messages \nso to evaluate this they use the \nmulti-session chat data set so the \nmulti-session chat data set is generated \nby human labelers who they're given a \nprompt to play a particular Persona and \nthen they have five SE five chat \nsessions and each chat session has about \n12 messages so this is the data set is \nyou play a role like hey I am into to uh \ngaming and horror movies and things like \nthis and then you chat with another \nhuman who similarly has like a Persona \ncard so then the data set is augmented \nto add a single question answer pair at \nthe six session that will do some kind \nof long range reference to something \nsaid earlier to see if it was able to \nuse this uh particular way of organizing \nits memory to recall the particular \nthing about who it's speaking with so \nthese are the results of uh jointly \nhaving the Rouge score which is like the \nsome some type of engram overlap I'm not \nsure the exact details of but you know \nthis kind of engram overlap between that \nground truth answer and then what the \nlanguage model produce as well as this \naccuracy which is this llm self eval \nthing where you give gbt for uh the \nquestion answer and then the gold answer \nand you say you know how was this answer \nis it accurate did it f is it close \nenough to the uh the gold answer so then \nanother task they tested was \nconversation opener so this was about uh \nseeing how well it can open the \nconversation with something engaging Bas \nso this is measuring that engaging this \nwhereas this measures a consistency so \nthis is you know the the it has the gold \nPersona of the user and then it has this \nuh human Baseline of what was said so \nI'm setting the elsat I want to be an \nattorney blah blah blah and then has \nthis particular preferences around I \nlove coffee and I love tea so then these \nare three different kinds of responses \nfrom mgbt whether it's using the work in \ncontext and the recall storage to say \nwork in the uh the tea and the coffee \nthing into the opening response versus \njust something generic like you know hey \nit's a pleasure to talk to you let's you \nknow let's talk so so using this kind of \nstuff to have a more engaging opener and \nand they similarly measure this by \nhaving the similarity in conversation \nopeners between humans and then the mgbt \nwith these different contexts so here's \nanother Super exciting detail to mgbt is \novercoming this lost in the middle \nproblem so lost in the middle is a \nfamous paper that shows that uh in \nretrieval augmented generation the \nlanguage model tends to only attend to \nthe first search result or the last \nsearch result so if you have the \ninformation you need in the middle so \nreturn 10 search results to put in the \ninput and the thing you need is at \nposition five the language model is not \nreally able to parse the search results \nand find it in position five so because \nmgbt does this kind of paging of the \nsearch results and only adding relevant \ninformation back to its working memory \nyou have this kind of flat line of it \ndoesn't matter how many documents you \nretrieve it's going to have the same \nperformance because it's parsing through \nthe search results to add it to its \nworking memory and they also introduced \nthis new task of nested key value \nretrieval so in Lost in the middle uh \none of the tasks is you have key value \ndictionaries so it's like U ID key u ID \nvalue and it would say like what's the \nvalue for \n94071 FF right and so then it has to \nlook up the value so now you're kind of \ndoing this chaining where it's storing \nthe the nested values and so it's it's \ntesting this multi-hop question \nanswering where you're the you know the \nintuition what it would eventually be \nused for is you have questions like did \nAristotle use a laptop you break that up \ninto when did Aristotle live when were \nlaptops invented answer each separately \nand then merge it together so this is \nkind of testing that ability to merge \ntogether facts awesome so that's a recap \nof the core ideas of mgbt and some of \nthe experiments in the paper now let's \ndive into some of the future work \ndirections outlined in the paper as well \nas some of my personal takeaways and how \nI think mgbt will impact the entire \nspace of retrieval augmented generation \nso starting off the authors mention \napplying mgbt to other domains with \nmassive or unbounded context they \nexplore using mgpt for chat Bots as as \nwell as document analysis in this case \nreproducing the natural questions \nexperiment from Lost in the- middle and \nshowing how mgpc can help with that they \nalso discuss integrating different \nmemory tier Technologies like databases \nor caches I think that is a super \ninteresting one where you have different \nkinds of memories and you have different \nlatencies for the different types of \nmemory and so that is a super \ninteresting topic then further improving \ncontrol flow and memory management \npolicies just I think just further \nunderstanding the action space and how \nto describe the tool of me of memory \nmanaging your memory to the llm and then \nfine-tuning an open source model for M \nGPT tool use so in the experiments \nthey're prompting mostly gbt 4 gbt 3.5 \nto do this what would it take to get \nllama 2 to achieve the same kind of tool \nfollowing for uh memory management so I \nwant to kind of outline that a little \nmore because I think that's a pretty \nexciting future Direction so we \ngenerally are looking at this idea where \nwe're using gbt 4 to create training \ndata then we use knowledge distillation \nto train a smaller model on the labeled \nexample from gbt 4 and this way you \ncompress it into the smaller models or \nsay the open source models so this is \nkind of you know we're there are all \nsorts of tasks that you can kind of \ncompress this way and I think that's one \nof the most exciting directions for the \nfield right now is we're using language \nmodels for all sorts of things whenever \nyou have a prompt for something you have \na task that you could then generate \nlabeled examples with GPT 4 and then \ncompress it down into a model into say \nllama 2 with the 7 billion parameters \nit's going to be cheaper to serve and \nyou know you run it well it's it's still \nin the air if that's going to be cheaper \nto serve because you know open AI they \nthey have all sorts of you know \ninfrastructure behind how they serve \ntheir API so it's interesting still \nexactly the cost difference between you \nserving your llama 27b compared to the \ngbt uh 4 3.5 turbo all these kind of \nstuff so there's also kind of the idea \nthat say F 1.5 billion parameter that \ntextbooks are all you need paper there's \nthis idea of you can maybe keep going \nand keep compressing it and if we get to \nthe point of say \nyou only need a 300 million parameter \ntransformer for your task and say neural \nmagic is exploring uh like sparsifying \nthese models to run them on CPUs so that \ncould be really interesting in terms of \njust you know the cost of running these \ninference and if llm inference cost gets \nsuper fast and super cheap that unlocks \nall sorts of kind of new use cases so \nhere are some of my personal takeaways \nfrom this so firstly for me it was \nreally interesting to see this kind of \nexplicit uh when to active retrieval \nthing and compare that with Flare which \nis the active retrieval augment to \ngeneration technique so with Flare what \nyou do is you're sampling the next \nsentence and you multiply out the log \nprobabilities of the tokens for that \nnext sentence if that's below a certain \nthreshold you'll do another retrieval \nbecause it's saying that basically that \nnext sentence it wasn't grounded in \nfacts you need to retrieve more \ninformation to help have a better next \nuh sentence generated compared to this \nkind of M GPT where you have this like \nexplicit you know I I don't know what I \nI don't have what I need to write this \nnext sentence so let me go retrieve and \nupdate my working context and so this \nkind of whether you just want to decode \nit from the probabilities of the \nlanguage models or you want to have this \nkind of memory management active \nretrieval as an explicit tool that it \nyou know calls with functions the next \nbig thing and something that they talk \nabout in the paper as well is kind of \nthis latency of mgbt if every time you \nchat with your uh you know your chat \nbody it has to do all these steps then \nthat's going to be really slow and \nthat'll be problem so there' probably be \nlike a a layer on top of this where it's \nlike kind of a quick answer compared to \nthis whole like operating system thing \nand that's kind of related also to the \nyou know the compressing the model and \ntrying to make all this run faster the \nthird point for me that I think is \nreally interesting is the difference \nbetween this kind of uh web result \npaging or reranking so similar to web \ngbt mgbt is going to like scroll through \nsearch results and so I'm curious what \npeople generally think about this \ndifference between like next page \nprevious page actions compared to just \napplying a reranking model which is a \nhigh-capacity model that generally takes \nin the query in each document and then \ngives it a higher capacity ranking score \nlike matching score and then Resorts the \nlist from say the course grain retrieval \nor we're now seeing these kind of \nranking models that would take in like \nyou know 10 documents as input and then \nrerank them by kind of looking across \nthe documents in addition to just a sort \nof query and one candidate document at a \ntime kind of setup so a lot of \ninteresting things happen with ranking \nand it makes me I'm not sure I'm super \nbullish on this kind of paging concept \nbecause I think reranking is already \nkind of you know know the the better \nversion of that so uh then in the paper \nthey also have these kind of um \nperspectives on training longer context \nmodels sort of framing that the purpose \nof this uh paper is is hey we're you \nknow we're never going to get models \nthat can uh process like a 100,000 \ntokens so we're going to need these kind \nof memory management techniques and so \nwhat I've kind of learned about this \nespecially in the weeva podcast with \nofier press is that it's not just kind \nof the quadratic attention you can kind \nof have like gradient checkpointing and \nthings like Alibi attention to get \naround sort of the computational \ncomplexity behind uh scaling the input \nlength the real problem is sort of the \nuh training data and there's not a lot \nof good um training data that's \nnaturally like 100,000 context length so \nthat's more so the interesting thing is \nwhere do you get this data from so I've \nhad these really interesting \nconversations with Owen kgve who's the \nfounder of sci-fi and so this will be \nlinked in the description it's a GitHub \nproject where you're creating synthetic \ntextbooks and I think this kind of \nsynthetic data it could be the answer to \nhow do we create the training data for \nthese super long context models so some \nother takeaways is I think this kind of \nparallel asynchronous concurrent \nprocessing is going to be a super \ninteresting direction for the evolution \nof this so you know say you're having \nthis conversation and you we talking \nabout mgbt and you also want to kick off \nthis research on how does self rag \nmanage rag selfrag is like another paper \nthat came out it's like this is like the \ndog food as I'm doing this I'm thinking \nit would be interesting if I could also \nhave a knowledge of that paper so \nimagining it's kicking off that async \nresearch task and then interrupt he \nfinished the report or I've written it \nto the database all these kinds of \nthings so then actually let me come back \nto the gorilla thing but so seven would \nbe uh this idea of the use of databases \nin caches so a really interesting thing \nand I you know I'm not an expert on this \nbut I learned so much from listening to \nuh Eddie and present how multi-tenancy \nwas architected in we8 at the AI \nconference and some future directions \nlike you you have all these kinds of U \nmemory with computers right you have \nlike the memory cache you have like L1 \nL2 and then you have like RAM and then \nyou have ssds you know hard disk and \nthen you maybe have like cold cloud \nstorage so there's like all these \ndifferent kinds of ways of having memory \nand maybe the llm operating system can \nmore intelligently kind of cache memory \nand use like the physical storage so \nit's definitely not something I'm an \nexpert on but it it definitely I can see \nkind of you know how that could be an \nopportunity so then let's talk about \ngorilla and so shashir Patel is one of \nthe authors of this paper this comes \nfrom the same lab as the gorilla llm so \nthat's kind of what drew me to this \ncurious to see if there was a connection \nwith the gorilla llm so I think the \nangle here is allocating as few tokens \nas possible with the gorillas so \nthinking about mgbt and Guerilla the \nidea is to describe the tool in as few \ntokens as possible because the whole \nidea of this is you know we need to be \nefficient with our token allocation \nsimilar to lead to like memory \nallocation is token allocation so if we \ncan just describe our tools like you \nknow in the case of the we8 gorilla you \nhave access to a vector database API you \ncan perform different kinds of searches \nsuch as bm25 vector or hybrid you can \nadd reranking or you can add filters so \nyou just have this succinct natural \nlanguage description then it can do the \nnatural language instruction of the \nsearch it wants to execute with you know \nmore sophisticated searches rather than \njust uh search music right you can use \nall the apis of we v8's graphql API and \nthen it can translate this natural \nlanguage instruction into the graphql \nwith the gorilla under the hood so \nmultiple language models also in the \nintermediate say the parser step let say \nin this parser step you have another uh \nlanguage model a gorilla that is H \nformulating the tool requests into the \nparticular API so thank you so much for \nwatching this explanation of mgpt I \nreally hope you enjoyed it I'd be more \nthan happy to answer any questions or \ndiscuss any ideas you had about the \ncontent you know explored in this video \nif you want to connect with me \npersonally I prefer to manage \nCommunications on X at C30 if you want \nto learn more about wv8 you can check \nout we8 iio or if you want to join the \nWEA community on slack so thank you so \nmuch for watching and I hope you found \nthis useful \n", "type": "Video", "name": "MemGPT Explained!", "path": "", "link": "https://www.youtube.com/watch?v=nQmZmFERmrg", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": [{"text": "hey everyone thank you so much for", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 0, "tokens": 0, "vector": null, "score": 0}, {"text": "watching this pay-per-view video of mgpt", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 1, "tokens": 0, "vector": null, "score": 0}, {"text": "mgpt is a super exciting new research", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 2, "tokens": 0, "vector": null, "score": 0}, {"text": "paper that's bridging together Concepts", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 3, "tokens": 0, "vector": null, "score": 0}, {"text": "in operating systems with large language", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 4, "tokens": 0, "vector": null, "score": 0}, {"text": "model applications and this is probably", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 5, "tokens": 0, "vector": null, "score": 0}, {"text": "the super exciting novel thing about", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 6, "tokens": 0, "vector": null, "score": 0}, {"text": "this is this reframing of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 7, "tokens": 0, "vector": null, "score": 0}, {"text": "perspective around retrieval augmented", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 8, "tokens": 0, "vector": null, "score": 0}, {"text": "generation as well as kind of llm tool", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 9, "tokens": 0, "vector": null, "score": 0}, {"text": "use into this perspective of thinking", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 10, "tokens": 0, "vector": null, "score": 0}, {"text": "about the llm as the processor the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 11, "tokens": 0, "vector": null, "score": 0}, {"text": "kernel behind the operating system that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 12, "tokens": 0, "vector": null, "score": 0}, {"text": "swipes in its own memory similar to page", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 13, "tokens": 0, "vector": null, "score": 0}, {"text": "replacement and all these kind of but", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 14, "tokens": 0, "vector": null, "score": 0}, {"text": "quickly before we dive further into the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 15, "tokens": 0, "vector": null, "score": 0}, {"text": "details of mgpt the general setup is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 16, "tokens": 0, "vector": null, "score": 0}, {"text": "that large language models have a limit", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 17, "tokens": 0, "vector": null, "score": 0}, {"text": "on how much text they can process as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 18, "tokens": 0, "vector": null, "score": 0}, {"text": "input so say you're just chatting back", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 19, "tokens": 0, "vector": null, "score": 0}, {"text": "and forth with one of these large", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 20, "tokens": 0, "vector": null, "score": 0}, {"text": "language models you can generally get a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 21, "tokens": 0, "vector": null, "score": 0}, {"text": "pretty large amount of messages so say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 22, "tokens": 0, "vector": null, "score": 0}, {"text": "gbt 4 with 8,000 tokens as the maximum", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 23, "tokens": 0, "vector": null, "score": 0}, {"text": "input you can trade 140 messages of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 24, "tokens": 0, "vector": null, "score": 0}, {"text": "about 50 tokens back and forth before", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 25, "tokens": 0, "vector": null, "score": 0}, {"text": "the chatbot is no longer able to uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 26, "tokens": 0, "vector": null, "score": 0}, {"text": "reason about conversations you had in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 27, "tokens": 0, "vector": null, "score": 0}, {"text": "the past so you know say you fired on", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 28, "tokens": 0, "vector": null, "score": 0}, {"text": "chat gbt 2 months ago and told it your", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 29, "tokens": 0, "vector": null, "score": 0}, {"text": "birthday was October 11th then two", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 30, "tokens": 0, "vector": null, "score": 0}, {"text": "months later it no longer remembers when", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 31, "tokens": 0, "vector": null, "score": 0}, {"text": "your birthday was so this is kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 32, "tokens": 0, "vector": null, "score": 0}, {"text": "framing it in this chatbot perspective", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 33, "tokens": 0, "vector": null, "score": 0}, {"text": "of how many chats you can have back and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 34, "tokens": 0, "vector": null, "score": 0}, {"text": "forth with one of these popular large", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 35, "tokens": 0, "vector": null, "score": 0}, {"text": "language models if you also think about", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 36, "tokens": 0, "vector": null, "score": 0}, {"text": "uh chat with your docs you then also", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 37, "tokens": 0, "vector": null, "score": 0}, {"text": "have to have uh the specific information", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 38, "tokens": 0, "vector": null, "score": 0}, {"text": "in the context window which also eats up", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 39, "tokens": 0, "vector": null, "score": 0}, {"text": "some of these tokens and thus how many", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 40, "tokens": 0, "vector": null, "score": 0}, {"text": "messages you can trade back and forth", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 41, "tokens": 0, "vector": null, "score": 0}, {"text": "before it can reference old messages by", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 42, "tokens": 0, "vector": null, "score": 0}, {"text": "just looking in the context window so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 43, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval augmented generation has", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 44, "tokens": 0, "vector": null, "score": 0}, {"text": "emerged as a solution for this is a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 45, "tokens": 0, "vector": null, "score": 0}, {"text": "super popular technique where you use", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 46, "tokens": 0, "vector": null, "score": 0}, {"text": "vector eddings and search queries to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 47, "tokens": 0, "vector": null, "score": 0}, {"text": "only populate the input with relevant", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 48, "tokens": 0, "vector": null, "score": 0}, {"text": "information so here's an example without", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 49, "tokens": 0, "vector": null, "score": 0}, {"text": "rag this use this example of time you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 50, "tokens": 0, "vector": null, "score": 0}, {"text": "say what is rtoc a feature in weate and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 51, "tokens": 0, "vector": null, "score": 0}, {"text": "chbt doesn't know what it is but if you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 52, "tokens": 0, "vector": null, "score": 0}, {"text": "instead you know say please ground your", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 53, "tokens": 0, "vector": null, "score": 0}, {"text": "answer in the following information and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 54, "tokens": 0, "vector": null, "score": 0}, {"text": "then you ask it what is refc now it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 55, "tokens": 0, "vector": null, "score": 0}, {"text": "knows how to answer the question so when", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 56, "tokens": 0, "vector": null, "score": 0}, {"text": "all the user wants to do is know what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 57, "tokens": 0, "vector": null, "score": 0}, {"text": "refc is we get away with this pretty", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 58, "tokens": 0, "vector": null, "score": 0}, {"text": "simple rag setup where we can just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 59, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieve some kind of information to use", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 60, "tokens": 0, "vector": null, "score": 0}, {"text": "in our context window and then answer", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 61, "tokens": 0, "vector": null, "score": 0}, {"text": "the question so say we only need 200 to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 62, "tokens": 0, "vector": null, "score": 0}, {"text": "300 tokens in this particular example", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 63, "tokens": 0, "vector": null, "score": 0}, {"text": "but now let's imagine a long", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 64, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation where the user is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 65, "tokens": 0, "vector": null, "score": 0}, {"text": "repeatedly asking questions about how to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 66, "tokens": 0, "vector": null, "score": 0}, {"text": "use refc for their particular", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 67, "tokens": 0, "vector": null, "score": 0}, {"text": "application and we have to balance me um", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 68, "tokens": 0, "vector": null, "score": 0}, {"text": "managing the memory of this conversation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 69, "tokens": 0, "vector": null, "score": 0}, {"text": "history as well as lookups from our", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 70, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval database so the big idea in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 71, "tokens": 0, "vector": null, "score": 0}, {"text": "mgbt and this is super exciting is what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 72, "tokens": 0, "vector": null, "score": 0}, {"text": "if the large language model was aware of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 73, "tokens": 0, "vector": null, "score": 0}, {"text": "its own input window limitation and took", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 74, "tokens": 0, "vector": null, "score": 0}, {"text": "actions accordingly so they're extending", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 75, "tokens": 0, "vector": null, "score": 0}, {"text": "the large language model with the tool", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 76, "tokens": 0, "vector": null, "score": 0}, {"text": "use of knowing when to add retrieval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 77, "tokens": 0, "vector": null, "score": 0}, {"text": "results or say things that it learns", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 78, "tokens": 0, "vector": null, "score": 0}, {"text": "from the conversation into its working", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 79, "tokens": 0, "vector": null, "score": 0}, {"text": "memory so let's step into the overall", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 80, "tokens": 0, "vector": null, "score": 0}, {"text": "architecture of mgpt so mgpt is the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 81, "tokens": 0, "vector": null, "score": 0}, {"text": "operating system for rag applications", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 82, "tokens": 0, "vector": null, "score": 0}, {"text": "bridging together memory with tool use", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 83, "tokens": 0, "vector": null, "score": 0}, {"text": "and this particular focus on managing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 84, "tokens": 0, "vector": null, "score": 0}, {"text": "the main context memory so at the heart", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 85, "tokens": 0, "vector": null, "score": 0}, {"text": "of the oper in system we have the large", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 86, "tokens": 0, "vector": null, "score": 0}, {"text": "language model processor then we have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 87, "tokens": 0, "vector": null, "score": 0}, {"text": "the virtual context so the main context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 88, "tokens": 0, "vector": null, "score": 0}, {"text": "is what's currently in the input for the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 89, "tokens": 0, "vector": null, "score": 0}, {"text": "large language model to make its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 90, "tokens": 0, "vector": null, "score": 0}, {"text": "prediction what's in the external", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 91, "tokens": 0, "vector": null, "score": 0}, {"text": "context is say our Vector database or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 92, "tokens": 0, "vector": null, "score": 0}, {"text": "our store of data where we can uh swap", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 93, "tokens": 0, "vector": null, "score": 0}, {"text": "in and out with the main contexts like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 94, "tokens": 0, "vector": null, "score": 0}, {"text": "page replacement and operating systems", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 95, "tokens": 0, "vector": null, "score": 0}, {"text": "to get the relevant context that we need", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 96, "tokens": 0, "vector": null, "score": 0}, {"text": "to complete a certain task so this is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 97, "tokens": 0, "vector": null, "score": 0}, {"text": "the the memory part of it and then the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 98, "tokens": 0, "vector": null, "score": 0}, {"text": "memory is managed with functions and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 99, "tokens": 0, "vector": null, "score": 0}, {"text": "Tool use so tool use is a super exciting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 100, "tokens": 0, "vector": null, "score": 0}, {"text": "idea where we conect Lang language", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 101, "tokens": 0, "vector": null, "score": 0}, {"text": "models to things like say calculators or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 102, "tokens": 0, "vector": null, "score": 0}, {"text": "maybe a weather API if you want to ask", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 103, "tokens": 0, "vector": null, "score": 0}, {"text": "it the question what's the weather in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 104, "tokens": 0, "vector": null, "score": 0}, {"text": "Boston right now it needs to send that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 105, "tokens": 0, "vector": null, "score": 0}, {"text": "external request rather than relying on", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 106, "tokens": 0, "vector": null, "score": 0}, {"text": "the information stored in its parameters", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 107, "tokens": 0, "vector": null, "score": 0}, {"text": "or particularly in the weather API", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 108, "tokens": 0, "vector": null, "score": 0}, {"text": "example it's unlikely that you're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 109, "tokens": 0, "vector": null, "score": 0}, {"text": "keeping your vector database fresh with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 110, "tokens": 0, "vector": null, "score": 0}, {"text": "with that particular information so you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 111, "tokens": 0, "vector": null, "score": 0}, {"text": "probably have these kind of external", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 112, "tokens": 0, "vector": null, "score": 0}, {"text": "services that work into this picture as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 113, "tokens": 0, "vector": null, "score": 0}, {"text": "well but more interestingly are these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 114, "tokens": 0, "vector": null, "score": 0}, {"text": "functions around reading and writing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 115, "tokens": 0, "vector": null, "score": 0}, {"text": "memory so reading memory is where you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 116, "tokens": 0, "vector": null, "score": 0}, {"text": "you know read from the vector database", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 117, "tokens": 0, "vector": null, "score": 0}, {"text": "we say retrieval a search query and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 118, "tokens": 0, "vector": null, "score": 0}, {"text": "there's also ideas around pagination and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 119, "tokens": 0, "vector": null, "score": 0}, {"text": "query rewriting in this mgpc paper but", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 120, "tokens": 0, "vector": null, "score": 0}, {"text": "we'll get to that later but this is the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 121, "tokens": 0, "vector": null, "score": 0}, {"text": "idea of where you read memory to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 122, "tokens": 0, "vector": null, "score": 0}, {"text": "potentially add to the main context by", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 123, "tokens": 0, "vector": null, "score": 0}, {"text": "using these uh operating system", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 124, "tokens": 0, "vector": null, "score": 0}, {"text": "functions like a pen to the working", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 125, "tokens": 0, "vector": null, "score": 0}, {"text": "context we'll get into that later as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 126, "tokens": 0, "vector": null, "score": 0}, {"text": "well but also interestingly we have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 127, "tokens": 0, "vector": null, "score": 0}, {"text": "write memory so as you're having this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 128, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation history as I'm talking to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 129, "tokens": 0, "vector": null, "score": 0}, {"text": "my chat gbt for a long time the mgbt has", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 130, "tokens": 0, "vector": null, "score": 0}, {"text": "these functions around you know Connor", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 131, "tokens": 0, "vector": null, "score": 0}, {"text": "just told me his birthday is October 11", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 132, "tokens": 0, "vector": null, "score": 0}, {"text": "so let me add that to to my uh my", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 133, "tokens": 0, "vector": null, "score": 0}, {"text": "storage then we also have this idea of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 134, "tokens": 0, "vector": null, "score": 0}, {"text": "interrupts and events so events are what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 135, "tokens": 0, "vector": null, "score": 0}, {"text": "triggers mgpt to start doing some", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 136, "tokens": 0, "vector": null, "score": 0}, {"text": "processing so whether this could be as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 137, "tokens": 0, "vector": null, "score": 0}, {"text": "simple as I come to Chad gbt and I say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 138, "tokens": 0, "vector": null, "score": 0}, {"text": "what is rtoc and then that triggers the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 139, "tokens": 0, "vector": null, "score": 0}, {"text": "event that starts all this processing or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 140, "tokens": 0, "vector": null, "score": 0}, {"text": "say I upload a document or say there's a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 141, "tokens": 0, "vector": null, "score": 0}, {"text": "system message like hey your context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 142, "tokens": 0, "vector": null, "score": 0}, {"text": "window is at uh 3,500 tokens let's let's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 143, "tokens": 0, "vector": null, "score": 0}, {"text": "you know start trimming it down or you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 144, "tokens": 0, "vector": null, "score": 0}, {"text": "have things like a timer like every five", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 145, "tokens": 0, "vector": null, "score": 0}, {"text": "minutes maybe it trims down or something", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 146, "tokens": 0, "vector": null, "score": 0}, {"text": "like this so you have this kind of idea", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 147, "tokens": 0, "vector": null, "score": 0}, {"text": "around interrupts from operating systems", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 148, "tokens": 0, "vector": null, "score": 0}, {"text": "where maybe you have some kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 149, "tokens": 0, "vector": null, "score": 0}, {"text": "asynchronous processing like to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 150, "tokens": 0, "vector": null, "score": 0}, {"text": "large language model you say uh research", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 151, "tokens": 0, "vector": null, "score": 0}, {"text": "how selfrag works selfrag is a paper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 152, "tokens": 0, "vector": null, "score": 0}, {"text": "similar to mgbc that came out around the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 153, "tokens": 0, "vector": null, "score": 0}, {"text": "same time so say you're doing that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 154, "tokens": 0, "vector": null, "score": 0}, {"text": "asynchronously while you continue the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 155, "tokens": 0, "vector": null, "score": 0}, {"text": "chat and then it interrupts and says hey", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 156, "tokens": 0, "vector": null, "score": 0}, {"text": "I finished this uh research report", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 157, "tokens": 0, "vector": null, "score": 0}, {"text": "should I work it into the conversation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 158, "tokens": 0, "vector": null, "score": 0}, {"text": "or what should I do with this so this is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 159, "tokens": 0, "vector": null, "score": 0}, {"text": "the general overview of how mgpt works", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 160, "tokens": 0, "vector": null, "score": 0}, {"text": "so I took this quote from I don't know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 161, "tokens": 0, "vector": null, "score": 0}, {"text": "if it's an ex quote but just to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 162, "tokens": 0, "vector": null, "score": 0}, {"text": "reference that I got this from outside", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 163, "tokens": 0, "vector": null, "score": 0}, {"text": "of the paper this was Charles Packer on", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 164, "tokens": 0, "vector": null, "score": 0}, {"text": "the amazing run llm podcast with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 165, "tokens": 0, "vector": null, "score": 0}, {"text": "Professor Joseph Gonzalez and he frames", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 166, "tokens": 0, "vector": null, "score": 0}, {"text": "this idea of mgbt as an agent that knows", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 167, "tokens": 0, "vector": null, "score": 0}, {"text": "how to use memory management tools and I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 168, "tokens": 0, "vector": null, "score": 0}, {"text": "think that's just a perfect way to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 169, "tokens": 0, "vector": null, "score": 0}, {"text": "describe it a super exciting direction", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 170, "tokens": 0, "vector": null, "score": 0}, {"text": "for this whole field of retrieval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 171, "tokens": 0, "vector": null, "score": 0}, {"text": "augmented generation is endowing the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 172, "tokens": 0, "vector": null, "score": 0}, {"text": "large language model with the option to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 173, "tokens": 0, "vector": null, "score": 0}, {"text": "write to the database as well or in this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 174, "tokens": 0, "vector": null, "score": 0}, {"text": "particular case read WR to its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 175, "tokens": 0, "vector": null, "score": 0}, {"text": "particular main context so you've always", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 176, "tokens": 0, "vector": null, "score": 0}, {"text": "had this idea of read from the Save", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 177, "tokens": 0, "vector": null, "score": 0}, {"text": "Vector database and then just kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 178, "tokens": 0, "vector": null, "score": 0}, {"text": "blindly put it into the main context but", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 179, "tokens": 0, "vector": null, "score": 0}, {"text": "now you kind of have this layer in the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 180, "tokens": 0, "vector": null, "score": 0}, {"text": "Middle where you have search results and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 181, "tokens": 0, "vector": null, "score": 0}, {"text": "then you're saying what from the search", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 182, "tokens": 0, "vector": null, "score": 0}, {"text": "results am I going to put into my main", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 183, "tokens": 0, "vector": null, "score": 0}, {"text": "context and then kind of keep there as I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 184, "tokens": 0, "vector": null, "score": 0}, {"text": "continue the conversation so I think", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 185, "tokens": 0, "vector": null, "score": 0}, {"text": "this quote is just so powerful an agent", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 186, "tokens": 0, "vector": null, "score": 0}, {"text": "that knows how to use memory management", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 187, "tokens": 0, "vector": null, "score": 0}, {"text": "tools so the general idea here is that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 188, "tokens": 0, "vector": null, "score": 0}, {"text": "we're building an operating system for", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 189, "tokens": 0, "vector": null, "score": 0}, {"text": "large language models and a quick", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 190, "tokens": 0, "vector": null, "score": 0}, {"text": "question I'd ask the audien is what you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 191, "tokens": 0, "vector": null, "score": 0}, {"text": "think about framing Frameworks like Lang", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 192, "tokens": 0, "vector": null, "score": 0}, {"text": "chain or llama index in this kind of way", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 193, "tokens": 0, "vector": null, "score": 0}, {"text": "is thinking about them as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 194, "tokens": 0, "vector": null, "score": 0}, {"text": "operating systems for large language", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 195, "tokens": 0, "vector": null, "score": 0}, {"text": "models that orchestrate the connection", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 196, "tokens": 0, "vector": null, "score": 0}, {"text": "between language models and tools and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 197, "tokens": 0, "vector": null, "score": 0}, {"text": "Vector databases and memory but so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 198, "tokens": 0, "vector": null, "score": 0}, {"text": "diving a little further Andre karpathy", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 199, "tokens": 0, "vector": null, "score": 0}, {"text": "has also written a really interesting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 200, "tokens": 0, "vector": null, "score": 0}, {"text": "tweet on this kind of llms and operating", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 201, "tokens": 0, "vector": null, "score": 0}, {"text": "systems and this is quite an interesting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 202, "tokens": 0, "vector": null, "score": 0}, {"text": "idea I think of uh taking that next step", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 203, "tokens": 0, "vector": null, "score": 0}, {"text": "in the thinking of not just llms and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 204, "tokens": 0, "vector": null, "score": 0}, {"text": "databases but having a whole operating", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 205, "tokens": 0, "vector": null, "score": 0}, {"text": "system that orchestrates this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 206, "tokens": 0, "vector": null, "score": 0}, {"text": "thing so from Andre karpathy with many", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 207, "tokens": 0, "vector": null, "score": 0}, {"text": "puzzle pieces I assume dropping recently", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 208, "tokens": 0, "vector": null, "score": 0}, {"text": "a more complete picture is emerging of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 209, "tokens": 0, "vector": null, "score": 0}, {"text": "llms not as a chatbot but the kernel", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 210, "tokens": 0, "vector": null, "score": 0}, {"text": "process of a new operating system so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 211, "tokens": 0, "vector": null, "score": 0}, {"text": "what we're seeing in mgbt is the llm is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 212, "tokens": 0, "vector": null, "score": 0}, {"text": "the kernel process that's saying I need", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 213, "tokens": 0, "vector": null, "score": 0}, {"text": "to change my memory I need to use this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 214, "tokens": 0, "vector": null, "score": 0}, {"text": "tool or I need to respond to this event", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 215, "tokens": 0, "vector": null, "score": 0}, {"text": "so it's the kernel and the operating", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 216, "tokens": 0, "vector": null, "score": 0}, {"text": "system that just that is you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 217, "tokens": 0, "vector": null, "score": 0}, {"text": "orchestrating how to manage its memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 218, "tokens": 0, "vector": null, "score": 0}, {"text": "and use tools for example today it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 219, "tokens": 0, "vector": null, "score": 0}, {"text": "orchestrates input and output across", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 220, "tokens": 0, "vector": null, "score": 0}, {"text": "modalities text audio Vision code", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 221, "tokens": 0, "vector": null, "score": 0}, {"text": "interpreter ability to write and run", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 222, "tokens": 0, "vector": null, "score": 0}, {"text": "programs browser internet access or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 223, "tokens": 0, "vector": null, "score": 0}, {"text": "embeddings databases for files and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 224, "tokens": 0, "vector": null, "score": 0}, {"text": "internal memory storage and retrieval so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 225, "tokens": 0, "vector": null, "score": 0}, {"text": "some examples of the different kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 226, "tokens": 0, "vector": null, "score": 0}, {"text": "uh functions it can it can do or memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 227, "tokens": 0, "vector": null, "score": 0}, {"text": "it can access a lot of computing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 228, "tokens": 0, "vector": null, "score": 0}, {"text": "Concepts carry over currently we have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 229, "tokens": 0, "vector": null, "score": 0}, {"text": "single-threaded execution running at 10", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 230, "tokens": 0, "vector": null, "score": 0}, {"text": "Herz tokens per second and enjoy looking", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 231, "tokens": 0, "vector": null, "score": 0}, {"text": "at the assembly level execution traces", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 232, "tokens": 0, "vector": null, "score": 0}, {"text": "stream by Concepts from computer", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 233, "tokens": 0, "vector": null, "score": 0}, {"text": "security carryover with attacks defenses", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 234, "tokens": 0, "vector": null, "score": 0}, {"text": "and emerging vulnerability so that that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 235, "tokens": 0, "vector": null, "score": 0}, {"text": "I think there's just so much information", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 236, "tokens": 0, "vector": null, "score": 0}, {"text": "so much interesting stuff to explore in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 237, "tokens": 0, "vector": null, "score": 0}, {"text": "that in that little text alone this idea", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 238, "tokens": 0, "vector": null, "score": 0}, {"text": "of you know you know we have single", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 239, "tokens": 0, "vector": null, "score": 0}, {"text": "threaded where we just have one llm", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 240, "tokens": 0, "vector": null, "score": 0}, {"text": "process you know where most of I know at", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 241, "tokens": 0, "vector": null, "score": 0}, {"text": "least I'm doing this is logging the llm", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 242, "tokens": 0, "vector": null, "score": 0}, {"text": "in my terminal and just kind of watching", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 243, "tokens": 0, "vector": null, "score": 0}, {"text": "it Go by because you know you're paying", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 244, "tokens": 0, "vector": null, "score": 0}, {"text": "for the tokens but this kind of we SE", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 245, "tokens": 0, "vector": null, "score": 0}, {"text": "things like uh maybe Lang Smith is a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 246, "tokens": 0, "vector": null, "score": 0}, {"text": "good example from Lang chain of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 247, "tokens": 0, "vector": null, "score": 0}, {"text": "visualizing these complex prompt chains", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 248, "tokens": 0, "vector": null, "score": 0}, {"text": "for uh understanding these execution", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 249, "tokens": 0, "vector": null, "score": 0}, {"text": "traces but I think this kind of like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 250, "tokens": 0, "vector": null, "score": 0}, {"text": "parallelism you know if you have like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 251, "tokens": 0, "vector": null, "score": 0}, {"text": "concurrency and llm tasks like again", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 252, "tokens": 0, "vector": null, "score": 0}, {"text": "that example of like uh research self", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 253, "tokens": 0, "vector": null, "score": 0}, {"text": "Rag and then it's doing This research in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 254, "tokens": 0, "vector": null, "score": 0}, {"text": "the background and then it says hey I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 255, "tokens": 0, "vector": null, "score": 0}, {"text": "finished like there's probably just so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 256, "tokens": 0, "vector": null, "score": 0}, {"text": "much opportunity from that and so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 257, "tokens": 0, "vector": null, "score": 0}, {"text": "finishing up I also like the nearest", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 258, "tokens": 0, "vector": null, "score": 0}, {"text": "neighbor analogy of operating system", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 259, "tokens": 0, "vector": null, "score": 0}, {"text": "because the industry is starting to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 260, "tokens": 0, "vector": null, "score": 0}, {"text": "shape up similarly Windows uh OS X and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 261, "tokens": 0, "vector": null, "score": 0}, {"text": "Linux GPT Palm cloud and llama an", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 262, "tokens": 0, "vector": null, "score": 0}, {"text": "operating system comes with default apps", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 263, "tokens": 0, "vector": null, "score": 0}, {"text": "but has an app store you say the chat", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 264, "tokens": 0, "vector": null, "score": 0}, {"text": "gbt Marketplace and kind of how code", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 265, "tokens": 0, "vector": null, "score": 0}, {"text": "interpreter is plugged in with coh here", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 266, "tokens": 0, "vector": null, "score": 0}, {"text": "you have coral and so yeah we're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 267, "tokens": 0, "vector": null, "score": 0}, {"text": "definitely seeing that kind of app store", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 268, "tokens": 0, "vector": null, "score": 0}, {"text": "around the language model and then most", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 269, "tokens": 0, "vector": null, "score": 0}, {"text": "apps can be adapted to multiple", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 270, "tokens": 0, "vector": null, "score": 0}, {"text": "platforms again the API say wv8 generate", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 271, "tokens": 0, "vector": null, "score": 0}, {"text": "module showing how you can also take the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 272, "tokens": 0, "vector": null, "score": 0}, {"text": "the model out of the app store tldr", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 273, "tokens": 0, "vector": null, "score": 0}, {"text": "looking at llms as chat Bots is the same", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 274, "tokens": 0, "vector": null, "score": 0}, {"text": "as looking at early computers as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 275, "tokens": 0, "vector": null, "score": 0}, {"text": "calculators we're seeing an emergence of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 276, "tokens": 0, "vector": null, "score": 0}, {"text": "a whole new Computing Paradigm and it is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 277, "tokens": 0, "vector": null, "score": 0}, {"text": "very early so this is a super exciting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 278, "tokens": 0, "vector": null, "score": 0}, {"text": "tweet in this whole context of uh llms", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 279, "tokens": 0, "vector": null, "score": 0}, {"text": "and operating systems so let's dive into", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 280, "tokens": 0, "vector": null, "score": 0}, {"text": "a little more particularly what makes", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 281, "tokens": 0, "vector": null, "score": 0}, {"text": "the the mgbt and operating system which", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 282, "tokens": 0, "vector": null, "score": 0}, {"text": "is particularly this kind of memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 283, "tokens": 0, "vector": null, "score": 0}, {"text": "management as a large language model", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 284, "tokens": 0, "vector": null, "score": 0}, {"text": "tool so what they're adding in mgbt is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 285, "tokens": 0, "vector": null, "score": 0}, {"text": "the working context append replace these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 286, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of functions so you have this kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 287, "tokens": 0, "vector": null, "score": 0}, {"text": "of conversation where you say hello Chad", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 288, "tokens": 0, "vector": null, "score": 0}, {"text": "welcome I'm excited to embark on this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 289, "tokens": 0, "vector": null, "score": 0}, {"text": "journey with you as a PhD in computer", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 290, "tokens": 0, "vector": null, "score": 0}, {"text": "science blah blah blah and then the user", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 291, "tokens": 0, "vector": null, "score": 0}, {"text": "says you know this information of my", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 292, "tokens": 0, "vector": null, "score": 0}, {"text": "birthday is October 11th and my favorite", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 293, "tokens": 0, "vector": null, "score": 0}, {"text": "cake is this chocolate lava my favorite", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 294, "tokens": 0, "vector": null, "score": 0}, {"text": "cake so this is an example of how it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 295, "tokens": 0, "vector": null, "score": 0}, {"text": "takes the conversation history and it's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 296, "tokens": 0, "vector": null, "score": 0}, {"text": "deciding what is important to put in its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 297, "tokens": 0, "vector": null, "score": 0}, {"text": "context so similarly", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 298, "tokens": 0, "vector": null, "score": 0}, {"text": "uh it might have a system message that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 299, "tokens": 0, "vector": null, "score": 0}, {"text": "says warning the conversation history", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 300, "tokens": 0, "vector": null, "score": 0}, {"text": "will soon reach its maximum length", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 301, "tokens": 0, "vector": null, "score": 0}, {"text": "you're making the language model aware", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 302, "tokens": 0, "vector": null, "score": 0}, {"text": "of its own token limitation say Hey you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 303, "tokens": 0, "vector": null, "score": 0}, {"text": "know you've got 3500 tokens we're going", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 304, "tokens": 0, "vector": null, "score": 0}, {"text": "to need to compress this so then it will", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 305, "tokens": 0, "vector": null, "score": 0}, {"text": "compress it as following it takes the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 306, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation history and it depends this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 307, "tokens": 0, "vector": null, "score": 0}, {"text": "key personality trait enjoys high-speed", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 308, "tokens": 0, "vector": null, "score": 0}, {"text": "Adrenaline Rush activities like Formula", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 309, "tokens": 0, "vector": null, "score": 0}, {"text": "One racing and intense gaming sessions", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 310, "tokens": 0, "vector": null, "score": 0}, {"text": "in csgo so it's doing this to compress", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 311, "tokens": 0, "vector": null, "score": 0}, {"text": "its context window so similarly with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 312, "tokens": 0, "vector": null, "score": 0}, {"text": "search we say search will quickly get", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 313, "tokens": 0, "vector": null, "score": 0}, {"text": "into recall versus archival storage and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 314, "tokens": 0, "vector": null, "score": 0}, {"text": "how they differentiate that in the paper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 315, "tokens": 0, "vector": null, "score": 0}, {"text": "but you're having this conversation what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 316, "tokens": 0, "vector": null, "score": 0}, {"text": "was the artist you mentioned you could", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 317, "tokens": 0, "vector": null, "score": 0}, {"text": "get into so the user is asking about you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 318, "tokens": 0, "vector": null, "score": 0}, {"text": "know conversation history so you're then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 319, "tokens": 0, "vector": null, "score": 0}, {"text": "looking into your you know your external", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 320, "tokens": 0, "vector": null, "score": 0}, {"text": "storage your vector database where you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 321, "tokens": 0, "vector": null, "score": 0}, {"text": "might have two kinds of vector databases", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 322, "tokens": 0, "vector": null, "score": 0}, {"text": "you can have all sorts of kinds of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 323, "tokens": 0, "vector": null, "score": 0}, {"text": "vector databases but for now you have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 324, "tokens": 0, "vector": null, "score": 0}, {"text": "the storage of the event history like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 325, "tokens": 0, "vector": null, "score": 0}, {"text": "all the conversations between you and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 326, "tokens": 0, "vector": null, "score": 0}, {"text": "your chatbot as well as say like general", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 327, "tokens": 0, "vector": null, "score": 0}, {"text": "information like if you're chatting with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 328, "tokens": 0, "vector": null, "score": 0}, {"text": "your docs this is the conversation we've", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 329, "tokens": 0, "vector": null, "score": 0}, {"text": "had these are the docs so two two", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 330, "tokens": 0, "vector": null, "score": 0}, {"text": "databases so say you're searching the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 331, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation history about music from", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 332, "tokens": 0, "vector": null, "score": 0}, {"text": "there it recovers you know you're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 333, "tokens": 0, "vector": null, "score": 0}, {"text": "talking about you like Taylor Swift so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 334, "tokens": 0, "vector": null, "score": 0}, {"text": "it adds that to the working context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 335, "tokens": 0, "vector": null, "score": 0}, {"text": "similarly we also have replace so this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 336, "tokens": 0, "vector": null, "score": 0}, {"text": "is a super exciting idea where you have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 337, "tokens": 0, "vector": null, "score": 0}, {"text": "new information so you used to say you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 338, "tokens": 0, "vector": null, "score": 0}, {"text": "know I was super into horror movies", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 339, "tokens": 0, "vector": null, "score": 0}, {"text": "recommend me horror movies and now your", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 340, "tokens": 0, "vector": null, "score": 0}, {"text": "tastes have evolved and so now you're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 341, "tokens": 0, "vector": null, "score": 0}, {"text": "into romantic comedy so it replaces the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 342, "tokens": 0, "vector": null, "score": 0}, {"text": "in context with I watch horror movies to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 343, "tokens": 0, "vector": null, "score": 0}, {"text": "romantic comedies so I think another", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 344, "tokens": 0, "vector": null, "score": 0}, {"text": "really interesting quot from the paper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 345, "tokens": 0, "vector": null, "score": 0}, {"text": "is to think about this as the the mgbt", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 346, "tokens": 0, "vector": null, "score": 0}, {"text": "is documenting its progress on the task", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 347, "tokens": 0, "vector": null, "score": 0}, {"text": "by writing to its own working memory so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 348, "tokens": 0, "vector": null, "score": 0}, {"text": "it's doing a long task like document", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 349, "tokens": 0, "vector": null, "score": 0}, {"text": "analysis it's only writing to its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 350, "tokens": 0, "vector": null, "score": 0}, {"text": "working memory say important things that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 351, "tokens": 0, "vector": null, "score": 0}, {"text": "it's going to help it further so it's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 352, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of like this idea of distilling The", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 353, "tokens": 0, "vector": null, "score": 0}, {"text": "Core Concepts into you know what's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 354, "tokens": 0, "vector": null, "score": 0}, {"text": "helping you with your research or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 355, "tokens": 0, "vector": null, "score": 0}, {"text": "whatever you're doing so let's dive a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 356, "tokens": 0, "vector": null, "score": 0}, {"text": "little further into types of context so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 357, "tokens": 0, "vector": null, "score": 0}, {"text": "these types of context are the explicit", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 358, "tokens": 0, "vector": null, "score": 0}, {"text": "labels of the parts of the input window", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 359, "tokens": 0, "vector": null, "score": 0}, {"text": "to the large language model and I think", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 360, "tokens": 0, "vector": null, "score": 0}, {"text": "this kind of Separation this explicit", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 361, "tokens": 0, "vector": null, "score": 0}, {"text": "thing of these are the system", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 362, "tokens": 0, "vector": null, "score": 0}, {"text": "instructions this is the conversation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 363, "tokens": 0, "vector": null, "score": 0}, {"text": "history this is the working context I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 364, "tokens": 0, "vector": null, "score": 0}, {"text": "think there's just so much more", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 365, "tokens": 0, "vector": null, "score": 0}, {"text": "opportunity to explore that kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 366, "tokens": 0, "vector": null, "score": 0}, {"text": "separation of the parts of the input", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 367, "tokens": 0, "vector": null, "score": 0}, {"text": "window so say you have kind of this uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 368, "tokens": 0, "vector": null, "score": 0}, {"text": "say you're in these multi-agent", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 369, "tokens": 0, "vector": null, "score": 0}, {"text": "Frameworks like autogen where you have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 370, "tokens": 0, "vector": null, "score": 0}, {"text": "this uh information about your persona", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 371, "tokens": 0, "vector": null, "score": 0}, {"text": "like I am a software engineer I like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 372, "tokens": 0, "vector": null, "score": 0}, {"text": "goang and things like this and then you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 373, "tokens": 0, "vector": null, "score": 0}, {"text": "also have say a highle description of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 374, "tokens": 0, "vector": null, "score": 0}, {"text": "like what you're working on as well as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 375, "tokens": 0, "vector": null, "score": 0}, {"text": "this kind of retrieval context and maybe", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 376, "tokens": 0, "vector": null, "score": 0}, {"text": "more immediate recent conversational", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 377, "tokens": 0, "vector": null, "score": 0}, {"text": "context with the other software", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 378, "tokens": 0, "vector": null, "score": 0}, {"text": "engineers and that multi-agent framework", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 379, "tokens": 0, "vector": null, "score": 0}, {"text": "but this kind of separation of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 380, "tokens": 0, "vector": null, "score": 0}, {"text": "categories of the input window and how", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 381, "tokens": 0, "vector": null, "score": 0}, {"text": "you think about retrieving and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 382, "tokens": 0, "vector": null, "score": 0}, {"text": "augmenting each particular part of it so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 383, "tokens": 0, "vector": null, "score": 0}, {"text": "we start off with system instructions so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 384, "tokens": 0, "vector": null, "score": 0}, {"text": "system instructions you know these are", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 385, "tokens": 0, "vector": null, "score": 0}, {"text": "like the pre- prompt is like you are a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 386, "tokens": 0, "vector": null, "score": 0}, {"text": "helpful assistant but now that you are a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 387, "tokens": 0, "vector": null, "score": 0}, {"text": "helpful assistant thing has been", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 388, "tokens": 0, "vector": null, "score": 0}, {"text": "extended with the the descriptions of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 389, "tokens": 0, "vector": null, "score": 0}, {"text": "the tools that you have access to so in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 390, "tokens": 0, "vector": null, "score": 0}, {"text": "say open AI funks you get this like Json", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 391, "tokens": 0, "vector": null, "score": 0}, {"text": "dictionary that tells you what a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 392, "tokens": 0, "vector": null, "score": 0}, {"text": "function does and how to format the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 393, "tokens": 0, "vector": null, "score": 0}, {"text": "input output Arguments for sending a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 394, "tokens": 0, "vector": null, "score": 0}, {"text": "request to that API so if it says hey", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 395, "tokens": 0, "vector": null, "score": 0}, {"text": "this is a calculator you can use it to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 396, "tokens": 0, "vector": null, "score": 0}, {"text": "add multiply numbers together this would", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 397, "tokens": 0, "vector": null, "score": 0}, {"text": "be how you would uh trigger a request to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 398, "tokens": 0, "vector": null, "score": 0}, {"text": "the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 399, "tokens": 0, "vector": null, "score": 0}, {"text": "calculator the conversational context is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 400, "tokens": 0, "vector": null, "score": 0}, {"text": "then a first in first out cue of recent", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 401, "tokens": 0, "vector": null, "score": 0}, {"text": "event history and then an interesting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 402, "tokens": 0, "vector": null, "score": 0}, {"text": "thing is this recursive summarization so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 403, "tokens": 0, "vector": null, "score": 0}, {"text": "one of in my opinion one of the most", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 404, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting ideas of Lang chain in llama", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 405, "tokens": 0, "vector": null, "score": 0}, {"text": "index has been this idea of uh where you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 406, "tokens": 0, "vector": null, "score": 0}, {"text": "where you have this kind of recursive", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 407, "tokens": 0, "vector": null, "score": 0}, {"text": "summarization so if you have docu you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 408, "tokens": 0, "vector": null, "score": 0}, {"text": "have too many documents that you can fit", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 409, "tokens": 0, "vector": null, "score": 0}, {"text": "into one input window you'll you'll have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 410, "tokens": 0, "vector": null, "score": 0}, {"text": "some kind of prompt like please", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 411, "tokens": 0, "vector": null, "score": 0}, {"text": "summarize the following documents you'll", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 412, "tokens": 0, "vector": null, "score": 0}, {"text": "receive them one at a time as well as a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 413, "tokens": 0, "vector": null, "score": 0}, {"text": "summary so far and then so you keep this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 414, "tokens": 0, "vector": null, "score": 0}, {"text": "local summary and you just keep looping", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 415, "tokens": 0, "vector": null, "score": 0}, {"text": "through the documents updating the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 416, "tokens": 0, "vector": null, "score": 0}, {"text": "summary and so on so you do this to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 417, "tokens": 0, "vector": null, "score": 0}, {"text": "end of the conversation history so say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 418, "tokens": 0, "vector": null, "score": 0}, {"text": "these are my last 10 you know back and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 419, "tokens": 0, "vector": null, "score": 0}, {"text": "forth of the chatbot and these are my", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 420, "tokens": 0, "vector": null, "score": 0}, {"text": "first 200 messages these would be", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 421, "tokens": 0, "vector": null, "score": 0}, {"text": "recursively summarized and just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 422, "tokens": 0, "vector": null, "score": 0}, {"text": "something that can fit in the input and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 423, "tokens": 0, "vector": null, "score": 0}, {"text": "then you have this working context so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 424, "tokens": 0, "vector": null, "score": 0}, {"text": "this working context is where is the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 425, "tokens": 0, "vector": null, "score": 0}, {"text": "memory scratch pad for where the LM", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 426, "tokens": 0, "vector": null, "score": 0}, {"text": "processor is reading say what it's just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 427, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieved and it's looking through the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 428, "tokens": 0, "vector": null, "score": 0}, {"text": "search results and it's saying okay I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 429, "tokens": 0, "vector": null, "score": 0}, {"text": "want to take that and put it in my", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 430, "tokens": 0, "vector": null, "score": 0}, {"text": "working context or you know similarly", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 431, "tokens": 0, "vector": null, "score": 0}, {"text": "looking through its conversational", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 432, "tokens": 0, "vector": null, "score": 0}, {"text": "history so these this is what's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 433, "tokens": 0, "vector": null, "score": 0}, {"text": "currently in the in the memory to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 434, "tokens": 0, "vector": null, "score": 0}, {"text": "language model what's currently in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 435, "tokens": 0, "vector": null, "score": 0}, {"text": "context so then we also have this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 436, "tokens": 0, "vector": null, "score": 0}, {"text": "external storage if we'll you know go", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 437, "tokens": 0, "vector": null, "score": 0}, {"text": "all the way back to our picture of this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 438, "tokens": 0, "vector": null, "score": 0}, {"text": "whole thing we have the main context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 439, "tokens": 0, "vector": null, "score": 0}, {"text": "that's of system instructions", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 440, "tokens": 0, "vector": null, "score": 0}, {"text": "conversational context and then working", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 441, "tokens": 0, "vector": null, "score": 0}, {"text": "memory and then we have our external", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 442, "tokens": 0, "vector": null, "score": 0}, {"text": "context which is where our Vector", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 443, "tokens": 0, "vector": null, "score": 0}, {"text": "database comes into the picture so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 444, "tokens": 0, "vector": null, "score": 0}, {"text": "within external storage the authors are", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 445, "tokens": 0, "vector": null, "score": 0}, {"text": "looking at two different kinds of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 446, "tokens": 0, "vector": null, "score": 0}, {"text": "storage so recall storage this is just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 447, "tokens": 0, "vector": null, "score": 0}, {"text": "like the Raw event log so say it's chat", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 448, "tokens": 0, "vector": null, "score": 0}, {"text": "history or document processing just the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 449, "tokens": 0, "vector": null, "score": 0}, {"text": "raw you know what happened I uploaded", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 450, "tokens": 0, "vector": null, "score": 0}, {"text": "this document I asked you this question", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 451, "tokens": 0, "vector": null, "score": 0}, {"text": "about the document the system ended up", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 452, "tokens": 0, "vector": null, "score": 0}, {"text": "sending this answer so that I then sent", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 453, "tokens": 0, "vector": null, "score": 0}, {"text": "the next question which was this or just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 454, "tokens": 0, "vector": null, "score": 0}, {"text": "the um the archival storage which is the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 455, "tokens": 0, "vector": null, "score": 0}, {"text": "general read right store of say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 456, "tokens": 0, "vector": null, "score": 0}, {"text": "Wikipedia or you know your docs in the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 457, "tokens": 0, "vector": null, "score": 0}, {"text": "chat with docs classic example so these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 458, "tokens": 0, "vector": null, "score": 0}, {"text": "are kind of the two kinds of storage", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 459, "tokens": 0, "vector": null, "score": 0}, {"text": "that we might retrieve from so the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 460, "tokens": 0, "vector": null, "score": 0}, {"text": "authors also present three different", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 461, "tokens": 0, "vector": null, "score": 0}, {"text": "ways of querying these external database", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 462, "tokens": 0, "vector": null, "score": 0}, {"text": "it can be time based where say you just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 463, "tokens": 0, "vector": null, "score": 0}, {"text": "get the most recent events which makes a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 464, "tokens": 0, "vector": null, "score": 0}, {"text": "ton of sense for conversation history", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 465, "tokens": 0, "vector": null, "score": 0}, {"text": "but then say you have information", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 466, "tokens": 0, "vector": null, "score": 0}, {"text": "storages then you have text search and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 467, "tokens": 0, "vector": null, "score": 0}, {"text": "embedding based search so the next key", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 468, "tokens": 0, "vector": null, "score": 0}, {"text": "part to this and this is probably the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 469, "tokens": 0, "vector": null, "score": 0}, {"text": "key part is this self-directed editing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 470, "tokens": 0, "vector": null, "score": 0}, {"text": "and retrieval so again we saw within", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 471, "tokens": 0, "vector": null, "score": 0}, {"text": "that function schema that goes into the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 472, "tokens": 0, "vector": null, "score": 0}, {"text": "system instructions are going to be how", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 473, "tokens": 0, "vector": null, "score": 0}, {"text": "you do this working context out of pen", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 474, "tokens": 0, "vector": null, "score": 0}, {"text": "working context out of replace the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 475, "tokens": 0, "vector": null, "score": 0}, {"text": "functions for how you will take say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 476, "tokens": 0, "vector": null, "score": 0}, {"text": "search results and then you work that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 477, "tokens": 0, "vector": null, "score": 0}, {"text": "into the working context or update the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 478, "tokens": 0, "vector": null, "score": 0}, {"text": "working context so then we have the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 479, "tokens": 0, "vector": null, "score": 0}, {"text": "control flow so events are going to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 480, "tokens": 0, "vector": null, "score": 0}, {"text": "trigger the start of this process so the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 481, "tokens": 0, "vector": null, "score": 0}, {"text": "you know user message system message", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 482, "tokens": 0, "vector": null, "score": 0}, {"text": "user interactions and then we have this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 483, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of function chaining for how we're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 484, "tokens": 0, "vector": null, "score": 0}, {"text": "managing retrieval results which is also", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 485, "tokens": 0, "vector": null, "score": 0}, {"text": "a really interesting uh part of this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 486, "tokens": 0, "vector": null, "score": 0}, {"text": "paper that I think of as marrying mem", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 487, "tokens": 0, "vector": null, "score": 0}, {"text": "gbt with web gbt but with this also kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 488, "tokens": 0, "vector": null, "score": 0}, {"text": "of interesting rephrasing of the query", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 489, "tokens": 0, "vector": null, "score": 0}, {"text": "so with web gbt you had search actions", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 490, "tokens": 0, "vector": null, "score": 0}, {"text": "so you wouldn't just retrieve and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 491, "tokens": 0, "vector": null, "score": 0}, {"text": "just take the top five results and just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 492, "tokens": 0, "vector": null, "score": 0}, {"text": "put those into the into the input you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 493, "tokens": 0, "vector": null, "score": 0}, {"text": "would instead say uh let me see the next", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 494, "tokens": 0, "vector": null, "score": 0}, {"text": "page of search results because you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 495, "tokens": 0, "vector": null, "score": 0}, {"text": "this is how humans use things like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 496, "tokens": 0, "vector": null, "score": 0}, {"text": "Google search as we you know scroll", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 497, "tokens": 0, "vector": null, "score": 0}, {"text": "through the results to try to find the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 498, "tokens": 0, "vector": null, "score": 0}, {"text": "thing that we're looking for so mgbt is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 499, "tokens": 0, "vector": null, "score": 0}, {"text": "also adding this thing where uh in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 500, "tokens": 0, "vector": null, "score": 0}, {"text": "addition it might look through say you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 501, "tokens": 0, "vector": null, "score": 0}, {"text": "know three pages of results and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 502, "tokens": 0, "vector": null, "score": 0}, {"text": "reflect on uh let me actually try a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 503, "tokens": 0, "vector": null, "score": 0}, {"text": "different query this query is not", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 504, "tokens": 0, "vector": null, "score": 0}, {"text": "specific enough and I'm learning that by", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 505, "tokens": 0, "vector": null, "score": 0}, {"text": "looking at the results that come from", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 506, "tokens": 0, "vector": null, "score": 0}, {"text": "this query so that's a pretty", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 507, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting additional layer to this we", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 508, "tokens": 0, "vector": null, "score": 0}, {"text": "say have things like uh query", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 509, "tokens": 0, "vector": null, "score": 0}, {"text": "reformulation where you pass the query", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 510, "tokens": 0, "vector": null, "score": 0}, {"text": "to the large language model and prompt", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 511, "tokens": 0, "vector": null, "score": 0}, {"text": "it like here's a query uh could you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 512, "tokens": 0, "vector": null, "score": 0}, {"text": "please reformulate it to get better", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 513, "tokens": 0, "vector": null, "score": 0}, {"text": "search results when passed to a search", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 514, "tokens": 0, "vector": null, "score": 0}, {"text": "engine and things like this but making", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 515, "tokens": 0, "vector": null, "score": 0}, {"text": "it more meta with this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 516, "tokens": 0, "vector": null, "score": 0}, {"text": "self-correcting where it sends this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 517, "tokens": 0, "vector": null, "score": 0}, {"text": "query sees some results and then learns", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 518, "tokens": 0, "vector": null, "score": 0}, {"text": "from that to reformulate the query so as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 519, "tokens": 0, "vector": null, "score": 0}, {"text": "a quick recap of the core ideas we have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 520, "tokens": 0, "vector": null, "score": 0}, {"text": "the main context that has these explicit", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 521, "tokens": 0, "vector": null, "score": 0}, {"text": "separations of the part of the context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 522, "tokens": 0, "vector": null, "score": 0}, {"text": "from the system instructions to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 523, "tokens": 0, "vector": null, "score": 0}, {"text": "conversational context or the event", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 524, "tokens": 0, "vector": null, "score": 0}, {"text": "history as well as the working context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 525, "tokens": 0, "vector": null, "score": 0}, {"text": "and I think this that part of it is just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 526, "tokens": 0, "vector": null, "score": 0}, {"text": "super exciting the continued exploration", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 527, "tokens": 0, "vector": null, "score": 0}, {"text": "of how we explicitly separate the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 528, "tokens": 0, "vector": null, "score": 0}, {"text": "context especially as we get longer and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 529, "tokens": 0, "vector": null, "score": 0}, {"text": "longer context models then we have the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 530, "tokens": 0, "vector": null, "score": 0}, {"text": "external context which has the recall", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 531, "tokens": 0, "vector": null, "score": 0}, {"text": "storage and archival storage or say two", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 532, "tokens": 0, "vector": null, "score": 0}, {"text": "different ways of thinking about it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 533, "tokens": 0, "vector": null, "score": 0}, {"text": "could be two different classes in a we8", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 534, "tokens": 0, "vector": null, "score": 0}, {"text": "vector database instance but two", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 535, "tokens": 0, "vector": null, "score": 0}, {"text": "different sources to retrieve", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 536, "tokens": 0, "vector": null, "score": 0}, {"text": "information from then we have this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 537, "tokens": 0, "vector": null, "score": 0}, {"text": "self-directed editing which is you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 538, "tokens": 0, "vector": null, "score": 0}, {"text": "how we're augmenting our work in context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 539, "tokens": 0, "vector": null, "score": 0}, {"text": "with things from the event log or say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 540, "tokens": 0, "vector": null, "score": 0}, {"text": "our retrieval and then we also have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 541, "tokens": 0, "vector": null, "score": 0}, {"text": "these search actions through the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 542, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval like paging through search", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 543, "tokens": 0, "vector": null, "score": 0}, {"text": "results or say formulating a new query", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 544, "tokens": 0, "vector": null, "score": 0}, {"text": "then we have this control flow and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 545, "tokens": 0, "vector": null, "score": 0}, {"text": "function chaining understanding that we", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 546, "tokens": 0, "vector": null, "score": 0}, {"text": "have system events that kick off the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 547, "tokens": 0, "vector": null, "score": 0}, {"text": "mgbt process as well as say the function", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 548, "tokens": 0, "vector": null, "score": 0}, {"text": "chaining involved in paging through", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 549, "tokens": 0, "vector": null, "score": 0}, {"text": "search results and reformating the query", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 550, "tokens": 0, "vector": null, "score": 0}, {"text": "so kind of opening up the framework to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 551, "tokens": 0, "vector": null, "score": 0}, {"text": "be extended in the future now let's dive", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 552, "tokens": 0, "vector": null, "score": 0}, {"text": "into sorry now let's dive into some of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 553, "tokens": 0, "vector": null, "score": 0}, {"text": "the experiments in mgbt so they start", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 554, "tokens": 0, "vector": null, "score": 0}, {"text": "off with the the general questions of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 555, "tokens": 0, "vector": null, "score": 0}, {"text": "does mgbt improve consistency and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 556, "tokens": 0, "vector": null, "score": 0}, {"text": "engaging this so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 557, "tokens": 0, "vector": null, "score": 0}, {"text": "consistency does mgbt leverage its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 558, "tokens": 0, "vector": null, "score": 0}, {"text": "memory to improve conversation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 559, "tokens": 0, "vector": null, "score": 0}, {"text": "consistency can it remember relevant", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 560, "tokens": 0, "vector": null, "score": 0}, {"text": "facts preferences and events from past", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 561, "tokens": 0, "vector": null, "score": 0}, {"text": "interactions to main coherence this is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 562, "tokens": 0, "vector": null, "score": 0}, {"text": "the whole idea of you know two months", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 563, "tokens": 0, "vector": null, "score": 0}, {"text": "ago you told chat gbt that uh your", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 564, "tokens": 0, "vector": null, "score": 0}, {"text": "birthday is October 11th and now you're", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 565, "tokens": 0, "vector": null, "score": 0}, {"text": "talking to it later and it's going to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 566, "tokens": 0, "vector": null, "score": 0}, {"text": "remind you of your birthday or things", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 567, "tokens": 0, "vector": null, "score": 0}, {"text": "like this so then engaging this does", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 568, "tokens": 0, "vector": null, "score": 0}, {"text": "mgbc produce more engaging dialogue by", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 569, "tokens": 0, "vector": null, "score": 0}, {"text": "taking advantage of its memory does it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 570, "tokens": 0, "vector": null, "score": 0}, {"text": "spontaneously incorporate long-range", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 571, "tokens": 0, "vector": null, "score": 0}, {"text": "user information to personalize messages", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 572, "tokens": 0, "vector": null, "score": 0}, {"text": "so to evaluate this they use the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 573, "tokens": 0, "vector": null, "score": 0}, {"text": "multi-session chat data set so the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 574, "tokens": 0, "vector": null, "score": 0}, {"text": "multi-session chat data set is generated", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 575, "tokens": 0, "vector": null, "score": 0}, {"text": "by human labelers who they're given a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 576, "tokens": 0, "vector": null, "score": 0}, {"text": "prompt to play a particular Persona and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 577, "tokens": 0, "vector": null, "score": 0}, {"text": "then they have five SE five chat", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 578, "tokens": 0, "vector": null, "score": 0}, {"text": "sessions and each chat session has about", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 579, "tokens": 0, "vector": null, "score": 0}, {"text": "12 messages so this is the data set is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 580, "tokens": 0, "vector": null, "score": 0}, {"text": "you play a role like hey I am into to uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 581, "tokens": 0, "vector": null, "score": 0}, {"text": "gaming and horror movies and things like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 582, "tokens": 0, "vector": null, "score": 0}, {"text": "this and then you chat with another", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 583, "tokens": 0, "vector": null, "score": 0}, {"text": "human who similarly has like a Persona", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 584, "tokens": 0, "vector": null, "score": 0}, {"text": "card so then the data set is augmented", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 585, "tokens": 0, "vector": null, "score": 0}, {"text": "to add a single question answer pair at", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 586, "tokens": 0, "vector": null, "score": 0}, {"text": "the six session that will do some kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 587, "tokens": 0, "vector": null, "score": 0}, {"text": "of long range reference to something", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 588, "tokens": 0, "vector": null, "score": 0}, {"text": "said earlier to see if it was able to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 589, "tokens": 0, "vector": null, "score": 0}, {"text": "use this uh particular way of organizing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 590, "tokens": 0, "vector": null, "score": 0}, {"text": "its memory to recall the particular", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 591, "tokens": 0, "vector": null, "score": 0}, {"text": "thing about who it's speaking with so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 592, "tokens": 0, "vector": null, "score": 0}, {"text": "these are the results of uh jointly", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 593, "tokens": 0, "vector": null, "score": 0}, {"text": "having the Rouge score which is like the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 594, "tokens": 0, "vector": null, "score": 0}, {"text": "some some type of engram overlap I'm not", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 595, "tokens": 0, "vector": null, "score": 0}, {"text": "sure the exact details of but you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 596, "tokens": 0, "vector": null, "score": 0}, {"text": "this kind of engram overlap between that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 597, "tokens": 0, "vector": null, "score": 0}, {"text": "ground truth answer and then what the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 598, "tokens": 0, "vector": null, "score": 0}, {"text": "language model produce as well as this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 599, "tokens": 0, "vector": null, "score": 0}, {"text": "accuracy which is this llm self eval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 600, "tokens": 0, "vector": null, "score": 0}, {"text": "thing where you give gbt for uh the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 601, "tokens": 0, "vector": null, "score": 0}, {"text": "question answer and then the gold answer", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 602, "tokens": 0, "vector": null, "score": 0}, {"text": "and you say you know how was this answer", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 603, "tokens": 0, "vector": null, "score": 0}, {"text": "is it accurate did it f is it close", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 604, "tokens": 0, "vector": null, "score": 0}, {"text": "enough to the uh the gold answer so then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 605, "tokens": 0, "vector": null, "score": 0}, {"text": "another task they tested was", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 606, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation opener so this was about uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 607, "tokens": 0, "vector": null, "score": 0}, {"text": "seeing how well it can open the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 608, "tokens": 0, "vector": null, "score": 0}, {"text": "conversation with something engaging Bas", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 609, "tokens": 0, "vector": null, "score": 0}, {"text": "so this is measuring that engaging this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 610, "tokens": 0, "vector": null, "score": 0}, {"text": "whereas this measures a consistency so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 611, "tokens": 0, "vector": null, "score": 0}, {"text": "this is you know the the it has the gold", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 612, "tokens": 0, "vector": null, "score": 0}, {"text": "Persona of the user and then it has this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 613, "tokens": 0, "vector": null, "score": 0}, {"text": "uh human Baseline of what was said so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 614, "tokens": 0, "vector": null, "score": 0}, {"text": "I'm setting the elsat I want to be an", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 615, "tokens": 0, "vector": null, "score": 0}, {"text": "attorney blah blah blah and then has", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 616, "tokens": 0, "vector": null, "score": 0}, {"text": "this particular preferences around I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 617, "tokens": 0, "vector": null, "score": 0}, {"text": "love coffee and I love tea so then these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 618, "tokens": 0, "vector": null, "score": 0}, {"text": "are three different kinds of responses", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 619, "tokens": 0, "vector": null, "score": 0}, {"text": "from mgbt whether it's using the work in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 620, "tokens": 0, "vector": null, "score": 0}, {"text": "context and the recall storage to say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 621, "tokens": 0, "vector": null, "score": 0}, {"text": "work in the uh the tea and the coffee", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 622, "tokens": 0, "vector": null, "score": 0}, {"text": "thing into the opening response versus", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 623, "tokens": 0, "vector": null, "score": 0}, {"text": "just something generic like you know hey", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 624, "tokens": 0, "vector": null, "score": 0}, {"text": "it's a pleasure to talk to you let's you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 625, "tokens": 0, "vector": null, "score": 0}, {"text": "know let's talk so so using this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 626, "tokens": 0, "vector": null, "score": 0}, {"text": "stuff to have a more engaging opener and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 627, "tokens": 0, "vector": null, "score": 0}, {"text": "and they similarly measure this by", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 628, "tokens": 0, "vector": null, "score": 0}, {"text": "having the similarity in conversation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 629, "tokens": 0, "vector": null, "score": 0}, {"text": "openers between humans and then the mgbt", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 630, "tokens": 0, "vector": null, "score": 0}, {"text": "with these different contexts so here's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 631, "tokens": 0, "vector": null, "score": 0}, {"text": "another Super exciting detail to mgbt is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 632, "tokens": 0, "vector": null, "score": 0}, {"text": "overcoming this lost in the middle", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 633, "tokens": 0, "vector": null, "score": 0}, {"text": "problem so lost in the middle is a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 634, "tokens": 0, "vector": null, "score": 0}, {"text": "famous paper that shows that uh in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 635, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval augmented generation the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 636, "tokens": 0, "vector": null, "score": 0}, {"text": "language model tends to only attend to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 637, "tokens": 0, "vector": null, "score": 0}, {"text": "the first search result or the last", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 638, "tokens": 0, "vector": null, "score": 0}, {"text": "search result so if you have the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 639, "tokens": 0, "vector": null, "score": 0}, {"text": "information you need in the middle so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 640, "tokens": 0, "vector": null, "score": 0}, {"text": "return 10 search results to put in the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 641, "tokens": 0, "vector": null, "score": 0}, {"text": "input and the thing you need is at", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 642, "tokens": 0, "vector": null, "score": 0}, {"text": "position five the language model is not", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 643, "tokens": 0, "vector": null, "score": 0}, {"text": "really able to parse the search results", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 644, "tokens": 0, "vector": null, "score": 0}, {"text": "and find it in position five so because", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 645, "tokens": 0, "vector": null, "score": 0}, {"text": "mgbt does this kind of paging of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 646, "tokens": 0, "vector": null, "score": 0}, {"text": "search results and only adding relevant", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 647, "tokens": 0, "vector": null, "score": 0}, {"text": "information back to its working memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 648, "tokens": 0, "vector": null, "score": 0}, {"text": "you have this kind of flat line of it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 649, "tokens": 0, "vector": null, "score": 0}, {"text": "doesn't matter how many documents you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 650, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieve it's going to have the same", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 651, "tokens": 0, "vector": null, "score": 0}, {"text": "performance because it's parsing through", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 652, "tokens": 0, "vector": null, "score": 0}, {"text": "the search results to add it to its", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 653, "tokens": 0, "vector": null, "score": 0}, {"text": "working memory and they also introduced", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 654, "tokens": 0, "vector": null, "score": 0}, {"text": "this new task of nested key value", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 655, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval so in Lost in the middle uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 656, "tokens": 0, "vector": null, "score": 0}, {"text": "one of the tasks is you have key value", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 657, "tokens": 0, "vector": null, "score": 0}, {"text": "dictionaries so it's like U ID key u ID", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 658, "tokens": 0, "vector": null, "score": 0}, {"text": "value and it would say like what's the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 659, "tokens": 0, "vector": null, "score": 0}, {"text": "value for", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 660, "tokens": 0, "vector": null, "score": 0}, {"text": "94071 FF right and so then it has to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 661, "tokens": 0, "vector": null, "score": 0}, {"text": "look up the value so now you're kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 662, "tokens": 0, "vector": null, "score": 0}, {"text": "doing this chaining where it's storing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 663, "tokens": 0, "vector": null, "score": 0}, {"text": "the the nested values and so it's it's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 664, "tokens": 0, "vector": null, "score": 0}, {"text": "testing this multi-hop question", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 665, "tokens": 0, "vector": null, "score": 0}, {"text": "answering where you're the you know the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 666, "tokens": 0, "vector": null, "score": 0}, {"text": "intuition what it would eventually be", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 667, "tokens": 0, "vector": null, "score": 0}, {"text": "used for is you have questions like did", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 668, "tokens": 0, "vector": null, "score": 0}, {"text": "Aristotle use a laptop you break that up", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 669, "tokens": 0, "vector": null, "score": 0}, {"text": "into when did Aristotle live when were", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 670, "tokens": 0, "vector": null, "score": 0}, {"text": "laptops invented answer each separately", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 671, "tokens": 0, "vector": null, "score": 0}, {"text": "and then merge it together so this is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 672, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of testing that ability to merge", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 673, "tokens": 0, "vector": null, "score": 0}, {"text": "together facts awesome so that's a recap", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 674, "tokens": 0, "vector": null, "score": 0}, {"text": "of the core ideas of mgbt and some of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 675, "tokens": 0, "vector": null, "score": 0}, {"text": "the experiments in the paper now let's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 676, "tokens": 0, "vector": null, "score": 0}, {"text": "dive into some of the future work", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 677, "tokens": 0, "vector": null, "score": 0}, {"text": "directions outlined in the paper as well", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 678, "tokens": 0, "vector": null, "score": 0}, {"text": "as some of my personal takeaways and how", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 679, "tokens": 0, "vector": null, "score": 0}, {"text": "I think mgbt will impact the entire", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 680, "tokens": 0, "vector": null, "score": 0}, {"text": "space of retrieval augmented generation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 681, "tokens": 0, "vector": null, "score": 0}, {"text": "so starting off the authors mention", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 682, "tokens": 0, "vector": null, "score": 0}, {"text": "applying mgbt to other domains with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 683, "tokens": 0, "vector": null, "score": 0}, {"text": "massive or unbounded context they", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 684, "tokens": 0, "vector": null, "score": 0}, {"text": "explore using mgpt for chat Bots as as", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 685, "tokens": 0, "vector": null, "score": 0}, {"text": "well as document analysis in this case", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 686, "tokens": 0, "vector": null, "score": 0}, {"text": "reproducing the natural questions", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 687, "tokens": 0, "vector": null, "score": 0}, {"text": "experiment from Lost in the- middle and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 688, "tokens": 0, "vector": null, "score": 0}, {"text": "showing how mgpc can help with that they", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 689, "tokens": 0, "vector": null, "score": 0}, {"text": "also discuss integrating different", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 690, "tokens": 0, "vector": null, "score": 0}, {"text": "memory tier Technologies like databases", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 691, "tokens": 0, "vector": null, "score": 0}, {"text": "or caches I think that is a super", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 692, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting one where you have different", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 693, "tokens": 0, "vector": null, "score": 0}, {"text": "kinds of memories and you have different", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 694, "tokens": 0, "vector": null, "score": 0}, {"text": "latencies for the different types of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 695, "tokens": 0, "vector": null, "score": 0}, {"text": "memory and so that is a super", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 696, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting topic then further improving", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 697, "tokens": 0, "vector": null, "score": 0}, {"text": "control flow and memory management", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 698, "tokens": 0, "vector": null, "score": 0}, {"text": "policies just I think just further", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 699, "tokens": 0, "vector": null, "score": 0}, {"text": "understanding the action space and how", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 700, "tokens": 0, "vector": null, "score": 0}, {"text": "to describe the tool of me of memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 701, "tokens": 0, "vector": null, "score": 0}, {"text": "managing your memory to the llm and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 702, "tokens": 0, "vector": null, "score": 0}, {"text": "fine-tuning an open source model for M", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 703, "tokens": 0, "vector": null, "score": 0}, {"text": "GPT tool use so in the experiments", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 704, "tokens": 0, "vector": null, "score": 0}, {"text": "they're prompting mostly gbt 4 gbt 3.5", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 705, "tokens": 0, "vector": null, "score": 0}, {"text": "to do this what would it take to get", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 706, "tokens": 0, "vector": null, "score": 0}, {"text": "llama 2 to achieve the same kind of tool", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 707, "tokens": 0, "vector": null, "score": 0}, {"text": "following for uh memory management so I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 708, "tokens": 0, "vector": null, "score": 0}, {"text": "want to kind of outline that a little", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 709, "tokens": 0, "vector": null, "score": 0}, {"text": "more because I think that's a pretty", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 710, "tokens": 0, "vector": null, "score": 0}, {"text": "exciting future Direction so we", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 711, "tokens": 0, "vector": null, "score": 0}, {"text": "generally are looking at this idea where", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 712, "tokens": 0, "vector": null, "score": 0}, {"text": "we're using gbt 4 to create training", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 713, "tokens": 0, "vector": null, "score": 0}, {"text": "data then we use knowledge distillation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 714, "tokens": 0, "vector": null, "score": 0}, {"text": "to train a smaller model on the labeled", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 715, "tokens": 0, "vector": null, "score": 0}, {"text": "example from gbt 4 and this way you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 716, "tokens": 0, "vector": null, "score": 0}, {"text": "compress it into the smaller models or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 717, "tokens": 0, "vector": null, "score": 0}, {"text": "say the open source models so this is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 718, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of you know we're there are all", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 719, "tokens": 0, "vector": null, "score": 0}, {"text": "sorts of tasks that you can kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 720, "tokens": 0, "vector": null, "score": 0}, {"text": "compress this way and I think that's one", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 721, "tokens": 0, "vector": null, "score": 0}, {"text": "of the most exciting directions for the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 722, "tokens": 0, "vector": null, "score": 0}, {"text": "field right now is we're using language", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 723, "tokens": 0, "vector": null, "score": 0}, {"text": "models for all sorts of things whenever", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 724, "tokens": 0, "vector": null, "score": 0}, {"text": "you have a prompt for something you have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 725, "tokens": 0, "vector": null, "score": 0}, {"text": "a task that you could then generate", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 726, "tokens": 0, "vector": null, "score": 0}, {"text": "labeled examples with GPT 4 and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 727, "tokens": 0, "vector": null, "score": 0}, {"text": "compress it down into a model into say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 728, "tokens": 0, "vector": null, "score": 0}, {"text": "llama 2 with the 7 billion parameters", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 729, "tokens": 0, "vector": null, "score": 0}, {"text": "it's going to be cheaper to serve and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 730, "tokens": 0, "vector": null, "score": 0}, {"text": "you know you run it well it's it's still", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 731, "tokens": 0, "vector": null, "score": 0}, {"text": "in the air if that's going to be cheaper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 732, "tokens": 0, "vector": null, "score": 0}, {"text": "to serve because you know open AI they", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 733, "tokens": 0, "vector": null, "score": 0}, {"text": "they have all sorts of you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 734, "tokens": 0, "vector": null, "score": 0}, {"text": "infrastructure behind how they serve", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 735, "tokens": 0, "vector": null, "score": 0}, {"text": "their API so it's interesting still", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 736, "tokens": 0, "vector": null, "score": 0}, {"text": "exactly the cost difference between you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 737, "tokens": 0, "vector": null, "score": 0}, {"text": "serving your llama 27b compared to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 738, "tokens": 0, "vector": null, "score": 0}, {"text": "gbt uh 4 3.5 turbo all these kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 739, "tokens": 0, "vector": null, "score": 0}, {"text": "stuff so there's also kind of the idea", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 740, "tokens": 0, "vector": null, "score": 0}, {"text": "that say F 1.5 billion parameter that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 741, "tokens": 0, "vector": null, "score": 0}, {"text": "textbooks are all you need paper there's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 742, "tokens": 0, "vector": null, "score": 0}, {"text": "this idea of you can maybe keep going", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 743, "tokens": 0, "vector": null, "score": 0}, {"text": "and keep compressing it and if we get to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 744, "tokens": 0, "vector": null, "score": 0}, {"text": "the point of say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 745, "tokens": 0, "vector": null, "score": 0}, {"text": "you only need a 300 million parameter", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 746, "tokens": 0, "vector": null, "score": 0}, {"text": "transformer for your task and say neural", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 747, "tokens": 0, "vector": null, "score": 0}, {"text": "magic is exploring uh like sparsifying", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 748, "tokens": 0, "vector": null, "score": 0}, {"text": "these models to run them on CPUs so that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 749, "tokens": 0, "vector": null, "score": 0}, {"text": "could be really interesting in terms of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 750, "tokens": 0, "vector": null, "score": 0}, {"text": "just you know the cost of running these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 751, "tokens": 0, "vector": null, "score": 0}, {"text": "inference and if llm inference cost gets", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 752, "tokens": 0, "vector": null, "score": 0}, {"text": "super fast and super cheap that unlocks", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 753, "tokens": 0, "vector": null, "score": 0}, {"text": "all sorts of kind of new use cases so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 754, "tokens": 0, "vector": null, "score": 0}, {"text": "here are some of my personal takeaways", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 755, "tokens": 0, "vector": null, "score": 0}, {"text": "from this so firstly for me it was", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 756, "tokens": 0, "vector": null, "score": 0}, {"text": "really interesting to see this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 757, "tokens": 0, "vector": null, "score": 0}, {"text": "explicit uh when to active retrieval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 758, "tokens": 0, "vector": null, "score": 0}, {"text": "thing and compare that with Flare which", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 759, "tokens": 0, "vector": null, "score": 0}, {"text": "is the active retrieval augment to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 760, "tokens": 0, "vector": null, "score": 0}, {"text": "generation technique so with Flare what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 761, "tokens": 0, "vector": null, "score": 0}, {"text": "you do is you're sampling the next", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 762, "tokens": 0, "vector": null, "score": 0}, {"text": "sentence and you multiply out the log", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 763, "tokens": 0, "vector": null, "score": 0}, {"text": "probabilities of the tokens for that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 764, "tokens": 0, "vector": null, "score": 0}, {"text": "next sentence if that's below a certain", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 765, "tokens": 0, "vector": null, "score": 0}, {"text": "threshold you'll do another retrieval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 766, "tokens": 0, "vector": null, "score": 0}, {"text": "because it's saying that basically that", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 767, "tokens": 0, "vector": null, "score": 0}, {"text": "next sentence it wasn't grounded in", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 768, "tokens": 0, "vector": null, "score": 0}, {"text": "facts you need to retrieve more", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 769, "tokens": 0, "vector": null, "score": 0}, {"text": "information to help have a better next", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 770, "tokens": 0, "vector": null, "score": 0}, {"text": "uh sentence generated compared to this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 771, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of M GPT where you have this like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 772, "tokens": 0, "vector": null, "score": 0}, {"text": "explicit you know I I don't know what I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 773, "tokens": 0, "vector": null, "score": 0}, {"text": "I don't have what I need to write this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 774, "tokens": 0, "vector": null, "score": 0}, {"text": "next sentence so let me go retrieve and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 775, "tokens": 0, "vector": null, "score": 0}, {"text": "update my working context and so this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 776, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of whether you just want to decode", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 777, "tokens": 0, "vector": null, "score": 0}, {"text": "it from the probabilities of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 778, "tokens": 0, "vector": null, "score": 0}, {"text": "language models or you want to have this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 779, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of memory management active", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 780, "tokens": 0, "vector": null, "score": 0}, {"text": "retrieval as an explicit tool that it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 781, "tokens": 0, "vector": null, "score": 0}, {"text": "you know calls with functions the next", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 782, "tokens": 0, "vector": null, "score": 0}, {"text": "big thing and something that they talk", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 783, "tokens": 0, "vector": null, "score": 0}, {"text": "about in the paper as well is kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 784, "tokens": 0, "vector": null, "score": 0}, {"text": "this latency of mgbt if every time you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 785, "tokens": 0, "vector": null, "score": 0}, {"text": "chat with your uh you know your chat", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 786, "tokens": 0, "vector": null, "score": 0}, {"text": "body it has to do all these steps then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 787, "tokens": 0, "vector": null, "score": 0}, {"text": "that's going to be really slow and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 788, "tokens": 0, "vector": null, "score": 0}, {"text": "that'll be problem so there' probably be", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 789, "tokens": 0, "vector": null, "score": 0}, {"text": "like a a layer on top of this where it's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 790, "tokens": 0, "vector": null, "score": 0}, {"text": "like kind of a quick answer compared to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 791, "tokens": 0, "vector": null, "score": 0}, {"text": "this whole like operating system thing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 792, "tokens": 0, "vector": null, "score": 0}, {"text": "and that's kind of related also to the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 793, "tokens": 0, "vector": null, "score": 0}, {"text": "you know the compressing the model and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 794, "tokens": 0, "vector": null, "score": 0}, {"text": "trying to make all this run faster the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 795, "tokens": 0, "vector": null, "score": 0}, {"text": "third point for me that I think is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 796, "tokens": 0, "vector": null, "score": 0}, {"text": "really interesting is the difference", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 797, "tokens": 0, "vector": null, "score": 0}, {"text": "between this kind of uh web result", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 798, "tokens": 0, "vector": null, "score": 0}, {"text": "paging or reranking so similar to web", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 799, "tokens": 0, "vector": null, "score": 0}, {"text": "gbt mgbt is going to like scroll through", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 800, "tokens": 0, "vector": null, "score": 0}, {"text": "search results and so I'm curious what", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 801, "tokens": 0, "vector": null, "score": 0}, {"text": "people generally think about this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 802, "tokens": 0, "vector": null, "score": 0}, {"text": "difference between like next page", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 803, "tokens": 0, "vector": null, "score": 0}, {"text": "previous page actions compared to just", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 804, "tokens": 0, "vector": null, "score": 0}, {"text": "applying a reranking model which is a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 805, "tokens": 0, "vector": null, "score": 0}, {"text": "high-capacity model that generally takes", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 806, "tokens": 0, "vector": null, "score": 0}, {"text": "in the query in each document and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 807, "tokens": 0, "vector": null, "score": 0}, {"text": "gives it a higher capacity ranking score", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 808, "tokens": 0, "vector": null, "score": 0}, {"text": "like matching score and then Resorts the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 809, "tokens": 0, "vector": null, "score": 0}, {"text": "list from say the course grain retrieval", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 810, "tokens": 0, "vector": null, "score": 0}, {"text": "or we're now seeing these kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 811, "tokens": 0, "vector": null, "score": 0}, {"text": "ranking models that would take in like", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 812, "tokens": 0, "vector": null, "score": 0}, {"text": "you know 10 documents as input and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 813, "tokens": 0, "vector": null, "score": 0}, {"text": "rerank them by kind of looking across", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 814, "tokens": 0, "vector": null, "score": 0}, {"text": "the documents in addition to just a sort", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 815, "tokens": 0, "vector": null, "score": 0}, {"text": "of query and one candidate document at a", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 816, "tokens": 0, "vector": null, "score": 0}, {"text": "time kind of setup so a lot of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 817, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting things happen with ranking", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 818, "tokens": 0, "vector": null, "score": 0}, {"text": "and it makes me I'm not sure I'm super", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 819, "tokens": 0, "vector": null, "score": 0}, {"text": "bullish on this kind of paging concept", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 820, "tokens": 0, "vector": null, "score": 0}, {"text": "because I think reranking is already", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 821, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of you know know the the better", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 822, "tokens": 0, "vector": null, "score": 0}, {"text": "version of that so uh then in the paper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 823, "tokens": 0, "vector": null, "score": 0}, {"text": "they also have these kind of um", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 824, "tokens": 0, "vector": null, "score": 0}, {"text": "perspectives on training longer context", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 825, "tokens": 0, "vector": null, "score": 0}, {"text": "models sort of framing that the purpose", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 826, "tokens": 0, "vector": null, "score": 0}, {"text": "of this uh paper is is hey we're you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 827, "tokens": 0, "vector": null, "score": 0}, {"text": "know we're never going to get models", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 828, "tokens": 0, "vector": null, "score": 0}, {"text": "that can uh process like a 100,000", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 829, "tokens": 0, "vector": null, "score": 0}, {"text": "tokens so we're going to need these kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 830, "tokens": 0, "vector": null, "score": 0}, {"text": "of memory management techniques and so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 831, "tokens": 0, "vector": null, "score": 0}, {"text": "what I've kind of learned about this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 832, "tokens": 0, "vector": null, "score": 0}, {"text": "especially in the weeva podcast with", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 833, "tokens": 0, "vector": null, "score": 0}, {"text": "ofier press is that it's not just kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 834, "tokens": 0, "vector": null, "score": 0}, {"text": "of the quadratic attention you can kind", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 835, "tokens": 0, "vector": null, "score": 0}, {"text": "of have like gradient checkpointing and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 836, "tokens": 0, "vector": null, "score": 0}, {"text": "things like Alibi attention to get", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 837, "tokens": 0, "vector": null, "score": 0}, {"text": "around sort of the computational", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 838, "tokens": 0, "vector": null, "score": 0}, {"text": "complexity behind uh scaling the input", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 839, "tokens": 0, "vector": null, "score": 0}, {"text": "length the real problem is sort of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 840, "tokens": 0, "vector": null, "score": 0}, {"text": "uh training data and there's not a lot", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 841, "tokens": 0, "vector": null, "score": 0}, {"text": "of good um training data that's", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 842, "tokens": 0, "vector": null, "score": 0}, {"text": "naturally like 100,000 context length so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 843, "tokens": 0, "vector": null, "score": 0}, {"text": "that's more so the interesting thing is", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 844, "tokens": 0, "vector": null, "score": 0}, {"text": "where do you get this data from so I've", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 845, "tokens": 0, "vector": null, "score": 0}, {"text": "had these really interesting", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 846, "tokens": 0, "vector": null, "score": 0}, {"text": "conversations with Owen kgve who's the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 847, "tokens": 0, "vector": null, "score": 0}, {"text": "founder of sci-fi and so this will be", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 848, "tokens": 0, "vector": null, "score": 0}, {"text": "linked in the description it's a GitHub", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 849, "tokens": 0, "vector": null, "score": 0}, {"text": "project where you're creating synthetic", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 850, "tokens": 0, "vector": null, "score": 0}, {"text": "textbooks and I think this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 851, "tokens": 0, "vector": null, "score": 0}, {"text": "synthetic data it could be the answer to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 852, "tokens": 0, "vector": null, "score": 0}, {"text": "how do we create the training data for", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 853, "tokens": 0, "vector": null, "score": 0}, {"text": "these super long context models so some", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 854, "tokens": 0, "vector": null, "score": 0}, {"text": "other takeaways is I think this kind of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 855, "tokens": 0, "vector": null, "score": 0}, {"text": "parallel asynchronous concurrent", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 856, "tokens": 0, "vector": null, "score": 0}, {"text": "processing is going to be a super", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 857, "tokens": 0, "vector": null, "score": 0}, {"text": "interesting direction for the evolution", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 858, "tokens": 0, "vector": null, "score": 0}, {"text": "of this so you know say you're having", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 859, "tokens": 0, "vector": null, "score": 0}, {"text": "this conversation and you we talking", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 860, "tokens": 0, "vector": null, "score": 0}, {"text": "about mgbt and you also want to kick off", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 861, "tokens": 0, "vector": null, "score": 0}, {"text": "this research on how does self rag", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 862, "tokens": 0, "vector": null, "score": 0}, {"text": "manage rag selfrag is like another paper", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 863, "tokens": 0, "vector": null, "score": 0}, {"text": "that came out it's like this is like the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 864, "tokens": 0, "vector": null, "score": 0}, {"text": "dog food as I'm doing this I'm thinking", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 865, "tokens": 0, "vector": null, "score": 0}, {"text": "it would be interesting if I could also", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 866, "tokens": 0, "vector": null, "score": 0}, {"text": "have a knowledge of that paper so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 867, "tokens": 0, "vector": null, "score": 0}, {"text": "imagining it's kicking off that async", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 868, "tokens": 0, "vector": null, "score": 0}, {"text": "research task and then interrupt he", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 869, "tokens": 0, "vector": null, "score": 0}, {"text": "finished the report or I've written it", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 870, "tokens": 0, "vector": null, "score": 0}, {"text": "to the database all these kinds of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 871, "tokens": 0, "vector": null, "score": 0}, {"text": "things so then actually let me come back", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 872, "tokens": 0, "vector": null, "score": 0}, {"text": "to the gorilla thing but so seven would", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 873, "tokens": 0, "vector": null, "score": 0}, {"text": "be uh this idea of the use of databases", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 874, "tokens": 0, "vector": null, "score": 0}, {"text": "in caches so a really interesting thing", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 875, "tokens": 0, "vector": null, "score": 0}, {"text": "and I you know I'm not an expert on this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 876, "tokens": 0, "vector": null, "score": 0}, {"text": "but I learned so much from listening to", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 877, "tokens": 0, "vector": null, "score": 0}, {"text": "uh Eddie and present how multi-tenancy", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 878, "tokens": 0, "vector": null, "score": 0}, {"text": "was architected in we8 at the AI", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 879, "tokens": 0, "vector": null, "score": 0}, {"text": "conference and some future directions", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 880, "tokens": 0, "vector": null, "score": 0}, {"text": "like you you have all these kinds of U", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 881, "tokens": 0, "vector": null, "score": 0}, {"text": "memory with computers right you have", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 882, "tokens": 0, "vector": null, "score": 0}, {"text": "like the memory cache you have like L1", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 883, "tokens": 0, "vector": null, "score": 0}, {"text": "L2 and then you have like RAM and then", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 884, "tokens": 0, "vector": null, "score": 0}, {"text": "you have ssds you know hard disk and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 885, "tokens": 0, "vector": null, "score": 0}, {"text": "then you maybe have like cold cloud", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 886, "tokens": 0, "vector": null, "score": 0}, {"text": "storage so there's like all these", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 887, "tokens": 0, "vector": null, "score": 0}, {"text": "different kinds of ways of having memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 888, "tokens": 0, "vector": null, "score": 0}, {"text": "and maybe the llm operating system can", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 889, "tokens": 0, "vector": null, "score": 0}, {"text": "more intelligently kind of cache memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 890, "tokens": 0, "vector": null, "score": 0}, {"text": "and use like the physical storage so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 891, "tokens": 0, "vector": null, "score": 0}, {"text": "it's definitely not something I'm an", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 892, "tokens": 0, "vector": null, "score": 0}, {"text": "expert on but it it definitely I can see", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 893, "tokens": 0, "vector": null, "score": 0}, {"text": "kind of you know how that could be an", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 894, "tokens": 0, "vector": null, "score": 0}, {"text": "opportunity so then let's talk about", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 895, "tokens": 0, "vector": null, "score": 0}, {"text": "gorilla and so shashir Patel is one of", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 896, "tokens": 0, "vector": null, "score": 0}, {"text": "the authors of this paper this comes", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 897, "tokens": 0, "vector": null, "score": 0}, {"text": "from the same lab as the gorilla llm so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 898, "tokens": 0, "vector": null, "score": 0}, {"text": "that's kind of what drew me to this", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 899, "tokens": 0, "vector": null, "score": 0}, {"text": "curious to see if there was a connection", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 900, "tokens": 0, "vector": null, "score": 0}, {"text": "with the gorilla llm so I think the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 901, "tokens": 0, "vector": null, "score": 0}, {"text": "angle here is allocating as few tokens", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 902, "tokens": 0, "vector": null, "score": 0}, {"text": "as possible with the gorillas so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 903, "tokens": 0, "vector": null, "score": 0}, {"text": "thinking about mgbt and Guerilla the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 904, "tokens": 0, "vector": null, "score": 0}, {"text": "idea is to describe the tool in as few", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 905, "tokens": 0, "vector": null, "score": 0}, {"text": "tokens as possible because the whole", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 906, "tokens": 0, "vector": null, "score": 0}, {"text": "idea of this is you know we need to be", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 907, "tokens": 0, "vector": null, "score": 0}, {"text": "efficient with our token allocation", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 908, "tokens": 0, "vector": null, "score": 0}, {"text": "similar to lead to like memory", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 909, "tokens": 0, "vector": null, "score": 0}, {"text": "allocation is token allocation so if we", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 910, "tokens": 0, "vector": null, "score": 0}, {"text": "can just describe our tools like you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 911, "tokens": 0, "vector": null, "score": 0}, {"text": "know in the case of the we8 gorilla you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 912, "tokens": 0, "vector": null, "score": 0}, {"text": "have access to a vector database API you", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 913, "tokens": 0, "vector": null, "score": 0}, {"text": "can perform different kinds of searches", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 914, "tokens": 0, "vector": null, "score": 0}, {"text": "such as bm25 vector or hybrid you can", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 915, "tokens": 0, "vector": null, "score": 0}, {"text": "add reranking or you can add filters so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 916, "tokens": 0, "vector": null, "score": 0}, {"text": "you just have this succinct natural", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 917, "tokens": 0, "vector": null, "score": 0}, {"text": "language description then it can do the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 918, "tokens": 0, "vector": null, "score": 0}, {"text": "natural language instruction of the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 919, "tokens": 0, "vector": null, "score": 0}, {"text": "search it wants to execute with you know", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 920, "tokens": 0, "vector": null, "score": 0}, {"text": "more sophisticated searches rather than", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 921, "tokens": 0, "vector": null, "score": 0}, {"text": "just uh search music right you can use", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 922, "tokens": 0, "vector": null, "score": 0}, {"text": "all the apis of we v8's graphql API and", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 923, "tokens": 0, "vector": null, "score": 0}, {"text": "then it can translate this natural", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 924, "tokens": 0, "vector": null, "score": 0}, {"text": "language instruction into the graphql", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 925, "tokens": 0, "vector": null, "score": 0}, {"text": "with the gorilla under the hood so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 926, "tokens": 0, "vector": null, "score": 0}, {"text": "multiple language models also in the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 927, "tokens": 0, "vector": null, "score": 0}, {"text": "intermediate say the parser step let say", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 928, "tokens": 0, "vector": null, "score": 0}, {"text": "in this parser step you have another uh", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 929, "tokens": 0, "vector": null, "score": 0}, {"text": "language model a gorilla that is H", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 930, "tokens": 0, "vector": null, "score": 0}, {"text": "formulating the tool requests into the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 931, "tokens": 0, "vector": null, "score": 0}, {"text": "particular API so thank you so much for", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 932, "tokens": 0, "vector": null, "score": 0}, {"text": "watching this explanation of mgpt I", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 933, "tokens": 0, "vector": null, "score": 0}, {"text": "really hope you enjoyed it I'd be more", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 934, "tokens": 0, "vector": null, "score": 0}, {"text": "than happy to answer any questions or", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 935, "tokens": 0, "vector": null, "score": 0}, {"text": "discuss any ideas you had about the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 936, "tokens": 0, "vector": null, "score": 0}, {"text": "content you know explored in this video", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 937, "tokens": 0, "vector": null, "score": 0}, {"text": "if you want to connect with me", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 938, "tokens": 0, "vector": null, "score": 0}, {"text": "personally I prefer to manage", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 939, "tokens": 0, "vector": null, "score": 0}, {"text": "Communications on X at C30 if you want", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 940, "tokens": 0, "vector": null, "score": 0}, {"text": "to learn more about wv8 you can check", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 941, "tokens": 0, "vector": null, "score": 0}, {"text": "out we8 iio or if you want to join the", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 942, "tokens": 0, "vector": null, "score": 0}, {"text": "WEA community on slack so thank you so", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 943, "tokens": 0, "vector": null, "score": 0}, {"text": "much for watching and I hope you found", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 944, "tokens": 0, "vector": null, "score": 0}, {"text": "this useful", "doc_name": "MemGPT Explained!", "doc_type": "Video", "doc_uuid": "", "chunk_id": 945, "tokens": 0, "vector": null, "score": 0}]}