{"text": "Thank you so much for watching the 43rd episode of the Weaviate Podcast with Roman Grebennikov and Vesvolod Goloviznin ... \nhey everyone thank you so much forwatching another episode of the weviapodcast I'm super excited about thisepisode we're welcoming Erica Cardenasfor the first time on the wevia podcastErica has recently been accepted tospeak at Haystack us 2023 about we v8'sref and recommendation and all theseexciting topics so Erica firstly thankyou so much for joining the podcastthank you for having meand we're I'm also super super excitedto welcome Siva and Roman from meta rankmeta rank is a super exciting uh rankingsoftware and the watch their Haystacktalk as well and there's so manyexciting topics that I'm just so excitedto get into I think this will be just anawesome search and recommendation uhpodcast and that kind of topic soum maybe it kick things off Erica couldyou maybe talk a bit about kind of likethe weevier perspective onrecommendation and ref to back and kindof like sort of like where we're comingfrom in this topic yeah of course umyeah so we really struck to back um afew releases priorum so what this does is it really workswell with recommendationum so what it does is it's factorizingthe user along with its interactionswith products or moviesum so but it why it's called raft effectcentroid is because it's taking theaverage of the uh interactions with theproducts or movies like I saidum so what it does is it's creating myuser digital profile shall I say bytaking the movies that I'm interactingwith so let's say I like sci-fi androm-com it's going to average those twoembeddings and then my digital profileis essentially just the average of thoseinteractions that I haveum so yeah this is great withrecommendation and it it what's awesomeabout it is that it really works umquickly um so all it takes is a fewinteractions right for it to create thisdigital profile just to make sure thatthe recommendation is accurateum to the user and you're not kind ofrecommended recommending things thatthey don't likeum so in addition to that the benefit ofthis approach is thatum it can be characterized from itsactions and relationships so the kind ofum yeah just like I said therecommendations are clear andpersonalized to that specific userum so by aggregating theircross-references it allows me to be toimmediately learn from the user'spreferences and everything and how thisit ties into using Vector searches thatyou can use the near Vector filterum or yeah use the near vector and typein my digital profile of my embeddingand then it's going and then you can tiein symbolic filters of let's say I kindof want Sci-Fi movies that are uh wereproduced after 2015 so it's digitallyappealing and it's not like the oldstuff that no one kind of wants to seeanymoreum so this also ties into going togenerative searchum so let's say from my movies exampleif I want it to summarize like five newmovies that I'm interested inum it can kind of do that right becauseit has my digital profile along withcreating maybeum like along with um I don't know ifyou guys think like with gpt4 it willeventually create content so how do youreally filter that out and make it likeuser specific and there's definitelyties into meta ranks with all of thiscontent and like an abundance ofinformation that users will eventuallyhave how can we rank that and you knowmake it more user specific I have aquestion regarding recommendationsbecause every time I hear embeddings andrecommendations I'm triggered uh to aska question how you compute thisembedding so technically is it like amatrix factorization collaborativefiltering oryeah I think if I'm hopping on thisquickly um yeah I think right now wejust have um like we vectorize all theproducts or the movies with clip andthen we you know the user likes thesemovies you know like these three moviesand so we just average these embeddingsand send them back to the user yeah Ithink I yeah and I'd love to talk abouthow this extends to collaborativefiltering I think that'll be a superinteresting topic but I think um thatwas a really great background Eric and Ithink that really sets the stage forkind of our interest in recommendation Ithink also kind of ranking this topic isof course relevant to search in generalwhere you know they will get into thesekind of things but to pass in like uhRoman and Siva can you tell us aboutkind of like the founding story of metarank generally how you're seeing thespaceyeah maybe I can uh I can chip inbecause probably later on Roman will dothe main token because he's moretechnical uh than I am uh we've beenworking closely with Roman for more thanuh seven years already I thinkum we've been working in an e-commercestartup before and uh the startup wasn'twas in the search and recommendationspace it was like a it was used inelasticsearch back in the day and youknow the recommendations were based oncollaborative filtering uh like reallysimple algorithms but they were workingkind of really well and you know we'vehad quite a few customers uh it was asuccess story of a startup I wasacquired uh back in the day uh and uhactually what Roman did in there isworking on personalization how do youactually personalize search results andlater on category and collection Pagesfor for e-commerce Storesum can I was kind of managing Roman abit uh it's kind of that's how we camecame up together uh with the idea ofhaving an open source uh engine that cando personalization uh and dopersonalized ranking kind of foreveryone that is not specific toe-commerce orattack or kind of any other verticalthat you can easilycan I just take uh drop someconfiguration drop your events and thenkind of it runs the personalization youdon't need to know uh a lot machinelearning stuff for data science okay youdon't need to set up complex uh datapipelines kind of use serious Stuff Etcuh just take the tool it works almostout of the box kind of that was kind ofthe idea behind metric and uhum yeah maybe Roman can kick in nowbecause he's been working mostly on itfrom the code perspective yeah so as uhwe you mentioned Haystack so when learnto rank was a hype thing like for in2023 it's not anymore like uh like on ahype but more like a commodity but backin the days if you hear all the talksrelated to ranking they're kind of youonly change the company names but thegeneral like okay we did some sort offeature engineering this time oflabelings and back and forth and then wethrow everything to xgboost and got ourImprovement in conversionyou you can just see that the companiesare doing the same thing but it usuallytakes quite some time to set up all thisdata processing pipeline becausethrowing things on exit boost is easyComputing the things especially in realtime is not sowe decided to make it like a commodityyou know so how this how it was withLucina originally because to do searchback in the days you need to be you knowlike a Java specialist knowing howinverted indexes work and do this crazythings with the leucine API which isobscure enough and then solar andelastics search came and then no oneeven knows how Lucin works you justthrow jsons to elastic and it worksuh eventually this commoditization ishappening for my own experience and myown opinion even with this Vector searchbecause like hnsv is2016 or something so can you do VectorResearch in 2016why notuh but did anyone build Vector searchthen no because you need to have youknow PhD in different things to gluethings together and now you throw jsonstomaybe it and it worksyeah so I love that um the you know thethe whole design of meta rank I'm prettyfamiliar with it I started looking intoit the kind of how you pass these Jsondictionaries for the user features andthe item features and maybe I mean therethere's quite a few topics I want to hopinto with this with because metal rankthis whole like ml Ops stack aroundranking could we maybe touch on thattopic a little bityeah so it's not about some basicfeatures about items and users like thisitem has this price this user uh camefrom an advertisementthere are usually some more statefulcomplicated features this item has aclick-through rate of something over thelast seven days and it quickly becomesquite complicated if you want to do backtesting and training so you need to havesome feature logging if there's two waysof computing features like offlineonlineand if you want to do something morecomplicated uhI don't know embeddings like do somecross encoders it also complicatesthings but and at the end it the samething so okay take mini LM from sentenceTransformers and feed it with choir andwith a title and compute the similarityso it's the same thing people are doingagain and again so we wanted to make italso a commodity like you throw jsons tomap Rank and it workslisten on this topic so seven Roman youguys really touched on making metal rankuser friendly and easy for people to useright it's like very abstract didn'treally know what's going on under thehood it's just like as simple as justdoing a Json file so um how do you guyslike how do you guys prioritize the userexperience in this case and what kind ofapproach do you take to thatoriginally we took Canadaum we tried to build the tool that wecan use ourselves it's like me as a likeI mean I have a development backgrounduh although like I'm a manager now butcan I still can can do some coding uhbut I'm not versed in this all the metalstuff for data science whateverum it's gonna I was the test guy uh whocould kind of go into my take match Rankand do something with it like we havethis uh uh movie lens uh data set thatyou know we use in our demo and kind ofused in several talks as well uh thatwill build specifically to Showcasepersonalized ranking and the idea isthat me as a regular developer can takemetric can run some comments can I can Iread the docs can they follow the stepsand it can they in the end getpersonalized ranking uh kind of we tookoriginally this approachum it worked quite well althoughoriginally metric was kind of built withaquite some uh specific Technologies andin the back so you in order like if youwant to run it to run it locally uh it'sit's not hard kind of you just it's aJava app you run it but if you want torun it uh let's say in kubernetes uh itbecame one hell of a job because uhbecause of the technologies that we'veused inside metrics kind of we'vefocused on simplifying that stuff wefocused on simplifying like completelyremoving uh databases having likein-memory storages so that you can runit locallyum but yeah like like and uh after thatcan I just get a feedback from the usersuh the companies we have some severaltest pilots uh let's call them like thatso companies from different verticalsthat try to use metric they havedifferent use cases uh different uhamounts of data even like uh once likesome companies have maybe like thousandsof data points others have millions ofdata points like how do you optimize forthat uh how to make it easy for them touse in different use cases kind of sotest it on us and then uh gettingfeedback from early adoptersbut usually early adopters came andhave some so obscure ways of using metarank you never even thought that peoplewill come with it but if you startthinking and just go back one step it'skind of reasonable and you just becominga you get a better understanding on howit can be used so we're always focusedon implicit feedback for the rankinglike users clicks on items and weoptimize based on that but in some casesyou have explicit feedbackso and for large companies that's kindatypical for example so you can haveanalysts who will just label the searchresults manually for top 1000 querieswhy don't you use it but with metal rankno wayand so just speaking to people that'swhy we have slack and people usually gothere and asks an absolutely weirdquestionscan you give us an example of one ofthose or is it all covereduh there was a guy who came there andasked uh what about reinforcementlearning and I was like what aboutreinforcement learning so can you doreinforcement learning it like I know intheory how to do reinforcement learningfor a search but I never did it actuallyand this guy like what I did I will tellyou and started just posting their likea long reads on how to deal with thedifferent links and no so what do youthinkand click or below that's interestingexperienceyeah it's really interesting I meanmaybe I think like recommendation onthis topic a little bit I thought a bitabout how it could be a reinforced andlearning problem where you know maybeyou make a sequence of recommendationdecisions to ultimately achievesomething like the guy I think aboutkind of like The Tick Tock the likevideo platform where maybe if I show youvideo a c d and e you watch eight forseven seconds I've already forgotten butwhat I just said the next one for threeseconds and then for five seconds andthen something about that leads you towatch the last one for like two minutesuh maybe a better example would be likekind of the education case like if I'mrecommending you educational resources Ilike this example a lot because butlet's say I have like five parts to mychapter and I also have a summary of thefive things if I'm trying to recommendyou something that'll probably lead tothe average case best score I'llprobably just out give you the summarybut if I give you these five in sequencethen so that kind of thing you have asequence but to take a step back I thinkmaybe if we could sort of explain I'mworried that we might have dived in alittle too quickly for the podcast if wecould just kind of explain thedifference between retrieval and rankingI know it's a little it's like I knoweveryone here already knows it but ifyou guys could just describe how you'reseeing the difference between thesethingsoh I can I read re-read the splayed andkohlberg papers today so I can give youlike a long lecture aboutan issues of retrievalbut if he if we speak about matter rankit is a gestural ranking thing and it'snot a silver bullet because it's heavilydepends on the retrieval sideuh so for some cases if your retrievalis very very focused on Precision likeyou search for pizza and it found singlePizza whatever maybe there are somemargaritas and Quattro for mojissomewhere but it's not in this resultsit's focused on a Precision we got likea perfect Precision like one documentand that's relevant documents so nothingwrong with the search results from thePrecision perspectivecan you improve it with rankingprobably now that's just because of onedocument and the search resultsso you need to balance between precisionand recall so a little something whichmight not be 100 relevant but there willbe just more relevant results overallbut where is the balance that's the goodquestion so I don't know forelasticsearch it's uh if you have a longqueries you can combine them with or soit at the end it will allow you to havesome better recall in the cost of uhnoise in the search resultsuh semantic search and Theory helps likesolves this particular problem becausefor example if you're searching forpizza it's just single term like youcan't have pizza or or what or pizza uhso with with semantic similarity it willmatch also pepperoni and all that thingscan you explain more about the historyof ranking with keyword features likeexactly like a pizza and then likeumso I didn't get the question likeranking with keywords iswell yeah I guess my angle is like howdo you combine like with the textfeatures such as like with bn25 the BM25 score along with like an n-grammatching like how do you rank with thatah okay soyeah Roman maybe we can also touch thepoint about multi-rich multi how do wecall themretrievers yeahyeahbut I will start with the usually how ithow people rank when they don't have anyfeedback so for example you have n gramsyou have BM 25 scores you can't havesome cosine distance between embeddingsand so onthese are just characteristics of youruh items so you can just throw it as aparam as a ranking factor to the LambdaMart model for this like literally justthrow things and text to XG boost andhope that it will workand surprisingly it usually works sothere are some approaches even to do itwithin elasticsearch like playing withboosts so there was a talk on Haystack acouple of years ago about learning toboost and there was like an almostanalytical solution to the problem ofhow to optimize boosts not like randomlybut you literally just compute whichboosts her minimizing pairwise lossacross your click-through history whichsounds very smart but at the end it'sjust logistic regression and you gotyour numbers like put this boost thereand you got your nice ranking but insome cases for case like multipleretrievals retrievers sorrywhen you have elasticsearch for Terrormatching and I don't know via V8 for uhsemantic matching and then you canintersect so these two sets of resultsin a single ranking so if document comesonly from term matching then it gotsonly bm25 score if it comes from vaviateandelasticsearch then there are two rankingfactors like your bm25 score and yourcosinedistanceand you use it so if you have only tworanking factors you can go without allthis complicated uhLambda Mark methods but if you mixuser Behavior I don't know like aclick-through writer or maybe a clickconversion rate or maybe length of adocument or length of your query then anumber of ranking factors goes upand you can't just mix it with logisticregression that easily because itdoesn't become more stable when you havemore ranking factorsyeah and uh kind of when it comes tomatch rank uh from the metrics userperspective uh it's the same thing youjust have some yaml configuration forthose features so you have bm25 as afeature uh for for the Lambda Mark modelyou have uh let's say cosine similarityas as a fee as another feature maybesomething else as another feature and uhmetric does all the all the work for youfor kind of combining those featurestogether combining the scores of youritems like if you have a set of resultsfrom multiple retrievers Metra andcombines those uh kind of the the scoresof each Retriever and uh kind of doesall the smart things puts it into themodel and can you you get the optimal uhranking in the end uhthat kind of increases your CTR orwhateveruh whatever else it can increase can itdepend depending on your kpis and yourbusiness goalsum kind of that's kind of where we alsokind of where we try to make the lifeeasier for the people and you don't needto think how you match stuff togetherin case of multiple YouTubers forexamplebut I got the impression that all thisranking optimization are kind of acomplicated topic for people so if youare attending Haystack conferenceprobably you know what's that but ifyou're trying to explain to your grandmawhat is the ranking and or just you knowyou pitch investors like we dore-ranking and they're like you do whatuh so we're considering to make it a bitmore a human friendly so we also dorecommendations because it's also kindof a not completely similar but uh giventhe data model we have for theinput events it's quite easy toimplement recommendations on top so youyou sell metric it's just a way to havea contract abouttype of different events like segment IOdoes for analytics for exampleuh net rank does does for ranking andrecommendations so that's an interactionthat's a metadata about item that'smetadata about user you just throw itthere and it works and you just tune theparameters of different models sofrom my experience doing machinelearning is usually like five percent ofall the time you do while buildingranking or recommendations and 95percent you just struggle and cry arounddifferent data pipelines how to computethese features is computed incorrectlyokay that's a nice article releasedlet's try it soum but it would be nice if the contractstays the same and you got all thisimprovements just for freeyeah it's another kind of fun thingabout recommendations is that canoriginally metric was only about uhre-ranking and kind of personalizedthrough ranking and uh we did a hack anduse lunch about a year ago and peoplewere kind of really excited we were notexpecting uh to have that much responseand kind of people right in US joiningslack Etc but everyone was asking aboutrecommendations because whenever can youtalk about ranking and personalizationeveryone thinks about recommendationsand can I finally about like two monthsago probably we've added the ability tocalculate recommendations uh into metricas well and that's also kind of based onthe user feedback that we got becauseum when it comes to recommendations uhthere are a lot of different algorithmsthere are a lot of python libraries thatyou can that you can take to implementthose recommendation widgets in your inyour store or in your web app on yoursocial network uh but in order toutilize them you need to be a pythonexpert you need to know how you need tohave data pipelines and all all theother things uh to hook that up anddisplay the recommendation widgets withmetric you already have all of thatbuilt in and thanks to like we'vealready have had that as well that's whyit was kind of easy for us to to addthose kind of recommendation Generationstuff into metricyeah so I think this topic is just superinteresting this kind of like there'sthis kind of topic of like multi-vectorrepresentation of objects like if I haveyou know a book and I have a title Ihave a abstract let's say and and I havelike content I would have a vector forthe title a vector for the contentVector for the author on like multiplevectors that represent this object andthen when I'm ranking them I would havelike you know the vector similarityscore for the title uh the BM 25 scorefor the title maybe also these engramfeatures that Erica mentioned andcombining all of this with an XG boostmodelmy big question with this kind ofapproach is do you then kind ofsacrifice out of domain generalizationlike by fitting it with this kind ofmodel do you just hyper focus on thisdata you have like how are you thinkingabout the generalization of this kind ofapproachuh so in text search uh if we just speakabout text search that you have onlyquery and a document and that's it uhit's hard to generalize but usually youalso have Behavior so okay this visitorinteracted with this sowas presented with these documents andyou have some sort of a bias in thistraining data because people click moreon the first items and then uh this itemwas displayed after that item so thereis some sort of pairwise differenceso it's just practically quite useful todoso and it still tries to optimize uhso on this interactions between thefeatures like you described the 10 gramsthey can be non-uhnot linear so it's hard to find somelinear explanation for them like putthem in a logistic regression and hopethat it will rank properlyum because for example BM 25 score isunbounded to the top so it can like oneor five or 55 or 5000 that's possiblevalues what you can't just easilynormalize it andyouso it quickly becomes quite complicatedfor normal normalizing different rankingfactors and if you throw everything atexubus it just handles it automaticallyyeah super interesting I think um maybestaying on the XG boost style I'm superfascinated with the way that you'veimplemented the Kafka streaming and howyou estimate the click-through ratewithin a window can you maybe talk aboutthat kind of system design for how youget that feature with the streaming databecause I think that's just a superpowerful part of thisso that's uh that's a long story soSarah mentioned that we did some uhdesign decisions originally so whenpeople try to run Metro rank somewherethey found that it's kind of a verycomplicated thingso we use the patch of Link before thatfor the streaming all the streamingstateful streaming thingsand it's nice when you're a largecompany with1000 customers uh to use this type ofstreaming framework but if you are justa small to medium Edo Tech provider youdon't need this type of heavy orartillery for data processing you don'tyou can process it on one two nodes youdon't need a cluster of 100 nodesbutbeing able toto scale you sacrifice the simplicityand some flexibility so we struggledquite a lot using a bunch of Link we tryto solve this problem of complexity withdocumentation and when I wrote thedeployment kubernetes deployment guidefor meta rank which was like you knowlike a Bible so huge so long with allthis you need to install this then youneed to have kubernetes operator tocontrol state of the Apache Flink jobsthen you do a custom resource for thejob that you deploy something there andyou need to be like a professionaldevops to run itum at the end we just removed the Apachelink and we wrote all this dataprocessing pipeline into something morereasonable at the end it's just notreally Java but scalab but whatever GBMappyou sacrifice we sacrifice scalabilitybut still it depends uh on performanceso uh for this click-through rates uhone of the first complicated features inMetro rank but I remember that I in myprevious couple of companies I spentquite some time implementing it properlybecause you don't only need don't onlyneed click through rate uh right now forthis period of time if you do backtesting you need to have to be able toanswer for question what wasclick-through rate for this item half ayear ago for the seven daysand you're likeum that's you know that's possible tocompute but uh imagine that you have acouple of millions or maybe billions ofdifferent search results and Computingit one billion times quickly becomesunreasonableso you do a lot of different tricks andhacks and all these hacks are part ofMetro rank so it's maybe my fifthattempt to implement this rolling windowclick-through ratesso technically uh this click-throughrates are aggregated within a bucket solike one hour or maybe one day itdoesn't really matter soum they are aggregated not like the CLthe actual rate so you count number ofuh for example interactions like clicksand number of impressions in a rollingbufferof uh of this where bucket is like aperiod of time and then uh from time totime eventually depending on the yourload not every time like one once in anhour you divide one rolling buffer toanother rolling buffer and get yourrolling CTRand then you aggregate for the periodslike one day and so onso we spent quite some time sooriginally we even had some somethinglike a feature store implemented byyourself on top of a bunch of Link uhbut it was quite complicated to do somestateful things on top of that and atthe end we get rid of it and simplifythat quite a lot but uhas a fan of test driven development itwas like a pleasure factoring so you youhave so many tests and you just makethem all of them pass and at that momentyou can releaseyeah sorry guys I need to plug in mycomputer everywhereyeah no problemohsome of thatokay great I I do have a follow-on questso let's goawesome so I think this kind ofclick-through rate this discussion offeature store is really interesting I'mreally excited to have this chat andlearn from you about this because I'vebeen thinking a lot about how do weintegrate with leviate with meta rankwhat would this kind of thing look likeand maybe as a quick background so we wehave symbolic properties but uh I don'tI don't know how well that interfaceswith this kind of CTR online estimationthing I listened to your talk where youtalk aboutum you know cold data postgres hot dataredis and then or does or does this justlive in meta rank where in you know youas you mentioned like one thing that'sso cool about this is you've done thethe kubernetes like it's like an APIthat you know with weave yet I can justkind of send my data you know API gitscore back so like how how would weintegrate sending you know integratingthe properties because we do havemetadata and we V8 how do we integrateit with meta rank so I think that's notthe way we should be integrated withmetal rank but uh the on the custom theintegration should happen on thecustomer side so you send your it's likean analytical events you send to segmentIO like user actionsuh you got your inventory update andthis item now is in stock or your titleis changed or Price changed or you got auser new user registered and you knowsomething about this user I don't knowcountry or ageit's also just bits of metadata and youthrow these events into thisinto the API or into the Kafka streambut like with segment or Googleanalytics just some specific types ofevents you notify that this happened atthat moment and meta rank stores thishuge logo of all this metadata changesand also you send events for okay Itried to display this search results ormaybe recommendations to this visitorand then visitor clicked on item numberthree so you sent rankings and clicksand then you have a very largeclick-through history with all themetadata for each item with thetimestampsand then you can Replay in meta rank soyou canconfigure different types of featureextractors like click-through rate andthen you just replay all this history ofevents with your new features and youget your back tested results with allthe features recomputed even if youchange somethingso uh but uh we see a weight ofintegration between Metro Rank and vv8for recommendations because how we dorecommendations right now is that theyare collaborated filtering based onesand in the case if your uh embedding ishugeuh we're just storing everything in Ramin you know the station as we livenothing fancy and if you have a lot ofitems you can't really store this in Rambecause it quickly becomes expensiveso we have a way to integrate withdifferent Vector search engines byoffloading this embedding so how itlooks like so you're not Computing theseembeddings on the side so customer justsends analytical events okay that's auser that's a click that's a rankingmeta rank periodically computes allthese embeddings and dump them to vv8for example and then if you ask forrecommendation it just also like a proxyfor the vv8 but also Computing the theembeddings by itselfit can do clip embeddings for movies butit can do collaborative filteringembeddings foruh interactions it can do contentembeddings for text sotwo weeks ago I took part in hackathonto build this type of functionality soit's not yet so it's in the master sobut not there's no stable release forthatbut uhyou can do any types of embedding so wecan do sentence Transformers now andsomething custom if you just upload aCSV there with embeddingsand then it will just serve them eitherfrom memory if it can fit memory or fromsome some bloggable Vector searchengines if it can'tyeah I also can in terms of kind ofcollaboration with the other companieswe didum can we try to collaborate with opensearch because they've recently releasedthe ability for external re-rankers tobe plugged into open search itselfum but it's it's still kind of uh it'sonly integrating only one part of ofMetron uh only the retrieval part theranking part but we still need to sendanalytical events anyway so kind of wedon't see yet a big benefit of uh havingsome sort of like a plug-in that will doeverything for you because you knowbecause of the way metric is built kindof this kind of two there are two waysyou need to use to to integrate withmetric like the retrieval and the theanalytical stuffum it's hard to build a connector forfor the LA for external libraries uhkind of to integrate both of these partsum it's kind of with uh kind of wehaven't invested invested yet intobuilding auh a plugin for open searchum so that's why I kind of where we'retrying to concentrate on the uh on likehow you can utilize different toolstogether uh like a separate uhapplicationsand kind of this hackathon that Romanmentioned and uh kind of the the stuffaround embeddings that it built intometric it's not public yet can wehaven't released it yet and there is nodocumentation yet uh but it's cominghopefully soonthere is documentation if you go on ourdocs there is a like a drop down thereand you need to choose like not not thestable one yeah the unstable docks yeahyeah but usually no one goes thereit's good that you have the two separateattacks yeah because what we've noticedas well is that sometimes people uh kindof look uh in the old docks like they'reusing the old version of match rankthey're using the old version of matrankand they're using the new Docs and thatwas the original problem of having likeseparate branches for the docks as wellI guess on the topic of collaborativefiltering and also like click-throughrate and personalized recommendationum I guess how does this solve the likecold start problem like I'm new to awebsite butum maybe there's some metadata on myinteractions on Googleum how do you guys handle that I guessif my question was clear enough yeah butuh it depends on what you count as ainformation about youso when you just land it on the websitewe can already know are you on mobile oron desktop from which refer you came notlike exactly refer but probably it'slike organic Google search advertisementor maybe Instagram link on this type ofgranularityuh your location maybe time of date thetime date and so on that's still contentcontext and even with this amount ofinformation oh and the page you landedto so if it's just the top page that'sone thing if you land it on a specificproduct probably and you came fromGoogle probably you search for thisproduct on Google and clicked on a linkso that's also an interesting bit of acon context about youso even without interactions uhany website can know quite a lot aboutyou but not like you know privacysensitive information but more like anaggregation so okay you came here wehave no idea who you are we don't knowthe name your click history nothing butjust some hints that your came frommobile from us and the middle of aSunday night uhfrom Google and game on a specificproduct that's enough to adapt at leastto see how other people like youinteracted in the past and adaptyeah and uh yeah maybe also depend ontop of thatum in the company kind of previouslyworked in we we did quite a few a btests that showed that uh kind of thisapproach really increases the conversioneventually because I'm gonnayeah of course kind of you're a uniqueperson uh but when you aggregate youamong like 100 000 of other people youhave similar behaviors and uh theability of uh of the personalizationmodel to adapt quickly uh to what you doon the website uh yeah kind of you asRoman mentioned kind of we already knowwhere you came from and kind of what'swhat's your location but as as long asyou click a few items well with no kindof interests uh kind of what type ofproducts you you want to buy or whateverit's gonna all of that can is directlyingested into the model and uh in almostreal time you get a personalized rankingafterwards so you don't need to knowlike really a lot about a person uh tostart personalizing as long as you havelike the moral build as long as you usemetric for exampleyeah I guess I always forget how muchinformation is just um like how you cancreate like this digital profile soeasily just like boom I'm on the websiteand now I've been I'm not as unique asyou said right like I'm as similar assomeone else's behavior and you know itis personalized in the products that yourecommend are accurate amazing there issome sort of a balance between privacyintrusivenessand like business values soMetro rank tries to be as generic aspossible sofor example a long time ago we not notthrough it's not related to Metro rankbut uh I've seen people doing it thatyou can integrate with the DMP type ofProvider providers to get some moregranular information about what you didbefore on other websitesso advertisements as advertisers usuallynot only know this information about youlike you know Facebookum they know your interests and you canpurchase this type of segments like towhich segments you belong and so but uhit's usually used for ads and there issome a couple of floors DMP platformslike from Oracle and so on and theyon Oracle that wasa link somewhere that you can go withyour normal browser to unsubscribe likejust opt out of tracking and there youcan ask for the data you have for somereason this link is down for a year I'mjust trying to do it again and again andit's still kind of temporary problemscome again later and that'sum but when it worked it uh shown youlike a segments uh for like a type ofthird power party tracking and that'svery privacy intrusive for me so I'magainst using it and matter rank isabout first uh for like a first partytype of tracking so yourwe have zero known about you when youcame on the on the website so okayyou're on a mobilefrom UKthat's kind of it but it's not thatprivacy intrusive as knowing your genderbased on your searches on Facebookyeah I'm really curious well this kindof brings me into this topic of like therank lens demo that you have and sort ofthis General topic of recommendationdata sets I think umlike what do you think about sort of theuser features that are captured in thesedata sets are they realistic compared tothe applications you work onI think uh probably like a small remarkis that uh all the data sets uh thatexists really suck because uh usuallythey have let's say like informationabout the items maybe some informationabout the searches and zero informationabout the the actual users that did thesearch so it's almost impossible to douh like a ranking demo uh because thereare no open data sets that have userBehavior embedded in them and that thatwas the background why we had to come upwith our own data sets can I spend ourmoney Etcum use crowdsourcing uh engine uh toLocker AI uh to to help us build the thenecessary interactions uh for the forthe data set as wellRoman what do you thinkyeah so for search it's stillproblematic there are some data sets butthey are usually very text focused ormaybe in a very specific domain like aquestion answering in a medical searchwhich is nice but not e-commerce usuallywhere the money areumuh last year there was this Amazon EA esCI data set released which I'm reallybig fan of the problem of this data setis that there is not so it's also textto to focused on text you have like asearch query product title productdescription that's ituh uh and uh you can't do much on thisdata set with meta rank even if it'swonderful on its coverage it's uh 150000 queriesreferencing almost1.6 million productsso until this and explicit labels forall of them which is very very expensiveto build and it's I'm glad Amazon opensource this type of levels but you don'thave metadata you don't have anythingabout users uh we can't do anythingabout users because it's Amazon but wecan do about metadata because theproduct ID and the caci data set isAmazonproduct ID this Asin so you can scrapeuh kind of scraping 2 million Amazonproducts is a tricky process but weactually did it we won't say that we'vedone it we won't say yeah we've done itso someone else did it and formallyformally uh that's a good question fromthe legality sothere was a court case LinkedIn versussomeone I forgot the name IQ somethingwho scraped LinkedIn and even theyscrapped like a private date on LinkedInyour contact date on LinkedIn and stillthey wonthat it's kind of a still not reallyprivate data it's still open sowe didn't scrape any private data wedidn't uh use tiny tricks touh sneak into the locked in section ofthe website it's just what Google Seeslike Google can scrape Amazon why can'twe scrape Amazon like like the same inthe same way of Google so there is anextension for the csci data setfrom from me personally towith all this metadata like prices uhproduct popularity review score numberof reviews and all the structuredinformation about and categories whichis also very importantso the end goal is to have some sort ofa search demo of meta ranks but therewas no data set and then Amazon escicame but there is something missing butnow it's now it's betteryeah but still it kind of misses the theuser metadata so it's kind of hard to dopersonalized ranking demos or uh liketests evenumand that's maybe like ifAmazon will collaborate with aMechanical Turk for example which is anAmazon service they can produce a dataset that is kind of labeled with usersas well with user informationum you know as I mentioned earlierthat's why you know we had to build ourown data sets and kind of we've made itopen source as well for everyone to useuh but it's kind of it's hard for us toto make it popular among among peoplebecause we're small okay a small companyand still it's not that big of a dataset as well you know it's going tofocused on the movies so not e-commerceso I don't call it a company it's justtwo folks doing open source technicallyso company assumes that you make moneyon that and ohyeah this is such an interesting topicum when we were prototyping ref I hadyou know gone to Twitter and sort ofsimilarly used the Twitter API to kindof like reverse out their recommendationa little bit like you can get sometweets out that way and then you can seehow well averaging the embeddings oflike tweets like for the case of our refthing uh so this last question I havefor you is a pretty big one I'm verycurious what your opinion is on thesecross encoder models that are like takethe query and document as input to ahigh capacity Transformer and uhparticularly there's kind of well maybeactually let me just set it up justgenerally like what do you think aboutthese kind of cross encoders compared tothe XG boost style models that we'vemostly been talking about this crossencoders are not againjust supplementary theme like orthogonalso it's not only about cross encoders asis there are some otherretrieval models like Colbert and allthis modern stuff that's playedand it's just extra information for thefinal ranking so you justcombine different signals from differenttypes of ranking algorithms uh togethertrying to push your ranking qualityfurthersoum I think cross encoders are wonderfuluh but uh I got an impression thatpeople uh consider cross and colors likesome rocket scienceoh to train across and go to fine-tunecross encoder you need to have a team ofdata scientists to dowhich is surprisingly not the caseuh so it's quite easy just you only needto have GPUwhat BT GPU but that's the only thingyou needand but for example for for the sentenceTransformers packageeverything is implemented for you andit's very nicely documented anddifferent approaches but different prosand cons and even examples on how tofine tune on Ms marker for example justblog your own data set and leave it forfor a nighthmm yeah so that's what I'm actuallydoing right now you mentioned thateverything was uh you were accepted onthe haystack uh me too so we'll we'llsee each other there so I'm trying andso that I'm going to speak about thisparticular type of uh particular problemof combining learn to rank and uhterm search metadata and Vector searchso it's usually not about choosingsomething like okay we need to use onlyVector search instead of elastic no youshouldn't you really just throweverything together in a giant Ensemblemodel and it usually works better thansingleseparate onealso congratulations on getting acceptedI'm looking forward to your talking yeahthank younow I need to prepare it that's thecomplete the most complicated partyeah uh yeah fantastic I think um yeahwell I I love that perspective on Crossencoders as just another signal I Ithink it makes a ton of sense I guesskind of one more little thing I want toadd to this is kind of the idea of thelarge language model ranking and whetheryou can you know like distill that intoanother feature or use that to train thecross encoder or the or this kind ofthing but like the idea where I mighthave like you know let's say it's Conorwatching movies and I have a descriptionof Connor like I kind of translate thesetabular features into text and then Iuse like query tabular to texttranslation and the current moviedescription like you know all that goesas input to the gpt4 fireplace to likeget the ranking what do you think aboutthat kind of like what role do largelanguage models have in rankinguhI think the larger the model the morecontext it might handle not only aboutyour query and your products but justsome common sense understanding aboutthingsso in this hackathon we did a couple ofexamples of semantic uh recommendationsfor movies it was just movie lens dataset with the different algorithms ofrecommendations like collaborativefiltering semantic embeddings with miniLM like tiny model compared to Chad GPDjust like you know minuscule and it wasembeddings from cohere AI which arequite huge as far as I know it's 100something billionsoflinks and the embedding itself is 2 000somethingthe dimensionalities like 200048. so that's a huge one and if youstart clicking on movies and see whatwas going to be recommended to you younotice that sometimes the smallembedding and large embedding aregenerating almost the same thinguh in some simple cases so I don't knowyou go for a Terminator movie you mightguess what you will get on all thealgorithms because it's quite an easytask you don't need a lot of context youneed to know what robot is and likerobot killing people that's itum but a wonderful example was aboutaliens there aliens movieuh so collaborated filtering suggestedsomething other people like yeah it wassomething about space and some somecreepy movies uhand to this large embeddings from coherialso was about different types of alienswhich are usually not very kind topeopleso a bit different types of movies thancollaborative filtering but still in thesame area and the small embedding whichhas a very limited amount of memory andthe amount of context it can handle itfound a couple of alien movies from thesame Frenchies then it decided okaythat's actually people escaping fromsomething why don't you put movies aboutescaping from a jailthe same thing and yeah there's a moviecalled a man called Ripley Ripley is sounusual name probably that's the sameRipleyso semantically good match but uh withthe 80 megabytes 80 millions ofConnections in the network you can'tjust learn that there can be multipleripleys actuallyand you can there are multiple types ofjails and some jails are flying in spaceand there's a bit different thing thanjail on EarthsoI think the larger the model the moredescriptive it is but it usually dependson Hardware sokohiria is like one dollar per 1000embeddings and if you need to embed 1million items like esei data set youneed to to you need to spend twothousand dollars on thatso quite expensive for for hackathontype of project quite expensive and weneed to do it periodically because youritems are changing in time soit's about resourcesyeah amazing well I thought this was agreat podcast Roman Siva thank you somuch for your time Erica for joining thepodcast for the first time and um yeahit's such a great dive into these topicsaround ranking I think it can kind ofthe Cross encoder can seem so simplejust this kind of like query documentand there's distinction where retrievalis like this kind of coarse grain surgewith the vector index or inverted indexwith the bm25 things like this and thenwe have this more fine-grained highcapacity model and then kind oftransitioning into the XG boost with themetadata features and all the thingsyou're doing behind I I think it's sointeresting like as we talked about thestreaming data to estimate theclick-through rate and and yeah just thewhole thing is so interesting so thankyou all so much for joining the podcastyeah thanks for having us thank youthank you for the invitation", "type": "Video", "name": "Erika Cardenas, Roman Grebennikov, and Vsevolod Goloviznin on Recommendation and Metarank - Pod #43!", "path": "", "link": "https://www.youtube.com/watch?v=aLY0q6V01G4", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}