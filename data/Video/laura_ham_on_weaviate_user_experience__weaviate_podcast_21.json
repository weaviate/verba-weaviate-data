{"text": "Thank you for watching the 21st Weaviate Podcast with Laura Ham! Laura Ham has worked on Weaviate at SeMI Technologies ... \nhey everyone thank you so much for checking out the webv8 podcast today is going to be truly one of the most special episodes of the week a podcast we've had so far laura hamm is making her debut on the wva podcast uh laura has created so much amazing content that helped me personally learn how to use wev8 and all sorts of things from wv-8 examples to say the design of the graphql and blog post tutorials around this graph like data model and all these exciting things so uh laura thank you so much for coming on the webva podcast thank you conor yeah it's great to finally be in your podcast so could we start with um the the introduction of kind of the origin story of what led you to be working on vv8 yeah that's a good start so um that goes back already like five years i think uh when i started working together with uh both the one of the founders of of sammy and weaviate um yeah back then we were working both as a freelancer or some other projects and bob started working on on wev8 and i think like we were both super interested in natural language processing and how like all the developments in that world happened and that's where yeah we started collaborating and um yeah started working on we fade basically so i think bob tells us when i asked him how he first got into this he says the king minus queen plus man that kind of thing was that a similar inspiration for you that led you into this uh vector embedding kind of part of natural language processing yeah yeah definitely so at the time you had like these first word effect models for example uh coming up and with word effect of course words are represented as vectors um and that's also where you have this king minus um man plus female is queen thing uh is coming from of course so basically with these algorithms like word to fact we were like they allowed us to use neural networks to understand language and word associations and um yeah what's what's been really interesting to me um specifically is that you can calculate then like how similar uh different words or different concepts are uh to each other so you can find synonyms or related concepts which is of course very relevant if we talk about a search because i think like before with natural language application applications people were working are still working a lot with ontologies or taxonomies and think like ontologies and taxonomies they need to be defined beforehand so before you start using an application and i see the potential problem or challenge there is that there is also always one or more people defining this ontology or taxonomy and they have to agree on some meanings of words because in an ontology you have a word and you have the context of the word or what it means so people have to agree on this meaning and um that's really hard if you work with a lot of people yeah basically if you then yeah then you don't know how to deal with sign names or yeah you basically have to deal with okay i want to give the best search experience to a user so you need to know what kind of words he or she is using um as an ontologist and i think this is one of the the problems that algorithms like word to fact or like the birth models today with neural networks can solve yeah i'm really excited to dive into the ontologies and and yeah i remember another story baba told about they couldn't agree whether it's a sea or a lake and that kind of idea where you have the disagreement on the terms and and uh going to new york with you and seeing the ontologies the symbolic graphs i had never really been exposed to that kind of thing before but i quickly want to dive a little deeper into the into your five years at uh semi technologies in wva can you tell me about sort of the and then we'll kind of get deeper into how we evade itself has evolved but how has your experience with the kind of startup company growing how has that been yeah yeah that's been great so um so like five years ago i started more in a research-like position so i was looking at technologies like word effect and how can we use that to build a good neural search experience basically um so i've been experimenting a lot building a lot of prototypes to test um and what's good to mention i think is that i've been working with like real users or the customers from the start so we really learned from them what their challenges are and like how we can solve them and test things out so yeah i was really more like a research position back then i was also still studying i was doing a master's degree in human computer interaction so that also like the lessons that i learned in my studies i could directly apply in the research that i did with review because my goal was to make the search experience or the yeah user or developer experience of natural language processing or search search engines as friendly as possible so it was really good that i could put it in practice directly so and during that time of course the startup started to grow so we've it got developed uh until like the version uh 1.0 we had like two years ago i think and since then the team has also been growing and that's just really amazing to see so yeah during that time i've also been doing a lot of talks at conferences i've been in close contact with the open source community so always like trying to grow the community uh learn from their feedback that they have and um yeah since i was involved in improving the developer experience i for example designed the whole graphql api that we still have today and the documentation that is still out there yeah those kind of things and then now that the team is like way bigger i can focus more uh on like uh yeah one thing again that's more like the research so it's really exciting yeah that's so interesting and i'm really curious so could we dive a bit more into the human computer reaction and the user experience the graphql design i love how it has this like we've eight has this get and then you can chain on these functions like if you want to do the near text search the near vector question asking and then accessing the properties of your data i can take me through the design of the graphql and maybe principles from human computer interaction what what that kind of field of study how does it help you think about these kinds of things yeah yeah super interesting so yeah first i will take a step back so first i want to share like share why we have graphql so um because we also have normal restful and restful api endpoints and but those like rest api endpoints are more for accessing the resources so accessing the data so uh updating data uploading data um deleting data you can all do those kind of things stressful but then if you want to start searching through it um you need a yeah you cannot um do it in one yeah single url query basically um so that's i mean the user experience of doing a search in a restful like way it's really hard so that's why we started looking at rafcal basically um and yeah of course like when i started designing it my first goals were you know the the general design principles that you should have with api design like it should be intuitive to be readable [Music] yeah simple as possible like consistency in terms of naming etc um [Music] and then i started designing and then i thought okay we're we're building a search engine which works for example with semantic search in text or images but so i wanted to also give a nice experience when you write a query that it feels like you're writing it in natural language and that's where the the get and then near text and then like the class and properties come from because you can really read it as okay i want to get a data that is of type article and from that i want to see the name the content the authors and so on and i want to find articles that are near this piece of text so i want to yeah i try to integrate the human language as much as possible in there yeah well that was really well said i really like that flow of it and and and that also helped me understand sort of the difference between the rest api and the graphql api if you want to have like arguments to a rest api you had to have like this long url right with like the question mark and that kind of thing yeah exactly compared to like stacking it out with the graphql right yeah it's really interesting the idea of a natural language interface with a search engine on say like multi-modal data arbitrary data where you could say uh give me a picture of a dog playing with the ball i don't know but like that kind of natural language uh interface experience uh so could we then kind of transition a bit to um so when you have the graphql and you have the new ux how does that tie into the vector database of webva and the all the indexing stuff and how does the whole team kind of coordinate that kind of thing yeah so right now we have like a big v8 core team so like possessive core engineers who are really building uh abbreviate and next to that we have like the research team that you and i are in um and um yeah so the goal is to have like we do research like we find new technologies that might be a potential feature or like an improvement or something and our current approach now is that you know we um we pick up these things we test if they are useful for us we do like experiments um yeah to evaluate it and then the goal is to come up with a good design for which we can pass on to the core team let's say and this design that consists of yeah what this technology is but also how it should look like from a user perspective so how it should be used by user and um yeah that's that's a really important thing that we uh find really important with building vva is that we always try to have the highest ux as possible so [Music] that means the design is from an api perspective because wav8 ends at api level so all the things that the user or developer using vfit will see is an api level so this is the user experience and from there we start building a design basically and yeah so once we have that we can pass it to their core team and they can start building uh and do it like um in the most efficient way of course and so on so when you when i want to ask about your approach to the research process and when you see new papers or new ideas coming out do you instantly have this perspective of okay what would this look like in we v8 is that your first kind of approach to thinking about it um yes and no so of course i'm always thinking about like can we use this with rev8 yes or no but it's like um i kind of address a bigger question um and that is does it add value in a search experience so weaving is a effective search engine so the goal is that people can use this to improve their yeah search experience so if it's a really nice new technique or new machine learning model or whatever that is not related to this or would not improve the search experience then i might use it for something else but not for we've yet obviously so there's always this bigger question in my head like okay can we use this to improve the experience basically can i ask about the like the development of search and the application of search has any particular say use cases that you use to reason about most uh like most problems say like the question of who's the best basketball player of all time searching through wikipedia like do you use these kind of like examples to mo to like guide your thinking uh yeah i think there's always use cases in mind when i um when i think about usability or like uh for potentially new feature and yeah this of course can come from my own imagination but it can also come from what i get back from like open source users or um yeah other people that use a search engine when you find yourself designing things do you ever like maybe go too particular into one application and then have to think about how does this generalize out or is it yes that's a tricky thing right so it's um yeah of course like of course you're you're sometimes i'm experimenting and then you really dive into one subject but then it's really important to indeed take that step back and then generalize and think okay is this only useful for this particular problem or can it be useful in more situations and both is fine but you need to be aware of what what case it is basically you generally have like maybe like less is more is that kind of a good way of thinking about how you kind of design these like like function calls almost like when you design like a graphql api it's kind of like a function maybe the the more succinctly you can describe it is that the better way kind of generally yeah that's a good way of looking at it i think of course it should be it should be simple and intuitive but if you oversimplify it that's that's also dangerous of course it should still be clear what it means and um yeah now that we see that we um are adding more and more features to improve the whole search pipeline basically this also um yeah so another topic comes to my mind now is that how do we scale this uh graphql api to serve all the possible use cases before we had like um you could do you could use rev8 for just a semantic search so it would be a simple query where you have one [Music] piece of text or one image that you would search by but now with all like um yeah other methods to increase like make the pipeline bigger uh to improve the search experience and improve the results basically um the graphql should also be uh yeah so be able to support that of course and then yeah it becomes really difficult to to come up with a good language that supports it basically yeah i'm so excited about this idea of the adding new features and building out the pipelines uh quickly before we dive into that can we talk about say uh what goes into the integrations with uh you developed these coding tutorials of how to combine wev8 with gina and wev88 with haystack how's your experience been making these like open source tools fit together yeah yeah that's really exciting so uh haystack by by deep set and gina as well are neural search frameworks which basically means that they focus on the entire ecosystem around neural search so that goes from like data pre-processing and fine-tuning um to the search as well um and yeah those frameworks are like should be used in in python and that's really nice if you want to build like a whole search experience right um but if you want to scale this to production or to like big data then you also need an efficient database that lies underneath this application basically and that's yeah rephrase one of the possible yeah databases that supports this so since i think the beginning of this year we have these integrations with haystack and gina that if you use their framework you can use review as a database needed basically and yeah that's just super cool to work with with these people on this project yeah i think that's a super interesting uh connection obviously being like part of we've had i like the vector database and where you have the h and sw efficiently find the nearest neighbor structure with the persistence and the database features then you can i put pipe stream pipeline that upstream to things like question answering re-ranking and overall thinking about these pipelines so i'm super excited to dive into this topic of search pipelines so we have maybe retrieval we could have sentenced transformer retrieval bm25 retrieval aggregate step and then cross encoder all these things can you take me through your understanding of search pipelines yeah that's a good question so um how i see it is that like basic information retrieval um that comes like that interacts with a database so if we have we've ate as database then a basic information retrieval is just like making query and getting some results back from the database this however so we use bi-encoders models so that's our neural networks that make factor representations out of words or sentences um and then like data will be basically retrieved in wv8 by comparing the vector of a query and comparing with the vectors of the data objects so um this is a really efficient method um but it also comes with some drawbacks that is maybe not as accurate as you want to be um for this like we also next to buy encoders that create vectors out of words we also have cross encoders so cross encoders do not produce vectors but they compare a query directly with a sentence or a word and give a value between zero and one how similar it is this this kind of methods if they are trained on the yeah representative data set have a higher recall like higher higher accuracy than a buy encoder but it comes with a cost because it's computationally very expensive so what's interesting now is if we combine these cheap methods of buying coders with the more expensive but more accurate methods cross-encoders so the idea is basically to have like use a buy encoder to retrieve initial set of data [Music] which is a subset of the of of course all your data uh relevant to your search query and then re-rank them uh reorder them based on a cross-encoder which can be executed because it's uh like a shorter list basically um so that's one way to improve the initial results of information retrieval um yeah and there's uh i can go on with like more ways so we have um you can all so this was one way of re-ranking results basically you can go on with that so if you want to personalize search based on some user information for example you could use another re-ranker to re-rank those results again and have the most relevant results to this user place on top so you can basically extend this pipeline with many models uh that you want uh to have a like a good search experience you know i love what uh so i think bob pitched this idea of having like um you're in the ocean and you cast a big fish net and you get a bunch of fish on the boat with retrieval and then say you have to have like workers who pick up the fish and it's more expensive to have the workers compared to the fish net then they're more accurate at looking at the fish and making sure it's the fish you're looking for so one of the topics that really excites me about this is thinking about this kind of zero shot generalization thing and these models that have been pre-trained and they come off the shelf and with retrieval models say it's kind of i say i think like the deep learning end of we've eats vector representations are built on these pre-trained sentence transformers let's say they have data sets like wikipedia where you use the heuristic of neighboring paragraphs make these representations similar or maybe you have like the ms marco data set where they've published like a million uh query correct result or like what they clicked on pairs and so you use that to train these retrieval models and then it's been trained on such a big data set that you say it will do this zero shot generalization to your problem and i think this kind of way that we have these pipelines you see it as a way to say correct the error of zero shot retrieval so you know the you're trying to search through say the we vva documentation and you're trying to use retrieval from wikipedia and of course there's a bit of a domain shift so maybe instead of having to fine-tune our retrieval model we could just fine-tune the cross-encoder right or these kind of things how do you see this kind of like zero shot generalization of the retrieval and the cross encoder we could have zero shot cross encoders too does it make it like simpler to adapt it to your problem kind of or yeah i think yeah that's really interesting so i think we need to experiment with that what works best because i think if you have so if you have the review like a vpa documentation which contains a lot of um like specific words to alleviate which of course do not appear in wikipedia um then if you just use this model train on wikipedia it doesn't work right on your technical documentation i think just um just fine-tuning a cross-encoder like retraining a cross-encoder wouldn't necessarily solve the whole problem because if the results were not caught in this big net of fish in the first place then the expensive fishman cannot find the right fish anyways so we also need to make sure that those right fishes are initially already caught in that big net basically and yeah so that might mean we also need to fine-tune a bi-encoder or what's also really interesting is uh combine it with um with sparse search so for example bm25 which just looks at um so it doesn't use neural networks or anything it just looks at uh the words itself so bm25 is maybe like a like a cage like a lobster cage like it like we have like our fish net and we have maybe like some other kind of fishing device how do you see the interplay of uh of the bm 25 and the sentence transform i think it's a big question but like just kind of taking it from the beginning what like what does bm25 add to sentence transformers or that they each miss out on yeah yeah that's super interesting so i think like before we had just sparse methods so just tf idf bm25 um which just used like exact words to retrieve uh data um but now like of course these bm25 and tfidf methods they don't know anything about synonyms or glycemi so that's where dense methods so methods that are trained with a neural network to understand the language solve that problem but if you just use dense methods like like review is using as we speak then if you use that on a data set that is not uh like as out of domain of your trading set basically you might see problems um and that can so then it becomes interesting to combine vm like methods with dance encoders to um yeah bridge that gap basically because i think like if you are if you have a search query that contains some very specific words um like um what does near text do in wv88 if you want to search by that then we know that you really need to have the word near text in your result so if we use bm25 on that query um we will see for sure results with near text but if we just use that by encoder we might see relevant results but maybe the near text isn't really on top or like um so yeah if we combine those methods i think they like can solve a lot of out of domains problem problems yeah it it definitely seems like they complement each other well and i think this comes back into the user experience design and how you're going to interface with these two ways of search so i guess maybe the most straightforward way to do it would be to have say an aggregation score right where you have like 0.5 times the bm25 score plus 0.5 times the sentence transformer score uh rank maybe might be a way to like heavily emphasize so so how is how would the user interface design then take a concept like bm25 send this transformer and then create an experience in which you can combine them easily for search pipelines yeah yeah that's super interesting so first we need to find out like what are all the possible ways that you can combine them because the the way you just described is like a linear way so you have on you do both searches so the dance search and sparse search in parallel parallel and then you um do like um alpha times the dance better times the sparse and you combine them so that's a linear way what you could also do is use rf method and what that means is you take both result lists and you don't look at the individual scores but you look at the order so the results that appear on top on both results will appear on top in the final result as well so these are already two methods of combining the results basically maybe there are more um so we need to make sure we first look at okay which methods to combine them are relevant um and then secondly to support them in a graphql design or like another way of in an api it doesn't have to be graphql maybe um yeah that also supports if there are coming more methods coming in the future that also supports like uh yeah to be able to scale to that basically this is one idea that uh that i think we talked about a little bit recently that i think might be kind of overdoing it but do you think maybe when you have a query you kind of classify whether this is a query that should go to bm25 and you should kind of add one more part in the pipeline where uh the query what is near text in wva and then this query intent classifier or pipeline inference thing goes this is pretty entity centric we should probably send this to bm25 and weight it according to this function do you think that would maybe add like too much to it or do you think that maybe could just i guess coming back to the user experience it could compress it a lot because you just have this thing that creates the pipeline and then it's like uh like pipeline wizard or something like that yeah yeah that's super interesting so um i think we're definitely moving in that way that we like um so we've it itself is already modular and i think like the whole graphql or like the whole api maybe it is not rascal uh whole api design should also be modular so i picked this element in my pipeline this element i want to combine them like this um and then um yeah and then like you said like looking at the queries or really query parsing and doing maybe even some manipulation to the create to make uh the list of results better in the end um yeah that i think that's that's super cool so if you like what's what i saw in research is that bm25 queries which are very specific so basically long queries with a lot of entities or named entities in there they um achieve a higher score in the result list than um than shorter queries or like one word queries so if we could somehow learn from a query if it is very specific or not we can give a higher score to the bm25 compared to the dense methods and this leaves a lot a little bit of experiment but i think this is definitely what the way we're moving yeah i really want to dive back into the modular design but you brought up something that i think is pretty is really interesting in that um you know it doesn't always have to be so complicated right like something like just the length of the query could be enough of a heuristic to tell you which one you probably want to use i can also ask about the design of the uh the scalar filters how you can say do a vector search but then you can also kind of label it symbolically and filter the search that way how how did that kind of come to be in the inspiration of combining it that way with uh simple kind of filters as well as this kind of vector alignment right yeah yeah um so that's really around the strong points of rehab i believe so if you just have a vector index or vector yeah vector index where you can store vectors and retrieve vectors um that are basically algorithms like um i think like files and scan you can just put vectors in there but not the data object itself so if you do so you can do just a vector search which means you put a vector as inputs you get vectors as output but that's not really usable if you talk about real data because you want to see um the actual data object um so we've a doesn't only store the vectors but it also store the actual data object which means yeah if you search by one you can if you search by vector you can get actual results back that belong to two vectors of course but then we've it also combines this vector search with like you said the the structured filtering um we call this a wear filter so like in sql you can put the air filter and that um so in that you can say some restrictions to your search some filters so let's say you want like the color of your product always to be read in the results then this is a really strict filter what then happens in a search if you combine this with a near text search we will first perform this structured filtering and it uses like inverted indexes for that which then creates an allow list for an effective search so it's a two-step approach basically and yeah i think that that's really that's yeah really cool from a technical perspective but it's just really um yeah it's just something you need to have from a ux perspective if you talk about the database i think yeah i think that's huge for the the ux of deep learning search generally if the if you are getting a nearby uh shoe image and you can filter it with the red uh color tag you you already get a much better kind of uh space of that and so i see kind of a couple ways of taking this conversation but quickly i wanted to talk about the idea of i just quit just kind of the comparison of face and weaviate and uh how you can store the symbolic things so maybe to give like a quick example of something i've been doing is studying uh you have archive title abstracts and you vectorize the abstracts and you store the vectors in weaviate but then you also store the index and so what that lets you do is then you want to take the title and see if you can find the matching abstract and you don't just have the vector because then you don't know if it matched it or not you also have the index so that's like kind of one example that i've been doing that shows how storing the additional things in addition to the vector helps you like study these things and then also i'd say if the topic is weaviate versus face having that persistence of the database layer is super useful for this because it takes a super long time to like upload a million vectors right and and that kind of thing so having it like it's going to stay in there as a database i've also found that to be incredibly useful so uh and then so i know i'm kind of jumping around the conversation topic but so what so this inverted index thing is like um you invert the category so it's red and then the things that have the property read how does an inverted index and the h w index how do those two things coexist oh that's a good question that's really technical um so i think inverted index is something that we know already from relational databases um basically what yeah like you said what you do is you invert the yeah the properties of a data object in in the table so instead of like having each data object with a property and a value you would have a value first and then each data object that has this value um which that basically just improves the efficiency like it has a lower latency i think that the whole h and sw is like um that's an yeah in a n algorithm so uh brookside's nearest neighbor algorithm that allows for very efficient um vector search so that's on the other hand basically um yeah yeah i think the that approximate nearest neighbor thing is definitely one of my uh my favorite topics around we've gate and i'd i love to get back into the modular thing but can you tell me about your experience with the approximate nearest neighbors kind of how you first became introduced it introduced to it and then sort of what that unlocks sort of when you're thinking about these search pipelines yeah so a n um so let me take a step back so if you have like um a database full of vectors which are like basically points in a high dimensional space and you want to search through it you basically want to do a k n search so nearest neighbor search from a certain point and this point is your search query um so with k n you basically retrieve all the elements or all the vectors with data objects that are closest to this search query um and it retrieves yeah all of them to like how big you want to have it but if you want to do this on a large scale and with large i mean i don't even mean billions or millions but even thousands it's really expensive so the computation time to retrieve those nearest neighbors is really expensive so that's where you that's when that's why a and m so approximate nearest neighbor algorithms were introduced um because yeah if you have like a real uh real-time application with a lot of data then k n1 skill and basically h and sw so using graphs basically to do this kind of uh yeah sure retrieving the nearest neighbors but like approximately is one way of doing it yeah i think it's amazing i mean doing the like i've been doing some tests where i'm doing the exact nearest neighbor and it really takes a crazy long amount of time so i yes i think that's such a huge part of it and so we could then come into like the modular design and user experience and so like one module of the modular design would be the these vector indexes the inverted uh object indexes for say the color is red the hospital name is etc the state is etc whatever these symbolic filters and then kind of going upstream to modules like near text pipelines question answering and then also it's kind of this um how this enables the integrations with uh gina and haystack is this kind of modular design right and um so i wanted to ask about the you've made videos on how to add custom modules and i want it kind of asked this topic about the extensibility of webv8 and adding custom parts to it yeah so first like talk a bit about how this modular design works so basically aviate itself is is a vector search engine vector database so without any modules it's a pure vector database so that means you need to upload your own vectors with your data and query it with your own vectors then you can use for example a buy encoder or like a retriever model like a bird model sentence bird model or resnet50 for images you can add that as module on top of wev8 to calculate the vectors of your data and of your search queries if you don't have them yet so um yeah we've yet offered some of these modules out of the box so we have our own trained modules which are very lightweight but there is also modules like you can use every model that is published on hugging face for example or open ai which have pre-trained models available to do this kind of inference and um yeah so you can use these modules for these models as an alleviate module with vvas um yeah then to your question you can also like not choose not to use any of these pre-trained models but use a model that you trained on your own or whatever um yeah so basically what you then do is you use basically design of a [Music] yeah if you have text you use design of a text factorization module in viveviate and instead of like talking to this module model from hugging face you talk to your own model via [Music] api calls yeah i think that the graphql design is so intuitive for how you can chain these things together and i definitely think that whole thing is really interesting and so i'm sorry to be uh sort of jumping around the topics a little bit but i think um so we've talked about kind of like we've eaten i think something that makes it so unique we've we have the um the vector index and how that plays with the inverted object index for adding these symbolic filters but then one other big part of like the we va data model that that i really think is interesting i want to talk about is the graph like data model and having relations between your data and how you can say uh uh what's the hackernoon or it's a wine was the wine was made in and then like a brewery or originally from say france and place like that so can you tell me about the graph like data model and how you can link things each thing can have its own h and sw and uh inverted index right with each of the classes that you'd link together with these um cross references yeah yeah that yeah um so we we then review like the the data model works like you have cluster classes so data classes which have a name for example a wine um and like this data class can have some properties with some value so property can be as you said or like it can be the name of the wine so you have class wine and then like a value name of the wine you have uh um whether it's um maybe like the type of grapes or whatever and then but you can also define like where it's coming from um where it's like who is the producer which color has it um so but yeah these uh properties can be a class on itself so if you have a lot of wines and you see that the countries for example is a limited list of course so you can also make a class out of this country you probably want to do that so then from the wine you can refer to which country it's coming from and um yeah this is basically a graph like model um because you can make close references between one and the other in a one-to-many um relationship kind of yeah way you think maybe we could sort of try to pitch how we could put the we va documentation into this kind of um this kind of data model so one way that i like it the most is with this kind of multi-modal sense where um say like using the twitter thing for example where you have tweet has image and then so you can separate out the like text vector index with the image vector index and i also see you could do that with like code also maybe like so if we have like a we've yet uh in the vva documentation say there is a tutorial and we want to say has code has text and then you have a code vector index so if you want to search just for a code snippet you can kind of isolate it that way is this making sense how i'm trying to describe this like could you take me through how you might decompose that data and then organize it in this kind of model yeah yeah multi-modal models are really interesting because what so if a machinery model is trained on both text and images they can represent it in the same vector space this means you can search by one modality for example text and find results in the other for example image or code so um yeah this is really interesting because the way we need we need to vectorize text is is like uh different from like how we look at images so what is captured in the image so combining these or in code so combining these into one model allows us to search through them by whichever modality we want and this is also something that we can use in the documentation later documentation search because the way you you need to index like encode text as vector is different from encoding code or images as vectors yeah i'm curious if you think this idea as well say we have these um so we have the we vva general slack where we see a lot of these questions about specific things and say we want to have like a class that is um slack conversations and then we have another class is the um the vva documentation or maybe like a code tutorial that would like walk you through an example of how to use it and then you maybe link link it that way so it's like slot conversation uh most relevant to documentation that kind of way of breaking down the data and then i guess like then thinking about how the how you can kind of apply the relational filters through it does that kind of thing make sense as a way to use the data model um yeah definitely so you could use the questions that are posted in slack channel or on stack overflow as uh yeah as part of your data model of course so you can like link those questions with the actual content where the answer is can be found in yeah yes yeah i think that whole thing is really interesting the all the different parts of the vba model and then the user experience design how the graphql lets you access these things i think all that is just really interesting so kind of um stepping out into more of a meta topic you've been an avid conference speaker can can you tell me about like what goes into uh sort of your preparation uh the the whole the whole kind of experience i guess is something i'm curious about is someone who's like kind of interested in doing this kind of thing as well and like you've traveled all over europe and in new york and so like what is that experience been yeah yeah it's been really great so i'm really happy that we can travel again like after all the the go with restrictions so actually i just started to travel since this year before that i did like a lot of meet-ups and conference presentations and like workshops online but i think this whole thing of being in person and being able to actually talk with people see their responses like answer their questions and learn about like their interest and motivation that adds so much value to um to whatever you're doing i think so i think like um yeah i get really excited to to speak in front of these people and explain them a really new concept um and then like seeing their reaction okay this could actually be something that i can be using uh and then talking about like possible use cases and so on um yeah in terms of preparation so um usually i'm doing like introduction talks to vector search so what is vector search um because this is a relatively new concept for most of the people so um yeah in that case i have like um some slice ready and then i adjust like just like the slides to to the conference i'm speaking at um to make it like fitting with the audience etc and um yeah i also sometimes give workshops and then i have like a bison jupiter notebook ready to to share with the audience that they can actually build their own vector search application within the hour basically so yeah that's just super exciting to do yeah let me ask a quick question on which one do you prefer between the overview or the hands-on workshop kind of thing oh that's a hard question um yeah i think the the workshop because i there i also start with uh like a small presentation because i want first people to know what they're actually gonna do um but then to see the excitement of people that they like do their first neural search basically their first semantic search and then like seeing the possibilities that it opens for them it's just yeah that's really cool yeah and i think that it comes back to the kind of hopefully there's a consistent theme i know we're going around the ebay topics but that user experience and i think there was i remember reading a techcrunch article uh with bob where it's like um it's like bob put their articles into techcrunch and then showed them how to do the queries right and because that graphql design it's so like you get it right away when you start like using the near text and i think that really ties the whole thing together with the user experience to putting on the workshop to people saying like oh i get what this is right and that whole kind of flow of it yeah yeah i think that's a really important uh topic so um if you are using especially a new technology like some like new yeah new technology new database you don't want to be held back by um yeah a difficult uh way of querying it by for example so the query language uh is like the api is the main interface for people so that that is the first thing that we need to like just like the documentation is we really need to have that uh intuitive and as simple as possible and we also so that also um so we v8 has client libraries like in python java go [Music] javascript um so that you can use vvate easily within your own applications and of course like the team like stefan and martin are working on that so that's also part of the whole developer experience basically that we want to have as high as possible yeah and i also think that um that semi console that lets you uh connect to the webv8 instance and then do the graphql queries without even uh writing python code or what and even in the python code i think it's you it's the same thing right where you just have like the three uh quotations string bracket and then you just paste in that same graphql but yeah the the console thing i think that is like a beautiful user interface for uh for getting started with it also yeah exactly yeah and also um so now that the community is growing we also see that people work like people start to contribute to eve but also contribute to examples or like uh some demo projects that are made with vva so we see people that made like a really simple user interface for querying images for example in a multi-modal way or a really intuitive user interface for doing it in text or having a movie recommender or search engine and i think like if you start to abbreviate and you look at this repository of examples it's really easy to get started and that's what really excites me yeah i mean i think that's such an interesting uh part of what we're trying to do with our next like you know few months of doing this is like how quickly can people learn webv8 how quickly can they get their data and how quickly can they understand how to query it and yeah so i think also just the whole thing about content getting people to dispute with webview and i think this is like such a great uh coverage of topics and i think from everything from the understanding of the graphql the user experience hearing your story of the time that we've ate and um design of modules extending it with other plugins like haystack gina hugging face open ai and how this whole thing fits together i think this is a great overview so thank you so much laura for uh for coming on the wii va podcast and explaining these things thank you connor for having me that's great ", "type": "Video", "name": "laura_ham_on_weaviate_user_experience__weaviate_podcast_21", "path": "", "link": "https://www.youtube.com/watch?v=gjJBYcYMB-o", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}