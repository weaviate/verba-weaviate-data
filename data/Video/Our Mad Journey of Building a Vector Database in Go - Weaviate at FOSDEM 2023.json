{"text": "Building a database from scratch is no small feat. Doing so in Go might just be pure madness. In this talk, Co-Founder & CTO ... \nit's four o'clock so let's time let'slook at our preview sorry now next talkI have been doing some math things andgo but building a database I honestlyhave strong respect for so next up isATM which is going to tell us everythingabout crazy Journeys and gothank you thank you yeah Welcome to ourmad journey of building a database andgo and um yeah it's pretty mad to builda database at all it may be even worseor even a matter to build a databaseum Ingo when most are built invery closerokayokay cool let me start over in case youdidn't hear it so hi my name is EtienneWelcome to our mad journey of building avector database in go so building adatabase at all could already be prettymad doing it in go when most are builtin C or C plus plus could be even evenmatter or even more exciting and wedefinitely encountered a couple ofunique problems that led us to Great uhCreative Solutions and there's lots ofshouts out in there and also a couple ofwish lists so we just released go 1.20and of course the occasional Madness solet's get one question out of the wayright away why does the world even needyet another database there's so many outthere already butprobably you've seen this thing calledchat GPT because that was that waspretty much everywhere and it's kind ofhard to hide from it and uh chat CPT isa large language model and it's it'sreally good at putting text togetherthat sounds really sophisticated and andsounds nice and sometimes is completelywrongum and so in this case we're asking itis it math to write a database and go Imight disagree with thatum but either way basically we're now ina situation where on the one hand wehave these machine learning models thatcan do all the cool stuff and do thissort of interactively and on the Fly andon the other side we have traditionaldatabases and those traditionaldatabases they have the fact becausethat's kind of what databases are forright so wouldn't it be cool if we couldsomehow combine those two so for exampleon the query side if I ask Wikipedia whycan airplanes fly then the kind ofPassage that I want that has the answerin it is titled the physics of flightbut that is difficult for a traditionalsearch engine because if you look atkeyword overlap there's almost none inum but a vector search engine can usemachine learning models basically thatcan tell you these two things are thesame and searching through that at scaleis a big problemthen there's that sort of chat GPT uhside where you don't just want to searchthrough it but maybe you also want tosay like take those results summarizethem and also translate them to Germanso basically not just return exactlywhat's in database but do something withit and basically generate uh more datafrom it and that is exactly where VBAcome in so V8 is a vector search enginewhich basically helps us solve this thiskind of searching by meaning instead ofkeywords without uh sort of losing whatwe've done in 20 plus years of searchengine research and now most recentlyyou can also interact with these modelssuch as chat cpt3 and of course also thethe open source versions of itso bb-8 is written in go is that a goodidea is that a bad idea or have we justgone playing madso we're not alone that's good so youprobably probably recognize these thingsthey're they're all uh bigger brands atthe moment than video it is going pastum and some of those vendors have reallygreat a blog posts where you see some ofthe like optimization topics and some ofthe crazy stuff that they have to do soif you've contributed to to one of thosesome of the things I'm going to saymight sound familiarum if not then uh buckle up it's gonnaget mad so first stop on our mad Journeymemory allocations and that also bringsus to our friend the garbage collectorso for any high performance goApplication sooner or later you're goingto talk about memory allocations anddefinitely consider a database a highperformance application that Lisaconsider V8 a high performanceapplication and if you think of whatdatabases do like in essence basicallyyou have something on disk and you wantto serve it to the user that's like oneof the the most important user Journeysin a database and here this isrepresented by just a number so it wentfor un32 so that's just four bytes ondisk and basically you can see these arethese four bytes if you parse them intogo they would have the value of 16 inthat 2 and 32 and this is essentiallysomething very much simplified that adatabase needs to do and it needs to doit over and over againso the standard Library gives us theencoding slash binary package and therewe have this binary.read method withwhich I think looks really cool it to meit looks like idiomatic go because ithas the Iota reader interface likeeveryone's favorite interface and youcan put all of that stuff in there anduh if you run this code and there's noerror then basically you get exactlywhat you want you could turn those sortof four bytes that were somewhere ondisk uh turned them into our in-memoryrepresentation off that un32so is this a good idea to do thatexactly like that well if you do it onceor maybe twice could be a good idea ifyou do it a billion times this is whathappensso for those of you who are new to toCPU profiles and go this is madness thisis pretty bad so first of all you see itin the centerum parsing those 1 billion numbers took26 seconds and 26 seconds is not thekind of time that we ever have in adatabase but worse than that if you lookat that profile we have stuff likeruntime mluk GC runtime memo runtime Madvice so all these things they'rerelated to memory allocations or togarbage collection what they're notrelated to is parsing data which is whatwe wanted to do right so how much timeafter 20 seconds did we spend what wewanted to dodon't know doesn't even show up in theprofileso and to understand why that is thecase we need to quickly talk about thestack and the Heapso you can think of the stackas basically your function stack so youcall one function that calls anotherfunction and then at some pointbasically you go back through the stackand this is very short-lived and this ischeap and fast to allocate and why is itcheap because you know exactly theruntime of your variables or the lifecycle of your variables so you don'teven need to involve the garbagecollector so no garbage collector cheapand fast then on the other side you havethe Heap and the Heap is basically thisthis sort of long lift kind of memoryand that's expensive and slow toallocate and why because and also todeal okay why because it involves thegarbage collector so if the stack is somuch cheaper then we can just alwaysallocate and stack right so warning thisis not real go please please do not dothis um this is sort of a fictionalexample of allocating a buffer of size 8and then we're going to say like yeahplease put this on the stack uh and thatis not how it works and for most of youyou probably say like this is prettygood that it's not that that it worksthat way because why would you want todeal with that but for me just trying tobuild a database and go so yeahsometimes like this this something likethis may be good or maybe not so howdoes it work go does something that'scalled Escape analysis so if you compileyour code with gcflax Dash M then goannotates your code basically and tellsuser what's happening there so here youcan see in the the second lineum that this num variable that we usedwas moved to the Heap and then in thenext point you see the byte stock readerwhich represents our io.reader escapedto the Heap so two times we see thatsomething happened to the or went to theHeap we don't exactly know what happenedyet but at least sir there's proof thatwe have this this kind of allocationproblemso what can we do well we can simplify abit it turns out that the binary uh orencoding binary package also has anothermethod that looks like this which isjust called U n32 on the little endianpackage and the it kind of does the samething you just put in the buffer on theone side so no reader this time you justput in the Raw buffer basically with thethe position offset and on the otherside you get the number of and the crazything is this one line needs no memoryallocations so if we do that again our 1billion numbers that took 26 secondsbefore now takes 600 milliseconds so nowwe're starting to get into a range wherelike this is acceptable for a day for uhfor databases and more importantly whatwe see on that profile the profile is somuch simpler right now there's basicallyjust this one function thereum and that is that is yeah it's what wewant it to do so admittedly we're notdoing much other than parsing the dataat the moment but at least we got sortof rid of all the noise and you can seethe speed upokay so quickly to to recapum if we say a database is nothing butreading data and sort of parsing it toserve it to the user then uh we do thatover and over again then we need to uhtake care of memory allocations and thefix in this case was super simple wechanged two lines of code and reduced itfrom 26 seconds to 600 millisecondsbut why we had to do that wasn't veryintuitive like that it wasn't veryobvious in fact I haven't even told youyet why thisbinary.littlend.read why that escaped tothe Heap and in this case it's becausewe passed in the pointer and we passedin an interface and that's kind of ahint basically that something mightescape to the Heap so what I would wishis yes this is not a topic that you needevery day you write go but maybe if youdo need this would be cool if there wasbetter educationokay so Second Step delayed decoding sothis is kind of the idea that wewouldn't want to do the same work twiceand we're sticking with our example ofserving data from disk but now while thenumber example was a bit too too simpleso let's make it make it uh slightlymore complex we have this nested arrayhere basicallyum a sort of slice off slice of view in64. and that's representative now for amore complex object on on your databaseof course in reality you'd have likestring props and that kind of things butjust sort of to show that there's moregoing on than a single number and let'ssay we have 80 million of them so 10million of the outer slice and theneight elements in each inner slice andour task is just to sum those up sothese are 80 million numbers and we wantto know what is the sum of them so thatis actually kind of a realistic databasetask for uh for an olap kind of databaseum yeah we need to somehow representthat data on disk and we're looking attwo ways to do this uh the first one isJson representation and then the secondone would be the sort of binary encodingand then then there'll be moreso Json is basically just here forcompleteness sake we can basically ruleit out immediately so when you'rebuilding a database you're probably notusing Json to to uh store stuff on diskunless it's sort of a Json database whybecause it's space inefficient so if youwant to represent those numbers on disklike space and base Json basically usesstrings for it and then you have allthese control characters you have likeyour curly braces and your quotes andyour cones and everything that takes upspace so in our fictional example thatwould take up 1.6 gigabyte and you'llsee soon that that we can do that moreefficient but also it's it's slow andpart of why it's slow is again becausewe have these memory allocations butalso the the whole parsing just takestime so in our example uh this took 14seconds to sum up those 80 millionnumbers and um yeah as I said before youjust don't have double digit seconds ina databaseso we can do something that's a bitsmarter which is called length encodingso we're encoding this basically asbinary and we're spending one uh in inthis case one byte so that's basically au and eight and we're using that as alength indicator so basically that tellsus that when we're reading this fromthis that just tells us what's coming upso in this case it says we have eightelements coming up and then we know thatour elements in this example is U and 32so that's four bytes each so basicallythe next 32 bytes that we're reading aregoing to be our eight inner arrays andthen we just continue then we basicallywe read the next length indicator andthis way we can encode the stuff sort ofin uh yeah in one contiguous thing thenof course we have to decode it somehowand we can do that because we've learnedfrom our previous example right so we'renot going to usebinary.littleindian.read but we're doingthis in an allocation freewayum you can see that in the length linebasically and um yeah our goal is totake that data and put it into ournested sort of go slice of slice ofslice of U in 64. andum the code here basically you see we'rereading the length and then we'reincreasing our offset so we know whereto read from and then we're basicallyrepeating this for the the inner slicewhich is just hinted at here by thedecode inner functionso what happens when we do this first ofall the good news 660 megabytes that'sway less than our 1.6 gigabyte before sobasically just by using a more spaceefficient way to represent data uh We'veyeah done exactly that we've reduced oursize also it's much much faster so wewere at 14 seconds before and now it'sdown to 260 millisecondsbut this is our mad journey of buildinga database so we're not done here yetbecause there's some hidden Madnessand hidden Madness is that we actuallyspend 250 milliseconds decoding while wespend 10 milliseconds summing up those80 million numbers so again we're kindof in that situation where we're doingsomething that we never really set outto do like we wanted to do somethingelse but we're spending our time on onum yeah and doing something that wedidn't want to do so where does thatcome from and the first problem isbasically that what we did what we setout to do was fought from the get-gobecause we said we want to decode sowe're basically thinking in the same waythat we're thinking as we were withJason we said that we want to decodethis entire thing into this go datastructure but that means that you see weneed to allocate this massive sliceagain and that also means that we needto in each inner slice we also need toallocate again so we're basicallyallocating and allocating over and overagain where our task is not to allocateour task was to sum up numbersso we can actually just simplify this abit and we can basically just not decodeit like While We're looping over thatdata anyway instead of storing it in anarray we can just do with it what weplan to do and in this case um thiswould be summing up the data sobasically getting rid of that decodingstephelps us tomake this way faster so now we're at 46milliseconds of course our our footprintof the data on disk hasn't changedbecause it's the same data that we'rereading we're just reading it in aslightly more efficient wayum but yeah we don't have to allocateslices and also because we don't havethese like nested slices we don't havelike slices that basically have pointersto other slices so we have better memorylocality and now we're at 46milliseconds and that is that is cool so46 milliseconds is basically the timeframe that can be acceptable for adatabaseokay so quickly in recap we immediatelyruled out Json because it just wasn'tspace efficient and we knew that weneeded something more space efficientand also way faster binary encodingalready made it much faster which isgreat but if we decode it up front thenyeah we still lost a lot of time and itcan be worth it in these kind of highperformance situations if you eithersort of delay the decoding as late aspossible until you really need it orjust don't do it at all or do it in sortof small parts where we need it no wishlist here but an honorary mentioned sogo 1.20um they've actually removed it from thefrom the release notes because it's soexperimental but go 1.20 has support formemory Arenas the idea for memory Arenasis basically that you can bypass thegarbage collector and sort of manuallyfree that data so if you have somethingthat you know has the same sort of lifecycle then you can say okay put it inthe arena and basically in the end freethe entire Arena which would sort ofbypass the garbage collector so thatcould also be a solution in this case ifthat ever makes it like right now it'ssuper experimental and they basicallytell you we might just remove it sodon't use itthird stop is something that when Ifirst heard it almost sounded like toogood to be true so um something calledsimdi I'll get to what that is in asecond but first question to theaudience who here remembers this thingraise your hands Okay cool so you'rejust as old as I amum so this is the the Intel Pentium 2 uhprocessor and this came out in late 90sI think 1997 and was sold for a coupleof couple of years and back then I didnot build databases definitely not in gobecause that also didn't exist yet butwhat I would do was sort of try to play3D video games and I would urge myparents to to get one of those newcomputers with an Intel Pentium 2processor and one of the arguments thatI could have used in that discussion washey it comes with MMX technologyand of course I had no idea what that isand it probably took me 10 or so moremore years to find out what MMX is butit's the first in a long list of Cindyinstructions I haven't explained whatCindy is yet but I will in a secondum some of those especially the one inthe in the Top Line they're not reallyused anymore these days but the thebottom line like avx2 and AVX 512 youmay have heard them in in fact for formany open source project they sometimesjust sort of slap that label and read melike yeah yeah has avx2 optimizationsand that kind of signals you yeah wecare about speed because it's like lowlevel optimized and aviate does theexact same thing by the wayso to understand how we could make useof that um I quickly need to talk aboutVector embeddings because I said beforethat vva doesn't doesn't search throughdata by keywords but rather through itsmeaning and it uses Vector embeddings asa tool for that so this is basicallyjust a long list of numbers in this casefloats and then a machine learning modelcomes in and basically it says dosomething with my input and then you getthis Vector out and if you do this onall the objects then you can compareyour vectors so you basically can do avector similarity comparison and thattells you if something is close to toone another or not so for example thequery and the object that we have beforeso without any CMD we can use somethingcalled The Dot product the dot productis a simple calculation where basicallyyou use you multiply each element of thefirst Vector with the same correspondingelement of the second vector and thenyou just sum up all of those elementsand we can think of this likemultiplication and summing as twoinstructions so if we look out for shoutout here to the the compiler Explorerwhich is super cool tool to see likewhat your go code compiles to we can seethat this indeed turns into twoinstructions so this is a bit of a liebecause there's more stuff going onbecause it's in the loop Etc but let'sjust pretend that indeed we have thesetwo instructions to multiply it and toto add itso how could we possibly optimize thiseven further if we're already at such alow level well we can because this isour mad Journey so all we have to do isintroduce some Madness and what we'redoing now is a a practice that's calledunrolling so the idea here is thatinstead of looping over one element at atime we're now looping over eightelements at a time but we've got we'vegained nothing like this is we're stilldoing the same kind of work like we'redoing 16 instructions now in a singleLoop and we're just doing feweriterations so by this point nothinggained but why would we do thatwell here comes the part where I thoughtit was too good to be true what if wecould do those 16 operations for thecost of just two instructions soundscrazy right well no because Cindy I'mfinally revealing what the acronymstands for it stands for singleinstructions multiple data and that isexactly what we're doing here so we wantto do the same thing over and over againwhich is multiplication and thenadditions and this is exactly what theseCindy instructions uh provide so in thiscase we can Multiply eight floats withother eight floats and then we can addthem upso all this perfect here maybe notbecause there's a catch of course or notJourney how do you tell go to use theseavx2 instructions you don't do you rideassembly code because go has no way todo that directly the good part is thatassembly code integrates really nicelyinto go and um in the in the standardLibrary it's used over and over again soit's kind of a standard practice andthere is tooling here so shout out toAvo really cool tool that helps you uhbasically you're still writing assemblywith uh with Avo but you're writing itin go and then it generates the assemblyso you still need to know what you'redoing but it's like it it protects you abit so it definitely helped us a lotso Cindy recap um using ABX instructionsor other CMD instructions you canbasically trick your CPU into doing morework for freebut you need to sort of also trick go touse assembly and with this tooling suchas Apple it can be better but it wouldbe even nicer if the language had somesort of support for it and you made mysaying and now okay this is this mad guyon stage that wants to build a databasebut no one else does and needs that butwe have this issue here that was openrecently and unfortunately also closedrecently because no consensus could bereached but it comes up back and backbasically that go users are saying likehey we want something in the languagesuch as intrinsic so intrinsics arebasically the idea of having high levellanguage instructions to do these thesesort of AVX or SMD instructions and C orC plus plus has that for exampleone way to do that and maybe you'rewondering like okay if you have such aperformance hop path like why don't youjust write that in C and you see go orwrite it in rust or something like thatsounds good in theory but the problem isthat the call Overhead to call C or Cplus plus is so high that you actuallyhave to Outsource quite a bit of yourcode for that to to pay off again so ifyou do that you you basically end upwriting more and more and more in thatlanguage and then you're not writing goanymore so personally that's not or itcan be in some ways but it's not alwaysa great ideaso demo timeum this was gonna be a live demo andmaybe it still is because I preparedthis running nicely in a Dockercontainer and then my Docker Networkjust broke everything and it didn't workbut I just rebuilt it without Docker andI think it might work if not I havescreenshots basically thatum I do a backup so example query hereI'm a big wine nerd so what I did is Iput wine reviews into vv8 and I want tosearch them now and one way to do it toshow you basically that the keyword thatyou don't need a keyword match but cansearch by meaning is for example if I gofor an affordable Italian wine let's seeif the internet connection worksit does so what we got backum is basically this this wine reviewthat I wrote about a barolo that Irecently drank it and you can see itdoesn't say Italy anywhere it doesn'tsay affordable what it says like withoutbreaking the bank so this is a vectorsearch that basically happened in the inthe background we can take this one stepfurtherby uh using the generative side so basethis is basically the the chat GPT partum we can now ask our database based onthe review which is what I wrote when isthis wine going to be ready to drink solet's see you saw before that was thefailed query when the internet didn'twork no no it's actually working sothat's niceum and here in this case you can seethat so this is using open AI but youcan plug in other tools can plug in opensource versions of it this is usingopenai because that's nice to be hostedat a service I don't have to run themachine learning model on my laptop thenyou can see it tells you the wine is notready to drink yet we will need at leastfive more years which is sort of a goodsummary of this and then you can seeanother one is ready to drink right nowit's in the perfect drinking window sofor the final demo let's combine thosetwo let's do a semantic search toidentify something and then do an AIgeneration basically so in this casewe're saying find me an aged classicRiesling best best wine in the worldracingum and based on the review would youconsider this wine to be a fruit bomb solet's have sort of an opinion from themachine learning model in it and here wegot one of my favorite wines and the themodel says no I would not consider thisa fruit bomb while it does have somefruity notes it is balanced by theminerality and acidity which keeps itfrom being overly sweet or fruity whichis um if you read the text like this isnowhere in there so this is kind of coolthat the that the model was was able todo thisokay so let's go back now with the demotime by the way have a GitHub repo withlike this example so you can run it toyourself and um and yeah try it outyourself so this was our mad journey andare we mad at go are we mad to do thiswell I would pretty much say no becauseyes there were a couple of Parts wherewe had to give get really creative andhave to do some some yeah rather uniquestuff but that was also basically likethe Highlight Reel of building adatabase and all the other parts like itdidn't even show the parts that wentgreat like concurrency handling and thethe powerful standard library and ofcourse all of you basically representingthe Gopher Community which is superhelpful and uh yeah this was my way tobasically give back to all of you so ifyou ever want to build a database or runinto other kind of high performanceproblems then maybe some of thoseexamples helped you and if you now wantto try out bb8 you can see it on bb8ioor the GitHub is vb8 vv8 you can followme on Twitter atEtienne di or you can follow viviatedvv8io I don't have a mastodon yetbecause that kind of seems to be the newthing but I was busy writing assemblycode so I had no time to create one yetum yeah that is our mad Journey thankyou very much[Applause]cool if you have yeah I see a questionI'll try to run towards youI've been running all day so it might beslowhi um thank you for for your talkum quick question about a compression uhyou talk a lot about data sizeum have you waited the pros and consbetween the compression to reduce thesize and so the the bandwidth needed toread the data and then the penalty ofdecompressing yes yes absolutely sobasically the the uncompressed examplewas sort of the simplified versionbecause 25 minute talk and had to cutdown in real life definitely compressionespecially like using a un 64 in thisexample most of the bits are probablygoing to be zero so you can gain a lotfrom from a compression and we have aninverted index also in in vv8 so we havethese like kind of posting lists andthey're very similar because they theystart from from zero basically go up sothere's lots of overlap and lots ofgains to be made with compressionum yeah maybe something for for our madJourney part twoyeah so my first question is uh doesn'tgo itself leverage this simd things itseems like it should compiler should dothese thingssort of okay-ish the problem isbasicallyum typically with like the AVX 512 wherewe wanted to do eight things at oncethis is specific to some CPUs and the gocompiler doesn't doesn't do it as welltypically from the way that the gocompiler does it I could get like a twotimes speed up but never more sort ofnever in the uh yeah so Realms of eighttimes but in general and this is not somuch a go specific thing like handoptimized uh um yeah assembly or lowlevel Sim D is most likely going to befaster than what a compiler do simplyfor the fact that you know exactly whatyou want to do like how long the videothey're going to be in this kind ofstuff whereas the compiler basically hasto guessand the second question is like did youtry any other encoding like uh somethinglike uh there was something called groupparent I'm not sure we are using floatshere but there are other encodingalgorithms which might save the spacemore like yeah yeah this goes in thesame direction basically as the thecompression question so definitely morethis is sort of a I don't want to say afictional example but it's sort of asimplified example for the the purposeof a slidetrack", "type": "Video", "name": "Our Mad Journey of Building a Vector Database in Go - Weaviate at FOSDEM 2023", "path": "", "link": "https://www.youtube.com/watch?v=K1R7oK2piUM", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}