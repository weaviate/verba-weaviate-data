{"text": "This meetup by Etienne Dilocker is all about the horizontal scalability of the Weaviate vector search engine, a feature that became ... \nthanks okay then officially welcome totoday's meetup that has the titlehorizontal scaling uh which is yeah thethe 1.8 release that we released todaywhere we released the release candidatetodayand really today is going to bejust about deploying vv8 in a cluster ina horizontally scaled fashion uh on a ona kubernetes cluster and uh the lastmeetup that we had was a lot of theoryand i'm sorry the last meetup that iheld was a lot of theories sort ofaround all the the architectureum that makes up vvate and today is sortof the counterpart to that like umwe have taken all of that architectureand we have put it into vba and now wejust want to want to use itso today also marks uh the as i justsaid the the day that we released the1.8 uh release candidate which is ithink one of the biggest if not thebiggest umpull request that we merged on bv8 sofar so 115 um commits there uh overthree months in the makinguh yeah lots of lots of effort lots ofof help from a lot of people very coolstuff in it and something that i'm alsosuper proud of is we when we started ourarchitectural roadmap and i'll get tothat in a second uh one thing that wesaid is that we will release this by theend of q3 and today is september 30thand hey we actually made that and whenthat when does that ever happen insoftware development that you estimate adate and um yeah and it actually worksoutso um let me quicklyas i said today is going to be mostlysort of very practical but i want tovery quickly sort of recap which issix slides or so a very quickly recapwhere we are on that roadmap so westarted um the first thing was was justimproving the performance of our hnswimplementation that we had way back inversion 1.4um and then we implemented the ls entrystorage which made importing a lotfaster becauseactually both of those releases madeimporting a lot faster uh but 1.5 wassort of the point where we said likeyeah um riding is no longer thebottleneck and and this is sort of thethe start to our scaling roadmap becausewe saiduh scaling horizontallyonly makes sense if what we're scalingis already efficient because otherwisewell what what good is it running onfive nodes if you could get the sameperformance out of a single note sothat's how we started this roadmap umsaying sort of yeah first we want to getthe max out of a single node and then wewant to scalehorizontallyfor that uhwe had the sharded indices milestonewhich was completed sometime in augustbut it wasn't actually released yetmostly because the added value ofcharting your indices really onlybecomes apparent when you have a naturalcluster which is the current milestonetoday we released one 1.8 um or therelease candidate for 1.8which has horizontal scaling uh in in umin parentheses here without replicationthat's the next step on the roadmap andi'll get to the the differences whatthat means in a secondumyeah so so this roadmap is still ongoingbut today um we have the first releasethat's horizontally scalable andreplication and dynamic scaling iscoming a bit later thenso yeah uh that brings me to to talkingquickly about uh sharding versusreplication and maybe the limitationsthat we have here and that is also aperfect point to switch over to our docswhich have also been updated for therelease so i'm on the if you start outuh you end up on the the current releasei'm on the the 1.8 release already whichbecause it's just release candidate youget this it's wearing a warning here umyeah we've revamped this page andthere's a lot more i'm not going to gointo this into detail now but um there'sa nice new overview about thearchitecture and we have a whole newsection about scalingand in here we have sort of the the twomajor motivationsof um why you would want to scale youryour bb8 cluster um the first one andthis is sort of the one that i'm mostlygoing to be showing todayum is if you want to have a largerdata set size than a single node can fitum the motivation is basically to chartyour data set onto multiple nodes andthen essentially if umyeah if onenote could only fit i don'tknow so so today an article came out byone of our community members who isrunning i think 60 million objects 60million vectors on a single node solet's for the sake of arguments say that60 million is the limit that one nodecould handle then you could add twonodes and you could have 120 million andand so on so this is the the majormotivation um of sharding your datathe second motivation would be higher aquery throughput so if you have a singlenode and let's say you can handle makingthis up completely a thousand queriesper second on that single notebut your traffic increases then themotivation would be to scale to matchthat umthat higher throughput and that is whatwill be possible with replication sothis is something that's that'simportant to knowas you chart your data setyou don't actuallygain anything on the querying side butyou gain stuff on the importing side soso um you have more resources to importso that gets faster but not on querywith replication that's going to be theother way aroundand then the the third one which is alsoa benefit of replication is highavailability so if you have your dataset running on um yeah let's sayreplicated on three nodesif one of those nodes nodes failthen you can still umyeah use the cluster normally the onlylimitation is going to be thatthroughput is slightlylowerbut then you could scale sort of for ahigh availability and we also have asummary of thatover here in that section where you cansay advantages when increasing shardingyou can run larger data sets and you canspeed up your importsthe disadvantage is that even as you addmore resources to your cluster you don'tactually improve the query sideand then the other way around forfor replication the system becomeshighly available and you can scale yourquery side linearly where thedisadvantage is that even though you addmore resources to your cluster theimport actually doesn't speed up becausenow it has to be imported or replicatedontomultiple nodes so this is the the sortof intro to that there's a lot morethings that we can get into but yeah iwouldn't tackle those as part of thelive demowhich yeah which will dive right inbasicallyum so for the first part let's let's seei have prepared a kubernetes clusterum and in there i've created a namespaceand this namespace is currentlycompletely empty so if i look at all theresources in that first connect alwaystake some time let's see if the clusteris still reachable that would be nicethat really took long i think subsequentqueries should be much faster um yes soi have a kubernetes cluster and thisnamespace is completely empty and now iwant to deploy bb8 into that namespacefor this we have a new release of ourhelm chart which let me also show youthatthere we gohelm is the the german word for helmetso i always get like these helmet thingshere but i actually want the helm chartuh which has releases so there we go wehave let's also release candidatebecause it points to the vivian releasecanadaum for 14 which works with horizontalscalability so i've already downloadedthat so you can see here i have thisthis v8 pgc which is just the latesthome chart and i have a very very simplevalue cml file um which is basicallymeant to to deploy this so i'moverriding a few things i'm overwritingwell actually i don't even need tooverride this anymore because that's nowpart of the release that i had to duringdevelopment and i have replicas and iactually want to start with a singlereplicaand then right here this is just somesome firewall configuration so i'mbasically whitelisting my own ip addressin the firewalland uh yeah we're starting with a singlereplica and this this is tiny this isnot a size that makes a lot of sense inin real life probably with just two cpuson a single node but for now for demopurposes that's absolutely absolutelyperfect so this is my values yaml and ihave a deploy script it's almost almostdoesn't make sense to call it the scriptbecause it's very simple we're basicallyjust running this item potent uh commandto upgrade in my namespacewith that value cmo um yeah so sorrythat's a release name and down here isthe the namespaceso let me simply run thisand we should deploy a vba cluster thatcurrently has a single node so ignorethose warnings i'm running with the thegke autopilot cluster so basically as ideploy more stuff on that cluster itautomatically provisions uh newinfrastructure in the background whichis kind of cool actually so if we lookatthe parts so it's okay it's just maybethis for for cube ctl maybe easier tounderstand if they actually type thoseout uh so we have currently a single umv8 note right here which is currentlybeing provisioned as you can seecontainer creating so this is mostlyjust the kubernetes cluster which has toto download uh the imageand maybe just watch thiswhen it's actually it's actually runningalready so that's cool so just to toprove that this works we can look atthe service definition and here we see aservice that has an external iptake a look at that and now if i contactthisthere we go so this v8 instance isrunning and right now it has a singlenode which is not the point of thismeetup so let's take our values yaml andas with any configuration that youchange in um your values yaml that willbe applied once you deploy it again solet's say we go for three replicas forexample so let's do that and i'm justrunning my deploy scripttakes a secondclean that up and now again if we watchcube cpl get pods you will see that theyare being created in a stateful set inan sort of ordinal fashion so we'restarting with the vba 0 and then we'recurrently creating instance bb81and once that is done and ready then itwill create bb83 so let's just wait forthat for a secondsomething to note while these are um soyou can see the one is pending right nowthat's that means that the cluster needsto provision the infrastructure was veryfast uh one thing to noteabout um dynamic scaling so as we saidon the roadmap dynamic scaling isactually not yet not yet present so letme go to theroadmapyeah dynamic scaling is actually thelast point on the roadmap sosome things of dynamic scaling so asyou're seeing right now i'm actuallyadding notes when the cluster is alreadythere that already works but there aresome limitations basically as rule ofthumb if there's no data in the clusteryet you can do whatever you want ifthere is data in the cluster and youincrease its size that works however ifyou um there's basically no way yetto to drain a node or to tell a nodethat is being decommissioned and thatwhatever load is on the node should bemoved to a different node so that issomething that will come in thedynamic scaling milestone so basicallyif you have data imported on a threenode cluster and you reduce it to twonodes that that will break at the momentbecause that's yeah not not the dynamicscaling part yet um but coming back toto um our cluster which is now ready sothat was basically all we had to do andwe see all of this is ready and ofcourse you don't have to worry aboutsomething like such as load balancingbecause it's running on kubernetes sothe service that we have in front of itwill alreadyload balanceacross those three uh deviate notesthere their pods in kubernetes speak inin v8 speak their their notes becausethey're not tied to two kubernetes thatjust makes it much easierso if we get that service againhere it has that external ipand that basically has the load balancerin front of it so if we contact it againwellthere's nothing in it yet so if we lookat for example the schemayou can see right now it's empty solet's import something into that let'sget started with we have thenews publication data set this verysimple data set um we run that also inour documentation with slightlydifferent configuration but that doesn'tmatter but we can just use that and wecan just import it so let me justquickly import that that is python 3importthat point then i always need to checkwhat the order is deviate url firstthat onecache here it's cache english and batchsize i don't know let's go for somethinglike 128.okay so that is running that isimporting okay now i need adifferent uh terminal tab hereum so now what we can do let's i want toshow something um let's quickly look atthese email that we have yeah schema isthere cool and i know that one of theclasses in that schema is called articleso let me take a look at this onewe maximize this so here you see adifferent difference to previous vbaversions first of all we have this wholesharding config thing that didn't existbefore but more importantlyi didn't change anything about my importscript this is exactly the same importscript that we have been running um onyeah on regular pv8 instances but youcan see that it said the desired countand also the actual count for shards tothreeso the desired and actual count at themoment is always the same because umyeah charts are basicallyor the creation of shards is basicallyatomic at the momentin the future this is going to be anasync process with regards to toreplication for example so let's say youhave a replication factor of one andthen you set you increase this to threereplicas then data has to be replicatedfrom thoseone node to the the other nodes so thatthat is basically when that processbecomes asynchronous right now it'ssynchronous so desired and actual is thesamehowever what i wanted to say isbasically um that yeah it automaticallyadjusted the amount of shardsto my cluster size and in the seconddemo that i'll show later we can alsosee that it doesn't have to be that wayyou can also control this if you don'twant to set it to that size okay ideallyi've been talking enough for this tofinish yeah that's cool so um let's takethat urland let's maybe just connect to thatcluster and for this we can take the vv8consoleyep that downgrades because it's not anhttps connectionokay still the same urlcool so that should be i probably haveit in my history somewhere but let'smaybe just start from from scratchso let's just send a query any kind ofquery as you're used to sending to vvaso let's go forarticle and then we cango for a title and summary maybeand then to make it interesting let'sset itlimit and let's set a near text so thatbasically means this is going to be avector search because i'm running withthe contextionary you can of course alsorun with transformers for simplicitysake so we don't need gpus in this demoi've just picked the contextionary whichworks fineand i've asked bob before for an exampleuh that because he uses this data set alot and he said housing prices is onethatthat he typically uses so let's go for avector search of housing prices uh thecontent itselfdoesn't actually matter just to to sortof as a proof of concept it does findstuff relating to to house it housingprices and uhhousing shortages etc so the vectorsearch is working uh the part that iwant to show is basically if i run itagain it's still working and the theinteresting part here is because we'rerunning with three nodes in that clusterand we have a load balancer in front ofit we cannot predict which node is hiton that search but if i run it again andagain and again and again it will alwaysreturn the same results so basically nomatter which chart we hit whether thatchart has all the data or parts of thedata deviate internally makessure that it contacts all the othercharts that umyeah that have data or um that it needsdata from and this is also why we saidbefore in the limitations of shardingthat the queries per second actuallydon't go up if you increase the theamount of chart even even if for eachnew chart you add a new physical nodethat has new hardware umbecause your data set is now spread ontodifferent nodeswe don't know which node contains yourdata um and andin this simple case and this is maybealso a good point to to talk about thisthere are a few more other fields thatwe see hereso right now we are sharding on the keyid which is the with the underscore thisis the internal or not the internal idbut the the id umthe the uuid that every um object in vv8hasand we're currentlyhaving a strategy which means hash soessentially we're creating a hash fromthe idand there's just a specific hashfunction in this case it's a murmur 3and i think it's a 64-bit hashtheinteresting part about this is so soright now this is fixed and this isactually immutable but in the future andthis is why it's in the country the planis to um open that upand so that you could for example uh setthis to a different field umso um sorryif for example you have a specificproperty in your data and you know thatyou usually set a where filter on aspecific property you could set thathere and then you could already chartaccording to that and then you could bein situations where basically a singlechart can answer your uh queryand then you do actually benefit fromfrom sharding as well with regards tothe throughput in this case right nowbecause the ids are basicallymeaningless from the perspective ofsuch a searchright now i just have to hit all threeshards and basically combine the resultsumokay that speaking of combining resultsthat's basically the perfect segue intoan aggregationso let meaggregate an article again and let'smaybe start withjust a count yeah account count is alsoaccount isn't actually that interestingfor what i wanted to show let me justquickly get this what i wanted is ithink there's a propertyconvert countyeah which is just an inf so this is notvva counting anything that is just aproperty in that data set where eacharticle has the specific word conceptand here let's say we go for i don'tknow a maximum and a minimumumso if we run that so first of all if irun it again same result that'simportant because we never know whichwhich node is being umwhich node is serving that querybasicallyumyeah so so if we have something like amaximum or a minimum that is easy toaggregate like one chart will say myhighest number is i don't know 15 000one chart will say my highest number isuh 100 and the next one will say myhighest number is 168016852 this is easy to aggregate formaximum we just pick the highest forminimum we pick the lowest et ceteraif we go for something like a mean thevalue becomes being an approximate valueso what we're doing in the case of amean for example is we simply take themean of each chart's result which wouldbe the real mean if um data wasperfectly evenly sharded but in reallife it's never going to be perfectlyeven so this is something you have tokeep in mind if you're working on asharded data set the mean is going to bean approximate volumebutyeah the important thing is no matterwhich note you hit you're always goingto get the real resultsso let's come backhere this was the first demowhich was cool but also only a tiny tinydata set soas we saw with itno aggregatearticlemetacountyou can see this is really just just a3500 data points in this data set so ialso want to demo a second case with alarger data set and especially on thisone i want to show you thatas you add more shards and therefore addmore resources to your clusterum you also increase the import speedso for this let me just switch mykubernetes context to a second namespacewhich i already prepared and here i'vealready actually deployed vbaand in this case if we take a lookthree attemptsif we look at this specific namespace wecan see that we actually have 12 v8nodes running so they're stillrelatively small but there's 12 nodesjust to show that yeah you canscale them as you wish there's also animporter job which was still runningfrom my test before let me quicklydelete thisrate it againso in thisin this cluster um i also have so thesame thing applies here i don't have aservice herethis has a different ipso just to show before we startnot localhost i'm so used to typinglocalhostum if we look at the schemathis instance is currently empty so ifit has no schema it also can't have anydata because data is held in in classesso to showan import on a larger cluster i haveprepared a very simple import job whichruns a script so let me go for thisimport outstanding that is the wrong onethat isfolder let me go forlet me go for this kubernetes job justthe kubernetes job if you're if you'renew to kubernetes a job is basicallyjust a pod that just runs once or ifit's a cron job and it runs like a crownjob but basically um it's not likeonce it finishes kubernetes doesn't makesure to restart it which is umyeah i'll post to the deployment orstateful set where if it goes downkubernetes should make sure that it goesback up againthis script basically just randomlygenerates vectors or objects that have aa vector attached to them which israndom and i can just configure it i canask it to have this many dimensions thisis just where it shouldset to send it to total size which iscurrently set to a hundred thousandpatch size set to one thousandand charts which i'm going to set to onefor the first example so even though ihave so this is i said this before umthat uhthe the shards are picked to the size ofthe cluster unless you explicitlyconfigure them so even though i have a12 node cluster right now i'm explicitlytelling this class should only uh bechart orshould only have a single chart whichmeans it can only live on a single noteand i'm doing this on purpose so then wehave a baseline comparison basically solet me cube ctlapply minus f import job that createsthe job and now if we look at ourpodsand we can see oh it's already runningthat means it was scheduled on a notethat already had the the image locallythat's niceso then we can just attach to the logswhich is uh let me type it out cube ctllocks minus f and the name of that thingand then we can see it's currentlyimporting it's not super fast because ofcourse these these nodes are sized uhvery small it only has i think in thiscase four cpu so two more than in myprevious exampleand as you can see basically as with anydata set in the beginning the thebatches are basically artificially fastbecause there's no not much dataimported yet um but as this imports ithink this willsort ofeventuallygo to around five seconds or somethingper per batch and then it will stayrelatively constant at that rateum i'm not going to keep it running allthe timeum because i think this job in total ithink it would take about i don't knowthis thing about six to seven minutes orso to completeum but what i want to do is connect tothat bb8 instance and just show you thatstuff is happening just to sort of showthat it's umyeahnot just printing random stuff butactually importing something so let'slog out herelet's log out into a login into this oneand then let's run a simple aggregatequerycall the demo class yeah let's justcount itand there we go we currently have thirtynine thousandand forty thousand now so batch size wasone thousand so that makes sense and ifwe look at ourlogs againthey should now be at yeah forty percentso i think yeah the first one starts atzero percent so the highest would be 99so that that matches perfectlyand yeah as i said sort of as these uhbatches will average around five secondseventually i think it will take six toseven minutes maybe maybe eight minutesor so to complete um but i'm actuallygoing to stop it becausesomething lead oh it's very delete thejoblet's delete itokay and now let's modify that same joband as i saidall we have to do and this is i thinkalso something that's that's really coolall that we have to do to make use ofthat cluster is just change theconfiguration in the in the classandoh by the way i haven't shown sort ofwhere this is in the class um yet onthis one i'll show you um when this isrunning right now so for now let's maybego for for a chart i'm not going to gofor the full 12 yet just for for eightfor nowum and then let's apply that job againand other job by the way um firsti need to delete the jobuh no i think it already did yeah allright good so i can apply it the jobitself will delete every v8 classum so it always startsbasicallyso if we look at the pods it's alreadyrunning again that's niceso let's attach to itand now you can see this is way fasteralready so we're now talking about batchtimes they're taking yeah i don't know300 milliseconds or something becausewe're now using a cluster of eight nodeswhere previously we were only using asingle note so also let me go here againand show you and look we've alreadysurpassed the the other oneso yeah this one i think we can actuallylet that finish because it's going togoing to be finished veryso let's wait for yeah another i don'tknow 20 seconds or soso funny thingas i um sort of tried this out and thisis also the explanation for why i wentfor eight shards right now not for thefull 12.umas i tried this out yesterdaywe found out that these batches arestarting to become so large that thebottleneck right now is actually notdeviated itself but we've had clients sowe tested with this is running with thego client because it's a bit moreefficient than the python clientbut we're seeing right now thatbasically in the batch where you sendthe entire data which in this case is a300 dimensional vectors so that's quitea lot of data that's being sent thereand you get the response in the responseyou get the same data backbecause um well it's just sort of thethe idea of creating an object then youget the same object back because somefields might have beenfilled by by vv8 for exampleand this is currently entirely done injson and yesterday i uh checkedthe size of i think a batch of tenthousand that is just running a thousandand for ten thousand objects the batchwas actually 27 megabytes and turns outat 27 megabytes just sending the batchover http and sort of parsing the jsonis actually quite slow so this isbecoming the bottleneckand this is basically um yeah sort ofpreventing the times from going downlinearly so if we run this same jobagain so let'sdeleteimporterand run it againthis timewith the full 12 shards so inideally sort of from a vva perspectivenow we're adding 50 more resources sothis should in theory uh speed it up uheven faster but it doesn't actuallybecause the bottom line right now is thethe client so um that's why i pickedthese these steps of sort of one eightand no twelve because between one andeight it's it's still more or lesslinear but as we sort of add more powerto this clusteryeah the client becomes the bottleneckso let'skeep cal applying my job againand let's take a look at it okay thistime it landed on a note that didn'thave the the image locally yet it seemsso it actually has toactually downloading uh but now it's onand running that's goodso if we attachto the logs of that one againand you can see it is a bit faster umbut yeah it's definitely not 50 fasterso right now there is um yeah sort of asaturation in thisexample which is in no wayrepresentative but just for for for thisparticular umcaseum sort of around uh eight no eightnotes in this case um so let's see ithink the total time on the other onewas 52 and yeah this is barely anyfasterthis is48 so adding 50 more resources in thiscase didn't actually pay offbut as said this is something that'scurrently the limit is in the client sowe measured the time of sort of fromvba's perspective how much work it hasto do as opposed to the clients andwe're seeing that the clients are thebiggest overhead which is something wecan easily fixvarious ways compressionmaybe a binary protocol on the requestum what would probably also help is justto make the the response maybe a bitmore efficient that the vector wouldonly be sent to the flag is set orsomething like this um but yeah the coolcase is the vv8 cluster itself it'sstillyeah it still works very nicely evenwith 12 notes one other thing that iwanted to show on this particular onebefore we wrap up um i set the um yeahthe sharding configuration in my scripti wanted to show the effect that iactually had andlet me quickly do i still have the iphere no to get that againserviceml classhere you can see um that because i saidthat the charts to 12 minutes here theyended up at 12and if we were tochange that again to a different valuelet's just go look for thejob and let's maybethat back to oneand apply it againand now we need to wait for it toactually runit's already running that's cool so nowwe canlook at the classic and and now we canseethat it's just one so that was basicallythe change that i was doing a pointbeing thatjust in your configuration in yourschema configuration that you're alreadysending you now basically have controlover how that class should be spread umamongst your your vivian notesyeah that wraps up the second live demoandas you can see herei'm still importing now on a single uhnotemuch slower now than it was on the onthe cluster um yeah before we move totwo questions because we have still havea bit of time i just want to veryquickly walk you through it through thenew documentation because well it'sactually not new documentation it's justa few new pages in the architecturesectionum but yeah as we said we have theroadmap which i talked about in thebeginning alreadyand horizontal scalability is nowreleasednext up is replication which i think thebenefits we outlined beforealso if we go to the overviewwe have this this graphic here which ithink is also really nicely shows how ohwow that'sthere we go umshows sort of how everything tiestogether in vb8 especially with regardsto modulesumalsoyeah from a scaling perspective so ifyou were to run a module that needs gpusfor examplethat module runs in its own container soyou could run that on separate hardwarewhich is gpu accelerated or the vb8 corewhich is now horizontally scalableas the stateful part is completely cpuonlyspeaking of cpu let me zoom in a bitagainof cpus and resources we also added aguide on umsort of how tohow tosize your cluster or how to size yournodes that's that's the same thing so aquestion that that i received today wasif i'm running vva in a cluster um howdoes that change my my um yes or i thinkit was specific to memory but in generalmy resource requirements and the answeris it really shouldn't so basically ifyou're running with 24 cpus before andnow you say i want to run on three nodesthen you should be able to run threenodes of the eight cpus each and thesame is true for for memory uh but ingeneral we have this new section in thedocumentation umyeah sort of outlining the role of cpuswhat do they do why would you add morecpus same for from memoryum also something aboutyeah potential bottleneckshow garbage collection in go wouldaffect your bb8thing what you can do to potentiallyreduce memory requirements if it's toohighuh caching vectors on diskthe role of gpus etc so this is reallycool new guide that should definitelyhelp you and of course the one onhorizontal scalability with everythingthat we talked about right nowum what other points didn't we oh yeahthere are two two more points that ididn't actually three more points that ididn't talk about at allum one is re-sharding so resharting isalso something that um we put in thedynamic scaling milestone so it meansright now the shard count is immutableyou cannot change itum the reason for this isbasicallynot actually the reason for it mostlythat it's going to be in a latermilestonebut still there is something that youneed to to keep in mind with regards torecharging um this h and sw index thatwe built up you can't just cut that inhot half or cut that into individualparts so basically a resharing processisbasically a new import so what thatmeans issort of in the worst case this is nothow it is in vv8 but this is how itcould be let's sayyou're going from one chart to twoshards and you would have to sort ofbuild up everything again that wouldessentially just meanyou need to re-import your entire datawhat we have in vv8 is a virtual chartsystem which is very much inspired by wewe talked about this in depth in the umin the architecture meetup where we wentthrough all the theory which is inspiredby cassandra'svirtual notes and the idea here is thatbasicallywe assigndata or we assign yeahobjects basically to a virtual chartwhich then belongs to a physical chartand if we change the number of physicalchartsonlythose virtual shards or only somevirtual shards basically have to bemoved so this means that if you go forexample from four shards to five shardsyou don't wanna have any movementbetween the four existing shards theonly movement you wanna have is fromthose four charts to the new chart sothis is this example here um that if youhave so here we have if it takes as anexample if it took you 60 minutes toimport your data into four shards andnow you're adding a fifth chart um theneach chart will have to transfer 20 ofits data which means that the reshardingprocess would take roughly 20 of theimport time which would be uh 12 minutesin this casesoimportant to keep in mind resharding itis on the roadmap for dynamic scalingum or is it actually i think here itsays it's it's sort of it's on theroadmap but not even in that point it'sjust something that that we can do inthe future but there is a cost torecharging because of the h is w indexuh next point that i did not talk aboutyet and i also won't talk about rightnow for more than a sentence or twoum how do notes discover each otheruh basically you can see thatinwhen i showed the services herethere is a vvate headless service whichis part of the new umof the new uhhelm chart that we deployed or that wereleased todayand basically what that does is it justresolves the ips of the individual nodesand then the nodes themselves uhyeah they use that information tocommunicateand as long as as any node in thecluster has contact with any existingnodes they will discover each otherbecause they are using a gossip protocolor gossip-like protocol and this is notsomething we invented um and also notsomething we implemented but somethingwe just are using a hashicorp's memberlist go library for this and and this isalso that this gossip protocol alsowould communicate stuff like a failurescenario for example so if one node isum assumed dead then basically that newswill spread like like gossipumyes this is allthe important thing to say about this isbasically that you don't have to doanything as long as you use the the vbahelm chart so as you could saw as youcould see with the umthe first example where we started fromscratch having nothing but a kubernetescluster all you have to do is configurethe replicas and it will be deployeduh next thing is also something that wedon't have in right now but that um yeahmight make sense in the future which issomething such as node affinity so as isaid before i could tell vva to onlycreate one chart or eight charts andthese one or eight charts werebasically distributed among those 12nodes physical nodes kubernetes partsthat we hadbut we can't currently control whichnodes should get something so this issomething that we might add in futurelike a label or rule for example solet's say if you hadasync node sizes um some nodes biggerthan others then you might want tosort of put more charts on one node ormaybe you have more critical nodes orsomething like that so in the future wemight add labels here and if you're ifyou've used kubernetes before i thinkthe term node affinity is also one thatthey useso that's definitely um inspired bykubernetes and meant to to work withkubernetesyeah other than that we've talked aboutthe stuff that isn't implemented yetwhich is basically what is on theroadmap so replication will be part ofthe next release probably will haveanother meetup where you can show thatsomething that i'm already lookingforward to to showis um yeah actually putting query loadon the cluster and getting it to a pointwhere um it's maxed out and then justadding new notes and umyeahand increasing the query uh load or thequery capability once we havereplication so that is currently underdevelopment well it is going to be aftertoday because today we finished um thehorizontal scaling without replicationmilestonewhich is ready to use as you can see 1.8i think it's currently not yet in theconfigurator let me check actually idon't have to check i know that wehaven't put it in yet but um let menevertheless demonstrate yeah it's nothere yet but we'll add it tomorrowprobablyas a as a release candidateyeah that wraps up the live demo thoseactually wanted to to go to this onethat wraps up the live demo", "type": "Video", "name": "Weaviate Meetup \u2013 Horizontal Scaling, Sharding, Kubernetes, and more in Weaviate v1.8.0", "path": "", "link": "https://www.youtube.com/watch?v=gIIsZ21hdfk", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}