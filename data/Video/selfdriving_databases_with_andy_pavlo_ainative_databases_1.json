{"text": "Hey everyone! Thank you so much for watching the first episode of AI-Native Databases with Andy Pavlo! This was an epic one! \n[Music] [Music] n [Music] hey everyone we're super excited to present the AI native database podcast series we've invited some incredible people discuss where these new advances in generative AI are taking us and the role that database systems will play in it this series contains four interviews with Andy Pavo Paul grth John Ma and Dan shipper all four podcasts feature weeva co-founder and CEO Bob vanl thank you so much for watching I really hope you enjoy the series hey everyone everyone thank you so much for watching another episode of the weeva podcast in our special edition series featuring weeva co-founder Bob vanl exploring the future of databases how all these recent Trends in AI is going to shape the future of databases I can't even tell you how excited I am to welcome Andy Pavlo to the weeva podcast Andy is the co-founder of OT utune pioneering the self-driving database system such an exciting idea around using machine learning models to tune database systems maximize latency and throughput all sorts of things we'll get into in the podcast and he is also a professor of databases at Carnegie melon where in my view and I'm sure shared by many others he's put together one of the world's greatest resources for learning about databases including a recurring Series where he has industry experts give talks such as this year our we8 cgo Eddie and dilocker join the the series and so Andy I can't imagine a better guest in our series with Bob on exploring the future of databases thank you so much for joining our joining our podcast sorry thank you for inviting me this is about datab business I'm happy to be here thanks so much for being here indeed yes and so to set a stage a little bit so we we do these um this this miniseries right so where we talk with people um about the role of um ml or AI we use it interchangeably on databases and one of the things that that started to happen was that of course Vector databases like um started to play a role in the whole uh uh in the wake of of generative models for the retrieval augmented generation use case of course we had semantic search capabilities and those kind of things however some people also started to argue maybe the future of the database because of what's Happening Now in Ai and machine learning is um not a database as we know it today maybe we can somehow capture the information in the weights that are stored in the models as well and the way that we talk about databases today might just completely changed uh change and and and rather than us as a uh a database company just you know sit here and like nah you know probably won't happen in the coming years why not explore this publicly on a on a podcast with some of the experts like yourself and need to see like where do we think this might you know be going and is there some Merit to that argument that people um uh are making and I think as a as a first question to to kick off because there's a relation with machine learning um there as well can you explain a little bit in in from your perspective what is a self-driving uh database management system system and what is the role of machine learning in such a system yes so I guess we have to sort of start from the beginning to Define what a a database is dat minut system and then Define what does it mean to have a self self-driving database man system so a database is this idea or this this repository information that's meant to to model something in the real world so for example a university has students students take classes the classes get grades and so a database could represent that aspect of the real world businesses have have sort of similar models as well and so a database management system is a class of software that is designed specifically to uh store and retain and provide access to a database so people often times use the word interchangeably so to be overly pedantic you would say you know a database of the University could be run in a database system like Oracle myle or postgress and so the challenge with databases especially if with relational systems um or really really any databases but especially in relational systems um the challenge is that the the databas man system is sort of designed to be this general purpose uh software that can sort of accommodate any type of database you know obviously there's data models and reasoning we can ignore that for now um but like the idea is that I could take postgress and I could run my University database on it I could run my bank database on it right and the database system is meant to accommodate that right so doesn't come with a predefined schema and so the challenge is that when you abstract away the actual uh how the new system is going to physically store the data and when you write queries how those queries are actually going to be executed like through something like SQL uh somebody has to make a decision what's the best or optimal way to do all those operations what's you know should I store my data as a roast or as a column store should I be compressed and so forth and then for a SQL query using that as an example it's a declarative line anguage and so it's just saying this is the answer I want and it's up for the database system to figure out what's the best way to uh to to to execute it what's how to generate the query plan for it and so this is a the well-known problem Le focusing on relational databases going back to the 1970s people realized very early on that uh somebody's have to make a decision and you know a human can do it to certain extent but for really challenging environments and applications you'd want it to be automated you want the databased system to try to figure this stuff out automatically so there's again a long line of research uh again going back to like the 1970s actually uh one of my PhD adviser his adviser wrote one of the first papers on how to automatically pick indexes that was like in 1976 um so the the various vendors that are out today they all have some tools that that that human dbas are administrators or devops people can use to to figure out how to how to tune the system um like C Tock indexes had a two knobs but the it's still very it's very much a manual process and so our research at Carnegie melon on self-driving databases was looking at it from the perspective of if you had to build a brand new database system from scratch knowing that it was going to be tuned automatically by an AI or machine learning algorithm what would you do differently how would you design the system differently because the way we interact with postgress and myql and other database systems we're going through apis that are really meant for humans like to look at query logs look you know the API methods you're going to use to to change things uh and it may not be you know you can build automated Tools around it but it's there's certain things you may be do in the inside that be slightly different and so we had uh sort of two projects at at carneg melon building a system from scratch in the space um and I you know I thought we were making pretty good progress on it but then through combination of the the pandemic I then spun out of start start out with one of my P students Dana Van Akin and then uh I had a baby uh so the combination of those three things sort of was a was a as a trifactor of a bad idea or too much going on so we ended up killing the project um and but we took a lot of machine learning stuff that we were doing in those projects and then ported it over to to postgress so it's not postgress it's not uh like I said there's it's not designed to be tuned automatically by Machine learning but like we can get pretty far far with it we do have to change some of the internals which I can talk about to to facilitate better you know machine learning operations but um that's sort of the big picture the goal would would be can we build a database system and have it completely managed by uh AI machine learning and not require any human input and that is a there there's so many things to to unpack here that that's so interesting I I you know I I I made a couple of notes when when you were when you were talking so the the first one is the um and this is something that I that I um that I don't really understand and there's like I I I don't have an eloquent way of asking the question so I'm just GNA blur it out why isn't that just one database why where where do we sit in the where do we where do we get where do we get is it is it on the from the outside in from a developer experience perspective or does that sit from an inside out perspective on the indices so that the way that we structure the database the way that we that we SE those kind of things because for example you mentioned in your example you mentioned compression right so we use compression or not those kind of things but um you know um uh um one could argue like well you know that's something we could turn on or turn off right so we could say like we we add this to the database and compression it so and simple example is in the factor index we have in we right so we have a PQ algorithm you turn it on you turn it off right so what why does it is it purely like a commercially driven thing or an experienced thing or is that just from a from a purely theoretical maybe even philosophical point of view could there be just one right so it's a great question I think it's a combination of things um and I will say also too I one of my side projects is uh I maintain this website that the databases of databases dbdb doio it's like like Encyclopedia of every single database I know about and we're currently up to as of what November 2023 we're up to 954 and I know there's a couple other ones I need to add there uh but like we're getting close to a thousand and this is goes back you know the first databases to the 1960s to today um and so I I think to answer to the question why isn't there just one database I think it's a combination of three things one is that the uh the the programming environments evolve over time and people want sort of a database system that can sort of interact with whatever that the new thing that they're building so you know you think of like the late 80s early 90s object orent programming like C++ of small talk that was the hot thing so people were like okay well I want a database system that stores C+ plus objects for me and there was a whole sort of object or a database movement for a while um and then XML became a hot thing and then there was a bunch of databases that could store XML Json was a hot thing bunch of story Json um and so I think there's there's always sort of evolution of of sort of best practices of how people build applications that would an with the database and that sort of pushes thing things forward and for better worse people start new database systems around that space I think another aspect related to that is also the the data model changes as well mean object orate databases that's one sort of data model and then there's implementations of that and so that that thing that evolves over time and then the last one is as you said it's there's a lot of commercial activity in this space right uh like if you were a startup today and say hey I'm going to build a brand new operating system whether it's a monolithic kernel or a micr kernel I'm going to Linux you know as a general purpose operating system that'd be very very hard to get funding and actually do that and be a major major undertaking but with databases there's just so much money slashing around and the you know systems like post Gus and others like they're good but like you know they they they definitely have their rough edges and people often feel like they can do better I mean you guys did this you you better dat from from scratch um to serve a new sort of class applications that maybe didn't exist 10 years ago uh and so I think that I I would say right now we're in the Golden Era of databases because there is so many uh different options out there that are specialized towards different different workloads different environments different data models different different kind of problems um and and I don't see I I could see that tapering off a bit over time um you know so everyone's chasing the the snowflake IPO who knows whether the market can sustain so many of these other you know cors in that space uh we'll see um but yeah I I just I think that the bars lower the bar entry the bear of Entry is lower to build a new database system and get people actually start using it versus like something like a brand new operating system yeah that's that's that's a good point and I think it's it's fascinating it's fascinating how that how that emerges and how that opportunity emerg and that kind of also leads into my into my second question and I need to I need to give a little bit of context this because um it has to do with the original story of of we8 because um um it's a long time ago I I opened the uh the gith up repo for we8 at the at the airport in San Francisco um today I can by no means take any credit for the awesomeness that's happening on the lowlevel stuff on the on the database side but the um initially what the idea was um and it was like directly related to to machine learning was that um I was intrigued by uh the data modeling problem and you just mentioned that you said like okay we use a database to you know for real world applications to uh represent you know real world uh objects or probably also actions right and I was fascinated by that so I was there was a combination of machine learning um um um things like schema.org for the semantic map played a role in that just to get an understanding how do we represent things and one thing that I learned in my professional life was like uh the problem is the people so uh we as humans do not agree on how to call things so I was in a um I I was I was hired by somebody um back then I I was running my small uh software engineering um uh consultancy and I was hired by somebody who was like you know early 20s and I made this big proposal how we could in Json represent something big in the organization and the guy gave me an assignment and he said I'm going to send you to three people in the organization I believe from the top of my mind it was the marketing department the sales department and something else and he said ask them how to represent a customer in your Json model he said and if you figure that out we'll implement it so I went to uh uh to to Department one and I was just super happy because they explained exactly to me what the definition of customer was and I could easily capture it in my Json mod so then I went to the second Department it's like well we kindly disagree with this definition right so now I got into trouble now when I got to the third Department I just it was just I couldn't do it right so the idea popped up like what if we would just take any definition that people use to define something in the uh in the data model so I didn't care if the sales department or the marketing department had a different way of representing in this case customer but I would use Vector space and the models to try to retrieve information as based on their similarity right so that was the original idea for um uh uh for for weate so like can we rather than have these strict relation that especially were coming out like link data semantic web those kind of things can we infirm infer them based on the models and and uh um their relations and the reason so this leads into my question because what I find fascinating I also ReRe your paper about the uh about the um the self-driving um database that that talks about the database itself so on a meta level how do we interact with the database right so the scalability indices those kind of things but it doesn't say anything about the actual data in the database and something that I'm starting to think about more and more what's happening in the space is that the models not only interact with the how we operate the database but also the data that's actually in the database so infering relations optimizing data maybe even doing CR um uh you give it a prompt and there like a a crot function that that happens on the data itself and I and this is kind of leading up to that question of like how the database is evolving and I think the question is how do you see or do you see a trend in people building these systems like what we are doing we're playing around with this too where the models start to interfere not only with the database but also what's happening in the database with how the world is modeled inside the database when you say the the models and Fair what do you like what do you mean by that specifically yeah so we so and Conor wrote an amazing blog post about this something we call generative feedback loops where we basically the model queries the database in this case it has ER BNB data in it but it's missing descriptions we basic hey your weate instance without descriptions but we have like the name of the host the price per night the location um take that information generate a description with a factor and and store that back into the database right so where we can see use case as I like to say like in the in in database world the data world we always had the uh the're saying a [\u00a0__\u00a0] in [\u00a0__\u00a0] out but this is an opportunity to go from turn chicken [\u00a0__\u00a0] into chicken salad by basically having the model and the database collaborate and I'm just I'm just curious how you look at that development in the space that the models start to interfere with what's in the database rather than the database itself I I wouldn't say it's interfering as like a negative thing right it's it's it's augmenting right uh and I think that for certain applications absolutely this this this makes sense to to using your example uh of you know A&B Airbnb rentals you know the description may not be perfect uh but it's it's probably good enough right um for other things especially when you start getting into like financial data Enterprise data things get dicey because you can't easily explain why certain things happen right so you know for example if you're using uh some kind of AI model that like is determining whether someone should get a loan for for a house and it's spitting out you yes yes or no answers uh and someone gets denied alone they're gonna want to know why people would start complaining so I think for some Greenfield applications this makes sense for the uh some of the more traditional brick and morar things I suspect that they're going to be more conservative and we're in the early days of llms and it's super fascinating it's a very exciting field I think there needs to be a little bit more structure and and uh explainability accountability involved in these things um but I definitely I definely like think that you could imagine you know using gen AI techniques as you said to fill in missing data um or I think another big space I this is not my research area but I think using it for entity uh resolution would be super important right is is you know Mike Mike Smith and Michael Smith are they the same people uh just based on looking at the the names the feels of the you know for for you know a user in a in a database just looking at the far chars the raw strings you may up able to figure that out but if there's additional semantics you can infer from the additional metadata about that person then you know a model could make a better decision about these things and I think that's like super exciting the problem is get getting getting the training data for that is expensive and costly because it's not something you can always just Outsource yeah sorry if I can dive in quickly um a question I'm really curious about with auto tune and tuning the databases and it's kind of related to generative feedback loops and having llms process the data is I'm curious if you're thinking about tuning the schemas like I feel like with data schemas as as Bob mentions with how do we describe our customers we have all these you know attributes we come up with um do you think like llms can tune the schemas and maybe this is evaluated for like either you know accuracy in like a rag sense or maybe just like latency throughput in the database sense yeah I uh I have a demo video I've used for talks last year we've tried gbt chat gbt 4 to help it uh like optimize a schema and basically I took a I took a a schema of real real database uh and I actually injected mistakes that I that are like that a human would be able to figure out like for example um it was a procress database so you can you know if you name the you can name a varchar column uu ID and and so and you know with varar 128 but it really should be the the native uuid type and you sort of give the schema to chat gbt and say hey you know what are some mistakes in here or like there's duplicate indexes and things like that uh and that has been pretty uh uh the results are pretty inconclusive like sometimes it works but often times it actually doesn't and I admit we didn't do a lot of Context Engineering prompt engine you really push it to try to uh you know get better and I know there was the the recent update or announcement from open AI about about additional contexts engineering you can do I we haven't played with any of that um we do we've also played with uh We've also played with um trying to use chat TBT to infer or understand what the application actually is right just based on the schema um and and also what omm are they using what what does the application stack look like above now some of these things you actually don't need machine learning right it's some things are really obvious to figure out what om they're using so for example using Django like Jango will name some tables like Django underscore right or like uh squize or one of these omm schema management tools they'll put you know specific table names and you so if you see that you know what they're using um but in so that one it could do it could figure out what Oram you're using for the most part uh but it wasn't good at um trying to decipher exactly what the you know what the application actually was because our our idea was if if if we can say okay well here's like 10 categories of applications like the financial data it's a you know it's a tech startup kind of thing you know are there optimizations we may want to apply uh to you know for one category versus another and could chat gbt at least identify what category you belong in um that we have we haven't played out that hasn't worked out so much um so I think I think through better uh prompt engineering we could we could get better SCH SCH uh you know the schema optimizations the challenge though is though because it's disconnected from the application uh and this goes back to why we want to know what the omm is like if it's if they're writing raw queries and they're like calling select star on a table and then we start reordering the schema that's going to break a bunch of application code up above that maybe is assuming the offset of of columns or if you start doing things like let me let me normalize like I have this you know table with lot of columns and we break that out into subtables again that's going to break a bunch of application code up above um so you can imagine doing some kind of integration with like co-pilot in Visual Studio GitHub where you do have access to the application can figure this out um or data dog has go ahead yeah yeah what I find so fascinating about this and and not to make it too esoteric but I I really find this fascinating is that there's this there seems to be this shift happening where that in in the past right the um uh the database was very was very binary right so if we if we if we take the um in the feedback that it gave so so so let's take the self-driving car analogy right so um if you take a self-driving car uh um and it drives from A to B and it drives from A to B exactly how you set it out to do this um um it's still very pin because it does it right or does it wrong right that there's like no there's there's nothing in between there so with in with the database it's like this is how we Define the schema it's going to eat it or not right it's going to accept it or not this is how we store the data it's going to accept it or not but with the because of the the models especially the generative models we start to add this subjective element to how we're designing these systems to the model so for the first time in history it seems that we're starting to give away human subjectivity on how we Define a schema how we store the data how we represent the data to the model so now it becomes not self-driving in back to the car analogy as in I want to go from A to B but you you insert subjective things right so it drive me from A to B with the most beautiful scenery and it's the model that that you know that determines what beautiful means in this context right and uh or a beautiful scenery and and this is what I find fascinating about the the use of these of these of these um uh uh models because the it seems that we start to move towards systems where the system has an opinion how it needs to be designed or how it needs to be structured and I'm just very fascinated what that what that might what that might lead to in the future because I could imagine for now if you look at a at a traditional database right so what do we what is the um um um us as a as a as as a database provider or you as a as a professor to your students what is is the kind of the most important thing that you want people to give away so you want to I guess the most important thing you want people to learn is like how do you build a reliable system right so it's reliable yes but now this other element is added to it like how do we make sure that that the thing um you know does something almost like ethically or morally agreeable in how we design our systems I find that a fascinating a fascinating development and I maybe you know better but I think that's new or or am I am I am I am I wrong there um um yeah I think that I mean if you take like like a traditional bi olap you know database system or even like an operational database system right like for the most Parts those are always producing precise answers and then the the thing that changes is like how efficient could it be to actually execute those queries now there are like in some oap systems you can do approximate queries like you can take s you do samples and you you produce back something that has like here's some confidence interval um but those are you know most of the major oap systems use those but I suspect that most people don't know to like instead of calling count star call approximate count right um could you get back of some confidence in one like humans just simply can't reason about those things um so I think the semantic search stuff is is is interesting it's a natural progression I think from the exact search you would see in like text search enges like a a vesa elastic search Lucine kind of stuff um where now you you know instead of saying you know here's you know find the exact keywords and things like that it's like okay we'll find me things that sort of smell like this and then the challenge of course is like as you said like it's very subjective like what what is good what is bad May differ from one person to another um so I would say that the and I'm not just saying this because I'm I'm you know it's my job is to educate people how to build database systems but like I don't see databas systems going away because at the end of the day you you need to collect information from the outside world it's just now a different a consumer is going to be these large langu models so I think you know the the LMS are augmenting our existing systems uh for the better and not supplanting them yeah yeah it's it's that's that's that's um um um that that's a good point and to if we look at that so one thing that I'm what I'm Fascinate about is like but in what direction right so to give to to um uh um to you know to give some more color to that to that point is the um Conor recently did a podcast with Patrick Lewis right so one of the the the rack inventors and if you go to the to the hugging phase on G up if you go into the hugging phase um repo somewhere you find hidden you know deep down below you find hidden a a folder that's called Rag and um uh in there they use Library so they use phase and then they have two models two DPR models and basically what happens is the um um at the model um tries to do a um Vector search on retriev defa time basically right so so the model moves a little bit more towards in this case this is a search library but let's say for the sake of argument the database so the model moves in that example towards the database so in that case what you just said just really holes right we just need to have a very strong database that just needs to be support of of these models however I'm also curious about if you see any Trends or we see any Trends where it actually is the other way around so that the database the data layer more starts to move towards the model so that it for example becomes possible to I don't know to to manipulate weights in in a in in such a way um that we can reliably store information or can say something about the path you know that is being traveled through the weights to get to to an to to a result that basically we get this Big Blob for for like a better term of of binary weights that just stores our information and yes we need to run that reliably but you know you could argue that if if we're able to figure it out might be easier to just you know write you know run a Big Blob of of binary weights rather than the complexities that sit in the database right now so I think my question is like could there be a potential future where actually moves in the other direction where we just start to see people more move towards the model and create database systems where where they going to go like you know what we're just going to store it we're going to try and to store it in the model itself and to add one more thing to that I um I don't know if you have this at hand Conor but we were discussing this um this paper uh that we've seen and I forgot the name I believe it was MTH or something where people changed information weights in the database so that they for example say it like um I don't know LeBron James place and then it it fills in with basketball but they were actually able to update the weights to change it to baseball for example right so as in the first step of saying that we can real time modify the quote unquote memory that's in the in the uh in the model with of course the goal of storing information in there real time so long winded question but I'm just curious if you could see a future where it moves actually away from the databas as we know it today more into the model as it is today so you can imagine there there's two things there there's I think there's a data market kind of approach where like instead of selling here's my raw CSV or paret files of data here's some safe tensors file that you can just run uh that that that that'll spit out answers for a particular uh application domain so you can imagine a world going going like that um and then to your point of like could you build a database system to just using safe tensors as an example like could you build a databas system around the manipulation and uh accessing a safe tensor file like the actual internals not just using it you know with within some like py chch wrapper um yeah you you can you could think about something like that and what's interesting is that you know instead again just instead of treating the safe tensor file as a blob okay well I actually understand what the bittes are actually telling me and so the interesting thing about that is like it's a multi-dimensional array um and relational database systems aren't really designed and do very well for all multidimensional arrays like that right there's row stores there's column stores now in the SQL standard in 2023 they just add a support for for multidimensional arrays that looks a lot like Ramon's rql language um but I don't think I think you would still need a sort of custom engine be able to do that manipulation um I mean I don't know what the a you guys might know better than idea what the average size of a safe tensor file but you just look at something like staple diffusion they're like 8 gigs 10 gigs they're not they're not massive uh so it e easily fit in memory but I think over time as the models obviously get much more sophisticated the dimensionality of of these vectors increase you can imagine start getting you know model files in in the terabyte range and so then in in there's the sort of like how do you expose an API and manipulate the the tensor file but then the but how to manage that that that that that data in memory and on disk well that's just classic database systems and so a lot of the same ideas that we use for you know systems for the last 30 40 50 years would apply in that same space as well so I think like the management of of moving data back and forth between dis and memory that doesn't change whether it's a tensor file or you know a relational database system but think the API and how you manipulate it and how you access the the data within the files is going to change yeah yeah interesting interesting and and the what you mentioned about the API so I I would love to to double click on that as well so um I had recently had a very interesting conversation with somebody and and that conversation was from the perspective of rest because um um to not make it too complex in the in the discussion it's like the restful architecture is a nice way to just describe apis and how we interact with our data and cross functionality and those kind of things and one thing that we were discussing was that that the um um the the the the the status Cod is that we see the um the way that the API is designed and those kind of things is very much focused on humans right so humans connect um uh the apis together so what the stat what the status quo says right or or the um the way we Define an object and those kind of things is very human human centered right obviously and one of the the the the um the discussion topics that we had and it was just an open discussion was like would it be time to extend those kind types of API architectures like for example the restful architecture to actually have status codes just to give you a very pragmatic example that you basically tell the receiving end whatever you're going to send back is going to be processed by an llm rather than by a human connecting the dots together and an an example use case for that might be that if you send a result back from a database could be for example in a rack use case right if you send information back for a human uh um uh to consume so maybe products that you're searching through you want to make sure that the ranking and those kind of things is done appropriately because you're going to represent it in an app on your website but if you're actually going to send it into a generative model to get some insights out of that through the context window or however you do that then it's helpful for the database to actually know the information that I'm going to send out is going to be consumed by a model rather than by a developer connecting the dots so I think the question basically is like do we need to rethink in your opinion the way that we now design apis how people or maybe even go as far as like uh the SQL language itself because there we might go to a future where it's not being written or consumed by humans or developers but by llms doing something with the information coming from from the database I can't prove this but I would say most of the output of database queries is consumed by machines not humans right and no sorry yeah yeah just to make sure that what I sorry so just to make sure what I what I meant so um um I I I think absolutely the majority of of um API requests are processed by a machine but what I mean is like it's it was a human that basically connected the two together so the output of the of the API needed to be human readable to know how to represent it in the end application but that's bit a model not we don't need to do that necessarily right so you can give way more information more complex information faster those kind of things that's not processible that a human can process to make those uh build those applications but if the model produces the end application so what you're describing is basically a projection and SQL in relational algebra right you're defining what you want the output of a query to be and so from the database system perspective if there's a you know if there's additional information or different context or even different formatting or bite ordering or encoding scheme that you want to use because it's going to an llm rather than you know some other python code or something like that right like uh then that from the databas projective perspective that's just a projection now how many layers are in front of a you know a SQL query what rest or craft ql or you know to you actually get to the consumer of the result you know from my perspective as someone who focuses on database systems I don't care right if you want data encoded in a certain way okay again that's a projection I can build that in in a database system and then is up for whoever the application developer is to say okay I need this I don't need this and then you'll make a call into the D system appropriately and that's the beauty of a declarative language like SQL that you can tell the D system here's the answer I want I don't care how you produce it this but caveat of course bad query plans and all that kind of you know BBA problems like I don't care what I don't care how you produce it but this is what I want it to be and the database system job is to go figure out how to get you that information so absolutely yes there's additional things that you think that would would benefit data being assumed by llm versus you know a generic you know front-end application by all means but then like we we we can just add that to the database system as another projection output yeah that's and I just want to quickly double click on something just it's a tiny s side step but I find this fascinating and this is more a question to you as a teacher right so as a Prof so the the I was you just um described that how the database operates is something that you care about right but how it's consumed um um less so however databases are complex systems I mean we we work with a lot of developers and developers come in in a wide you know range of of of you know um you know the the the the spectrum of knowledge that people have is very very different and I'm a big believer that we need to be able to help every everybody to use the database right so we need to help people and that sits in the in the on the API level so when they start to interact with the with the database do you as a as a the students that you have I mean I saw it also in in hn video right the questions that that the students these are very smart people they know how these systems work they'll probably figure stuff out what is the respons I have say this is why I love carnegi melon the students are smarter than I am they don't know it yet by the time they figure out they graduate and so I look like a genius yeah but so the thing what is what is your so you as a professor having people building these systems that are going to be crucial in it doesn't matter if it's in banking in health care and those kind of things what kind of what kind of responsibility do you take as a as a teacher to make sure that people understand that even how great the database is that people need to know how to operate it how to make the database work is there is there is there responsibility there or is that is it too naive of a thought no no 100% agree with you and that's sort of what the you know what we tell students at the beginning like we tell them like look you know the class the semester is 150 students not all of them are going to go off into to various Tech startups and and build actual database Management Systems most of them are going to pursue other applications or domains or other problem domains you know whether or not it's in computer science or not and I tell them like look the database is a really interesting thing because like no matter what field you're in in the rest of your life you're going to have to interact with a database system whether it's like something like Excel right because that's sort of a database uh or something like really huge like a massive snowflake red shift terar data installation right they're going to inac the database and what the what our courses try to provide is you know an understanding of actually what's going on on the inside so that you know if and when there is a problem because there always will be database problems that they deal with in their application code they can at least understand what the database system is trying to do for them right so that's that's that's sort of that's a that's one big pillar of of what my I think my sort of my objective is or my goal is with courses that we teach um and of course again then there's the advanced class and here's the kids that go off to the Amazon and microsofts of the world and actually build databas systems so we go a bit more iniquity details but this General sort of master's undergrads class is what's going on to your point so yes I I do think feel like it's important uh you know it's sort of it's sort of like you can only do so much in with research so like how far you know sort of how far I want to go up the application stack and how far I want to go down to the hardware right like do I actually want to be fabbing chips specifically to make my databas go faster it's interesting uh but it's you know it's not my sort of real focus and same thing like do I want to be building an application framework at the very top that that can uh interact with the database better than you know one way versus another you know the auto stuff we're doing is probably the highest we'd actually want to go to say okay well we know a little bit what the application is doing but we're not trying to replace it yeah I I find that fascinating because the um it's like on that intersection of how people start to interact with the with the database because of the models right it's just a we see that it's a different way of interacting uh and then on the other hand you of course at the core where where you sit also you know what you teach the students at developing the database but the um the previous podcast we recorded in this in this series was with we also had John MAA on from from Microsoft where we actually talked about that right so what what how do we make sure that everybody understands how these new types of databases work to make sure that that they understand what the implications are of adding Ai and machine learning to um uh uh um to that data workflows and and and you know how do we make sure that people understand yeah basically what those implications are so that's something I find extremely fascinating and I'm also fascinating where that where that trade-off sits right so we we notice that sorry go yeah I say another pillar in in addition to saying like you if you want to understand what's going on inside the databases we teach that but also like every 10 years there's there's another hype CLE on databases as we talked about in the beginning because there's a lot of money around and and things evolve over time and people want to build new database systems so I tell the students you know what they also can get out of the course is basically just a good BS meter do you understand like when people come out and make wild claims about what their database can or cannot do it you know they'll be in a better position to decide uh you know whether that's real or not now I will say the you know I know you guys are building a vector database the vector database is the current height right uh you guys fully admit that and it's it's similar to the nosql stuff of of a decade ago but I will say what's fascinating is I feel like the vector database people are more grounded uh in about like okay here's we're focusing on this you know one specific problem and we can do that really really well whereas like the nosql guys are making all sorts of claims about why relational databases are stupid slow and old you don't want to use SQL and all right right you don't want to use transactions then they eventually learned that okay the things that they were avoiding are actually a good idea and so the vector databases I think you guys have done a better job at saying like Hey we're doing this one problem we're doing it really well and you this is why you want a specialized system but you you still need your you know your relational you know database system on in the front to collect the new data so I so go ahead yes sorry no I just want to say so so one thing that so this is something I'm thinking about a lot right so in in in my role in in um in in in the company it's like a you think about okay how do we position a new database right so how do we explain to in our case we're open source we also have a community I say so a we have users and and and and customers that that they're not different when it comes from a from a a usage perspective so they're part of our community so how do you leverage your community or how what do you tell your community and and I'm if I try to peel off the onion and go to the center and like what sits there and I can't help but going back to the index so you just go as deep as the index and the reason I bring that up is because one thing and in all honesty and I always I'm always public about this we kind of got lucky with this because I tell you when when we started with this it it was very obscure Niche to work with vect Bings right so so the uh but the the the big difference between a nosql database so for example yeah well any nosql database versus a SQL database it it at some point it becomes very hard to make an argument why you should use one thing over um Over N right and they are arguments but they're often sit out the fringes but if you have a new data type right in this case the factor embedding you'll just take it from there and that's where your argument starts right so you take it from there I um today it's it's not a new data type right sqls had SQL I think SQL 2003 or 2002 added uh single Dimension arrays that's a very good point so I'll that's the good point so I'll I'll I'll I'll take that back where that where that specific data type was the um the first class citizen in the database so and the index that's that's the key and and the API to to do the similarity search exactly so that were they were they were basically saying like so the so um um the example that I sometimes you know that that ass gives like hey you know you have like for example it's full text search you have the strings text Fields those kind of things then you got time series databases because you know if you want to do something there you have no SQL database for document stores those kind of things um so every time there was like a something that was like in the index or or related to the data type we started to see see new database around that and one thing that we got lucky with in just in how AI uh or ml right took off was that that factor embedding and as you said the index to to to support real-time use cases just took off made it quot easier to show this to the world it's like Oh no just like this is what we do this is what we specialize in and and um and this is just this is our expertise and everything that comes around that right so the API interface even the contents that we write right how we how we address people that just became easier because we didn't have to um uh um we were not basically uh uh um how should I say Reinventing an an an uh uh um a wheel so we didn't have to say it's like X but then open source or something like that right no no no it was like really something we we start to build from scratch well I think also too the the vector databases again you guys aren't trying to replace operational databases right it's it's it's almost again you're like a better elastic or vesa like like it's it's a it supplements what people already have so in some ways the bear of Entry is lower right because it's not like you're trying to say hey you're running your bank off of Oracle or whatever get off that and use we8 because no one would do that because the risk is just way too high especially as a new databas startup like no one would would say I'm gonna put my mission critical application like if you know we8 fails the whole business grinds to Hal you guys say oh no no like you still have your databas record we'll ingest it we'll build the embedding and you know we can supplement and do additional searches that you couldn't do before so I think that's another difference between the nosql guys and you as well like you're not trying to say as you said just replace some existing you know the you know the existing infrastructure companies no that that that's true and actually so today the now recording this um uh somebody from the um um uh um um def def um from from the snowflake team um published the blog post literally this right so you have your system of record and that was then that was stored in in a in a snowflake instance and then running weate next to it to to searches and those kind of things so that is that is correct that is a very different in different argument that so so for example um I think most Factor databases I mean goes for us right we're not transactional right and we also not yes aiming to be that that's like a not we're not focusing on that right so so that's that's a very good point but I also think that the that the um the way and how you position the database or how you invite developers to use it is there basically saying like hey if you build stuff with all these AI models and you need like a um something to store something stateful right um You can use us right so we we help you with that we make the model stateful so that's a that's an argument that we have that I think is kind of new so that's a and that's something where I would say like that we kind of got lucky with right so because who knew that it would take off the way uh uh the way it did we just I I really don't think that anybody saw that coming so so again like using the nosql system as example and when people say no I mean like you think of a Json database like like [\u00a0__\u00a0] just use them as example you know their first five minute experience using mongodb versus like a relational data system was is phenomenal like you just turn them on throw some Json in you store it and I think it has better integration with people building web applications because the primary data is is in Json so I think you guys have done the same thing in you know we M us pine cone a bunch of you guys that you have better integration with the AI ecosystem than you know you know existing databases the challenge though I think uh is that the question is is is it index and that AI ecosystem is that enough right is that a large enough mode um yes and I think over time again not it's your company but I'm telling you you know here's what I think is gonna happen because we we just see the same pattern every 10 years from the new category dat coming around eventually you'll have to support transactions you'll probably have to support SQL there'll probably be some standardization around on what a you know what the API the query language would look like for these things similar to how like the graph databases are going through this now with gql so I think over time there's a lot of databases in the vector data space uh but the major ones will sort of stick around the other ones will s fall the Wayside but then you evolv to start doing all the things you don't do now yeah exactly and that is also I mean that is something that the um um I mean that I'm also you know public about that that is also by the way that's also exciting about running a database startup is that that's exactly the thing you that's what you figure out so that's at my end of the so the the Spectrum what I do in in a database company that that's exactly what you figure out right so what is that so so how long to we until we8 Sports sequel to put you on the spot so so well it's like that's say now you're putting me on the spot so it the um I I I that's very hard to say I that's that's very hard to say because I I I still think that there's a way to actually bypass that right and what I mean with bypassing is like that's what I meant earlier through the model so for example um the work Conor beening with Gorilla right that is like a that we get to a way that it just doesn't that it doesn't matter anymore how you define uh your your queries but it just knows how to you know how to interact with the database I I would not be surprised if that's something they were goingon to see so that there's like this this layer on top of database that whatever people feel comfortable with interacting with the database right that you basically write your query however you want to write it and that it parses that in a way that it knows how to talk to the um uh uh to the database so for example how you see that with us already is that um now to the grpc clients the clients start to become more turn into drivers where the where they really play a role of like they're they're not like a thing that's just written on the side to talk to the apis but it becomes a part of the database how you interact with it how it optimizes batching and those kind of things I I don't see why it should stop there without the interaction of of the models right so that that somebody could say I prefer to use in this specific case we8 through uh language X or to to a syntax Y and that they could do that I I am I I know that sounds a little bit futuristic but I'm I with the speed at which things are going and also the research that Conor has been polishing about with the with gorilla and those kind of things I would not be surprised that that that's actually a way where we're going that we more have like a driver like approach to interact with database and that the user can be free in how he or she um uh um prefers to quy the database so you basically tell me the same like this is the no sequel story 10 years ago this Cassandra said the same I'm serious Cassandra said the same thing right and then they they're like oh you're yeah you're using grpc but like they were using Thrift well guess what they now they say you should be using cql uh I know the the the mongodb co-founder Elliot Horwitz uh you know helped out with sponsor some research early at carig melon uh he was you know 2012 he's like oh we're never gonna support sequel [\u00a0__\u00a0] support sequel as of 2021 so I think in five years we be able support sequel no okay so did I'll take you I'll take that bet but the um but the um uh and and it's a good reason right because if you're successful you're getting more customers and that that's what you want you want people using your database and then people start putting more data in it's like okay well I want to hook up Tableau or micro strategy to this like it's it's a good problem to have no no no but what what I'm trying to say is like more the that I'm that so so I think that the so so my my my response sits kind of in between so I think and again this is very speculative but I would not be surprised with all the research that we know that coming out of combining the models with query languages that yes in five years people will be able to query weate with SQL but there's no SQL interface added to weate itself it's like it's the interaction with the models in between that have have an optimized way of interacting with the database and that the model knows how to so gorilla is an example of thata research right so they know how to interact with the database through for example something like the grpc endpoints and basically it's like a form of prompt engineering you just give it whatever you want so rather that I say um that I have a restful endpoint that I do in weit slob slash whatever right or I do select uh star from same collection name whatever whatever I prefer to put in to that input prompt the model will say Okay I know I understand what you what you need and this is how I'm going to query we for you that's what I meant so yes they will use be able to use S but I think we're moving away from purely implementing those kinds of languages in the database itself yeah that so this another fascinating part of the sort of modern ER databases as well is is there's all this these middleware systems that sort of do these kind of translations that you're talking about now right now there's like uh you know there's there's a Gra file as a parser to take some query language and then convert it into another query language like it's very manual um you know most systems you know you think of like there's front ends for like the cipher graph query language to postgress right there's a front end for that that you know takes it takes the parts of the the cipher language and converts it to SQL uh there's other things like for the mongodb uh query API uh this is something I to your point almost like I've been thinking about could you build a uh llm to be like the Rosetta Stone to take any query language from any database and then have it spit out another one the challenge though is when you start getting to weird like Corner cases or like null semantics of like for one system you know the a a query should perform a different way versus another and then you start making transactions because then you start like different isolation levels how things get updated triggers like it gets it gets really messy really quick um the only work that I know in this space there's a startup called datometry that takes like Terra data SQL queries and converts it to like Azure queries and they gave a talk with us at car Mel a few years ago and like they go through all the different like here's this corner case here's that corner case and I just wonder again instead of human engineering this could you just is it possible to have like a a giant training data set to say okay this equal query to this equal query and then build a model based on that or you know this query language or this query language exactly and I I so and again I mean because it's like you know we're we're speculating about future and I I and this is where that whole developer experience um um you know plays plays a role is like I I do have this ambition if we have a distribution of like the whole distribution of developers right so you have like this nice it's the diffusion of Innovations model right it's very similar this bell curve right you have like the innovators the early um adopters early majority those kind of things how can we reach everybody because if we like or not databases are complex for the majority of people right they they need to go through a big learning curve right so um and I know that since since the beginning like the dawn of of of digital technology and storing information there's this desire I mean look look at look at Cobalt and those kind of things how close can we get to human like um but no no but like but like we already have you already have sat you're at proliferation everybody has a cell phone everybody's on web pages they're interacting with databases it's just so many you know you know they're not writing raw SQL queries and so I don't think the the world should like I to be honest like again as someone who like makes has my job or my my my passion is like okay let me teach SQL and teach databases I fully admit like you know the average person probably doesn't need to be writing SQL query as a database and so it's going to be through various forms and interfaces sort of essenti what we have now and then there's things like chat TBT and and and other things where their natural languages you quer you can do right so I I think we're here now it's just a matter of like you know do people know they're interacting with a relation D or the vector in some ways that like it doesn't matter yeah so I I'm not it's I'm not sure about that because the the thing is this so the the the if you move through the stack right so the higher up you go in the stack so let's take a bank for example bank is a great great example right so so you could argue that um if I use the graphical user interface in the app on my bank to just look at my recent transactions I'm carrying the database right so I'm just saying like you know show me transactions that happened yesterday right the problem though is that um there seems to be this um um it's almost I think it's like a could be a law because we see it everywhere right is that the higher we move up in the stack the more abstract uh abstraction you take away from um uh um querying the database and the problem that emerges with that is that the use cases become narrower and narrower right so if I now say let's say that my bank would give me access to just do SQL queries over the Clusters that they have running just for the sake of argument right to to um uh um uh to see my transactions the upside of what I get with that is that if I want to I don't know integrate it with the accounting system that I have it's super easy because then I just write a little of code right and I interact but the the The Catch 22 is the easier we make it that we make it for for people to use EG the graphical user interface the query the more abstraction we lose where people can build other things with the databases um uh or with the data that they have as well and if there's like a Utopia where we can say doesn't matter anymore you just tell what however you want to describe how abstract you want to become how detailed you want to it doesn't matter anymore you can even use human language to do this you can now interact with your data for example at the bank right so and my so my mom can do it just to see the transactions to days ago but I can use the same interface where the model sits in between that two for example connected to my accounting software so the that is a problem that is unsolved so the quote unquote easier we you we make it to use the the technology the less abstraction and the less things we can do with it I think that uh I think you're overestimating people's desires to do that right uh the average just assuming the average person right uh I think that there just to your point like humans are messy uh interaction with computers is hard and I think that having that having certain restrictions or limitations streamlines the things you know that people want to do most you know for 99% of people and then for the 1% that want to do deeper things you know uh again average person not application developers uh you know you know is there better ways to expose apis to to people get they need absolutely yes I don't know the answer is rest is not going away graphql seems to be diminishing a bit um but I think like unfettered access to data I don't that's you're proposing uh is I think it' be overwhelming for the average person right yeah sure so so maybe going all the way to the graphical user interface is a little bit too far but let's take for example um U um graph is a great example right so I'm of the opinion um um that it you know if you want to use a graph database and you interact with it right so you like you write what is it cyppher or something that that's relative atively complex right so I think one of the the reasons why in my opinion why gra came up was because it just became easier to write a um a graph-like um uh um a query the problem though was that it came at a cost it's almost impossible to write um uh many to many queries in in graph here right so we even saw there was like a startup back in the day that started with graph data database that started with graphql I was like oh boy now we can serve all the queries we want to serve I believe they introduced something called graphql plus minus which broke all clients now we had another developer experience problem but the point I'm trying to make is that there seems to be the stency that if we take abstraction away and it doesn't have to go as far up as the um as the graphical user interface but if we every time we try to take abstraction away to make it easier for people to interact with their data in this case in database that that comes at a cost that we can do less things um that's that's just that's just something that I'm F and I hope that the models might be a way to overcome that so like you just you just describe the high you want the more precise you want or the more abstract you want I'll try to figure out what you mean right so for example what you said in defining a schema that you did this experiment with the students with with with J GPT where you where you basically wrote a um um query you asked um uh um jgpt is this is this correct right is this is this SQL query correct I think what might be an interesting experiment is actually saying like if it knew what the mistake was and pointed out the mistake that you ask the model basically do you understand what I'm trying to achieve and if it understands what you try to achieve then even if you make a typo in your SQL query it understands what you're trying to achieve solves it queries it and sends back the information and it's yeah you know I I you made a typo but it's fine you you know you you you you you forgot something somewhere but it's like I understand what you mean I got it from the database I had to check the current schema but you know had a few few few feedback loops going back and forth between the mod and database and I understand what you mean and if we go down that path then we can go further and further and further and then we end all the way to the my my mom using the banking app uh uh in in how she wants to you know interact with it and with that in indirectly with the database as a quick plug uh we had actually a speaker from Alibaba uh for our seminar Series this semester talk about they have a v called cat SQL that is a an llm designed to do natural language to SQL that actually looks the schema sort of as you said and can I think can can correct things what's actually interesting too is like it can learn things like I know that when you when you query this this this cable even though you only ask these two columns I know that you're also gonna need these other two columns because that's it's the next thing it sees or something like that so like it also gives you back data that you actually didn't even ask for and anticipates things you're going to need I think so I think I think I think the space is super new super fascinating uh I don't foresee people replacing application code entirely with natural languages uh I think preciseness matters a lot for again for certain applications um but to your point yeah I think as a as a quick and dirty way to get start getting data out of systems uh natural language would be like a good first start because you can do things much more quickly than you know writing you know 100 line SQL query ex and and I know it's a little bit of a contrarian view in the in the space but I'm just excited it's so exciting to see how people start you know try to reinvent systems help people interact with um with machines and and with data in particular so it's just something that that I'm that I'm um yeah I'm very excited about and I think also looking a little bit at the at the at the at the time because you're you're you know it's I really appreciate how much time you're giving us but the there there's one more question from my side and I don't know Conor maybe also have some questions but the um what do you what do you think like you know what what is the most exciting thing that you hope to see resulted in the coming five years in the in the database landscape what a thing where you like for whatever reason we still haven't figured it out out hopefully like five or 10 whatever years from now we will figure it out and then maybe together with models maybe not but I'm just very curious what you what you hope the big you know breakthrough in databases will be in the coming years um so I would say I think Hardware is interesting um just because focusing on analytics the you know the way you would build a sort of modern you know olap data warehouse datab system now is actually hasn't really changed that much since like snowflake of 2012 right or even before that Vector wise uh from the from CW where they buil duct TB um like the core architecture is is more or less the the same um and so I'm actually curious to know like what's the new hardware on the horizon I don't know what it is until I had a bunch of interesting projects that got cancelled uh there's some stuff with risk five coming out with additional accelator but I I i' be interested to know if like there's some something new comes along that says okay we got to rethink everything um persistent memory was I thought was that like Intel's optane uh like I totally was all bought into that because you just changed the entire storage hierarchy of a databas system but Intel killed it right uh and I don't think anybody's gonna try that something in that space for 10 15 years um so I I me know like on the computational side I'd be interested to know like what's going to be the the the next big thing that requires just to rethink database systems I and at this point I'm honest I don't know what it is um I think that the llms and Vector indexes those are just going to be table Stakes for any D system now um you know you guys have a head start pine cone has a head start over uh other systems but like you know since chat tpd blew up in this time last year so December 2022 like s in in in you know less than 12 months less than a year a lot of major databases have have vectores even Oracle notoriously you know notoriously slow not because you know from software engineer perspective but because their it's enterprise databas system cautious even they announced they have um so I think when was the last time when was the last time that you saw such um enthusiasm for new stuff in the database space yes it be Json right so [\u00a0__\u00a0] Ki B all that stuff the no sequel guys that was the hot thing late 2000s and it took a while before the relational databases adopted uh you know Incorporated in in their in their systems um which is surprising because Json looks a lot like XML and they all had a support for XML in in the 2000s but like you say like mongodb blew up in like 2009 2010 postest didn't add Json until 2012 uh and the SQL standard didn't add Json support or Json data types until 2016 so it took a long time whereas the vector index is like between the time like you chat to be blew up within you know six or seven months a bunch of the major systems that now support for them um so I think that you know things like we8 and and and other Vector deases you guys are evolved over time to start doing more of the things that you know incumbent existing databas systems actually look like and so the lines will actually start to get more blurred like you know that you that you guys potentially could become the database of record and you may need to support transaction you probably will support SQL and and then so that's one one perspective and then the you know the postgress of the world those'll start adding support for for you know Vector operations or similar similarity searches I think um I think standardization of what the API should be or the the query language should be for Vector searches I think that would be nice to have resolved in five years but the SQL standard is g to take a while so like so just again I'm just predicting so maybe 2028 the SQL standard will now include uh a vector you know Vector support but like by then and every all the VAR systems will have their own apis and query language and so there'll be a standard but no one's going to follow it um as as we humans do yeah as we humans do yes yeah so back to question like I think it'd be nice to know in five years what the next big Hardware thing is going to be and that we have to rethink the design of database systems um I'm uh I'd like to see more Automation in databas systems and again not just because I have a startup in this space but I think uh I I think there's a lot of Unsolved problems um and a lot of it isn't always machine learning a lot it's just interacting with humans um so I think that would be interesting well on the transactional database side oftentimes you're limited by the speed of light because you have to communicate over wide air networks and so there's there's limitations what you can actually do um so I don't foresee any sort of groundbreaking fundamental changes to how you build transaction systemss I think'll just be improved engineering yeah that makes thank you thanks for sharing this was great yes I would say Al I'm very excited about BPF I think that's super fascinating as well that like like can you start putting BPF eppf in Linux kernel like can you put uh can you start putting you know database logic inside of the OS kernel and then you can imagine in the future we' have like a unic kernel where you just have like okay here's a operating system that that only runs a database system and how much of that functionality can be push down the kernel I think that's another big Trend we might see as well it's so funny it's just not not to not to not to uh uh go down another rabbit hole but I recently saw people started to argue or come up with ideas if if a model could become a form of Colonel so who knows maybe that's a way how things get connected together but it's a it's exciting there's like a lot of stuff happening people are creative and building a lot of new stuff so it's just it's just an amazing time it's just uh I think that the most you know joyful things that just that I can see so many people build new stuff low level up in doesn't matter everywhere so it's like it's uh it's exciting so thanks again for for doing this I really appreciate it oh thanks for having me yes amazing thank you both so much um Bob I remember when we were talking in Croatia and you and we were talking about like who would be the ideal guest and I was like it' be so amazing if we got have Andy Pavo on the podcast and I can't believe here we are and now we have this podcast Andy thank you so much for joining oh yeah I'm just I'm just regular dude you said I I apologize for not scheduling soon like it's the busy time in the semester so like it was bad timing but like I I apologize I wasn't trying to blow you guys off please understand that no no but ", "type": "Video", "name": "selfdriving_databases_with_andy_pavlo_ainative_databases_1", "path": "", "link": "https://www.youtube.com/watch?v=_QBZv5DrCUM", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}