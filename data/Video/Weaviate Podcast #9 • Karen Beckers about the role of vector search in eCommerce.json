{"text": "Karen Beckers, Data Scientist from Squadra Machine Learning Company, gives insightful information about how to use vector ... \n[Music]thank you so much for checking out theeighth episode of the we va podcasttoday i'm joined with karen beckers adata scientist at squadron machinelearning company karen thank you so muchfor coming on the podcast can you tellus about how you're using the we vv8vector search engineyeah thank you for having me i'm reallyexcitedas you said i'm a data scientist it'squite a machine learning companyand we're a company that providescustomers with ai and data sciencesolutions on one hand we have our ownproductsum and we focus onsuppliers wholesalers and retailand with those products we providesolutions for smart product datamanagementsupply chain optimization and as we liketo call it ai commerce instead ofe-commerce but on the other handwe do projectsand these projects we provide datascience solutionsfor any specifictask that a customer might have so andthis is actually where viviate comes inbecause for one of our customers ane-commerce customer we're building asearch engineand we're doing this a little bitdifferent than themoretraditional methods of search soactually umbuilding the search engine based on theimage relevanceso we started out with the proof ofconcept of only a thousand productsuh just to see if it was actuallypossible can weget relevant resultsumresults are relevant to the query basedon the imagesand at that point we were just bruteforcing it so we were just we calculatedthe vectors which is brute forcingthe the vector similarityand of course that doesn't scale ifyou're going to larger data set so wehad to transfer uh transform to adifferent platformand um so that's when we we stumbledupon wev8 and umsince then it's it's been so much easierthe whole process has been so mucheasier and yeah it's really it's reallygreat to be to use with yetyeah i think that that idea of using animage to search for products is sointeresting and i've seen uh demos ofsay like the fashion mnist data set togive kind of like a illustration of whatthis looks like where you say take a bagand then hit the data set of bags tofind the most similar looking bagwhat so what kind of data sets are youusing to kind of uh bring that to thereal world to say like maybe pinteresthave an api or like how do you get thedata set of real world uh theseecommerce kind of picturesum so the the data that our customeruses he um they they scrape thedata fromfrom brands that they they are sellingand we're using azero shot model that is actually able tomaptextual texts and images to the samevector spaceumand for search that actually worksworked well and we're also using it forclassificationumbut for classification you can do somelike after the vectorization you coulddo a linear probe toyou know match thethe vector a bit more a bit better tothe categoriesthat sounds so interesting like thatpipeline of um so for so you could havean image image search a text to imagesearch and then you can also append aclassifier with the high level discretevariables ofbag shoe or maybe brands like nikeadidas orthat kind of thing so what kind of um sowith the text to image search and theimage to image search what kind of arethe two different things that go intoeach of those thingsumso forthe thing if you use text to image thenumyou can also expand that to text to textand then combine thoseand the difference with image to imageis that you only have that image andum[Music]so we're using the model that i justmentioned that maps text to the samevector space as images but we're alsousing only text modelsumso if you if you do text to image thenyou can use both but if you do imageimage then you only have that imagemodel so you only can make use of theinformation that is stored in the imageumwhich is also a challenge but that'sinteresting of courseyeah it's so interesting you can also uhlike label it with like you know thesymbolic metadata that describes theimages as well to have that kind ofmaybe sanity checking for the imageimage search i'm curious about how youevaluate the um do you annotate say likethe top k and you have annotations ofthe best nearest neighbor for images orhow do you kind of evaluate an imagesearch system at scaleyeah that's that's difficult um becausewe don't have a golden standard oflike a set of queries that we we knowthat these products have to come up inthe top 10 results we don't have that sothat's difficultumbut we're now using atool called cupidwhere you umwhere you can they the tool lists yourtop 10 results and you canannotate them yourself with eitherbinary battery uhmeasurements or on a scaleand then as you update your algorithmand different results come come up thenthat automatically updates as well soyou at least have a quantitative idea ofhow good the results areyeah that's so interestingthe umso cupid is a labeling software is thatcorrect i'm really curious about thesekinds of things and uh can you tell me alittle bit more about what cupid doesyeah i'm actually just getting intocupid myselfwe started on that uh i think two weeksagoso that's all that's very newbut umit's not not in that sense a labelingsoftware it'sumit's maybe more relevancy toolfor any search engine so it's actuallyum[Music]it's pre-built for solar orelasticsearchum but we justumrewrote our our weavit output so that itlooks like elastic output so that thetool can actually interpret thatumbut i think just for any search engineyou needa tool to umto score your results to say okay howhow well is my my system actually doingand cupid is just one of those toolsthat that can help you with thatyeah thanks so much for that i i lovefollowing along with these labelingsoftwares and i see like the big namethings like say um scale ai and snorkelai the things that i think most peopleare aware of but also been looking intothings like rubrics and learning moreabout these tools i think it's such aninteresting uhpart of this so the next question that ilove to ask on the web podcast and ithink especially for image to image andtext to image search is such aninteresting different angle is usuallywe're talking about text to text searchwhere we have all these say sentencetransformers and the hugging face modelhub i'd say is you know mostly gearedtowards natural language processing butso how well does say using a resnet 50trained on imagenet uh just right offthe shelf taking those pre-trainedembeddings and then using that to imageto do image to image search in thetransferring domain from you know thethousand or so classes in imagenet intoe-commerce how's that off-the-shelftransition from pre-trained model intoapplicationumthat's a good questionumyeah sothe the model that we're using it's notnot the pre-trained resonant or it isum one of the versions actually resonantbasedumbut this one is it's just trained on thebasically what they say is like wholewikipedia whole internetum with the images and the labels themetadata labels that are with the imagesumsothatgives you a whole like a very broadbroad scale of what what the the modelactually knows so that's that's reallygreatbut umfor a really funny example actually whatwe saw that themodel was trained up untili thinkmaybe 2019 sopre-coveredand so it doesn't recognize face masksso that's actually very funnybut of course now face mask you can'tyou see them everywhere there's such anormalnormal view on the street and the modeljust doesn't know those so that's that'sdifficultwow that's such an interesting part ofthe um the updating information andthat's one of my favorite things aboutdecomposing deep learning tasks intoretrieve and then read because uh whenyou separate it into a separateretrieval task you can easily update theinformation compared to having onerunning supervised learning model andyou just try to like update theinformation by doing further gradientupdates with some uh new data set but ilove how you could justjust you know drop in a new retrievaldata set with the face mask to have thatadaptationand yeah i think that's such aninteresting part so it so is this theopen ai clip model that you're usingyeah and yeah exactlyyeah i really like this paper it's uhthey use this weight space ensemblingtechnique where they go from the uh fromthe zero shot generalization of cliptrain on all of the internet and thenthey fine tune it on particular datasets and these are like academicbenchmarks it's not like quite like uhe-commerce product matching but theyshow that if you do that weight spaceensembling along the path from thepre-trained clip checkpoint into thefine-tuned representationthen you get like the both the zero shotflexibility as well as that like indistributionfine-tune things so do you have uh likeparticular ways of evaluating that thatidea of the out-of-district like the howyou would say how flexible it is howrobust it is compared to the evaluationon the fine-tuned data setum no that's actuallyvery difficultright nowbecause we we don't have we haven'tfine-tuned clip ourselvesmainly because we don't have a largeenough data set that's actually labeledthat was alsoumthe challenge that brought this customerto us their data isn't labeledumandwe had a we had a a blog on mediumactually about image classification uhso that's how they came uh came to usum[Music]so that was already a challenge for usokay we we can do image classificationbut it's difficult if we don't have anylabeled data so that's why we we turnedthe clip and then that thatthat actually turned out to to workreally wellumand we're all we're also yeah we'reconstantly thinking umabout how can we how can we improve backwhen we we fine-tune the model but if wedon't have any any labeled data thenthat's really difficult soyeah i see the um like the idea of usingtransfer learning to label data for someother domain or say umyeah like this idea of maybe you mightcall it programmatic labeling where youhave the pre-trained model that you'renow using to label data it kind ofreminds me of say like semi-supervisedlearning as well yeah you know propagateit and go label the unlabeled data andyeah this is one of the things like uhcoming back to these say like uh opensource labeling software tools therubrics framework has a great interfaceforuh this this idea that we're describingif you use the clip model to label yourunlabeled data set and i think that'ssuch an interesting topic with likebootstrapping unlabeled data sets andthen maybe pushing those to say like thehugging face data sets or somethingwhere people can collectively use themand build on themwhat kind of a vision and language datasets like inspire you to work on themmaybe like visual question answering orvisual common sense reasoning i seemaybe like a lot of vision basedrobotics where the labeling is uh likefollow instructions through some kind ofthing something like that what kind ofvision and language data sets interestyou the mostumum i have to say like except forwe're not doing a lot of visionvision projects right now so we'remainly using using clip for that we wedo use a lot of language modelsumthere was this project um where wetrained the team the googlet5 modeland we we use it to train a paraphraserumand we have we've been using abirdscentsy bird uhum[Music]so umi think yeah maybe those are maybe themore standard models but umi think right now the model that thathas the most promise um that has beenproven to be the most promising for alot of projects that we're we're workingon is probably sentence birdyeah sentence bird is so cool i lovethese like the siamese architecture ofthe decomposition of bird into justsomething that'sintentionally producing embedding soso the um yeah the text description sowriting some kind of description thatdescribes the product is that kind ofit's an interesting thing to me iswhether you want to take like an imageof the shoe that you've seen on on maybeyou're watching a tic toc video and yousee a shoe that you like and you want tojust take a picture of it and use thatto indexlike amazon oror whatever to get the product butcompared to writing a languagedescription of the thing you're lookingfor do you think thethe language description is maybe a moreuhsay like robust path for search thanimage based searchnot sure actually becauseyou knowas they always say like a picture saysmore than a thousand wordsi think that probablyuhi think that probablyis true for this as well right um youcanyou always describe the the image or theproductum from your own imagination and if thatdoesn't really matchumor is just differently nuanced fromumhow it's represented in vector spacethen that umthat could could be problematic andmaybe maybe an actual image is morerobustand you could you could probably do bothas well right like have the um you sendthe image and then maybe it's like justinspiration and you're trying tolike um i like this sneaker but maybesomething that's more soi don't know what kind of textualdescription would expand on thisparticular sneaker but the combinationof language and text to search forsomething how would that kind of thingworkyeah that's really interesting i thoughtum i read an articlea while back they're saying that googleis actually working on that right nowthat you can upload an image anduse a textual descriptionum i'm really interested to see how thathow that would workumi don't have any experience with thatum i am i imagineyeah imaybe you can combine the vectors insome waysay if you if you would would map thevectors to the same vector spaceand maybeyou can calculate an average of the twovectors combined that has thethat both informationthe information of both both entitiescombinedi'm very interested to see how thatwould workyeah i love that idea and like alsomaybe combining it with like thesymbolic annotation which i want to askabout next but uh yeah i love the googlesay the landmark detection competitionthey host on kaggle i think they hostthat every year whereyou have an image of say eiffel towerand then you index their database tofind the other image of the eiffel towerand i think this is one of the most uhlong running nearest neighbor opensource competitions on kaggle and youhad such an interesting idea of addingon the text to further enhance that likeimage image text image kind of searchthing so i want to talk about symbolicfilters and like symbolic search seemsto be basically solved where if you havetheyou know symbolic annotation on theproducts and the query you can justexactly match them and say they'reexactly matchedso could you extract the symbolicfilters um from the text description sopeople don't have to beuh like entering their schema and havethis kind of fixed schema whereas theycan just write natural languagedescriptions and then from there you cancreate a symbolic kind of tagging fromityeah we we do um we do that in in somesense um where we haveone of the products actually that we wehave at the machine learning companyis a feature extraction tool where youcan upload a product descriptionand thenyou also uploadyour your data model so you you knowthe the whole taxonomy you know whatfeatures there are and what the possiblevalues are and then the algorithmextracts um those features from from thetextumso we're also doing that for thiscustomer as well and we're trying toenhance it withimage feature extractionso um where we accept for example coloruh you have a list of colors and thenyou can say okay what color matches thisuh product bestthat's super cool that because that kindof adds like the symbolic filtering ofsay regular expression matching in textto images where you can you know findthe color exactly by using the um byhaving just the pixel that appears inthe thing uh can you so can you tell mea little more about yeah this mappingfrom like unstructured data likeyeah images or just a languagedescription you describe your productwith into structured data where you havethat data schema you have that kind ofpredefined model of what your data lookslike how does that mapping fromunstructured to structured data lookumso on text based we we mainly useregular expressionsbut[Music]of courseyou can also provide a list of synonymsand then you have a really elaboratesystem that can um extract those thoseelements from the text but then ofcourse there's also the possibility whenthey're the the product is actually redshoes but then the description says youcan also pair this really well with yourblue jeans so then extract red and blueand for that we actuallyagain use some vector representation todetermine which color is actually bestfitted to the product so use the contextof the whole text to determine whichvalue is actually trueyeah i love that dimension of addingsymbolic filters even within the samedata domain so so for like searching forimages if you search not just for sayanother shoe but like then a wholeoutfit to be returned and you add thesymbolic filter on to what's beingreturned and this is kind of like one ofthe more technical details in wv8 that ireally like talking about is the um likethe pre-filtering step on h sw wherethey actually cook these symbolicfilters into this massive vector indexthat can do something like search forthrough 100 million vectors of picturesof shoes and e-commerce products i thinkit's so interesting though uh so on thatalso though coming back to symbolic andstructured data and we talked aboutfusing embedding spaces of imagerepresentations and languagerepresentations could we form say usingtechniques like contrastive learning ormaybe mass auto encoders representationsof the structured data as well and thenhave that further embedding spacealignment between images language andthen the structured data as well throughsome deep learning technique to encodethe structured datathat's a very interesting ideaum[Music]i think if if we can that would ofcourse be very helpful becausewith the symbolic data you're almostallrestricted to to keywords ora list of synonyms and that's nevercomplete so if we can actuallyuh have some kind of embedding spacethat incorporates everythingum that would that would be awesome ofcourseyeah yeah i think like the multimodallearning the ability to combine allthese different kinds of data i i thinkthat's what's driving like what's on thefrontier of what will drive so muchprogress in this technology kind of sowith these advances in deep learning forsearch and e-commerce can you maybe tellme some things that uhnot to name any particular e-commerceplatforms but some of the things thatare missing that really need to be addedor on the like the front the cuttingedge of like uh new features ine-commerceum[Music]with with deep learning well actually ithinkummaybe what we're doing and what we'retrying to do right now and retrievingproducts based on the images umi think that would help a lot if that uhof course it's still an ongoing processand it's very difficult to to tune ittune it well and and get the properresults because sometimes you do needtextualfields to get the actual good resultsbut if if we can umalready establish a baseline based onthe images that i think a lot of uhe-commerce platformsuh could benefit from that thatif their suppliers uh provide the datathen of course there's always noise inthatand supplier maybe some suppliers theydon't provide the data in the correctformat and so if we can enhance thatwith the images or some some automateduhin an automated fashion then that wouldreally be a helpful thingyeah i love the idea of say when you seesome funny thing at home goods and youtake a picture of it and then it indexeslike etsy ebay amazon and you have thiswhole like umthat idea of going from an image intothe whole catalog of all the things onthe internet i think is like such aninteresting topic with things that mightbe on the frontier and like new ideas ine-commerce so so i wanted to ask youabout what you think about kind of opensource generally and the idea of sayproviding demonstrations of what yourtechnology can do on say hugging facespaces and how there are these easierinterfaces to build and share userinterfaces with tools like saygradio or streamlit as well as kind ofthe general topic around sayopen sourcing data sets and publishingpapersumi'm actually not familiar with withgradio streamlit but in generalopen source datasets and openness modelsand the whole open source community ithink it's it's it's actually for usit's great because a lot of times we getcustomers that like they're notuhtheir company isn't that large so theydon't havethat that a great amount of dataand the data is often not not structuredwell or it's it's really noisyso that is always difficultyou know that there is an ai solutionthat will work for them but if you don'thave the data to train that modelyourself then that's very difficult soum using those open source models andbeing able to tobaselike have a foundation based on thoseand then being able to fine-tune it withthe the smaller set of data that you dohave that that is really helpfulyeah that like collection of pre-trainedmodels and like coming back to thepre-trained uh siamese bur sentence berti'm not sure what the s stands for inesper i think it might be sentence forbut yeahbut but yeah like the the boom in thepre-trained architectures it enablessuch a like starting point and also likekind of in taking down the cost oftraining these models because you havethe pre-trained checkpoint so you don'tneed even with your smaller data setgenerally you don't need touh tune it for as long do you see thecost as being one of the other like bigselling points of these pre-trainedmodelsyeah exactly could we uh if you wouldfor example gt2 or even gp3 that's noteven realistic to train it yourself withwiththe data and the the costwe can we can haveum so yeah if we if we don't have to dothat ourselves and that that'sthat's really helpful that's that'sgreatwe can we can't use that we can'tmimic that ourselves as a as a smallersmaller company not not one of the thelarge larger tech companies in the inthe us of courseyeah the cost of it is such aninteresting part of deep learningbecause it'syeah to push the cutting edge of it youneed to really have expensive computersand you know distributed computers andall thepretty interesting stuff have any recenttrends and kind of efficiency gains indeep learning been interesting to youumyeahumthere comes one model to mine i actuallyforgot its nameumyeah let me think about it i thought itwas really really interesting because ofcourse with all the bigger models thatare out there right now umthere's a lot more computational cost alot of morein that sense electricity use and allthe data centers that are constantlyrunning andumyeah we're trying to be a little bitmore environmentally friendly but datascience isn't really and so i read aboutthis this model that umthat uses a lot less capacity um that isactuallyumi thought it was was a multitask somemultitask model but it would only umactivate thoseneurons that i would actually use andthen and that way it ituse a lot less computational uhpoweri'm yeah i forgot the name about it buti thought that was very very interestingif we couldumfrom a data scienceperspective be a little bit moreenvironmentally friendly as wellyeah i think you're talking about the umthe lottery ticket hypothesis and the inthe masks that they put on theon the network and it shows that youonly need to say the sparse sub networktouh achieve the same performance as thefull dense networkand yes i think as cool as that sparsemasking idea is i think they still havesome like hardware optimizations beforeyou can really completely realize theefficiency gains of applying the maskingonto the dense architecture because ithink right now you're still doing thesame computation you just add the massto it no okayso i think there's still uh someinteresting things to be developed inthat kind of idea sokind of more broadly with like um datascience and then like we v8 vectorsearch and i think it's reallyinteresting maybe this transition anddatabase technology from sql relationaldatabases into nosql the flexibility ofjson kind of data the way that it letsyou just adaptively update your schemaand now into wev8 where we have theflexibility of nosql but plus this deeplearning functionality what do you thinkabout this kind of trend in this toolingfor data scientistsuh yeah i think it's really helpful uhespecially since we'regenerally in data science we're moving alot more towardsusing vectors than than any othertype of dataso having the infrastructure to actuallyuse that and make because thei think the previousgeneration of databasesthey're they're they're very they'rereally well established and you they'rethey're great to useum sogoing into that new area of vectorsis they may be a bit more tricky in thedatabase sense so using a tool like likewe've a waywhere you can actuallyuh have a solid base umfor your data then that that's that'sreally greatmoveforward yeah i think there's a lot ofinteresting topics with um how datascientists will use vector searchfunctionality and as particularly aswe've been talking about the idea ofusing unstructured data more so whereyou just haveimages or just freeform languagedescriptions of whatever data you'retrying to describe maybe and then youcould go into all sorts of things likeaudio video biological data graphstructured road networks all these likeunstructured kind of data sources thatyou can use now forstandard kind of data science do youthink the downstream functionality as wesay describe like nearest neighborsearch as retrieve and then read beingyou take the retrieval part and then usethat as input to some kind of supervisedlearning model do you think supervisedlearning models will become a morecommon tool for data scientists i knowwe maybe do things like regressionanalysis and look at the coefficients ofregressions and do the correlations doyou think maybe things like sayretrieving from your data and then usinga text-to-image model togenerate some kind of say visualizationof your data or any kind of thesecreative supervised learningapplications do you think that willbecome more popular with sayjust like the average data scientist whoisn't necessarily like a machinelearning research scientistumwould you maybe rephrase that i'm notsure i understood ityeah like um the idea of labeling pairsof data for like labeling x y pairs andtrying to bootstrap somesome kind of taskdo you think that's something that couldbecome more common with like a typicalday in the life of a data scientist orin comparison to maybe say umusing mostly say like descriptivestatistics looking forlike statistics in the distributions ofdata and the kind of say traditionalsort ofproducing charts and that kind ofobjective of data scienceoh in that sense yeah i do think uh thatwill become more um[Music]we will see that a lot morebecause i also think that um the modelsthat are out there and the tooling thatis out there to use the models isumhow do you say it's more accessible thanit was beforeso not only for actual data scientistsbut also for peopleum they're not really data scientistsbut they're more accessible to use umi actually had a header id once thatmaybe in the future there will be like aplug-in in in excel where you you loadyour data and you just you push a buttonin excel and say okay they're now nowtraining gradient descenttraining simple regression model or evenan ensemblemethod um that and then maybe not evenpeople who know about the data sciencecan use those those methodsoh i love that idea even people whodon't even know about data science likeyou could just have a natural languagevery fuzzy description of what you'retrying to do with your data and and itcould interpret that and map it into afunctioni've seen um hugging face added togoogle sheets and yeah that kind ofintegration i think is so interesting ofadding deep learning functionality intosay just like excel spreadsheets butthen also as we talked about integratingthe unstructured data as well which ithink is such an interesting part of ofthe weevie because with wva you canstill have your structured csvs if youwant to look through that and have thatkind of json data but then you can alsoaddimages andlanguage and things that aremore uncommon to this so so with youruse of uh we v8 how has that been do youhave any things that like you know maybeyou wish were added to ev8um wellthere were actually already a couple ofthings that um when we started out withwev8 i think it was the end of novemberumsome functionalities that we reallyneeded weren't there yet sofor example the the openai click modelthat we were using they um didn't haveitout of the box in in we've yet yet so weof course we could import our ownvectors and then use a new vector searchwith thatum but then the downside is that forevery query we would have to vectorizethe query ourselves so send an apirequest to our api send it back and allthe latency issues that come with thatum so that um they already that the clipmodel is actually integrated in with itright now so that's already great thatthat's really helpfulumbut also what we're i've heard thatthey're that they're not currentlyworking on the beam 25 integraimplementation so we're really lookingforward to that becauseas you said we we can use the symbolicdata to filterumbutthen the integration of doing actualkeyword search retrieving results basedon keyword search and then combiningthat with the image resultsis currently very difficult becausethere's no score coming from the keywordsearch and umthere is a score from the image searchbut then how how you have to combine itin some way how they're doing that ifyou don't have scores for both so we'rereally looking forward to that to thatimplementationbut i've heard they're working on itright now soyeah that's so interesting and uh kindof the first thing you said the themodularity of the different vectorizersor the different embedding models howyou have the open ai embedding model inembedding models like clip or say the umthe latest cpc code cpc text and how youcan put the model into eva so you don'tneed to have two separate apis and theni love this idea of the combination ofdifferent retrieval models in the sameapi so you can have the bm25 and you canhave your dense esper representation allin that same api and then you startgetting into this really interestingtopic of how do we interpret this kindof fuzzy distance and combine theoutputs of tfidf bm25 these lexicalsparse retrievals with denseesberg how how are we supposed to fusethe outputs of themdo you have any further ideas on thismaybe say like um coming back to thelabeling software maybe we could uselabeling software to start annotatingthe uh the different scores that comeout of our model and then have likeanother neural layer on top of that thatuh interprets the outputs from say fivedifferent retrievals where it could beuh tf idf bm25 and then say threedifferent variations of training youresber model because the the ways thatyou fine tune it right could lead todifferent behavior too many ideas on ilike how we can combine those outputsyeah that's actuallyvery difficult and we we've been stuckon that for quite a while now umbut it's very interesting what you'resaying we also have that idea that wehave all these different components sowe havethe image image results but we're alsodoing atext similarity on the product names andwe can do text similarity on ever anyother field that we have but then alsodo the keyword searchand then all those different componentshow are we going to combine those and weactually had an idea of training maybejust a very simple random forest and usethose weightsum actuallythe or thethe the feature importances of thatmodel uh to use as weights for for allthe different componentsumbut uhright now we don't have a fixed solutionyet so if you haven't have any thenideas always welcome because it's a verydifficult topic and it's still ongoingand it will probably be ongoing for awhile i don't think it will be solvedvery soonyeah i've discussed this with some uh ofthe we vva team and we love this maybecalling this human computer interactionthis idea of how we interpret thesefuzzy distances from neural searchescompared to as bob describes the binaryoutput of when you search for somethingin a traditional search engine it eithercontains it or it doesn't compare tothis where it's like this is 80 similarto what you said and you're like okay sowhat do i make of this and i i love whatyou said with the random forest layer ithink maybe in my studying of deeplearning i become like overfit to thisidea of putting a neural network ontoeverything butwhen you just have these uh you knowfive different outputs you couldprobably just use a simplerlike uh just a random force or uhlike really like umnot not using a neural networkimmediately because umthe well the whole the whole field of aiwhereespecially the past couple of yearseveryone's really focused on neuralneural techniquesbut umit's easy to forget the diff the otherother techniques are more traditionaltechniques that are actually very goodas welland they are very easy to train do nothave use so many computationalcomputational capacities so that that'si always like the ideas of keeping itsimpleand then having a model that actuallyworksyeah actually worked is importantlikei think it's because of like thethe appeal of using unstructured data isso appealing with deep neural networksthat you forget that like once you havea tabular structure once you have asymbolic schema now say like xgboost isthe new state of the art and umand deep learning is going to be likeharder to adapt and maybe you havethings like missing values all theseother things that come withlike these more traditional kind of datascience tools and thatthinking on that kind of aspect of itso i think we've covered a ton ofinteresting topics from uh image searchtext search and the frontier of applyingdeep learning for search into e-commerceplatforms uh is there anything else sortof that we might have missed with theparticular application domain ofe-commerce with deep learning for searchum[Music]well what's interesting in the ine-commerce is that um so many of the themodels the language models right nowthey're trained onlarge stretches of text butoften in e-commerce you don't have thatespecially if you look at the queriesthey're generallylike two three words and that's it andthat's that's also interesting to lookat if the i know i know there are somemodels that are more trained on onshorter stretches of text umumbut there there that is also a challengefor e-commerce there isn't reallya standard language model that isespecially trained for e-commerce yet soum that will be interesting in thefuture if someone wouldbe able to train that i think that wouldhelp a lot ofpeople yeah i love that thinking aboutthat like um style shift it's like kindof an abstract concept i mean it's veryconcrete when you describe style asshort sequences of text compared to longsequences of text but as we've uh beendoing the po we va podcast say um you'retraining achatbot model and you're going fromreddit conversations intoreal podcast conversations and kind ofthat style shift from the underlyingdomain is such an interesting thing andi guess like with my kind of likeacademic side of this i i think thesedata augmentation techniques could bereally interesting as i've kind ofpresented this idea of maybe learning astyle transfer model so like a textiletransfer model that couldaugment your data set by usingby using this kind of generative modeli know a lot of people who really buildthese systems for real are kind ofskeptical about that idea of addinganother model into the pipeline ofgenerating training data what do youthink about synthetic data and dataaugmentation as a technique to improvethese modelsum[Music]ithinkumit's an interesting idea andi think in many cases it can work reallywell but umi always think it's a bit tricky umif your your data isn'tuh great or it isn't isn't that cleanandit's very difficult to umwell if you keep training with the datathen uh it will only become more noisiersothat yeah i think that that's definitelysomething that you have to look out forbut in generalumyeahusing some data augmentation techniquescan be really really helpful of courseyeahyeah i think especially if you're tryingto use say generative adversarialnetwork scans for data augmentation thenyou have this problem of mode collapseand then if you sample from that you'rejust adding that mode collapse bias andclustering your your data even more onthat one point so itand then just generally that idea oflike compounding errors of yourgenerative model makes an error and nowyou put it into your discriminativemodel and it just runs away with the airi like techniques like maybe variationalauto encoders or these diffusion modelsthat maybe have these explicitobjectives around encouraging diversityin the generative model i think withthese language models the way that youdo the tree structured decoding like howwith like open ai's codecs theygenerate like a thousand differentpotential generations and they call thisrepeated sampling where they traversethe generation tree several times andthen put that into the compiler to seewhat doesn't like have an error becausethis is a model that generates code sothese kind of maybe tree structureddecoding strategies could be a way toachieve that diversity in the generativemodelyeah that's very interestingyeahyou know that like idea of thegenerative model but i think also justlike the way that retrieve then readadds that interpretability is also suchan important part of building thesesystems andso are youlike inspired by say these recentadvances like deepmind's retro modelmaybe facebook's internet augmentedgeneration or openai's web gpt wherewe're seeing maybe less hype around thisidea that like let's just build trillionparameter language models and maybe moreof a recent idea into let's decomposethe task into information retrieval andthen supervised learning yeah i think umi think in general maybe i'm not such abeliever in like onegreat ai that solves everything i thinkumdividing it into subtasks it will be amuch more effectivethan uhthan one one thatone-size-fits-allyeah it kind of comes back into thislike end-to-end like people like thisend-to-end idea whereyou know instead of featurization andlearning we just put it into onepipeline and maybeeverything could be end to end but maybesometimes we need to have a taskdecomposition andsay like multi-task learning doesn'treally always work that well maybe ifyou have things like as you mentionedthe t5 framework that unifies thesetasks into at least you kind of havelike a similar gradient scale whenyou're trying to do multi-task learningthat idea of like decomposingthe end-to-end pipeline into subtaskswhat do you think about that kind ofidea of just like let's make this wholething end to end make everythingcontinuous anything discrete let's put acontinuous relaxation on it and just tryto do gradients through this whole thinguhi'm not sure i don't it would be cool ifit works but i iuh i have my doubts actuallydo you have similar doubts in that kindof scope of one model that performs allthe tasks to the idea of off-the-shelfpre-trained embeddings like one modelthat say covers all the distributions ofdata do you think those two kind ofideas are the same the idea ofend-to-end i can learn every task thisgpt-n is the language model that doeseverything and then this idea that saylike clip and is the embedding model foreverythingum[Music]well one of what i've learned from myexperience with clip is thatit is very usefulas you as i said we don't have the databutumif you have any labeled data and you canfind units for your specific task it'salways better in my in my experienceum but it's it's it's very useful tohave the the general general modelgeneral embeddings as a baseline umbut if if you can fine-tune it to anyspecific task then yeah that wouldalways have my my uhmy preferencealso for example the gt3 model i thinkgt3 is amazing and all the theall the capabilities it's really greatbut umwith with the prompt engineering it'sit's very difficult if toto steer it in your exact directionit can do so muchbut um what we've seen a lot a lot oftimes that itum it will generate great texts that arelike you can't tell if they're they'rehuman written or ai writtenbut um it will also just make up stuffand since it's so well written you don'tknow that it's actually made upbuta lot of times information is not trueand then there's a is the problem likehow are you gonna check if it's not trueor if it is um andso it's it's difficult with such modelsto to steer it in into adirection that you you actually wantso if you can fine-tune anything ofcourse you can now find your gp3 as welland i think that that's also a greatmove forward tostill leverage the capabilities of themodel but then actually steer it intoyour directionyeah that topic of fine-tuning languagemodelsor steering yeah i like that steeringword too it's really a really nice wayof like trying to think of like ah movethis big powerful towards someuseful direction and yeah i like maybelike two techniques like as we mentionedthis idea of like generating a massivetree of potential decodings and thenputting a discriminative model thatparses that tree or maybe we've seenrecent advances from openai onusing reinforcement learning to train areward model and then use that to kindof fine-tune the model or maybe youcould just have supervised learningwhere you have some sequence to sequencedata set and you um fine-tune it on thatbut i wanted to come a little bit backto this idea offine-tuning versus off-the-shelf modelsparticularly with these embeddings and iwonder like if you think that maybethere is a fine-tuning bias where as wesay that like having labels it generallyimproves it but is that maybe becauselike the train test split is from thesame distribution of labels and thatmight kind of bias your thinking intosaying that well clearly i have thistrain test split and it's better on mytest set once it's been fine-tuned onthis train set compared to maybesacrificing the robustness and the zeroshot flexibility that is kind of likemaybe like the key advertisement ofthese models like as you fine-tune itand you evaluate it and you say theselabels have made it better is thatbecause you know you're evaluating it onthe same distribution of labels andyou're not really doing say like dataaugmentation corruption tests orwhatever like a domain shift test youcould like i don't think there even aregreat tools for that do you think likeyou're not like maybe people aren'tproperly evaluating how robust theirmodels are when they say that the finetune model is better than theoff-the-shelf modelumwell i think i agree with what you'resaying that of course if you're you'refine-tuning then you're you're losingsome of the the zero or the few shotcapabilitiesumyeah of course that's true umi've never actuallylikefine-tuned on a general data set thatwasn't specific to a task so i don'tknow ifthat would have helpedlikestill like maintaining the zero shotcapabilities umbut i thinkum if you're fine-tuning for a specifictask then that'suh if you you lose that the the othercapabilities then um[Music]of course you should be aware of thatbut i don't think that should beproblematic umbut yeah you should definitely be awarethen that if you're functioning for itfor one task it won't scale to adifferent task yeah that's that's thethat's something you will lose yeahdo you think maybe those theoff-the-shelf way to then the fine-tunemodel could be combined in thatabstraction layer where we talked aboutputting a random forest layer on top ofdifferent outputs of retrieval or do youthinklike yeah like having some kind ofrandom forest on top of the twofrom the off the shelf and the fine tunedo you think that would be useful or isthat just reaching for somethingum sothen you would put the embeddings in arandom forest andmaybe i think i think evenjust the output of the distance to thequery maybe like as we talked about justhaving like five distances returned fromtfi fbm 25 and the esper it's like thetwo distances of the pre-trained andthen the fine tune is it earlier imentioned the weight space ensemblingtechnique i think this paper was fromthe allen institute in the university ofwashington maybe others i'm i don'texactly remember but it's like this ideathat you doan ensembling of the weights as you goalong that path from the clippre-trained checkpoint that open aireleases down into thisfine-tune thing and you could have someway of combining the outputs from eachof those two checkpointsand maybe generalizing that with ouridea of the random force abstraction ontop of these retrieval modelsyeah it's a very interesting idea not ii'm not really sure how that would workactually but um[Music]yeah i i thinkit would yeah it would be interestingi'm not i'm not really visuallyvisualizing it right nowyeahi think those diagrams and maybe theretrieval pipelines it's like maybe theyneed to be interactive diagrams or youcan like yeah press plus and add moreretrievals and stuff like thatso as we've covered so many topics ihave maybe like a meta question for youis just asking like um what are yourfavorite sources of information yourfavorite strategies to improve yourskills as a data scientistumwell there are a lot actually i i reallyloveworking with with people for example nowfor this customer that we're building asearch engine we're working with peoplefrom all over the world and people whohave a lot of experience in search andjust being able to work with thosepeople and get the knowledge from themuh doing some pair programming uhsessions with them and that that helps alot and that's that's very interestingand i think that that's maybe my myfavorite waybut also just umlike reading vlogs on on medium orum what watching the videos of the scaleai conference for example i think that'sthat's very interesting as well soyeah i think the i prefer it to be likein person that that's my my favorite waybut they'll there are so many ways to toget new knowledge and it'sit's unending[Laughter]yeah i agree the in-person thingdefinitely adds like having a conferenceor definitely adds a lot to it and it'sfunny also mentioning the scale aiconference that was such a superstarlineup of uh talks they had this year itreally was if people are looking formaybe something to watch that scale aiconference you have like clement de langrichard sacha like a lot of theseleaders of these massive companies thatwe're talking about most of the timeso yeah that was a super cool thing sothank you so much karen i learned somuch from uh talking to you about allthese topics and uh good luck with theseprojects on ecommerce such aninteresting application the squadronmachine learning company it all soundsso exciting and coolyeah thank you very much connor[Music]", "type": "Video", "name": "Weaviate Podcast #9 \u2022 Karen Beckers about the role of vector search in eCommerce", "path": "", "link": "https://www.youtube.com/watch?v=brUP1OEtQ5U", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}