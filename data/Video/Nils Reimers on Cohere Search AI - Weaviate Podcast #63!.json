{"text": "Hey everyone! Thank you so much for watching the 63rd Weaviate Podcast, I couldn't be more excited to welcome Nils Reimers ... \nhey everyone thank you so much forwatching the weeva podcast I could notbe more excited about our next moviepodcast we're hosting Nils rhymers againon the wevia podcast to discuss allsorts of things about Ai and search sortof last time when we did our firstweekday podcast and those we werepresenting the cohere multilingualembeddings models and we similarly havea really exciting integration toannounce with weavier and the coherere-rankers so you know I love kind ofhaving this the new update about cohereand weavate as well as diving into allthese academic topics with you because Ijust think you're one of the world'sleading scientists on search and it'sjust so much fun exploring these thingswith you so firstly thank you so muchfor joining the podcastyeah I'm super happy to be hereum exciting times so I don't knowprobably like half a year ago I was heretalking about multilingual so semanticsearch is amazing for multilingualsetups so especially as a Europeanum it's it's nice to see work outside ofEnglish be done and yes super happy totalk today more about re-rankuh challenges and semantic searcheveryone faces at some point and yessolutions for that yeah I love thatfirst podcast how we you know describethis kind of evolution from building thesentence Transformers library to now acohere and how your Evolution andthinking about the maintaining of thisdata set kind of we discussed like thiskind of closed Source versus open sourcemodel kind of category and we had thesebig topics around like how do you handledistribution shift what's the state ofsparse vectors and the future of that soI'm going to be kind of uh kick thispodcast off with the cohere re-rankerssort of what goes into that and maybefor like levia users listening like youknow sort of like what they can expectfrom adding this to their searchyes soum so recently like a couple months agowe launched a new model a re-rank modelwhich is like a super cool thing sothere's still a lot of people who sadlydon't use vv8 who are like stuck on likeold lexical search systems uh sometimesproprietary where they are not able tochangeand it was re-rankedum what you do the the API looks reallysimple you put in the query you put itin like a collection of documents top100 top 1000 documentsand it's as Dimension as the name saysit does a re-rank so you've given athousand documents and that spits yourlike which documents are the mostrelevant one so so this is like supereasy to add for anyone who's not yet onvb8 Whose stock was like old solarimplementations or external apis that Ineed to usebut also in in vv8 itselfum it makes really sense to do both so Ido like semantic search for somebettingsum get the top 100 top 1000 out of likeembedding search and put it into re-rankumso so s talked previously and in manyother settings there are certainchallenges and semantic search with somebettings and which will also talk latermore about uh looking forward to that soso one challengesemantic search and embeddings have islike really complex queries so so if youhave like multiple facets where you saygive meum I want you to know the informationhow Google employees changed in Europebetween 2010 and 2015.so at some point it's like really hardfor embedding modelsum to to get the produce the rightembedding so so it's like basically yourbeddings are like shooting in the darkum so so it doesn't know like whichinformation do you have in your vectordatabaseum out of your search query it does likea shoot in the dark and then hopes thatthere are like 10 documents which areclose by giving you the information howGoogle employees changed number ofemployees in Europe changed in 2010 to2015.and re-rank is really well on thesetypes of queries so it used differenttype of Technologyum where it looks at all the documentsyou provide in like all the hundreddocuments you you provide and then makesa decision based on these Androiddocuments okay which one is the mostumyeah the best for your query so it's notlike a shoot in the dark I produce theembedding and then I hope to get the toptop 10 with the information I reallyunderstanding reading all thesedocuments you provide in like in the top100 listand then telling you okay these are likethe top 10 documents uh with the mostrelevant information and so what we seeis like really strong boostand search quality especially on complexdomains complex queries where you havelike multiple aspects so not like asimple fact like who's the founder ofFacebook but okay here's like a reallycomplexquery like okay which test company waslarge exposure to Europereported a revenue increase of at least20 over the past yearso so if you have like these reallycomplex queries um we rank is extremelyexcellent on thatyeah it's amazing kind of thatseparation of you know complex querieslike when do you need to use re-rankingI find that all very interesting kind ofyeah just just from the beginning oflike you know you retrieve yourcandidates with bm25 and then youre-rank them or with Vector search I Ialways love we had like thisillustration early when we first startedlooking to ranking models it's likethinking about it like a fishing boatwhere you cast like a big fish net intothe ocean and then you get like athousand fish onto the boat and then thefishermen on the boat are like lookingfor the green fish within the fish and Ialways love that angle because it showslike how the ranking models are likemore accurate but slower and I feel likethat's you know but you're adding areally interesting extra Dimension thatthere are some particular kinds ofqueries like the multi-discourse thingwhere you have this kind of funky querythat you would really need to have thathigh Precision you know document andquery as input I guess I think we canreally dive into this topic of rankinggenerally and what ranking means insearch but quickly I kind of want tounderstand a little more about thetraining of the ranking models thatcohere is is this like kind of the samedata set used to train the embeddingsbut you train a classifier instead of anembedding model is that a cartoon Cityuh yeah it's it's similar based on someof my data sets so last year we spent alot of time to to get like a big dataset in many languages so got likeroughly a billion question answer pairsin English half a billion in non-englishlanguagesand then yeah this this is the basis forthe embedding model and also like forthe rewrite models So based on theselast amount of questions people haveasked and answered in the pastthe model luckily it knows a lot aboutdomains like really long tail about yeahthe weirdest subtopics you can find onthe internetand and yeah really gets this knowledgewhich which make them extremely powerfulyeah I love that conversation topic ofhow you think about curating this dataset obviously you know one of yourearlier works with the sentenceTransformers and you know we're gettinga billion pairs together that had reallyinspired my interest into this wholekind of cat I think that was just a hugeevangelist for all this so it quicklyyou mentioned like long tail and youknow I remember that one billion pairsit had like Reddit stack Overflow howare you currently thinking about thatdata set aggregation I'm sure like forlisteners understanding how cohere wouldthink about something like this is areally interestingpart of ityes sir soOne Challenge was in the field ingeneral is umhow quickly is the knowledge gettingoutdated so we're producing like newnew words new product names new companynames new events Games movies and so onso so this is like in general like achallengeumit's hitting especially hard theembedding models so as mentionedembedding models it's like shoot in thedark so so you have like one shot youhope to produce the right embeddingwithout like having a lot ofpossibilities to compare results and sothey are like really really subjectiveto these issues so if there's notsomething new happensum they are not aware of a lot ofembedding models that they are trainedon like old data like Ms Marco from2016 with a bird model which was alsotrained on like 2017 2018 data so if youask the models anything about Coronastill thanks Corona is a nice beer anice Mexican beer and then if it asks ifyou ask like okay what are the symptomsof Corona it will say okay you gethangover and drunk by itum so so that's like a really reallychallenging for the embedding modelum so here you wouldn't need likeconstantly updated information uh whichwas like hard in terms of deploymentbecause you you need to re-enteric oryour vector database so so if you go inlike a billion scale this this becomes areally slow and expensiveand for the re-ranking model as youmentioned it's like this fisherman andsay okay look at the fish look like okaywhere's the green fishum these are a lot more robust in termsof like domain shift out of knowledgeout of timeso here you don't need to to update themas often and also the the update is mucheasier so so with some bettings if youupdate the embedding model you need tore-encodeyour whole Vector database which is slowand expensive and painful if you havelike a billion embeddingsat the re-rank model you yeah it's justlike one API call on top of the top 100results you get from the vector databaseso it's like really easy to update toswitch it and yes so here we were aimingto have like always up-to-date knowledgeum in these modelsyeah that is a super powerful point therobustness of the ranking models and Ihope you have people listening know thatyeah you know that that kind of thatproblem of updating either the coronaexample is perfect I won't even addanything to it but but just that kind ofcontinual learning problem andunderstanding that the cross encodersthe way they attend to the query and thecandidate documents it makes them morerobust to I mean we I think we were allseeing this zero shot ability of modelsand so it kind of brings me I kind ofwant to talk broadly about rankingmodels I understand that like you know alot of ranking models use kind ofsymbolic features as well like say it'slike Google search it probably has likeyou know some information about me likeyou know I'm 27 I'm a male and it willuse these features as well as kind ofthe content and the quick like the querycontent as well as these symbolicfeatures and you'd maybe give that toxgboost and there's some new work that'sshowing how you can maybe uh prompt llmswith these kind of features do you thinkabout those kind of features in in thesekind of systemsyes sir so this is still a kind of likea big challenge big issue with semanticsurgeumforsemantic search queries they work niceif I ask like what's the averagelifespan of a cat especially with VP Ifind the informationbut if I search like let's say on it onSpotify for um updates on AI like I wantto listen to like some cool podcastsupdates on AIum if you just search on the text baron the text field you might find like ashow which has like yeah updates on AIbut this show might be from like 2015 itmight be really poorly rated like oneout of five stars and then there's likeanother show which is like I don't knowlike a week old really highly rated whatthe name is like not like updates herelive I like I don't know weekly digestand machine learningum you as a user would prefer like therecent one the popular one the highlyrated one or like the old one and sothis is like a big limitationum as you mentioned a lot of people whatthey do is like XG boostand I'm all learning to rank sobasically in the most simple formum you have like some semantic matchfrom ether like re-rank or embeddingsuh you have like a score on recency youhave a score on popularity and then youdo like a linear interpolation and sayokay I don't know 50is semantic match uh 30 is isum recently and 20 is popularity andthen you play around with the three waysto give you like the final rankingumin generalum it's not really fun to do this umit's really really brittle so you spenda lot of Cycles to play around withthese three weights uh like chaosrecency should be like 10 20 50 percentif you just for like recently too highonly the the most recent podcast willshow at the Top If you put likepopularity too high only the mostpopular as shown even if you like Idon't know do like a really Niche querylong tail query with okay I'm reallyinterested in this oneuh tiny podcasts you're not able to findit and then you try to balance itbetween these three factorsand so yeah so I think there's a lot ofpotential here to make it better whilewe're also like working on it likerethinking like how can youum yeah learn these as part of the modelyeah I think um like if I can um yeahjust kind of continuing on the potentialof this I think you know having the llmand prompting it where you get eachsearch result is like a Json dictionaryand the keys are like content and thenthe text content and another key mightbe you know date published is probably agood example when you want to sort byrecency and sort of as you can justprompt the llm to like you know pleaseuh you know re-rank these but prioritizerecency you know but like not at thecost of it it's not relevant like thatkind of soft fuzzy prompt in it and it'sstill able to kind of interpret that andI think the distillation of the LMS intothe cohere re-rankers for thatparticular tab I love that topic of likedistill llms into some specific task andI think the ranking is just the perfectperfectly set up for this so I thinkthis would actually transition reallynicely as we come into our academictopics to talk about temporal queriesand how you're thinking about thatyes attemptum it's a challenge so it's like reallya lot of people go go into like semanticsearch so so you see a lot of peoplereally testing around and yes sadlyembeddings itself they don't have like atemporal understanding so let's say youhave your email inbox you you search forit which time is my flight goingand then with semantic spiritual you getthe information hey your flight is goinguh 5 p.m on August 4th 2010 so it'sfetching you like an email that's 10years oldum because yeah for for the embeddingthere's like no Temple notion in it soso if if there's Nema from 2010 that hasexactly your words hey your flight isscheduled at 5 PM it will find and showyou this resultso so what what you often have in searchis like theseyeah not not these implicit expectationsor assumptions from users so if I searchfor at which time is my flight going Iwant to know like probably the nextflights or something today tomorrow thisweek so I'm looking for like my nextflight that's going in e-commerce youoften have it when I search for shoesum there's like a lot of shoes on Amazonbut yeah it makes a difference and I'm aman a womanuh am I like what's my age do I havekids do I have like son or daughter andand what age are my kids and thendepending on theseum it makes a difference so maybe I'mlooking for my uh shoes for my daughterwho's like two years oldum so so maybe I put just kids shoes inin the best case it shows me likeum shoes for girls two years olduh but yeah this is not in the querythere's somewhere outsideand so it's a fascinating problemum how to encounters where yes semanticsurge what was the mattings hittingcertain limits so so in the embeddingspace you you can't have like thesetemporary relation and then yeah peoplestart to hack around and say Okay umcementing match 80 percent recency 20percentuh try try to use thresholds let's sayokay find all emails um at which time ismy site going so find all emails with athreshold above 0.7and then rank them based on recency solike a lot of hacks and tricks going onin the space to really go from like ashiny demo to an actual production usecaseyeah I have kind of a coupleperspectives on this temporal queriesthing I think like for I think it's alsoquite heavily related to kind offiltered Vector search and for people tounderstand that you do the hsw graphtraversals and you have this like allowlike one way that we do and we've eitherI could I could go on about these thingsthat I probably saved up late for laterbut like you'd have an allow list ofnodes that match the filter IDs and solike date greater than July 5th could belike one of the Criterion that lets youTraverse the embedding proximity graphbut I think there are quite a few thingsthis the first is like like there's kindof like an emerging category of startupsaround like metadata extraction fromunstructured text chunks so we had BrianRaymond from unstructured on the podcastyesterday I listened to Doc ugamipresented llama index and there's ChimaLang chain law minute they also havelike these data loaders and so likeusing language models or I think kind oflike especially talking in those rhymerslike llms we both kind of understandthese just mean like deep learningmodels it doesn't necessarily have to belike 200 billion parameters to do thetask but like training specializingmodels on extracting metadata that youcan then label each year text chunkswith the date that if it's captured inthat which that's why I really like theexample you just presented and it addeda new perspective is when you have thatquery that's like you know I needflights for tomorrowyou I guess you need to have some kindof query understanding layer in themiddle of that D and so that makes meask you would is that the next cohere uhmodel integration that we'll be doing isthe aquarium intentuh yes uh so if you're search for whichtime is my flight going tomorrowum you need to toin some some integrationum I'm not the biggest fan of likemetadata extraction so because thenyou're kind of like limited to likeumyeah which meta data do you have what doyou extract and doesn't match what'slike the theum the thing you you have when we havesomething like um at which time is myflight going tomorrowlike finding the right email is kind ofchallenging so so it's not like the mostrecent email you got was flightinformation because this could be aflight somewhere in the futureit's probably not an email which is like10 years old but it can be somewhere inbetween like somewhere in between likeone year and yesterdayso it's like really really hard toexpress this as heart filters or as SQLwhere you say okay give me I don't knowif I asked like at which time is myflight going find all the flights emailsI got and then sort them by recency andpick the most recent oneumso here we're currently developing yoursmarter way so New Foundation model insearchum where we don't have to do like thetracks with metadata filtering and goingfrom unstructured data to structureddata and thenlanguage like SQL or whatever or howeveryou express your filters and yourordering but really do it like in themall itselfbecause I mean it's it's always peersbut observed for me that we have likeLMS and we take LMS to transformunstructured data to structured data tothen be able to search to search on itso why not like directly use it in thealarms and be able to do let them do thejob and and yeah extract what's neededand then tell me okay what's done thereyeah I think um I guess there's there'skind of I have two kind of reactions tothis the first of which is there's kindof like filters that are like totallyunrelated to the content so like it likeif I have a you know shoes again andit's like how many of them are in stockthere's like no way of having theembedding you know how many I have in mystore kind of so I kind of see like thatcomponent to filters but then again likehow an llm or whatever metadataextraction model similarly would not beable to derive that and so yeah I agreewith you it yeah it's very interesting Iguess I I probably would just need moretime to see it all play out to have astrong opinion of my own about this butI agree with you that like if the llmcan extract the metadata from the chunkitself then you probably also couldcapture it in the embedding and thereprobably is something to thatyeah I guess yeah I mean these metadatafloaters they are nice and e-commerce wesee that I'm like on the left bar wehave like a sidebar where you can filteron the price where you can filter likethe brand the color the sizeumhere it's always like a question it'slike yeah you always have like these hotfilters where smkgive me anything I don't know like someitem let's say a smartphone that's belowlike I don't know anything below 500and then I have like a really hot filterthat's like anything below 500 butwhat's the case if there's like asmartphoneperfectly fitting what I wanted so I waslike looking for Christmas for a newsmartphone it should be like small sothat fits well in my pocket cameraquality was importantFactory lifetime was important I didn'twant to spend more than 500 dollarsbut these five hundred dollars is likekind of like a soft limit so it costslike 500 and one dollar and it's likethe perfect phone yeah I take it also ifit costs like 550 or 599 dollars I saidyeah it's so much better than anythingelse and I would buy it and it's uh so Ithink this is at least what I see inVision like long term and we can get ridof these filters and just phrase it as asearch query where I say okay I want asmartphoneum should be small enough to fit into mypocketum should have like good camera qualitygood battery life time and I don't wantto pay more than 500.and then the model can decide itself andsee yeah here I got like a phone and gotreally highly rated good feedbackreviews on users the size is like reallysmall so so it's a tiny phoneum but it costs 520 dollars but I thinkyeah 520 it's good good enough and areyou willing to to go like twenty dollarsover your budget let's say yeahperfect so I'm willing to do thisthis reminds me back to our originalconversation on ranking models where Icould have like yeah like that that likeboost filter is kind of like what I liketalking calling it and then we getdiscussions of like what an API wouldlook like but like yeah like you knowplease rank it higher if it's less than500 but you know you don't need to be sostrict about it and that kind ofthinking about how you do the iPhone umyeah like um I guess it kind of alsoreminds like it's this topic again it'svery similar to the llms extractingmetadata it's the ranking models it'slike if the ranking models can do itthen can the embedding models do it aswell but I think like having thatsymbolic control it just makes it somuch easier I I guess one other ideathere's this paper called nhq which islike you would have embeddings for eachof the filters as well and maybe youcould have like a multi-vector rankingthing where you have the pooled vectorfor the entire you know Amazon iPhonethis iPhone that we're talking aboutthis the description of it and then youalso maybe have like vectors for each ofthe labels and so it's still kind oflike embeddings so sort ofyeah maybe that kind of thing but so Ithink kind of I kind of did want to staya little more on your skepticism of themetadata extraction with language modelsbecause I think it ties to another oneof you know the topic so we'vepremeditated is like um I find it veryrelated to kind of chunking and longdocument representation because I feellike what happens isum your motivation to extract metadata alot of the times is because you're likeparsing a PDF and you know it's like asemantic category like you know it'sthere's only a hundred tokens in thispart of the document but like for areason it's got like a title like uhthis is like this uh legal clause andthen here's like another one right likeso so yeah so maybe if we could kick itoff with your perspectives on Longdocument representations and then maybewe can see we can tie that back to thiskind ofextraction topic yeah so so I mean fornow metadata extractionit gets the the things done like in manycases so just say like long term like Idon't know five ten years I don'tEnvision the field that we're stilltaking LM extract metadata put it intolike some relational database for likeyeah find ways how we can do it directlybut yeah to the topic long documents umyeah long documents are challenging inan embedding searchumfor a long time sequence lengths havebeen a challenge in Transformer modelslike birds it's like 500 above tokensand this this got recently fixed waslike longer sequence lengthsum like like llama 2 what we have nowopen source models up to like 32kum but it's sadly not solving it forembeddings or search so so yeah you candeploy it but there's a quality of allthese models is just terrible and theissue is that embeddings can encode likeone one Topic at a timeso they can store like one fact so solet's say like the founder of a companyand can encode these like Max Zuckerbergfounded Facebookum but they struggle if you have likemultiple facts like let's say you havelike a long list of all U.S equities sothey're like 2 000 or moreuh us equities right now with the phonenumber informationit's like okay should I include it likeat Facebook or Google or at Amazon orNvidiaum so so you get somewhere some strangeembedding in the middle uh which is hasnothing to do with the specificinformationum so so what you need to do is liketake the long documentum break it down into individual factsand that's the first challenge like howdo I know okay this is like a new topicso I'm am I still with the old topictalking about Mark Zuckerberg and fondof Facebook or is it the new topic aboutBill Gates and how he founded Microsoftum so so that's one challenge secondchallenge is contextualizationum so you might have like a header andthen you know okay this this paragraphisum belongs to the header so so forexample in every reports you have Appleannual report 22ndumin the text itself it never mentionsApple it always mentions we or ourcompany and it also doesn't mention 2022nd anymore it says our company saw alot of growth this year and then thequestion is like okay who's like ourcompany who's like this yearand so here the contextualizationapproaches are kind of interested inwhere they take the long documentand you decontextualize it so if youhavea paragraph like our companies or a lotof growth this year you rewrite it toApples or a lot of grills in 2020.and then also to look at like okay canwe split it into like individual topicswhich we can then encode as paragraph inthe vector databaseyeah I love that uh it just I just hadthe light bulb go out but like you knowI love this idea of like well we're kindof trying to call these generativefeedback loops where you use some kindof generative model to like kind ofalter the data that is indexed in thedatabase or or just save for any reasonkind of but this particular case of likeyou know like something I love is thesummary index where you take like youknow these podcast clips and say I'mstuttering like uh right and it kind ofwill compress that into a summary of thecontent that I say and then you embedthat summary and I love that I thinkit's a really clever way to build uhbetter search indexes and as youmentioned disambiguating you know ourcompany means Apple that that to me thatsounds like another kind of likegenerative feedback loop use agenerative model to fix the data thereso then there were kind of two things Iparse out of what you're saying um thefirst of which is kind of a uh likegenerally you know language models aregetting along your contacts things likeAlibi attention you know the details ofhow that works I think maybe you'rerelevant for the podcast but likegenerally we're seeing models that cantake 8K 16k 32k and it's like will Alibiattention work its way to embeddingmodels maybe if I could quickly get yourtemperature on that and then we couldcome back into like multiple facts andmaybe yeah because we and then we alsohave like structure graph data so Ithink it would be a nice transition tothat but let me quickly take yourtemperature on like Alibi attention it'sclearly you know being impactful withanthropic cloud and you know all thesekind of things will that kind of thinghelp embedding modelsbadly not as as mentionedum embeddings only work if you have likeone factin a per textand there's like not so many texts outthere where you say okay I have like 8000 tokens but it's just I don't knowrepeating Max Zuckerberg foundedFacebookum totally if you take like a 8 000token article let's say from MarkZuckerberg or Facebook there's like alot of informationum about Facebook early who founded itearly days nowadays transitions to metaand so on which are like all differentfactsand every effect needs like a differentembedding so so yeah we can add Alibi toit that's not the issue yeah if youinput it like full Wikipedia article andthen you search on it um search qualityis terribleso the so then this brings me back tothe metadata extraction thing becauseidentifying facts isn't that kind ofsimilar in a way like because you haveto say like okay this is one fact thisis two facts in this unstructured textChunkmyes it's kind of metadata so so it's uhcurrently like a hack a trick that getsthe things done so so it's totally okayin searchfor search for the past 50 years italways has been like using hacks to getthings doneumchallenges always but when you do likethis the contextualization which Imentioned earlier like our companyhad the best year or this was the bestyear for company where you replaced thisyear was 22nd and company Appleum challenges there like how much shouldyou decontextualize like how muchinformation should you provide into thatum it's kind of like easy for like thisreally simple one sentencebut if they go in like an annual reportyou have like Apple annual port 2020.subsection I don't know Europesubsectionum I don't know iPhone subsectionuh Market uh share of iPhone in Europeand then you have like some informationlike complex information on it so soit's like probably a lot of like contextinformation to understand this paragraphum well then the question like okay howmuch do you include do you just includeit's Apple 2020um or is it do you also include like allthe information what I talk about like amarket in Europe for the iPhone withlike certain subset of customersum and then it becomes like reallyreally challenging again to find a goodtrade-off where you say okay you havelike this one sentence but to reallyunderstand the sentenceyou might need like full paragraph orfull page of context information andthen the question was also like how toembed it where you say okay this this isthe sentence and here's like the fullcontext to understand the sentenceyeah I love that decontextualization Ithink that's a wonderful phrase likewe've seen like Disney yeahlike one example right now we knowDonald Trump is front of the uh court istriedum due to and we have like a lot ofcontext information where he was notaccepting the last U.S elections andyeah Trump fans were storming U.Scapitalum so so there's like a lot of contextout of context information where alsothe question is like okay if I Indexthis news article where Donald Trump hasis this trialed in Washington do I alsoprovide like all these backgroundinformationwhich led to the trial or notyeah that's because like um so you wouldtake like one text Chunk that's like umTrump fan storm U.S capital and thenmaybe you'd want to add to the chunklike because they believed the electionwas quite a topic maybe find anotherexample but but that kind of thing of itmakes me think like about um you knowmodels at data ingestion that again thattopic of like the summary index kind ofthing but where you use more models inthe process of parsing out your data andbuilding up the index and I think it'sall very interesting but yeah I thinkthis would be a great transition totalking about uh graph data I'm not sureif we're if you you know like maybe totransition like there's kind of two waysthat I see about thinking about multipleabout organization of facts themselvesyou would have like you know Nilsrhymers works at cohere and you knowlike author sentence per and like youhave these these relations and then whenI just grab the node nose rhymers I canreally easily parse out all the factsAssociated but or you would take eachfact have a natural sentence for it andthen embed them and search so I yeah Ilove kind of I don't have a greatunderstanding of when to use which but Ithink those twonow headsets yeah let's see it's aninteresting so interesting road ahead ofus so everything searches just at thebeginningum current technology is totally fail asmentioned if I ask like any searchsystemum at which time is my flight goingum they all fail possiblyum so so this was like an interestingaspect what we need to see in terms ofresearch in Industryum what Innovations come in like like dowe use like these knowledge graphs wherewe represent facts and say okay this ispretty soon they have like thisinformation and their cve like pastPublications past company engagement andso onumlike more in a symbolic way or do we doa lot more in like kind of like anabstract way where we keep like a textrecord and then the model is ableget to find the relevant information andquicklyumyeah quickly recent about this and yeahright now like finding thesedisinformation and then judging is itrelevant or not is this kind ofchallenging so we all know largelanguage models they have challengeswith hallucination so so if you ask themwhat are the symptoms of some fakedisease like these these I just inventedum they give you like really compellingwriting what is this disease what aresymptoms what is the treatmentbecause LMS transform us they areterrible in not knowing and knowing thatthey don't know itand that's that's basically like thechallenge in search lie you need todecideis this text providing me theinformation is it answering the questionor not like at which time is my flightgoingumso here they're like really really badat and we need yeah a lot of Innovationsand breakthroughs and this spaceyou know I I I do have to likehypothesize that the kind of crossencoder would be really great at thatlike at which time is my flight goingand then boy yeah hopefully I mean andthen it kind of retrieves from yourcalendar it's kind of like the it thiswhole thing is our the way ourconversation is evolving is reallyinspiring me into the whole likeretrieval augmented generation as wellas like kind of the agents thing I thinkthe agents thing ties into at which timeis my flight going and you've hooked itup to tools like my calendar and so andthen like that that's kind of likethere's all these like models in themiddle I found this topic so fascinatingbecause like they're like sorry if thisis too much of a tangent but I like thispaper called gorilla quite a lot wheregorilla is like a large language modelfine-tuned to use a particular tool solike in the case of the calendars don'thave too many apis but it's like how doI format a request to get uh like noserhymers is this Friday and like geteverything to understand when yourflight is but you know generallyactually let me kind of just broadly howhow do you feel about retrievalaugmented generation right now and Imean it seems to me obviously fromalleviate like this is like you know ahuge evangelist I know you know coherehas like the Corral system Coral systemand yeahyeah yeah it's a massive topicum so so we have this Coral system whichis like an intelligent Enterprise agentso so you plug it into your Enterprisedata and then you can ask questions likeokayum we we have this customer give me anoverview of the customer engagementwhere are we which are the latest topicsand blocks from this customer so insteadof like you as manager like pinging thesets wrapum you get it directly from your CRMdataso I always have the feeling people putdata in Salesforce but yeah look at itand instead of like Ping people togethersummary so hopefully we can change thatso yeah we're truly augmented generationisfascinating and we have like reallystrong models here on the one side forsearchand because this is still a bottleneckand on the other side in generation andcitation so so big issueum was generated models of us generativemodel hey um I don't know what's thesize of this companyspits me out like some number like whenI say okay what's the revenue of Appleit gives me some number but it's I don'tknow is it true or not and and I don'tknow if I used to ask like thesegenerated models hey how many studentsstudy them in my University where I didmy PhDgave me a number but it was like a bitof like off by some few thousandstudents and that's like really hard toto to judge it and here citations isrelevant to say okay I can go back tothe primary source and say okay the UIgot the informationsofor example if I ask the model in anEnterprise settingumand what's the the pricing discount wecommunicated to that clientyou don't want to have like somehallucinatedso so you don't want to say yeah we wesaid 30 discount and then you think okayit's 30 discount but actually you justcommunicated like 10 discountum or or is it okay in terms of likelegal questions is it okay to useum your software in such a such settingand then the model says yeah perfectlygood but then you say now well how can Itrust it and I think here giving thecitation and say hey yeah you can usethe setting here and the source is thisemail from January where we ask thosequestions and based on the answer theyprovided we thinkum yeah you can use the software in thesetting so so you can verify it as ahuman if it's actually true or notyeah I think there's so many topics toexplore I mean the kind of uh give thecitations I think that's one of the mostclear applications like uh reasons to dothis like as exciting as L alums are thehallucination problem and having beingable to look at the search resultsthere's so many interesting things inthat though like the the question ofwhat is the size of this company I'vebeen loving saying this recently is thatevery weevier class is jointly a vectorindex a Json index and as well as an SQLindex with we don't have an SQL API wehave an aggregate API so the syntax is alittle different and it's a littleinteresting thing of how to interfacethat but like you you Tran you take thiswhat is the size of this company and youknow is that a vector search queryperson I think it would be better offTranslating that to like a you knowsymbolic aggregate like you know thisbut then this coming back that clearrightand that they're the challenges again doyou have this in like a relationaldatabase or aggregate like you have likea column yeah let's say employees orRevenueum it's also a bit unspecified size ofcompany do you mean like Revenue profitemployees yeah um in the past it couldalso be like physical size of thecompany like how many square meters isthe companyum and and here yeah I think that that'sthe challenge was metadata to come backto that so so if you ask like okay howmany employees work at this company ifyou have a column if you extracted thisit's good if you just have like Theunstructured Meta like unstructuredannual reportsum yeah it can just look into a lag andsay okay fine in the unstructured meterdata okayumthis is theumthis is the size of the company like thenumber of employees of the company thenwhere it becomes interesting isum if you do like combinations of likeinference of information when you sayokay how many employees does Apple havein Europeit sounds so maybe in your database youjust have like I don't know fromBloomberg you get the data number ofemployees at Apple but you don't knowlike employees in Europe for Apple likefrom unstructured data like some newsarticles someand we report some press release theymentioned okay we have like I don't know100 000 employees roughly 30 of theseare in Europe and then you can inferfrom like these two information nuggetsokay Apple a good estimate is like 30kin Europeand so that's that's fascinating likewhere we need to rethinkum how databases work and then we willsee a lot of Innovations going a lotmore into like unstructured only becausewe're structuredyou will need to think beforehandum that someone will ask like how manyemployees does Apple have in Europeand and this is kind of like a rabbithole where it says yeah you could asklike okay how many employees are inGermany how many employees like Franceand then it gets like you wouldn't needto think about this beforehand when youcreate the metadata and Abstract thedatayeah well all that is why I believereally strongly in kind of the longevityof Frameworks like llama index linechain like Haystack Gina is like thiskind of you know like the sub quite likeself-ask prompting is kind of like theAcademic Way of like there's a papercalled neural databases from JamesThorne and others which is like yeahexactly I mean you painted the pictureperfectly you decompose the questioninto like maybe a symbolic question aswell as a vector search and then youlater on kind of pull it and I thinkthat kind of you know semantic layer oforchestrating these kind ofLMS and all that will be reallyinteresting um I kind of wanted to stayas sorry to be picking the topics butlike when we're talking about retrievalaugmented generation a little more andtalking about kind of reducinghallucinations as being maybe one of thebiggest drivers of this kind offramework I wanted to get take yourtemperature on retrieval aware trainingthis like for example I mentioned thegorilla thing earlier the way thegorilla thing works is you retrieve theAP you're you're giving it a naturallanguage command like in the example ofwe via to apis you'd be like bm25 searchin pod clip return speaker content andit will take that natural command andthen translate it into the graphql thatcould execute against the weba databaseso the way this is trained is youretrieve the API reference and that goesin the input alongside the naturalcommand and the schema to you knowoutput the graphql query and I feel likethis kind of retrieval aware trainingcould just be so powerful I'm curiouslike if cohero is thinking about doingthis would be om is obviously in thesearch and all this kind of stuffyes that's uhit's it's a big Focus so so internallyand also to offer customers we have areallynice wreck modelum which which stuff these uh so inItalian rack versus like QuarryFoundationum how do you break up your your queryinto sub queries execute on these how doyou get the data how do youcreate like the subset of data that goesinto the rack model let's say you havelike a queryum how did the revenue develop for thebig five test companies during covetso so this is not like a single query soso if you work with the inner reports ofcompanies it's not like a single queryit's like a set of queries so you getneed to get the data for Facebook from2019 from 22 for Google for for Amazonand so on and then you need all toprompt this into the generate modelum challenge is was a lot of generatingmodel out there and like llama open Aiand traffic they they have not beentrained on this and we trained likeextensively on this so on the internetyou often see like the final result soyou write the final blog post but youdon't see like the research that wentinto the the blog post like what werethe search queries you formulated uhwhen you were informing yourself aboutthe model and so so this is currentlywhat we're doing it's like showing theresearch process like how does a humansearch for information which informationdo they take into account beforeformulating the responseso bring this capability to the modeland then also be able to reference backand say okay this this part of theinformation I got from the source thispart of information I got from thatsourceso hereum yeah we will see at least from hereyou will see a lot more on Foundationmodel from from thisum models like really understand tosearch what to search for how toreference back informationum as it's kind of like a vital eventyeah I meanand so going forward I mean it's it'salso the shift we saw with humans Idon't know when I started to programwe still remember people try to memorizelike every function you have in C so solike okay you know all the thefunctionings because it was like reallyslow to search so you had like a bigbook and then you don't need to go inthe back in the index and see okay whichfunction do I use to I don't know sleepmy process for a secondbut this really changed was like Googleand stack Overflow or nowadays yeah Idon't know there are some functions wealways searchum like I always search what I like thearguments for the select function pythonand yeah with co-pilot it's awesomeyeah less and less knowledge needs to bein our head and and we're doing more andmore storage in the background and thenuse the search resultsto enter to the next token and the samewill happen with generate model theythey will learn how to search how totake search results into account so Ithink the kind of really interestingphilosophical thing for me is I rememberlike you know Bob had showed me thisnotebook from Nick Frost which was likequery formulation so you take the promptand you don't just send the prompt tothe vector database you first send theprompt to an LM to ask it what would bethe query for this to then query withthat and then answer the question thatway and I think kind of for me it's likeyou know this difference betweenlearning how to search I think this iskind of there are a few things to thisbut I like the first thing there's likehow to search with Google search likeBing API serp API and like kind of likethe web GPT search actions where youjust kind of think about like what queryto send maybe like next page of resultsversus kind of the gorilla thing whichis like how to particularly use the apisof like weviate and these searchdatabases Vector database search engineslike crazy you want to use and then Ithink there's also this kind of reallyreally interesting emerging category oflikeend-to-end rag where you would maybe putgradients from the reader back to theencoder and it so it's kind of learningit in a very neural way like none of thesymbolic layers have had the Bing API orthe weeviate API but it's just goingkind of and it also would you kind ofuse weaving to have to store the vectorembeddings from the encoder even if it'slearned end to end so kind of thesethree things that hopefully that's a nottoo ambiguous of a question but likeyeah I mean the final one let's end toendum it's it's interesting my reallyreally challenging I mean there was thisoriginal ritual paper which had likeretrievalumwithin the pre-training of the model soso before it predicts like the nexttoken the missing token it looks intolike a massive Vector database to findlike similar textumpeople were extremely excited about thatat that time butfeels like there's like basically zerofollow-up so I haven't seen anyone likereproduce or or work on it umas a challenge isumin these settings you you make it likeoften like too easy so so in your textyou have like a lot of duplicatesand then the question challenges is umwhen you ask like okay what's what's vv8and then it retrieves the informationthere's a similar textlike a new duplicate for the model it'slike really really easy to just copypaste the words from from there so soyou don't get like anyreasoning or knowledge into the modelumif you're not extremely careful so youhave to control like how good is thesearch quality if it always finds likean exact duplicate of the text youcurrentlydo next token prediction on it it willnot learn anything just like yeah do dopredict the next token and we'll copythe the token from the search resultsand that's a challenge other challengesengineering wiseend to ends youhave yeah many moving Parts which youneed toto fix and it's like really hard toimprove upon individual parts let's sayif you have an end-to-end systemand and you see okay search quality isnot greatum because it doesn't take like recencypopularity into account let's say you dolike search over news you ask okay giveme in insights about the US president'selections and then gets like informationfrom 20 years agoin an end-to-end system you can't go inand fix this one system and say okaymake the search results better or makethe generative better it's always likeif you want to fix one thing you have towork on the hill pipelinesearch and generate like search errorand generation search and generateand this makes it like a reallynightmare to to work on enhanceyeah uh yeah I I agree 100 with that Ithink yeah yeah and I I guess the onlyyeah with the rag into end thing I'm notsure really where my sentiment is at onnow and I don't want to put out like abold too too strong opinion but I meanwhat you mentioned about kind of parsingout the search results this kind ofbrings us to our original Top This IsWhy I'm so excited about the coherere-rankers is like you know I read thatpaper lost in the middle that's abouthow you can't just give it like 20search results and expect it to find theanswer in the 20 and that's why I thinkthe re-ranking having that top oneis just going to be so powerful and yeahkind of you you mentioned retro and I Iwould love to get like to dig it alittle further with you is that I soretro is the idea where instead ofretrieving to put it in the input solike you retrieve text put the retrievetext in the text input and thenTransformer you would retrieve theembeddings and then you put that inlayer like eight out of 12 in theTransformer and I'm not sure I exactlyunderstand the math but I think it'ssomething like you know in that you canlike transpose the the key and thatquery key value kind of attentionmultiplication such that by retrievingthe way that you could you could putlike a thousand embedding so you putlike a gigantic amount of memory kind ofin the middle of the Transformer so soyeah likeI'm not sure like um I think thequestion is like is that maybe a betterway to do long context I think might bea way of thinking about ityeah it's set sets yeah it's achallenging to make predictions[Music]umI mean yeah long contextumI mean yeah we have these memorynetworks they were really popular in2015. that's lstms so there was like abig hype on memory networks andinputting stuff in memory and andscaling memorywhich also didn't share to be arealisticso I think kind of yeah we we need amixture so so in Lim pre-traininghaving like on the one side like Closebook is good so so it's the same withwith let's say studentsumif we're educating teaching people howto programum it's good to have like some sometimeslike close booksum tasks to say okay here's a function Idon't know written a CSV file transformthe data write out a Jsonum without looking at stake overflowprogramming references or I don't knowasking co-pilot to do this so thisreally helps students to learnunderstand Concepts and to memorizeand it also makes sense in othersettings to say yeah you can use stackOverflow or or python references to lookfor it you can use stake overflow for itto look for Solutionsum but yeah in general for for manysettings nowadays like really hard tofind examples to say okayif if you give a task likeum I don't know give give me all theprime numbers between 1 and 100.as an exercise to students yeah peopleput it into Google find it on stack flowoverflow or ask me how I am get the codebut it's not really preventing them fromlearning umso so I think for lmms we need somethingsimilar something needs to be closedbook say okay here you don't have likezero uh references like like and saycoding write me find me all primenumbers between 1 and 100 and print themas a listand do this as close book do likeanother step where you say okay you'reallowed to search pythonum references so here's like the pythonreference handbook and I give you likesome hints and say okay these functionscan be helpful or make it like reallyum like yeah allowed to use everythingand say okay you are you're allowed touse all the Googleoil stack Overflow but thenum yeah more on mostly goes here andsays yeah I just copied the results sohere you as a teacher need to be likereally good and creative and find tasksum where there's not a solution yet andso that the student be like a human or abit like no I'm still is able to learnsomethingumuh I love that that I always love theselike deep learning training algorithmsthat are inspired by human learning I'venever before that thought about thedistinction between when you learnsomething when you learn better byhaving a be closed book versus open bookit'sextremely interesting and novel thingI've never heard before um yeah yeahit's just really interesting I love likecurriculum learning and I kind of thinkgenerally the interesting thing is kindof the extensibility of rag sort of likeyou know right now the way we do ragswith llms is you know the llms aretrained with language modeling but wejust augment the input data and it worksthat way and I think with retro there'sanother paper called memorizingTransformers that shows we can and Ithink retro is like you can retrofit Ithink that's like what the name meansthat you could take an existing LM andextend it with that layer eightattention soyeah that's all super interesting soyeah also so I think kind of ananchoring podcast is you tease thatmaybe you had a bit of an announcementbut not too much and if we could talkabout this kind of I think we've alreadysort of talked about it a bit in thepodcast but this kind of foundationmodel for searchyeah so um as mentioned search still hasmany challenges uh long documentstemporal information multiple fieldsmulti-modalityuh popularity recently so so yeah myteam is currently working on like NewFoundation model for search to reallyaddress all these aspectsyes it looks really cool uh so lookingforward to a talk a bit more on this inthe futureI really yeah we want to tackle most ofthese problems so obviously there willbe challenges going forward and we hopeto to do like a leapfrog jump like inthis this space yeah stay tuned for formore and more announcements on thatyeah that's of course we're exciting andI I really want to also ask about kindof you know like I think cohere offersfine-tuning embedding models and I guesskind of my thinking about how finetuning Works generally is that thebetter the foundation model the moreeffective fine tuning and then there areall these questions about like what areyou paying for like some kind ofguarantee of model performance do youshould you get to have the weights orjust like have the API host all thesekind of questions and so I'm curiouslike with New Foundation model forsearch and then you know will that beable to cover will you not even needfine tuning because I also feel likekind of the sentiment on fine tuning islike some people hate it some peoplelove itum in general I think we we try to getaway with as little fine-tuning aspossible so so fine-tuning always in thepast means you need a lot of data andyeah no one wants to create like a lotof dataum it says for example we had like onecustomer says okay we love searchresults that contain a table becausetables are really relevant for our usersso like a markdown table[Music]um how can we get them at position oneand with fine-tuning it would be likeembedding models yeah annotate 10 000exampleswhere you search for where you have liketwo results posters relevant but the onewith the table should be more relevantand then fine tune the modelwhere obviously they say yeah no waysorry we're not Google we're not able tocreate like these 10 000 examplesso so one one way ishow can we put it into the foundationmodel that we give like theseinstructions for Search and say okayum if you find two results both are onthe topic prefer the one was themarkdown table or in podcastum first check is is the contentrelevant to the search query and thenumprefer like recent podcasts and popularpodcasts over non-reason non-popularpodcastum and the other aspect is like how canwe still include these preferences orget the preferences quite quickly andencode it in the modelbecause preferences can be differentdepending on the companies also a newsearchyou extremely care about recency if youare run an archiveokay here like historic news articlesyou don't care so much about recencyum recently can change on users someusers say okay I'll just listen topodcasts at most months old I would sayno it's super interesting to also listento podcasts 10 years oldcan depend on the setting like in sportsyeah no one listens to like 10 years oldspot podcast focused on Sportsbut in other like let's say art I don'tknow True Crime you say yes it doesn'tmatter if the podcast is like 10 yearsold or one month oldit's still True Crime it's a nice storyum yeah I care more about likepopularity and then is there like a goodpersonal fit and so this is like goingforward bigyour working block fastum how can we enablenon-expert users to really steal themodel first approaches was the promptingthat you are have like some easy way tocommunicate it and then going by yarnprompting have efficient ways for yourshow like 50 examples 100 examples andthen based on these hundred examples themodel is able to to understand youumyeah I think that's always been the goalof deep learning is trying to learn withas few examples as possible because ofthe painstaking effort of collecting bigdata sets I love that kind of maybelanguage models could generate syntheticqueries from your documents if all youhave is documents of that angle I I loveI mean I think it's been one of ournumber one topics throughout this wholepodcast is how do I boost based on doesit contain a markdown table and you knowmaybe the again the ranking models couldtake that kind of prompt of like pleaseif it has a markdown table or if you'veextracted that metadata where you havelike uh contains markdown table true andyou know you promote those results so soyeah all of it it sounds so excitingNils thank you so much for joining theWii VA podcast it's you know so greatfor me to learn about how you'rethinking about all these things I'm sureall our listeners will love this andyeah thank you to our listeners andeveryone at the wevia team that enablesme to have conversations like this thisreally helps my education and knowledgeof deep learning and search Nils thankyou so much great thank you so much", "type": "Video", "name": "Nils Reimers on Cohere Search AI - Weaviate Podcast #63!", "path": "", "link": "https://www.youtube.com/watch?v=KITxQzV97jw", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}