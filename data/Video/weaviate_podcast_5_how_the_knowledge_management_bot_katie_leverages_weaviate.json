{"text": "Katie is a knowledge management bot, continuously improving, self-learning, and trained by humans. Under the hood, Katie is ... \nthanks for checking out the fifth episode of the we vva podcast today i'm joined with michael weichner who's building a really interesting system called katy which is a really exciting use of these natural language processing vector search systems to answer questions about uh business data and so in this podcast it's going to be a little different when we really dive into a specific application and put together all the pieces of the vector search engine solution and the we vva database and understanding how to build these kind of systems end to end so michael thank you so much for coming on the podcast and could you explain to us what the kd system is and what the goals of it are oh yeah sure well thank you very much for the invitation um yeah well maybe just to give you a little background how i got to katie actually i'm uh i'm participating in open source for quite a long time i became apache software foundation member 2004 whereas at this time we did a content management solution so i'm really part of various open source communities for for many many years and one of the big problems i think on mailing list is you know that many people uh ask the same questions and i think it's it's good that they ask these questions but then you know of course there are some people which get tired of these and then the answer is uh read the manual and i understand this but at the same time it's not so nice that people do this you know and and so i often thought you know how can you solve this problem that you know that uh and you know a machine a machine is much more patient than humans you know so i i always thought if a machine could be doing this this would be great actually detecting you know duplicated questions and then answering these also on mailing list or you know chat channels like slack or whatever i mean at these times like didn't exist you had irc and uh similar things that's one that's one reason and then the other thing was like i for most of the time i worked with within my own company and which which never you know like was not like a huge company and then there was a time when i worked for a bigger company which had like 600 employees and there the first time i realized you know if you are in a bigger company you of course you know the people working next to you are working in the team but you don't know everyone at this company and then it's a similar problem you know you had a question but you don't know how to ask this because uh you know a slack channel with 600 employees just doesn't scale it doesn't work because you know if everyone would post you couldn't and you know people would just get crazy and get out of the channel and also these mailing lists it's similar and then so what's happening you normally you you ask the people around you you know like you could be the person sitting next to you or people from your team and then you say well how does this work and then they say oh i don't know but ask this person and then you know you you continue like this so again you know i was thinking how could you solve this and that so that's the other thing i observed and then the other thing was at this time at this company i worked on uh basically i worked you know i did kind of research on conversational interfaces you know like similar to siri and alex and these kind of things and uh we were doing prototypes and you know very simple things like for example then you you know here in europe you have a lot of public transportation so you can say you know hey siri tell me what is the the next train going to decent this city you know or how much does this cost and and these cases they worked quite well but you know as soon as it's getting more complicated you know for example if you have to say something like you know i should be there at this point and you know maybe i i don't know you have different conditions uh you know that the things the chatbots don't work so well anymore whereas humans you know they really are able to deal with the situation because they say uh okay maybe you mean these or what what exactly do you want and then by asking you a couple of questions and also understanding the context you know humans are able to deal with this kind of uh not so clear conversation and and fuzziness so so i was thinking oh maybe maybe it's just uh maybe we tried to solve something which we are not quite there yet even humans are able to are capable of doing this so i thought oh you know maybe we just concentrate on detecting duplicated question if you're able to solve this problem you know then we can make the next step and go beyond this so this is actually how i started katie it's really i my focus was just on you know detecting duplicated questions you know and trying to answer them as good as possible which the idea is so you know so you ask me a question for example you know i i love mountain biking like riding my mountain bike and doing cross-country races so one one one question is there you know what are the best tires you know to do country cross country race because uh you know you want to be as fast as possible so and many people ask this question and of course the answer is changing you know because there are new tires every year you know that there are some they have all these little uh but still the question is the same so if if somebody's answering this question and you know somebody's asking the question again two days later you know i can just pull it up so so that's that's the the main focus of haiti and and then of course once you start doing this you you very naturally you get into this vector search area you know because uh yeah it's as i said you know the the typical example would be you know when i'm asking you how old are you connor you know it's and i'm asking two days later what is what is the age of conor you know they are for us humans it's comple it's it's clear it's the same question you know it's about your age but for the computer it's not so clear you know so and uh so this is i think where the similarity search comes in then you know it's um yeah that's that's it so on the first thing you said i it reminded me of this book a lot uh working in public the making and maintenance of open source software i really recommend this to readers and um yeah it really describes that problem that you're describing the first thing you said about open source software people asking the same questions and and the kind of the strain on the developers time of answering the same question over and over again i love hearing that story this this idea of detecting duplicate questions and that kind of motivating use case i wanted to ask you if you saw the the core question pairs data set and how much that kind of academic data set guides your real world projects no i i saw that i i to be honest i'm not uh i i'm subscribed to quora and i receive you know quora keeps sending me notifications about because i you know i i started physics many years ago like i'm actually a physicist i i didn't study computer science uh but maybe and i got very naturally i actually when i started physics i didn't like programming so much i i was more like the you know pen and paper person but then when i did basic research i did computer simulation so i had to get into programming and this was like yeah like like 25 years ago and and i really loved it because i think it's like building lego you know it's building things with lego you can build whatever you want without much money you know you don't need much you just need a computer and that's it basically and uh but coming back to court and you know so an encore i receive a lot of uh questions and answers regarding physics you know people always ask things like you know who's the best physicist you know and how about these theory and these kind of things so so these are actually but otherwise i didn't use quora much but then i saw that quora i think published this data set of i think 400 000 questions and answers of course which is really great and uh at the same time very similar stack overflow where people ask you know questions and answers and but there again you know what i saw is what i have observed the problem is you know for example with stack overflow even if there are a lot of questions and answers you know you still for the same question you get a lot of answers you know and and you not just and also again questions are formulated differently you you and in the end a human actually would be able to consolidate these you know if a human would really spend time on this they would say okay here are five questions they are actually the same question you know but they're just formulated differently at the same time there are 20 answers and some of them are right some of them are not really right you know and again you know i i think this is no i mean i think it's great for and stack overflow they provide great amount of content to you know for us as a training and uh training set basically and also at the same time think about how can we improve this because still with stack overflow and quora i still as a human i don't get a perfect answer you know like it's not like and of course maybe sometimes there isn't a perfect answer because there are if you know it's like this again with the mountain bike example you know depending if i'm just asking what is the best tire for cross-country race you know there will not be one silver bullet tire you know that depending on the race conditions there can be different tyres so it's not a perfect but still a human would tell you okay depending on this condition this tire is really great or this tire is really great and i think the same is true with stack overflow sometimes and quara and for us this is really a great great data you know which we can make use of and and but our goal and maybe our promise is that with katie we really are able to do this better you know better than what we are able to do and i'm very confident that we we can do better we can even do better than humans you know because uh these these computers uh we have the possibility that we really are able to process much more data than a human is able to process basically so which i think is really great actually yeah and it sounds interesting like um you could get you could have like a certainty threshold on the duplicate and if it's say uh like in between 70 to 80 then you would ask for more context from the user and get even more kind of feedback in that system but so the question that we talk about on all every we vva podcast that i'm curious about is so with a data set like cora question pairs 400 000 annotated examples of similar questions a massive annotation scale you'd imagine bootstrapping something like that for yourself would be expensive and difficult and so the question is does is that all does that generalize a model that's trained on aligning the similarity between the core question pairs data set do you feel like you need to fine-tune that for your use case or do you feel like that off-the-shelf model just works right away i know we actually we have to find unit because just to give you an example one of our customers is an insurance company you know for legal uh insurance you know like let's say for example your neighbor i don't know for some reason made uh you know the children of your neighbor hit your door and now the door is kind of damaged you know so then you call your insurance company and say hey by the way my neighbor did this and you know what about you know and then you ask these questions and so in the insurance company space they have a lot of you know very specialized terms you know and very specialized situations which you will not find on quora you know or we which will not find on stack overflow or whatever so and this data this is not available publicly you know i mean some of it is you know some you know some regular cases or some more obvious cases they might be public you mean us as far as i know for example google and tencent you know they try to get uh they really tried to get into this insurance space and also make it more public but still there's a lot of special terms and special situations which are not public and you will not get this data for free you really have to work with these companies and even then they are very hesitant to give this data out but of course if they want something like katie to get good results they have to give us the data otherwise we can i mean again but to think about it yourself you know if you never worked in the insurance space you will not know the terms and the the situations which are happening there you know and so you are not able to you even if you have like kind of a transfer learning but you will not able to answer the things the questions so you really have to get familiar with these special situations and and you have to fine-tune your models based on these basically but but otherwise of course yeah that the learning itself is the same you know whether it be the insurance or whether it be uh you know a medicine or whether it be physics or whether it be just the general public domain knowledge basically so yeah it sounds like the problem is the out of distribution of the new words and uh even something like a sub word or a byte pair encoder tokenizer still has to generalize to these out of distribution tokens when you go from say yeah core question pairs to legal documents or even stack overflow where you might ask a question about a specific python library that obviously is not in the core data set so it has to try to generalize to some new tokens and obviously it has no basis to do that so maybe like advances in tokenizers would help that but i i agree that it does seem like and there's a paper called don't stop pre-training that i really like that that talks about this further fine-tuning and so yeah i think i agree that it seems like in most cases the further fine-tuning will be important so as you've been fine-tuning these models what have been some of the lessons you've learned in training uh say siamese bird style encoders are you a fan of using data augmentation or what kinds of things go into that fine-tuning oh to be honest i i don't know i i'm not familiar enough to be honest with these details this is actually one reason we use v8 you know because i really yeah i have to be honest i'm not i i couldn't tell you this is something i well me personally i still have to learn and at the same time we really try to you know really learn from uh products or companies like bv8 you know to do this so yeah i i really couldn't tell you i i just know i what i know although what i've learned is in this sense it's really yeah you do have to the context is very important you know it's like just you said python for example you know in programming python is a language but if you go to you know if you don't if you don't talk about like let's say you are in agriculture you know python people will not consider python in a language they consider it an animal basically you know so so uh i think in this sense the context understanding the context is very very important this is something i've learned and and also uh and and i think let's let's say this way you know i think by understanding the context and uh yeah you can do much better answers basically and you you have to somehow use this also uh i try to let me try to think about you know it's like my my wife or my children are asking me a questions question you know and if they just shout it across the room you know and i don't know the context it's very hard to answer these questions so i have to ask well what do you mean exactly are you asking because of this or asking because of this so also humans you know if you don't have the context you can't really answer you can just make a guess statistically of course you know if they ask me all the time the same thing or i already anticipate the context i can answer it but if it's completely out of con i'm not aware of the context i can't really give you a good answer except that i say okay with in 90 of the cases uh if somebody asks this question this will be the answer but it might be completely wrong because i don't know the context well i think you've touched on another kind of part of this that is that is such an exciting part of these retrieve and read pipelines is how you can take the query you can maybe use the same kind of encoder for the query as your document index and then return more documents you could have a user embedding you could maybe have a history of queries from the user and then you have these pipelines where you might want to further annotate the query whether it's just with uh like late fusion with the you know the latent spaces the embeddings that goes back into the retrieval component and you can put together these pipelines of having your database having different retrievers whether those different retrievers are a symbolic sparse retriever tfidfvm25 or a dense dpr esbert or some kind of neurosymbolic search which is what we've eat offers is by doing a you know esper look up but also with symbolic filtering these different kinds of retrievers you have different ways of processing the query itself and then different ways of then reading from what's turned so as you develop these pipelines for flowing the data through to the end use case how has that been in plugging these different components together and how has how much of like what wev8 offers has kind of bootstrap this kind of end-to-end pipeline well uh yeah maybe i can tell you a little bit about the architecture about katie you know how it works now and how we make use of vv8 and where we really see the advantage of this so what my understanding right now is you know i don't think at the moment and maybe don't get me wrong about it's really just my my state of the art at the moment it seems to me there is no silver bullet you know it's there's no one solution which gives you the perfect uh solution basically and so what we did is the the way how we built it uh the architecture is really that we can plug in different algorithms very easily even per you know pair knowledge base you know like for example in the insurance space we can use a completely different algorithm for the knowledge base of the insurance or you know for for frequently asked questions of apache lucene we can use apache lucien by itself so so we realized oh that's at least our opinion i think it's very important that we can very easily change this exchange this you know and even everyone can use their own version so vva for the vva frequently asked questions we can use v8 you know and see how far we get at the same time we can use different algorithms at the same time you know and having different result sets and then you know combining them somehow so this is one thing i think which is very important and i think the other thing i think which is very important and this is just observing myself you know observing humans you know how you process questions and answers i think the magic is the magic is really in understanding the question you know how we because once you understand the question and this is something maybe we can talk about a little more in detail you know what does it actually mean understanding the question but i think by understanding the question you can give a good answer and i think a very simple case is like you know if you if if uh if you if somebody would ask me how old is connor you know i understand it's about the age of conor but the point now is i know i don't have this information in my knowledge base you know in my knowledge graph in my brain i know you you know i know conor i know there is a corner and i know you are the only corner i know but i know i don't have this information in my knowledge base so once i understand the question i can tell you oh sorry i don't know the answer you know and this is for example something which search engines don't do today you know they always give you an answer you know they they never tell you oh sorry i don't know i understand your question but i don't know the answer and i think this is something which you can see and i think it shows that humans do this not just based on you know uh uh uh uh probabilities but they really by understanding you know of course they can say okay maybe the answer is like this and this but they still tell you actually i don't know and and i think this is also very important to understand so our goal at the moment is really to to develop something like a at the concept of understanding a question and i think there i think one of course one thing is really named entity recognition you know again if you if you take the example of you know how old is corner you a simple named entity recognition is understanding corner is a human it's a person you know and uh how old is it means it's about the age so once you have these two concepts a person named connor and the h you know then you can do a normal query there's no more you know similarity search or whatever you can go into a regular rational database and just do a query and and if you see there is no corner you know you can say okay sorry i don't have an answer you know even if i understand your question so uh but then of course uh you know when so if you use just similarity search in a brute force version you know then then the similarity search probably will return yeah there is something you know uh yeah this question how old is conor it's very it's similar similar to the question how old is uh i don't know uh you know uh cornelia i connelly is like a female name i don't know i i don't don't get me uh uh maybe a better example is you know in in in in in english uh in german italia italian space you have the name andrea and andreas you know or andrea for example andrea can be a female name or it can be a male name so if you ask how old is andrea you know and if you have this answer uh in the database somehow you know and but somebody's asking how old is andreas probably from the sentence embedding it it's very similar you know it's very close to each other but actually it's very different because me as a human i understand andreas is a completely different person than andrea you know because one is it could be male or female or the other is very sure it's a male version you know so and i think this is something we really have to be careful with and uh and i think this is something to be honest i don't know either yet how to do this best but uh but i think this is why i like vv8 very much because i think what i think really is great about vva that v8 is really focusing very hard on these you know and they're really very dedicated on these and i think it's really great to have this and that vv8 is doing this so yeah if i could pitch you on maybe an idea to um an idea around this idea of say disambiguation and named entity recognition and then trying to understand how well your system is understanding your query i was thinking maybe it could be interesting to have a visualization of the graph structure of the nearest neighbors to your query so uh when you do a query and you get an answer that you know you like what's going on at this answer you could you could look into the graph and you could see the what h sw has returned and you can see kind of the linking between the distances between maybe it's your query and in the nearest say sentence or paragraph in the document index or maybe it could even be and then coming back to this idea of named entity recognition disambiguation maybe it could link to a word embedding as well and i don't think we've explored too much of doing the distances between entire contextual representations of entire sequences compared to the individual word embeddings but i can imagine for this kind of thing where you have a query like um maybe it's like some kind of question about some specific breed of tiger and that's and tiger is one of your word embeddings maybe you'd want to see that kind of thing on the graph to be like okay well it at least sees that i'm trying to ask about a tiger and then maybe you'd also want to plug it into a generative model like a gbt that can generate a long sequence of text to to generate something that would have a high semantic similarity according to your uh your you know that latent embedding space but then still have that be on the natural language manifold and not just be like adversarial noise to optimize the similarity but some kind of like graph visualization like that to give you more understanding of how your system has interpreted the query well i i could imagine uh that this could really happen i think let's say this way i think there's still a lot of room space for improvement and just to give you an example uh maybe it's a little bit off topic but i think it's very similar you know about just understanding i think why humans are considered to be quite intelligent you know not just humans and i think this you can see you know uh when you when you think about i mean i don't know whether you know this book by uh conor man i think the slow and fast thinking and i think it's really a great book and because and i think it's also the question about consciousness you know and and instinct viruses doing con conscious conscious uh decisions you know so for example i think we humans we have a lot of instincts inside it's it's really like you know you have some input it goes through the neural network and it just has an output and you don't really know why you know it's just this is just happening and and i think the problem is there often we humans then have a lot of instincts at the same time and at the same time you have to you know make a decision you have to decide which instinct you should follow you know the a very uh something i learned in biology is like this you know you you have a little mouse here and you have something to eat here and then here you have like a predator like an an owl eating the mouth so the the mouse wants to has the instinct to eat the cheese you know at the same time the mouse has the instinct to to run away from the predator from the owl you know so and it has these two instincts so so the mouse goes closer because it really is hungry you know in one street but at some point it's getting too close to the island it's getting afraid and you know and then and now what you know so in biology what you can observe the mouse hits there and this doesn't know whether it should run away or should go closer and these two instincts they are very you know they are not not very intelligent they just eat or run away from the predator and now i think this is now where the consciousness comes in you know you have now to make a decision what do you want to do you know and i think this is what it seems to me a little bit with you know this search you know you you have the you know you have the tf idf algorithm and you have you know the similarity search yeah like instincts you know but still to make decision you know which one is now the best results there you need some kind of understanding and consciousness in the sense like and i think this is this is what it seems to me is currently a little bit missing you know you have to these algorithms they return something and sometimes they return great results you know but you're not so sure whether you can trust them and somehow you have to find a way where you can say okay yeah this really fits and and and that's why i'm saying i think there is not a silver bullet i think you know i think it's rather my my prediction is rather you will have different algorithms which really have great you know yeah great they deliver sometimes great results but you still have to have like a higher level algorithm which then makes a decision based on these lower well these more instinct algorithms you know you know what should it you know which one should you trust and and i think this is what it seems to me and and i think this is what huma what why humans are intelligent in this sense you know because humans are able to do this for whatever reason you know whatever reason they have developed this but i think this is why or whatever life form you have you know life form which is not just following the instincts but you can make uh decisions based on these various instincts and i think that the book of kahneman just describes this very nicely and we humans have a problem with these too you know because we have to force ourselves to the slow thinking our natural behavior is always to think fast and sometimes we are right you know but many times we are wrong you know and we should and i think with computers it's the same you i think you you have to implement these kind of uh algorithms i think yeah yeah and i love the um the search application for studying neurosymbolic ai and system one system two thinking fast and slow i think search is one of the most useful ways to make progress on this kind of way of thinking and so you could think of thinking fast and slow as thinking fast is where you have your siamese burnt and you're just doing vector distance comparisons and then thinking slowly would be re-ranking where you say use a pairwise encoder so the pairwise encoder it takes in two sequences as input and then has the cross-attention so it requires several more computations you wouldn't go hit the whole data set with something like that or you could even have like a try wise you can generalize that obviously as you do things like sparse transformers long former increase the size of your input window to to think slowly that way and so you could think of thinking slowly with neural layers and you could also think of the neural layer as being the thing that tells you how to traverse your retrieve than read pipeline it annotates the query it says it has say you have a big system with 10 different retrievers 10 different readers it can route through that by having some kind of labeled training data and doing gradient descent learning a continuous representation of the space so you could have the neural layer thinking slowly or you can do these kind of symbolic processing things like say causal inference or maybe program synthesis i'm not really too much of an expert of it myself i was wondering if maybe you could help me understand more about this kind of thinking that the thinking slow thing should be a symbolic computation i mean pre-coding some traversal over retrieve and read graph is a symbolic kind of again to be honest i really don't know this this is something we also try to find out at the moment i i i really have to be honest i don't know either how exactly the slow thinking will work and i just think this is yeah i well you know maybe i'm completely wrong again if you take uh and if you compare again with the nature you know i mean if you think about flying you know how how humans learn to fly you know they they try to imitate birds you know they they they saw that you know birds have wings but they also imitated and today you know i mean we can today humans are able to fly you know in in 12 hours from europe to brazil you know which is fantastic no no bird can do this but still the plane still has you know the plane works differently than the bird but it still has wings you know it's so there's still we learn from the nature but the technology is slightly different and we are more advanced than nature is basically also of course forget about the the climate change about the flight this is not something we did so well or not doing so well but let's apart from the climate change you know the the things we how we do this we really done this well but still it's very close in one way to the nature and i think this is the same i think i would argue the same is probably true for search you know and how we can find things or how we can answer questions you know but i tell you honestly i don't know either how this slow thinking what exactly you know how this slow thinking i just think my god's feeling at the moment is really the magic is in understanding the question you know understanding what people actually are looking for kind of understanding a concept i think this is also because you know i mean again i know maybe this doesn't it's not doesn't compare exactly but you know if you think about a child i can show a child a zebra once you know i don't have to show a child a zebra you know one million times so that the child is able to recognize the zebra i just show it once and and the child will recognize it immediately again doesn't matter whether it's in a different position and of course there are some ambiguous moments you know depending on the light and things like that it will not maybe not recognize this the zebra but generally it really does recognize another thing i think in this sense i think we can still learn a lot from nature and how we do this and i think this is [Music] i think we're not quite there yet so but i think we we get there we i think it's more a matter of time and that the climate change doesn't kill us in that before yeah i can't really tie this back to the to how exactly i think this will solve the problem of say uh one shot learning fuchsia learning you see the zebra and i can generalize to new zebra instances but this kind of idea of say cellular automata self-organizing systems these kind of uh message passing regeneration things and like and then the local kind of heavy and learning i think that could be a promising uh like inspired by nature's solution to ai i'm still i think it's tough to completely connect say heavy and learning cellular automata to then system one system two and like let's go back to our retrieve and read way of just imagining such a system that we would want to be inspired by but i had this kind of idea with where say uh we interviewed uh charles pierce from kenius on the weev8 podcast and they're building a they have 60 million academic papers that are connected in a citation graph and so you i could i think maybe you can model that as a cellular automata system where uh you destroy parts of one of the paper and then it locally re regenerates itself and that kind of system maybe and i know we're kind of getting off topic from retrieve and read but like what do you think about cellular automata is kind of a paradigm for ai yeah good question i don't i again i really don't know i have to admit i uh maybe you can because i think i'm not even familiar with the concept can you can you tell me a little bit more about the concept yeah for anyone curious about this there's a really great uh the distil publication distill.pub has a visualization of this with images where uh they have like a lizard image and like a smiley face image and you erase a pita piece of it and it's it's like a local regeneration module so it so it learns how to be you know recover from the damage of the eraser and so so it's it's trying to emulate the idea of where you have like a local nested model with complexity that still does message passing to other local kind of nested modules and kind of the reason i brought this up is when you're thinking about this kind of idea of nature inspired ai and i think maybe the cellular automata idea and thinking about how that might plug into something like a retrieved and read pipeline it's kind of like a researchy idea i think of it as but i think it could be a really interesting kind of approach to it yeah no i i have to admit i really don't know uh sorry i i can only tell that i think yeah we i mean again maybe that's why i'm a physicist you know i think i'm very good at oh yeah i think i'm very good at recognizing patterns you know like that you can see yeah just patterns you know and and and and uh i think once you can see this you know you can uh that's why i'm saying this this example is the flying you know how we imitated nature and then we improved it beyond nature at least in one way you know i think the same can be true for you know ai basically that we see how nature is doing this and and that we try to imitate it but go beyond it because i think nature is not perfect you know i mean it's far from perfect in the sense you know and it took i don't know millions of years to get there and and i think also generally ourselves you know just because we have a great culture well we have developed the culture i think we humans our instincts are still very much like 10 000 years ago probably you know we just don't see these so much because we are they are kind of because of culture we develop they are kind of hidden but if you are honest with ourselves we are still very instinct-driven basically so i'm not saying nature is the best possible solution and uh and yes at the same time maybe we find another way to do this completely different than nature uh which is not i think don't i don't think i think we just have to try all these possibilities like the one you just mentioned you know i think we just have to give it a try and see how far we get i think we just in the end it's evolution you know we we just try see how things go and if it doesn't go we we try another way or we try them in you know parallel and we just see how the things go and uh but it just seems to me again you know if you again if you take the you know the idea of evolution you know there's not one way of doing it you know you know there's multiple ways of doing and and some whatever you call success you know some of are more successful than the others and i think i think this is what we that that's why i'm saying with similarity search this is i that's why i think it's great you know i mean i don't know whether you saw this somebody asked on the the slack channel couldn't we implement like uh tf idf into vv8 you know and uh to have this combination you know and and uh and i understand very much why uh people who are asking for this and at the same time i i really admire bob and his team that they say well let's focus on the similarities search you know that they really say okay hey you know we really want to get the most out of this and i think that's that's really great i think and yeah we just have to try i think and and see how far it goes and combine the things and that at some point we just get that and bad dirty and yeah with katie i think it's really i mean our goal is really just to you know to give you the best possible answer you know to to whatever question and there i see still you know for simple questions i think we we can still already give good answers but i have to admit you know once you go into you know communicate chat channels like slack or ms teams or whatever or you go on public mailing lists i mean you know this people don't ask just a good question first they describe the problem you know and sometimes this is very unclear this problem and then they at the end they say who can help me you know and and this is really very tricky you know it's very challenging to get out of this and you can see this with humans you know i mean even myself even if i'm are familiar with certain topics you know i i really don't get the question i have to ask what exactly do you mean you know well can you describe this in a little bit more detail i can give you can you give me an example because you know of course statistically i could say okay there's a limited set of answers or at least i have a limited set of answers in my knowledge base and i just give one which is the most probable you know but uh you know to give a really good answer i have to ask like some counter questions to to find out what does this person really mean and then suddenly it becomes clear and then i say oh sorry yeah i i don't know the answer oh i can say yeah yeah of course this is the answer you know this is this is exactly what you want and say oh thank you very much you know and i think this is really this is another challenge and i think this is independent actually of the actual search algorithm this is more about again about understanding what does this person want yeah it answers the question well i'm thinking um like we recently interviewed malte peach from haystack and i think haystack's pipelines may be what someone is looking for if they want to use tf idf s bert but um what we v8 has built and what i'm a strong believer in is they've integrated the symbolic filtering into the neural search even though bm25 is as strong baseline as i've been kind of looking through the information retrieval literature and it does seem like you know bm25 is so a strong way to go i do suspect that symbolic annotation of neural queries will win the win in the long term as you scale up the data sets is you know just there it's still early and it's already better yes so i definitely think about that and then um so another interesting thing about the idea of like giving it an example and really dressing up your question with the context is i think kind of like the domain generalization where uh me personally i'm working on modeling uh keras code examples and keras api references uh programming language for deep learning and um like subtleties in the way that you ask the question can really throw off the model and is this something that you've observed and are thinking about is maybe data augmentation like a generative model that can dress up the question in the training data so that it has more kind of distribu generalization but this kind of problem of the way you ask a question can really really throw it off no i mean no you're definitely right depending on how you ask a question this can completely uh lead to very long results this is this is absolutely true we observe these two and again i think there i think it's really uh again if you think about how we humans are doing this you know i mean if you ask me a question you know and i think again i think i can as a human i'm not able to understand somehow this question is confusing you know in the sense like not i'm not saying i'm not blaming the other person asking the question it's just but it's confusing for me because somehow i'm not i think i uh i'm able to understand this in most cases you know sometimes i'm very confident and about the question i and and i give you the right answer sometimes i'm confident about the question i give you a completely answer because i i was just too confident about what you're asking me you know and then the other person tells me no no michael this is not what i meant i said oh yeah sorry this was my first thinking you know i i was thinking too fast you absolutely like if i would have listened more closely to you uh yeah now i understand you you ask something completely different so but sometimes at the same time it's i think what you were talking about is yeah i can feel i really don't really understand this question you know and then i i really have to ask you conor well is this what you meant and then you just add a little bit more information and then i say okay now it's clear to me and i think this is exactly what you're saying you know just if there's a little piece missing and then it would be would become very clear and and if this little piece is missing it can lead to a completely different situation and but i think yeah and i think the same is true for these models you know when you're saying that it's completely throwing off the model i think there you know that's why i'm saying i think if you if you compare this with our human things you can see we humans are not much better actually our instincts are not much better or not better at all but i think the difference is we are able to to you know we are consciously we are able to understand this and then we are consciously able to you know counter ask a question and then make it clear and i think this is what it seems to me yeah kind of missing in the computer world you know that you i mean google is trying to do this and i think quite well by saying well did you mean this or did you mean that you know and and also of course you know profiling us they know when i'm asking for java they know it's not the island because they know from the history they know most of the time i'm asking for the travel programming language so so in this sense uh i think they're already doing quite a good job but you're absolutely right and but of course they again if you compare with a human you know we have this conversation it's not a one-way thing it's it's a in going into both directions and i think the same you know is true i think for for such computer systems you know i think this is why in the end yes it will become a conversation maybe not a conversation like we have now but it's like a conversation in order to clarify the question and then once you have clarified uh you give a great answer so maybe there's a i can give you a very good example that's another use case we are working on again it's a very simple use case it's some of my friends they're very much into cycling uh and this is actually a coincidence yeah that yeah it's not because of me that i like cycling they they just and they they would like what they would like to do is really like a very simple thing you know you have a problem with your bicycle and you would like to find a repair shop which is able to do this and you know i don't know how this is in the u.s but you know here in europe it's often like this depending on the brand uh yeah you can't go to every repair shop some of the report shops they will tell you you know sorry we don't cover this brand you know you have to go to another repair shop so but again you know the thing is like this when i ask a question you know this and this is broken where can i repair this of course i will tell you there are like 10 repair shops in your neighborhood but now the thing is like from my experience i know depending on your brand you know i have to you know make a narrow more narrow selection so i will ask oh yeah about conor i understand your question but you know what brand do you have do you have a scot bicycle or do you have a track or do you have i don't know whatever you know and depending on and then you say yeah yeah i have a scott you know and and then okay then then i think it's best you go to this repair shop so so you know it's i think this is this kind of conversation what i'm talking about you know and i think this is uh and i think so it's not necessarily the the problem of the model i think it's more uh because i think my model is not necessarily better you know my human model is not necessarily better than the computer model but it's more like the the the the clear the how do you see the clearness of the question you know the the understanding and i think this is why i'm saying it's not necessarily important i think to of course the better the model is great you know the better the better but i think it's not necessarily again i think it will not necessarily solve the problem in the end i think it's more like this combination that you are able to clarify the questions you know that you have this conversation and i think this is why we humans are very good at you know because we can we have this ability to clarify out of the fuzziness you know to clarify the things and of course this cannot just be by asking questions you can also by looking at you you know by you know depending what phase you make you know depending the temperature you know depending whether you have the weather conditions you know if you ask me for an umbrella for example if you ask me for an umbrella if i see you at the beach you know this beautiful weather i know well you're not asking for a random brother you're asking for an umbrella for the sun you know and i i guess that's why i mean you know you yeah i think so i think it's not just the model it's really yeah this ability to clarify what you're looking for actually yeah i love that example of the beach beach versus say being in seattle for what is umbrella that that's such a great example of disambiguation but so i think this is a great transition into this topic of multimodal embeddings and how that can help you add context so in the example of looking for the bicycle repair shop it might be easier to have a tabular description of bike models rather than putting it into natural language because if you set up the tabular schema for describing the bike and then you hit the database of the tabular schema it seems more natural and maybe you want to have a neural representation of tabular data as well but and then like another example would be say you go on something like instagram or pinterest and you see a pasta that you really like and you're trying to query your local restaurants to see who who can make this pasta for you in that case again the image is going to be so much better than trying to have a text description of the pasta so i think this kind of topic of multimodal not just text but text maybe it's even uh in the last podcast with multi we talked about uh tables for searching through scientific papers so tables you know and then or compared to tabular data that you designed for describing a bike model and then again images audio the facial expression the way you ask the question the tonality in the way you ask the question such an interesting kind of thing and have you started thinking about like integrating other kinds of data than text in in the kd system uh no not yet because we're not even there yet with the you know the simple version of yeah no but you're absolutely right i think this is uh yeah i think in the end uh this is what it's going to evolve to you know that we have these multi-modal inputs and and uh conversations i think and i think you know again i think we humans we do this very unconsciously you know we we do these uh you know we we're not even aware that we are doing this you know but that actually we are doing this all the time and we are so good at it that you know it's again i'm really sorry if i might get off topic again but you know we i think humans most of the thing that the consciousness is really just the tip of the iceberg you know we we i don't know i don't know how much percent but let's say 90 of the things we're doing unconsciously and based on these unconscious things we make a lot of decisions and do a lot of things we and and this is why we are so seem to be so intelligent so and i think these computers i think this is the same thing you know i think we and i think this is why many people think computers are limited you know they will never get like humans but i think this is not really fair you know because we don't really give the computers the input which the humans have you know if you just think about our senses you know we have the you know we have the temperature we have the sense of you know wind or not wind we have uh you know all kind of sensors and this is all being fed into us and we give this to process and based on this we can do something with computers we just have the input of the data with the keyboard and that's it basically it means it's clear that computers can with this little input you know i mean you can try this on yourself if you only get very limited input you know if you are limiting yourself from a lot of input you you get completely lost and and in this sense i think this is why i think uh yeah it's just at the beginning in this sense that i think once computers have this you know they can become much more powerful and again another example i think you know we talk to each other we talk to ourselves all the time you know i mean again we don't program computers to talk to themselves you know again i think if you would program a computer to talk to oneself that computer could talk communicate with itself you know this might would change a lot actually and so i think in this sense i think it's a little unfair actually how we treat computer systems you know and at the same time you know i know many people are quite afraid of this you know i'm not really afraid of this i i think yeah it's just a natural uh but no i i we completely wish you this multi uh this multimodal thing i think this is and i think this year i think if evie is doing this and uh i think that's really great i think so and yeah with katie i have to say at the moment we are focusing more on the uh one step after the other you know we are already very happy if you just can't give uh you know with somebody's asking a question and we can give the best possible answer you know and and i think then the next we just go one step after the other and i think yeah vvh can help us with this and i think that's really great and if we can help deviate the other way around you know that we can share our experience which we are making we turn this to viviate you know i think we're very happy to share this and i hope viviate will succeed better with our you know our experience our observations basically yeah and we've eat has recently added the clip image tech support which is kind of like the first step i think aligning images and text will be the first probably step to combining all these different modalities but i think you're painting a really interesting kind of future for ai we have things like the perceiver i o architecture that can take in any kind of input data and have this kind of latent uh latent array that it attends to to form representation and integrate all sorts of data and then i think another really interesting part of this is the role of language in this and to me it started with the text-to-text transfer transformer the t5 model where they showed how you could unify all these supervised learning tasks through the language modeling task so you just say uh you just prepend it will say natural language inference give it the two things sentiment classification question answering like you just describe the task as natural language and it makes sense and it works and i and then um so eric jang recently wrote an article titled just ask for generalization that really describes how the way that i understand generalization is there's kind of like two modes to it there's robustness and corruption testing where you rotate an image add some noise and all of a sudden it thinks the panda's a dog and who knows why that happens and that's a huge problem and then the other side of generalization is compositional generalization where what makes us so excited about things like open ai's dolly is that it's able to combine the concept of avocado and armchair and avocado armchair and create that and create that kind of image so the compositionality and language is the interface for compositionality as uh eric jang describes really well in the in the article just asked for generalization so the idea of perceiver i o combining all sorts of different kind of types of data senses and then the language interface for uh querying for each for like accessing that compositionality of the multimodal data and then yeah that idea of self play and maybe reinforcement learning has a piece to play in this as well but overall i think this paints a really exciting picture of kind of where ai is headed no i i agree no i think it's it's it's very exciting i have to say and i wish i have i wish i i would have started earlier with these things because i'm still i still have to learn so much you know and it feels to me like you know when i started physics you know i remember you know i or when i did basic research you know ai existed at this time but it was very you know the neural networks it was not so advanced you know and i think really over the last couple of years and i i have to say admit you know i was like sleeping not a sleeping beauty but i was kind of sleeping you know and these things passed beside me and then later i realized oh wow so many things happened and i really uh i i and i'm slowly i'm catching up and uh yeah but at the same time i see uh still huge you know huge opportunities still you know and i think we are far from uh yeah i think we and at the same time i see the limitations of humans you know as i said you know my for example uh you know my wife she's originally from brazil and you know and she's when i see how she has to learn german and i have to see how i learn portuguese you know it's it's crazy you know how we humans have difficulty to learn another language whereas you know if i see people or google translate you know how well they do the translations just based on feeding data into it you know and i i wish me as a human i would be like this you know i wish somebody could plug in the portuguese language into my into myself and i could just speak portuguese you know and for me to just you know just learn simple words i take so much time i take a couple of days just to remember them you know and but then at the same time it's it's crazy you know then once i have some words suddenly i can make combinations you know and and out of nowhere i i don't know why you know it's just happening and it's it's really fascinating so no so i think it's i i agree completely i think it's it's really fascinating but yeah i have to meet myself i i'm not a i'm not an expert in many things i just have to still catch up and learn and uh yeah and i hope he can contribute and i hope he can contribute back also to viviate as i said because i i really appreciate what vv8 is doing that they're doing this open source you know and making things available because i really think again i think this is something important i think uh you know with the bigger companies i mean they have great knowledge i mean you can see i mean google is yeah definitely the benchmark on i mean other companies too and i think you know without becoming too political but i think these things these technologies i think it's important that not just a few companies or not just a few organizations have these i think it's important that this everyone is able to access this you know i think it's a little bit like the having some human rights you know like able to vote you know on a political system and i think with artificial intelligence i think it's the same that you really have this knowledge you know and that this knowledge is being shared uh among everyone you know and of course i understand from a company point of view you would you would like to have an advantage you know in order to earn money i mean for everyone but i think these i think this is why i think i appreciate very much what v8 is doing that they share this knowledge you know and really try to advance this knowledge i think this is really great yeah and i and i really like uh companies like mosaic ml that's building systems around efficient training of deep learning and i think the big thing that's preventing it from being more democratic and everyone having access to it is the size of the models if if you need to have 100 billion parameters or you know essentially like a million dollar machine to do this then that's going to be a huge problem and i recently made a video on a title general purpose readers where i think this idea that we've eat is doing haystack these uh neural search engines of decomposing the task into retrieve then read components you'll probably be able to you probably won't need as much parametric complexity in the reader now because it doesn't need to store the data in the parameters so i think this this kind of idea of separating out the reader and then and then branding the reader as the general purpose kind of ai api that can reason over any kind of embedding space what as it generalizes to you know images text and all that kind of stuff or like even like if we think about robotics and how all the senses regarding that and so i really think that kind of idea of a reader api will be helped democratize the kind of technology but so i think we've covered so many uh research topics in our podcast and and i'd love to have you on again later on as to keep this conversation going but as we kind of wrap this up could you tell me a little more about uh the future for katie and kind of what's on your road map that you're trying to build right now yeah sure but maybe if you don't mind just one remark you just said about what you just said about you know these uh democratizing and about the large big models i think they're again i'm not an expert in this but you know again if i just compare with nature you know our brain doesn't need so much energy and it's quite small and it's capable of you know great things so there my hope still is of course that you know i think the thing is like at the moment it feels to me like a little bit like we are doing 20s ai we're trying to do this on computers with uh you know it's like uh how's that let's say this but you know it's like you use a tractor for agriculture to i don't know to to to go drive 10 000 kilometers of course it will take you a long time you know and it seems to me i think i could imagine that uh you know that that the the info the the hardware that these will all you know if you are able to change the hardware you know like processes or whatever and you know that they are more optimized for ai that this will also change things you know and make things more democratic and it seems to me that as far as i know google is working on this that they have specialized ai whatever processes and i could as i said i'm not an expert in this but i could imagine you know that we are currently trying to do things on infrastructure and hardware which is not really made for these kind of things and if he actually you know if he changed this then this could really suddenly change everything as well you know suddenly the things we're trying to do becomes accessible for everyone very easily and just yeah to just to have this but coming back to your question about uh the road map yeah so the world map at the moment is really i think me personally i really would love to have haiti that we can just use it you know inside you know public mailing this uh public flag channels you know and really just try to make an improvement there you know that uh that katie you know just could be like a superhuman you know understanding these questions you know giving great answers and just making life easier for people in these areas because as i said you know i think it's a little bit sad that i mean i know this from many probably middle east you know that uh you know people many people psychologically they don't they they are afraid to ask questions because they might look stupid you know they they they rather spend hours you know searching you know googling or whatever uh and not finding the right answer but just asking a simple question you know which somebody who has this knowledge could answer and and i think this would really be great uh if he could solve or improve this problem i think this would really be great i think that that's one thing on the world map and the other thing is really to make sense of conversations you know i mean you have you have a lot of conversations going on but you know of course humans are lazy they don't want to document you know the the key findings you know i remember we had on uh you know like 15 years ago i was part of this cocoon it's cocoon is an apache software foundation project which doesn't isn't really very active anymore but you know at the same time i remember people were asking questions and then eventually there was a good answer you know and then always people said you know let's let's take this answer with summary or good answer so that people know this is really the answer they don't have to read like a thread of 100 emails to get to the right answer and again you know of course nobody was doing this maybe some discipline people they said okay this is the summary is a good answer some some people maybe even documented this in the wiki or somewhere but let's be honest you know humans are quite lazy they you can tell them as much as as you want they don't do this and they're not bad people but they're just lazy and i think if katie could get sense out of these big conversations and create summaries and then you know provide this again as good answers i mean this would be a huge help and you know i mean you know again if you completely compare it with the not computer world you know it's like physical cleaning if i have a vacuum cleaner you know vacuum cleaner is a great invention you know i don't have to do everything by hand you know i just clean it you know with the vacuum cleaner goes much faster so and if i it again this is something i think that we really make sense out of these conversations which are happening in public mailing lists or public channels uh this would be great and then of course for us earning money you know i mean yeah i think yeah somehow somewhere we have to pay the salary and if we can sell these technologies to the companies you know which have internally the same problems you know because if you have bigger corporations you know they have also the same thing you know they have uh people talking to each other and you know uh there we can apply the same technology and if they pay us for this you know that they can use our software for this then the better you know and uh yeah so that's basically on the roadmap to just uh improve these things and in the end make life easier you know that you can spend your time on other things basically and yeah uh you know again it's uh if you uh another comparison is you know here i don't know about the us but i guess it's similar in the s but here in switzerland if you go to the shop you know you can do the self checkout you know of course people were very afraid that the people that people counting the things you know and that they lose their jobs but i don't think this happened actually you know they just are able to do other things you know and and i can do the self-checkout it's much faster and and it's really great and you know and i think it's i think it's rather that you pay these people you know i mean and the reason that people do these jobs because they don't have such a good education and i think we rather spend the money on giving people a better education and they can do something which is more meaningful and well meaningful in the sense like you know uh yeah not not something which machines could do and i think i think the same is with haiti you know if he can do improve these things and people then can spend their time on other things i think great i think and yeah unless they want to do these things then they can still do this of course i'm not so don't get me wrong it's not it's not about replacing people it's really just supporting people and making life easier so and i think my life becomes easier you know if i don't have to search two hours for something and i just take two minutes to find the right thing i mean great i think yeah i can go to the forest you know and and walk there and yeah i think it i think it's such a like a noble mission statement and this problem you're solving is so important and i you know you've communicated it very clearly i think everyone would agree with the importance of this one question i had and i i hope this isn't like giving away the trade secret of it but how easy is it to get the data from slack into your database is the slack offer an easy api to just take your slack conversations and just have it as a json file or whatever yeah it's like it's actually i have to admit was to say uh uh all credits to slack is actually very easy you know it's it's also uh the if you you can't dislike you you just ask for the permissions you know and that you get the content you know and then basically we just read everything and we just try to detect questions you know and again you can do this in a more less sophisticated or more sophisticated way you know the the less sophisticated way that the least sophisticated way is you just look for a question mark then a little bit more sophisticated you you look for words like who where when why these kind of things in the combination and of course the more sophisticated way again you you send the data through some neural network which is doing some classification of the you know the communication and then we'll say ah this is a question for example this is like a question about i don't know something about these about something about these like these no slack is really good about these they are really good ms teams they're a little bit more restrictive there you only get the content at least i talked to microsoft and they said you only get the content if you directly you know if you say hey katie you know and then you really have to address it to katie to that katie is getting the content otherwise you can't read the whole communication which i think is a little yeah it i think it would be nice if you could read the whole communication uh then the other thing metrics i don't know if you know metrics metric is like an open source uh chat uh it's more like email you know federated uh matrix is really great too but with metrics you have to pull the content but of course this you can do and this email is the same you know you just pull the content basically you know you you you just what katie is doing you know it's basically uh you know just subscribing basically to to imap you know and just pulling the content and then analyzing it and writing it back you know just like what you do as a human you know basically uh so it's the same so uh no actually this is quite easy but yes you have depending on the channel you have to do this differently for each channel so that's a little bit it would be nice if this would be a little bit more standardized but it's it's okay and no i have to say it's like it's really good it's it's probably the opposite you know that people are sometimes afraid that katie is learning too much you know from these things and people are little but you know it's funny again it's very psychological because you as a human are reading these too you know what i mean is like if you are in a in the vva channel you you will read these messages too you know so why shouldn't katie read these messages you know uh i think there's still this uh fear that that that computers are doing something bad with this information you know whereas humans could do just the same you know uh and and this is actually quite interesting that that but yeah of course and uh but i think this is more like a topic for you know uh yeah privacy you know the privacy issues that you just follow certain privacy issues just as you require from humans too you know it's like when you are saying that uh you know if you work in the company and you have to sign a confident confidence confidence conf agreement for being confidential you know and uh i mean and of course you have to do the same thing with the computer that you know that you make sure this data is well protected and it's not being misused and and i think as then of course but there i have to admit you know once you know if i could hack your brain you could i could only get your information of course with a computer that's a little bit more difficult if you are in a company with let's say you know like for example one thing is about the private bank which might has 2 000 employees you know and the computer is collecting all the data from these 2 000 employees and somebody is able to hack into this you have the information of all of them you know whereas if i just can get connect with you i only have your information i don't have the information of the 1999 people otherwise i mean this is to be fair that's the difference you know these computers you you are able depending you're able to get much more information than just from one person you know and and i think this is something we have to be yeah careful with and and i have to me but this is again what we do with katie we really have this you know we have every knowledge base it's completely separated you know we don't share the data between the knowledge bases you know it's not it's not like one big brain but basically every knowledge base is dedicated uh data container basically so because we want to make sure that you know if somebody says no let's delete this data you hit the button and it's deleted you know instantly basically and you don't have to see oh how was this connected with these intensities yeah so this is something we really try to take good care of yeah but of course mistakes can happen and yeah i'd love to see like um similar to how we all trust say the stripe api with payments i'd love to see some kind of federated learning company emerge where you you go to a product like katie and you see it's like the data is managed with company name and it's like a data privacy for deep learning kind of api that we all trust i'd love to see that kind of thing exist to solve this kind of problem no i think it's a i agree with you that you know that is really uh it's a challenge and i think it's uh i think you have to define this as a requirement you know as a strict requirement if you don't define this as a strict requirement people will start to not do this so well you know not so properly and in the end it's not because they're evil it's just because they don't think about this you know and i think you have to be very clear about this and yeah i think this changed very much and i have to say you know maybe in switzerland this is a little bit more uh obvious i don't know i don't know i'm just saying in switzerland because you know there's uh the banks are very much about privacy the banks and the insurance companies they are very about privacy and so they are really forcing you to do these you know and and even sometimes it sounds a little silly how they you know because they are uh but but it's in this sense it's a good thing because they're really forcing you to think about this and uh and uh yeah i think generally it's very important uh also again i think privacy is a very important thing also on the level of humans you know it's i think doesn't matter yeah i i know it can be also have the opposite side you know but i think still i think it's an important very important thing and i think you have to have this as a requirement from the very beginning so yeah so that to ask kind of more of a personal question about the development of this thing obviously katie this mission is very big this this kind of thing you know if it's built it could be so valuable what's kind of like your um day-to-day like the level of how much work is going into developing this kind of a thing and the organization of katy i'd imagine scaling it up to building a whole company around this and what's your thinking about all that kind of stuff of uh you know really bringing because it's such a powerful vision i see it as requiring almost maybe like a herculean effort i mean a lot of these things like you know alleviate and uh other tools help facilitate it but how much how hard is this to really bring this to life well i think at the moment we are quite lucky actually we have uh the seed funding we received the investors are very very nice people in this sense and uh they're not like you know they're not pushing us to let's say you know to make a profit you know very soon in this sense i think i think what is most important at the moment for us is just to show that this could really work you know that this really makes sense you know and it could really work we are able to pull this off and that yeah it it it does create an improvement and then that people start to see the potential you know i think this is the most important and but i have to say at the moment we are still uh i wish we could spend more time on the fundamentals you know like these for example this concept of understanding that we uh yeah to develop this concept of understanding of a question and then basically out of this on this concept of understanding making a query and this conscious process of you know making a selection of these different algorithms this is something i hope we will be able to spend more time soon at the moment we are still spending a lot of time on the the more the the regular things actually like you know what you were asking how to connect to channels like slack and you know because the thing is uh honestly you know in order to to make this uh that it work we need the data we need that people start interacting with it you know also this is why i i really appreciate very much viviate that they allow us to use the vva channel the review channel i think is a great use case because they are like 300 or more members and people ask a lot of questions you know and it's really such a great use case to test it and and i think this is very important for us so but i think now we are getting really close to this that we have the the the fundamentals to to do these things to get the information and to answer that really people start interacting with it i know this sounds a little silly but it it's quite a lot of work actually it sounds very easy from the outside but there's so many details and then also like for example with this insurance company they're really also they're really doing this too and they're very uh enthusiastic about it and uh but at the same time you know we also had some uh setbacks you say this and you know that for example we had one company they also used they also used like very much you know and we were we had great hopes actually but we had to find out that you know they only use slags for social interaction you know they only use like in the sense like hey when do we go for lunch hey when when does this person has birthday uh you know who who restarted the server you know it's it's a lot of questions which katie can't answer because you know i mean i can't katie can't answer when we should go for lunch you know so so uh so i we had to realize you know depending on the situation you know these convocation can't scan channels they don't they're not being used for uh knowledge with which katie can make any sense of basically you know and but this was a very important lesson lesson to learn so for example what we learned there is a very important lesson we learned was that yeah really we have to analyze the communication we have to be able to analyze the communication and then see does this communication actually make sense you know in the sense like for katie you know does it actually is it actually uh you know again you know like if you have uh you know if you have a road bicycle you know but you live in the mountains without any votes you know you can have a fantastic road bicycle but it doesn't make sense it just doesn't make sense because in the mountains there are no streets and it so you need a different tool you know to do this so and this again it sounds silly but this was an important lesson to learn then the other important lesson to learn was that we have these uh three phases of deploying katy in the sense like you know i mean you know this probably from siri you know many i mean i know i think siri and alexa are great you know but sometimes you can observe this many people they they play with you but they say at some point uh well you know yeah i can i can use it for this and that but for all the other things i can't use it and they get frustrated and they don't really start use siri anymore so what we learned is it's really important not to frustrate people so what we did is we have three phases of katie so when we deploy katy the first thing is just to analyze you know we katie is reading and analyzing the things but you don't really see katie you know it's just there listening you know it's just like an employee you put into a company and the employee doesn't know much and you don't you know you just tell just observe and listen you know just look and try to learn as much as possible this is the first phase and the second phase is basically to have a motivated employee a moderated kd so basically you say okay now i think you learned enough and now you should be be to actually you should be ready to participate you know but in order not to not make people angry uh you don't directly answer but show me your answers first basically and you know and then the humans can basically moderate katie so if katie uh is providing a good answer then they say okay yes this is a good answer just put send it you know but if it's not good you have to correct it basically and once you get to the level that you can see okay kd is really answering in a good way like let's say 95 of the questions are good or 85 then you basically let katie lose you know and you just then katie is there you know so and i think these three phases are very important and uh because otherwise you know you frustrate people because they people think okay first of first they think oh kg doesn't know anything second they all see always or he whatever he doesn't provide the right answers you know and and so they just say oh please turn it off it's annoying you know so so i think it's very important from a human point of view that katie you you only see katie at this time when it really is good enough basically and this was also a very important lessons we had to learn and and that's why i'm saying you know i wish we could yeah well this took i know now it sounds like okay why didn't you know this in the first place but it was really things we had to experience and and it took us some time to learn these things and built into katy basically so and but and i think now we are very close to actually really spend more time on these fundamental algorithms you know like what i said about the concept of understanding and you know then using different algorithms and combining them and getting the most out of it and this is this is going to be the next big step and and i think then i think then i hope we really have this we can prove and then i hope basically we can go to the next round of financing or whatever but yeah it's going to be a critical point of view i tell you honestly if you're not able to prove this yeah it's uh yeah we i don't know how to continue but so far we have nice investors and they trust us and i hope we can prove this and i'm i'm very confident i'm very optimistic you know that we can do this uh i think we just have to continue yeah it's so awesome it's such an exciting vision and so interesting for me to i learned so much from this conversation and thank you so much for having it and thank you so much for coming on the wva podcast really hope to see you again and uh check in in a little bit to see you know how this is all coming together so many uh moving parts things in development that are so exciting and the vision is so captivating of the kd this question answering system in slack channels and maybe a good place to uh demo it out and illustrate it would be with our we v8 slack channel which is really the original inspiration for this podcast between uh eddie and anaya's uh trying to address questions from the we va chat in a podcast form so maybe that would be a fun thing for you to for us to kind of integrate telling the story of how this is coming together well thank you very much thomas i really appreciate the opportunity to tell about katie and how this works together with bb8 and i really again i would like to thank you very much vivian for giving us the opportunity and to use it you know i think he's really fantastic and i really hope that we can uh yeah that we can really learn as much as possible from each other and share this information and you know improve both of us you know and yeah and i i yeah it's just i think it's really great thank you very much [Music] ", "type": "Video", "name": "weaviate_podcast_5_how_the_knowledge_management_bot_katie_leverages_weaviate", "path": "", "link": "https://www.youtube.com/watch?v=dcu2xIO_lAE", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}