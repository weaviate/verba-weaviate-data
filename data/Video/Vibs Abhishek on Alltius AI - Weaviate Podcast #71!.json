{"text": "Hey everyone! Thank you so much for watching the 71st Weaviate Podcast with Vibs Abhishek! Vibs is the CEO and Founder of ... \nhey everyone thank you so much forwatching another episode of the we8podcast I'm super excited to welcomevibs abishek vibs is the CEO and founderof alas which has created some amazingproject uh products like no plus andvibs is also a professor at businessschool at UC Irvine covering thingsaround information systems and AI so I'mso excited to explore these topics withvibs vibs thank you so much for joiningthe podcast thank you so much K it'swonderful to be on the podcast I'm a bigfan of vv8 you've been using it eversince we started building alus so it's apleasure to be on this podcast you knowI'll give you a quick background aboutmyself uh I've been doing AI forprobably like 25 years or so so you knowI'm I don't look that old but I am quiteold U and probably the last 15 yearsI've been doing a lot of research on AIand teaching AI at schools like upen CMUand more recently at UC Irvine um youknow I think what's happening withgenerative AI is really taken the Worldby the storm but this is sort of achildhood dream coming true for me thisis what I wanted AI to do when I startedworking with AI in you know when I was akid almost uh we can create these agentsthat have magical properties they cantell stories they can do cool things uhbut more importantly I see manyapplications of them in the Enterprisespace and so uh for the last few yearsI've been teaching courses on NLP at UCIand at CMU I've been working with largelanguage models for quite some time andyou know the for me the inflection pointwas gpt3 uh is how much power it had andhow much it could do without creatingthese custom models for NLP which iswhat people have been doing forever inNLP right um and then that's when Istarted thinking of how can we applythis technology to solve businessproblems and that was a Genesis of altshow can we you know create these AIassistants that can help people in theworkplace uh technology and the worldaround us is changing very rapidly andwe are not learning things any faster soinstead of you know uh trying to solvethe problem of how do we learn fastercan we have these AI assistants that goout and learn on your behalf and canhelp you do different things pitchbetter talk to your customers betterimprove customer experience for exampleand so that's what we have been buildingat all tiers uh for the last 18 monthsor soyeah that's also exciting I I had a lookaround Al's website in the blog post Isaw things like DARPA finalist forlearning assistance and yeah overallthis kind of assistant platform you'vebuilt is so exciting I highly recommendpeople watching this video go take alook at it quick four minute loom videoreally gives you the overview but sothis perspective I think you've createdone of the most impressive uh userinterfaces I've seen for managingmultiple assistants or agent whicheverword we want to use right assistanceagents but like this kind of way of uhyou know I upload documents and then sayI have my chat with docs agent or Ipoint it to my SQL database that haslike I don't know sales data and then Ihave my kind of assistant that does SQLqueries can you talk more about yourperspective on multiple assistance andhow you might want to manage that rightI think you know uh thanks for pointingthat out Conor the way we think aboutassistant is really they are related toa Persona right so if you have acustomer service rep you have anassistant that faces that customer repif you have a end user on your websitethat's a different Persona and anassistant can be created to solve theirproblem uh it can be an operationsmanager and you have an assistant forthat operations manager so we have afairly horizontal platform that we' havecreated of course we going very deepinto certain use cases around sales andsupport uh where our customers find alot of need uh but our platform rests onthree different pillars the first pillaris knowledge right all the informationthat we can sort of understand or knowto solve a particular problem right orto do a particular task and what we havebeen able to do is systematically try tobuild not only uh unstructured sourcesof of information like PDFs and docs andwhatnot uh but more in line of thatimages and videos we have imageunderstanding video understanding but inthe last couple of months we've alsobeen able to build in structure data uhso you can connect it to apis you canconnect it to databases flat files csvsuh and so you know we believe that to dodo a task right when we think about thisperson trying to do something that datamight aside in many different places howcan we pull in all of that data combinethat in some meaningful way so beingable to access different types of datasources is very very important for us sothat's one pillar for us the secondpillar is what we call the pillar ofskills is once you have the data in whatcan you do with that right so think of aQ&A assistant that's a very simplisticassistant that lot of people arebuilding today is I have now all of thisdocumentation let's say PDF documentsfor example right can you answerquestions on that but it goes evenbeyond that in the sense that maybe aquestion some pieces of informationdecide in a database somewhere somepieces of information aside in adocument like a policy documentation uhand how do you pull that information into be able to answer questions uh so wethink of these skills being run bydifferent agents um and you know that'sthat that is our distinction betweenagents and assistants an assistantmirrors a Persona a real person whereasan agent does a specific task right andassistant can be a combination ofmultiple different agents right um andso you can have an agent or a skill thatis helping you pitch right create apitch for your customers or helping yousolve a customer support ticket right uhso these are what we call skills andbehind every skill is an agent that'stechnically implementing what we talkabout and then we uh have this model ofwe talk about channels and this is wherewe make them available rightso maybe as a consumer I'm interactingwith this assistant on a widget that'son a website or a mobile app it can besomething that's integrated in slackright a lot of our def Tool Company thatour customers have a slack or a Discordbot and we integrate there or it can beplugged into your support system uh youyou know I think it's it's quite wide interms we want to make it as widelyaccessible as possible so we have apisthrough which you can make uh theassistant that you have trainedavailable across multiple differentsources you can plug it into your frontend you can plug it into your coresystem to do something uh so we keepadding these channels but really we wantto meet where the user is right withthatphilosophy yeah wow I that that kind ofknowledge skills channels I I think it'ssuch an awesome abstraction there's somuch to dive into there right I think umyeah maybe if we could kind of come backto the data part I'm really C and justkind of go through the full stackagain microscope the so the data I'mreally curious about like um there sothere's a lot of stuff around like dataingestion that's coming up we recentlyour last podcast was with n AI wherethey're talking about keeping the sourcein the sync destination in sync so sayyou have uh your you know you have yourSQL data in say postgress and then youwant to sync it up with your vectordatabase or you know all these kinds ofdifferent things and so maybe if wecould just dive into like I've seen thethe UI on no plus for how I would uploadmy documents or I also really reallylove this kind of like uh also using theweb so if I if I it look for a questionand I can't answer it maybe I do a websearch and maybe I add that result tothat back into the knowledge can wemaybe just uh talk through kind of theconcrete tools and perspectives on thatkind of curation of the knowledge Corpussure so you know I think we like what werealized very early on is we tried manydifferent approaches right we startedbuilding very early in the space so wetried everything from finecing a model uh to you know what we haveto rags what we finally sort of decidedis we would have to build somethingcustom uh to both ingest the data so ifyou think about even PDF documents forexample there are many different typesof PDF documents uh so we use a bunch ofdifferent apis just to understand whatis it a presentation is it a you knowuser manual is it something else how dowe ingest that so even for PDF ingestionwe have different ingestion uhapis um and then if you think about uhintegration with custom some apis orpublicly available apis what we havebeen able to do is we can read in theproduct doc the API documentation get atoken and to some extent I think none ofthis works 100% like we discussed lasttime but we can get it to work 90% Andthen with some you know heavy lifting wecan get it to work 100% but so what wedo is we have this Ines framework thatwe have created that is custom orproprietary to us of course we use Langchain for a lot of our orchestration Hbut once that data comes in it can gointo let's say um a vector data databaseit can go into Knowledge Graph theknowledge graph helps us basically crossreference stuff and when we can't findan answer in the in the vector databasewe can go and look at one hop two hop uhthings from there on uh to pullinformation from uh the vector databaseor wi Versa right we sort of use that ina very uh in a very Tiddly coupledmanner uh but some of the API and thestructured dat data that we have wedon't typically pull that in becausesome of our customers are huge customerswith millions of transaction records orbillions of transaction records sothere's no way possibly we can storethat in any infrastructure that we haveinternally but what we want uh to do ishave the ability to be able to query andpull this information as needed so whenwe retrieve information we have an agentthat does the retrieval which figuresout you know should I be looking at avector database should I be looking atthe knowledge graph should I be lookingat doing an API call to pull thatinformation in right so there'sintelligence in the retrieval layer uhand you know for most of this we notactually going really to an llm to dolike of course the llm is part of thequerying and resolving from thisutterance how do you get to the sourceof the information but we have notstarted even constructing the answer sothere's a lot of uh steps in fetchingthe right information synthesizing itcleaning it up before we actually sendthis to the llm to be able to create theanswer right uh for most part the finalL that we're using is for some kind ofuh you know human like answer generationor maybe some higher order reasoningonce we have all the information we needto do some higher order reasoning tosynthesize that information but a lot ofthe retrieval is sort of our own codetechnology that we have built and thereason we decided I think you know thereare different ways of doing this when wewere building we realized that forEnterprise use cases Hallucination is avery very big problem and we tried tosolve it in many different ways andfinally we realized that uh we have toreally control the information that weputting into the llm uh or the prompt tofinally generate the answer and the onlyway we could do that was throughcreating our own custom you know uh datastorage data retrieval uh datarecommendation layer to be able to dothat yeah before moving on to skills andthe second pillar I really want tounpack this a little more this kind oflike SQL router as llama index calls itthat's how I first became aware of theidea where you take a query like what isthe average age of country music singersand you route that to the SQL databaseinstead of the vector database and so Ikind of want to dig on this a littlemore like it sounds like you'recombining Vector search with knowledgegraphs and I know ol GRA with Cipher Ihad quickly tried to learn it and likesparkle and I was but now with the LM Isuppose it's easier so yeah how do youmanage that like is there like a prompttemplate for how to formulate queries ineach of the languages you have to kindof retrieve the schemas maybe yeah soyou know uh on that currently we'reusing our own intent manager to be ableto do that uh and basically the intentmanager issimply um you know a classificationmodel that we have built uh using birdbut uh we tried doing that using thelangin agent framework it wasn't asaccurate as we wanted it to be like itwould know when it's supposed to go tothe you know Q&A uh you supposed to goto the vector database and maybe try topull from an API so we ended up buildingthis intent manager that's doing therouting for us uh of course we keepexperimenting uh you know we take maybethree four steps forward one step backuh because everything is solving soquickly uh that's the solution that'sbeen working for us I don't know if youhave heard of other solution that worksuh you know I think in Enterprise thethe it has to work most of the timeright I think and so that reallyconstrains Us in terms of how much wecan experiment or what's a what's atolerance we can have right on some ofthese things not working yeah I thinkthat's such a powerful idea that thatlike classifiers classifiers are the youknow the introduction to machinelearning but still just like one of theeasiest models to train and but it alsoI guess it has this like I see thelanguage models is they're so good atzero shot they can give you the proof ofconcept give you your MVP but then whenyou want to you know get get it reallyrunning so but this idea of classifyinga pipeline I'm so curious like um somaybe this would be a good transitioninto skills and we could come backbecause I understand skills to be sayquestion answering or summarization orreading from one of your blog postsabout using LTS for finance finance andyou things like topic literacy gettingstarted research support analysis so somaybe if we could talk about theseskills and then we could maybe come backto this kind of intent manager routerclassifier on top of that right so youknow so the skills are like really tasksthat people need to do right uh so thinkabout I I have a customer who calls inthey're asking me a question how do Ianswer that question very quickly rightso that's a standard Q&A type assistantor a Q&A skill right part of assistantor it can be uh help me create a pitchfor let's say some of our we have acouple of insurance customers and thereuh someone will call in and say hey I amuh 75y old man in California withdiabetes and I'm looking for aninsurance plan that has good uh dentalbenefits right and so very quickly whatwe need to do is look at all the plansare there maybe 6,000 Plus plans figureout which plans match the benefits thatthis person is looking for uh and thensay here are the plans so this is likejust retrieval of that information rightso this is so maybe building on the Q&Ascale it just pulls up that informationbut then there's another skill on top ofthat that can sort of say help me Pitchthe plan to that customer right and howdo you pitch the plan is a differenttype of skill because this might requireyou to be in compliance with localregulation you can say some things inCalifornia that you can't say in NewYork and vice versa you want to have acertain brand voice you want to maybenot even the brand voice there is asales manager who's your manager andthey want you to be selling in a certainway so the pitch agent is thencustomized or can be customized for thatspecific agent uh and you know so that'sthe beauty of large language models iswe can have all of this parameterizationmostly in English and say here is acustomer this is what they want this ishow you should be pitching this is thegeneral framework for pitching nowcreate a pitch for this particularcustomer right of how do we sell thisinsurance better so so that would belike that pitch would be a skill rightand we give ability to our our customerswhich would be like these insurancecompanies for example in this case howto customize and create that pitch uhskill for the particular use case um andyou know I think that's why we goingdeeper and saying can you build skillsfor specific use cases for specificIndustries which people can then veryeasily customize with adding in theirown you know secret source to thoseassists I yeah I guess is the the firstthing of like finding the the right planfor you the 75-year-old diabetes patientit it kind of like it kind of reminds meof this like when to use a classifierversus when to use embeddings and iflike you have like 60 plans maybe it'sbetter to use a classifier but if youhave 60 Millsomething yeah so I really like thatnugget but then what you were finishingtalking on this um you know customizingthe script I this is what I think isjust so powerful about the languagemodels is in the traditional sense offine-tuning maybe you have this styleand then you have some examples and youfine tuna model but it's not as flexibleto like now I want to change it to dothis so yeah I'm very curious about howyou think about that kind of you knowhow would you adapt it would you uh youknow have this you change the promptthen maybe you generate synthe itic dataand then you fine-tune it and thencompress it to make it you know yeah Ithink it it relies on a few differentthings right I think the way that wehave architectured a system it ispulling in the right you know because wehave this huge back end that can pull inthe right pieces of information uh soone way is you take an llm and fine tuneit for a particular insurance customeron all the data right typically what weseen is that two challenges with thisone is we need to have an instance thenfor every customer and if you know ifyou're hosting a version of L of 70b forevery customer it just our coststructure just go out goes out of actvery quickly uh the second thingis the bigger the model is so you knowthe bigger models are better atreasoning for example this is what wehave found out and I think there's thereare papers that talk about that butthey're also more difficult to change uhbecause you need to update so many modelparameters so the way we get around thisproblem is saying here is the data andwe become very good at retrieval andsaying okay this is how you pitch a planand now for pitching a plan this is howpeople have pitch plans in your companywe sort of summarize that put that inthe prompt or it can even be pulled upwhen we creating the prompt atruntime uh and then that is instructionthat then goes to the LM to say you knowthis is is this is the world putblinders on and then go and create theanswer and so that helps us really matchit to the specification not only thedata is very accurate and the answersare not there's no hallucination butthen match it to exactly how thatparticular company wants to or thatEnterprise wants to make it available tothat end customer right and then we canadd layers around policy and complianceand all of these things things uh sothat the llm does not you know go out ofbonds and of course we do some postprocessing stuff on the an that are justgenerated to make sure that it iscompliant and whatnot but really that'swhat is helping us you know being ableto generate the answers in the way thatour customerswant yeah I think I guess yeah I thinkthere's so much to this kind ofconversation topic of like uh you knowif you want to have a language model foreach of your customers is like maybewe're imagining some kind of likereinforced learning from Human feedbackwhere each of your customers is saying Ilike dislike this answer and then you'retuning the language model and there areideas like maybe you have like the Lowathe low rank adaptation you have likethese sparse parameters for each ofthose customers and maybe you dosomething like that but then you alsomention this idea of like the generalreasoning ability and if you fine-tuneyour language model in the specific setof conversations is it going to lose itsability to say format the API requestfor the tools you might have hooked itup with as well as right yeah so yeah soI think all that is so interesting andmaybe we can come back to that topic aswe come into agents but I kind of wantto round out this third pillar as wellthis the channels that you're deployingthese agents into so like I imagine aslackbot or maybe something that reviewsP requests like what kind of channelsare you thinking about yeah so yeahslack is definitely one of in factthat's the first channel that we startedout we did not even have a front endslack was what we started with you knowbecause I love slack as a product ormaybe I loved slack as a product for therecent refresh that they went through umso we started out with slack we addedthe widget of course we have our ownplayground where people can go in andsort of interact I think that's more forthe training purpose not so much for endconsumption but some customers are usingthat for end consumption too uh there isan API that you can connect to uh wewant it to be very low code or no codebecause the target persona for us isbusiness users uh the reason we want toTarget business users is I feel there'sa lot of power in language models but ifwe are just depending on data scientistsand Engineers to bring it to the marketwe just don't have enough people whounderstand these things well right so wewant really to put them in the hands ofbusiness users and that's why we havetried to create a very very youve playedwith the tool it's very easy to use uhbut we do have that API connection thatyou can train the assistant and you canuse it uh to integrate with your frontand or wherever you need to do that inyour own workflow uh we keep adding morechannels we are planning to add aDiscord B we planning to add uh WhatsAppB uh so as in when we have requests fromcustomers we keep adding there it's faireasy for us to add new channels um soyeah but I think the the idea is youknow with with the philosophy of makingit available wherever the end user is wewant to be available in those thoseplacesyeah I think it's so interesting I Iguess like for me I wonder with theEnterprise customers and you have thisconversation do they have like some kindof you know data Lakehouse Warehouse I'mnot super knowledgeful of thedifferentiation there but like and yousort of would say you know you have allthese different sources of data I'mgoing to hook up like 50 agents to theparticular sources and and then here's achatbot you know this GUI you can talkto it when you like or it'll send youemail yeah I think that's a generaldirection we're going uh I wouldn't saythat we can handle like 50 agentsespecially 50 like agents that thatacquiring databases I think there is alittle bit of a climb for that but ofcourse like 5 10 agents are notdifficult to do uh typically you knowany assistant for us would have anywherebetween five to 10 maybe sometimes even20 agents uh but there'll be like someof them will be like more like Q&A uhsome of them would maybe big like APIagents uh and so and so forth uh what wewere also doing is earlier we had agentagents that could process differenttypes like there was an image agentthere was a um like a video agent now wecombining all of that into one andsaying okay you know because we'reputting all of the data in one in vv8for example with the right tags we canhave just one agent that can go andindex all of the data it has slightlydifferent Behavior because you know whenyou answer from a video for example youneed to be able to retrieve that segmentfrom that video and show it in whateverthe front end is right whatever thechannel is um but um overall I think weconsolidating some things on the agentside so that you don't have too manyagents but that's the vision right likeyou should be able to connect it to asmany sources of information as possibleand our routing mechanism then figuresout where to go and look for thatinformation yeah I I think kind of likecollectively settling on the theseabstractions around what's an agent andthen assistant so to recapping formyself the assistant it has a Personalike you are a news chatbot or like youare a data analyst and then an agent islike the skill so so the agent is likethe question answering or summarizationright do with this kind of abstractiondo you see any kind of overlap like likewhen you're separating it separating itout into skills like question answeringsummarization as being like two of themost canonical things that people dolike do you ever find like the questionanswering model needs to summarize stuffand so you know within yeah that'spossible too right so so you know Ithink like again just to recap theframework right assistant is for a realperson who wants to do something rightand so really what the assistant isdoing is running a workflow right it's aset of tasks uh an agent is doing aspecific task right so so let's say forexample um you know I'muh I keep going back to this customersupport and sales use cases but let'ssay uh I'm an assistant for a salesagent one of my skills can be comparedifferent products right and what thatmight require is for me to go andsummarize product a and product B andthen do a comparison right so there is achain of thought that runs which is thisis how we summarize a and this is how wesummarize B and then there's acomparison that needs to run and that'ssort of the overall comparison skill uhright and that is just one of the skillsthat's part of that sales assistantright there can be another skill whichis how do I negotiate price better giveme a script to negotiate price betterright so that can be another scale thatthe assistant can have right so ourframework is fairly General in terms ofhow you can go in and create theseskills you know it's almost like Legoblogs right you have some Primitives youhave like these tools that you can puttogether to create agents right and thenyou can put agents together or skillsand agents are synonymous in our caseright you can put these agents or skillstogether to then create the assistantthat does helps a particularperson yeah I I love the obstruction Iguess it's like um you can think of likethe the question answer or the thecompare documents thing is like a like atool kind of like the API is likeanother one of the abstractions right isthe is the tool so so then it so I'mkind of curious like when it finish itscompare documents now it has this resultdo you save that result somewhere doesthat just go into the input window ofthe main assistant yeah so we have adialogue manager that's doing all thisorchestration right it will call if andthe dialogue manager is the one that hasthe intent uh classifier also as a partof that so it will call the differentpieces get the right information it hassome memory that and that's not likethat's not being powered by an llmthat's like really like software that'sdoing all more like you know I wouldsay something like dialog flow forexample like it's really that dialog FLequivalent for us is that's the one thathas memory and it's sort of storing allthe intermediate steps and then tryingto figure out what to do like even whenyou have a conversation should itmaintain context should it not maintaincontext right uh when should it refreshthe last three questions that were askedfor example uh and figure out that wehave moved to a different topic right soall that is being done by the dialogmanager right now yeah well I so I wasfrom our notes in preparing for thispodcast I was inspired to read moreabout this mem GPT paper and I'm reallyglad I did because I think it put me inthe right frame to understand this ideawhere they kind of separated it out intolike the kind of like event part of thememory which is like the running historyof the dialogue as well as like theworking context and they have thingslike um you know when you search whenyou search you then have the searchresults and it's like what do I want tothen take to put in my in context memoryand so right yeah I think that is thisabstraction of like the top level hasthis like its own event cue and then itcalls the other model that then has itsevent queue and yeah and that's a veryyou know I just saw your podcast on MGPT it looks very fascinating and youknow that's one of the things that uhI've been thinking about is can weinstruct you know the our like no forexample to retain some things in memoryright and so I asked a question I saidokay retain this in memory I ask asecond question I say retain this inmemory and then when I ask a thirdquestion uh and so this is this goesbeyond context right I think one waythat we maintain context is we just lookat the previous you know interactionslike any like one two five interactionsright whatever it is but I think therecan be a deeper way of thinking aboutthis is there is like actual memorywhere we putting stuff in uh eitherautomatically or by what the user issaying and then we sort of say okay uhnow answer everything else from here onbased on what's there in the memoryright and now flush the memory and youknow forget that that context so I thinkthis is this is an idea that we' havebeen thinking about too uh anddefinitely I love to read more about MGPT I just sort of got a cursory view ofthat from your podcast which is veryinteresting uh but yeah I think thesethings are very like you knowessentially if you think of it llms arejust uh you know next toen predictionmachines they're not full Computingdevices right like you can't run anoperating system so to speak right youusing uh llms and so how do we get it tothat stage like think of that as thechip right uh in the usual operatingsystem parland but we still need to betall of these other pieces and like ragwould be one aspect of this right likeyou have some memory uh but then uh youknow you have the hard disk and then youhave RAM and then you have all of thesethings so I think you need to build allof these pieces uh to uh to make itreally a powerful and a self-containedyou know Computing machine forexample yeah I love that kind of likehierarchies of memory and the analogesof like Ram is in context dis is like myyou know Vector database or mySQL I guess one thing I'm I really wantto ask you about is so this kind of ideaI you know I I keep the history of ourchat in my knowledge base or maybe I dothis kind of like GPT cache idea whereit's like question answering and you askme a new question and the vectorsimilarity to one of the questions I'vepreviously answered is above like 0.9 soI just send you that answer but then I'mreally curious so so that so that gbtcache idea is like I'm caching questionsthat real humans have come to my chatbotmy customer service and they've actuallyasked this question but I'm reallycurious if there can be some some kindof offline processing where you giveyour the llm like a hundred of yourdocuments and then it I don't know Idon't know how exactly how this isorchestrated but it it creates kind oflike new information like maybe newquestion answering pairs that it it likesomehow has decided that's that's it'san amazing point so this is somethingthat my co-founder Sid proposed a fewweeks ago and we have actually addedthis feature it's in staging it do notmoved to production which is can wecreate this fq list to begin with rightso improve the you know the cost andalso the the the response time given aset of docu like especially in thiscustomer support use case we can do thisright for generic things that are moregeneric and we create a list ofquestionsbeforehand uh and not wait for people toask these questions that we start doingsemantic casing on for example so that'sactually an idea that we have been wehave actually implemented already youknow I think that's the the fascinatingpart of this right like it's likeeveryone is building in this space andwe're thinking of these new cool ideasum and so definitely it has a big impacton you know how fast we are able toserve these questions because latency isa big issue uh and you know like we havenow probably hundreds of thousands ofusers not current users but you knowmaybe in an hour trying to access asystem so we speed is becoming an issuefor us um and so these are some ways inwhich we can actually solve that problemand not really you know at runtime relyon the llm to generate theseanswers yeah I love it from thatperspective of optimizing latency andcost I think that's kind of the originof the GBC cach and and yeah thatautomatically populate FAQ it reallyinspires me into this whole and I don'tknow if I've like done too muchdaydreaming with this kind of thinkingbut like this way that you can use theLM to generate synthetic queries whichthen you could use to tune the systembecause you can also have the llm sayhey was that a good answer to thissynthetic question I came up with and itcan kind of like tune itself that yeahthat's a that's a very interesting pointyou know one of my friends is aprofessor at UCI in CS and he's done alot of the seminal work in llms and youknow understandability of large languagemodels and one of the ideas that heproposed was how do we use the llms forbe a fact checker or even checking thequality of answers we haven't done thatat runtime yet we do you know I thinksome of the things for example when wetry to maintain context we using the llmto generate the question we say okayhere are the three previous responsescan you generate a question uh whichthis is a continuation question but sortof create a self-contained questionbased on what was asked earlier so butthere are ways in which you can you knowoffline process this and say hey uh tellme the quality of the answer be and thethe challenge is there two folds I wouldsay right one is typically you don'twant you want the maker maker andChecker to be different like so you wantyou don't want the same llm to beanswering this question you know itmight be a little bit of cheating uh butthere are also certain llms that arebetter for this job like gp4 is muchbetter at this than any llm that we havetried out when you look at you knowquality of the answer or you know doingsome little bit of introspection so tospeak um so yeah so some of the smallermodels are not good at this some of thelarger models are better and Iexperience dpd4 is probably the bestwhen it comes to sort of answering thesetypes ofquestions yeah I don't want to like I II think maybe they'll stay in the cloudsand we'll come back to some calaryquestions but when I was looking at noplus it kind of inspired me of thinkinglike you know like a notion forassistance kind of and so I was curiousif maybe like you know someone in adifferent depart like you know acrossthe company we have all these roles likeyou know product team marketing teamsales team and so like if theirassistants talk to you know if if thesales assistant talks to the engineeringassistant to try to come up with thesequestions and and the I think that's awe haven't thought about that I thinkthat's an interesting idea you knowmaybe we thinkabout I think it's the experiment worthdoing doing you know you add twoassistants and you know we had these uhI think Google home versus Alexa typeinteractions uh it's possibly like it'sdoable right like I think when weintegrate something in slack for exampleright you have to address it you know atno and whatever right at that assistantand it'll answer your question all weneed to do is sort of put in two of themin the channel and see how they interactuh that might be interesting you knowand I think that sort of gets in theline of automation right like how muchof your task can be automated we haven'tstarted thinking in the direction but Ithink it's a powerful idea of like ourmodel of an assistant is very individualCentric but can we take it from that andsay hey can we think about teams ofdifferent people interacting with likeinteracting through their assistantsright um that might being testing yeahyeah I love it I think it's such anexciting direction of the future and itbrings me to my next question that Iwanted to ask you which is about uh whenI was looking through no plus I sawthings like how you have the umattribution of sources in the questionanswering so it's you know the the loomvideo it you asked it a question aboutthe expense reports I think and it sayshey this is the answer and by the wayit's in this PDF you know just in casewant to check it so I'm curious likejust your perspectives on the userinterface design another recent weevapodcast was Charles Pierce from tacticand they have tactic generate which islike you know a UI for comparison acrossmultiple documents and so I'm justreally curious how you think about thekind of the creating of the userinterfaces that you know coming to ourlast example if we have agents that aretalking to each other I might want youknow some kind of new way of visualizingso it's you know I think it's I thinkit's a moving Target I would saydefinitely my like Sid is the one who isresponsible for a lot of the thinkingthat goes behind the uxuh but one of the principles that wehave gravitated towards is making addingas much transparency as possible rightbecause there is a level of trust thatneeds to be developed especially in theEnterprise use cases people might beskeptical people might be afraid ofwhat's happening so we want to give asmuchvisibility uh to the customers to theend users right and our customers as asmuch as as much visibility as possibleso I think that has uh defined a lot ofthe user interface uh I think the easeof use has also defined a lot of theuser interface right how do you go inhow do you create these assistantsmaking it very easy for you knownon-technical user to be able to do thatthe choices of words that we use theimagery we use all of that is to make itvery simple for folks to start using ituh I I do think that there is going tobe a learning curve in terms of you knowI talk about this idea of how do we movefrom a world of clicks toconversations right uh I feel it's it'sa very important idea not because I I'vesort of thought about it but you knowconversations are very natural for usand even when we started Al and you veryyou were very focused on how do wecreate these assistants only for SASproducts right uh the the thinking thatwas driving myperspective at that point was you knowfor every tool there is a differentlanguage we need to go and learn thatlanguage this language is of clicks andthen I have a workflow that I canarticulate in words but then I have toconvert that that workflow into thelanguage of the clicks right so thereare two facture points right one is Idon't know that language and so I needto learn that language and then I needto do that translation right and whatthese large language models have donedone by and large is not they're notperfect yet but you know I don't need todo that translation I can say this iswhat I want to do and the systemunderstands what I'm trying to do andthen it does the translation right andhopefully there's enough data that thetranslation can be done right think of ageneral Transformer model that's whatit's doing right converting from like itgoes back all the way to B right liketranslating from one language to anotherlanguage right I think translating froma language to maybe machine instructionor clicks or whatever have you right uhI I think that's going to be thefundamental change that will happen inuser interface design I'm not much of anus expert so I don't know whatthat uh user interface looks like in thefuture but definitely it'll be veryconversational at it's I'm not sayingthat click will go away completely Ithink we use that also right we have weask people to click on things and verifythings and whatnot I think clicks are agoodway to get you know very definitive uhinput uh when you don't want to have toomuch you know uh ambiguity in what isbeing said or the kind of input that youwant back from the user but there willbe an interesting way to design theseinterfaces that you know I can onlypossibly imagine but maybe I can't evenarticulate in words toomuch okay so I hope I'm getting thisright so with with clicks with goingtowards conversations instead of clicksis this kind of like the workflowDiscovery almost like RPA kind of thingwhere you'd like you know if I'mresearching uh books about databaseinternals I don't know and I'm on Amazonand I'm looking through the books and soyou kind of look at the clicks of how Inavigate the user interface and and somaybe is that I think that can be onethat can be one way of doing that rightthat can be that's probably what Adeptstarted out doing um uh that you knowthis is what the user wants to do thisis what they you know actually theclicks that they do on the page can wecreate a translation from that userinterface to the clicks that they'remaking but I think it can go even deeperright I think if we can have these APIIntegrations then we don't we can justcompletely circumvent that layer rightwe can say here is what the user wantsto do here is what our apis are able todo can we like this is like exactlywhat's happening for uh text to SQL forexample right I type in a query and thenthat gets converted into SQL and thenthe right piece of information isfetched for me uh I would say it's sortof maybe that is the direction to go andsort of you can then completelycircumvent this translating from whatthe user wants to do to clicks to thenAPI calls to just directly go to APIcalls right but I think it will dependupon you know I think there are fewcompanies that are trying to navigatethat route to like I think what fix isanother company that's trying to do thisAdept was trying to do this uh but uhyeah I think conversations I think themy insight is conversations will becomemore important in the user interfaces uhand then they'll be figuring out fromthe conversation what actually needs tobedone yeah I love it I I think the thecode interpreter for me has reallyhelped me understand like you know likeputting uh writing code into a chatbotwell I guess a lot of people probablyalready knew that with co-pilot andstuff like that but yeah I coulddefinitely imagine just even thecomparison across documents that it justkind of gives you the analysis in a chatbot and yeah is really exciting so Ithink kind of a concluding that clicksinstead of conversations I mean sorryconversations instead of clicks is areally interesting insight and so Ireally wanted to ask you this question Ithink your you know duality ofbackground is so fascinating to be CEOfounder of a tech company as well as aprofessor at UC urbine and businessschool can you talk about maybe likewhat that joint experience has taughtyou yeah you know I think uh I've takena very non-traditional path to becomingan entrepreneur uh like of course whatthe academic background has taught me islike expertise in this particular areain natural language processing largelanguage models uh given that I'm abusiness professor a lot of my effortfor the last decade or so has been howto get value out of AI and that's a verytough problem right like I think youthink about even forget about generativeAI but but more traditional AI a lot ofthese AI projects don't succeed and alot of my effort has been how do you youknow build AI should you even build Aiand if you build AI how do you deliverbusiness value uh so a lot of that so Ithink all of that learning has reallyhelped me think about use cases wherewhat we doing at alts is Meaningful andit's very customer-driven very focusedon delivering value to customers toOutput to customers really know tangibledollar right whether it is on therevenue side or whether it's on the uhthe cost side of things and so I thinkthat has really helped me take a broaderperspective not sort of as a technicalperson saying okay this is coooltechnology let's sort of find outSolutions of this but really looking atthis the problem and saying okay how canwe solve that problem using thetechnology that we had right and I thinkback when we started then generative AIwas not cool so we not sort of sayingokay how do we build a generative AIstartup I think the problem that Istarted with was you know I've taughtprobably 5 6,000 students by now theystruggle to use software how do we helpthem learn this stuff sooner and thensaid okay seems like you know afterlooking at bunch of different ways uhgenerative AI seems to be the right toolto build that platform to enable them tolearn things right and as sort of thatled to okay we can't only we don't wenot only can build toolsfor helping them learn but can itactually it can be a true assistant tothem right so that was the progressionthat we took as a company right and ofcourse then CH GPD happened and then thewhole sort of you know I think all of usare living in that World um but so Ithink that's really helped me make thattransition or I would say inform a lotof the decision that we make at at allon a day-to-daybasis yeah I love that kind of like thedog fooding of like how do I teach mystudents better while being an NLPprofessor and then I think thattransitions so nicely to kind of likecustomer service support tickets whichalso is kind of like this educationproblem and I guess for me the big thingis with uh I think with the with thepast a before chat gbt and largelanguage models and for me it it tookchat gbt gbt 3 wasn't enough for mepersonally but maybe we talk about thatanother time like the um you know youused to have this data lay in problemlike to to train a question answeringmodel like Bert on you know a newcustomer service data set you would haveto have some domain expertise in thatthing right and now it seems like thelarge language models can really helpyou bootstrap data in a really novel wayexactly I think that's the real you knowdifferentiator that you know these arewhat what we call gpts right generalpurpose technology so it's not generalpurpose Transformer general purposetechnology that earlier in NLP you wouldhave to curate data for a specific usecase even if you wanted to do somethinglike classification using bird you wouldhave to actually go and get data forthat domain for that you know particularuse case uh to be able to train a modelon that and I think what the you knowGPD 3 onwards has done is you don't needthat specific training data right youcan get I think and you know I think itgives you a false sense of comfort Iwould say you you spoke about thisearlier right it's easy to create aprototype and you get you can getstarted early uh soon uh but uh you knowit still requires all this thinking andfine-tuning and you know putting all theguard rails in place to actually make itproduction ready so I would say it'sit's generally in the right directionthat these models are powerful enoughthat they don't need a ton of data toget started so earlier you have to startfrom scratch every time you wanted tobuild an NLP model now you're probably50% of the way there just because of thelarge language models but you still haveto do that heavy lift of how do you gofrom 50 to 80 to 90 to 98% right uh uhso but but so I think that's why I sayit gives you a false senseof um accomplishment or success uh butyou still need to walk that but at leastyou're able to start a lot of people areable to start in that Journey which theywere not able toearlier yeah so I guess my last questionwould be the the 55% of the way theything I think that is just one of themost interesting topics I bring it up onevery podcast is this kind of likefine-tuning zero shot thing and I'm justcurious like like so so do you think toget a really performant customer servicelet's say for how to fix an airplane orsomething like that like you have tofine-tune it with gradients somehow ordo you think maybe you can just tuneyour knowledge base tune your retrievalmaybe that maybe that entailsfine-tuning your embedding or rankingmodel but like this idea that youinstead of needing to find in thelanguage model you can just get a reallygood context and then the zero shotmodel could get to that95% I think that's a tough question youknow uh our our stance is you can get alot of the way there with without finetuning uh like our experience has beenthat if you really want to find tune youneed to have a ton of data to find tuneotherwise it just it doesn't work and Ithink it can be we don't know how tofind tune the model as wellso it can be our lack of knowledge butunless we have youknow thousands or hundreds of thousandsof documents for example right uh it ispossibly you can get much better resultsby just you know some kind ofaugmentation of the llm uh uh I think italso depends upon you know how diverseagain the llm is in a certain you knowI'll get a little bit technical hereright is in in a certain space becauseof what it's trained on it's trained onthe internet data and what space isthe uh the other documents or the othercontexts coming from right and if thereis no overlap or there's very littleoverlap probably you know you want tofine tune it even with the augmentationand everything U but I think it dependson you know how much of that data is soyou know I think companies talk abouttheir data being private but it doesn'tlike customer support data pretty muchpeople are talking about similar thingsmaybe the context is a little bitdifferent but it's not a very differentvocabulary like think about twodifferent languages for example if I'vetrained a language model on German andthen I'm asking it questions in Hindifor example I'm not sure that it's goingto do the translation even if I weresupplying stuff in Hindi to to it rightI think the current models are able todo some of that at translation becausethere's so much diverselanguage and content out there but I'msort of making this very Stark case thatyou know there needs to be a significantamount of overlap between what thelanguage model is trained on and whatyour domain uh has data on right um andIthink if there is significant overlapmaybe just you know using anaugmentation works for reducinghallucination and whatnot uh uh and itdoesn't have to be in the same time spanright I think you learn the vocabularythe vocabulary is consistent over timethe facts have changed and that's whyyou need theaugmentation but if you're speaking adifferent language then then you need todo something to the languagemodel yeah it's such an interestingtopic I use I remember the wave where itwas like uh bioert legal Bert and likedomain Bert yeah I guess like for me I'mcurious if like when especially as theyscale the context l to like 100k ifmaybe uh you could give it the wholehistory like you know there aredifferent kinds of cells like immunecells there are T cells and it's likethe whole description of it and if youcan just pack it in the general Reasonercan learn the language from the contextbut I think it's interesting it's aninteresting idea I think some of thepapers that I have seen on this say thatwhen you have very bigtoken uh lens then it relies more onthings at the beginning and things atthe end and sort of ignore stuff inbetween uh we haven't done too many explike we just started trying out clot souh in a big way to sort of you know seeif this is actually true or not so wedon't know yet and answer to thatquestion uh but I think I I'll sort oftake one step back I would say these arevery complicated models and they're notwell characterized right I think of as acomputer scientist you think aboutcharacterizations right of system uhthese systems are very ill understoodlike if you think about a support Vectormachine logistic aggression decisiontree we understand them well weunderstand the mathematical propertiesof those things uh given how complexlike neural networks always has has thisproblem right forget about deep learningor even L language models even simpleneural networks we have not been able tocharacterize them very well and so wedon't know what the properties are ofthese models why like why does it forgetthe cont in between we don't know and ifwe don't know then how do we fix it Ithink it's going to be a challenge rightand maybe we add some hacks to actuallysolve the problem which makes somethingelse you know these are very complexsystems right you change something herethe whole network sort of coll cancollapse potentially right so I think Ifeel you know as a scientist this is agreat time to be alive to justcharacterize how these systems work uhbut as a practitioner I think you knowwe just trying to learn how to makethings do the you know learn llms do thethings that we need them to do right sobut it's it's I would say it's afascinating time to be building in thisspace yeah definitely well vibs thankyou so much for joining the wva podcastit was so interesting learning aboutthese three pillars around knowledgebased skills and channels I love thatabstraction as well as how you separateassistance and agents this descriptionof the hierarchy of assistant you couldhave and I was so impressed by lookingthrough the no Plus platform I thinkit's just one of best uis of how you'vecaptured all these different assistantsso thank you so much for joining thepodcast I love this conversation andlearned so much thank you so much Conorthanks for having me on this podcast itwas wonderful talking to you", "type": "Video", "name": "Vibs Abhishek on Alltius AI - Weaviate Podcast #71!", "path": "", "link": "https://www.youtube.com/watch?v=4aTkpjejaUs", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}