{"text": "Hey everyone! Thank you so much for watching the 62nd Weaviate Podcast with Atai Barkai! We are stepping into the meta with ... \nhey everyone thank you so much forwatching the wevia podcast I'm superexcited to host a Thai barkai co-founderof talk it AI which has created podcastgbt I you know personally for me thekind of dog fooding of using this we V8podcast the transcriptions that I getfrom whisper and putting that intoweviate and using that to prototypethese retrieval augmented generation llmVector database apps it's been so muchfun for me so I'm you know so excitedfor this conversation I love diving intowhat we can do with podcasts kind of thefuture of podcasting with large languagemodels and generally how you know I lovelike hearing like-minded people who arecurious about this kind of applicationso firstly it's Ty thank you so much forjoining the wevia podcast glad to behere Connor and yeah I checked out youruh weavia podcast GitHub and it's verycool yeah where we're at it's a greatthing to dog foodthank you that means the world to me I Imean the it may be first before divinginto the GitHub and maybe telling you abit about some of the projects that I'vedone sort of Lessons Learned let me likeif you you could tell us about you knowhow you see the space and what motivatedyou to get into this yeah so talk at AIis building an llm native audio videodatabaseum so kind of a layer in between Vectordatabases and relational databases andthe individual file analysisum so transcription the organization allthat stuffum and are kind of uh breakthroughproductum is a consumer product uh we kind ofhave our own design partner um for theuh database component it's calledpodcastgbt.aium which just launched in Alpha about amonth ago uh and it's basicallyum you know haveAI listen to all your podcastsum find the most interesting parts foryou uh and then send those to anypodcast app um so obviously yeah likethe big thing that shifted with languagemodels is the computer can actuallyunderstand what people are talking aboutright it's no longer just keywords umand that just opens the possibility toto do search to do you know semanticsearch not keyword search but you'relooking for type of content or contentabout something and you can actuallyfind it and you can know how highquality is it how relevant howinterestingum so how relevant to your otherinterests so so there's a lot you can donow that wasn't possible beforeyeah I mean and yeah I think that'sperfectly it is it's kind of what I'myou know hoping we can hash out in thisconversation is you know furtherexploring what's possible now thatwasn't possible before when I cameacross podcast gbt and reached out toyou because I was really curious to talkto you I one thing was um you know thiskind of like interactive experience likechat with podcasts that you chat withyour data chat with PDF chat withpodcasts like can you tell me how yousee that kind of like interactiveexperience with podcast listening yeahso actually it's interesting because theconsumer product uh you know consumersdon't care about the technology theycare about the experience uh andpodcasting is a very interesting mediumum because so first of all I don't knowif you know this worldwide there'sroughly two billion hours of podcastslistening uh per month which is a lotright there's only eight billion peopleon the planetum and uh and it's generally it's verydifferent kind of consumption from whatpeople do on you know Tick Tock orTwitter it's long form uh you knowroughly every session is on average 23minutes long uh which makes sense to allof us right while you commute while wewantumso people really kind of want to startpressing something and then not worryabout it uh so the interactive componentis very very interesting in outside ofpodcast consumption right to build toolsuh for podcasters to build maybe like ajust a plain search engine uh but whenyou think about just plain podcastconsumption you actually want to go asfar away from possible from uhinteractivity and actually the directionwe took this toum is we don't even have our own app weactually did start having our napum but uh what we figured out is reallykind of the intelligence is the producthere and there's no reason to try tomoveum people over from their habit rightpeople have habits formed over yearsthey use this app the process app foryearswhat's the minimum way that we canaugment uh that experience withoutasking the user for anything so so thebasically kind of the interface we cameup with is uh all the podcasts are builton top of uh this open protocol calledRSSum and yeah not many people know thisbut even you know apple and Spotify uhthey don't actually host the content oranything they just you tell them here'swhere my podcast lives and then theykind of redisplitum so we can put up our own podcast foryouum that is looks the same to thatpodcast application it's just one moreRSS feed uh except the contents insideof it can now beum essentially Clips but long form Clipsright not so not two minutes but youknow 15 minutes 20 minutesum from maybe what was a three hour longepisode uh and we can deliver that toyou right away and also tell you what'sinside of that clip why you should watchthat clip right uh so it's very specificum so so yeah that's how we think aboutthis from the perspective of plainconsumer product for podcast consumptionuh but of course when you start to thinkabouttools for podcasters which is I thinkone of the obvious applications ofhaving you know audio database then thenthe interactivity starts to become a lotmore importantumand then on our side that interactivityis mostly on the back end side all rightwe kind of figure out okay what are yourinterestsum based on what you tell us right nowactually we're going to add Twittercrawling soon so you can just you knowsee what your ideas areum and then surface things are reallykind of hyper targeted uh for you uh inthis long form worldyeah well there a lot of reallyinteresting ideas in there I love thekind of um I guess kind of the first oneof the earlier things you weredescribing is that kind of syncing up ofthe clip recommendation clip extractionkind of with apple podcast with Spotifyand how you can unify these interfaces Ido think that's a really powerful topiclikeum you know with review like sometimeswhen I think about this weeva podcastand that kind of demo project I thinkabout like maybe integrating this on theWii v8.io website so like and you know Ibuild my clip kind of recommendation butI do think what you're describing isprobably the more likely uh future forthis of that kind of personalization ismanaged by some kind of platform almostlike sub stack how you have like anemail list but I think kind of justgenerally it's like thelike the evolution of these email liststhey become more like a CRM for youwhere it like keeps information aboutyou know why particularly you would wantto watch this this podcast clip and Ithink yeah if we can maybe stay on thatuh like hyper personalization of podcastrecommendation yeah I think like justkind of like using the language modelsto take the podcast clip take somebiography from a person or or even yeahI I loved what you said about theTwitter that kind of like data dataconnection is is a super powerful thingso yeah maybe if you could just tell mea little more about how you see like youknow personalizing it uh you know howhow exactly is that completely new withthe language models and all this yeahyeah so I mean really before you evencan get to personalizationum on the if you think about theintelligence kind of pyramid uh that'skind of the personalization is the verytip of the of the pyramid um there's alot of work you have to do beforehandum so obviously basically like the firststeps is transcription getting the youknow what the words that are being saidand diarization which uh not as manypeople know the stone but it's who saidwhat right so it's not you these thesewords were said but this person saidthat you know I'm saying these wordsyou're gonna say words laterum so that's kind of your basicfundamental building block um but thenthe really interesting part uh and bythe way that you know and there's beenmassiveum advancements uh in the last year youknow uh open ai's whisper uh and Whispertwo uh are just you know it's opensource it's free you can run it on yourown gpus and it's kind of significantlybetter than anything that existedum up until that point uh nowadays youknow even more competition which isgreat but like we're really starting toget to the very very tip liketranscription is almost solved not quitethere's still you knowumniches that they need to be uh solvedand obviously it's not necessarily 100perfect but overall you get very goodqualityum diarization is is still not quite atthe same level but you canum get very very close toPerfection uh especially with the aid ofkind of a language modelto sanity check uh like does it makesense that all of a sudden this sentencewas said by somebody else like maybe notokay yeah uh we can kind of uhuse the intelligence there to straightenthat out so but once you have thisdiarized transcriptthe really interesting part isum coming up with a hierarchy ofsegmentsum because you have essentially you knowif you think about a podcast especiallyright because these things tend to bepretty longum you have uh you know maybe a30-minute segment that iskind of an arch right that or an arcthat gets covered and then inside of itit might be about five minute and sevenminute and eight minutes that kind ofare even more pointed to a specificDirection so you want to be able to findthis uh hierarchyum of segments and that is really it's avery interesting problemum it's not trivial you can kind of doit in a recursive way a lot of thetechniques that workum if you find the small segments if youkind of zoom out you can use them tofind the bigger segmentsum so uhso that's very interesting and overthere there's actually in our experiencewhat works what tends to work best hasto do with embeddings uh so kind of agood entry point to theum Vector database and we can talk aboutthat but then once you've gotten all ofthis stuff so now we have a coherentsegment that is you know 25 minutes longum now you gotta match the segmentwith a person uh and right so like ifthere's a three hour long podcast maybeI'm really into uh you know mybackground before uh Tech is physicsright so if somebody's talking about uhinterpretations of quantum mechanicsthat's really interesting to me maybeit's not very interesting to you so howdo I map this segment to me and to youmaybe a segment aboutum I don't know if any something elsethat you'reuh into and and and there it's actuallyit's a very interesting one I think it'san open bar I think we're going to see alot of advancements uh in that realm themost trivial thing you can do again hasto do with embeddings right like whatwhat type of things belong in yourcluster of thingsum and obviously just traditionalranking personalized ranking like yousee but I think what's reallyinterestingwith language modelsumis that this type of ranking canactually now rely on the content onwhat's inside ofum the content rather than you know kindof proxies of user interests like who'sclicking whatum and if you think about you know whatnews feeds look like a lot of the timesnowadays you can tell they're reallyoptimizing for the clicks but it's it'sboth a conscious kind of choice maybebut also they really don't have muchbetter to do like how are you going toknow if this video is good or not if youdon't know what's inside of it uh youkind of have to rely on clicks but ifyou can now uh look inside of thecontentthat gives you a whole new dimension uhto uh rate content by uh which isespecially important for you knowlong-form content where people you knowthey really want to be engaged for theduration of their Drive their walk uhit's not good enough to click bait themuh so uh yepyeah firstly I'm glad I you know yousometimes when I take notes when I'mdoing a podcast I only have one piece ofpaper but I just did like half of mypaper on what you just said soit was really great I you know I kind ofbeginning with that um diarizationwhisper having that integrated in thesame platform that then does the llmpersonalization I yeah I believestrongly in that I you know right now Ihave like a collab notebook that mywhisper goes into personally I've cutwell I'm also kind of not necessarilyworking on this all the time but I'vekind of given up on diarization becauseyou know for me it's like um labeling Iyou know whisper doesn't give you thediarization and I haven't maybe someonewants a link to it and it'll just solvemy problem right away but like I've justI've just decided to just chunk the textas you mentioned like the llm can sanitycheck like does it make sense for thiscup that actually I think works prettywell and they just scale yeah and thatscale is nicer for me to just get allthese podcasts in there quickly and yeahso I believe strongly with that my otherthing kind of with a platform that doesthis is like for me my whisper willtranslate like weediate to wv-8 you knowyeah yeah yeah and so these kind ofthings are like kind of a problem forthen you know like an embedding that islike you know uh you know like yeah Ican imagine these little transcriptionerrors are kind of problematic for theseinformation specific podcasts like ourpodcast particularly is going to beabout like you know we usually reallydive into it on Vector databases and soit's like you know those littletranscription errors butso then we so then talking about kind ofpersonalization again is um this kind oflike I love this separation as youmentioned like the popularity bias beingtoo strong and we've yet we have thisthing called reftubec where it's likethis is like one of the Demos in thatGitHub repository too where it's likeConor and then I interact with like fourpodcast clips and this is something likethat you know is just going viral onTwitter is somebody discovering thisthat averaging these embeddings actuallylike produces a pretty nice Vector inthe middle of it I'm just so surprisedwhen I started playing with this but youknow just averaging those four clipsthat the embedding of those four Clips Iliked just using that then is the searchVector yeah and then yeah that kind ofranking stuff you know we just did likean integration with coheres re-rankingmodels and that takes his input like theyou know the the query and the documentand replacing the query with like a userbiography and so maybe first search yeahyeah I think all that's so powerful butkind of the so the you know this in mynotes that I'm replying but the the onething that you said that I really wantto get more thoughts on is thathierarchy of segments I've never heardthat before so that like you know like amoment and I've you know I've beenplaying with summarization chains it islike this idea where it's like theprompt is like you will receive theclips one by one as well as the localsummary so far or the local list ofchapters so far and you just you knowbut that kind of idea of maybe havinglike a topic modeling where you you knowyou have the latency the embeddings ofall the clips and then you cluster thoseclips and then you know you have likehierarchical topic modeling yeah can youjust tell me more about how you see thatperspective of yeah hierarchy ofsegments I think there's definitelysomething to that yeah yeah so I mean Ithink it's really interesting for likeit's it's um well first actually I meanit's all kind of related the the and Iwould I would also love to hear we coulddo this later your theorization uh takebecause that's uh that's interesting forus actually the arizationuh which surprised me uh significantlyboosted performance of the rest of thechainum and I I suppose it might be a youknow we did I didn't try to do justllm guest sterization maybe that wouldhave been good enoughum but if you just compare to the plaintranscriptum it really made a big difference tothe rest of the chainum and you can kind of see it yourselfif you if you yourself just look at atranscript with theirization withoutum it's much easier to understand what'sactually happening um with this littlepiece of informationum but on the on theum hierarchy of segmentsumso what's interesting actually with refto Vector I don't know if you saw Yohelike of a baby AGI Fame like he he didhe posted a tweet that is uh anaveraging of all the embeddings of histweets and then back to text uh and it'sreally interesting to see what theresult of that wasum and uhwhat you can tell is that the kind ofhighest order bitis style to some extent uh it looks likeright you cannot mistake that text thatcame out for something other than atweet uh it's a tweet by a techie rightit's like kind of like so so that's thefirst kind of highest order bit to someextent that gets maintained thereum so the way we think aboutum transcription and honestly uhsorry not your screenshot butsegmentationumis you're trying to findthe flow of topics right the thing thatrepresents a flow of topics the best isan embeddingbutyou want uh you want to kind of lose thestylistic partsum when you try to figure outthe flow of topics so we the first thingwe do before we we look at embeddings iswe uh kind of normalizethe segments that we're looking at to tobe of a uniform style to some extent sowe say okay let's summarize what'shappening in this clip from kind of thisthird person perspective so hey thisperson talked about this they broughtthat up like rather than just have thatplain embedding of what was saiddirectlyum and and what we found is that whenyou do that then when you look atembedding uh distancesthat tells you when actually topics haveshifted so um a strategy that we that weuse is we basically embed we take allthese segments we chunk them upwe normalize them we embed thenormalized textand then we compare the embeddingdistance between a chunkand the preceding chunkum and and we actually do this for thetwo previous predecessors right so yousee okay like if you have all this arrayof segments essentiallyum you look how essentially you'reasking how different is this segmentfrom the segment right before it andfrom the segment right the previousbefore and before before right and thenumwhat you see is when you find uhwhen when you you look at all of thesefor the entire podcast the spikesin embedding distancecorrespond to topic changes to toessentially segmentations and and youcan do this uh when you do this with uhsegments that represent very shortsegments then you getthe shorter segmentsbut you can repeat the same exactprocesswith a longer segments right so let'ssay now you've found okay here is oneshort segment now let's take whichconsisted of a lot of these kind of youknow micro segments right so now let'stake this we summarize this we normalizethat uh and you can repeat the sameprocess again and now you see okay theseall these these four segments that areeach you know five minutes longthey make a coherent segment that is youknow 25 minutes long uh because there'sthis Arc change that happens you knowthatum I don't know if that made sense it'skind of uh oh yeah that sounds I meanit's I think uh kind of firstly thatkind of like normalized the Style bymaking it like kind of I read this onepaper that's called uh like retrievingtexts based on abstract descriptions andso you take like a podcast clip and youprompt the language model to yeah likejust just make the content normalize thestyle that's yeah that's a reallyinteresting kind of thing and you knowas you mentioned just looking at theembedding distance to detect topicchange that that could be a huge costsaver compared to having the languagemodel go through it and and yeahobviously I love any kind of applicationof embeddings but like um yeah really myyou know my curiosity as we were talkingis going into this like multi-discoursetopic this is like you know you you aretrying to embed a chunk of text thattalks about multiple things like I thinkkind of as the tie kicked off thispodcast we had a lot of speaker turnsthat mentioned multiple things like itwould be like you know whisperdiurization ref devec and ranking likeall in the same kind of clip and so whatkind of happens with embeddings is likean embedding for just that you knowmulti-topic thing is doesn't really workall that well soyeah what you're saying I'm trying toI'm trying to come up with a goodquestion to follow up with it but thatkind of like you know separating out thetopics I think that is definitely apowerful thing for just umprobably like text chunking in generalprobably for anyone building any kind ofapplication with Vector databases theyshould be thinking about something to dowith that I mean maybe youyeah I don't know maybe I mean and thenI really like what you're saying abouthow you would try to then tie all thetopics that you decompose into one bigcoherent thing yeah is it this is kindof my first time hearing this so I'm I'msorry if I'm not like quick enough tocome up with like a good reflection toit but that kind of uh yeah it'sumobviously this is uses use casedependent but for podcasts whereit's people speaking right it's not youknow a lot of text that is natively textis kind of by default very structuredyou know if you look at archivedocuments they all kind of look the samethey have the same styleum soyou can kind of get away without doingany type of normalization because it'salready normalized by whoever wrote thething in the first place but when youlook at just conversation free-flowingconversationum then uhyeah if you know the example you saidinitially we started talking about okayabiate and uh Lambda index and all thesethings if we just look at the embeddingsfor that that will now connect to someother time that we said lamendixum very strongly but if you firstsummarize this then the summary would bewell a Thai encounter uh discussed at ahigh level likea few uh llm Technologies including youknow we V8 and lime addicts and so onand so forth so so now that's a verydifferent thing to embedum because Now it connects tosummarization right so maybe we also inthe beginning of the podcast wediscussed at a high level some otherthings right we also discussed at a highlevel what talk at AI does so so nowthese two things connect whereas maybethey wouldn't have before we normalizeitum so for me for you know for kind offree form content the step of embeddingis almostnecessarily tied to some type ofnormalization by the language model tobegin withum in order again if you talk about kindof a longer chunk of content uh thatyou're trying to relate to other longtypes uh long chunks of contentyeah I think that's absolutely brilliantthat's the first time I've well I I'veI've been studying this problem of likedomain generalization and deep learninglike you train an image classifier onclipart and it can't generalize tophotorealistic images or sketches likeunderstanding the confounding impact ofstyle on deep learning models and yeahthis just really helped a click for me Imean I love that summary index the ideathat you use the LMS to summarizesomething in the embedding of thesummary ends up creating better searchum yeah so I thought that was really areally interesting conversation topiclet's um if we could pivot I love alsotalking about how can we make podcastingmore interactive kind of the long formmake it more interactive I'm curiouswhat your thoughts are on thatyeahum it's it's a tough one honestly so wewe actuallyumgot to this world in a very convolutedway we started just with podcastsum not with AI actually more it's kindof socialum podcasting and uh and you knowthere's a bunch of of companies thatstarted out around the same timeum and basically none of them made itand it's because like there's somethingwhen you start to like really look atpodcasts this world of podcasting I meanwhat works really well in this worldis obviously tons of consumption righttwo billion hours a month that's a lotuma lot of by a lot of people right soit's it's pretty Universal in the USsomething like a third of of adultslisten to uh our weekly podcast as soonas they list on average to two to threehours a week so so that's quite a lotlike it's it's pretty variable so thething that is brokenis distribution right so peoplegenerally haveum four to five podcasts they kind ofkeep track ofuh and then they It's All or Nothingconsumption anything that's outside ofthese four or five Pockets it will nevereven get the chance to enter theirsphereum and if you and it's also All orNothing at the level of the episodebecause you have this you know two threehour long episodes oftentimesand unless you listen to the whole thingyou will never hear the 30 minutes inthe middleum and and that's just really hard tosolve um because again it's kind of it'sa multitasking medium uh right in itsnative form like these two billion hoursof consumption people consume pockets inother places too right on Tick Tockthat's a lot there's Autumn it's frompodcasts that go viral but but that's avery different mode of consuming thiscontent which is also importantumfor spread especially butumbut if you look up just plain podcastconsumption it's generally amultitasking medium uh so people consumeit while they're walking their dog whilethey're exercisingum and interactivity is really hardthere because you're you know screen offit's kind of like a screen off mediumumwhich is why it can be long form by theway that's in itself pretty interestingyou know because every other medium inour lives is pulling to shorter andshorter and shorter right like soYouTube videos went to tick tocks rightso if I'm like 10 minutes long to now aminute long right that's kind of theaverage uh text went from blog posts totweets right so most media kind of pulltoo short for them but but if you butpodcast because it's a multitaskingthing you know if you imagine in yourmind walking and listening to One Minuteone minute one minute like that soundslike hellum so it's like the long form is whatworks and then that kind of comes handin hand with not as much interactivityuh so the question is when you want toadd interactivitywhat where are the entry points that youcan do thatum easily uh or that kind of thatcorrespond to user habits and userpreferencesum and I think so so there's like a fewplaces that I mean first of all likejust podcast is just a wealth ofknowledgeuh that is really fascinating thatin a form that is really easy to consumeuh so better integration with search youknow you search for something on Googleyou find text probably there is somefive-minute click from a podcast ifdepending on your topic that will belike much much better for you to likeget thenumthen then a blog post that's talkingabout it but you'll get the blog postyou won't get this five minute segmentsoum so so that's one place to addinteractivityum and then on the consumption sidethere's there's a lot of thingsuhtwo we can talk about but maybe I'llpause it there so but I I think yeah Ilove that everything you said about kindof how you consume podcasts like for meyou know I think that two to three hoursis probably about accurate and you justlike for me personally I'm sure it'saccurate for everyone but like you knowI usually am kind of tired from work orcoding and something so it's more likeI'm yeah walking around or like playinga video game and that's more theexperience and so when I think aboutthat kind of like uh clip recommendationthing I think maybe one way it couldwork is like you listen to Connor andit's high talking about this and thenmaybe they are some llm with a voicenarrator that says like you know and nowhere's a clip from machine learningStreet Talk where they also talk aboutthis topic and maybe that's one way tobuild the experience where you have somelike intermediate narrator that's reallylike an llm with a voice clip thing butyou know something that you ended theconversation with uh your speaking turnas it did the podcast thing about itlike transitions butum this uh like the the informationvalue of pod guest Clips like youmentioned whether you Google search fora topic whether you would want to bebrought to you know a medium article aYouTube video an archive paper or apodcast clip and I think the podcastcliplike it adds that it's kind of like whenyou're at maybe like a spelling bee whenyou're like could you use it in asentence I don't know why that wouldhelp you spell it better but like if theif the task instead of spelling it waslike what's the meaning of it right likeI feel like that kind of likeconversational context of something likeyou know like one of my favoriteprojects is building this like you knowllama index has this like uh queryrouter across different indexes so Ihave the blog post the podcasttranscriptions and then I have the weviacode base and so I feel like if it's ifyou're talking about like what isreftubec there's there's definitely acleaner in the blog post or the codedocumentation but there's something tothat like how they used in conversationkind of right like it's kind of like ait has like a unique information valueto itand that kind of brings me the questionI wanted to ask about is it's it's likelike these podcasts it's almost like asport like you and I are right now likethink about like what are we gonna saynext how am I going to react to What atie is going to say and so I to me it'skind of like this like post-gameanalysis almost like I'd like I lovelike the interview study kind of papersI think like that is also somethingpowerful it's like how do you go fromlike a podcast into kind of a blog orsomething that's more curated and morelike a reflection of these thingsyeahum sorry can you say that like just thelast part again so so the likesometimes like just as an anecdote Iremember when I started the weba podcastand I had this conversation with HanZhao the CEO of uh Gina Ai and he likejust gave me this massive tour of neuralsearch and I was like this should belike a survey paper there was like thisshould be like an academic survey butthere was so much to it so like I feellike they're even like our conversationnow is like how do we go from like allthese topics we talk about kind of liketranscribing it and then I feel likealso kind of turning it into the writtenartifact as well could be an opportunityfor this stuff yeah yeah I know for sureit's it's uh there's definitely if youlook at the content that is kind ofright now hidden inside of audio andvideoand it is hidden right because for themost part these are opaque files theylive in a hardware assignment where anduh when they do get surfaced for youthey it's very non-granular they theykind of here is a video that you know isrelevant for this but okay it's an hourlong wait where rightum and uhyeah so I think there's a lot ofinteresting things of justputting this uh a plain textual form uhand it seems like it's getting closerand closer to actual realityum and then uh on the other side it'salso very interesting to kind of uhyou know there's this trend that'shappening outside of podcasts and ofpersonalization of content right likeyoutheyou know there's the South Park episodethat went viral that got generated bythe LM so you know people you can have aSouth Park episode generated just foryou that nobody else watches like Ithink things will probably start to getmore and more to that place probably notliteral personalization at first butmore kind of the long tail of content sohere's like a segment of people that youknow before it wouldn't make sense tomake content just for themumhow do you startto do that now that it's much cheaper tocreate contentum and uh I think one of the biggestchallenges there and in general withllmsis this kind of like uhMirage of like we're almost at 100 rightwho almost can do the whole thing byitself and then what you can find isthat pretty consistently you can if theLM can do it at all you can get to like80 90 percent like pretty quickly likeright you're not gonna get like 30 likeif it can do it at all like you can getit to 80 90 but then the last 10 percentis really difficultum to get and you know we kind of sawthis with self-driving cars where theykind of got really really good reallyreally fast and it's like okay next yearthat's full self driving next year nextyear and it's like still not hereobviously with progresses continue to bemade maybe it will be here in five yearsum so but but that's something I'mthinking about in terms of plain youknow if if you're trying to actuallycompete on articles right like somebodyonce you read your article for Real uhrather than something else then I thinkthat the human augmentation is reallythe most uh interesting place where youcan maybe take the podcast episode andnot literally put a blog post up but youcan do 90 of the work and then if thisis interesting enough a human comes inthe loop and like finishes it upbasicallyum for consumption so that so that'ssomething that could be uh veryinterestingyeah that I mean that's that's perfect Iwas like I was kind of disappointed whenI was when I ran my summarization ofthese podcasts experiments because yeahlike it what it'll do is it'll likeespecially that sequential summarizationchain it'll collapse the topics intolists because it like doesn't reallyunderstand what I'm talking about withweavia and like maybe just like as ifanyone's interested in like what I'mworking on out right now I'm kind ofI've gotten really into the LM finetuning thing and you know particularlywe're building this model called gorillabut like I'm starting to learn moreabout it you know Samsung has helped mea ton with sub strategies like we V8listeners are curious about anyways butlike I agree really strongly with thislike um I think we need to fine tune thellms to get that 90 to 100 likeyou know for the for I don't think justthe gbt4 API well I don't know thoughit's so interesting I hear so manyperspectives on this and and it's likethis has been I always this topic comesup on every single web podcast rightwhether you need to fine-tune models orespecially now as retrieval augmentedgeneration is emerging like you knowwhen I as I talk about like sometimes myfrustration with these summarizations ofpodcasts is that it'll just likecollapse the thing into a listso so it'll have like multiple topicslike it'll be like you know Connor andAlexa first discovered uh talked aboutthis you know they described this thinglike and so like it captures the keywordand then it has some some sentence thatsummarizes the topic that makes somesense and then like on the next step itjust boom collapse all that into just acommon separated list and the last topicsorry that wasn't too clear but butreally so so basically you're asking itto go from the transcript to uh a textarray like a comma separated array of uhso I'm trying to capture like thissummer you know like I my goal kind ofwas like can I automate the task ofpublishing a podcast of which I alwayslike write a description and then I cutup the chapters and as it was writingthe description it would you know itwould just collapse the because it's gotthe it goes you will receive the clipsone at a time as well as the summary sofar and then you inject the summary sofar and then the next then you Loopthrough each of the clips and so thesummary so far will be like you knowthey just they discussed this topic thenthey discuss this topic and with thedescription of the topics and then itwill just boom comma separated list ofof just the keywords that describe thetopic but anyways I I think I'm gettinga little distracted from our mainconversation topics but basically myconclusion is like I'm I'm very curiousabout what fine-tuning LMS are going tolook like even though I'm still on thefence like I am working on this but Ithink like it also could be the casethat just retrieval augmented generationcould retrieve more background on eachof the keywords and avoid the collapsethat way so I don't know what the whatthe conclusion is going to be but it's alot of fun supporting it but let me kindof come back into one of the things wewere just talking about which is thissocial component to podcasting I thinkit's very interesting like as an exampleI really like Ben morica's data exchangepodcast and I think one thing that wouldbe interesting is like you know we thereevery now and then we have the sameguess like um you know he talked toJerry Lou I also had Jerry Lou on thispodcast and it's like uh like I would bevery interested in like what did Ben askJerry that I I didn't or you know if Iimagine any you could compare any twopodcasts like this it's maybe moreinteresting for me personally becauselike I was in the podcast but like youknow that kind of like comparison ofpodcast and maybe share a guess and it'slike what did they uniquely talk aboutthat's kind of where I see the socialangle goingyeah yeah for sure I mean what'sinteresting nowis that uh although honestly I wouldalso have to talk about the thefine-tuning versus uh rag like let's seeI think that's super fascinatingum but but on the topic of what you justbrought up you know it's kind ofinteresting you see this pattern inpodcasting where a guest would go on adifferent podcast and sometimes you getdiff totally different thingsum but sometimes they kind of say thesame thing on five different podcasts ohyeah and they kind of have to becauseunless you subscribe to that podcast youwon't hear this episode even though it'sabout the same it's roughly the samecontent so I thinkit would be interesting you know if wekind of take for granted that it doesn'tmatter necessarily where you saidsomethingum because the right content gets to theright person the right time thenumI think these things will naturallyevolve to be more distinct every time solike he's like okay we already talkedabout this people who care about thisthey already saw this now let's talkabout something elseum and obviously there's value to kindof repeating the same conversationsometimes but but that can be up to theperson they don't kind of have to dothis to get their message out to someextent hmmyeah it makes me think about like um Iguess just the future of social mediagenerally like if I you know just likelooked up Bob inlight and I just sawlike um you know a summary of what he'sbeen talking about for the last week onyou know Twitter Hacker News uh LinkedInmaybe even like I think because there'salso this interesting kind ofinterception between like your internalcompany meetings like and maybe I'mgoing on topic but like it's kind ofthis whole all this like podcastingstuff I think it's just extremelyrelated to just recording your teammeetings within your company like I'dimagine like you know that that therecould be there's so much value to beextracted by just you know getting moreof capturing the information shared inthese kind of meetings butyeah it's all it's all reallyinteresting I I maybe wanted to pitch anidea to you which was like um you knowone of these machine learningconferences iclr they developedsomething called open review where theyyou know they open source the um thereviews for papers and I was and I'm andyou know Twitter has like Communitynotes Now sort of x x it's called X nowI'm not it's gonna take me a while toremember to say that but well I stillcall Facebook I can't do the meta thingyeah I actually have started calling himI think because like the the Llama 2models the image like because now it'sso I'm seeing the like you know allthese exciting things and it's like metaand it could be more for me too it'sstarting to do fineyeah yeah but um so I was curious aboutwhat like an open review Community notesfor podcasts might look like where likemaybe the platform shows thetranscription and like you like becausesometimes I say things on the podcastand then later I'm like ah I actuallydon't really think of it that way youknow you your podcast basically it'slike oh this is not quite right yeahyeah and like people could kind ofyeahyeah that's that's a really interestingthingumI I think this like in an ideal worldlike you should have always you knowwhile you're listening likebe able to open your podcast app and andkind of see okay where can I go fromhere so kind of like a combination of menote but also okay this he heardsomething this sounds really interestingwhat are you know Clips related to thistopic that you're right now listening touh from other podcasts potentiallyum and uh and obviously with llms youcan combine this with like a differentperspective like and and this starts toapply more and more if you get to likepolitical topics right there's likesomebody's talking says something withthis that moment oh that's aninteresting argument like did somebodyrespond to this argument on some otherpodcast I think that that could be veryvery interestingumand uh and obviously when you starttalking about Clips thenumyou don't even have to interruptanything you can kind of let people ifyou display a clip you can display thecounter clip at the same time you candisplay related tweets about it I meanyeah I think there's a lot of potentialthere and I'm a big fan of like openreview I think that you know on Academiathe the existing peer review system addsa complete unreasonable amount offriction and you can see what happensyou know with tweets the community likeor seats I don't know what we call themnowlike it actually works right like thislike people like you get really usefulcontextumandif we can do this like we should do thiseverywhere rather than add friction youknow you could either block the Tweetuntil they got community reviewed or youcan let everything go and andput allow context to surface upuh with intelligence uh kind of asobjectively as possibleumyeah I love that that like um yeah likeum they they used to call it likemisinformation detection and thenthere's all like there could be bias butI think yeah that kind of like here'sone perspective here's the counterperspective it reminds me like well itkind of coming back to thinking aboutpodcasting it reminds me of there's thislanguage modeling decoding algorithmcalled tree of thoughts where tree ofthoughts is like you sample all sorts ofcontinue like you know because languagemodels are stochastic models and so theycould sample many different generationsand so say I sampled 10 and then youknow I keep expanding the tree with 10from 10 you know and so like I there'sso many directions the podcast could goin and I think the other thing that'sreally brilliant about that idea withpodcasting is like you alternate thelanguage models that continue the treeand they impersonate Conor impersonate atie by like either being and this iscomes back to our fine-tuning versus ragThing by either being the fine-tunedConor llm or being the rag Conor LMthat's hooked up to like because I Ithink I prefer the rag thing as beingthe directions huge for the futurebecause I think it's going to be easierI don't know it's it's a really trickything because it's getting really cheapto fine-tune language models with uhsparse fine tuning and all that stuff sobut maybe it's right now it's definitelyeasier to just curate the Corpus ofinformation and things I've said to themimpersonate me with a rag to the chat tothe like gpt4 API yeah but yeah I dothink that like how many different wayscould we have continued our conversationwe're having right now right like I feellike maybe like in a meta breaking likethe fourth wall everything everywhereall at once like what what's the otherversions of the conversationyeah and then having all thosetranscriptions and then um it will okayso this is kind of another idea I hadwritten down that I wanted to pitch toyou is I had you Shang Wu on the podcastwho's building something called chatArena and so chat arena is like whereyou simulate conversations betweenpeople and Personnel other people yeahso the Stanford or something elseI think uh UCL uhyeah sorry but and this would be anotherbenefit of the community notes is youcan always correct because it's sorryI'm getting off topic but this idea oflike you simulate all theseconversations and then you look forIntel like look for new ideas in thesimulated conversation likethat one that's that's interestingumit's kind of like like I've gotten a tonof new ideas from talking to you now andbut it's like um well yeah it's likecould an llmbecause you know these like how youexplain to me like a lot of these topicsjust comes from your real experience Idon't know if an llm impersonating youwould be able to react to come up withthese new things but yeah there's like alot of debate I think about like whethersynthetic data can discover newknowledge broadly kind of yeah and noit's it's super interesting I think it'sit's uh I mean it all kind of connectsalso the fine tuning versus you know uhrag becauseI think we're all still learning itsounds like a cliche but it's true thatwe're all still learning there's thisnew tool in the world and we don'treally know what it's good at and whatit's not and you can really see thatclearly if you look at any blog postsabout like gpt3 when it came out youknow like two years ago or maybe alittle longer at this point like they'reextremely naive from our perspectiveright now like people are like saying ohwhat does it mean that it can likeautocomplete the story like that but notlike that like and then like what we arediscovering over time is no there'sthese these types of things it's good atthese types of things it's bad these areyou know uh you know rlhf like here's atechnique a pretty simple techniquewhere like one percent extra compute allof a sudden this thing ismuch more capable at uh this thing and Ithink we will find you know what I Ithink there's almost certainly room forfine tuning I I find it really hard tobelieve that like in two years like ohforget fine-tuning just do rag maybe Idon't know but I find it a little bithard to believe uh with existingtechnology because it's just so much itit's so effective at umespecially kind ofselecting pre-existing capabilities fromthe base model because otherwise all youhave to to talk all you have toavailable to explain to the languagemodel what you want is inside of thecontext window and that only gives youso much opportunity and practically it'soften just way way too verbose you knowpeople do like few shot learning ifyou're trying to get a Json out of alanguage model like you might give itfive examples ten examples like you'renot going to give it 5 000 examples inyour context Windowsum and uh but with fine tuning you cando that and I mean that's what whenopenai added function calling likethat's you know people try to solve thatproblem with chainsfor a month and you can get to someplaces like you know there's uh there'sa bunch of pro there's like theguardrails project there's uh Jsonformer but but the fine-tuning reallyreally picks this up and on the otherhand if you just care about plain factsthen yeah probably it seems like that'sa place whereum rag is uh more helpful than you knowfine-tuning new facts into the modelumbut uh sorry I'm forget I'm forgettinglike how we we there was like the pointhere another good point to have thatI'll test the yeah no I I got a ton itout of that I mean I think um yeah Ican't reveal who said this yet but um arecent review podcast it separated itbetween if you want to teach thelanguage model a new skill versus thenfine tune versus knowledge then rag isone perspective but think about it likelearn a skill versus learn knowledgelike a lawyer you know has the knowledgeof like here's the law says and thenthey have the skill of how to craft theargument from the laws kind of a and Ican kind of relate to that thing and Iguess kind of you know you mentioned thelong context thing I mean and thenthere's kind of the idea of also likewell instead of investing the energy andfine-tuning the language model maybe youfine-tune the embedding model or justtweak your search systems with like therank you know ranking tuning and maybethere's just more to that giving it theperfect context but kind of likesomething and I hope I'm not about toget get us off topic too much but likethis kind of thing of you mentioned likegbt3 to gbt4 I mean what a phase shiftright like gbt3 you had to like you knowfew shop prompt it to do a task badly Imean like I almost set your opinion itwould like come on you know and so nowit's like talking to you fluently andit's it's like blown the world's mindlike everyone you talk to if you talk tothem about Chachi BT they're like theyget it and it's crazy where whereas Idon't think people really reacted tothat with gbt3 but I think kind of liketo me it's like this idea of likeexperience grounds language or onmeaning and uh understanding it kindcoming towards nlu paper from EmilyBender I I forget the title but like thethe language models that are doing RL HFto like do customer support like we hadthis thing Kappa AI in our slack and itwas you know it answers your questionsabout weaviateand I imagine having a conversation withthat language model can maybe beinteresting because you're like what areyou learning like you answered 5 000questions like what are people askingwhat are you learning and maybe there'ssomething to that I'm not sure that'swhere we got it before right like thecreativity part so I'm actually in mypersonal life forget like productdevelopment like I've I've had manyinteractions with a language model thatfelt like it evoked creativity rightlike it like you bounce ideas you know Imean even rubber ducking can be helpfulbut this was not a rubber duck rightlike it actually gave its own creativitynow I I think probably it got I don'tthink it made things up it only got atthem from pre-existing things that arerelated but you know I am not aware ofthese things that are out thereum and B like one of the big advantagesof language models is you know theydon't get psychologically stuck I guessthey can right you can get this Loop butevery time every run is a fresh runum andumso that can help you get out of some youknow you might see a problem in thiskind of very you know laser focusedblindfolds uh way uh and that languageunlock you kind of open up a newdirection that you maybe you would havegone to eventually but but it will takeyou a while so yeah I think there'sdefinitely opportunity to actually makethese things interesting uh andespecially the more intelligent smallintelligent modelsumyeah like you said gpd4 versus gpt3 is abig big jumpumyeah absolutely I think that um you knowsome people it's only interpolating butit's like okay but it's interpolatingbetween a super high dimensional spaceand it's like the inner you know theinterpolations in this space are stillgoing to be really interesting yeah likemeasure I love that topic of like how doyou measure generalization broadly butyeah also I think this has been anincredible coverage of topics and so Iyeah kind of wrapping this up I I thinkwe did explore so many topics but isthere maybe anything you want toconclude with kind of on like how yousee the future of podcasting I mean Iknow we talked about a lot of potentialthings but like kind of maybe one thingthat maybe you even had like maybebefore we started talking we alreadykind of like what what you're convincedofyeah so I mean I think you knowpodcasting and generally audio videoum you know like I said like talkingwe're building this audio video databaseis the first internal kind of designpartner of thisum product andI think what's obvious is if you lookthree years down the lineone way or anotherum audio video are gonna become assearchable as textum where you can search and search andanalyzable right so you can now doanalysis at the level of semanticsum you know like podcast is oneapplication of this call centers I thinkthat we brought this up at another Pointthat's another big application and rightnow you have to build all this customcode to answer pretty general questionslike you know where are there callswhere the customer got angry and in theend actually got resolved wellum and in legal analysis people like doLegion assets over audio and video uh soso this this is I think what's reallyinteresting is the trend of taking theseunstructured you know speech and uh andvideo later too when you look at actualpixel on the screen andummake them as analyzable as we're used towith text uh so so I think that's goingto be very interesting and becausethere's so much knowledge and highquality knowledge locked away in theseformats I think that will that will havea a big impact uhyeah II really turn into the exploding heademoji because the um like this post gameanalysis I you know I had a conversationwith my brother-in-law this weekend whodoes uh stand up comedy and and we'retalking about like stand-up comedyversus like giving an academic lectureand kind of like the way the crowdreacts to it and it's and it just makesme think like you know after you do uhcomedy or a comedy podcast maybe you'dbe like you know how did I do how manylaughs did I get and that kind of visualinformation but I think it's also veryinteresting for like the academic thingbecause it's not as obvious like youknow if you laugh like you laugh and itcan probably easily detect that whereaslike if you pitch like an idea in theother in the guest like likes it or youlike you know like you're like oh youknow like it's like more of a subtlething and I think that kind of likepost-game analysis of like you know howdid I do in the podcast like was Iinteresting and I think there probablyis a lot of like um audio visual likeinformation that you would not get outof just the text transcript right butright now I'm I'm personally very bytowards the text I you know that's wherewe're starting out like right now we'renot really looking at visual stuff atall that that most of the information isI think in the textyeah but I mean certainly that audiovideo there's certainly there's going tobe breakthroughs in deep learning inthat I yeahyeahyeah really cool supposed to be inthat's high thank you so much forjoining the weba podcast this is such anengaging conversation for me I learnedso much to change opened my eyes aboutthis thank you very much for having meit was a really fun", "type": "Video", "name": "Atai Barkai on PodcastGPT - Weaviate Podcast #62!", "path": "", "link": "https://www.youtube.com/watch?v=DgDbtuGugqA", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}