{"text": "Hey everyone! Thank you so much for watching the 3rd episode of the AI-Native Database series featuring John Maeda and Bob ... \n[Music] [Music] n [Music] hey everyone we're super excited to present the AI native database podcast series we've invited some incredible people discuss where these new advances in generative AI are taking us and the role that database systems will play in it this series contains four interviews with Andy Pavo Paul grth John Ma and Dan shipper all four podcasts feature weeva co-founder and CEO Bob vanl thank you so much for watching I really hope you enjoy the series hey everyone thank you so much for watching another episode of the weeva podcast we have another Super exciting episode in our special CEO series featuring weeva CEO Bob vanl today we welcome John ma the VP of design and AI at Microsoft John has had an incredible career the intersection of design and Ai and human computer interaction I want to say the the professor at MIT the president of Rhode Island School of Design and I'm so excited to welcome John to the podcast thank you so much glad to be here with the CEO oh wow this is an honor yeah so thanks for being here John it's like I I told Connor before this like I I'm following your work for like a long time already and when I started to work in in in software and so I what Connor said is true so I I studied music and you were actually one of the first that I like hey it's actually okay that if you have like an art background that you can work in software it was kind of a validation that that was like okay right that's a uh so and and now here we are and I remember the of course the the famous design in Tech reports I remember that number one I was I've been I think I've been to all of them at South by side west and um the funny thing was I remember last year I was sitting in the audience I also noticed by the way that the room of the design and tech report keeps growing on a yearly basis and the people listening to the report but I remember that last time I was sitting there and you were talking about happening in Ai and the role of of you know desig in that and there it was Vector database it was like on the screen in the report and I was like could you imagine this holy cow I was like this is amazing so thank you for being here this is fantastic whoa you're saying early art technology conflict many years later and then create Vector database company and we connect together through Vector databases yes it's kind of perfect because you know I watched your talks and they're always about how human expression and these multi-dimensional vectors are literally relatable right yes and that's something that uh having an abstract thinking ability from the Arts makes you quite unique as a a leader in the field well thank you it's it's a um so one of the things that I also that I learned and again that's also party through your work was the um is the the the the role of the of like um I wouldn't say if I would say user experience that would be too narrow way bigger but this the that that that human influence on the technologies that we're building right and how people interact with that and um so once it's like two years ago some three years ago I I was invited to give a t talk and I actually did it about that subject right so what's the role of human language in the software that we in the technology that we that we create and that's actually something that I would love to talk about today because one of the things we're doing in this series is that we're saying like we now see this new wave of like technology and the databases for example with AI effected database Etc but we actually want to get the question as like what where are we going right so this is most likely not the end you know the the lost you know the end of the line it's like just a we're somewhere now with everything that that everybody's creating and we're trying to get the the question answer like so what's what's next where are we going what's like the optimal way of interacting with our Technologies and we've been talking to to scientists we hav't talked more on a philosophical level about these kind of things but I also would love to talk to you about that from a more a from The Experience SL human kind angle right so how do we where do we want to go in interacting with these systems and I think what's so interesting I'm very curious to hear your thought your take on this is that the now with AI it feels as if people start to anthropomorphize with the systems like it's like a it it's not like it gives me data but it's like it it tells me something there's a and I would love to get your take on why you think that this is what this is opening up and where we going with this well first of all you know whenever I explain to Executive teams how this AI works I urge them to understand that there's two kind of AI models that are emerging at the same time one being completion and the other being embeddings right and we love generative AI but if it's contextless it hallucinates so only having Vector databases working with generation do we get lower hallucination right it's almost as if there's questions and answers but the answers depend upon the context of the question being asked which is the hell Foundation of art you know I'm excited about how we're asking questions about um meaning whose meaning your meaning long form short form medium form and I love that uh at least right now in 2023 late 2023 they say that even if you have a giant token window uh it only remembers the beginning and end like a human being might um and so really uh memory matters a lot and on the topic of humanization I I consciously tell people the thing that Dr Joseph weisen bomb explained in the 1970s that as humans we can't help but imagine that these things are human when we're talking with them and that's dangerous so we don't think when we're talking to a squl server that it's a human ever we interacting with it in a way like could get it wrong could get it right it's up to me I think with these ways of communicating with vectors hearing a voice in our head that it's alive in some form uh it's not going to advance the science I believe can can can you say more about that so so can you double click on that why not um you know with the new open AI assistant API um I'm really struck by how many folks are excited about making these um We call we say plugins planners and personas so making these Persona type objects mhm because people who can't program this is great way to program because you're creating context for an assistant and now you can communicate with it have two assistants communicate with each other to do work it's essentially computer programming but with a conversational personality based interface um however if you start thinking they're real people or they're capable like real people then I think that's s of um uh it makes you less good at engineering the system I believe maybe maybe just put it that way yeah I I have a question about that so I um I once was at a at a conference in on Iceland actually in raic and the the I don't know if the conf it was a tiny conference I don't I don't remember it still exists but it's called material and the goal of the conference was um that everything in software moves so fast that um um we we great stuff but then we just stop using it and then we lose that knowledge and the they gave example as an example they gave they went way back in like 500 years back in time to uh DaVinci and they showed one of the drawings that he had for like a crossbow or something and they said like based on this drawing today we cannot build this crossbow because the the the knowledge that he assumes that we have about how to build a thing is gone and then they moved it closer to today and they took flashh as an example right an action script so when that was like killed what what there was a lot of creativity happening in flesh right so what people were building and then all of a sudden it was gone so so my question is like is they is there is there a risk in based on what you just said in um taking that abstraction layer of actual engineering Away by giving people the feeling that they're just interacting or the experience of just interacting with the system that we just losing knowledge on how to build reliable good systems good question I mean I've heard people talk about you know prompt engineering versus prompt design and everyone's looking for ways to kind of categorize what's better or what's not I guess my concern is that um uh that wisen bomb style c word of caution that we can't help but have the delusion that these things are really sentient and thinking when it's talking to you it's like when a doll talks to you as a kid you think it's alive yeah so we can't help but awaken that sort of childlike learn how to communicate with another human being uh when we're kids we can accept the surrogate as a stuffed animal talking when we're older we're like oh it's not alive um I think that that interface is very power ful but then if the interface engenders the wrong kind of trust like oh trust me I'm like fully sentent and 100% always right oh okay I'll listen to you all the time um that's poor engineering I think interesting Social Engineering also in so so just to make sure that I that I that I um got this correctly so you're basically saying that if you make the system that's that's that's being designed SL engineered um if if you make people believe that it's a sentient being that's a form of bad design or bad engineering am I saying as a just a a perfect example of irresponsible AI there responsible AI I guess there's Ry and II or something whatever yeah um uh and again um you know that that's a that's a judgment called that people will make differently some people as we know are if you look online there's already very realistic humanistic things that are meant to kind of lull you into thinking they're really real and for some people like in therapy situations they're seeing that this is really good for people who are having a really hard time and can always have access to a human being quote unquote to talk with I read something about security guards at night uh who are really troubled they need someone to talk with I find that an interesting use case um that said but in general environments of work or Building Systems once we personify them overh humanize them uh I think it just gets us humans in the wrong kind of relationship that's why I like the word co-pilot yeah because the pilot is the human and the co-pilot is the co-pilot the pilot is boss and co-pilot is not boss the co-pilot needs boss to get feedback from the co-pilot doesn't know everything in the world but if once you personify it as knowing everything in the world and being as good as your partner or could be your boss then you lose your accountability I think ah interesting so the the so basically the risk sits in the fact that we just we're basically shifting accountability away right so it's like it's really an ethical thing right so it's like they we saying like no no no it's like the the the AI told me to do this or the AI said you know that I should have done this something you really trust right it's like oh well you know my my AI Sven or Jan told me this that's why I believe it um you know we get in the same problem ourselves like you know like David said this it must be right then he to run off on a wild goose chase and then you come back and say oh uh David wasn't right I'm going to tell David they weren't right right um if if there are many AI agents personifying things uh it's easy to lose accountability I think I think it becomes less responsible yeah that's that's interesting because with they back to a SQL uh to a SQL system it sounds really weird to say like you know my SQL database told me to do this right that's kind of a weird perfect example it's it's kind of nobody's going to buy that right so so what what query went in to make you do this weird kind of thing right so it's say that makes that makes a lot of that makes a lot of sense so but it's so is how is this related to um so people like Jean Lun and sah they now make a lot of noise right about the um they like we should not go into the whole doomsday scenario thinking these kinds of M how how is that is it related to that or is it different um I think since I was younger I always believe that that saying when you learn how to drive you go to where you're driving like how do I steer well if you steer towards the edge of the whatever you're going to go that way so stay in the lanes by like you know looking in between the lanes and you're going to steer that way I think that in this era um the more we focus on going in that direction we'll end up in that direction so I bias towards qu asking questions throughout how do we go on that side because all technologies have a kind of a yin and yang uh pro and con you know most people know about the Nobel Peace Prize but most of them don't know that Alfred Nobel created dynamite which was a life-saving technology for miners who were digging mines with their hands and tools it was very dangerous the dynamite was amazing but also Dynamite is responsible for the most deaths in any War scenario uh in in the early 1900s yeah yeah no that's that's say okay yeah that's say yeah I see yeah I so I just I so I have one more question related also to the design aspect from this right so now now we're gonna see if I if I listened you know if I saved all the information correctly from where where did your vector bets go exactly exactly so um you distinguish three types of design right so um uh um uh so classical design so the the traditional May there is like style kind of design right if I if I may call it traditional design then we have design thinking so related to um more conceptual right the so how we how we create um Design Systems organizations Etc and then we have computational design related to how we build software and Technologies and um on so every design and tech report that I've seen and we've been talking about um technology then that obviously set in the computational design bucket right so my my question is everything what's happening now with AI has that more influence on computational design or X on design thinking are I think that um by the way I created that taxonomy because everyone who talked about design it was getting confusing and I wanted to characterize computational design which nobody understood and um I got a lot of people angry at me who are in class iCal design and design thinking but anyways I think it's sort of worked for me and it's worked for a few other people maybe because I think of computational design exactly as you're saying that it was waiting for AI to occur and now computational design is in the way way foreground and it's impacting classical design how we make things with gener of AI we can already see that in the image making space the model making space space the ux wireflow space it's like wait a second it's sort of making classical design artifacts design thinking it's being used to be able to make offsites much faster it's being able to help you build consensus in large organizations faster so I think about design thinking as being revolutionized by AI uh right now and increasingly so and the neat thing about computational design is it is impacted by Mo's laws impact so now with AI it's just going to keep doubling at a speed that um it's really hard to keep up with I don't know about you Bob but every morning or yourself Connor every morning like oh that wasn't possible oh it's not possible now I thought maybe it'll take like nine to 15 months and suddenly huh new world yeah yeah I have a I have a to as an anecdote so I have I have a um friend who um somebody somebody tweeted something that they built with like an image thing with we something and this friend retweet it and he and he said like I remember the times when I was a VP at at Google it took us like six months to build this and now somebody alone builds this in the weekend it's like it's insane how fast that that's gone yeah it is it is amaz like it is amazing how we're able toate create with AI in a truly agile manner to build poc's faster than ever we thought was going to ever happen yeah and we're so used to AI taking a long time like n months to gather the data M months to to train um more months to sort of test now we can like rapidly test and um like if you look at all the open AI Innovations after Dev day in the last 48 hours it's like could you ever build that last year I I don't think so well exactly so I'm one thing that I'm that I'm curious about now you now you mention Open the Eyes so the in in your opinion right so I so I started to work on on on we8 way back in in 2016 wasn't database yet but it's was like a it was of course had that focus on machine learning and I remember that I was on stage you know giving demos and people was oh you have some some kind of a keyword list or something I was no no no no no it's the model right so it's like and you the the the I think I saw a video from you like you have like apples and bananas and pears showing distance I did all that stuff too and all and there was like also a lot of like status quo bias right so no no no no we're fine how we're doing stuff right now and that shifted with that whole jet GPT release right so for the whole what's your why why was why was it that thing in your opinion that was eye openening thing because people were building stuff I mean um the whole the whole uh the generative models were already there people were experimenting with we already saw companies come up using these these these API endpoints to create like avatars and that kind of stuff but for whatever reason it was this chat interface on chat. open.com I believe that that made that that that shift why what why was that was it what what happened why why was people ready at that time and not before well you know I'm jealous of you Bob because you've been doing this longer than me so I uh but technically speaking I've done it longer in terms of expert systems in 1980s and list machines and so but that AI didn't do a lot so I think you started at the right moment um and uh you know you you knew what embeddings were you knew about all these things that were emerging I didn't for sure and I think that um people who were in the field were in Moors law the kind of a you were there in the early days and the doubling went from 1 to 2 2 to 4 4 to 8 8 to 16 and it was taking a long time I think we've arrived and chat jti arrived at the moment when it was doubling in giant chunks um analogy I give in how to speak machine com for a British riddle about a pond with lily pads you clear the pond and The Story Goes that if you plant one Lily Pad it doubles overnight and one becomes two two becomes four four becomes eight but the riddle goes on day 30 when is the uh on excuse me the riddle goes on day 30 the pond is completely filled with lily pads on what day is it half full the average person is going to say day 15 cuz 30 divided by 2 is 15 but Mor law people will say day 29 yeah so I think that chat gbt happened at the moment when embedding models and uh generation models and the ability to scale that capability to millions of users happened at that doubling moment and now it's doubling even further yeah yeah that's interesting and I that and the so one thing that I also find very interesting what you said about you you just said something about like about embeddings and you like you know I I didn't knew what they they were those kind of things so one thing that I really appreciate also in in in your work also what you're now doing like you know on the with the LinkedIn videos and that kind of stuff is that the um we as like technologists and Building Technology we have this tendency to write complex stuff right and and what we do is we signal to the outside world look how smart we are right that is what we're doing so let's make sure that we have this mathematical equation in that blog post to to to show that we I don't I don't think that the majority of people read those blog post actually can parse that what's what's in there and but the problem is that what what we're doing with that is like that's all you know it's it's all very um you know we do that for ourselves right to just show off that we know stuff but we're leaving like a large group of people behind who do not understand this kind of stuff I saw recently on um on a Reddit post where people where somebody I think it was like I think it on the Lang chain Reddit or something like I actually don't know what embeddings are and how they work and then a lot of people respond I don't know either right and they were they were building stuff and you're doing such a great job in the in the um um um in just explaining to people in lame layman's terms what what's happening what we're building but I also remember that you um uh couple of months ago you had like a LinkedIn post where some somebody I think critic Iz that or the the the depth that you were going in with what you were sharing in the videos oh yeah and I was surprised that people don't get that right so it's like okay but I I would love you to to speak about that because it's a it's a we need to help people to understand how they can build these systems right well you know I benefit from not being that smart and I have a hard time understanding stuff and after I understand it so that I can explain it to myself I'm happy to explain it to others knowing that there are much smarter people in these different fields that can explain it better than me and they're often more than happen to tell me that and I'm used to it from all the different fields I've been in whether because I began in engineering and I went to design and people thought I was uh knew nothing about design I got my MBA people thought I knew nothing about business went investing people told me didn't know anything about investing you know I've been doing just a variety of things and I'm used to people telling me I don't know what I'm talking about and I appreciate that criticism because it forces me to want to learn more yeah but he isn't it also so I I appreciate that answer but I'm I isn't this also aren't we isn't isn't our job to help people understand this kind of stuff is well I think you see it that way and your team's doing a marvelous job of explaining things so that anyone can understand it and um it's part of your strategy I think which I think is a good one um it's been my strategy but as you know some people take the strategy of gee you're too dumb to understand this so you're going to come to me as the expert and thank me for my expertise oh this is interesting I think it's because you're an artist that's why you're doing it that way it's very unusual um someone asked me like why do I come across as so uh insecure or lacking confidence it's because I'm curious yeah I'm curious and curious people don't look as confident as people who are less curious MH artists are curious and they like to share what they're thinking to get feedback around it in ways that more people can actually give you feedback because it could be wrong and when you're wrong you're excited because ah I got to improve that I think it's the basic of agile engineering right but I think artists live very agile mentality yeah so it's it's interesting you that you say that because it's like I I I see that as like two topics right it's from my perspective it's exciting to share with people hey look what we're figuring out look what we're trying out look what we're what we're building right so I um as a very pragmatic example um I always call myself the the the noob uh we8 user so every time that there's a new release right I'll just try it out and I'll I'll I'll just push all the buttons and I'll I'll it go you know talk to all the apis and figure stuff out and then I ask new questions and then I go like but like you know if I have this question then probably somebody else has that question too right and then it ends up in a documentation or it ends up somewhere else or like a a default setting in in the so I me these things like saying defaults right what does that mean right so for database those kind of things I I think about that but it's like I agree with what you're saying it's like it's fun I mean from my perspective it's fun to share that and the second thing is there's there's and I'm not sure if you see this the same way but the way that you would what you were describing what saying like you know um studying art MBA um into investing those kind of things there's of course some kind of a athetic also in The Beginner's mind right to to to keep that to to keep being good at being in The Beginner's Minds that that that the expertise is being in The Beginner's mindset well well you know you reminded me how when I wrote laws of Simplicity my favorite story I found and put in that book is a story of realizing that if you're in like uh karate the martial arts um apparently if you you know you work from a white belt to a whatever a yellow belt green belt where you work way up to a black belt and uh I I heard that the goal of the black belt is to have that black belt so worn out that it becomes a white belt I kind of love that idea because it kind of embodies this beginner mindset desire uh I know that every time I think I'm good at something I tend to change Fields because I'm worried of becoming complacent interesting interesting so is the the so what's next for you where you going so it's like we're now what's what's because now you're you're like in that AI space and and everything so I gotta tell you like like in the last 48 hours it's assistance assistance assistance it's you know 4v4 turbo all the way sort of a uh I I I love the multimodal uh capability you know I'm a I'm a personal subscriber of gbt plus catchat gbt plus and I was like using it like you know I was like what is this this is like really good um I like how I'm appreciating multimodal models appreciating language right because most people don't realize because I come from image processing they don't realize that image processing was really hard maybe you can find one or two things but it's like oh few I found a cat I guess I'm done but now with uh large language models there's a cat it's probably indoors or it's outdoors is there a bowl or there's no bowl is there chair it's an indoor it's probably a kitchen it's like um an amazing way to kind of rebuild the thing that is being looked at and so when I see 4V I'm like wow image processing plus semantics amazing yeah yeah exactly and so I I've I've I've actually one more question about that so the the um um so I I mentioned for also the statusc bias and um it's a question about that and the especially when it comes for to the creative Industries and um there's this this um uh lecture that was given by um the the science fiction or the I I believe he also calls calls design fiction author Bruce Sterling and um it was actually a couple of years ago in Amsterdam and he in his lecture he makes the case that everything every technological innovation that's happening um and the impact that it will have on society you can see that with musicians first that is the that is the the case that he's Mak so so so an example would be um uh um when when when the web came up right so what was the first thing that people started to to share where we saw like the um uh things like aggregation Theory and those kind of things we saw that through Napster in the music industry right and and those kind of things and what's fascinating now with um everything what's happening with the models right and the multimodal models right might maybe it's happening in music maybe it's not but it's like in the creative Industries and and and what I meant with status quo buy that some people are afraid they go like oh boy there goes my job or let's go this or that or I believe that the the riders in in in Hollywood right so one of the the the points that they had that they were worried about was like the impact of AI on their jobs I I'm not a I'm a I'm a glass Health full guy kind of guy right so my question I guess is all this combines all into a question is like how do you think how big is the impact going to be unlike in a assuming that you have a positive point of view on this as well for the creative Industries how is this going to help the musicians the authors the writers the the the just all the creatives in the world to create new things right not enhance or maybe you think it will enhance things or create new things but how do you how do you see this what will this do for the creatives in the world uh well first of all I'm excited about your comment by that person who in their design fiction describe musicians kind of the canaries and the coal mine you know um there was someone who told me how in the 60s and 70s there was no computer science departments so IBM recruited from the music department because music is a skill that you learn in different language and have representation so I've always like that analogy and you also made me think most early digital technology was onedimensional it was more sound waves right it was more easy for the new technology to impact musicians because it was accessible to them two Dimension three dimension four dimension much harder so um going to just art in general and creativity I look to the era in Europe of the Arts and Crafts movement where there was um rusin and Morris they were leading the Arts and Crafts movements in the late 1800s in reaction to the textile machines making it easy to make textiles and that's the era of the Lites the so-called Lites that would go and break the frames of these looms mechanical looms to demonstrate against essentially the AI of that era um and rusc and Morris were seen as people who were more backwards looking like why would they make things that are so expensive or just handmade I think that they were making things that machines could not make and that's why we have kept them even now in museums all over the world so I think we're entering an era where there will be artists who will rightfully demonstrate against what this art is and what it can do negatively and there going to be artists who are now going to ask themselves what can we humans make that AI cannot make I think that's really interesting and if you're a technologist you get excited like oh wow those artists are going to make things that AI can't make so I'll now automated it you know go for it I say on that too as well yeah exactly I I I find it so fascinating because I I I um I know you have this this this two by two right with engineering science arts and design right and yeah I believe that it was ner oxman who made this into yeah she made a more much more fancy diagram so it's hers is better yeah yeah and that's like it's it's so interesting how we're now with everything that the technolog is enabling right so from the level of the mod models but also the database that kind of stuff that we are just now bringing that to people and that we seem to be moving now more in this Arts design kind of way where people just start to create new things to inspire people to start new businesses and then it's like keep cycling around but but the models can code pretty well right I mean they just keep getting better and better so coding engineering science it's it's all going to be disrupted and um you know I was uh visiting a university recently and I was talking to people there and the dean of the school was saying like what do we do you know when we don't know what to grade uh what do we do when the students can use things that are far beyond what we have available to them as tools um so it's an exciting time it's also a time where people are afraid and that's why leaders of product companies like yourself can make a huge difference and um that's I really appreciate your social team makes really good stuff uh makes it very Tick Tock like you know I like oh this is going to work uh so uh kudos to them thank you thank so just to make sure just to to as an end note so do do I hear correctly that you're thinking that this basically this model like this that that that crap cycle how how we as humans have how things have informed each other to keep growing as a as a as as a human species that you think that that's going to be disrupted oh um it's more that all of those four quadrants are being disrupted um it is those people who live across them that I think are kind of Lucky like yourself um you know and I think it's good that we're all trying to explain to more people how these models work because then they they can then they can understand how they're they are limited in some degree and they're more powerful than you could ever expect and in that understanding fear levels go down and the constructive ability to go across all those four sectors to create new value uh for Humanity becomes more possible so I think that the fear is coming you know we talk about uh AI interpret interpretability or understandability I kind of think knowing what embeddings are is a first step towards AI explainability you know oh is that how it works banana orange Apple oh uh generative models using statistics oh that makes sense then the question goes deeper of like how it works and how it's created those are all important questions but even the doorway to understanding is blocked yeah no it's a and again it's a I just I think the work that you're doing in helping in that and and we as a company humbly try to help there as well just to give as many many people access to these Technologies to build stuff right to create things whatever they want to build well exactly and that's why I feel lucky to be in the middle of semantic kernel world where it's all about making it easier for Enterprise app developers to make stuff it's why we launched the Cozy AI kitchen to kind of widen the funnel of understanding where I show up as a cook and I'm cooking with the semantic kernel oven and you know I know all all the different other ways to build an AI and people tell me like why would I build a semantic kernel there's this that or whatever it's amazing and I'm like semantic kernel is a boring alternative for Enterprise apds that need to make secure and reliable AI prototypes and solutions yeah well why doesn't do this do that because it is the boring and reliable way to do things I just stick to that but who would ever want that well it turns out lot of people that yeah yeah so that's true where I'm thank you so much John this was this was wonderful I I really enjoy thank you Connor it's an honor to be with here with you ", "type": "Video", "name": "Humans and AI with John Maeda: AI-Native Databases #3", "path": "", "link": "https://www.youtube.com/watch?v=c9t0VViIP9c", "timestamp": "", "reader": "JSON", "meta": {}, "chunks": []}