{"text": "\nTo conduct semantic search queries on a large scale, one needs a vector database to search through the large number of vector representations that represent the data. To show you how this can be done, we have open-sourced the complete English language Wikipedia corpus backup in Weaviate. In this article, I will outline how we've created the dataset, show you how you can run the dataset yourself, and present search strategies on how to implement similar vector and semantic search solutions in your own projects and how to bring them to production.\n\nThe Wikipedia dataset used is the \"truthy\" version of October 9th, 2021. After processing it contains 11.348.257 articles, 27.377.159 paragraphs, and 125.447.595 graph cross-references. Although a bigger machine (see below) is needed for importing the data, the serving is done on a 12 CPU, 100 GB RAM, 250Gb SSD Google Cloud VM with 1 x NVIDIA Tesla P4. The ML-models used are multi-qa-MiniLM-L6-cos-v1 and bert-large-uncased-whole-word-masking-finetuned-squad both are available as pre-built modules in Weaviate.\n\n\ud83d\udcc4 The complete dataset and code is open-source and available on GitHub.\n\nDemo GIF of Weaviate using the Wikipedia dataset\n*Example semantic search queries in Weaviate's GraphQL interface \u2014 GIF by Author*\n\n## Importing the Data In Two Steps\n> You can also directly import a backup into Weaviate without doing the import your self as outlined here.\n\nTo import the data we use two different methods. The first is to clean the data set and the second one is to import the data.\n\n### Step 1 \u2013 Cleaning the Data\nThe first step is pretty straightforward, we will clean the data and create a JSON Lines file to iterate over during import. You can run this process yourself or download the proceed file following this link.\n\n### Step 2 \u2014 Importing the Data\nThis is where the heavy lifting happens because all paragraphs need to be vectorized we are going to use Weaviate's modular setup to use multiple GPUs that we will stuff with models, but before we do this we need to create a Weaviate schema that represents our use case.\n\n### Step 2.1 \u2014 Create a Weaviate Schema\nWithin Weaviate we will be using a schema that determines how we want to query the data in GraphQL and which parts we want to vectorize. Within a schema, you can set different vectorizers and vectorize instructions on a class level.\n\nFirst, because our use case is semantic search over Wikipedia, we will be dividing the dataset into paragraphs and use Weaviate's graph schema to link them back to the articles. Therefore we need two classes; *Article* and *Paragraph*.\n\n```javascript\n{\n  classes: [\n    {\n      class: \"Article\",\n      description: \"A wikipedia article with a title\",\n      properties: {...},\n      vectorIndexType: \"hnsw\",\n      vectorizer: \"none\"\n    },\n    {\n      class: \"Paragraph\",\n      description: \"A wiki paragraph\",\n      properties: {...},\n      vectorIndexType: \"hnsw\",\n      vectorizer: \"text2vec-transformers\"\n    },\n  ]\n}\n```\n\n*Weaviate class structure*\n\nNext, we want to make sure that the content of the paragraphs gets vectorized properly, the vector representations that the SentenceBERT transformers will generate are used for all our semantic search queries.\n\n```javascript\n{\n  name: \"content\",\n  datatype: [\n    \"text\"\n  ],\n  description: \"The content of the paragraph\",\n  invertedIndex: false,\n  moduleConfig: {\n    text2vec-transformers: {\n      skip: false,\n      vectorizePropertyName: false\n    }\n  }\n}\n```\n\n*A single data type that gets vectorized*\n\nLast, we want to make graph relations, in the dataset from step one we will distill all the graph relations between articles that we can reference like this:\n\n```javascript\n{\n  name: \"hasParagraphs\"\n  dataType: [\n    \"Paragraph\"\n  ],\n  description: \"List of paragraphs this article has\",\n  invertedIndex: true\n}\n```\n*Paragraph cross-references*\n\nThe complete schema we import using the Python client can be found here.\n\n## Step 2.2 \u2014 Import the Data\nBecause we are going to vectorize a lot of data. We will be using the same machine as mentioned in the opening but with 4 instead of 1 GPU.\n\nGoogle Cloud GPU setup with a Weaviate load balancer\n*Google Cloud GPU setup with a Weaviate load balancer*\n\nThe load balancer will redirect the traffic to available Weaviate transformer modules so that the import speed significantly increases. In the section: *Implementation Strategies \u2014 Bringing Semantic Search to Production* below you'll find more info about how you can run this in production.\n\nMost critically, we are going to set an external volume in the Docker Compose file to make sure that we store the data outside the container. This will allow us to package the backup and run Weaviate in the last step directly from the backup.\n\nIn the environment variables, we set a CLUSTER_HOSTNAME, an arbitrary name you can set to identify a cluster.\n\n```yaml\nenvironment:\n  TRANSFORMERS_INFERENCE_API: 'http:loadbalancer:8080'\n  QUERY_DEFAULTS_LIMIT: 25\n  AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n  PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n  DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'\n  ENABLE_MODULES: 'text2vec-transformers'\n  CLUSTER_HOSTNAME: '63e2f234026d'\n```\n\n*Docker environment setup*\n\nWe will also set the location of the volume outside Weaviate, in this case the data will be stored in the /var/weaviate folder\n\n```yaml\nvolumes:\n  - /var/weaviate:/var/lib/weaviate\n```\n\n*Volumes for backup*\n\nYou can find the complete Docker Compose file we've used here.\n\n## Query the Data\nThe current Weaviate setup has two modules enabled: semantic search and Q&A. The modules can be used for different types of queries. The query language used is GraphQL and can be used with a wide variety of client libraries in different programming languages.\n\n### Example 1 \u2014 natural language questions\nIn this example, we pose a natural language question, and we will assume that the first result contains the answer (hence the limit is set to 1). The result based on the latest dataset contains a certainty (i.e., the distance from the query to the answer in the vector space) of \u2248 0.68. In your end application, you can set limits to the certainty to determine if you want to present the results to the end-user, in the latest paragraph of this article (Implementation Strategies \u2014 Bringing Semantic Search to Production) you'll find more info about this.\n\n```graphql\n{\n  Get {\n    Paragraph(\n      ask: {\n        question: \"Where is the States General of The Netherlands located?\"\n        properties: [\"content\"]\n      }\n      limit: 1\n    ) {\n      _additional {\n        answer {\n          result\n          certainty\n        }\n      }\n      content\n      title\n    }\n  }\n}\n```\n\n\ud83d\udca1 LIVE \u2014 try out this query%20%7B%0A%20%20%20%20%20%20_additional%20%7B%0A%20%20%20%20%20%20%20%20answer%20%7B%0A%20%20%20%20%20%20%20%20%20%20result%0A%20%20%20%20%20%20%20%20%20%20certainty%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20content%0A%20%20%20%20%20%20title%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D)\n\n### Example 2 \u2014 generic concept search\nOne can not only search for natural language questions, but also generic concepts like \"Italian food\" in the overview below. The `nearText` filter also allows for more specific filters like `moveAwayFrom` and `MoveTo` concepts to manipulate the search through vector space.\n\n```graphql\n{\n  Get {\n    Paragraph(\n      nearText: {\n        concepts: [\"Italian food\"]\n      }\n      limit: 50\n    ) {\n      content\n      order\n      title\n      inArticle {\n        ... on Article {\n          title\n        }\n      }\n    }\n  }\n}\n```\n\n\ud83d\udca1 LIVE \u2014 try out this query%20%7B%0A%20%20%20%20%20%20content%0A%20%20%20%20%20%20order%0A%20%20%20%20%20%20title%0A%20%20%20%20%20%20inArticle%20%7B%0A%20%20%20%20%20%20%20%20...%20on%20Article%20%7B%0A%20%20%20%20%20%20%20%20%20%20title%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D)\n\n### Example 3 \u2014 mix natural language questions with scalar search\nWithin Weaviate you can also mix scalar search filters with vector search filters. In the specific case, we want to conduct a semantic search query through all the paragraphs of articles about the saxophone player Michael Brecker.\n\n```graphql\n{\n  Get {\n    Paragraph(\n      ask: {\n        question: \"What was Michael Brecker's first saxophone?\"\n        properties: [\"content\"]\n      }\n      where: {\n        operator: Equal\n        path: [\"inArticle\", \"Article\", \"title\"]\n        valueText: \"Michael Brecker\"\n      }\n      limit: 1\n    ) {\n      _additional {\n        answer {\n          result\n        }\n      }\n      content\n      order\n      title\n      inArticle {\n        ... on Article {\n          title\n        }\n      }\n    }\n  }\n}\n```\n\n\ud83d\udca1 LIVE \u2014 try out this query%20%7B%0A%20%20%20%20%20%20_additional%20%7B%0A%20%20%20%20%20%20%20%20answer%20%7B%0A%20%20%20%20%20%20%20%20%20%20result%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20content%0A%20%20%20%20%20%20order%0A%20%20%20%20%20%20title%0A%20%20%20%20%20%20inArticle%20%7B%0A%20%20%20%20%20%20%20%20...%20on%20Article%20%7B%0A%20%20%20%20%20%20%20%20%20%20title%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D)\n\n### Example 4 \u2014 mix generic concept search with graph relations\nWith Weaviate you can also use the GraphQL interface to make graph relations like -in the case of Wikipedia- links between different articles. In this overview we connect the paragraphs to the articles and show the linking articles.\n\n```graphql\n{\n  Get {\n    Paragraph(\n      nearText: {\n        concepts: [\"jazz saxophone players\"]\n      }\n      limit: 25\n    ) {\n      content\n      order\n      title\n      inArticle {\n        ... on Article { # \n", "type": "Blog", "name": "blog-semantic-search-with-wikipedia-and-weaviate", "path": "blog/2021-11-25-semantic-search-with-wikipedia-and-weaviate/index.mdx", "link": "https://weaviate.io/blog/semantic-search-with-wikipedia-and-weaviate", "timestamp": "2023-11-02 11:59:00", "reader": "JSON", "meta": {}, "chunks": []}