{"text": "\nEdit (5/Jun/2023): Auto-GPT has temporarily removed support for external vector stores as they refactor their code.\n\nWe are working on re-introducing the integration. For now, please use this version (https://github.com/Significant-Gravitas/Auto-GPT/tree/v0.3.1) to use Auto-GPT with Weaviate.\n\nAs generative language models such as GPT-4 continue to push the boundaries of what AI can do, the excitement surrounding its potential is spreading quickly. Many applications and projects are built on top of GPT-4 to extend its capabilities and features. Additionally, many tools were created in order to interact with large language models, like LangChain as an example. Auto-GPT is one of the fastest rising open-source python projects harnessing the power of GPT-4!\n\n## What is Auto-GPT?\nAuto-GPT has gotten a lot of attention lately, with the amount of stars jumping from 20k to 80k in a matter of days. Auto-GPT chains together \u201cthoughts\u201d and completes various tasks or assignments **autonomously**. It takes GPT-4 one step further by enabling the model to run iteratively and complete various tasks in a siloed fashion. It can write code and execute python scripts, conduct market research, and even order pizza.\n\nChatGPT requires humans to prompt the large language model (LLM) by developing and refining the text prompt. Meaning you need to build out your request step-by-step in order for the LLM to \u201cunderstand\u201d. Auto-GPT on the other hand, is able to independently define objectives needed to complete the assigned task **without (or with reduced) human feedback and intervention**. This is because of its ability to chain together thoughts.\n\nChain of thought is a method that is used to help language models improve their reasoning. It breaks down tasks into the intermediate steps that are needed in order to complete it. The program will then run continuously until it completes these tasks. For example, if it is working on a coding project, it will debug the code as it goes.\n\nLet\u2019s dig a little deeper into how Auto-GPT works under the hood. At the time of writing, Auto-GPT uses GPT-4 (or optionally, GPT-3.5) for text generation and GPT-3.5 for file storage and summarization. At configuration, Auto-GPT is given a list of tools such as a code executor, google search API, or a calculator. Additionally, it is possible to give Auto-GPT access to long-term memory via a vector database, such as Weaviate. Auto-GPT also has access to `skills` which are manifested as pre-configured prompts such as summarization.\n\nArmed with these tools, Auto-GPT begins with a user query. For example, \u201cPlease write out a grocery list and create a recipe using each ingredient.\u201d Auto-GPT takes this task and proposes an action plan to achieve the task such as:\n\nTask: Write out a grocery list based on past items\n\nPlan:\n1. Use the long-term memory from the Weaviate database to curate the list from last week\n2. Order the groceries\n3. Use the internet to look up different recipes\n\nAction:\n1. View previous grocery lists\n2. Order the groceries online\n3. Use the internet to gather recipes\n\nSince Auto-GPT is able to form these action plans autonomously, it is important that it confirms each action was completed. It shouldn\u2019t jump to step 2, if step 1 isn\u2019t finished. It will do this by reasoning with its actions. From there it will review the results and make a refined plan. The ability to reason and refine its actions is what makes Auto-GPT so clever.\n\n## Examples of Auto-GPT\nPeople all over Twitter have shared multiple demos of what they\u2019ve built with Auto-GPT. The possibilities are endless! In this section, we will cover a few popular examples.\n\nSully shared a thread on using Auto-GPT to conduct market research. The task is to understand the space of waterproof shoes and find 5 competitors. It will then need to report the pros and cons of each.\n\nVarun Mayya pointed out the opportunity of having Auto-GPT running autonomously. It was tasked to create an app, however, it noticed Node wasn\u2019t installed so it took it upon itself to download it by finding a Stack Overflow link.\n\nShubham Saboo shared this video of Auto-GPT ordering pizza on Domino's website.\n\nautogpt and weaviate\nautogpt and weaviate\n\n## How to use it in Weaviate\n\nAuto-GPT has both a short-term and long-term memory. By connecting to a vector database, like Weaviate, you enable the application to retrieve specific data. This extension is great if you\u2019re asking Auto-GPT to complete a task that it wasn\u2019t trained on. For example, if you have data about your customer base in Boston and would like to form an ad, Auto-GPT wouldn\u2019t be able to do that because this wasn\u2019t included in the training data. The solution to this problem is to connect to your Weaviate instance so that Auto-GPT can fetch the necessary information. Additionally, Auto-GPT can save and recall its actions for future use.\n\nHere is the codebase to see how Weaviate is integrated in Auto-GPT.\n\nThe easiest way to use Weaviate with Auto-GPT is with a WCS instance. Create a Sandbox instance by following these steps, and install Auto-GPT using the latest instructions from the repo, with the following notes in mind.\n\nNotes:\n- At the time of writing, it suggested using the latest stable release only, rather than the `master` branch.\n- We recommend running Auto-GPT in a Docker container so that it runs in a safer, sandboxed environment.\n- If you intend to run Auto-GPT directly from your device, rather than in a Docker container, we suggest installing the required libraries into a virtual environment, rather than to your system Python.\n\nDuring installation, edit the below variables in the Auto-GPT `.env` file based on the below:\n\n```\nMEMORY_BACKEND=weaviate  # Change from `local`\n\u2026\n\nWEAVIATE_HOST=your-endpoint.weaviate.network  # URL to your Weaviate instance (without \u201chttps://\u201d)\nWEAVIATE_PROTOCOL=https  # http if deploying Weaviate locally with Docker\nWEAVIATE_API_KEY=  # Add the API key here if you have authentication enabled\n```\n\nAnd then, you can start Auto-GPT. You can run it directly on your device, or within a Docker container. To run it directly, run:\n`python -m autogpt`\n\nOr run the following to start it within a Docker container:\n\n```\ndocker build -t autogpt .\ndocker run -it --env-file=./.env -v $PWD/auto_gpt_workspace:/app/auto_gpt_workspace autogpt\n```\n\nThe above steps will allow Auto-GPT to use the WCS instance as the memory backend, allowing it to store and retrieve information as required.\n\nWe note using a local instance of Weaviate with Docker is a little more complicated. You will need to modify the `Docker Compose` file such that the Weaviate container and the Auto-GPT container are able to communicate with each other.\n\n## Proceed with Caution\n\nAlthough Auto-GPT is a great project to try, it is best to test it out with caution. It is currently in the experimental phase, so it is best to not use it in production. Additionally, allowing Auto-GPT to run for a long period of time could get very expensive, and keep in mind that it may affect your device. Such as by writing or modifying files, and installing dependencies for example. If your task requires multiple steps, it is best to keep an eye on your OpenAI API usage, such as by setting a limit on your spend. Check out the disclaimer here.\n\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n", "type": "Blog", "name": "blog-autogpt-and-weaviate", "path": "blog/2023-04-18-autogpt-and-weaviate/index.mdx", "link": "https://weaviate.io/blog/autogpt-and-weaviate", "timestamp": "2023-11-13 10:42:16", "reader": "JSON", "meta": {}, "chunks": []}