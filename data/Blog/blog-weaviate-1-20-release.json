{"text": "1. Multi-tenancy \u2013 A scalable, efficient and easy solution for use-cases with many tenants per Weaviate cluster.\n1. PQ + Re-scoring \u2013 Product quantization (PQ) allows for faster vector search - now at basically no cost to accuracy!\n1. Autocut \u2013 A new way to set a threshold - set how many groups of results to retrieve from the result set.\n1. Search re-ranking \u2013 Multi-stage search (& re-ranking) for better end results. Multiple re-rankers available!\n1. New hybrid search ranking algorithm \u2013 Additional method available for deriving hybrid search scores.\n1. And more.\n\nWe hope we've whetted your appetite - so what're you waiting for?! Keep scrolling \u2b07\ufe0f!\n\nDowngrading from `1.20.x` to a `1.19.x` or lower is not possible.\nPlease proceed with caution, such as by making a backup of your data & schema, or cluster before upgrading.\n\n## Multi-tenancy\n\n> **Store data from up to millions of tenants in a single setup.**\n\nConceptual diagram of multi-tenancy in Weaviate\nConceptual diagram of multi-tenancy in Weaviate\n\nWe\u2019ll keep this brief as Etienne covered this in great detail in this blog post. The key point, though, is that Weaviate now makes it easy to store data from up to *millions of tenants in a single setup*.\n\nThis means that scaling your business or infrastructure to include data from a large group of users is easier and faster than ever. We have worked with our community on this feature to ensure that your compliance needs are met as well as performance needs, while keeping the experience a smooth one for everybody. Our multi-tenancy implementation allows for huge numbers of diverse users - whether they be large or small, and regardless of how often they access Weaviate.\n\nThe result is a multi-tenancy solution that we are very proud of. This is an opt-in feature, where to use multi-tenancy, you simply enable the feature and add the tenant key for each operation as required.\n\n- Concepts: Data # Multi-tenancy\n- How-to manage data: Multi-tenancy operations\n\n## PQ + Re-scoring\n\n> **Compress vectors with little to no recall loss.**\n\nConceptual diagram of query speed vs recall\nConceptual diagram of query speed vs recall\n\nWith `1.20` we\u2019ve improved Product Quantization (PQ) by leaps and bounds and are officially taking it out of experimental mode! Originally PQ was introduced and released in `1.18` and we wrote about it here.\n\nThe short summary is that we\u2019ve made a myriad of improvements around query speed performance, convenience of use with large datasets, added disk retrieval and rescoring to improve recall and more.\n\nFor all the nitty gritty details, take a look at the below sections\n\n\n  Query Performance\n\n\nWith `1.20` we\u2019ve improved query performance when PQ is enabled by implementing a more efficient DistanceLookupTable.\n\nThis was mainly accomplished in two ways:\n\n1. We restructured arrays by collapsing two-dimensional slices into a single dimension.\nThis serves multiple purposes:\nIt improves cache locality during lookups since now allocated memory is contiguous.\nIt allows us to decrease the number of allocations that need to be made. We now allocate one slice as opposed to 128+ sub-slices. This also means that we no longer need to save unnecessary slice headers, further reducing the overall size.\n\n2. We added a pool to reuse lookup lists between requests.\n\n\n\n\n\n\n  Rescoring for Recall Performance\n\n\nWe\u2019ve also improved recall by adding PQ rescoring efficiently to avoid any deterioration in performance. At first, when we calculate nearest neighbour distances, we only use compressed vector representations, this helps reduce memory requirements. However this distance might be inaccurate due to the distortion introduced by the lossy nature of PQ compression. This small distortion could affect the order/ranking of the vectors in the retrieved set which in turn affects the quality and relevance of the search results. To correct for this, we fetch from disk the uncompressed representation of all vectors in the final retrieved set, recalculate the distances to the query vector, and resort the list. After this rescoring phase we are then ready to respond to the query.\n\nAdditionally, with the introduction of rescoring, detailed above, we no longer need to support having more than 256 centroids - based on our testing one byte per code should be more than enough. We use this to optimize the codebook and gain performance by allowing the compiler to inline the extract/put code. We also don\u2019t need to cast bytes into `uint64` anymore since the size is fixed.\n\n\n\n\n\n  Fit Time on Large Datasets\n\nPreviously, if you added a large number of objects prior to enabling quantization the PQ fitting algorithm would take a long time - putting the index into read-only mode. With `1.20` we\u2019ve introduced the `trainingLimit` parameter which lets you define an upper limit on how many objects are used to train the PQ algorithm irrespective of the number of objects added to Weaviate. This parameter defaults to `100000` and so for large datasets if you load more objects, prior to enabling PQ, only `trainingLimit` subset will be used to train PQ - thus limiting the time it takes to fit. In addition to these major changes, we\u2019ve also fixed numerous bugs.\n\n\n\n\n  Experiments - Before & After\n\nBelow we provide a small taste of these experiments comparing PQ `1.18` vs the new and improved PQ of `1.20`. Firstly we show the performance on an experimental dataset followed by a more real-world dataset.\n\n\nFig 1\nFigure 1: Before(V1.18) Using Gist+l2. The Green curve is obtained using uncompressed vectors. Blue compressing with 960 segments (a dimension per segment, 4:1 compression ratio). Orange uses 240 segments (4 dimensions per segment, 16:1 compression ratio).\n\n\nFig 2\nFigure 2: After(V1.20) Using Gist+l2. Both graphs are built using 32 max connections. The orange curve is obtained using uncompressed vectors. The blue when compressing with 160 segments (six dimensions per segment, 24:1 compression ratio).\n\n\nA more real-world dataset example:\n\n\nFig 3\nFigure 3: Using DBPedia vectorized with OpenAI `ada002` using 500,000 vectors + cosine (V1.20). Both graphs are built using 32 max connections. The orange curve is obtained using uncompressed vectors. The blue is obtained by compressing with six dimensions per segment, 24:1 compression ratio.\n\n\nAs can be clearly seen above, previously there was a cost to be paid for compressing whereas now there is no real cost - compressed vs uncompressed performance is nearly identical even at high compression ratios. In addition to the experiments above, where we use Gist and `ada002` vectorized DBPedia, we\u2019ve also done many more tests using real-world datasets including high-dimensional vectors such as Meta\u2019s Sphere. These tests demonstrate that we can generate high recall with PQ + rescoring achieving significant memory reduction. More to follow on these detailed experiments soon!\n\n\n- Concepts: Vector Indexing # Product Quantization\n- How-to configure: Indexes # Vector index (see `pq`)\n\n## Autocut\n\n> **Ask Weaviate to retrieve groups of results for convenience.**\n\nA cute cartoon of Weaviate presenting results\nA cute cartoon of Weaviate presenting results\n\nBefore `1.20`, limiting the number of search results meant manually specifying a `distance` or the `limit` (max) number of objects. Both of which can be a bit cumbersome to use, especially with no prior knowledge of the dataset.\n\nWith Autocut, you can solve this by simply specifying the number of groups of results to be returned. Each \"group\" is determined by reviewing distances between results, so that a \"jump\" in distance between results is considered a new group.\n\n\n  Autocut explained with an example\n\nMore concretely, imagine a set of hypothetical results to a query \u201clarge economy\u201d from a dataset of countries. The results are sorted by distance from the query.\n\n| Title | Distance | Gap > 0.07 | Group |\n| --- | --- | --- | --- |\n| United States | 0.07 | \u2705 | 1 |\n| China | 0.09 | \u274c | 1 |\n| Japan | 0.23 | \u2705 | 2 |\n| France | 0.31 | \u2705 | 3 |\n| Canada | 0.33 | \u274c | 3 |\n| Russia | 0.36 | \u274c | 3 |\n| Indonesia | 0.48 | \u2705 | 4 |\n| Switzerland | 0.50 | \u274c | 4 |\n| Taiwan | 0.51 | \u274c | 4 |\n| Poland | 0.53 | \u274c | 4 |\n\nYou might see that there\u2019s a relatively large jump in distance between some results, for example between \u201cChina\u201d and \u201cJapan\u201d, and another one between \u201cJapan\u201d and \u201cFrance\u201d. Each autocut group would be based on these.\n\nHere, an `autocut` value of 1 would return all \"group 1\" results (i.e. the first 2 results), an `autocut` value of 2 would return all \"group 1\" and \"group 2\" results (i.e. the first 3 results), and so on.\n\n\n\n  An example GraphQL query with Autocut\n\nThis example searches the `Article` class for articles related to \"america\", and retrieves the top 3 groups with Autocut.\n\n```graphql\n{\n  Get {\n    Article (\n      nearText: {\n        concepts: [\"america\"]\n      },\n      # highlight-start\n      autocut: 3\n      # highlight-end\n    ) {\n      prop1\n      prop2\n    }\n  }\n}\n```\n\nPlease refer to our documentation for more code examples, including for various Weaviate client libraries.\n\n\n\n\n  Motivation for Autocut\n\nThe first motivation for Autocut was to provide a better experience to human searchers. By only delivering relevant results, we present a cleaner user interface for information discovery. In addition to human search, there is also fascinating research on how this impacts generative search: in \"Large Language Models Can Be Easily Distracted by Irrelevant Context\", Shi et al. have shown that model performance is dramatically decreased when irrelevant information is included in the prompt. This led to the second motivation for the autocut filter: limiting irrelevant search results that would be fed to generative search.\n\n\n\nAutocut aims approximate where a user would \u201ccut\u201d the results intuitively after observing N jumps in the distance from the query.\n\nIt can be combined with all vector search operators: `nearXXX`, `bm25`, and `hybrid`. `autocut` is placed after the operator, at the same level with `limit`/`offset`. It is disabled by default and can be explicitly disabled by setting its value to 0 or a negative number.\n\n- GraphQL references: Additional operators # Autocut\n- How-to search: Similarity search # Autocut\n- How-to search: BM25 search # Autocut\n- How-to search: Hybrid search # Autocut\n\n## Search re-ranking\n\n> **Multi-stage search for a better final results set.**\n\nA conceptual figure of a multi-stage search with Weaviate\nA conceptual figure of a multi-stage search with Weaviate\n\nWe are introducing our first set of rerankers with two modules:\n- Cohere\u2019s reranker, and\n- Integration with Sentence transformers cross-encoders.\n\nRerankers can improve the quality of the result set by reordering the results of a search, using a more expensive process than the initial search. As a reranker works on a smaller subset of data, different approaches can be used to improve search relevance.\n\nWith our reranker modules, you can conveniently perform multi-stage searches without leaving Weaviate.\n\nIn other words, you can perform a search - for example, a vector search - and then use a reranker to re-rank the results of that search. Our reranker modules are compatible with all of vector, bm25, and hybrid searches.\n\n\n  An example GraphQL query with a reranker\n\nYou can use reranking in a GraphQL query as follows:\n\n```graphql\n{\n  Get {\n    JeopardyQuestion(\n      nearText: {\n        concepts: \"flying\"  # search for \"flying\"\n      }\n      limit: 10\n    ) {\n      answer\n      question\n      _additional {\n        distance\n        rerank(\n          property: \"answer\"\n          query: \"floating\"  # sort \"floating\" results towards the top\n        ) {\n          score\n        }\n      }\n    }\n  }\n}\n```\n\nPlease refer to our documentation for more code examples, including for various Weaviate client libraries.\n\nThis query retrieves 50 results from the `Product` class, using a hybrid search with the query \u201cWhat is ref2vec?\u201d. It then re-ranks the results using the `content` property of the `Product` class, and the query \u201cwhat is ref2vec?\u201d.\n\nYou can specify which `property` of the `Product` class you want to pass to the reranker. Note that here, the returned `score` will include the score from the reranker.\n\n\n\nThis is just a first step in integrating ranking models with Weaviate. Read our blog here for further thoughts on this exciting space, and let us know what you want to see next \ud83d\ude09!\n\n- Modules / Reranker-cohere\n- Modules / Reranker-transformers\n- How-to search: Reranking\n\n## New hybrid search ranking algorithm\n\n> **A score-based hybrid results merger algorithm.**\n\nA conceptual figure of a hybrid score merger\nA conceptual figure of a hybrid score merger\n\nHybrid search uses results from a keyword (BM25) search and a vector search to produce its final set of results. In `1.20`, we introduce a new, optional, ranking algorithm that takes the BM25 and vector search scores to produce a more nuanced ranking of objects.\n\nWe are calling this the `relative score fusion` ranking algorithm, as it works by normalizing and summing the BM25 score and vector similarity values. This is in contrast to the existing `ranked fusion` algorithm which produced a new rank based on a sum of inverses of the BM25 and vector rankings.\n\n\n  Example GraphQL query with relative score fusion\n\nIn this example, we perform a hybrid search on the `Question` class, using the query \u201cfood\u201d. We specifically tell Weaviate to use the `relative score fusion` algorithm to rank the results.\n\n```graphql\n{\n  Get {\n    Question (\n      limit: 3\n      hybrid: {\n        query: \"food\"\n        # highlight-start\n        fusionType: \"relativeScoreFusion\"\n        # highlight-end\n      }\n    ) {\n      question\n      answer\n    }\n  }\n}\n```\n\nPlease refer to our documentation for more code examples, including for various Weaviate client libraries.\n\n\n\nIn our internal benchmarks, it showed improved recall performance over the existing algorithm, and we encourage you to try it out. This change also enables the new `AutoCut` feature to be used with hybrid searches, allowing you to automate how the search result threshold is set.\n\nStay tuned, as we\u2019ll be describing the `relative score fusion` feature in more detail in a separate blog post soon \ud83d\udc40.\n\n- GraphQL references: Search operators # hybrid\n- How-to search: Hybrid\n\n## And more!\n\nA conceptual figure of Weaviate performing a search\nA conceptual figure of Weaviate performing a search\n\n### Request success/failure rate in Prometheus metrics\n\nWith `1.20` we\u2019re rolling out a way to monitor the fraction of requests that succeed/fail due to user errors, and/or server errors. This enables us to track these ratios over time and see if significant updates affect this. Having a code for each request simplifies the log monitoring process!\n\nGiven this new way to track each request, we have added a new metric, `requests_total`. There are three possible statuses:\n- `ok`: request was successful\n- `user_error`: request ended with an error, that is mostly due to *users* wrong API usage\n- `server_error`: request ended with an unexpected error\n\nAdditionally, there are three labels associated with this metric:\n- `api`: `graphql` or `rest`\n- `query_type`: name of the endpoint\n    - `Get` / `Aggregate` / `Explore` / `batch` / `classification` / `misc` / `nodes` / `objects` / `schema` / `backup`\n- `class_name`: name of your class\n\n\n  Example requests\n\nHere are some example requests:\n\n```\nrequests_total{api=\"graphql\",class_name=\"n/a\",query_type=\"\",status=\"ok\"} 839\nrequests_total{api=\"graphql\",class_name=\"n/a\",query_type=\"\",status=\"user_error\"} 3\nrequests_total{api=\"graphql\",class_name=\"n/a\",query_type=\"Aggregate\",status=\"user_error\"} 8\nrequests_total{api=\"graphql\",class_name=\"n/a\",query_type=\"Explore\",status=\"user_error\"} 3\nrequests_total{api=\"graphql\",class_name=\"n/a\",query_type=\"Get\",status=\"user_error\"} 28\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"batch\",status=\"ok\"} 1143\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"classification\",status=\"ok\"} 9\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"misc\",status=\"ok\"} 14\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"nodes\",status=\"ok\"} 12\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"objects\",status=\"ok\"} 839\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"objects\",status=\"server_error\"} 4\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"objects\",status=\"user_error\"} 56\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"schema\",status=\"ok\"} 552\nrequests_total{api=\"rest\",class_name=\"n/a\",query_type=\"schema\",status=\"user_error\"} 55\n```\n\n\n\nThe full list of metrics that are offered can be found here\n\n### Chaos benchmarks improvements\n\nScalability and performance are front of mind for us and as such with `1.20` we\u2019ve introduced new chaos engineering style pipelines to help us assess Weaviate's performance and recall on ANN benchmarks including assessing Weaviate performance on PQ compressed vs. uncompressed vectors.\n\n## Summary\n\nThat's it from us - we hope you enjoy the new features and improvements in Weaviate `1.20`. As always, the new Weaviate releases are available on WCS just a short time after the open source release. So it'll be available for you to use/upgrade very soon.\n\nThanks for reading, and see you next time \ud83d\udc4b!\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n", "type": "Blog", "name": "blog-weaviate-1-20-release", "path": "blog/2023-07-11-weaviate-1-20-release/index.mdx", "link": "https://weaviate.io/blog/weaviate-1-20-release", "timestamp": "2023-11-02 11:59:33", "reader": "JSON", "meta": {}, "chunks": []}