{"text": "![The solution to TL;DRs - Weaviate's summarizer module](./img/hero.png)\n\n(*Note: You can skip to the TL;DR version [below](/blog/solution-to-tl-drs#bonus-tldr-version-edited)* \ud83d\ude09)\n\nHow often do you find yourself facing a wall of text in an email, a report, or a paper, and letting out a sigh? Nobody enjoys hacking their way through boring, dense prose. Especially if it's just to see if the information is even relevant.\n\nIn this day and age, this is a more common problem than ever. For a while now, the bottleneck in knowledge work has been our rate of information discovery and consumption. So how do we solve this problem?\n\nYou probably already know that Weaviate, as a vector database, can help with information cataloging and discovery. But did you know that Weaviate can also summarize information during retrieval?\n\nOur summarizer module ([`sum-transformers`](/developers/weaviate/modules/reader-generator-modules/sum-transformers)) can be added to a Weaviate instance to do exactly that.\n\nAnd as a bonus, we will also show you how to use our new generative module (`generative-openai`) to do the same thing as well.\n\nBy the end, you will see how you can use Weaviate to reduce the amount of TL;DRs ([too long\\; did not read](https://www.merriam-webster.com/dictionary/tldr)) in your life and in the lives of those around you.\n\n## `sum-transformers` in action\n\nSince we\u2019re talking about reducing TL;DRs - let\u2019s cut to the chase. The `sum-transformers` module does one thing - summarize a piece of text into shorter text. For example, it will produce a pithy, to-the-point summary like this:\n\n> *The Sydney Opera House is a multi-venue performing arts centre in Sydney, Australia. The building was designed by Danish architect J\u00f8rn Utzon and opened in 1973. It is one of the most popular visitor attractions in Australia, visited by more than eight million people annually.*\n\nFrom an original text that has about 7x the length!\n\n\n  See original text\n\n*The Sydney Opera House is a multi-venue performing arts centre in Sydney. Located on the foreshore of Sydney Harbour, it is widely regarded as one of the world's most famous and distinctive buildings and a masterpiece of 20th-century architecture. Designed by Danish architect J\u00f8rn Utzon, but completed by an Australian architectural team headed by Peter Hall, the building was formally opened by Queen Elizabeth II on 20 October 1973 after a gestation beginning with Utzon's 1957 selection as winner of an international design competition. The Government of New South Wales, led by the premier, Joseph Cahill, authorised work to begin in 1958 with Utzon directing construction. The government's decision to build Utzon's design is often overshadowed by circumstances that followed, including cost and scheduling overruns as well as the architect's ultimate resignation. The building and its surrounds occupy the whole of Bennelong Point on Sydney Harbour, between Sydney Cove and Farm Cove, adjacent to the Sydney central business district and the Royal Botanic Gardens, and near to the Sydney Harbour Bridge.*\n\n*The building comprises multiple performance venues, which together host well over 1,500 performances annually, attended by more than 1.2 million people. Performances are presented by numerous performing artists, including three resident companies: Opera Australia, the Sydney Theatre Company and the Sydney Symphony Orchestra. As one of the most popular visitor attractions in Australia, the site is visited by more than eight million people annually, and approximately 350,000 visitors take a guided tour of the building each year. The building is managed by the Sydney Opera House Trust, an agency of the New South Wales State Government.*\n\n*On 28 June 2007, the Sydney Opera House became a UNESCO World Heritage Site, having been listed on the (now defunct) Register of the National Estate since 1980, the National Trust of Australia register since 1983, the City of Sydney Heritage Inventory since 2000, the New South Wales State Heritage Register since 2003, and the Australian National Heritage List since 2005. The Opera House was also a finalist in the New7Wonders of the World campaign list.*\n\n\n\nHere are other examples, where the module produced summaries of biographical, mythical, and technical information:\n\n\n  \n    Lewis Hamilton (80% reduction)\n  \n\nSir Lewis Carl Davidson Hamilton (born 7 January 1985) is a British racing driver. In Formula One, Hamilton has won a joint-record seven World Drivers' Championship titles (tied with Michael Schumacher), and holds the records for the most wins (103), pole positions (103) and podium finishes (191) Hamilton joined the McLaren young driver programme in 1998 at the age of 13, becoming the youngest racing driver ever to be contracted by a Formula One team. After six years with McLaren, Hamilton signed with Mercedes in 2013.\n\n#### Original text\n\nSir Lewis Carl Davidson Hamilton   (born 7 January 1985) is a British racing driver currently competing in Formula One, driving for Mercedes-AMG Petronas Formula One Team. In Formula One, Hamilton has won a joint-record seven World Drivers' Championship titles (tied with Michael Schumacher), and holds the records for the most wins (103), pole positions (103), and podium finishes (191), among others.\n\nBorn and raised in Stevenage, Hertfordshire, Hamilton joined the McLaren young driver programme in 1998 at the age of 13, becoming the youngest racing driver ever to be contracted by a Formula One team. This led to a Formula One drive with McLaren for six years from 2007 to 2012, making Hamilton the first black driver to race in the series. In his inaugural season, Hamilton set numerous records as he finished runner-up to Kimi R\u00e4ikk\u00f6nen by one point. The following season, he won his maiden title in dramatic fashion\u2014making a crucial overtake at the last corner on the last lap of the last race of the season\u2014to become the then-youngest Formula One World Champion in history.  After six years with McLaren, Hamilton signed with Mercedes in 2013.\n\nChanges to the regulations for 2014 mandating the use of turbo-hybrid engines saw the start of a highly successful period for Hamilton, during which he won six further drivers' titles. Consecutive titles came in 2014 and 2015 during an intense rivalry with teammate Nico Rosberg. Following Rosberg's retirement in 2016, Ferrari's Sebastian Vettel became Hamilton's closest rival in two championship battles, in which Hamilton twice overturned mid-season point deficits to claim consecutive titles again in 2017 and 2018. His third and fourth consecutive titles followed in 2019 and 2020 to equal Schumacher's record of seven drivers' titles. Hamilton achieved his 100th pole position and race win during the 2021 season.\n\nHamilton has been credited with furthering Formula One's global following by appealing to a broader audience outside the sport, in part due to his high-profile lifestyle, environmental and social activism, and exploits in music and fashion. He has also become a prominent advocate in support of activism to combat racism and push for increased diversity in motorsport. Hamilton was the highest-paid Formula One driver from 2013 to 2021, and was ranked as one of the world's highest-paid athletes by Forbes of twenty-tens decade and 2021. He was also listed in the 2020 issue of Time as one of the 100 most influential people globally, and was knighted in the 2021 New Year Honours. Hamilton was granted honorary Brazilian citizenship in 2022.\n\n\n\n\n\n  \n    The Loch Ness Monster (52% reduction)\n  \n\nThe Loch Ness Monster is said to be a large, long-necked creature. Popular belief in the creature has varied since it was brought to worldwide attention in 1933. Evidence of its existence is disputed, with a number of disputed photographs and sonar readings. The pseudoscience and subculture of cryptozoology has placed particular emphasis on the creature.\n\n#### Original text\n\nThe Loch Ness Monster (Scottish Gaelic: Uilebheist Loch Nis), affectionately known as Nessie, is a creature in Scottish folklore that is said to inhabit Loch Ness in the Scottish Highlands. It is often described as large, long-necked, and with one or more humps protruding from the water. Popular interest and belief in the creature has varied since it was brought to worldwide attention in 1933. Evidence of its existence is anecdotal, with a number of disputed photographs and sonar readings.\n\nThe scientific community explains alleged sightings of the Loch Ness Monster as hoaxes, wishful thinking, and the misidentification of mundane objects. The pseudoscience and subculture of cryptozoology has placed particular emphasis on the creature.\n\n\n\n\n\n  \n    Bitmap Indexes (79% reduction)\n  \n\nA bitmap index is a special kind of database index that uses bitmaps. Bitmap indexes have a significant space and performance advantage over other structures for query of such data. Their drawback is they are less efficient than the traditional B-tree indexes for columns whose data is frequently updated.\n\n#### Original text\n\nBitmap indexes have traditionally been considered to work well for low-cardinality columns, which have a modest number of distinct values, either absolutely, or relative to the number of records that contain the data. The extreme case of low cardinality is Boolean data (e.g., does a resident in a city have internet access?), which has two values, True and False. Bitmap indexes use bit arrays (commonly called bitmaps) and answer queries by performing bitwise logical operations on these bitmaps. Bitmap indexes have a significant space and performance advantage over other structures for query of such data. Their drawback is they are less efficient than the traditional B-tree indexes for columns whose data is frequently updated: consequently, they are more often employed in read-only systems that are specialized for fast query - e.g., data warehouses, and generally unsuitable for online transaction processing applications.\n\nSome researchers argue that bitmap indexes are also useful for moderate or even high-cardinality data (e.g., unique-valued data) which is accessed in a read-only manner, and queries access multiple bitmap-indexed columns using the AND, OR or XOR operators extensively. Bitmap indexes are also useful in data warehousing applications for joining a large fact table to smaller dimension tables such as those arranged in a star schema.\n\n\n\nIf you examine these summaries, you will notice that these sentences are not lifted verbatim from the original text. Instead, what is produced is an *abstractive* summary, which is newly produced based on the original text.\n\nThe summarization module achieves this at query time by passing on the text that is retrieved from Weaviate to a language model that is trained specifically for summarization.\n\nThis means that you can set up your Weaviate instance to not only retrieve the most relevant query results for you but take the next step and add an overview of each retrieved object.\n\n![Summarized documents are easier to understand](./img/weaviate-summarize.png#gh-light-mode-only)\n![Summarized documents are easier to understand](./img/weaviate-summarize-dark.png#gh-dark-mode-only)\n\nSo, in a parallel fashion to the generative module, you can get back the information stored in Weaviate and *then some*.\n\nInstead of this:\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"title\": \"Sydney Opera House\",\n          \"url\": \"https://en.wikipedia.org/wiki/Sydney_Opera_House\",\n          \"wiki_summary\": ...\n        },\n        ...\n      ]\n    }\n  }\n}\n```\n\nYou can get back:\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"summary\": [\n              {\n                \"property\": \"wiki_summary\",\n                \"result\": \"\"\n              }\n            ]\n          },\n          \"title\": \"Sydney Opera House\",\n          \"url\": \"https://en.wikipedia.org/wiki/Sydney_Opera_House\",\n          \"wiki_summary\": ...\n        },\n        ...\n      ]\n    }\n  }\n}\n```\n\nWhere the `` is actually not something that is stored in Weaviate!\n\nHere is how:\n\n## Using `sum-transformers`\n\nThe required steps to make use of this module are as follows:\n\n1. Enable the module in your Docker Compose file (e.g. `docker-compose.yml`).\n1. Add this to your query:\n\n    ```graphql\n    _additional { summary ( properties: [\"\"]) { property result } }\n    ```\n\n1. Parse the results!\n\nThat's all there is to it. Let's take a look at each step in more detail.\n\n### Configuration (`docker-compose.yml`) file\n\nUse the `sum-transformers` module in addition to another vectorizer module, such as `text2vec-transformers`, or an inference-API-based model such as `text2vec-openai/cohere/huggingface`.\n\nAccordingly, the relevant lines are:\n\n```yaml\n---\nservices:\n  weaviate:\n    ...\n    environment:\n      ...\n      ENABLE_MODULES: 'text2vec-contextionary,sum-transformers'\n  ...\n  sum-transformers:\n    image: cr.weaviate.io/semitechnologies/sum-transformers:facebook-bart-large-cnn-1.0.0\n    # image: cr.weaviate.io/semitechnologies/sum-transformers:google-pegasus-xsum-1.2.0  # Alternative model\n    environment:\n      ENABLE_CUDA: '0'\n...\n```\n\nNotice that the `ENABLE_MODULES` variable includes `sum-transformers`, and there is a `sum-transformers` section that specifies the Docker image to be used, specifies the summarizer model, and whether to use CUDA (GPU) acceleration.\n\n\n  Example of an entire configuration yaml\n\n```yaml\n---\nversion: '3.4'\nservices:\n  weaviate:\n    command:\n    - --host\n    - 0.0.0.0\n    - --port\n    - '8080'\n    - --scheme\n    - http\n    image: cr.weaviate.io/semitechnologies/weaviate:1.17.4\n    ports:\n    - 8080:8080\n    restart: on-failure:0\n    environment:\n      CONTEXTIONARY_URL: contextionary:9999\n      SUM_INFERENCE_API: 'http://sum-transformers:8080'\n      QUERY_DEFAULTS_LIMIT: 25\n      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n      DEFAULT_VECTORIZER_MODULE: 'text2vec-contextionary'\n      ENABLE_MODULES: 'text2vec-contextionary,sum-transformers'\n      CLUSTER_HOSTNAME: 'node1'\n  contextionary:\n    environment:\n      OCCURRENCE_WEIGHT_LINEAR_FACTOR: 0.75\n      EXTENSIONS_STORAGE_MODE: weaviate\n      EXTENSIONS_STORAGE_ORIGIN: http://weaviate:8080\n      NEIGHBOR_OCCURRENCE_IGNORE_PERCENTILE: 5\n      ENABLE_COMPOUND_SPLITTING: 'false'\n    image: cr.weaviate.io/semitechnologies/contextionary:en0.16.0-v1.0.2\n    ports:\n    - 9999:9999\n  sum-transformers:\n    image: cr.weaviate.io/semitechnologies/sum-transformers:facebook-bart-large-cnn-1.0.0\n    # image: cr.weaviate.io/semitechnologies/sum-transformers:google-pegasus-xsum-1.2.0  # Alternative model\n    environment:\n      ENABLE_CUDA: '0'\n...\n```\n\n\n\nWith these variables specified, an instance of Weaviate can be spun up with the summarizer module enabled. Next, it's a matter of making queries:\n\nAt the time of writing, Weaviate Cloud Services (WCS) instances do not support the `sum-transformers` module.\n\nHowever, you can perform summarizations with the `generative-openai` module, by providing a specific prompt. Take a look below \ud83d\ude09.\n\n### Results with summaries\n\nSummaries are available at query time. In other words, they are not pre-determined but generated from the results retrieved by the `sum-transformers` model.\n\nThis can be triggered as an `additional` property, with a GraphQL query syntax like so:\n\n```graphql\n{\n  Get {\n     {\n      _additional {\n        summary (\n          properties: [\"\"],\n        ) {\n          property\n          result\n        }\n      }\n    }\n  }\n}\n```\n\nWhere the `_additional { summary ... }` instructs Weaviate to carry out the summarization.\n\nIn this syntax, `properties` specifies the fields to be summarized, where each summary will include a `property` that echoes the field name, and `result` is the summarized text output.\n\nThus, it will produce a result like:\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"Article\": [\n        {\n          \"_additional\": {\n            \"summary\": [\n              {\n                \"property\": \"wiki_summary\",\n                \"result\": \"The Loch Ness Monster is said to be a large, long-necked creature. Popular belief in the creature has varied since it was brought to worldwide attention in 1933. Evidence of its existence is disputed, with a number of disputed photographs and sonar readings. The pseudoscience and subculture of cryptozoology has placed particular emphasis on the creature.\"\n              }\n            ]\n          },\n          \"title\": \"Loch Ness Monster\"\n        },\n      ]\n    }\n  }\n}\n```\n\nNote that in this example, `Article` was the class name, `wiki_summary` was the input text and the query included the `title` field also.\n\n\n  See the full GraphQL query\n\n```graphql\n{\n  Get {\n    Article (\n      limit: 1\n      where: {\n        path: [\"title\"],\n        operator: Like,\n        valueText: \"loch ness\"\n      }\n      ) {\n      title\n      _additional {\n        summary (\n          properties: [\"wiki_summary\"],\n        ) {\n          property\n          result\n        }\n      }\n    }\n  }\n}\n```\n\n\n\nGrabbing these results is relatively straightforward. But as with many tasks that involve language models, there are a few tips and tricks to help you get the most out of this wonderful tool.\n\n### Alternative: `generative-openai`\n\nYou might have heard of our new [`generative-openai` module](/developers/weaviate/modules/reader-generator-modules/generative-openai) already. It can take your results, and provide a prompt to a generative model to get back a response.\n\nSo, this module can also be used to generate summaries by prompting it directly to do so. Below is one such example:\n\n```graphql\n{\n  Get {\n    Article(\n      nearText: {\n        concepts: [\"Bitmap Index\"]\n      }\n      limit: 1\n    ) {\n      title\n      wiki_summary\n      _additional {\n        generate(\n          singleResult: {\n            prompt: \"\"\"\n              Describe the following as a short summary: {wiki_summary}\n            \"\"\"\n          }\n        ) {\n          singleResult\n          error\n        }\n      }\n    }\n  }\n}\n```\n\nThis produced:\n\n> A bitmap index is a special kind of database index that uses bitmaps to efficiently store and query low-cardinality data. It is often used in read-only systems such as data warehouses, and is less efficient than traditional B-tree indexes for frequently updated data. Some researchers argue that bitmap indexes can also be used for moderate or high-cardinality data, and are useful for joining large fact tables to smaller dimension tables in data warehousing applications.\n\nFrom the original text below:\n\n\n  See original text\n\n*A bitmap index is a special kind of database index that uses bitmaps.*\n\n*Bitmap indexes have traditionally been considered to work well for low-cardinality columns, which have a modest number of distinct values, either absolutely, or relative to the number of records that contain the data. The extreme case of low cardinality is Boolean data (e.g., does a resident in a city have internet access?), which has two values, True and False. Bitmap indexes use bit arrays (commonly called bitmaps) and answer queries by performing bitwise logical operations on these bitmaps. Bitmap indexes have a significant space and performance advantage over other structures for query of such data. Their drawback is they are less efficient than the traditional B-tree indexes for columns whose data is frequently updated: consequently, they are more often employed in read-only systems that are specialized for fast query - e.g., data warehouses, and generally unsuitable for online transaction processing applications.*\n\n*Some researchers argue that bitmap indexes are also useful for moderate or even high-cardinality data (e.g., unique-valued data) which is accessed in a read-only manner, and queries access multiple bitmap-indexed columns using the AND, OR or XOR operators extensively. Bitmap indexes are also useful in data warehousing applications for joining a large fact table to smaller dimension tables such as those arranged in a star schema.*\n\n\n\nWhile this is not a custom-trained summarization model, this may be a great alternative solution where `sum-transformers` module cannot be used, or where you may wish to leverage flexible, large language models that are only available through APIs.\n\n## Best practice notes\n\n### GPU usage\n\nThe `sum-transformers` module is configured to spin up a Docker container on your system to carry out the inference (i.e. summarization) task. While inference tasks are far less resource intensive than training, they are still non-trivial.\n\nIt will run much faster on systems that support GPU acceleration with CUDA. CPUs may be fine for occasional or private, evaluation use, but for any kind of deployment, we highly recommend utilizing GPU acceleration.\n\n### Model choice\n\nCurrently, the `sum-transformers` module uses the `bart-large-cnn` model under the hood by default, with an option for the `pegasus-xsum` model. Both of these are well-known, high-performance models trained by Facebook and Google respectively.\n\nIn addition to these two models, however, you can use any model from the Hugging Face Hub (or your own) by following [this guide](/developers/weaviate/modules/reader-generator-modules/sum-transformers#use-another-summarization-module-from-hugging-face).\n\nEven when looking only at language models that are trained for summarization tasks, there is still a wide range of choices in terms of sheer numbers, which vary in the target domain (e.g. medical, legal, scientific, etc.) and size (number of parameters, i.e. speed). If you have specific needs, we recommend investigating other models.\n\n### Avoid too long an input\n\nAll transformer models have a maximum input length size. For example, `bart-large-cnn` has a maximum limit of 1024 tokens, where each token is part of a word (i.e. a few characters).\n\nInputting too long a text into the summarizer module will cause it to throw an error. Accordingly, if you envisage generating summaries using `sum-transformers`, we recommend considering chunking your data at import time to make sure that the content of each field is shorter than the maximum length.\n\n### But also... not too short\n\nThe [Goldilocks Principle](https://en.wikipedia.org/wiki/Goldilocks_principle) also applies here, where too short an input may cause the summarizer model to misbehave (i.e. [hallucinate](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))).\n\nWhen fed insufficient input, the model may \"pad\" the output with tokens that have very little grounding in the truth. Generally speaking, an input length that is shorter than a typical \"summary\" output length by the model is inadvisable.\n\n## Do more with less\n\nAll in all, summarizing your data with Weaviate can be another valuable tool in your toolkit to reduce TL;DRs in our lives. By combining the power of vector search with summarization capabilities, Weaviate offers a practical, easy solution to the problem of information overload.\n\nSo instead of slashing your way through thickets of prose to look for the information you need, work smarter! Whether it's with `generate-openai` or `sum-transformers` - let Weaviate lift you up to give you a bird's eye view of the whole landscape.\n\n## Bonus: TL;DR version (edited):\n\nWeaviate can also summarize information during retrieval through the use of its summarizer module, `sum-transformers`.\n\nThis module can shorten a piece of text into a pithy, to-the-point summary by passing the text retrieved from Weaviate to a language model trained specifically for summarization.\n\nBy using Weaviate to summarize your data, you can reduce the amount of too long; did not read (TL;DR) content in your life and reduce the problem of information overload. The `sum-transformers` module uses the `bart-large-cnn` model by default, with an option for the `pegasus-xsum` model, but any model from Hugging Face Hub can be used.\n\n\n", "type": "Blog", "name": "Blog Solution-to-tl-drs", "path": "blog/2023-02-28-solution-to-tl-drs/index.mdx", "link": "https://weaviate.io/blog/solution-to-tl-drs", "timestamp": "2024-05-08 10:51:30", "reader": "JSON", "meta": {}, "chunks": []}