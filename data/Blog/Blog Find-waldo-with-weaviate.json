{"text": "\n![Using image recognition to find Waldo](./img/hero.png)\n\n\n[https://github.com/tuitejc/WeaviateWaldo](https://github.com/tuitejc/WeaviateWaldo)\n\n\n## Defeated, but not out\u2026\n\nOne night while doing the usual bedtime routine with my son, we started going through a \u201cWhere\u2019s Waldo\u201d book. My son happens to be fantastic at pattern recognition and we raced to see who could find him first. My son was faster than me each time. Assuming that he had obviously memorized the locations on each page, I pulled out my phone and pulled up a fresh new image. He still won!\n\nAfter admitting defeat to my son, I told him I\u2019d be back for a rematch. Realizing his younger eyes would always have the edge, I decided I would try and use something he didn\u2019t have. Weaviate!\n\n## Can Weaviate Find Waldo?\n\nMost use cases I come across while working with users of Weaviate involve searching across text data. Retrieval Augmented Generation (RAG) use cases break up large bodies of text into smaller chunks, then use the context of a natural language question to find appropriate pieces of information, and stuff that into an LLM prompt. Finding the correct pieces of information, or chunks of text, to add into the prompt is the art of creating a good RAG application that doesn\u2019t hallucinate or provide inaccurate information.\n\nWeaviate is well suited for this purpose by converting the text chunks into a multidimensional vector space. By converting natural language questions into a vector, then finding other nearby vectors, Weaviate can easily pinpoint which chunks of data (vectors) are applicable to your question. In other words, Weaviate is really good at finding the \u201cneedle in the haystack\u201d of information.\n\n## Weaviate is Multimodal\n\nBesides text, Weaviate also supports image, or multimodal data and performs the same type of \u201cnear image\u201d search across a vector space. Applying the technique used in RAG applications to chunk text data, I can create chunks of my starting image, and convert each of those into a vector. Then, I can provide an image of Waldo and search across those image chunks for which one is similar. Once I find him, I can re-assemble the original image with the identified chunk highlighted.\n\n![Where's waldo image with grid on top](./img/image4.jpg)\n\n## Docker-Compose\n\nTo start I need to spin up an instance of Weaviate and a vectorizer that supports a multi-modal dataset. Weaviate provides a docker image for the Clip model which is perfectly suited for this use case. It\u2019s lightweight and I can spin up both the vectorizer and Weaviate together using Docker-Compose:\n\n```\nversion: '3.4'\nservices:\n weaviate:\n   image: cr.weaviate.io/semitechnologies/weaviate:latest\n   restart: on-failure:0\n   ports:\n    - 8080:8080\n    - 50051:50051\n   environment:\n     QUERY_DEFAULTS_LIMIT: 20\n     AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n     PERSISTENCE_DATA_PATH: \"./data\"\n     ENABLE_MODULES: multi2vec-clip\n     DEFAULT_VECTORIZER_MODULE: multi2vec-clip\n     CLIP_INFERENCE_API: http://multi2vec-clip:8080\n     CLUSTER_HOSTNAME: 'node1'\n multi2vec-clip:\n   image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1\n   environment:\n     ENABLE_CUDA: 0 # set to 1 to enable\n ...\n```\n\nI did this on my laptop and I only had 16GB of memory and no GPU and was able to run this locally, so this demo is very reproducible. A GPU would increase performance by up to 90% so this is definitely not the preferred method to run this, but it works.\n\nWait a few minutes for the services to start. You can tell when the vectorizer is up and running based on the log in Docker.\n\n![Clip Docker container](./img/image3.png)\n\n## Jupyter Notebook\n\nOnce running, open the WheresWaldo.ipynb notebook and install Weaviate-Client and the PILLOW library for python.\n\nOnce installed set up the connection to your local instance to Weaviate:\n\n```python\nfrom PIL import Image, ImageDraw\nimport base64, os, weaviate\nfrom io import BytesIO\nfrom pathlib import Path\n\nclient = weaviate.connect_to_local()\nprint(\"Connected to Weaviate\")\n```\n\nOnce connected, create the Python functions that do all the work of splitting the image, sending it to Weaviate, and re-assembling it.\n\nIn the next cell we defined how big of chunks we want to use. In this case I set each chunk to 250 pixels by 250 pixels. Based on the requirements of the Clip model, this was the smallest I could go and ended up working well for this initial test.\n\n```python\ninput_image_path = 'images/waldo_ski_image.jpeg'  # Change this to the path of your input image\nschemaName='WaldoCollection'\nsplit_width = 250  # Width of each small image\nsplit_height = 250  # Height of each small image\n```\n\nRunning the next cell will create a new schema within Weaviate. Running this code more than once will delete and re-create the schema.\n\n```python\ncreate_schema(schemaName)\n```\n\nThe next cell will split the Where\u2019s Waldo image locally. We will use these local versions of the image chunks for re-assembly later.\n\n```python\nsplit_image_locally(input_image_path, split_width, split_height, 'images/output')\nprint(\"Image is now split into local directory\")\n```\n\nOnce the images are stored locally we can loop through them and upload them to Weaviate which will automatically create vectors using the Clip vectorizer running alongside Weaviate.\n\n```\nprint(\"Uploading to weaviate in batches...\")\nupload_to_weaviate('images/output',schemaName)\n```\n\n## Upload and Vectorize\n\nNormally I would recommend using batching to upload data but since this is a demo, we want to wait for each image to get vectorized so we know when it\u2019s safe to run a query on the data. This may take a few minutes to run through depending on the resources of the machine you are running it on. GPUs will increase speed significantly, but if you just want to prove a point on your laptop, expect to wait during this part. Go grab a cup of coffee and check your email and by the time you get back to it it will be done.\n\n![image_tooltip](./img/image1.png)\n\n## Find Waldo\n\nOnce it is finished vectorizing we are ready to query Weaviate. Run the following code and it will perform a near_image check on the provided image of Waldo, get the coordinates of the chunk then re-assemble the original image with the chunk highlighted.\n\n```python\nschemaName = \"WaldoCollection\"\ninput_image_path = 'images/waldo_ski_image.jpeg'\nquery_image = 'images/Waldo_ski.png'\n\nhighlighted_parts = findWaldo(query_image,split_width,split_height,schemaName)\nprint(highlighted_parts)\n\nif highlighted_parts == []:\n   print(\"Waldo not found\")\nelse:\n  print(\"Waldo found!\")\n  reassembled_image = reassemble_and_highlight(input_image_path, split_width, split_height, highlighted_parts, 'images/output')\n  reassembled_image.show()  # This will display the reassembled image with highlighted parts\n```\n\n![Waldo image re-assembled and highlighted](./img/image2.png)\n\nIt worked! Using Weaviate I was able to find Waldo in a group of images. This has a lot of implications on the application. Using the same technique you could utilize a large corpus of image data to create an image lookup system.\n\n## The possibilities\n\nImagine taking aerial photos of crops and being able to identify which ones need additional nutrition or water. Take a picture of car damage to get an instant estimation of repair costs. Take a picture of a product to check the price across all major online vendors. You get the idea, but it all goes back to the concept \u201cfinding a needle in a haystack\u201d, which is what we at Weaviate do best.\n\nNow for my rematch\u2026\n\n\n", "type": "Blog", "name": "Blog Find-waldo-with-weaviate", "path": "blog/2024-04-30-find-waldo-with-weaviate/index.mdx", "link": "https://weaviate.io/blog/find-waldo-with-weaviate", "timestamp": "2024-05-08 10:52:06", "reader": "JSON", "meta": {}, "chunks": []}