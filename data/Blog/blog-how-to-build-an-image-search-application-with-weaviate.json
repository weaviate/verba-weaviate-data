{"text": "\nRecently, I was working with my colleague Marcin (an engineer from Weaviate core) on a really cool demo project. The idea was to build an image-search application for dogs, which allows a user to provide a picture of a dog, and the app would respond with the most similar breed. And if a user provides a picture of their partner (I might've tested this on my boyfriend \ud83d\ude04), it returns the breed most similar to them.\n\nOnce we had the demo up and running, I thought this was a perfect opportunity to share it. This blog post is the foundation for you to build another application around image recognition or product search.\n\nThis blog post will guide you to build a full-stack web application in **Python** with **Weaviate** and **Flask**. By the time you are done with the post, you will have built an image-search app! The application will take an image of a dog and return an image from the database that best matches the type of dog in an **instant**.\n\nYou are probably already aware that Weaviate can power \ud83d\ude80 fast vector searches with documents. What you might not be aware of is that it can also power vectorization and searching through other data types, whether it be audio, images, or others.\n\nThis blog post assumes you are familiar with vector search, as well as with spinning up an instance of Weaviate using Docker. If not, that's okay - these guides will help you!\n* Learn about Weaviate\n* Weaviate Installation\n* Docker Installation\n\n\nCheck out this article to learn more about why vector databases are so fast and how they work.\n\nWe will provide code snippets in this post, but you can check out the full code base in the Weaviate Examples GitHub repo under the `nearest-neighbor-dog-search` directory. We encourage you to follow along with us by cloning the repository!\n\nThis blog post covers:\n1. Image Vectorization\n2. Weaviate Database\n3. Flask Application\n\n## Image Vectorization\n\nIn this demo, we will search through a dataset of dog images. The current dataset has ten images of different dog breeds; however, you have the flexibility to change the dataset. Although I use dog pictures for the app, you can easily substitute the dog pictures for any images to make this your own use case \ud83e\udd14.\n\nNote, make sure you add the new images to the `flask-app/static/img` folder and run the `images-to-base64.py` and `upload-data-objects.py` file.\n\nFor a use case like ours, where we would like to identify similar types of dogs, the vectorization must work in a way that captures the information about the dog (breed, size, color, etc.).\n\nThe `img2vec-neural` module in Weaviate is designed to solve this exact problem! The module vectorizes each image to something that represents its contents, so that we can search images based on their semantic similarity. In other words, we can use `img2vec-neural` to query our database to see how similar the dogs are based on the image.\n\n### Img2vec-neural Module\nWeaviate's img2vec-neural module is a flexible vectorizer that enables conversion of images to meaningful vectors. `ResNet-50` is the first model that is supported on Weaviate. `ResNet-50` is a Convolutional Neural Network (CNN) that was trained on the ImageNet database. The model was trained on more than 10 million images and 20,000 classes.\n\n## Weaviate Database\n### Setup\nThe demo contains a `docker-compose.yml` file, which defines all the Weaviate modules required to run this demo. In this file, you will see the module, which in our case is `img2vec-neural` trained on the `ResNet-50` model. To spin up your Weaviate instance, navigate to the `nearest-neighbor-dog-search` directory from the cloned git repository, and run;\n\n```\ndocker compose up -d\n```\nOnce Weaviate is up, check that it is running with:\n\n```bash\npython weaviate-test.py\n```\n\nYou should see something like this, and we are ready to go!\n```\n{\"classes\": []}\n```\n\n### Schema Configuration\n\nThe dataset we're using contains ten dogs, each containing the following properties: breed, image, weight, and filepath. The schema defines a structure into which we will store data in our Weaviate database, where each object type is referred to as a `class`.\n\nThis includes the class name, which in our case is \"Dog\" and the properties, such as `breed`, `image`, and `filepath`. In this case, we also need to add in the vectorizer definition, which is the `img2vec-neural` module, so that Weaviate knows to use that specific vectorizer.\n\nWe will tell Weaviate that breed and filepath values are strings, weight is stored as an integer, and images are stored as a `blob` dataType. Putting it all together, the schema definition should look like the following;\n\n```python\nschema = {\n   \"classes\": [\n       {\n           \"class\": \"Dog\",\n           \"description\": \"Images of different dogs\",\n           \"moduleConfig\": {\n               \"img2vec-neural\": {\n                   \"imageFields\": [\n                       \"image\"\n                   ]\n               }\n           },\n           \"vectorIndexType\": \"hnsw\",\n           \"vectorizer\": \"img2vec-neural\", # the img2vec-neural Weaviate vectorizer\n           \"properties\": [\n               {\n                   \"name\": \"breed\",\n                   \"dataType\": [\"string\"],\n                   \"description\": \"name of dog breed\",\n               },\n               {\n                   \"name\": \"image\",\n                   \"dataType\": [\"blob\"],\n                   \"description\": \"image\",\n               },\n               {\n                   \"name\": \"filepath\",\n                   \"dataType\":[\"string\"],\n                   \"description\": \"filepath of the images\",\n               }\n           ]\n       }\n   ]\n}\n```\nOnce you've defined the schema, it is then added to Weaviate.\n```\nclient.schema.create(schema)\n```\n\nRun the `create-schema.py` to add the schema to your Weaviate instance;\n\n```bash\npython create-schema.py\n```\n\n### Images to Base64\nWe are almost ready to populate our Weaviate database full of cute dogs! We first need to encode the images to base64 values. Encoding the images to base64 is a requirement for using the blob dataType, which we defined in the schema.\n\nThe ten images in the dataset are stored in the `flask-app/static/img` folder. To convert the images to base64 run:\n\n```bash\npython images-to-base64.py\n```\n\nNote, the base64 images are stored in the `base64_images` folder.\n\n### Upload the Data Objects\nNow that we have defined the schema and converted the images to base64 values, we can upload the data objects to Weaviate.\n\nWhen uploading your data objects to Weaviate, you want to import your data in batches. The import speed is faster than uploading the objects one by one. Let's configure the batch process to upload in batches of 100, just in case we add more images.\n\n```python\ndef set_up_batch():\n   client.batch.configure(\n       batch_size=100,\n       dynamic=True,\n       timeout_retries=3,\n       callback=None,\n   )\n```\n\nWe will need to define the data properties that we want to upload. The function below will:\n1. Grab the images in the `base64_images` folder.\n2. Remove the file extension to hold just the breed name.\n3. Set the property values, as defined in the schema.\n4. Upload new data objects to Weaviate\n\n```python\ndef import_data():\n\n    client.batch.configure(batch_size=100)  # Configure batch\n    with client.batch as batch:\n        # Iterate over all .b64 files in the base64_images folder\n        for encoded_file_path in os.listdir(\"./base64_images\"):\n            with open(\"./base64_images/\" + encoded_file_path) as file:\n                file_lines = file.readlines()\n\n                base64_encoding = \" \".join(file_lines)\n                base64_encoding = base64_encoding.replace(\"\\n\", \"\").replace(\" \", \"\")\n\n                # remove .b64 to get the original file name\n                image_file = encoded_file_path.replace(\".b64\", \"\")\n\n                # remove image file extension and swap - for \" \" to get the breed name\n                breed = re.sub(\".(jpg|jpeg|png)\", \"\", image_file).replace(\"-\", \" \")\n\n                # The properties from our schema\n                data_properties = {\n                    \"breed\": breed,\n                    \"image\": base64_encoding,\n                    \"filepath\": image_file,\n                }\n\n                batch.add_data_object(data_properties, \"Dog\")\n```\n\nNow we will connect to the local host and upload the data objects.\n```python\nclient = weaviate.Client(\"http://localhost:8080\")\nset_up_batch()\nclear_up_dogs()\nimport_data()\n```\n\nRun this file with;\n```bash\npython upload-data-objects.py\n```\n\nAnd just like that, you have populated your Weaviate database with pictures of cute dogs and the vector representations of them!\n\nHere is a recap of what we've done so far:\n1. Defined the Weaviate schema\n2. Converted the images to base64 values\n3. Uploaded the data objects to Weaviate\n\nWeaviate Dogs\n\n## Flask Application\nFlask is a web application framework written in Python. Using Flask is a quick and easy way to build a web application, so we will use it in this guide.\n\n### Application File\nFirst, we will need to create our Flask application and connect it to our Weaviate client.\n\n```python\napp = Flask(__name__)\napp.config[\"UPLOAD_FOLDER\"] = \"/temp_images\"\nclient = weaviate.Client(\"http://localhost:8080\")\n```\n\nWe will use the `nearImage` operator in Weaviate, so that it will search for images closest to the image uploaded by the user. To do this we will construct the `weaviate_img_search` function to get the relevant results. The response from our search query will include the closest objects in the Dog class. From the response, the function will output the dog image with the breed name and filepath. Note that the query is also formulated so that the response is limited to two results.\n\n```python\ndef weaviate_img_search(img_str):\n   sourceImage = { \"image\": img_str}\n\n   weaviate_results = client.query.get(\n       \"Dog\", [\"filepath\",\"breed\"]\n       ).with_near_image(\n           sourceImage, encode=False\n       ).with_limit(2).do()\n\n   return weaviate_results[\"data\"][\"Get\"][\"Dog\"]\n```\n\nHow cool is that? We can find visually similar dogs in just a simple query to Weaviate. We could even scale this to millions of images running in milliseconds with Weaviate's ANN index.\n\nOnce we've created the app, we need to define the pages that will be on the website. The homepage will have the ten images of the dogs in our dataset. If you add images, it will also populate on the homepage!\n\nThe `/process_image` page will show the uploaded image along with the results from Weaviate. Once we have the image stored and converted to base64, we will send it to the `weaviate_img_search` function to return the results and re-render the page.\n\nThe code block below will:\n1. Populate the homepage with the images from the dataset.\n2. Save the uploaded image and convert it to base64\n3. Return the `nearImage` results from Weaviate to return the filepaths and breeds\n\n```python\n@app.route(\"/\") # defining the pages that will be on the website\n   def home(): # home page\n       return render_template(\"index.html\", content = list_images())\n\n   @app.route(\"/process_image\", methods = [\"POST\"]) # save the uploaded image and convert it to base64\n   # process the image upload request by converting it to base64 and querying Weaviate\n   def process_image():\n           uploaded_file = Image.open(request.files['filepath'].stream)\n           buffer = BytesIO()\n           uploaded_file.save(buffer, format=\"JPEG\")\n           img_str = base64.b64encode(buffer.getvalue()).decode()\n\n           weaviate_results = weaviate_img_search(img_str)\n           print(weaviate_results)\n\n           results = []\n           for result in weaviate_results:\n               results.append({\n                   \"path\": result[\"filepath\"],\n                   \"breed\": result[\"breed\"]\n               })\n\n           print(f\"\\n {results} \\n\")\n           return render_template(\"index.html\", content = results, dog_image = img_str)\n```\n\nOur `index.html` template has been set up to show images of the returned dog breeds.\n\n```html\n{ % for x in content % }\n\n     \n     {{x[\"breed\"]}} \n\n{ % endfor % }\n```\n\nWe then run the application as follows:\n```python\nif __name__ == \"__main__\":\n   app.run()\n```\n\nNow you will run this file with;\n\n```bash\npython flask-app/application.py\n```\nIf you navigate to 127.0.0.1, you will see the running web app.\n\nLet's test a query to see which dog looks most similar to a Goldendoodle puppy. We can see that the puppy resembles the Goldendoodle and Golden Retriever that are in our database.\n\n\n\nAnd just like that, you've built a complete app! Users can load an image of their favorite dog and see the nearest neighbor breed in the database!\n\n## Summary\nIn this demo, we reviewed how to:\n1. Create and upload your data schema\n2. Connect the Weaviate demo to a web application using Flask\n3. Use the nearImage operator in Weaviate\n\nAnd while this example uses a small dataset, Weaviate can power image searches like this at scale with very large datasets and in production environments. We think that you will be impressed at how fast it is, and how quickly you can build amazing search capabilities with image datasets. And when you do - please tell us all about it! We love hearing from our users in our great community.\n\nThanks for reading, and see you soon. You can also check out the other great Weaviate demos on GitHub!\n\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n", "type": "Blog", "name": "blog-how-to-build-an-image-search-application-with-weaviate", "path": "blog/2022-10-18-how-to-build-an-image-search-application-with-weaviate/index.mdx", "link": "https://weaviate.io/blog/how-to-build-an-image-search-application-with-weaviate", "timestamp": "2024-02-08 21:22:23", "reader": "JSON", "meta": {}, "chunks": []}