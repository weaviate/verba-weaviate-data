{"text": "\nWe are happy to announce the release of Weaviate 1.15, which is packed with great features, significant performance improvements, new distance metrics and modules, and many smaller improvements and fixes.\n\n## The brief\n\nIf you like your content brief and to the point, here is the TL;DR of this release:\n1. \u2601\ufe0fCloud-native backups - allows you to configure your environment to create backups - of selected classes or the whole database - straight into AWS S3, GCS or local filesystem\n1. Reduced memory usage - we found new ways to optimize memory usage, reducing RAM usage by 10-30%.\n1. Better control over Garbage Collector - with the introduction of GOMEMLIMIT we gained more control over the garbage collector, which significantly reduced the chances of OOM kills for your Weaviate setups.\n1. Faster imports for ordered data - by extending the Binary Search Tree structure with a self-balancing Red-black tree, we were able to speed up imports from O(n) to O(log n)\n1. More efficient filtered aggregations - thanks to optimization to a library reading binary data, filtered aggregations are now 10-20 faster and require a lot less memory.\n1. Two new distance metrics - with the addition of Hamming and Manhattan distance metrics, you can choose the metric (or a combination of) to best suit your data and use case.\n1. Two new Weaviate modules - with the Summarization module, you can summarize any text on the fly, while with the HuggingFace module, you can use compatible transformers from the HuggingFace\n1. Other improvements and bug fixes - it goes without saying that with every Weaviate release, we strive to make Weaviate more stable - through bug fixes - and more efficient - through many optimizations.\n\nRead below to learn more about each of these points in more detail.\n\n### Patch 1.15.1 note\nWe have published a patch release v1.15.1.\nTo learn more check the Weaviate 1.15.1 patch release blog.\n\n### Community effort\nNew Contributors\n\n\ud83d\ude00We are extremely happy about this release, as it includes two big community contributions from Aakash Thatte and Dasith Edirisinghe. Over the last few weeks, they collaborated with our engineers to make their contributions.\n\n\ud83d\ude80**Aakash** implemented the two **new distance metrics**, while **Dasith** contributed by implementing the two **new Weaviate modules**.\n\n  \ud83d\udc55We will send some Weaviate t-shirts to Aakash and Dasith soon.\n\n\ud83e\udd17We hope to see many more big and small contributions in the coming months and years. **#CommunityRocks**\n\n## Cloud-native backups\n\nCloud-native backups\n\nCreating and restoring database backups in Weaviate was one of the most requested features from the Weaviate community and customers.\n\nAnd, of course, database backups are not just about disaster recovery. Sometimes we need to migrate our data to a different environment. Maybe because our database grew and now we need more resources, or perhaps we need to set up a new developer environment.\n\nWe listened to your feedback, suggestions and use cases! So we made it our mission for the `1.15` release to design and implement an **elegant solution** with a great **Developer Experience (DX)**, which you will love \ud83d\ude0d to use for years to come.\n\n### Announcement\nIntroducing **Weaviate Cloud-native backups**. \ud83c\udf89\n\nIt allows you to make full database backups (or selected classes) straight to **S3**, **GCS** or the **local filesystem** with a single API call \ud83e\udd29; and restore the data to a Weaviate instance of your choice with another API call.\n\nWhat is really great about this implementation is that you can create a backup without downtime on a running instance. The database stays fully operational (including receiving writes) while the backup is transferred to the remote storage.\n\nThe database backups include data objects, plus their vectors and indexes. This way, restoring a backup is a straight copy of all the required elements without the need to re-create vectors or rebuild the indexes. (Read, this is going to be fast)\n\n### Backup modules\nCloud-native backups in Weaviate are handled with the addition of the new **backup modules**:\n\n* `backup-s3` - for S3\n* `backup-gcs` - for GCS\n* `backup-fs` - for local filesystem\n\nWithout getting into too many details (see the docs for more precise instructions), each module requires a different set of settings.\n\nFor S3 and GCS, you need your cloud bucket name, authentication details and some extra details like a project name or the cloud region.\n\n> For S3 authentication you can use access keys or IAM with role ARN's.\n>\n> For GCS you can use a Google Application Credentials json file.\n\nAlternatively, you can configure backups with the **local filesystem**. All you need here is to provide the path to the backup folder.\n\n> Note, you can have multiple storage configurations - one for each S3, GCS and the local filesystem.\n\n### Creating backups - API\nOnce you have the backup module up and running, you can create backups with a single `POST` command:\n\n```js\nPOST /v1/backups/{storage}/\n{\n  \"id\": \"backup_id\"\n}\n```\n\nThe `storage` values are `s3`, `gcs`, and `filesystem`.\n\nFor example, you can create a backup called **first_backup** and push it to **GCS**, like this:\n\n```js\nPOST /v1/backups/gcs/\n{\n  \"id\": \"first_backup\"\n}\n```\n\nThen, you can check the backup status by calling:\n\n```js\nGET /v1/backups/gcs/first_backup\n```\n\n### Restore\nTo restore a backup, you can call:\n\n```js\nPOST /v1/backups/{store}/{backup_id}/restore\n```\n\nSo, using our previous example, you can restore the **first_backup**, like this:\n\n```js\nPOST /v1/backups/gcs/first_backup/restore\n```\n\nYou can also, check the status of an ongoing restoration by calling:\n\n```js\nGET /v1/backups/gcs/first_backup/restore\n```\n\n### Cross-cloud\nHere is one interesting thing that you might not have noticed. You can use this setup to run Weaviate with one cloud provider but then store and restore backups to/from another cloud provider. So, for example, you can run Weaviate on AWS and use GCS for your backup needs. How cool is that?\n\n### Class backups\nYou can also create backups for specific classes or select which classes you want to restore. Just add one of the following properties to the `POST payload`:\n* `include` - an array class names we want to backup or restore\n* `exclude` - an array class names we don't want to backup or restore\n\nFor example, you can create a backup that includes Cats, Dogs and Meerkats.\n\n```js\nPOST /v1/backups/gcs\n{\n  \"id\": \"first_backup\",\n  \"include\": [\"Cats\", \"Dogs\", \"Meerkats\"]\n}\n```\n\nThen restore all classes, excluding Cats:\n\n```js\nPOST /v1/backups/gcs/first_backup/restore\n{\n  \"exclude\": [\"Cats\"]\n}\n```\n\n### Other use cases\nIt might not be immediately obvious, but you can use the above workflow to migrate your data to other environments.\n\nSo, if one day you find yourself with an environment that is not set up for what you need (i.e. not enough resources). Then create a backup, and restore it in the new environment. \ud83d\ude09\n\n### Follow up\nAre you ready to set up backups for your environment?\nHead to the documentation for a more in-depth overview and instructions.\n\n## Reduced memory usage\n\nReduced memory usage\n\nAs part of the continuous effort to make Weaviate faster, leaner and more powerful, we introduced new optimizations to use less RAM without sacrificing performance.\n\n### Thread pooling optimization\n\nFirst, we set our sights on parallel imports, where we introduced thread pooling to reduce memory spikes while importing data.\n\nPreviously if you had, e.g., 8 CPUs and would import from 4 client threads, each client request would run with a parallelization factor of 8 (one per CPU core). So, in the worst case, you could end up with 32 parallel imports (on a machine with \"only\" 8 CPUs). There is no performance gain if we have more parallelization than there are available CPUs. However, each thread needs additional memory. So with 32 parallel imports, we had the worst of both worlds: High memory usage and no performance gains beyond 8.\n\nWith the fix, even if you import from multiple clients, Weaviate automatically handles the parallelization to ensure that it does not exceed the number of CPU cores. As a result, you get the maximum performance without \"unnecessary\" memory usage.\n\n### HNSW optimization\n\nNext, we optimized memory allocations for the HNSW (vector) index.\n\nWe found that the data structures relied on dynamic allocations. So, even if we knew that an array would never be longer than 64 elements, the Go runtime could still decide to allocate an array[100] in the background when the array reaches 51 elements.\n\nTo fix that, we switched to static allocations, and Weaviate instructs the Go runtime to allocate the exact number of elements. This reduced **static** memory usage even when idle.\n\n### Results\n\n\ud83c\udf89 Between these two major updates, plus some smaller ones, we saw a **significant reduction in memory usage of 10-30%**\ud83d\ude80.\n\n\ud83e\udd14 With this, you can get more out of your existing setups and push your Weaviate instances to do more, or you could save on the resources.\n\n## Better control over Garbage Collector\n\nGOMEMLIMIT\n\nWeaviate is built from the ground up in Go, which allows for building very performant and memory-safe applications. Go is a garbage-collected language.\n\n> *A quick refresher:*\n> In a garbage-collected language, such as Go, C#, or Java, the programmer doesn't have to deallocate objects manually after using them. Instead, a GC cycle runs periodically to collect memory no longer needed and ensure it can be assigned again.\n\n### The problem\n\nWorking with a garbage collector is very safe, and the resource cost of running GC cycles is a fairly small tradeoff. We just need to ensure that we have the right balance of frequency of GC cycles and the buffer of available memory (on top of what we have estimated for our application setup).\n\nNow, increasing each of those comes with a price:\n* Increasing the frequency of GC cycles will use more CPU, which we could make better use of elsewhere.\n* Increasing RAM costs money - and for memory demanding setups, that can be a big \ud83d\udcb0sum.\n\nAnd if we get that balance wrong, we might end up with an Out Of Memory crash.\n\n### The solution\n\nAt the beginning of August, the Go team released `Go 1.19`, which introduced `GOMEMLIMIT`. `GOMEMLIMIT` turned out to be a **game changer for high-memory applications**.\n\nWith GOMEMLIMIT we can provide a soft memory cap, which tells Go how much memory we expect the application to need. This makes the GC more relaxed when RAM is plentiful and more aggressive when memory is scarce.\n\nTo learn more about memory management, GC and GOMEMLIMIT, check out this article, which explains it all in more depth.\n\n### Announcement\n\n\ud83c\udf89We are happy to share that all Weaviate `v1.15` binaries and distributions have been **compiled with Go 1.19** which comes with **GOMEMLIMIT**.\n\nNow, you can set your **soft memory cap** by setting the `GOMEMLIMIT` environment variable like this:\n\n```\nGOMEMLIMIT=120GiB\n```\n\nFor more information, see the Docker Compose environment variables in the docs.\n\n## Faster imports for ordered data\n\nFaster imports for ordered data\n\nWeaviate `v1.5` introduced an **LSM store** (Log-Structured Merge Trees) to increase write-throughput. The high-level idea is that writes are batched up in logs, sorted into a **Binary Search Tree** (BST) structure, and then these batched-up trees are merged into the tree on disk.\n\n### The Problem\n\nWhen importing objects with an inherent order, such as timestamps or row numbers that increase monotonously, the BST becomes unbalanced: New objects are always inserted at the \"greater than\" pointer / right node of the BST. This collapses the binary tree into a linked list with `O(n)` insertion rather than the `O(log n)` promise of the BST.\n\n### The Fix\n\nTo address that in Weaviate `v1.15`, we've extended the BST with a **self-balancing Red-black tree**.\n\nThrough rotations of the tree at insert, Red-black trees ensure that no path from the root to leaf is more than twice as long as any other path. This achieves O(log n) insert times for ordered inserts.\n\nRed-black tree demonstration\n*A visual representation of how the RBT works.*\n\nYou can try it yourself here. Add any ordered input, for example, 1, 2, 3, 4 and see how the tree stays balanced.\n\n### Results\nWe've run a few local tests to paint a better picture of what you could expect.\n\nFirst, we saw that the RB-Tree is a factor of 20 faster than the binary tree when adding objects with sequential keys (just the tree, without anything else).\n\nWith a full import test, we saw a **3x performance improvement** \ud83d\ude80.\n\n* Weaviate `1.14.1` - import time **~38 minutes**\n* Weaviate `1.15.0` - import time **~13 minutes** \ud83d\udd25\n\n## More efficient filtered aggregations\n\nMore efficient filtered aggregations\n\nRecently we've been working with a customer who was running multiple filtered aggregations on a large dataset. Unfortunately, the queries were slow, resulting in Out Of Memory kills in some cases. This was not good enough for what we expected of Weaviate.\n\n### Investigation\n\nTo investigate the issue, we've set up a database with 1M objects and a profiler to watch memory consumption.\n\nWe used that setup to run ten parallel filtered aggregations. Upon reviewing the memory consumption, we noted that some of the filtered aggregations were taking up to **200GB** of RAM (note, this was not the total allocated memory on the heap, as a big part of it was waiting to be collected by GC).\n\n### The issue\nFast forward, we identified two key issues. First, the Go library that we used for reading binary data (`binary.read`) isn't optimized for how we use it in Weaviate, as it makes many temporary memory allocations. Second, for every object in the aggregation, we would allocate new memory on the heap, process the read, and release the memory.\n\n\nThis is a bit like, if we want to eat a cake, we need to put it on a plate, eat the cake and then put the plate in the sink to wash. Now, if we want to eat a million cakes, we will be either very busy washing dishes or have a million plates in the sink (or even run out of plates).\nI am sure you would rather spend more time eating cakes than dealing with plates.\n\nThis is bad for three reasons:\n* Grabbing a new plate for each cake and then washing it takes time - **higher CPU use** with many GC cycles.\n* We would pile up many plates between each wash - **high memory consumption** between each GC cycle.\n* We might run out of clean plates - **OOM crash** if we **run out of RAM**.\n\n### The solution\nTo solve the problem, we implemented two solutions:\n* We created our own library for reading binary data optimized for the Weaviate-specific needs. It makes fewer temporary memory allocations.\n* We made sure to reuse the same memory where possible.\n\nIn the world of cakes, we optimized our eating technique to consume more cakes, and we only need one plate to eat all the cakes.\n\nOn top of that, we've introduced other minor optimizations. So if you are curious about that, drop us a message on Slack, and we can chat some more.\n\n### Results\n\nAs a result, the filtered aggregations are to **10-20x faster** and require less memory.\n\nWhen we rerun the original test (with ten parallel aggregations), we saw the memory consumption drop to 30GB (vs 200GB).\n\n\n\n## New distance metrics\n\nHamming and Manhattan distance metrics\n\nThanks to the community contributions from Aakash Thatte, Weaviate `v1.15` adds two new distance metrics: **Hamming** distance and **Manhattan** distance. In total, you can now choose between five various distance metrics to support your datasets.\n\nCheck out the metrics documentation page for a complete overview of all available metrics in Weaviate.\n\n### Hamming distance\nThe Hamming distance is a metric for comparing two numerical vectors. \nIt compares the vector values dimension by dimension and returns a total count of differing values. The fewer differences, the closer the vectors.\n\nFor example, the Hamming distance for the below vectors is **2**, which is the count of differing values.\n* A `[1, 9, 3, 4, 5]`\n* B `[1, 2, 3, 9, 5]`\n\n### Manhattan distance\nThe Manhattan distance (also known as L1 norm and Taxicab Distance) - calculates the distance between a pair of vectors, as if simulating a route for a Manhattan taxi driver driving from point A to point B - who is navigating the **streets of Manhattan** with the grid layout and one-way streets. For each difference in the compared vectors, the taxi driver needs to make a turn, thus making the ride this much longer.\n\nManhattan taxi driver\n\nThe Manhattan distance is calculated by adding up the differences between vector values.\n\nFollowing our previous example:\n* A `[1, 9, 3, 4, 5]`\n* B `[1, 2, 3, 9, 5]`\n\nWe can calculate the Manhattan distance in these steps:\n1. distance = `|1-1| + |9-2| + |3-3| + |4-9| + |5-5|`\n1. distance = `0 + 7 + 0 + 5 + 0`\n1. distance = `12`\n\nFor a deeper dive into the Hamming and Manhattan distances, check out our blog post on distance metrics. There you will learn how each of the distances works in more detail, when to use each, and how they compare to other metrics.\n\n## New Weaviate modules\n\n\nNew Weaviate modules\n\nThe list of the new goodies included with Weaviate `v1.15` goes on. Courtesy of a fantastic community contribution from Dasith Edirisinghe, we have two new Weaviate modules for you: Summarization and Hugging Face modules.\n\n### Summarization Module\nThe Summarization module allows you to summarize text data at query time.\n\nThe module adds a `summary` filter under the `_additional` field, which lets you list the properties that should be summarized.\n\nFor example, if we broke down this blog post into **chapters** in Weaviate, with **title** and **content** properties.\n\nWe could run a query to summarize the *\"New distance metrics\"* chapter like this:\n\n```graphql\n{\n  Get {\n    Chapter(\n      where: {\n        operator: Equal\n        path: \"title\"\n        valueText: \"New distance metrics\"\n      }\n    ) {\n      title\n      _additional{\n        summary(\n          properties: [\"content\"],\n        ) {\n          property\n          result\n        }\n      }\n    }\n  }\n}\n```\n\nWhich would return the following result:\n\n```graphql\n{\n  \"data\": {\n    \"Get\": {\n      \"Chapters\": [\n        {\n          \"_additional\": {\n            \"summary\": [\n              {\n                \"property\": \"content\",\n                \"result\": \"Weaviate 1.15 adds two new distance metrics - Hamming\n                 distance and Manhattan distance. In total, you can now choose\n                 between five various distance metrics to support your datasets.\n                 Check out the metrics documentation page, for the full overview\n                 of all the available metrics in Weaviate.\"\n              }\n            ]\n          },\n          \"title\": \"New distance metrics\"\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\n```\n\nHead to the Summarization Module docs page to learn more.\n\n### Hugging Face Module\nThe Hugging Face module (`text2vec-huggingface`) opens up doors to over 600 Hugging Face sentence similarity models, ready to be used in Weaviate as a vectorization module.\nNow, that's a lot of new models. \ud83d\ude09\n\n#### How this works\nThe way the module works, Weaviate coordinates the efforts around data imports, data updates, queries, etc. and delegates requests to the Hugging Face Inference API.\n\nYou need a `Hugging Face API Token` to use the Hugging Face module. You can request it here.\n\n*Note. Hugging Face Inference uses a pay-per-use pricing model.\nMake sure to study it well before you run a big job.*\n\nTo learn more, head to the HuggingFace Module docs page.\n\n## Other improvements and bug fixes\n\nOther improvements and bug fixes\n\nAnd, of course, there are many other improvements and bug fixes that went into this release.\n\nYou can find the complete list and the relevant links in the release notes.\n\n## Enjoy\nWe hope you enjoy all the new features, performance improvements, memory savings and bug fixes that made this the best Weaviate release yet!\ud83d\udd25\n\n\n\n\n", "type": "Blog", "name": "blog-weaviate-1-15-release", "path": "blog/2022-09-07-weaviate-1-15-release/index.mdx", "link": "https://weaviate.io/blog/weaviate-1-15-release", "timestamp": "2024-02-08 20:24:01", "reader": "JSON", "meta": {}, "chunks": []}