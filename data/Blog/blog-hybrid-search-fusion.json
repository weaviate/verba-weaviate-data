{"text": "\nHybrid search hero image - shows a combination of results from vector and keyword search\n\n- There are two fusion algorithms available in Weaviate: `rankedFusion` and `relativeScoreFusion`.\n- `rankedFusion` is the default algorithm.\n- `relativeScoreFusion` is the newer algorithm, and likely the better choice for most.\n- We would love to get your feedback on hybrid search. Please fill out this short survey.\n\n-----\n\nAs you might know already, Weaviate can perform many different types of searches, including vector search and keyword search. Vector search is based on similarities of meaning to the input, whereas keyword search is based on how often the input words occur in the results.\n\nVector and keyword based search each have their strengths and weaknesses that arise from this difference, where vector search is more forgiving semantically and keyword search is more precise. Hybrid search enables a \"best-of-both-worlds\" type capability using both of these search types.\n\nThat probably sounds simple enough. But do you know **how** hybrid search combines these results? And that Weaviate recently added a new algorithm for how this is done?\n\nIn this post, we\u2019ll dive into exactly the world of hybrid search to discuss how it works, how results are produced, the algorithms used, and more. So let\u2019s get into it!\n\n- Vector search and keyword search are also known as dense vector search and sparse vector search respectively.\n- Keyword search is also called a BM25 search in Weaviate, as it is based on the BM25F scoring algorithm.\n\n## How does hybrid search work, exactly?\n\nHybrid search main image - a figurative image of Weaviate bot combining results from vector and keyword search to produce hybrid search\n\nHere is an example of a hybrid search:\n\n```python\nresponse = (\n    client.query\n    .get(\"JeopardyQuestion\", [\"question\", \"answer\"])\n    .with_hybrid(query=\"food\", alpha=0.5)\n    .with_limit(5)\n    .do()\n)\n```\n\nAs mentioned, a hybrid search is really two searches under-the-hood. It performs a vector search (similar to `nearText` or `nearVector` in Weaviate) to find most similar objects to the vector of your query. Meanwhile, it also performs a keyword search, which ranks results based on how often the query terms occur.\n\nIn other words, a hybrid search performs both of these searches and combines the results.\n\n\n\n\n\n```python\nresponse = (\n    client.query\n    .get(\"JeopardyQuestion\", [\"question\", \"answer\"])\n    .with_near_text({\"concepts\": [\"food\"]})\n    .with_limit(5)\n    .do()\n)\n```\n\n\n\n\n```python\nresponse = (\n    client.query\n    .get(\"JeopardyQuestion\", [\"question\", \"answer\"])\n    .with_bm25(query=\"food\")\n    .with_limit(5)\n    .do()\n)\n```\n\n\n\n\nEach of these searches will produce results like these:\n\n\n\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"JeopardyQuestion\": [\n        {\n          \"answer\": \"a closer grocer\",\n          \"question\": \"A nearer food merchant\"\n        },\n        {\n          \"answer\": \"Famine\",\n          \"question\": \"From the Latin for \\\"hunger\\\", it's a period when food is extremely scarce\"\n        },\n        {\n          \"answer\": \"Tofu\",\n          \"question\": \"A popular health food, this soybean curd is used to make a variety of dishes & an ice cream substitute\"\n        },\n        {\n          \"answer\": \"gastronomy\",\n          \"question\": \"This word for the art & science of good eating goes back to Greek for \\\"belly\\\"\"\n        },\n        {\n          \"answer\": \"devour flour\",\n          \"question\": \"Voraciously eat an \\\"all-purpose\\\" baking ingredient\"\n        }\n      ]\n    }\n  }\n}\n```\n\n\n\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"JeopardyQuestion\": [\n        {\n          \"answer\": \"food stores (supermarkets)\",\n          \"question\": \"This type of retail store sells more shampoo & makeup than any other\"\n        },\n        {\n          \"answer\": \"cake\",\n          \"question\": \"Devil's food & angel food are types of this dessert\"\n        },\n        {\n          \"answer\": \"a closer grocer\",\n          \"question\": \"A nearer food merchant\"\n        },\n        {\n          \"answer\": \"honey\",\n          \"question\": \"The primary source of this food is the Apis mellifera\"\n        },\n        {\n          \"answer\": \"Giraffe\",\n          \"question\": \"Acacia leaves are the favorite food of this tallest mammal\"\n        }\n      ]\n    }\n  }\n}\n\n```\n\n\n\n\nAs you see in the above examples, vector and keyword searches produce results with objects in different order to each other, if not different objects altogether. And if we inspect the results of our equivalent hybrid query, you\u2019ll notice results from both `vector` and `keyword` search results.\n\n```json\n{\n  \"data\": {\n    \"Get\": {\n      \"JeopardyQuestion\": [\n        {\n          \"answer\": \"a closer grocer\",\n          \"question\": \"A nearer food merchant\"\n        },\n        {\n          \"answer\": \"food stores (supermarkets)\",\n          \"question\": \"This type of retail store sells more shampoo & makeup than any other\"\n        },\n        {\n          \"answer\": \"cake\",\n          \"question\": \"Devil's food & angel food are types of this dessert\"\n        },\n        {\n          \"answer\": \"Famine\",\n          \"question\": \"From the Latin for \\\"hunger\\\", it's a period when food is extremely scarce\"\n        },\n        {\n          \"answer\": \"Tofu\",\n          \"question\": \"A popular health food, this soybean curd is used to make a variety of dishes & an ice cream substitute\"\n        }\n      ]\n    }\n  }\n}\n```\n\nSo, how did they get there?\n\nA short answer is that Weaviate calculates for each object a weighted score, using both result sets. But given that they are two very different search types, how might we combine any numerical outputs from each search? This is not a trivial decision due to the two search types producing different metrics to each other. In some ways, this is where the rubber meets the road, and thus the implementation here is an important part of the hybrid search story.\n\nHybrid searches can be \u2018weighted\u2019 to give more weight to the vector or keyword search. This is done using the `alpha` parameter. You can read more here.\n\n## Fusion algorithms\n\nHybrid relativeScoreFusion algorithm depicted as two judges holding up two scores\nHybrid relativeScoreFusion algorithm depicted as two judges holding up two scores\n\nEach of the two (vector and keyword) searches returns a set of results with its own scores. These scores are then handed over to the selected fusion algorithm. A job of the fusion algorithm is to prepare the scores from each search to be compatible with each other, so that they can be weighted and added up and presented to the user.\n\nAs of `1.20`, there are two algorithms available - one called `rankedFusion` (the current default as of `1.21`) and another called `relativeScoreFusion`.\n\n### rankedFusion\n\nThe `rankedFusion` algorithm is the original hybrid fusion algorithm that has been available since the launch of hybrid search in Weaviate.\n\nIn this algorithm, each object is scored according to its position in the results for the given search, starting from the highest score for the top-ranked object and decreasing down the order. The total score is calculated by adding these rank-based scores from the vector and keyword searches.\n\nNow, let\u2019s take a look at the newer `relativeScoreFusion` algorithm.\n\n### relativeScoreFusion\n\nThe `relativeScoreFusion` algorithm was added in Weaviate version `1.20`.\n\nIn contrast  to `rankedFusion`, however, `relativeScoreFusion` derives each objects score by *normalizing* the metrics output by the vector search and keyword search respectively. The highest value becomes 1, the lowest value becomes 0, and others end up in between according to this scale. The total score is thus calculated by a scaled sum of normalized vector similarity and normalized BM25 score.\n\n## Full example\n\nAfter reviewing each algorithm, let\u2019s go through a complete example to demonstrate the difference between them.\n\n### Base Search Results\n\nLet's say that a search returns **five objects** with **document id** (from 0 to 4), and **scores** from **keyword** and **vector search**, **ordered by score**:\n\n\n  \n    Search Type\n    (id): score(id): score(id): score(id): score(id): score\n  \n  \n    Keyword\n    (1): 5(0): 2.6(2): 2.3(4): 0.2(3): 0.09\n  \n  \n    Vector\n    (2): 0.6(4): 0.598(0): 0.596(1): 0.594(3): 0.009\n  \n\n\n\n### Ranked Fusion\n\nThe score depends on the rank of each result and is computed according to `1/(RANK + 60 +1)`, resulting in:\n\n\n  \n    Search Type\n    (id): score(id): score(id): score(id): score(id): score\n  \n  \n    Keyword\n    (1): 0.0164(0): 0.0161(2): 0.0159(4): 0.0156(3): 0.0154\n  \n  \n    Vector\n    (2): 0.0164(4): 0.0161(0): 0.0159(1): 0.0156(3): 0.0154\n  \n\n\nAs you can see, the results of each rank is identical, regardless of the input score.\n\n### Relative Score Fusion\n\nHere, we normalize the scores \u2013 the largest score is set to 1 and the lowest to 0, and all entries in-between are scaled according to their **relative distance** to the **maximum** and **minimum values**.\n\n\n  \n    Search Type\n    (id): score(id): score(id): score(id): score(id): score\n  \n  \n    Keyword\n    (1): 1.0(0): 0.511(2): 0.450(4): 0.022(3): 0.0\n  \n  \n    Vector\n    (2): 1.0(4): 0.996(0): 0.993(1): 0.986(3): 0.0\n  \n\n\nHere, the scores reflect the relative distribution of the original scores. For example, the vector search scores of the first 4 documents were almost identical, which is still the case for the normalized scores.\n\n### Summary\n\nBefore adding these scores up, they are weighted according to the alpha parameter. Let\u2019s assume `alpha=0.5`, meaning both search types contribute equally to the final result and therefore each score is multiplied by 0.5.\n\nNow, we can add the scores for each document up and compare the results from both fusion algorithms.\n\n\n  \n    Algorithm Type\n    (id): score(id): score(id): score(id): score(id): score\n  \n  \n    Ranked\n    (2): 0.01615(1): 0.016(0): 0.016(4): 0.01585(3): 0.0154\n  \n  \n    Relative\n    (1): 0.993(0): 0.752(2): 0.725(4): 0.509(3): 0.0\n  \n\n\n### What can we learn from this?\n\nFor the vector search, the scores for the top 4 objects (**IDs 2, 4, 0, 1**) were almost identical, and all of them were good results. While for the keyword search, one object (**ID 1**) was much better than the rest.\n\nThis is captured in the final result of `relativeScoreFusion`, which identified the object **ID 1** the top result. This is justified because this document was the best result in the keyword search with a big gap to the next-best score and in the top group of vector search.\n\nIn contrast, for `rankedFusion`, the object **ID 2** is the top result, closely followed by objects **ID 1** and **ID 0**.\n\n## Which one to use?\n\nNow that you know more about these two algorithms, you\u2019re probably wondering this key question: which one to use, and when? Generally, we think that `relativeScoreFusion` might be a good choice.\n\nThe main reason is that `relativeScoreFusion` retains more information from the original searches than `rankedFusion`, which only retains the rankings. More generally we believe that the nuances captured in the vector and keyword search metrics are more likely to be reflected in rankings produced by relativeScoreFusion.\n\nHere are some additional notes on how we see these two:\n\n### Recall performance / benchmarks\n\nIn developing these two algorithms, we carried out some internal benchmarks testing recall on a standard (FIQA) dataset. According to our internal benchmarks, the `relativeScoreFusion` algorithm showed a ~6% improvement in recall over the default `rankedFusion` method.\n\nThis is quite a significant improvement. So in the absence of specific characteristics of your dataset or a need to retain backwards compatibility with previous searches, `relativeScoreFusion` might be a good choice.\n\n### Use with AutoCut\n\nIn `1.20` we introduced the AutoCut feature, which can intelligently retrieve groups of objects from a search. AutoCut relies on there being natural \"clusters\" (groups of objects with close scores).\n\nAutoCut works well with `relativeScoreFusion`, which often results in natural clusters that autocut can detect.\n\n### Why the default choice?\n\nGiven our earlier explanations, you might be wondering why `rankedFusion` is the default algorithm. In fact, currently we believe that `relativeScoreFusion` is more likely to be the better-performing algorithm.\n\nThe answer is that `rankedFusion` is the older, reliable choice that has worked quite well. In the meantime, we have been reviewing how `relativeScoreFusion` is received by the community, and making small tweaks like adding over-search to make it more robust.\n\nSo far, the reaction has been positive. But we are still in the evaluation phase, and we would love to get additional feedback from you, our users. We have prepared this short survey. We would really appreciate your input. Please let us know what you think!\n\n\n\n## Wrap-up\n\nHybrid search in Weaviate offers a powerful blend of vector and keyword search, using the strengths of both to deliver semantically rich results while respecting precision of keyword searches.\n\nAs we've explored, the introduction of `relativeScoreFusion` expands Weaviate\u2019s hybrid search capabilities that began its life with the `rankedFusion` algorithm. We invite you to dive in, experiment with these fusion algorithms, and share your experiences.\n\n### Further resources\n\n- How-to: Hybrid search\n- API References: Hybrid search\n\n", "type": "Blog", "name": "blog-hybrid-search-fusion", "path": "blog/2023-08-29-hybrid-search-fusion/index.mdx", "link": "https://weaviate.io/blog/hybrid-search-fusion-algorithms", "timestamp": "2023-11-13 10:42:30", "reader": "JSON", "meta": {}, "chunks": []}