{"text": "1. `ContainsAny` and `ContainsAll` operators added \u2013 Convenient, new operators to simplify complex queries.\n1. Multi-tenancy improvements \u2013 Experimental tenant deactivation for efficiency, performance improvements.\n1. New vectorizer modules\n    - `text2vec-gpt4all` provides fast transformer inference on CPUs; and\n    - `multi2vec-bind` vectorizes multi-modal data from up to 7 modalities.\n1. Performance improvements \u2013 A suite of improvements to search, indexing and backup performance.\n1. Hybrid search algorithm refinement - Improved scoring stability for small limits in hybrid search.\n\n`1.21` is already available on Weaviate Cloud Services - so try it out!\n\nFor more details, keep scrolling \u2b07\ufe0f!\n\n## `ContainsAny` and `ContainsAll` operators\n\nNew `ContainsAll` / `ContainsAny` filter operators\n\nYou asked for it - and it\u2019s here! `1.21` adds `ContainsAny` and `ContainsAll` operators to make your filters (syntactically) sweeter than ever.\n\nYou can use these to reduce complex chains of `And` or `Or` where filters to simple, digestible, queries that are easier on your eye and your brain.\n\nThese operators allow you to filter an array property, using a query array.\n\n`ContainsAny` will find all objects whose property contains one or more (i.e. *any*) of the query values. In other words - a series of `Or` statements.\n\n`ContainsAll`, on the other hand, will find all objects whose property contains every single one (i.e. *all*) of the query values. This can replace a series of `And` statements.\n\nThis is one of our most-requested features, and we are very excited for you to try it out.\n\n\n  Example usage\n\nConsider a dataset of people (class `Person`), where each `Person` object has a `name` and a `languages_spoken` property.\n\nA `ContainsAny` like this will return all `Person` objects whose `languages_spoken` values contain any of the listed languages in the query.\n\n```graphql\n{\n  Get {\n    Person (\n      where: {\n        path: [\"languages_spoken\"],\n        operator: ContainsAny,\n        valueText: [\"Chinese\", \"French\", \"English\"]\n      }\n    )\n    {\n      languages_spoken\n      name\n    }\n  }\n}\n```\n\nA `ContainsAll` query on the other hand will return all `Person` objects whose `languages_spoken` values contain every single one of the listed languages in the query.\n\n```graphql\n{\n  Get {\n    Person (\n      where: {\n        path: [\"languages_spoken\"],\n        operator: ContainsAll,\n        valueText: [\"Chinese\", \"French\", \"English\"]\n      }\n    )\n    {\n      languages_spoken\n      name\n    }\n  }\n}\n```\n\n\n\n## Multi-tenancy improvements\n\n### Deactivate / activate tenant shards (experimental)\n\nActivate / Deactivate tenants\n\nWe introduced multi-tenancy (MT) with `1.20`, and we are thrilled by your response so far.\n\n`1.21` adds an (experimental) feature to deactivate or activate individual tenants. This will allow you to scale even bigger with ease, because inactive tenants' data will not take up any space in memory.\n\nThis is possible because under the hood, each tenant is a partition shard, and tenant shards can now be deactivated while still retaining the data. Deactivated (`COLD`) shards do not consume memory or file descriptors, so this enables an unlimited number of non-active shards, limited only by disk space, while giving active (`HOT`) shards access to resources that they need.\n\nDeactivating unused subsets of data will help to reduce cost and improve the overall performance. We are very excited for you to try it out.\n\n> Read more:\n> - REST API: Schema: Multi-tenancy\n> - Concepts: Data: Multi-tenancy\n\nPlease use it with caution.\n\n### Improved cycle management for MT\n\nWith `1.21`, we've improved resource usage in a MT environment.\n\nAs you might imagine, enabling large-scale MT requires managing a large number of processes, unifying and centralizing the scheduling of background processes in each shard.\n\nWe've improved the way Weaviate manages these processes, leading to a more stable setup in a MT environment.\n\n## New modules\n\n### `text2vec-gpt4all` module\n\nNew `text2vec-gpt4all` module\n\nThis module allows you to perform local vectorization of text using the gpt4all library.\n\nA key benefit of this module is that it is optimized for CPU using `ggml`. For those of you without a GPU on hand, you can now take advantage of a transformer-architecture model without sacrificing speed.\n\nCurrently, `text2vec-gpt4all` supports the `all-MiniLM-L6-v2` model.\n\nIf you are looking to perform local vectorization and don't have a GPU, this module could be a great option for you.\n\n- Input text is truncated to 256 tokens. If you need to use longer chunks, you should explore a different module.\n- Available for `x86-64` devices only.\n\n> Read more:\n> - Modules: text2vec-gpt4all\n\n### `multi2vec-bind` module\n\nNew `multi2vec-bind` module\n\nWith `1.21` we are introducing a second multimodal module to Weaviate! The `multi2vec-bind` module will allow users to generate embeddings using the ImageBind model from Meta AI/FAIR out of the box.\n\nWe will cover some highlights about this great multimodal model below. For a detailed overview, have a look at this blog and the paper.\n\n`multi2vec-bind` can generate vectors from an impressive 7 different modalities of data! You can now embed data containing any combination of text, image, video, audio, inertial measurement unit (IMU) - accelerometer and gyroscope data, depth images, and thermal images with Weaviate.\n\n\n  How is this possible?\n\nImageBind is able to understand multiple modalities because it actually consists of multiple models, each that specializes in understanding one modality.\n\nThe embedding space for these specialist models is then unified/fused by using a contrastive loss function. This loss function, similar to its use in training the CLIP model, is used to make sure that similar concepts across different modalities are located \u201ccloser\u201d together in vector space.\n\nSo for example the vector representations of the sound of a lion roaring, the image of a lion roaring and the text \u201clion roaring\u201d should all be close in vector space whereas the multimodal representation of a car, should be further away.\n\nThe ability to encode and represent all of these modalities of data is quite exciting because now Weaviate can understand and perform cross-modal search and retrieval.\n\nThis means that when using the `multi2vec-bind` module you can query with and retrieve any of the above combinations of modalities. For example, you can perform a `nearAudio` search by passing in a sound file of a lion roaring as a query and retrieve a picture of a lion roaring. Or perhaps you want you\u2019ve got a tune stuck in your head but can\u2019t remember which song it\u2019s from? You can now record yourself humming the tune and then pass that in as a query to perform audio to audio search to retrieve the closest matching song! The possibilities are excitingly endless.\n\n\n\nWe know you've just been dying to vectorize that data from your accelerometer and gyroscope, and now you can! \ud83d\ude09\n\nTake a look at some examples of cross-modal search with `multi2vec-bind` below. Here, we are searching over a set of images using an audio file and then a video file, respectively.\n\n#### Example 1: Audio Search with car_audio.wav\n\n\n```python\nclient.query\n.get(\"BindExample\", [\"text\"])\n.with_near_audio({\"audio\" : \"car_audio.wav\"})\n.do()\n```\n\nTop retrieved image:\n\nImage of a car representing the top retrieved image from an audio search\n\n#### Example 2: Video Search with bird.mp4\n\n\n```python\nclient.query\n.get(\"BindExample\", [\"text\"])\n.with_near_video({\"video\" : \"bird.mp4\"})\n.do()\n```\n\nTop retrieved image:\n\nImage of a bird representing the top retrieved image from a video search\n\nWe\u2019ll explore the awesomeness of this new module more in a blog soon but for now, you can read more about the details of how you can use `multi2vec-bind` in the documentation.\n\n> Read more:\n> - Modules: multi2vec-bind\n\n## Performance improvements\n\nPerformance improvements\n\n### Alternative virtual memory access (pread vs mmap)\n\nThere is now an option to use `pread` for virtual memory access by setting it in the `PERSISTENCE_LSM_ACCESS_STRATEGY` environment variable.\n\nWeaviate has been using `mmap` to map a portion of disk space to virtual memory. While `mmap` is performant, it can lead to stalling situations under heavy load or memory pressure due to Weaviate not being aware that the memory is in fact virtual.\n\nIf this is an issue for you, you can use `pread` for virtual memory access.\n\n`pread` provides better responsiveness and avoids inducing downtime in a cluster. The tradeoff is that `pread` does not provide the same memory management benefits as `mmap`, and may not be as fast as memory access.\n\nThe current default will remain `mmap` - so if you want to change it, you must set the `PERSISTENCE_LSM_ACCESS_STRATEGY` environment variable to `pread`.\n\n\n  Further technical details\n\n\n\nWith `mmap`, the operating system handles the disk access. It maps files or devices into memory, which can be beneficial for large files because it doesn't require the entire file to be loaded into memory. For example, it can cache the entire disk enough memory is available, resulting in fast access.\n\n\n\n\nHowever, under heavy load or memory pressure, the use of `mmap` can lead to scalability issues and slow down the system.\n\n\n\n\nOn the other hand, the `pread` function performs regular disk I/O at a specific position.\n\n\n\n\nIt is similar to `mmap` in that it reads a specified number of bytes from a specific byte position. But, the Go runtime is aware of the disk I/O operations performed with `pread`, while it is not with `mmap` (as it is handled by the OS). So, disk I/O operations are handled differently between these two functions.\n\n\n\n\nWith `pread`, When a goroutine is waiting for disk I/O, the Go runtime parks it and works on other tasks in the meantime. This means that the goroutine is not blocked and does not cause performance issues.\n\n\n\n\n\n> Read more:\n> - References: Configuration: Environment variables\n> - Paper: \"Do you really want to use mmap in your DBMS?\"\n\n### Multiprocessing speedups for ARM64 processors\n\nFor those of you on ARM processors, you'll be happy to know that `simd` multiprocessing instructions are now used for faster distance calculations on ARM64 processors.\n\nThis optimization results in significant performance (up to ~40%!) improvements, especially for large data sets and high-dimensional embeddings.\n\nYou don't have to do anything to take advantage of this feature. Weaviate automatically detects the architecture and enables the optimization if it is supported.\n\n\n> Read more:\n> - References: Distance metrics: Implementations\n\n### Vector indexing improvements\n\nThe vector indexing (HNSW) algorithm has been updated to improve performance.\n\n#### Delta encoding\n\nThis release changes how the HNSW graph connections are stored in memory.\n\nPreviously, the graph was stored as an array with all the edges. However, from `1.21`, the graph is stored as a delta-encoded array, which is more efficient. This reduces the memory footprint of the graph, and improves performance.\n\n#### Reduce HNSW lock contention\n\nThis change reduces the potential for HNSW lock contention, improving performance.\n\nFrom `1.21` onward, the HNSW locking algorithms have been updated to be more selective about what needs to be protected and how, during read/write processes.\n\nOur internal testing showed improved performance by up to 20% in some cases.\n\n### Backup improvements\n\nYour backups will now be smaller, and will likely incur lower costs from cloud storage providers.\n\nThe new and improved backup process combines and compresses the required files to one backup file. Where there are a large number of files - such as with multi-tenancy users - this will be particularly beneficial.\n\nNot only will it compress the data, it will reduce the number of file operations, improving efficiency and reducing cloud storage costs.\n\nDue to this change, backups from `1.21` cannot be used to restore in a `1.20` instance.\n\nIf you might need to roll back, we recommend making a backup from `1.20` before upgrading to `1.21`.\n\n## Hybrid search algorithm refinement\n\nWe have introduced a small change with our new hybrid fusion scoring algorithm.\n\nWhere hybrid search is carried out with a small limit, a higher (internal) limit is used to determine the scoring, before returning the results with the original limit.\n\nThis addresses a potential issue where the scoring could be unstable with a small limit, as the scoring is based on a small number of results.\n\nAs a user, you don't need to do anything to take advantage of this change. It is automatically applied to all hybrid searches.\n\n## Summary\n\nThat's it from us - we hope you enjoy the new features and improvements in Weaviate `1.21`. This release is already available on WCS. So you can try it out yourself on a free sandbox, or by upgrading!\n\nThanks for reading, and see you next time \ud83d\udc4b!\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n\n", "type": "Blog", "name": "blog-weaviate-1-21-release", "path": "blog/2023-08-22-weaviate-1-21-release/index.mdx", "link": "https://weaviate.io/blog/weaviate-1-21-release", "timestamp": "2023-11-02 11:59:36", "reader": "JSON", "meta": {}, "chunks": []}