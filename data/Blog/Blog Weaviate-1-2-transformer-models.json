{"text": "\n### Weaviate v1.2 introduction video\n\n\n    \n\n\n## What are transformers?\nA [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)) (e.g., [BERT](https://en.wikipedia.org/wiki/BERT_(language_model))) is a deep learning model that is used for NLP tasks. Within Weaviate the transformer module can be used to vectorize and query your data.\n\n## Getting started with out-of-the-box transformers in Weaviate\nBy selecting the text-module in the [Weaviate configuration tool](/developers/weaviate/installation/docker-compose#configurator), you can run Weaviate with transformers in one command. You can learn more about the Weaviate transformer module [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers).\n\n![Weaviate configurator \u2014 selecting the Transformers module](./img/configurator-demo.gif)\n*Weaviate configurator \u2014 selecting the Transformers module*\n\n## Custom transformer models\nYou can also use custom transformer models that are compatible with Hugging Face's `AutoModel` and `AutoTokenzier`. Learn more about using custom models in Weaviate [here](/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-transformers).\n\n## Q&A style questions on your own dataset answered in milliseconds\nWeaviate now allows you to get to sub-50ms results by using transformers on your own data. You can learn more about Weaviate\u2019s speed in combination with transformers in [this article](https://towardsdatascience.com/a-sub-50ms-neural-search-with-distilbert-and-weaviate-4857ae390154).\n\n\nimport WhatNext from '/_includes/what-next.mdx'\n\n\n", "type": "Blog", "name": "Blog Weaviate-1-2-transformer-models", "path": "blog/2021-03-30-weaviate-1-2-transformer-models/index.mdx", "link": "https://weaviate.io/blog/weaviate-1-2-transformer-models", "timestamp": "2024-05-08 10:51:10", "reader": "JSON", "meta": {}, "chunks": []}